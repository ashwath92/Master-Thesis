<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:42:18Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|143001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05987</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Priority Rules on ATN (PRT) Intersections</dc:title>
 <dc:creator>Grabski, Waldemar</dc:creator>
 <dc:creator>Daszczuk, Wiktor B.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>68U20</dc:subject>
 <dc:subject>I.6.3</dc:subject>
 <dc:description>  In Autonomous Transit Networks some basic elements influence the throughput:
network structure, maximum velocity, number of vehicles etc. Other parameters
like station structure, dynamic routing or vehicle behavior on intersections
play minor role. Yet in highly congested nets, when vehicles interfere in the
traffic, some subtle decisions may influence overall system ridership. We
tested the impact of intersection priority rules on passenger waiting time,
which measures the throughput. The dependence occurred its relevance in a
crowded network.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, 1 table</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.05987</dc:identifier>
 <dc:identifier>Autobusy-TEST vol. 18(2017), No. 12, pp. 1503-1506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05989</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Data-Aided Carrier Frequency Offset, Phase Offset, Amplitude and
  SNR Estimation for Millimeter-Wave MIMO Systems</dc:title>
 <dc:creator>Rodr&#xed;guez-Fern&#xe1;ndez, Javier</dc:creator>
 <dc:creator>Gonz&#xe1;lez-Prelcic, Nuria</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work is devoted to solve the problem of estimating the carrier frequency
offset, phase offset, amplitude, and SNR between two mmWave transceivers.
  The Cram\'{e}r-Rao Lower Bound (CRLB) for the different parameters is
provided first, as well as the condition for the CRLB to exist, known as
Regularity Condition. Thereafter, the problem of finding suitable estimators
for the parameters is adressed, for which the proposed solution is the Maximum
Likelihood estimator (ML).
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.05989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05990</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Machine Learning to Enhance Vehicles Traffic in ATN (PRT) Systems</dc:title>
 <dc:creator>Czejdo, Bogdan</dc:creator>
 <dc:creator>Daszczuk, Wiktor B.</dc:creator>
 <dc:creator>Baszun, Miko&#x142;aj</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  This paper discusses new techniques to enhance Automated Transit Networks
(ATN, previously called Personal Rapid Transit - PRT) based on Artificial
Intelligence tools. The main direction is improvement of the cooperation of
autonomous modules that use negotiation protocols, following the IoT paradigm.
One of the goals is to increase ATN system throughput by tuning up autonomous
vehicles cooperation. Machine learning (ML) was used to improve algorithms
designed by human programmers. We used &quot;existing controls&quot; corresponding to
near-optimal solutions and built refinement models to more accurately relate a
system's dynamics to its performance. A mechanism that mostly influences ATN
performance is Empty Vehicle Management (EVM). The algorithms designed by human
programmers was used: calls to empty vehicles for waiting passengers and
balancing based on reallocation of empty vehicles to achieve better regularity
of their settlement. In this paper we discuss how we can improve these
algorithms (and tune them to current conditions) by using ML to tailor
individual behavioral policies. Using ML techniques was possible because our
algorithm is based on a set of parameters. A number of weights and thresholds
could be tuned up to give better decisions on moving empty vehicles across the
track.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.05990</dc:identifier>
 <dc:identifier>Autobusy-TEST vol. 18(2017), No. 12, pp. 1484-1489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05997</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Taming Wild High Dimensional Text Data with a Fuzzy Lash</dc:title>
 <dc:creator>Karami, Amir</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  The bag of words (BOW) represents a corpus in a matrix whose elements are the
frequency of words. However, each row in the matrix is a very high-dimensional
sparse vector. Dimension reduction (DR) is a popular method to address sparsity
and high-dimensionality issues. Among different strategies to develop DR
method, Unsupervised Feature Transformation (UFT) is a popular strategy to map
all words on a new basis to represent BOW. The recent increase of text data and
its challenges imply that DR area still needs new perspectives. Although a wide
range of methods based on the UFT strategy has been developed, the fuzzy
approach has not been considered for DR based on this strategy. This research
investigates the application of fuzzy clustering as a DR method based on the
UFT strategy to collapse BOW matrix to provide a lower-dimensional
representation of documents instead of the words in a corpus. The quantitative
evaluation shows that fuzzy clustering produces superior performance and
features to Principal Components Analysis (PCA) and Singular Value
Decomposition (SVD), two popular DR methods based on the UFT strategy.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.05997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05999</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing Political Fake News in Twitter by its Meta-Data</dc:title>
 <dc:creator>Amador, Julio</dc:creator>
 <dc:creator>Oehmichen, Axel</dc:creator>
 <dc:creator>Molina-Solana, Miguel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This article presents a preliminary approach towards characterizing political
fake news on Twitter through the analysis of their meta-data. In particular, we
focus on more than 1.5M tweets collected on the day of the election of Donald
Trump as 45th president of the United States of America. We use the meta-data
embedded within those tweets in order to look for differences between tweets
containing fake news and tweets not containing them. Specifically, we perform
our analysis only on tweets that went viral, by studying proxies for users'
exposure to the tweets, by characterizing accounts spreading fake news, and by
looking at their polarization. We found significant differences on the
distribution of followers, the number of URLs on tweets, and the verification
of the users.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.05999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06013</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compositional abstraction refinement for control synthesis</dc:title>
 <dc:creator>Meyer, Pierre-Jean</dc:creator>
 <dc:creator>Dimarogonas, Dimos V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a compositional approach to specification-guided
abstraction refinement for control synthesis of a nonlinear system associated
with a method to over-approximate its reachable sets. Given an initial coarse
partition of the state space, the control specification is given as a sequence
of the cells of this partition to visit at each sampling time. The dynamics are
decomposed into subsystems where some states and inputs are not observed, some
states are observed but not controlled and where assume-guarantee obligations
are used on the uncontrolled states of each subsystem. A finite abstraction is
created for each subsystem through a refinement procedure starting from a
coarse partition of the state space, then proceeding backwards on the
specification sequence to iteratively split the elements of the partition whose
coarseness prevents the satisfaction of the specification. Each refined
abstraction is associated with a controller and it is proved that combining
these local controllers can enforce the specification on the original system.
The efficiency of the proposed approach compared to other abstraction methods
is illustrated in a numerical example.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06013</dc:identifier>
 <dc:identifier>Nonlinear Analysis: Hybrid Systems, Volume 27, 2018, Pages 437-451</dc:identifier>
 <dc:identifier>doi:10.1016/j.nahs.2017.10.006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06014</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical decomposition of LTL synthesis problem for mixed-monotone
  control systems</dc:title>
 <dc:creator>Meyer, Pierre-Jean</dc:creator>
 <dc:creator>Dimarogonas, Dimos V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper deals with the control synthesis problem for a continuous
nonlinear dynamical system under a Linear Temporal Logic (LTL) formula. The
proposed solution is a top-down hierarchical decomposition of the control
problem involving three abstraction layers of the problem, iteratively solved
from the coarsest to the finest. The LTL planning is first solved on a small
transition system only describing the regions of interest involved in the LTL
formula. For each pair of consecutive regions of interest in the resulting
accepting path satisfying the LTL formula, a discrete plan is then constructed
in the partitioned workspace to connect these two regions while avoiding unsafe
regions. Finally, an abstraction refinement approach is applied to synthesize a
controller for the dynamical system to follow each discrete plan. The first two
steps let us find a discrete plan satisfying the LTL formula with reduced
computation need, even for large workspaces. The second main contribution, used
in the third abstraction layer, is the extension of finite-time reachability
analysis based on the monotonicity property to any (non-monotone) continuously
differentiable system, at the cost of an increased conservativeness. The
proposed framework is demonstrated in simulation for a motion planning problem
of a mobile robot modeled as a unicycle.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06015</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StackInsights: Cognitive Learning for Hybrid Cloud Readiness</dc:title>
 <dc:creator>Qiao, Mu</dc:creator>
 <dc:creator>Bathen, Luis</dc:creator>
 <dc:creator>G&#xe9;not, Simon-Pierre</dc:creator>
 <dc:creator>Lee, Sunhwan</dc:creator>
 <dc:creator>Routray, Ramani</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Hybrid cloud is an integrated cloud computing environment utilizing a mix of
public cloud, private cloud, and on-premise traditional IT infrastructures.
Workload awareness, defined as a detailed full range understanding of each
individual workload, is essential in implementing the hybrid cloud. While it is
critical to perform an accurate analysis to determine which workloads are
appropriate for on-premise deployment versus which workloads can be migrated to
a cloud off-premise, the assessment is mainly performed by rule or policy based
approaches. In this paper, we introduce StackInsights, a novel cognitive system
to automatically analyze and predict the cloud readiness of workloads for an
enterprise. Our system harnesses the critical metrics across the entire stack:
1) infrastructure metrics, 2) data relevance metrics, and 3) application
taxonomy, to identify workloads that have characteristics of a) low sensitivity
with respect to business security, criticality and compliance, and b) low
response time requirements and access patterns. Since the capture of the data
relevance metrics involves an intrusive and in-depth scanning of the content of
storage objects, a machine learning model is applied to perform the business
relevance classification by learning from the meta level metrics harnessed
across stack. In contrast to traditional methods, StackInsights significantly
reduces the total time for hybrid cloud readiness assessment by orders of
magnitude.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06017</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guaranteed error control bounds for the stabilised space-time IgA
  approximations to parabolic problems</dc:title>
 <dc:creator>Langer, Ulrich</dc:creator>
 <dc:creator>Matculevich, Svetlana</dc:creator>
 <dc:creator>Repin, Sergey</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65N15, 65N25, 65N35</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>B.2.3</dc:subject>
 <dc:description>  The paper is concerned with space-time IgA approximations of parabolic
initial-boundary value problems. We deduce guaranteed and fully computable
error bounds adapted to special features of IgA approximations and investigate
their applicability. The derivation method is based on the analysis of
respective integral identities and purely functional arguments. Therefore, the
estimates do not contain mesh-dependent constants and are valid for any
approximation from the admissible (energy) class. In particular, they imply
computable error bounds for norms associated with {stabilised space--time} IgA
approximations. The last section of the paper contains a series of numerical
examples where approximate solutions are recovered by IgA techniques. They
illustrate reliability and efficiency of the error estimates presented.
</dc:description>
 <dc:description>Comment: 24 pages, 15 figures, 13 tables</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06020</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An ILP Solver for Multi-label MRFS with Connectivity Constraints</dc:title>
 <dc:creator>Shen, Ruobing</dc:creator>
 <dc:creator>Kendinibilir, Eric</dc:creator>
 <dc:creator>Ayed, Ismail Ben</dc:creator>
 <dc:creator>Lodi, Andrea</dc:creator>
 <dc:creator>Tramontani, Andrea</dc:creator>
 <dc:creator>Reinelt, Gerhard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Integer Linear Programming (ILP) formulations of Markov random fields (MRFs)
models with global connectivity priors were investigated previously in computer
vision, e.g., \cite{globalinter,globalconn}. In these works, only Linear
Programming (LP) relaxations \cite{globalinter,globalconn} or simplified
versions \cite{graphcutbase} of the problem were solved. This paper
investigates the ILP of multi-label MRF with exact connectivity priors via a
branch-and-cut method, which provably finds globally optimal solutions. The
method enforces connectivity priors iteratively by a cutting plane method, and
provides feasible solutions with a guarantee on sub-optimality even if we
terminate it earlier. The proposed ILP can also be applied as a post-processing
method on top of any existing multi-label segmentation approach. We demonstrate
the power and usefulness of our model by several experiments on the BSDS500
image dataset, as well as on medical images with trained probability maps.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06021</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bendable Cuboid Robot Path Planning with Collision Avoidance using
  Generalized $L_p$ Norms</dc:title>
 <dc:creator>Hyun, Nak-seung P.</dc:creator>
 <dc:creator>Vela, Patricio A.</dc:creator>
 <dc:creator>Verriest, Erik I.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Optimal path planning problems for rigid and deformable (bendable) cuboid
robots are considered by providing an analytic safety constraint using
generalized $L_p$ norms. For regular cuboid robots, level sets of weighted
$L_p$ norms generate implicit approximations of their surfaces. For bendable
cuboid robots a weighted $L_p$ norm in polar coordinates implicitly
approximates the surface boundary through a specified level set. Obstacle
volumes, in the environment to navigate within, are presumed to be
approximately described as sub-level sets of weighted $L_p$ norms. Using these
approximate surface models, the optimal safe path planning problem is
reformulated as a two stage optimization problem, where the safety constraint
depends on a point on the robot which is closest to the obstacle in the
obstacle's distance metric. A set of equality and inequality constraints are
derived to replace the closest point problem, which is then defines additional
analytic constraints on the original path planning problem. Combining all the
analytic constraints with logical AND operations leads to a general optimal
safe path planning problem. Numerically solving the problem involve conversion
to a nonlinear programing problem. Simulations for rigid and bendable cuboid
robot verify the proposed method.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06025</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Symbolic Execution of Heap-based Programs with Separation
  Logic for Test Input Generation</dc:title>
 <dc:creator>Pham, Long H.</dc:creator>
 <dc:creator>Le, Quang Loc</dc:creator>
 <dc:creator>Phan, Quoc-Sang</dc:creator>
 <dc:creator>Sun, Jun</dc:creator>
 <dc:creator>Qin, Shengchao</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Symbolic execution is a well established method for test input generation. By
taking inputs as symbolic values and solving constraints encoding path
conditions, it helps achieve a better test coverage. Despite of having achieved
tremendous success over numeric domains, existing symbolic execution techniques
for heap-based programs (e.g., linked lists and trees) are limited due to the
lack of a succinct and precise description for symbolic values over unbounded
heaps. In this work, we present a new symbolic execution method for heap-based
programs using separation logic. The essence of our proposal is the use of
existential quantifiers to precisely represent symbolic heaps. Furthermore, we
propose a context-sensitive lazy initialization, a novel approach for efficient
test input generation.We show that by reasoning about the heap in an
existential manner, the proposed lazy initialization is sound and complete. We
have implemented our proposal into a prototype tool, called Java StarFinder,
and evaluated it on a set of programs with complex heap inputs. The results
show that our approach significantly reduces the number of invalid test inputs
and improves the test coverage.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06028</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Spectral Approach for the Design of Experiments: Design, Analysis and
  Algorithms</dc:title>
 <dc:creator>Kailkhura, Bhavya</dc:creator>
 <dc:creator>Thiagarajan, Jayaraman J.</dc:creator>
 <dc:creator>Rastogi, Charvi</dc:creator>
 <dc:creator>Varshney, Pramod K.</dc:creator>
 <dc:creator>Bremer, Peer-Timo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper proposes a new approach to construct high quality space-filling
sample designs. First, we propose a novel technique to quantify the
space-filling property and optimally trade-off uniformity and randomness in
sample designs in arbitrary dimensions. Second, we connect the proposed metric
(defined in the spatial domain) to the objective measure of the design
performance (defined in the spectral domain). This connection serves as an
analytic framework for evaluating the qualitative properties of space-filling
designs in general. Using the theoretical insights provided by this
spatial-spectral analysis, we derive the notion of optimal space-filling
designs, which we refer to as space-filling spectral designs. Third, we propose
an efficient estimator to evaluate the space-filling properties of sample
designs in arbitrary dimensions and use it to develop an optimization framework
to generate high quality space-filling designs. Finally, we carry out a
detailed performance comparison on two different applications in 2 to 6
dimensions: a) image reconstruction and b) surrogate modeling on several
benchmark optimization functions and an inertial confinement fusion (ICF)
simulation code. We demonstrate that the propose spectral designs significantly
outperform existing approaches especially in high dimensions.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06034</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study on the Best Uses of Technology in Support of Project-Based
  Learning</dc:title>
 <dc:creator>Taylor, James</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Project-Based Learning (PBL) is a teaching technique in which authentic,
real-world projects are used as the primary vehicle to drive the student's
learning experience. This technique has been found to be very effective, but
its overall adoption rate is relatively low, in part due to teachers'
unfamiliarity with how to best use technology to successfully implement it.
This research study involved a comprehensive survey of supportive technology
tools, as well as secondary survey research from students and teachers with
actual experience in PBL. The goal was to determine which types of technology
tools were most supportive of PBL. Overall, the study found that teachers and
students are mostly aligned with regards to the importance of technology and
the effectiveness of various types of tools. Tools which fostered collaboration
amongst teacher and students were ultimately deemed the most effective, but
content-development and assessment tools were also found to be particularly
helpful.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, 5 tables</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06039</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Syndrome decoding of Reed-Muller codes and tensor decomposition over
  finite fields</dc:title>
 <dc:creator>Kopparty, Swastik</dc:creator>
 <dc:creator>Potukuchi, Aditya</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Reed-Muller codes are some of the oldest and most widely studied
error-correcting codes, of interest for both their algebraic structure as well
as their many algorithmic properties. A recent beautiful result of Saptharishi,
Shpilka and Volk showed that for binary Reed-Muller codes of length $n$ and
distance $d = O(1)$, one can correct $\operatorname{polylog}(n)$ random errors
in $\operatorname{poly}(n)$ time (which is well beyond the worst-case error
tolerance of $O(1)$).
  In this paper, we consider the problem of `syndrome decoding' Reed-Muller
codes from random errors. More specifically, given the
$\operatorname{polylog}(n)$-bit long syndrome vector of a codeword corrupted in
$\operatorname{polylog}(n)$ random coordinates, we would like to compute the
locations of the codeword corruptions. This problem turns out to be equivalent
to a basic question about computing tensor decomposition of random low-rank
tensors over finite fields.
  Our main result is that syndrome decoding of Reed-Muller codes (and the
equivalent tensor decomposition problem) can be solved efficiently, i.e., in
$\operatorname{polylog}(n)$ time. We give two algorithms for this problem:
  1. The first algorithm is a finite field variant of a classical algorithm for
tensor decomposition over real numbers due to Jennrich. This also gives an
alternate proof for the main result of Saptharishi et al.
  2. The second algorithm is obtained by implementing the steps of the
Berlekamp-Welch-style decoding algorithm of Saptharishi et al. in
sublinear-time. The main new ingredient is an algorithm for solving certain
kinds of systems of polynomial equations.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06042</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Microbial community structure predicted by the stable marriage problem</dc:title>
 <dc:creator>Goyal, Akshit</dc:creator>
 <dc:creator>Dubinkina, Veronika</dc:creator>
 <dc:creator>Maslov, Sergei</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:description>  Experimental studies of microbial communities routinely reveal several stable
states. While each of these states is generally resilient, exposure to
antibiotics, probiotics, or different diets often trigger transitions to other
states. Can we predict which specific perturbations will cause such
transitions? Here we present a new conceptual model - inspired by the stable
marriage problem - which both exhibits these emergent phenomena and makes such
predictions. Our model's core ingredient is that microbes utilize nutrients one
at a time, while competing with each other. Using only two ranked tables with
microbes' nutrient preferences and competitive abilities, we can determine all
the stable states as well as the specific perturbations driving a community
from one state to another. Using an example of 7 Bacteroides species utilizing
9 polysaccharides common to the human gut, we predict that mutual
complementarity in nutrient preferences enables these species to coexist at
high abundances.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06047</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Avoiding Synchronization in First-Order Methods for Sparse Convex
  Optimization</dc:title>
 <dc:creator>Devarakonda, Aditya</dc:creator>
 <dc:creator>Fountoulakis, Kimon</dc:creator>
 <dc:creator>Demmel, James</dc:creator>
 <dc:creator>Mahoney, Michael W.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68W10, 90C25</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Parallel computing has played an important role in speeding up convex
optimization methods for big data analytics and large-scale machine learning
(ML). However, the scalability of these optimization methods is inhibited by
the cost of communicating and synchronizing processors in a parallel setting.
Iterative ML methods are particularly sensitive to communication cost since
they often require communication every iteration. In this work, we extend
well-known techniques from Communication-Avoiding Krylov subspace methods to
first-order, block coordinate descent methods for Support Vector Machines and
Proximal Least-Squares problems. Our Synchronization-Avoiding (SA) variants
reduce the latency cost by a tunable factor of $s$ at the expense of a factor
of $s$ increase in flops and bandwidth costs. We show that the SA-variants are
numerically stable and can attain large speedups of up to $5.1\times$ on a Cray
XC30 supercomputer.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06050</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wasserstein Distributional Robustness and Regularization in Statistical
  Learning</dc:title>
 <dc:creator>Gao, Rui</dc:creator>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Kleywegt, Anton J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A central question in statistical learning is to design algorithms that not
only perform well on training data, but also generalize to new and unseen data.
In this paper, we tackle this question by formulating a distributionally robust
stochastic optimization (DRSO) problem, which seeks a solution that minimizes
the worst-case expected loss over a family of distributions that are close to
the empirical distribution in Wasserstein distances. We establish a connection
between such Wasserstein DRSO and regularization. More precisely, we identify a
broad class of loss functions, for which the Wasserstein DRSO is asymptotically
equivalent to a regularization problem with a gradient-norm penalty. Such
relation provides new interpretations for problems involving regularization,
including a great number of statistical learning problems and discrete choice
models (e.g. multinomial logit). The connection suggests a principled way to
regularize high-dimensional, non-convex problems. This is demonstrated through
the training of Wasserstein generative adversarial networks in deep learning.
</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06056</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-Hop Out-of-Band Control Planes for Low-Power Multi-Hop Wireless
  Networks</dc:title>
 <dc:creator>Gu, Chaojie</dc:creator>
 <dc:creator>Tan, Rui</dc:creator>
 <dc:creator>Lou, Xin</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Separation of control and data planes (SCDP) is a desirable paradigm for
low-power multi-hop wireless networks requiring high network performance and
manageability. Existing SCDP networks generally adopt an in-band control plane
scheme in that the control-plane messages are delivered by their data-plane
networks. The physical coupling of the two planes may lead to undesirable
consequences. To advance the network architecture design, we propose to
leverage on the long-range communication capability of the increasingly
available low-power wide-area network (LPWAN) radios to form one-hop
out-of-band control planes. We choose LoRaWAN, an open, inexpensive, and ISM
band based LPWAN radio to prototype our out-of-band control plane called
LoRaCP. Several characteristics of LoRaWAN such as downlink-uplink asymmetry
and primitive ALOHA media access control (MAC) present challenges to achieving
reliability and efficiency. To address these challenges, we design a TDMA-based
multi-channel MAC featuring an urgent channel and negative acknowledgment. On a
testbed of 16 nodes, we demonstrate applying LoRaCP to physically separate the
control-plane network of the Collection Tree Protocol (CTP) from its
ZigBee-based data-plane network. Extensive experiments show that LoRaCP
increases CTP's packet delivery ratio from 65% to 80% in the presence of
external interference, while consuming a per-node average radio power of 2.97mW
only.
</dc:description>
 <dc:description>Comment: The 37th Annual IEEE International Conference on Computer
  Communications (INFOCOM 2018)</dc:description>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06061</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MEDRoP: Memory-Efficient Dynamic Robust PCA</dc:title>
 <dc:creator>Narayanamurthy, Praneeth</dc:creator>
 <dc:creator>Vaswani, Namrata</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Robust PCA (RPCA) is the problem of separating a given data matrix into the
sum of a sparse matrix and a low-rank matrix. The column span of the low-rank
matrix gives the PCA solution. Dynamic RPCA is the time-varying extension of
RPCA. It assumes that the true data vectors lie in a low-dimensional subspace
that can change with time, albeit slowly. The goal is to track this changing
subspace over time in the presence of sparse outliers. We propose an algorithm
that we call Memory-Efficient Dynamic Robust PCA (MEDRoP). This relies on the
recently studied recursive projected compressive sensing (ReProCS) framework
for solving dynamic RPCA problems, however, the actual algorithm is
significantly different from, and simpler than, previous ReProCS-based methods.
The main contribution of this work is a theoretical guarantee that MEDRoP
provably solves dynamic RPCA under weakened versions of standard RPCA
assumptions, a mild assumption on slow subspace change, and two simple
assumptions (a lower bound on most outlier magnitudes and mutual independence
of the true data vectors). Our result is important because (i) it removes the
strong assumptions needed by the three previous complete guarantees for
ReProCS-based algorithms; (ii) it shows that, it is possible to achieve
significantly improved outlier tolerance compared to static RPCA solutions by
exploiting slow subspace change and a lower bound on most outlier magnitudes;
(iii) it is able to track a changed subspace within a delay that is more than
the subspace dimension by only logarithmic factors and thus is near-optimal;
and (iv) it studies an algorithm that is online (after initialization), fast,
and, memory-efficient (its memory complexity is within logarithmic factors of
the optimal).
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06064</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Optimal Control of Cascading Failure in DC Networks</dc:title>
 <dc:creator>Ba, Qin</dc:creator>
 <dc:creator>Savla, Ketan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider discrete-time dynamics, for cascading failure in DC networks,
whose map is composition of failure rule with control actions. Supply-demand at
nodes is monotonically nonincreasing under admissible control. Under the
failure rule, a link is removed permanently if its flow exceeds its capacities.
We consider finite horizon optimal control to steer the network from an
arbitrary initial state, defined in terms of active link set and supply-demand
at nodes, to a feasible state, i.e., a state that is invariant under the
failure rule. There is no running cost and the reward associated with a
feasible terminal state is the associated cumulative supply-demand. We propose
two approaches for computing optimal control, and provide time complexity
analysis for these approaches. The first approach, geared towards tree
reducible networks, decomposes the global problem into a system of coupled
local problems, which can be solved to optimality in two iterations. In the
first iteration, optimal solutions to the local problems are computed, from
leaf nodes to the root node, in terms of the coupling variables. In the second
iteration, in the reverse order, the local optimal solutions are instantiated
with specific values of the coupling variables. Restricted to constant
controls, the optimal solutions to the local problems possess a piecewise
linear property, which facilitates analytical solution. The second approach
computes optimal control by searching over the reachable set, which is shown to
admit an equivalent finite representation by aggregation of control actions
leading to the same reachable active link set. An algorithmic procedure to
construct this representation is provided by leveraging and extending tools for
arrangement of hyperplanes and convex polytopes. Illustrative simulations,
including showing the effectiveness of a projection-based approximation
algorithm, are also presented.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06070</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-adaptation of Genetic Operators Through Genetic Programming
  Techniques</dc:title>
 <dc:creator>Salinas, Andres Felipe Cruz</dc:creator>
 <dc:creator>Perdomo, Jonatan Gomez</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Here we propose an evolutionary algorithm that self modifies its operators at
the same time that candidate solutions are evolved. This tackles convergence
and lack of diversity issues, leading to better solutions. Operators are
represented as trees and are evolved using genetic programming (GP) techniques.
The proposed approach is tested with real benchmark functions and an analysis
of operator evolution is provided.
</dc:description>
 <dc:description>Comment: Presented in GECCO 2017</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06070</dc:identifier>
 <dc:identifier>doi:10.1145/3071178.3071214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06071</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A MapReduce-based rotation forest classifier for epileptic seizure
  prediction</dc:title>
 <dc:creator>Jukic, Samed</dc:creator>
 <dc:creator>Subasi, Abdulhamit</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this era, big data applications including biomedical are becoming
attractive as the data generation and storage is increased in the last years.
The big data processing to extract knowledge becomes challenging since the data
mining techniques are not adapted to the new requirements. In this study, we
analyse the EEG signals for epileptic seizure detection in the big data
scenario using Rotation Forest classifier. Specifically, MSPCA is used for
denoising, WPD is used for feature extraction and Rotation Forest is used for
classification in a MapReduce framework to correctly predict the epileptic
seizure. This paper presents a MapReduce-based distributed ensemble algorithm
for epileptic seizure prediction and trains a Rotation Forest on each dataset
in parallel using a cluster of computers. The results of MapReduce based
Rotation Forest show that the proposed framework reduces the training time
significantly while accomplishing a high level of performance in
classifications.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06074</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benford's Law and First Letter of Word</dc:title>
 <dc:creator>Yan, Xiaoyong</dc:creator>
 <dc:creator>Yang, Seong-Gyu</dc:creator>
 <dc:creator>Kim, Beom Jun</dc:creator>
 <dc:creator>Minnhagen, Petter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A universal First-Letter Law (FLL) is derived and described. It predicts the
percentages of first letters for words in novels. The FLL is akin to Benford's
law (BL) of first digits, which predicts the percentages of first digits in a
data collection of numbers. Both are universal in the sense that FLL only
depends on the numbers of letters in the alphabet, whereas BL only depends on
the number of digits in the base of the number system. The existence of these
types of universal laws appears counter-intuitive. Nonetheless both describe
data very well. Relations to some earlier works are given. FLL predicts that an
English author on the average starts about 16 out of 100 words with the English
letter `t'. This is corroborated by data, yet an author can freely write
anything. Fuller implications and the applicability of FLL remain for the
future.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06076</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Deep learning methods for generation of a personalized list of
  shuffled songs</dc:title>
 <dc:creator>Gindra, Rushin</dc:creator>
 <dc:creator>Kotak, Srushti</dc:creator>
 <dc:creator>Natekar, Asmita</dc:creator>
 <dc:creator>Sharma, Grishma</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The shuffle mode, where songs are played in a randomized order that is
decided upon for all tracks at once, is widely found and known to exist in
music player systems. There are only few music enthusiasts who use this mode
since it either is too random to suit their mood or it keeps on repeating the
same list every time. In this paper, we propose to build a convolutional deep
belief network(CDBN) that is trained to perform genre recognition based on
audio features retrieved from the records of the Million Song Dataset. The
learned parameters shall be used to initialize a multi-layer perceptron which
takes extracted features of user's playlist as input alongside the metadata to
classify to various categories. These categories will be shuffled
retrospectively based on the metadata to autonomously provide with a list that
is efficacious in playing songs that are desired by humans in normal
conditions.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, submitted to IEEE Xplore, 12th INDIACom 2018 5th
  International Conference on Computing for Sustainable Global Development</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06080</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial As Deep: Spatial CNN for Traffic Scene Understanding</dc:title>
 <dc:creator>Pan, Xingang</dc:creator>
 <dc:creator>Shi, Jianping</dc:creator>
 <dc:creator>Luo, Ping</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) are usually built by stacking
convolutional operations layer-by-layer. Although CNN has shown strong
capability to extract semantics from raw pixels, its capacity to capture
spatial relationships of pixels across rows and columns of an image is not
fully explored. These relationships are important to learn semantic objects
with strong shape priors but weak appearance coherences, such as traffic lanes,
which are often occluded or not even painted on the road surface as shown in
Fig. 1 (a). In this paper, we propose Spatial CNN (SCNN), which generalizes
traditional deep layer-by-layer convolutions to slice-byslice convolutions
within feature maps, thus enabling message passings between pixels across rows
and columns in a layer. Such SCNN is particular suitable for long continuous
shape structure or large objects, with strong spatial relationship but less
appearance clues, such as traffic lanes, poles, and wall. We apply SCNN on a
newly released very challenging traffic lane detection dataset and Cityscapse
dataset. The results show that SCNN could learn the spatial relationship for
structure output and significantly improves the performance. We show that SCNN
outperforms the recurrent neural network (RNN) based ReNet and MRF+CNN (MRFNet)
in the lane detection dataset by 8.7% and 4.6% respectively. Moreover, our SCNN
won the 1st place on the TuSimple Benchmark Lane Detection Challenge, with an
accuracy of 96.53%.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2018</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06086</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Distant Speech Recognition</dc:title>
 <dc:creator>Ravanelli, Mirco</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Deep learning is an emerging technology that is considered one of the most
promising directions for reaching higher levels of artificial intelligence.
Among the other achievements, building computers that understand speech
represents a crucial leap towards intelligent machines. Despite the great
efforts of the past decades, however, a natural and robust human-machine speech
interaction still appears to be out of reach, especially when users interact
with a distant microphone in noisy and reverberant environments. The latter
disturbances severely hamper the intelligibility of a speech signal, making
Distant Speech Recognition (DSR) one of the major open challenges in the field.
  This thesis addresses the latter scenario and proposes some novel techniques,
architectures, and algorithms to improve the robustness of distant-talking
acoustic models. We first elaborate on methodologies for realistic data
contamination, with a particular emphasis on DNN training with simulated data.
We then investigate on approaches for better exploiting speech contexts,
proposing some original methodologies for both feed-forward and recurrent
neural networks. Lastly, inspired by the idea that cooperation across different
DNNs could be the key for counteracting the harmful effects of noise and
reverberation, we propose a novel deep learning paradigm called network of deep
neural networks. The analysis of the original concepts were based on extensive
experimental validations conducted on both real and simulated data, considering
different corpora, microphone configurations, environments, noisy conditions,
and ASR tasks.
</dc:description>
 <dc:description>Comment: PhD Thesis Unitn, 2017</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06087</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Zero-Shot&quot; Super-Resolution using Deep Internal Learning</dc:title>
 <dc:creator>Shocher, Assaf</dc:creator>
 <dc:creator>Cohen, Nadav</dc:creator>
 <dc:creator>Irani, Michal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Deep Learning has led to a dramatic leap in Super-Resolution (SR) performance
in the past few years. However, being supervised, these SR methods are
restricted to specific training data, where the acquisition of the
low-resolution (LR) images from their high-resolution (HR) counterparts is
predetermined (e.g., bicubic downscaling), without any distracting artifacts
(e.g., sensor noise, image compression, non-ideal PSF, etc). Real LR images,
however, rarely obey these restrictions, resulting in poor SR results by SotA
(State of the Art) methods. In this paper we introduce &quot;Zero-Shot&quot; SR, which
exploits the power of Deep Learning, but does not rely on prior training. We
exploit the internal recurrence of information inside a single image, and train
a small image-specific CNN at test time, on examples extracted solely from the
input image itself. As such, it can adapt itself to different settings per
image. This allows to perform SR of real old photos, noisy images, biological
data, and other images where the acquisition process is unknown or non-ideal.
On such images, our method outperforms SotA CNN-based SR methods, as well as
previous unsupervised SR methods. To the best of our knowledge, this is the
first unsupervised CNN-based SR method.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06088</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the 1G of Mobile Power Network: RF, Signal and System Designs to
  Make Smart Objects Autonomous</dc:title>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:creator>Costanzo, Alessandra</dc:creator>
 <dc:creator>Georgiadis, Apostolos</dc:creator>
 <dc:creator>Carvalho, Nuno Borges</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  This article reviews some recent promising approaches to make mobile power
closer to reality. In contrast with articles commonly published by the
microwave community and the communication/signal processing community that
separately emphasize RF, circuit and antenna solutions for WPT on one hand and
communications, signal and system designs for WPT on the other hand, this
review article uniquely bridges RF, signal and system designs in order to bring
those communities closer to each other and get a better understanding of the
fundamental building blocks of an efficient WPT network architecture. We start
by reviewing the engineering requirements and design challenges of making
mobile power a reality. We then review the state-of-the-art in a wide range of
areas spanning sensors and devices, RF design for wireless power and wireless
communications. We identify their limitations and make critical observations
before providing some fresh new look and promising avenues on signal and system
designs for WPT.
</dc:description>
 <dc:description>Comment: submitted for publication</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06091</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multigrid solver to the Helmholtz equation with a point source based
  on travel time and amplitude</dc:title>
 <dc:creator>Treister, Eran</dc:creator>
 <dc:creator>Haber, Eldad</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  The Helmholtz equation arises when modeling wave propagation in the frequency
domain. The equation is discretized as an indefinite linear system, which is
difficult to solve at high wave numbers. In many applications, the solution of
the Helmholtz equation is required for a point source. In this case, it is
possible to reformulate the equation as two separate equations: one for the
travel time of the wave and one for its amplitude. The travel time is obtained
by a solution of the factored eikonal equation, and the amplitude is obtained
by solving a complex-valued advection-diffusion-reaction (ADR) equation. The
reformulated equation is equivalent to the original Helmholtz equation, and the
differences between the numerical solutions of these equations arise only from
discretization errors. We develop an efficient multigrid solver for obtaining
the amplitude given the travel time, which can be efficiently computed. This
approach is advantageous because the amplitude is typically smooth in this
case, and hence, more suitable for multigrid solvers than the standard
Helmholtz discretization. We demonstrate that our second order ADR
discretization is more accurate than the standard second order discretization
at high wave numbers, as long as there are no reflections or caustics.
Moreover, we show that using our approach, the problem can be solved more
efficiently than using the common shifted Laplacian multigrid approach.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06096</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning in RF Sub-sampled B-mode Ultrasound Imaging</dc:title>
 <dc:creator>Yoon, Yeo Hun</dc:creator>
 <dc:creator>Khan, Shujaat</dc:creator>
 <dc:creator>Huh, Jaeyoung</dc:creator>
 <dc:creator>Ye, Jong Chul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In portable, three dimensional, and ultra-fast ultrasound (US) imaging
systems, there is an increasing need to reconstruct high quality images from a
limited number of RF data from receiver (Rx) or scan-line (SC) sub-sampling.
However, due to the severe side lobe artifacts from RF sub-sampling, the
standard beam-former often produces blurry images with less contrast that are
not suitable for diagnostic purpose. To address this problem, some researchers
have studied compressed sensing (CS) to exploit the sparsity of the image or RF
data in some domains. However, the existing CS approaches require either
hardware changes or computationally expensive algorithms. To overcome these
limitations, here we propose a novel deep learning approach that directly
interpolates the missing RF data by utilizing redundancy in the Rx-SC plane. In
particular, the network design principle derives from a novel interpretation of
the deep neural network as a cascaded convolution framelets that learns the
data-driven bases for Hankel matrix decomposition. Our extensive experimental
results from sub-sampled RF data from a real US system confirmed that the
proposed method can effectively reduce the data rate without sacrificing the
image quality.
</dc:description>
 <dc:description>Comment: This is an extended journal version of the conference paper
  arXiv:1710.10006. Some of the contents was featured in arXiv: 1710.1000</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06099</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Dimension is Unbounded for Planar Posets</dc:title>
 <dc:creator>Bosek, Bart&#x142;omiej</dc:creator>
 <dc:creator>Grytczuk, Jaros&#x142;aw</dc:creator>
 <dc:creator>Trotter, William T.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>06A07, 05C35</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In 1981, Kelly showed that planar posets can have arbitrarily large
dimension. However, the posets in Kelly's example have bounded Boolean
dimension and bounded local dimension, leading naturally to the questions as to
whether either Boolean dimension or local dimension is bounded for the class of
planar posets. The question for Boolean dimension was first posed by
Ne\v{s}et\v{r}il and Pudl\'ak in 1989 and remains unanswered today. The concept
of local dimension is quite new, introduced in 2016 by Ueckerdt. In just the
last year, researchers have obtained many interesting results concerning
Boolean dimension and local dimension, contrasting these parameters with the
classic Dushnik-Miller concept of dimension, and establishing links between
both parameters and structural graph theory, path-width, and tree-width in
particular. Here we show that local dimension is not bounded on the class of
planar posets. Our proof also shows that the local dimension of a poset is not
bounded in terms of the maximum local dimension of its blocks, and it provides
an alternative proof of the fact that the local dimension of a poset cannot be
bounded in terms of the tree-width of its cover graph, independent of its
height.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1710.09467</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06100</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query-Based Abstractive Summarization Using Neural Networks</dc:title>
 <dc:creator>Hasselqvist, Johan</dc:creator>
 <dc:creator>Helmertz, Niklas</dc:creator>
 <dc:creator>K&#xe5;geb&#xe4;ck, Mikael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we present a model for generating summaries of text documents
with respect to a query. This is known as query-based summarization. We adapt
an existing dataset of news article summaries for the task and train a
pointer-generator model using this dataset. The generated summaries are
evaluated by measuring similarity to reference summaries. Our results show that
a neural network summarization model, similar to existing neural network models
for abstractive summarization, can be constructed to make use of queries to
produce targeted summaries.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06107</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Railway Track Specific Traffic Signal Selection Using Deep Learning</dc:title>
 <dc:creator>Ritika, S</dc:creator>
 <dc:creator>Mittal, Shruti</dc:creator>
 <dc:creator>Rao, Dattaraj</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the railway transportation Industry moving actively towards automation,
accurate location and inventory of wayside track assets like traffic signals,
crossings, switches, mileposts, etc. is of extreme importance. With the new
Positive Train Control (PTC) regulation coming into effect, many railway safety
rules will be tied directly to location of assets like mileposts and signals.
Newer speed regulations will be enforced based on location of the Train with
respect to a wayside asset. Hence it is essential for the railroads to have an
accurate database of the types and locations of these assets. This paper talks
about a real-world use-case of detecting railway signals from a camera mounted
on a moving locomotive and tracking their locations. The camera is engineered
to withstand the environment factors on a moving train and provide a consistent
steady image at around 30 frames per second. Using advanced image analysis and
deep learning techniques, signals are detected in these camera images and a
database of their locations is created. Railway signals differ a lot from road
signals in terms of shapes and rules for placement with respect to track. Due
to space constraint and traffic densities in urban areas signals are not placed
on the same side of the track and multiple lines can run in parallel. Hence
there is need to associate signal detected with the track on which the train
runs. We present a method to associate the signals to the specific track they
belong to using a video feed from the front facing camera mounted on the lead
locomotive. A pipeline of track detection, region of interest selection, signal
detection has been implemented which gives an overall accuracy of 94.7% on a
route covering 150km with 247 signals.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06108</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Properties of Digital n-Dimensional Spheres and Manifolds. Separation of
  Digital Manifolds</dc:title>
 <dc:creator>Evako, Alexander V.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>54F45, 55M10</dc:subject>
 <dc:description>  In the present paper, we study basic properties of digital n-dimensional
manifolds and digital simply connected spaces. An important property of a
digital n-manifold is that M is a digital n-sphere if and only if for any point
v of M, M-v is a digital n-disk. It is proved that a digital (n-1)-sphere S
contained a digital n-sphere M is a separating space of M. We show that a
digital n-manifold can be converted to the compressed form by sequential
contractions of simple pairs of adjacent points. We study structural features
of digital simply connected spaces. In particular, a digital (n-1)-sphere S in
a digital simply connected n-manifold M is a separating space of M.
</dc:description>
 <dc:description>Comment: 15 pages, 13 figures. arXiv admin note: text overlap with
  arXiv:1412.0218, arXiv:1412.0134</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06108</dc:identifier>
 <dc:identifier>SCIREA Journal of Mathematics, Volume 3, Issue 1, February 2018,
  PP. 29-56, Pub. Date: January 14, 2018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06115</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning and Integral Equations</dc:title>
 <dc:creator>Dahm, Ken</dc:creator>
 <dc:creator>Keller, Alexander</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  As both light transport simulation and reinforcement learning are ruled by
the same Fredholm integral equation of the second kind, machine learning
techniques can be used for efficient photorealistic image synthesis: Light
transport paths are guided by an approximate solution to the integral equation
that is learned during rendering. In analogy to recent advances in
reinforcement learning for playing games, we investigate the training of neural
networks to represent this approximate solution in the context of Monte Carlo
and quasi-Monte Carlo methods in order to compute functionals of integral
equations.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06116</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Single Convolutional Super-Resolution Network for Multiple
  Degradations</dc:title>
 <dc:creator>Zhang, Kai</dc:creator>
 <dc:creator>Zuo, Wangmeng</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent years have witnessed the unprecedented success of deep convolutional
neural networks (CNNs) in single image super-resolution (SISR). However,
existing CNN-based SISR methods mostly assume that a low-resolution (LR) image
is bicubicly downsampled from a high-resolution (HR) image, thus inevitably
giving rise to poor performance when the true degradation does not follow this
assumption. Moreover, they lack scalability in learning a single model to deal
with multiple degradations. To address these issues, we propose a
dimensionality stretching strategy that enables a single convolutional
super-resolution network to take two key factors of the SISR degradation
process, i.e., blur kernel and noise level, as input. Consequently, the
proposed super-resolver can handle multiple and even spatially variant
degradations, which significantly improves the practicability. Extensive
experimental results on synthetic and real LR images show that the proposed
convolutional super-resolution network not only can produce favorable results
on multiple degradations but also is computationally efficient, providing a
highly effective and scalable solution to practical SISR applications.
</dc:description>
 <dc:description>Comment: Matlab code: https://github.com/cszn/SRMD</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06120</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypothesis Testing for High-Dimensional Multinomials: A Selective Review</dc:title>
 <dc:creator>Balakrishnan, Sivaraman</dc:creator>
 <dc:creator>Wasserman, Larry</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  The statistical analysis of discrete data has been the subject of extensive
statistical research dating back to the work of Pearson. In this survey we
review some recently developed methods for testing hypotheses about
high-dimensional multinomials. Traditional tests like the $\chi^2$ test and the
likelihood ratio test can have poor power in the high-dimensional setting. Much
of the research in this area has focused on finding tests with asymptotically
Normal limits and developing (stringent) conditions under which tests have
Normal limits. We argue that this perspective suffers from a significant
deficiency: it can exclude many high-dimensional cases when - despite having
non Normal null distributions - carefully designed tests can have high power.
Finally, we illustrate that taking a minimax perspective and considering
refinements of this perspective can lead naturally to powerful and practical
tests.
</dc:description>
 <dc:description>Comment: 19 pages, 6 figures. Written in memory of Stephen E. Fienberg</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06128</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed SMC-PHD Fusion for Partial, Arithmetic Average Consensus</dc:title>
 <dc:creator>Li, Tiancheng</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We propose an average consensus approach for distributed SMC-PHD (sequential
Monte Carlo-probability hypothesis density) fusion, in which local filters
extract Gaussian mixtures (GMs) from their respective particle posteriors,
share them (iteratively) with their neighbors and finally use the disseminated
GM to update the particle weight. There are two distinguishable features of our
approach compared to exiting approaches. First, a computationally efficient
particles-to-GM (P2GM) conversion scheme is developed based on the unique
structure of the SMC-PHD updater in which the particle weight can be exactly
decomposed with regard to the measurements and misdetection. Only significant
components of higher weight are utilized for parameterization. The consensus,
conditioned on partial information dissemination over the network, is called
&quot;partial consensus&quot;. Second, importance sampling (IS) is employed to re-weight
the local particles for integrating the received GM information, while the
states of the particles remain unchanged. By this, the local prior PHD and
likelihood calculation can be carried out in parallel to the dissemination \&amp;
fusion procedure. To assess the effectiveness of the proposed P2GM
parameterization approach and IS approach, two relevant yet new distributed
SMC-PHD fusion protocols are introduced for comparison. One uses the same P2GM
conversion and GM dissemination schemes as our approach but local particles are
regenerated from the disseminated GMs at each filtering iteration - in place of
the IS approach. This performs similar to our IS approach (as expected) but
prevents any parallelization as addressed above. The other is disseminating the
particles between neighbors - in place of the P2GM conversion. This avoids
parameterization but is communicatively costly. The state-of-the-art
exponential mixture density approach is also realized for comparison.
</dc:description>
 <dc:description>Comment: 13 pages, codes available on request</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06131</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-sparse Learning in Similarity Spaces</dc:title>
 <dc:creator>Demontis, Ambra</dc:creator>
 <dc:creator>Melis, Marco</dc:creator>
 <dc:creator>Biggio, Battista</dc:creator>
 <dc:creator>Fumera, Giorgio</dc:creator>
 <dc:creator>Roli, Fabio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  In several applications, input samples are more naturally represented in
terms of similarities between each other, rather than in terms of feature
vectors. In these settings, machine-learning algorithms can become very
computationally demanding, as they may require matching the test samples
against a very large set of reference prototypes. To mitigate this issue,
different approaches have been developed to reduce the number of required
reference prototypes. Current reduction approaches select a small subset of
representative prototypes in the space induced by the similarity measure, and
then separately train the classification function on the reduced subset.
However, decoupling these two steps may not allow reducing the number of
prototypes effectively without compromising accuracy. We overcome this
limitation by jointly learning the classification function along with an
optimal set of virtual prototypes, whose number can be either fixed a priori or
optimized according to application-specific criteria. Creating a super-sparse
set of virtual prototypes provides much sparser solutions, drastically reducing
complexity at test time, at the expense of a slightly increased complexity
during training. A much smaller set of prototypes also results in
easier-to-interpret decisions. We empirically show that our approach can reduce
up to ten times the complexity of Support Vector Machines, LASSO and ridge
regression at test time, without almost affecting their classification
accuracy.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06131</dc:identifier>
 <dc:identifier>IEEE Computational Intell. Mag., 11(4):36-45, Nov 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06132</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Boltzmann Machines for Second Order Moments and Generalized
  Gaussian Distributions</dc:title>
 <dc:creator>Raymond, Rudy</dc:creator>
 <dc:creator>Osogami, Takayuki</dc:creator>
 <dc:creator>Dasgupta, Sakyasingha</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Dynamic Boltzmann Machine (DyBM) has been shown highly efficient to predict
time-series data. Gaussian DyBM is a DyBM that assumes the predicted data is
generated by a Gaussian distribution whose first-order moment (mean)
dynamically changes over time but its second-order moment (variance) is fixed.
However, in many financial applications, the assumption is quite limiting in
two aspects. First, even when the data follows a Gaussian distribution, its
variance may change over time. Such variance is also related to important
temporal economic indicators such as the market volatility. Second, financial
time-series data often requires learning datasets generated by the generalized
Gaussian distribution with an additional shape parameter that is important to
approximate heavy-tailed distributions. Addressing those aspects, we show how
to extend DyBM that results in significant performance improvement in
predicting financial time-series data.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures. Accepted and presented in NIPS 2017 (time-series
  workshop) at Long Beach, California</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06134</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new and five older Concurrent Memory Reclamation Schemes in Comparison
  (Stamp-it)</dc:title>
 <dc:creator>P&#xf6;ter, Manuel</dc:creator>
 <dc:creator>Tr&#xe4;ff, Jesper Larsson</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Memory management is a critical component in almost all shared-memory,
concurrent data structures and algorithms, consisting in the efficient
allocation and the subsequent reclamation of shared memory resources. This
paper contributes a new, lock-free, amortized constant-time memory reclamation
scheme called \emph{Stamp-it}, and compares it to five well-known, selectively
efficient schemes from the literature, namely Lock-free Reference Counting,
Hazard Pointers, Quiescent State-based Reclamation, Epoch-based Reclamation,
and New Epoch-based Reclamation. An extensive, experimental evaluation with
both new and commonly used benchmarks is provided, on four different
shared-memory systems with hardware supported thread counts ranging from 48 to
512, showing Stamp-it to be competitive with and in many cases and aspects
outperforming other schemes.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06139</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TensorFlow-Serving: Flexible, High-Performance ML Serving</dc:title>
 <dc:creator>Olston, Christopher</dc:creator>
 <dc:creator>Fiedel, Noah</dc:creator>
 <dc:creator>Gorovoy, Kiril</dc:creator>
 <dc:creator>Harmsen, Jeremiah</dc:creator>
 <dc:creator>Lao, Li</dc:creator>
 <dc:creator>Li, Fangwei</dc:creator>
 <dc:creator>Rajashekhar, Vinu</dc:creator>
 <dc:creator>Ramesh, Sukriti</dc:creator>
 <dc:creator>Soyke, Jordan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We describe TensorFlow-Serving, a system to serve machine learning models
inside Google which is also available in the cloud and via open-source. It is
extremely flexible in terms of the types of ML platforms it supports, and ways
to integrate with systems that convey new models and updated versions from
training to serving. At the same time, the core code paths around model lookup
and inference have been carefully optimized to avoid performance pitfalls
observed in naive implementations. Google uses it in many production
deployments, including a multi-tenant model hosting service called TFS^2.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Workshop on ML Systems
  (http://learningsys.org/nips17/acceptedpapers.html)</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06143</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cuts in matchings of 3-edge-connected cubic graphs</dc:title>
 <dc:creator>Knauer, Kolja</dc:creator>
 <dc:creator>Valicov, Petru</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We discuss relations between several known (some false, some open)
conjectures on 3-edge-connected, cubic graphs and how they all fit into the
same framework related to cuts in matchings. We then provide a construction of
3-edge-connected digraphs satisfying the property that for every even subgraph
$E$, the graph obtained by contracting the edges of $E$ is not strongly
connected. This disproves a recent conjecture of Hochst\&quot;attler [A flow theory
for the dichromatic number. European Journal of Combinatorics, 66, 160--167,
2017]. Furthermore, we show that an open conjecture of Neumann-Lara holds for
all planar graphs on at most 26 vertices.
</dc:description>
 <dc:description>Comment: 10, pages, 6 figures, 1 table</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06145</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>clcNet: Improving the Efficiency of Convolutional Neural Network using
  Channel Local Convolutions</dc:title>
 <dc:creator>Zhang, Dong-Qing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Depthwise convolution and grouped convolution has been successfully applied
to improve the efficiency of convolutional neural network (CNN). We suggest
that these models can be considered as special cases of a generalized
convolution operation, named channel local convolution(CLC), where an output
channel is computed using a subset of the input channels. This definition
entails computation dependency relations between input and output channels,
which can be represented by a channel dependency graph(CDG). By modifying the
CDG of grouped convolution, a new CLC kernel named interlaced grouped
convolution (IGC) is created. Stacking IGC and GC kernels results in a
convolution block (named CLC Block) for approximating regular convolution. By
resorting to the CDG as an analysis tool, we derive the rule for setting the
meta-parameters of IGC and GC and the framework for minimizing the
computational cost. A new CNN model named clcNet is then constructed using CLC
blocks, which shows significantly higher computational efficiency and fewer
parameters compared to state-of-the-art networks, such as MobileNet and
ShuffleNet, when being tested using the ImageNet-1K dataset. Source code is
available at https://github.com/dqzhang17/clcnet.torch .
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06148</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating and designing DNA with deep generative models</dc:title>
 <dc:creator>Killoran, Nathan</dc:creator>
 <dc:creator>Lee, Leo J.</dc:creator>
 <dc:creator>Delong, Andrew</dc:creator>
 <dc:creator>Duvenaud, David</dc:creator>
 <dc:creator>Frey, Brendan J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose generative neural network methods to generate DNA sequences and
tune them to have desired properties. We present three approaches: creating
synthetic DNA sequences using a generative adversarial network; a DNA-based
variant of the activation maximization (&quot;deep dream&quot;) design method; and a
joint procedure which combines these two approaches together. We show that
these tools capture important structures of the data and, when applied to
designing probes for protein binding microarrays, allow us to generate new
sequences whose properties are estimated to be superior to those found in the
training data. We believe that these results open the door for applying deep
generative models to advance genomics research.
</dc:description>
 <dc:description>Comment: NIPS 2017 Computational Biology Workshop</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06157</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oscillation energy based sensitivity analysis and control for multi-mode
  oscillation systems</dc:title>
 <dc:creator>Silva-Saravia, Horacio</dc:creator>
 <dc:creator>Wang, Yajun</dc:creator>
 <dc:creator>Pulgar-Painemal, Hector</dc:creator>
 <dc:creator>Tomsovic, Kevin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  This paper describes a novel approach to analyze and control systems with
multi-mode oscillation problems. Traditional single dominant mode analysis
fails to provide effective control actions when several modes have similar low
damping ratios. This work addresses this problem by considering all modes in
the formulation of the system kinetic oscillation energy. The integral of
energy over time defines the total action as a measure of dynamic performance,
and its sensitivity allows comparing the performance of different
actuators/locations in the system to select the most effective one to damp the
oscillation energy. Time domain simulations in the IEEE 9-bus system and IEEE
39-bus system verify the findings obtained by the oscillation energy based
analysis. Applications of the proposed method in control and system planning
are discussed.
</dc:description>
 <dc:description>Comment: Conference paper, IEEE PESGM 2018</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06163</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a science of human stories: using sentiment analysis and
  emotional arcs to understand the building blocks of complex social systems</dc:title>
 <dc:creator>Reagan, Andrew J.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Given the growing assortment of sentiment measuring instruments, it is
imperative to understand which aspects of sentiment dictionaries contribute to
both their classification accuracy and their ability to provide richer
understanding of texts. Here, we perform detailed, quantitative tests and
qualitative assessments of 6 dictionary-based methods applied, and briefly
examine a further 20 methods. We show that while inappropriate for sentences,
dictionary-based methods are generally robust in their classification accuracy
for longer texts.
  Stories often following distinct emotional trajectories, forming patterns
that are meaningful to us. By classifying the emotional arcs for a filtered
subset of 4,803 stories from Project Gutenberg's fiction collection, we find a
set of six core trajectories which form the building blocks of complex
narratives. Of profound scientific interest will be the degree to which we can
eventually understand the full landscape of human stories, and data driven
approaches will play a crucial role.
  Finally, we utilize web-scale data from Twitter to study the limits of what
social data can tell us about public health, mental illness, discourse around
the protest movement of #BlackLivesMatter, discourse around climate change, and
hidden networks. We conclude with a review of published works in complex
systems that separately analyze charitable donations, the happiness of words in
10 languages, 100 years of daily temperature data across the United States, and
Australian Rules Football games.
</dc:description>
 <dc:description>Comment: 286 pages, PhD dissertation, University of Vermont (2017)</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06174</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Networks as 0-1 Mixed Integer Linear Programs: A Feasibility
  Study</dc:title>
 <dc:creator>Fischetti, Matteo</dc:creator>
 <dc:creator>Jo, Jason</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>90C11, 68Q32</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  Deep Neural Networks (DNNs) are very popular these days, and are the subject
of a very intense investigation. A DNN is made by layers of internal units (or
neurons), each of which computes an affine combination of the output of the
units in the previous layer, applies a nonlinear operator, and outputs the
corresponding value (also known as activation). A commonly-used nonlinear
operator is the so-called rectified linear unit (ReLU), whose output is just
the maximum between its input value and zero. In this (and other similar cases
like max pooling, where the max operation involves more than one input value),
one can model the DNN as a 0-1 Mixed Integer Linear Program (0-1 MILP) where
the continuous variables correspond to the output values of each unit, and a
binary variable is associated with each ReLU to model its yes/no nature. In
this paper we discuss the peculiarity of this kind of 0-1 MILP models, and
describe an effective bound-tightening technique intended to ease its solution.
We also present possible applications of the 0-1 MILP model arising in feature
visualization and in the construction of adversarial examples. Preliminary
computational results are reported, aimed at investigating (on small DNNs) the
computational performance of a state-of-the-art MILP solver when applied to a
known test case, namely, hand-written digit recognition.
</dc:description>
 <dc:description>Comment: submitted to an international conference</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06179</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Organic Visualization of Document Evolution</dc:title>
 <dc:creator>Perez-Messina, Ignacio</dc:creator>
 <dc:creator>Gutierrez, Claudio</dc:creator>
 <dc:creator>Graells-Garrido, Eduardo</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.m</dc:subject>
 <dc:description>  Recent availability of data of writing processes at keystroke-granularity has
enabled research on the evolution of document writing. A natural step is to
develop systems that can actually show this data and make it understandable.
Here we propose a data structure that captures a document's fine-grained
history and an organic visualization that serves as an interface to it. We
evaluate a proof-of-concept implementation of the system through a pilot study
with documents written by students at a public university. Our results are
promising and reveal facets such as general strategies adopted, local edition
density and hierarchical structure of the final text.
</dc:description>
 <dc:description>Comment: 5 pages. Short paper accepted at the 23rd ACM Conference on
  Intelligent User Interfaces</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06180</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Deep Reinforcement Learning Approach for Tower Line Wars</dc:title>
 <dc:creator>Andersen, Per-Arne</dc:creator>
 <dc:creator>Goodwin, Morten</dc:creator>
 <dc:creator>Granmo, Ole-Christoffer</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  There have been numerous breakthroughs with reinforcement learning in the
recent years, perhaps most notably on Deep Reinforcement Learning successfully
playing and winning relatively advanced computer games. There is undoubtedly an
anticipation that Deep Reinforcement Learning will play a major role when the
first AI masters the complicated game plays needed to beat a professional
Real-Time Strategy game player. For this to be possible, there needs to be a
game environment that targets and fosters AI research, and specifically Deep
Reinforcement Learning. Some game environments already exist, however, these
are either overly simplistic such as Atari 2600 or complex such as Starcraft II
from Blizzard Entertainment. We propose a game environment in between Atari
2600 and Starcraft II, particularly targeting Deep Reinforcement Learning
algorithm research. The environment is a variant of Tower Line Wars from
Warcraft III, Blizzard Entertainment. Further, as a proof of concept that the
environment can harbor Deep Reinforcement algorithms, we propose and apply a
Deep Q-Reinforcement architecture. The architecture simplifies the state space
so that it is applicable to Q-learning, and in turn improves performance
compared to current state-of-the-art methods. Our experiments show that the
proposed architecture can learn to play the environment well, and score 33%
better than standard Deep Q-learning which in turn proves the usefulness of the
game environment.
</dc:description>
 <dc:description>Comment: Proceedings of the 37th SGAI International Conference on Artificial
  Intelligence, Cambridge, UK, 2017, Artificial Intelligence XXXIV, 2017</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06180</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-71078-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06190</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Control Approach for Wind Turbine Generators to Provide
  Fast Frequency Response with Guarantee of Rotor Security</dc:title>
 <dc:creator>Wang, Siqi</dc:creator>
 <dc:creator>Tomsovic, Kevin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Wind generation is expected to reach substantially higher levels of
penetration in the near future. With the converter interface, the rotor inertia
of doubly-fed induction generator (DFIG) based wind turbine generator is
effectively decoupled from the system, causing a reduction in inertial
response. This can be compensated by enabling the DFIG to provide fast
frequency response. This paper proposes a quantitative control approach for
DFIG to deliver fast frequency response in the inertial response time scale. A
supplementary power surge function is added to the active power reference of
DFIG. The exact amount of power surge that is available from DFIG-based wind
turbine is quantified based on estimation of maximum extractable energy.
Moreover, the operational constraints such as rotor limits and converter
over-load limit are considered at the same time. Thus, the proposed approach
not only provides adequate inertial response but also ensures the rotor speed
is kept within a specified operating range. Rotor safety is guaranteed without
the need for an additional rotor speed protection scheme.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06199</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Optimal Transport</dc:title>
 <dc:creator>Alvarez-Melis, David</dc:creator>
 <dc:creator>Jaakkola, Tommi S.</dc:creator>
 <dc:creator>Jegelka, Stefanie</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Optimal Transport has recently gained interest in machine learning for
applications ranging from domain adaptation, sentence similarities to deep
learning. Yet, its ability to capture frequently occurring structure beyond the
&quot;ground metric&quot; is limited. In this work, we develop a nonlinear generalization
of (discrete) optimal transport that is able to reflect much additional
structure. We demonstrate how to leverage the geometry of this new model for
fast algorithms, and explore connections and properties. Illustrative
experiments highlight the benefit of the induced structured couplings for tasks
in domain adaptation and natural language processing.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06203</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attenuation Correction for Brain PET imaging using Deep Neural Network
  based on Dixon and ZTE MR images</dc:title>
 <dc:creator>Gong, Kuang</dc:creator>
 <dc:creator>Yang, Jaewon</dc:creator>
 <dc:creator>Kim, Kyungsang</dc:creator>
 <dc:creator>Fakhri, Georges El</dc:creator>
 <dc:creator>Seo, Youngho</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Positron Emission Tomography (PET) is a functional imaging modality widely
used in neuroscience studies. To obtain meaningful quantitative results from
PET images, attenuation correction is necessary during image reconstruction.
For PET/MR hybrid systems, PET attenuation is challenging as Magnetic Resonance
(MR) images do not reflect attenuation coefficients directly. To address this
issue, we present deep neural network methods to derive the continuous
attenuation coefficients for brain PET imaging from MR images. With only Dixon
MR images as the network input, the existing U-net structure was adopted and
analysis using forty patient data sets shows it is superior than other Dixon
based methods. When both Dixon and zero echo time (ZTE) images are available,
apart from stacking multiple MR images along the U-net input channels, we have
proposed a new network structure to extract the features from Dixon and ZTE
images independently at early layers and combine them together at later layers.
Quantitative analysis based on fourteen real patient data sets demonstrates
that both network approaches can perform better than the standard methods, and
the proposed network structure can further reduce the PET quantification error
compared to the U-net structure with multiple inputs.
</dc:description>
 <dc:description>Comment: 14 pages, 12 figures</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06204</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Semantic Retrieval for Surveillance Videos with Activity
  Graphs</dc:title>
 <dc:creator>Chen, Yuting</dc:creator>
 <dc:creator>Wang, Joseph</dc:creator>
 <dc:creator>Bai, Yannan</dc:creator>
 <dc:creator>Casta&#xf1;&#xf3;n, Gregory</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a novel framework for finding complex activities matching
user-described queries in cluttered surveillance videos. The wide diversity of
queries coupled with unavailability of annotated activity data limits our
ability to train activity models. To bridge the semantic gap we propose to let
users describe an activity as a semantic graph with object attributes and
inter-object relationships associated with nodes and edges, respectively. We
learn node/edge-level visual predictors during training and, at test-time,
propose to retrieve activity by identifying likely locations that match the
semantic graph. We formulate a novel CRF based probabilistic activity
localization objective that accounts for mis-detections, mis-classifications
and track-losses, and outputs a likelihood score for a candidate grounded
location of the query in the video. We seek groundings that maximize overall
precision and recall. To handle the combinatorial search over all
high-probability groundings, we propose a highest precision subtree algorithm.
Our method outperforms existing retrieval methods on benchmarked datasets.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06212</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Placement Delivery Array Design for Coded Caching Scheme in D2D
  Networks</dc:title>
 <dc:creator>Wang, Jinyu</dc:creator>
 <dc:creator>Cheng, Minquan</dc:creator>
 <dc:creator>Yan, Qifa</dc:creator>
 <dc:creator>Tang, Xiaohu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The coded caching scheme is an efficient technique as a solution to reduce
the wireless network burden during the peak times in a Device-to-Device (D2D in
short) communications. In a coded caching scheme, each file block should be
divided into $F$ packets. It is meaningful to design a coded caching scheme
with the rate and $F$ as small as possible, especially in the practice for D2D
network. In this paper we first characterize coded caching scheme for D2D
network by a simple array called D2D placement delivery array (DPDA in shot).
Consequently some coded caching scheme for D2D network can be discussed by
means of an appropriate DPDA. Secondly we derive the lower bounds on the rate
and $F$ of a DPDA. According these two lower bounds, we show that the
previously known determined scheme proposed by Ji et al., (IEEE Trans. Inform.
Theory, 62(2): 849-869,2016) reaches our lower bound on the rate, but does not
meet the lower bound on $F$ for some parameters. Finally for these parameters,
we construct three classes of DPDAs which meet our two lower bounds. Based on
these DPDAs, three classes of coded caching scheme with low rate and lower $F$
are obtained for D2D network.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06214</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Individual Physiologically Acceptable States for Discharge
  from a Pediatric Intensive Care Unit</dc:title>
 <dc:creator>Carlin, Cameron</dc:creator>
 <dc:creator>Van Ho, Long</dc:creator>
 <dc:creator>Ledbetter, David</dc:creator>
 <dc:creator>Aczon, Melissa</dc:creator>
 <dc:creator>Wetzel, Randall</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Objective: Predict patient-specific vitals deemed medically acceptable for
discharge from a pediatric intensive care unit (ICU). Design: The means of each
patient's hr, sbp and dbp measurements between their medical and physical
discharge from the ICU were computed as a proxy for their physiologically
acceptable state space (PASS) for successful ICU discharge. These individual
PASS values were compared via root mean squared error (rMSE) to population
age-normal vitals, a polynomial regression through the PASS values of a
Pediatric ICU (PICU) population and predictions from two recurrent neural
network models designed to predict personalized PASS within the first twelve
hours following ICU admission. Setting: PICU at Children's Hospital Los Angeles
(CHLA). Patients: 6,899 PICU episodes (5,464 patients) collected between 2009
and 2016. Interventions: None. Measurements: Each episode data contained 375
variables representing vitals, labs, interventions, and drugs. They also
included a time indicator for PICU medical discharge and physical discharge.
Main Results: The rMSEs between individual PASS values and population
age-normals (hr: 25.9 bpm, sbp: 13.4 mmHg, dbp: 13.0 mmHg) were larger than the
rMSEs corresponding to the polynomial regression (hr: 19.1 bpm, sbp: 12.3 mmHg,
dbp: 10.8 mmHg). The rMSEs from the best performing RNN model were the lowest
(hr: 16.4 bpm; sbp: 9.9 mmHg, dbp: 9.0 mmHg). Conclusion: PICU patients are a
unique subset of the general population, and general age-normal vitals may not
be suitable as target values indicating physiologic stability at discharge.
Age-normal vitals that were specifically derived from the medical-to-physical
discharge window of ICU patients may be more appropriate targets for
'acceptable' physiologic state for critical care patients. Going beyond simple
age bins, an RNN model can provide more personalized target values.
</dc:description>
 <dc:description>Comment: 8 pages with appendix, 6 figures (4 of which comprise 1 meta figure),
  4 tables in main section, 10 tables including appendix</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06223</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error-Tolerant Big Data Processing</dc:title>
 <dc:creator>Deng, Dong</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Real-world data contains various kinds of errors. Before analyzing data, one
usually needs to process the raw data. However, traditional data processing
based on exactly match often misses lots of valid information. To get
high-quality analysis results and fit in the big data era, this thesis studies
the error-tolerant big data processing. As most of the data in real world can
be represented as a sequence or a set, this thesis utilizes the widely-used
sequence-based and set-based similar functions to tolerate errors in data
processing and studies the approximate entity extraction, similarity join and
similarity search problems. The main contributions of this thesis include:
  1. This thesis proposes a unified framework to support approximate entity
extraction with both sequence-based and set-based similarity functions
simultaneously. The experiments show that the unified framework can improve the
state-of-the-art methods by 1 to 2 orders of magnitude.
  2. This thesis designs two methods respectively for the sequence and the set
similarity joins. For the sequence similarity join, this thesis proposes to
evenly partition the sequences to segments. It is guaranteed that two sequences
are similar only if one sequence has a subsequence identical to a segment of
another sequence. For the set similarity join, this thesis proposes to
partition all the sets into segments based on the universe. This thesis further
extends the two partition-based methods to support the large-scale data
processing framework, Map-Reduce and Spark. The partition-based method won the
string similarity join competition held by EDBT and beat the second place by 10
times.
  3. This thesis proposes a pivotal prefix filter technique to solve the
sequence similarity search problem. This thesis shows that the pivotal prefix
filter has stronger pruning power and less filtering cost compared to the
state-of-the-art filters.
</dc:description>
 <dc:description>Comment: PhD thesis, Tsinghua University, 2016</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06224</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vietoris-Rips and Cech Complexes of Metric Gluings</dc:title>
 <dc:creator>Adamaszek, Michal</dc:creator>
 <dc:creator>Adams, Henry</dc:creator>
 <dc:creator>Gasparovic, Ellen</dc:creator>
 <dc:creator>Gommel, Maria</dc:creator>
 <dc:creator>Purvine, Emilie</dc:creator>
 <dc:creator>Sazdanovic, Radmila</dc:creator>
 <dc:creator>Wang, Bei</dc:creator>
 <dc:creator>Wang, Yusu</dc:creator>
 <dc:creator>Ziegelmeier, Lori</dc:creator>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>05E45</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We study Vietoris-Rips and Cech complexes of metric wedge sums and metric
gluings. We show that the Vietoris-Rips (resp. Cech) complex of a wedge sum,
equipped with a natural metric, is homotopy equivalent to the wedge sum of the
Vietoris-Rips (resp. Cech) complexes. We also provide generalizations for
certain metric gluings, i.e. when two metric spaces are glued together along a
common isometric subset. As our main example, we deduce the homotopy type of
the Vietoris-Rips complex of two metric graphs glued together along a
sufficiently short path. As a result, we can describe the persistent homology,
in all homological dimensions, of the Vietoris-Rips complexes of a wide class
of metric graphs.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06228</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Explanations from Hadamard Product in Multimodal Deep Networks</dc:title>
 <dc:creator>Kim, Jin-Hwa</dc:creator>
 <dc:creator>Zhang, Byoung-Tak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The visual explanation of learned representation of models helps to
understand the fundamentals of learning. The attentional models of previous
works used to visualize the attended regions over an image or text using their
learned weights to confirm their intended mechanism. Kim et al. (2016) show
that the Hadamard product in multimodal deep networks, which is well-known for
the joint function of visual question answering tasks, implicitly performs an
attentional mechanism for visual inputs. In this work, we extend their work to
show that the Hadamard product in multimodal deep networks performs not only
for visual inputs but also for textual inputs simultaneously using the proposed
gradient-based visualization technique. The attentional effect of Hadamard
product is visualized for both visual and textual inputs by analyzing the two
inputs and an output of the Hadamard product with the proposed method and
compared with learned attentional weights of a visual question answering model.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, including appendix, NIPS 2017 Workshop on
  Visually-Grounded Interaction and Language (ViGIL)</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06229</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Panoramic Robust PCA for Foreground-Background Separation on Noisy,
  Free-Motion Camera Video</dc:title>
 <dc:creator>Moore, Brian E.</dc:creator>
 <dc:creator>Gao, Chen</dc:creator>
 <dc:creator>Nadakuditi, Raj Rao</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work presents a novel approach for robust PCA with total variation
regularization for foreground-background separation and denoising on noisy,
moving camera video. Our proposed algorithm registers the raw (possibly
corrupted) frames of a video and then jointly processes the registered frames
to produce a decomposition of the scene into a low-rank background component
that captures the static components of the scene, a smooth foreground component
that captures the dynamic components of the scene, and a sparse component that
isolates corruptions. Unlike existing methods, our proposed algorithm produces
a panoramic low-rank component that spans the entire field of view,
automatically stitching together corrupted data from partially overlapping
scenes. The low-rank portion of our robust PCA model is based on a recently
discovered optimal low-rank matrix estimator (OptShrink) that requires no
parameter tuning. We demonstrate the performance of our algorithm on both
static and moving camera videos corrupted by noise and outliers.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06235</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Index Modulation for 5G: Striving to Do More with Less</dc:title>
 <dc:creator>Cheng, Xiang</dc:creator>
 <dc:creator>Zhang, Meng</dc:creator>
 <dc:creator>Wen, Miaowen</dc:creator>
 <dc:creator>Yang, Liuqing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The fifth generation (5G) wireless communications brag both high spectrum
efficiency and high energy efficiency. To meet the requirements, various new
techniques have been proposed. Among these, the recently-emerging index
modulation has attracted significant interests. By judiciously activating a
subset of certain communication {building blocks, such as} antenna, subcarrier
and time slot, index modulation is claimed to have the potential to meet the
challenging 5G needs. In this article, we will discuss index modulation and its
general and specific representations, enhancements, and potential applications
in various 5G scenarios. The objective is to reveal whether, and how, index
modulation may strive for more performance gains with less medium resource
occupation.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06236</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Pricing of User-Initiated Data-Plan Sharing in a Roaming Market</dc:title>
 <dc:creator>Wang, Feng</dc:creator>
 <dc:creator>Duan, Lingjie</dc:creator>
 <dc:creator>Niu, Jianwei</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A smartphone user's personal hotspot (pH) allows him to share cellular
connection to another (e.g., a traveler) in the vicinity, but such sharing
consumes the limited data quota in his two-part tariff plan and may lead to
overage charge. This paper studies how to motivate such pH-enabled data-plan
sharing between local users and travelers in the ever-growing roaming markets,
and proposes pricing incentive for a data-plan buyer to reward surrounding pH
sellers (if any). The pricing scheme practically takes into account the
information uncertainty at the traveler side, including the random mobility and
the sharing cost distribution of selfish local users who potentially share pHs.
Though the pricing optimization problem is non-convex, we show that there
always exists a unique optimal price to tradeoff between the successful sharing
opportunity and the sharing price. We further generalize the optimal pricing to
the case of heterogeneous selling pHs who have diverse data usage behaviors in
the sharing cost distributions, and we show such diversity may or may not
benefit the traveler. Lacking selfish pHs' information, the traveler's expected
cost is higher than that under the complete information, but the gap diminishes
as the pHs' spatial density increases. Finally, we analyze the challenging
scenario that multiple travelers overlap for demanding data-plan sharing, by
resorting to a near-optimal pricing scheme. We show that a traveler suffers as
the travelers' spatial density increases.
</dc:description>
 <dc:description>Comment: 8 figures and Submission for possible journal publication</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06239</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Algorithms for Boolean Equation Solving and Quantum Algebraic
  Attack on Cryptosystems</dc:title>
 <dc:creator>Chen, Yu-Ao</dc:creator>
 <dc:creator>Gao, Xiao-Shan</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Decision of whether a Boolean equation system has a solution is an NPC
problem and finding a solution is NP hard. In this paper, we present a quantum
algorithm to decide whether a Boolean equation system $F$ has a solution and
compute one if $F$ does have solutions with any given success probability. The
complexity of the algorithm is polynomial in the size of $F$ and the condition
number of $F$. As a consequence, we have achieved exponential speedup for
solving sparse Boolean equation systems if their condition numbers are small.
We apply the quantum algorithm to the cryptanalysis of the stream cipher
Trivum, the block cipher AES, the hash function SHA-3/Keccak, and the
multivariate public key cryptosystems, and show that they are secure under
quantum algebraic attack only if the condition numbers of the corresponding
equation systems are large.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06240</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing Embedding Distortion with Weighted Bigraph Matching in
  Reversible Data Hiding</dc:title>
 <dc:creator>Wu, Hanzhou</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  For a required payload, the existing reversible data hiding (RDH) methods
always expect to reduce the embedding distortion as much as possible, such as
by utilizing a well-designed predictor, taking into account the carrier-content
characteristics, and/or improving modification efficiency etc. However, due to
the diversity of natural images, it is actually very hard to accurately model
the statistical characteristics of natural images, which has limited the
practical use of traditional RDH methods that rely heavily on the content
characteristics. Based on this perspective, instead of directly exploiting the
content characteristics, in this paper, we model the embedding operation on a
weighted bipartite graph to reduce the introduced distortion due to data
embedding, which is proved to be equivalent to a graph problem called as
\emph{minimum weight maximum matching (MWMM)}. By solving the MWMM problem, we
can find the optimal histogram shifting strategy under the given condition.
Since the proposed method is essentially a general embedding model for the RDH,
it can be utilized for designing an RDH scheme. In our experiments, we
incorporate the proposed method into some related works, and, our experimental
results have shown that the proposed method can significantly improve the
payload-distortion performance, indicating that the proposed method could be
desirable and promising for practical use and the design of RDH schemes.
</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06245</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Misspecified Nonconvex Statistical Optimization for Phase Retrieval</dc:title>
 <dc:creator>Yang, Zhuoran</dc:creator>
 <dc:creator>Yang, Lin F.</dc:creator>
 <dc:creator>Fang, Ethan X.</dc:creator>
 <dc:creator>Zhao, Tuo</dc:creator>
 <dc:creator>Wang, Zhaoran</dc:creator>
 <dc:creator>Neykov, Matey</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Existing nonconvex statistical optimization theory and methods crucially rely
on the correct specification of the underlying &quot;true&quot; statistical models. To
address this issue, we take a first step towards taming model misspecification
by studying the high-dimensional sparse phase retrieval problem with
misspecified link functions. In particular, we propose a simple variant of the
thresholded Wirtinger flow algorithm that, given a proper initialization,
linearly converges to an estimator with optimal statistical accuracy for a
broad family of unknown link functions. We further provide extensive numerical
experiments to support our theoretical findings.
</dc:description>
 <dc:description>Comment: 56 pages</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06246</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Multi-View Clustering</dc:title>
 <dc:creator>Chao, Guoqing</dc:creator>
 <dc:creator>Sun, Shiliang</dc:creator>
 <dc:creator>Bi, Jinbo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  With the fast development of information technology, especially the
popularization of internet, multi-view learning becomes more and more popular
in machine learning and data mining fields. As we all know that, multi-view
semi-supervised learning, such as co-training, co-regularization has gained
considerable attentions. Although recently, multi-view clustering (MVC) has
developed rapidly, there are not a survey or review to summarize and analyze
the current progress. Therefore, this paper sums up the common strategies of
combining multiple views and based on that we proposed a novel taxonomy of the
MVC approaches. We also discussed the relationships between MVC and multi-view
representation, ensemble clustering, multi-task clustering, multi-view
supervised and multi-view semi-supervised learning. Several representative
real-world applications are elaborated. To promote the further development of
MVC, we pointed out several open problems that are worth exploring in the
future.
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06250</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incentive Mechanism Design for Wireless Energy Harvesting-Based Internet
  of Things</dc:title>
 <dc:creator>Hou, Zhanwei</dc:creator>
 <dc:creator>Chen, He</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:creator>Vucetic, Branka</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Radio frequency energy harvesting (RFEH) is a promising technology to charge
unattended Internet of Things (IoT) low-power devices remotely. To enable this,
in future IoT system, besides the traditional data access points (DAPs) for
collecting data, energy access points (EAPs) should be deployed to charge IoT
devices to maintain their sustainable operations. Practically, the DAPs and
EAPs may be operated by different operators, and the DAPs thus need to provide
effective incentives to motivate the surrounding EAPs to charge their
associated IoT devices. Different from existing incentive schemes, we consider
a practical scenario with asymmetric information, where the DAP is not aware of
the channel conditions and energy costs of the EAPs. We first extend the
existing Stackelberg game-based approach with complete information to the
asymmetric information scenario, where the expected utility of the DAP is
defined and maximized. To deal with asymmetric information more efficiently, we
then develop a contract theory-based framework, where the optimal contract is
derived to maximize the DAP's expected utility as well as the social welfare.
Simulations show that information asymmetry leads to severe performance
degradation for the Stackelberg game-based framework, while the proposed
contract theory-based approach using asymmetric information outperforms the
Stackelberg game-based method with complete information. This reveals that the
performance of the considered system depends largely on the market structure
(i.e., whether the EAPs are allowed to optimize their received power at the IoT
devices with full freedom or not) than on the information availability (i.e.,
the complete or asymmetric information).
</dc:description>
 <dc:description>Comment: Full version of a paper arXiv:1703.05902 accepted to appear in IEEE
  Internet of Things Journal</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06251</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crack detection in beam structures with a novel Laplace based Wavelet
  Finite Element method</dc:title>
 <dc:creator>Zhang, Shuaifang</dc:creator>
 <dc:creator>Li, Dongsheng</dc:creator>
 <dc:creator>Shen, Wei</dc:creator>
 <dc:creator>Zhang, Xiwen</dc:creator>
 <dc:creator>Liu, Yu</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Beam structure is one of the most widely used structures in mechanical
engineering and civil engineering. Ultrasonic guided wave based crack
identification is one of the most important and accepted approaches applied to
detect unseen small flaws in structures. Numerical simulations of ultrasonic
guided wave propagation have caught more and more attention due to the fast
development of hardware and software in the last few years. From all the
numerical simulation methods, wavelet based finite element method has been
proved to be one of the most efficient methods due to its better spatial
resolution, which means it needs fewer elements to get the same accuracy and it
can improve the calculation cost significantly. However, it needs a very small
time interval. Laplace transform can easily convert the time domain into a
frequency domain and then revert it back to a time domain. Laplace transform
has thus the advantage of finding better results with a very large time
interval. which can save a lot of time cost. This paper will present an
innovative method combining Laplace transform and the B-spline wavelet on
interval (BSWI) finite element method. This novel method allows to get results
with the same accuracy and with a significantly lower time cost, which would
not only decrease the total number of elements in the structure but also
increase the time integration interval. The numerical Laplace transform and
BSWI finite element will be introduced. Moreover, this innovative method is
applied to simulate the ultrasonic wave propagation in a beam structure in
different materials. Numerical examples for crack identification in beam
structures have been studied for verification.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06259</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Oh Tanenbaum, oh Tanenbaum...&quot;: Technical Foundations of Xmas 4.0
  Research</dc:title>
 <dc:creator>Reichl, P.</dc:creator>
 <dc:creator>Claus, S.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Andrew Tanenbaum and his textbooks -- e.g. on Operating Systems, Computer
Networks, Structured Computer Organization and Distributed Systems, to name but
a few -- have had a tremendous impact on generations of computer science
students (and teachers at the same time). Given this, it is striking to observe
that this comprehensive body of work apparently does not provide a single line
on a research topic that seems to be intimately related with his name (at least
in German), i.e. Xmas Research (XR). Hence, the goal of this paper is to fill
this gap and provide insight into a number of paradigmatic XR research
questions, for instance: Can we today still count on Santa Claus? Or at least
on Xmas trees? And does this depend on basic tree structures, or can we rather
find solutions on the level of programming languages? By addressing such basic
open issues, we aim at providing a solid technical foundation for future steps
towards the imminent evolution of Xmas 4.0.
</dc:description>
 <dc:description>Comment: 5 pages, 12 figures</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06260</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Generative Model of Functional MRI Images for Psychiatric
  Disorder Diagnosis</dc:title>
 <dc:creator>Matsubara, Takashi</dc:creator>
 <dc:creator>Tashiro, Tetsuo</dc:creator>
 <dc:creator>Uehara, Kuniaki</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Accurate diagnosis of psychiatric disorders plays a critical role in
improving quality of life for patients and potentially supports the development
of new treatments. Many studies have been conducted on machine learning
techniques that seek brain imaging data for specific biomarkers of disorders.
These studies have encountered the following dilemma: An end-to-end
classification overfits to a small number of high-dimensional samples but
unsupervised feature-extraction has the risk of extracting a signal of no
interest. In addition, such studies often provided only diagnoses for patients
without presenting the reasons for these diagnoses. This study proposed a deep
neural generative model of resting-state functional magnetic resonance imaging
(fMRI) data. The proposed model is conditioned by the assumption of the
subject's state and estimates the posterior probability of the subject's state
given the imaging data, using Bayes' rule. This study applied the proposed
model to diagnose schizophrenia and bipolar disorders. Diagnosis accuracy was
improved by a large margin over competitive approaches, namely a support vector
machine, logistic regression, and multilayer perceptron with or without
unsupervised feature-extractors in addition to a Gaussian mixture model. The
proposed model visualizes brain regions largely related to the disorders, thus
motivating further biological investigation.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06272</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated flow for compressing convolution neural networks for efficient
  edge-computation with FPGA</dc:title>
 <dc:creator>Shafiq, Farhan</dc:creator>
 <dc:creator>Yamada, Takato</dc:creator>
 <dc:creator>Vilchez, Antonio T.</dc:creator>
 <dc:creator>Dasgupta, Sakyasingha</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep convolutional neural networks (CNN) based solutions are the current
state- of-the-art for computer vision tasks. Due to the large size of these
models, they are typically run on clusters of CPUs or GPUs. However, power
requirements and cost budgets can be a major hindrance in adoption of CNN for
IoT applications. Recent research highlights that CNN contain significant
redundancy in their structure and can be quantized to lower bit-width
parameters and activations, while maintaining acceptable accuracy. Low
bit-width and especially single bit-width (binary) CNN are particularly
suitable for mobile applications based on FPGA implementation, due to the
bitwise logic operations involved in binarized CNN. Moreover, the transition to
lower bit-widths opens new avenues for performance optimizations and model
improvement. In this paper, we present an automatic flow from trained
TensorFlow models to FPGA system on chip implementation of binarized CNN. This
flow involves quantization of model parameters and activations, generation of
network and model in embedded-C, followed by automatic generation of the FPGA
accelerator for binary convolutions. The automated flow is demonstrated through
implementation of binarized &quot;YOLOV2&quot; on the low cost, low power Cyclone- V FPGA
device. Experiments on object detection using binarized YOLOV2 demonstrate
significant performance benefit in terms of model size and inference speed on
FPGA as compared to CPU and mobile CPU platforms. Furthermore, the entire
automated flow from trained models to FPGA synthesis can be completed within
one hour.
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures. Accepted and presented at MLPCD workshop, NIPS
  2017 (LongBeach, California)</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06273</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Resourced Machine Translation via Morpho-syntactic Modeling: The
  Case of Dialectal Arabic</dc:title>
 <dc:creator>Erdmann, Alexander</dc:creator>
 <dc:creator>Habash, Nizar</dc:creator>
 <dc:creator>Taji, Dima</dc:creator>
 <dc:creator>Bouamor, Houda</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present the second ever evaluated Arabic dialect-to-dialect machine
translation effort, and the first to leverage external resources beyond a small
parallel corpus. The subject has not previously received serious attention due
to lack of naturally occurring parallel data; yet its importance is evidenced
by dialectal Arabic's wide usage and breadth of inter-dialect variation,
comparable to that of Romance languages. Our results suggest that modeling
morphology and syntax significantly improves dialect-to-dialect translation,
though optimizing such data-sparse models requires consideration of the
linguistic differences between dialects and the nature of available data and
resources. On a single-reference blind test set where untranslated input scores
6.5 BLEU and a model trained only on parallel data reaches 14.6, pivot
techniques and morphosyntactic modeling significantly improve performance to
17.5.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06276</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Migrate when necessary: toward partitioned reclaiming for soft real-time
  tasks</dc:title>
 <dc:creator>Zahaf, Houssam Eddine</dc:creator>
 <dc:creator>Lipari, Giuseppe</dc:creator>
 <dc:creator>Abeni, Luca</dc:creator>
 <dc:creator>Zahaf, Houssam-Eddine</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  This paper presents a new strategy for scheduling soft real-time tasks on
multiple identical cores. The proposed approach is based on partitioned CPU
reservations and it uses a reclaiming mechanism to reduce the number of missed
deadlines. We introduce the possibility for a task to temporarily migrate to
another, less charged, CPU when it has exhausted the reserved bandwidth on its
allocated CPU. In addition, we propose a simple load balancing method to
decrease the number of deadlines missed by the tasks. The proposed algorithm
has been evaluated through simulations, showing its effectiveness (compared to
other multi-core reclaiming approaches) and comparing the performance of
different partitioning heuristics (Best Fit, Worst Fit and First Fit).
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06276</dc:identifier>
 <dc:identifier>Proceedings of International Conference on Real-Time Networks and
  Systems, 2017, 10, pp.1-24. \&amp;\#x3008;10.1145/3139258.3139280\&amp;\#x3009</dc:identifier>
 <dc:identifier>doi:10.1145/3139258.3139280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06281</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Reduction in Chemical Reaction Networks: A Data-Driven
  Sparse-Learning Approach</dc:title>
 <dc:creator>Khalil, Omar A.</dc:creator>
 <dc:creator>Harirchi, Farshad</dc:creator>
 <dc:creator>Kim, Doohyun</dc:creator>
 <dc:creator>Liu, Sijia</dc:creator>
 <dc:creator>Elvati, Paolo</dc:creator>
 <dc:creator>Violi, Angela</dc:creator>
 <dc:creator>Hero, Alfred O.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:description>  The reduction of large kinetic mechanisms is a crucial step for fluid
dynamics simulations of com- bustion systems. In this paper, we introduce a
novel approach for mechanism reduction that presents unique features. We
propose an unbiased reaction-based method that exploits an optimization-based
sparse-learning approach to identify the set of most influential reactions in a
chemical reaction network. The problem is first formulated as a mixed-integer
linear program, and then a relaxation method is leveraged to reduce its
computational complexity. Not only this method calculates the minimal set of
reactions subject to the user-specified error tolerance bounds, but it also
incorporates a bound on the propagation of error over a time horizon caused by
reducing the mechanism. The method is unbiased toward the optimization of any
characteristic of the system, such as ignition delay, since it is assembled
based on the identification of a reduced mechanism that fits the species
concentrations and reaction rate generated by the full mechanisms. Qualitative
and quantitative validations of the sparse encoding approach demonstrate that
the reduced model captures important network structural properties.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06283</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bridge Between Hyperparameter Optimization and Larning-to-learn</dc:title>
 <dc:creator>Franceschi, Luca</dc:creator>
 <dc:creator>Donini, Michele</dc:creator>
 <dc:creator>Frasconi, Paolo</dc:creator>
 <dc:creator>Pontil, Massimiliano</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a class of a nested optimization problems involving inner and
outer objectives. We observe that by taking into explicit account the
optimization dynamics for the inner objective it is possible to derive a
general framework that unifies gradient-based hyperparameter optimization and
meta-learning (or learning-to-learn). Depending on the specific setting, the
variables of the outer objective take either the meaning of hyperparameters in
a supervised learning problem or parameters of a meta-learner. We show that
some recently proposed methods in the latter setting can be instantiated in our
framework and tackled with the same gradient-based algorithms. Finally, we
discuss possible design patterns for learning-to-learn and present encouraging
preliminary experiments for few-shot learning.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06289</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Chinese Dataset with Negative Full Forms for General Abbreviation
  Prediction</dc:title>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Abbreviation is a common phenomenon across languages, especially in Chinese.
In most cases, if an expression can be abbreviated, its abbreviation is used
more often than its fully expanded forms, since people tend to convey
information in a most concise way. For various language processing tasks,
abbreviation is an obstacle to improving the performance, as the textual form
of an abbreviation does not express useful information, unless it's expanded to
the full form. Abbreviation prediction means associating the fully expanded
forms with their abbreviations. However, due to the deficiency in the
abbreviation corpora, such a task is limited in current studies, especially
considering general abbreviation prediction should also include those full form
expressions that do not have valid abbreviations, namely the negative full
forms (NFFs). Corpora incorporating negative full forms for general
abbreviation prediction are few in number. In order to promote the research in
this area, we build a dataset for general Chinese abbreviation prediction,
which needs a few preprocessing steps, and evaluate several different models on
the built dataset. The dataset is available at
https://github.com/lancopku/Chinese-abbreviation-dataset
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06299</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measurement-based Efficient Resource Allocation with Demand-Side
  Adjustments</dc:title>
 <dc:creator>Chasparis, Georgios</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The problem of efficient resource allocation has drawn significant attention
in many scientific disciplines due to its direct societal benefits, such as
energy savings. Traditional approaches in addressing online resource allocation
problems neglect the potential benefit of feedback information available from
the running tasks/loads as well as the potential flexibility of a task to
adjust its operation/service level in order to increase efficiency. The present
paper builds upon recent developments in the area of bandwidth allocation in
computing systems and proposes a unified design approach for efficient resource
allocation which is based upon a measurement- or utility-based learning scheme.
We demonstrate through analysis the potential of the proposed scheme in
providing efficient allocation of resources in a large class of resource
allocation problems and when only measurements of the performances of the tasks
are available.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06302</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Explanation by Interpretation: Improving Visual Feedback
  Capabilities of Deep Neural Networks</dc:title>
 <dc:creator>Oramas, Jose</dc:creator>
 <dc:creator>Wang, Kaili</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning-based representations have become the defacto means to address
computer vision tasks. Despite their massive adoption, the amount of work
aiming at understanding the internal representations learned by these models is
rather limited. Existing methods aimed at model interpretation either require
exhaustive manual inspection of visualizations, or link internal network
activations with external &quot;possibly useful&quot; annotated concepts. We propose an
intermediate scheme in which, given a pretrained model, we automatically
identify internal features relevant for the set of classes considered by the
model, without requiring additional annotations. We interpret the model through
average visualizations of these features. Then, at test time, we explain the
network prediction by accompanying the predicted class label with supporting
heatmap visualizations derived from the identified relevant features. In
addition, we propose a method to address the artifacts introduced by strided
operations in deconvnet-based visualizations. Our evaluation on the MNIST,
ILSVRC 12 and Fashion 144k datasets quantitatively shows that the proposed
method is able to identify relevant internal features for the classes of
interest while improving the quality of the produced visualizations.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06309</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FPT-algorithms for some problems related to integer programming</dc:title>
 <dc:creator>Gribanov, D. V.</dc:creator>
 <dc:creator>Malyshev, D. S.</dc:creator>
 <dc:creator>Pardalos, P. M.</dc:creator>
 <dc:creator>Veselov, S. I.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we present FPT-algorithms for special cases of the shortest
lattice vector, integer linear programming, and simplex width computation
problems, when matrices included in the problems' formulations are near square.
The parameter is the maximum absolute value of rank minors of the corresponding
matrices. Additionally, we present FPT-algorithms with respect to the same
parameter for the problems, when the matrices have no singular rank
sub-matrices.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1710.00321</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06311</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounding Errors Due to Switching Delays in Incrementally Stable Switched
  Systems (Extended Version)</dc:title>
 <dc:creator>Kido, Kengo</dc:creator>
 <dc:creator>Sedwards, Sean</dc:creator>
 <dc:creator>Hasuo, Ichiro</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Time delays pose an important challenge in networked control systems, which
are now ubiquitous. Focusing on switched systems, we introduce a framework that
provides an upper bound for errors caused by switching delays. Our framework is
based on approximate bisimulation, a notion that has been previously utilized
mainly for symbolic (discrete) abstraction of state spaces. Notable in our
framework is that, in deriving an approximate bisimulation and thus an error
bound, we use a simple incremental stability assumption (namely {\delta}-GUAS)
that does not itself refer to time delays. That this is the same assumption
used for state-space discretization enables a two-step workflow for control
synthesis for switched systems, in which a single Lyapunov-type stability
witness serves for two different purposes of state discretization and coping
with time delays. We demonstrate the proposed framework with a boost DC-DC
converter, a common example of switched systems.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06316</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSTM Pose Machines</dc:title>
 <dc:creator>Luo, Yue</dc:creator>
 <dc:creator>Ren, Jimmy</dc:creator>
 <dc:creator>Wang, Zhouxia</dc:creator>
 <dc:creator>Sun, Wenxiu</dc:creator>
 <dc:creator>Pan, Jinshan</dc:creator>
 <dc:creator>Liu, Jianbo</dc:creator>
 <dc:creator>Pang, Jiahao</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We observed that recent state-of-the-art results on single image human pose
estimation were achieved by multi-stage Convolution Neural Networks (CNN).
Notwithstanding the superior performance on static images, the application of
these models on videos is not only computationally intensive, it also suffers
from performance degeneration and flicking. Such suboptimal results are mainly
attributed to the inability of imposing sequential geometric consistency,
handling severe image quality degradation (e.g. motion blur and occlusion) as
well as the inability of capturing the temporal correlation among video frames.
In this paper, we proposed a novel recurrent network to tackle these problems.
We showed that if we were to impose the weight sharing scheme to the
multi-stage CNN, it could be re-written as a Recurrent Neural Network (RNN).
This property decouples the relationship among multiple network stages and
results in significantly faster speed in invoking the network for videos. It
also enables the adoption of Long Short-Term Memory (LSTM) units between video
frames. We found such memory augmented RNN is very effective in imposing
geometric consistency among frames. It also well handles input quality
degradation in videos while successfully stabilizes the sequential outputs. The
experiments showed that our approach significantly outperformed current
state-of-the-art methods on two large scale video pose estimation benchmarks.
We also explored the memory cells inside the LSTM and provided insights on why
such mechanism would benefit the prediction for video-based pose estimations.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06317</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial-Temporal Memory Networks for Video Object Detection</dc:title>
 <dc:creator>Xiao, Fanyi</dc:creator>
 <dc:creator>Lee, Yong Jae</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce Spatial-Temporal Memory Networks (STMN) for video object
detection. At its core, we propose a novel Spatial-Temporal Memory module
(STMM) as the recurrent computation unit to model long-term temporal appearance
and motion dynamics. The STMM's design enables the integration of ImageNet
pre-trained backbone CNN weights for both the feature stack as well as the
prediction head, which we find to be critical for accurate detection.
Furthermore, in order to tackle object motion in videos, we propose a novel
MatchTrans module to align the spatial-temporal memory from frame to frame. We
compare our method to state-of-the-art detectors on ImageNet VID, and conduct
ablative studies to dissect the contribution of our different design choices.
We obtain state-of-the-art results with the VGG backbone, and competitive
results with the ResNet backbone. To our knowledge, this is the first video
object detector that is equipped with an explicit memory mechanism to model
long-term temporal dynamics.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06326</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Filling Curve Indices as Acceleration Structure for Exemplar-Based
  Inpainting</dc:title>
 <dc:creator>Dahmen, Tim</dc:creator>
 <dc:creator>Trampert, Patrick</dc:creator>
 <dc:creator>Weickert, Joachim</dc:creator>
 <dc:creator>Slusallek, Philipp</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Exemplar-based inpainting is the process of reconstructing missing parts of
an image by searching the remaining data for patches that fit seamlessly. The
image is completed to a plausible-looking solution by repeatedly inserting the
patch that is the best match according to some cost function. We present an
acceleration structure that uses a multi-index scheme to accelerate this search
procedure drastically, particularly in the case of very large datasets. The
index scheme uses ideas such as dimensionality reduction and k-nearest neighbor
search on space-filling curves that are well known in the field of multimedia
databases. Our method has a theoretic runtime of O(log2 n) per iteration and
reaches a speedup factor of up to 660 over the original method. The approach
has the advantage of being agnostic to most modelbased parts of exemplar-based
inpainting such as the order in which patches are processed and the cost
function used to determine patch similarity. Thus, the acceleration structure
can be used in conjunction with most exemplar-based inpainting algorithms.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Image Processing as a Regular Paper</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06338</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selective-Candidate Framework with Similarity Selection Rule for
  Evolutionary Optimization</dc:title>
 <dc:creator>Zhang, Sheng Xin</dc:creator>
 <dc:creator>Chan, Wing Shing</dc:creator>
 <dc:creator>Peng, Zi Kang</dc:creator>
 <dc:creator>Zheng, Shao Yong</dc:creator>
 <dc:creator>Tang, Kit Sang</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper proposes to resolve limitations of the traditional
one-reproduction (OR) framework which produces only one candidate in a single
reproduction procedure. A selective-candidate framework with similarity
selection rule (SCSS) is suggested to make possible, a selective direction of
search. In the SCSS framework, M (M &gt; 1) candidates are generated from each
current solution by independently conducting the reproduction procedure M
times. The winner is then determined by employing a similarity selection rule.
To maintain balanced exploitation and exploration capabilities, an efficient
similarity selection rule based on the Euclidian distances between each of the
M candidates and the corresponding current solution is proposed. The SCSS
framework can be easily applied to any evolutionary algorithms or swarm
intelligences. Experiments conducted with 60 benchmark functions show the
superiority of SCSS over OR in three classic, four state-of-the-art and four
up-to-date algorithms.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06340</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language and Noise Transfer in Speech Enhancement Generative Adversarial
  Network</dc:title>
 <dc:creator>Pascual, Santiago</dc:creator>
 <dc:creator>Park, Maruchan</dc:creator>
 <dc:creator>Serr&#xe0;, Joan</dc:creator>
 <dc:creator>Bonafonte, Antonio</dc:creator>
 <dc:creator>Ahn, Kang-Hun</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Speech enhancement deep learning systems usually require large amounts of
training data to operate in broad conditions or real applications. This makes
the adaptability of those systems into new, low resource environments an
important topic. In this work, we present the results of adapting a speech
enhancement generative adversarial network by finetuning the generator with
small amounts of data. We investigate the minimum requirements to obtain a
stable behavior in terms of several objective metrics in two very different
languages: Catalan and Korean. We also study the variability of test
performance to unseen noise as a function of the amount of different types of
noise available for training. Results show that adapting a pre-trained English
model with 10 min of data already achieves a comparable performance to having
two orders of magnitude more data. They also demonstrate the relative stability
in test performance with respect to the number of training noise types.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06343</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Squeezed Convolutional Variational AutoEncoder for Unsupervised Anomaly
  Detection in Edge Device Industrial Internet of Things</dc:title>
 <dc:creator>Kim, Dohyung</dc:creator>
 <dc:creator>Yang, Hyochang</dc:creator>
 <dc:creator>Chung, Minki</dc:creator>
 <dc:creator>Cho, Sungzoon</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we propose Squeezed Convolutional Variational AutoEncoder
(SCVAE) for anomaly detection in time series data for Edge Computing in
Industrial Internet of Things (IIoT). The proposed model is applied to labeled
time series data from UCI datasets for exact performance evaluation, and
applied to real world data for indirect model performance comparison. In
addition, by comparing the models before and after applying Fire Modules from
SqueezeNet, we show that model size and inference times are reduced while
similar levels of performance is maintained.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06346</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can co-location be used as a proxy for face-to-face contacts?</dc:title>
 <dc:creator>G&#xe9;nois, Mathieu</dc:creator>
 <dc:creator>Barrat, Alain</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Technological advances have led to a strong increase in the number of data
collection efforts aimed at measuring co-presence of individuals at different
spatial resolutions. It is however unclear how much co-presence data can inform
us on actual face-to-face contacts, of particular interest to study the
structure of a population in social groups or for use in data-driven models of
information or epidemic spreading processes. Here, we address this issue by
leveraging data sets containing high resolution face-to-face contacts as well
as a coarser spatial localisation of individuals, both temporally resolved, in
various contexts. The co-presence and the face-to-face contact temporal
networks share a number of structural and statistical features, but the former
is (by definition) much denser than the latter. We thus consider several
down-sampling methods that generate surrogate contact networks from the
co-presence signal and compare them with the real face-to-face data. We show
that these surrogate networks reproduce some features of the real data but are
only partially able to identify the most central nodes of the face-to-face
network. We then address the issue of using such down-sampled co-presence data
in data-driven simulations of epidemic processes, and in identifying efficient
containment strategies. We show that the performance of the various sampling
methods strongly varies depending on context. We discuss the consequences of
our results with respect to data collection strategies and methodologies.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06349</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Quantum Algorithms via Query Complexity</dc:title>
 <dc:creator>Ambainis, Andris</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Query complexity is a model of computation in which we have to compute a
function $f(x_1, \ldots, x_N)$ of variables $x_i$ which can be accessed via
queries. The complexity of an algorithm is measured by the number of queries
that it makes. Query complexity is widely used for studying quantum algorithms,
for two reasons. First, it includes many of the known quantum algorithms
(including Grover's quantum search and a key subroutine of Shor's factoring
algorithm). Second, one can prove lower bounds on the query complexity,
bounding the possible quantum advantage. In the last few years, there have been
major advances on several longstanding problems in the query complexity. In
this talk, we survey these results and related work, including:
  - the biggest quantum-vs-classical gap for partial functions (a problem
solvable with 1 query quantumly but requiring $\Omega(\sqrt{N})$ queries
classically);
  - the biggest quantum-vs-determistic and quantum-vs-probabilistic gaps for
total functions (for example, a problem solvable with $M$ queries quantumly but
requiring $\tilde{\Omega}(M^{2.5})$ queries probabilistically);
  - the biggest probabilistic-vs-deterministic gap for total functions (a
problem solvable with $M$ queries probabilistically but requiring
$\tilde{\Omega}(M^{2})$ queries deterministically);
  - the bounds on the gap that can be achieved for subclasses of functions (for
example, symmetric functions);
  - the connections between query algorithms and approximations by low-degree
polynomials.
</dc:description>
 <dc:description>Comment: 20 page survey of recent results, for Proceedings of International
  Congress of Mathematicians'2018</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06352</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN for IMU Assisted Odometry Estimation using Velodyne LiDAR</dc:title>
 <dc:creator>Velas, Martin</dc:creator>
 <dc:creator>Spanel, Michal</dc:creator>
 <dc:creator>Hradis, Michal</dc:creator>
 <dc:creator>Herout, Adam</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We introduce a novel method for odometry estimation using convolutional
neural networks from 3D LiDAR scans. The original sparse data are encoded into
2D matrices for the training of proposed networks and for the prediction. Our
networks show significantly better precision in the estimation of translational
motion parameters comparing with state of the art method LOAM, while achieving
real-time performance. Together with IMU support, high quality odometry
estimation and LiDAR data registration is realized. Moreover, we propose
alternative CNNs trained for the prediction of rotational motion parameters
while achieving results also comparable with state of the art. The proposed
method can replace wheel encoders in odometry estimation or supplement missing
GPS data, when the GNSS signal absents (e.g. during the indoor mapping). Our
solution brings real-time performance and precision which are useful to provide
online preview of the mapping results and verification of the map completeness
in real time.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06358</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Saga of KPR: Theoretical and Experimental developments</dc:title>
 <dc:creator>Sharma, Kiran</dc:creator>
 <dc:creator>Anamika</dc:creator>
 <dc:creator>Chakrabarti, Anindya S.</dc:creator>
 <dc:creator>Chakraborti, Anirban</dc:creator>
 <dc:creator>Chakravarty, Sujoy</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Quantitative Finance - General Finance</dc:subject>
 <dc:description>  In this article, we present a brief narration of the origin and the overview
of the recent developments done on the Kolkata Paise Restaurant (KPR) problem,
which can serve as a prototype for a broader class of resource allocation
problems in the presence of a large number of competing agents, typically
studied using coordination and anti-coordination games. We discuss the KPR and
its several extensions, as well as its applications in many economic and social
phenomena. We end the article with some discussions on our ongoing experimental
analysis of the same problem. We demonstrate that this provides an interesting
picture of how people analyze complex situations, and design their strategies
or react to them.
</dc:description>
 <dc:description>Comment: 14 pages, Submitted for publication in a special issue in Science and
  Culture (Kolkata, India)</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06365</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>'Indifference' methods for managing agent rewards</dc:title>
 <dc:creator>Armstrong, Stuart</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Indifference is a class of methods that are used to control a reward based
agent, by, for example, safely changing their reward or policy, or making the
agent behave as if a certain outcome could never happen. These methods of
control work even if the implications of the agent's reward are otherwise not
fully understood. Though they all come out of similar ideas, indifference
techniques can be classified as way of achieving one or more of three distinct
goals: rewards dependent on certain events (with no motivation for the agent to
manipulate the probability of those events), effective disbelief that an event
will ever occur, and seamless transition from one behaviour to another. There
are five basic methods to achieve these three goals. This paper classifies and
analyses these methods on POMDPs (though the methods are highly portable to
other agent designs), and establishes their uses, strengths, and limitations.
It aims to make the tools of indifference generally accessible and usable to
agent designers.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06387</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Short Packets over Block-Memoryless Fading Channels: Pilot-Assisted or
  Noncoherent Transmission?</dc:title>
 <dc:creator>&#xd6;stman, Johan</dc:creator>
 <dc:creator>Durisi, Giuseppe</dc:creator>
 <dc:creator>Str&#xf6;m, Erik G.</dc:creator>
 <dc:creator>Co&#x15f;kun, Mustafa C.</dc:creator>
 <dc:creator>Liva, Gianluigi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present nonasymptotic upper and lower bounds on the maximum coding rate
achievable when transmitting short packets over a Rician memoryless
block-fading channel for a given requirement on the packet error probability.
We focus on the practically relevant scenario in which there is no \emph{a
priori} channel state information available at the transmitter and at the
receiver. An upper bound built upon the min-max converse is compared to two
lower bounds: the first one relies on a noncoherent transmission strategy in
which the fading channel is not estimated explicitly at the receiver; the
second one employs pilot-assisted transmission (PAT) followed by
maximum-likelihood channel estimation and scaled mismatched nearest-neighbor
decoding at the receiver. Our bounds are tight enough to unveil the optimum
number of diversity branches that a packet should span so that the energy per
bit required to achieve a target packet error probability is minimized, for a
given constraint on the code rate and the packet size. Furthermore, the bounds
reveal that noncoherent transmission is more energy efficient than PAT, even
when the number of pilot symbols and their power is optimized. For example, for
the case when a coded packet of $168$ symbols is transmitted using a channel
code of rate $0.48$ bits/channel use, over a block-fading channel with block
size equal to $8$ symbols, PAT requires an additional $1.2$ dB of energy per
information bit to achieve a packet error probability of $10^{-3}$ compared to
a suitably designed noncoherent transmission scheme. Finally, we devise a PAT
scheme based on punctured tail-biting quasi-cyclic codes and ordered statistics
decoding, whose performance are close ($1$ dB gap at $10^{-3}$ packet error
probability) to the ones predicted by our PAT lower bound. This shows that the
PAT lower bound provides useful guidelines on the design of actual PAT schemes.
</dc:description>
 <dc:description>Comment: 30 pages, 5 figures, journal</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06391</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Effectiveness of Least Squares Generative Adversarial Networks</dc:title>
 <dc:creator>Mao, Xudong</dc:creator>
 <dc:creator>Li, Qing</dc:creator>
 <dc:creator>Xie, Haoran</dc:creator>
 <dc:creator>Lau, Raymond Y. K.</dc:creator>
 <dc:creator>Wang, Zhen</dc:creator>
 <dc:creator>Smolley, Stephen Paul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Unsupervised learning with generative adversarial networks (GANs) has proven
hugely successful. Regular GANs hypothesize the discriminator as a classifier
with the sigmoid cross entropy loss function. However, we found that this loss
function may lead to the vanishing gradients problem during the learning
process. To overcome such a problem, we propose in this paper the Least Squares
Generative Adversarial Networks (LSGANs) which adopt the least squares loss
function for the discriminator. We show that minimizing the objective function
of LSGAN yields minimizing the Pearson $\chi^2$ divergence. We also present a
theoretical analysis about the properties of LSGANs and $\chi^2$ divergence.
There are two benefits of LSGANs over regular GANs. First, LSGANs are able to
generate higher quality images than regular GANs. Second, LSGANs perform more
stable during the learning process. For evaluating the image quality, we train
LSGANs on several datasets including LSUN and a cat dataset, and the
experimental results show that the images generated by LSGANs are of better
quality than the ones generated by regular GANs. Furthermore, we evaluate the
stability of LSGANs in two groups. One is to compare between LSGANs and regular
GANs without gradient penalty. We conduct three experiments, including Gaussian
mixture distribution, difficult architectures, and a new proposed method ---
datasets with small variance, to illustrate the stability of LSGANs. The other
one is to compare between LSGANs with gradient penalty and WGANs with gradient
penalty (WGANs-GP). The experimental results show that LSGANs with gradient
penalty succeed in training for all the difficult architectures used in
WGANs-GP, including 101-layer ResNet.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06393</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-based Transform Coding with Application to Image Compression</dc:title>
 <dc:creator>Fracastoro, Giulia</dc:creator>
 <dc:creator>Thanou, Dorina</dc:creator>
 <dc:creator>Frossard, Pascal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  In this paper, we propose a new graph-based coding framework and illustrate
its application to image compression. Our approach relies on the careful design
of a graph that optimizes the overall rate-distortion performance through an
effective graph-based transform. We introduce a novel graph estimation
algorithm, which uncovers the connectivities between the graph signal values by
taking into consideration the coding of both the signal and the graph topology
in rate-distortion terms. In particular, we introduce a novel coding solution
for the graph by treating the edge weights as another graph signal that lies on
the dual graph. Then, the cost of the graph description is introduced in the
optimization problem by minimizing the sparsity of the coefficients of its
graph Fourier transform (GFT) on the dual graph. In this way, we obtain a
convex optimization problem whose solution defines an efficient transform
coding strategy. The proposed technique is a general framework that can be
applied to different types of signals, and we show two possible application
fields, namely natural image coding and piecewise smooth image coding. The
experimental results show that the proposed method outperforms classical fixed
transforms such as DCT, and, in the case of depth map coding, the obtained
results are even comparable to the state-of-the-art graph-based coding method,
that are specifically designed for depth map images.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06405</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Classification of Functional Gait Disorders</dc:title>
 <dc:creator>Slijepcevic, Djordje</dc:creator>
 <dc:creator>Zeppelzauer, Matthias</dc:creator>
 <dc:creator>Gorgas, Anna-Maria</dc:creator>
 <dc:creator>Schwab, Caterine</dc:creator>
 <dc:creator>Sch&#xfc;ller, Michael</dc:creator>
 <dc:creator>Baca, Arnold</dc:creator>
 <dc:creator>Breiteneder, Christian</dc:creator>
 <dc:creator>Horsak, Brian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This article proposes a comprehensive investigation of the automatic
classification of functional gait disorders based solely on ground reaction
force (GRF) measurements. The aim of the study is twofold: (1) to investigate
the suitability of stateof-the-art GRF parameterization techniques
(representations) for the discrimination of functional gait disorders; and (2)
to provide a first performance baseline for the automated classification of
functional gait disorders for a large-scale dataset. The utilized database
comprises GRF measurements from 279 patients with gait disorders (GDs) and data
from 161 healthy controls (N). Patients were manually classified into four
classes with different functional impairments associated with the &quot;hip&quot;,
&quot;knee&quot;, &quot;ankle&quot;, and &quot;calcaneus&quot;. Different parameterizations are investigated:
GRF parameters, global principal component analysis (PCA)-based representations
and a combined representation applying PCA on GRF parameters. The
discriminative power of each parameterization for different classes is
investigated by linear discriminant analysis (LDA). Based on this analysis, two
classification experiments are pursued: (1) distinction between healthy and
impaired gait (N vs. GD) and (2) multi-class classification between healthy
gait and all four GD classes. Experiments show promising results and reveal
among others that several factors, such as imbalanced class cardinalities and
varying numbers of measurement sessions per patient have a strong impact on the
classification accuracy and therefore need to be taken into account. The
results represent a promising first step towards the automated classification
of gait disorders and a first performance baseline for future developments in
this direction.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures, IEEE Journal of Biomedical and Health Informatics</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06405</dc:identifier>
 <dc:identifier>doi:10.1109/JBHI.2017.2785682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06414</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Wisdom of Polarized Crowds</dc:title>
 <dc:creator>Shi, Feng</dc:creator>
 <dc:creator>Teplitskiy, Misha</dc:creator>
 <dc:creator>Duede, Eamon</dc:creator>
 <dc:creator>Evans, James</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  As political polarization in the United States continues to rise, the
question of whether polarized individuals can fruitfully cooperate becomes
pressing. Although diversity of individual perspectives typically leads to
superior team performance on complex tasks, strong political perspectives have
been associated with conflict, misinformation and a reluctance to engage with
people and perspectives beyond one's echo chamber. It is unclear whether
self-selected teams of politically diverse individuals will create higher or
lower quality outcomes. In this paper, we explore the effect of team political
composition on performance through analysis of millions of edits to Wikipedia's
Political, Social Issues, and Science articles. We measure editors' political
alignments by their contributions to conservative versus liberal articles. A
survey of editors validates that those who primarily edit liberal articles
identify more strongly with the Democratic party and those who edit
conservative ones with the Republican party. Our analysis then reveals that
polarized teams---those consisting of a balanced set of politically diverse
editors---create articles of higher quality than politically homogeneous teams.
The effect appears most strongly in Wikipedia's Political articles, but is also
observed in Social Issues and even Science articles. Analysis of article &quot;talk
pages&quot; reveals that politically polarized teams engage in longer, more
constructive, competitive, and substantively focused but linguistically diverse
debates than political moderates. More intense use of Wikipedia policies by
politically diverse teams suggests institutional design principles to help
unleash the power of politically polarized teams.
</dc:description>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06417</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Online Defense Framework against Cyber Attacks on Automatic
  Generation Control</dc:title>
 <dc:creator>Huang, Tong</dc:creator>
 <dc:creator>Satchidanandan, Bharadwaj</dc:creator>
 <dc:creator>Kumar, P. R.</dc:creator>
 <dc:creator>Xie, Le</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We propose an online framework to defend against cyber attacks on Automatic
Generation Control (AGC). A cyber attack detection algorithm is designed based
on the approach of Dynamic Watermarking. The detection algorithm provides a
theoretical guarantee of detection of cyber attacks launched by sophisticated
attackers possessing extensive knowledge of the physical and statistical models
of targeted power systems. The proposed framework is practically implementable,
as it needs no hardware update on generation units. The efficacy of the
proposed framework is validated by a four-area synthetic power system.
</dc:description>
 <dc:description>Comment: 8 pages, 11 figures</dc:description>
 <dc:date>2017-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06424</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Write Stylized Chinese Characters by Reading a Handful of
  Examples</dc:title>
 <dc:creator>Sun, Danyang</dc:creator>
 <dc:creator>Ren, Tongzheng</dc:creator>
 <dc:creator>Li, Chongxun</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Su, Hang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Automatically writing stylized Chinese characters is an attractive yet
challenging task due to its wide applicabilities. In this paper, we propose a
novel framework named Style-Aware Variational Auto-Encoder (SA-VAE) to flexibly
generate Chinese characters. Specifically, we propose to capture the different
characteristics of a Chinese character by disentangling the latent features
into content-related and style-related components. Considering of the complex
shapes and structures, we incorporate the structure information as prior
knowledge into our framework to guide the generation. Our framework shows a
powerful one-shot/low-shot generalization ability by inferring the style
component given a character with unseen style. To the best of our knowledge,
this is the first attempt to learn to write new-style Chinese characters by
observing only one or a few examples. Extensive experiments demonstrate its
effectiveness in generating different stylized Chinese characters by fusing the
feature vectors corresponding to different contents and styles, which is of
significant importance in real-world applications.
</dc:description>
 <dc:description>Comment: CVPR 2018 submission</dc:description>
 <dc:date>2017-12-06</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06427</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Hate Speech in Social Media</dc:title>
 <dc:creator>Malmasi, Shervin</dc:creator>
 <dc:creator>Zampieri, Marcos</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we examine methods to detect hate speech in social media, while
distinguishing this from general profanity. We aim to establish lexical
baselines for this task by applying supervised classification methods using a
recently released dataset annotated for this purpose. As features, our system
uses character n-grams, word n-grams and word skip-grams. We obtain results of
78% accuracy in identifying posts across three classes. Results demonstrate
that the main challenge lies in discriminating profanity and hate speech from
each other. A number of directions for future work are discussed.
</dc:description>
 <dc:description>Comment: Proceedings of Recent Advances in Natural Language Processing
  (RANLP). pp. 467-472. Varna, Bulgaria</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06428</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Shapelet Transform for Multivariate Time Series Classification</dc:title>
 <dc:creator>Bostrom, Aaron</dc:creator>
 <dc:creator>Bagnall, Anthony</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Shapelets are phase independent subsequences designed for time series
classification. We propose three adaptations to the Shapelet Transform (ST) to
capture multivariate features in multivariate time series classification. We
create a unified set of data to benchmark our work on, and compare with three
other algorithms. We demonstrate that multivariate shapelets are not
significantly worse than other state-of-the-art algorithms.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06431</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Space Trade-Offs for Computing Euclidean Minimum Spanning Trees</dc:title>
 <dc:creator>Banyassady, Bahareh</dc:creator>
 <dc:creator>Barba, Luis</dc:creator>
 <dc:creator>Mulzer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In the limited-workspace model, we assume that the input of size $n$ lies in
a random access read-only memory. The output has to be reported sequentially,
and it cannot be accessed or modified. In addition, there is a read-write
workspace of $O(s)$ words, where $s \in \{1, \dots, n\}$ is a given parameter.
In a time-space trade-off, we are interested in how the running time of an
algorithm improves as $s$ varies from $1$ to $n$.
  We present a time-space trade-off for computing the Euclidean minimum
spanning tree (EMST) of a set $V$ of $n$ sites in the plane. We present an
algorithm that computes EMST$(V)$ using $O(n^3\log s /s^2)$ time and $O(s)$
words of workspace. Our algorithm uses the fact that EMST$(V)$ is a subgraph of
the bounded-degree relative neighborhood graph of $V$, and applies Kruskal's
MST algorithm on it. To achieve this with limited workspace, we introduce a
compact representation of planar graphs, called an $s$-net which allows us to
manipulate its component structure during the execution of the algorithm.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06435</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Coding Algorithms for Multi-Layered Video Broadcast</dc:title>
 <dc:creator>B&#xe9;rczi-Kov&#xe1;cs, Erika R.</dc:creator>
 <dc:creator>Kir&#xe1;ly, Zolt&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this paper we give network coding algorithms for multi-layered video
streaming. The problem is motivated by video broadcasting in a communication
network to users with varying demands. We give a polynomial time algorithm for
deciding feasibility for the case of two layers, and show that the problem
becomes NP-hard if the task is to maximize the number of satisfied demands. For
the case of three layers we also show NP-hardness of the problem. Finally, we
propose a heuristic for three layers and give experimental comparison with
previous approaches.
</dc:description>
 <dc:description>Comment: A preliminary version entitled &quot;A Network Coding Algorithm for
  Multi-Layered Video Streaming&quot; presented at International Symposium on
  Network Coding (NetCod), 2011</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06435</dc:identifier>
 <dc:identifier>Optimal and heuristic network coding algorithms for multi-layered
  video broadcast, Volume 71, Issue 1, January 2018, Pages 51-59</dc:identifier>
 <dc:identifier>doi:10.1002/net.21788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06438</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Adaptive Gas Cost Mechanism for Ethereum to Defend Against
  Under-Priced DoS Attacks</dc:title>
 <dc:creator>Chen, Ting</dc:creator>
 <dc:creator>Li, Xiaoqi</dc:creator>
 <dc:creator>Wang, Ying</dc:creator>
 <dc:creator>Chen, Jiachi</dc:creator>
 <dc:creator>Li, Zihao</dc:creator>
 <dc:creator>Luo, Xiapu</dc:creator>
 <dc:creator>Au, Man Ho</dc:creator>
 <dc:creator>Zhang, Xiaosong</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The gas mechanism in Ethereum charges the execution of every operation to
ensure that smart contracts running in EVM (Ethereum Virtual Machine) will be
eventually terminated. Failing to properly set the gas costs of EVM operations
allows attackers to launch DoS attacks on Ethereum. Although Ethereum recently
adjusted the gas costs of EVM operations to defend against known DoS attacks,
it remains unknown whether the new setting is proper and how to configure it to
defend against unknown DoS attacks. In this paper, we make the first step to
address this challenging issue by first proposing an emulation-based framework
to automatically measure the resource consumptions of EVM operations. The
results reveal that Ethereum's new setting is still not proper. Moreover, we
obtain an insight that there may always exist exploitable under-priced
operations if the cost is fixed. Hence, we propose a novel gas cost mechanism,
which dynamically adjusts the costs of EVM operations according to the number
of executions, to thwart DoS attacks. This method punishes the operations that
are executed much more frequently than before and lead to high gas costs. To
make our solution flexible and secure and avoid frequent update of Ethereum
client, we design a special smart contract that collaborates with the updated
EVM for dynamic parameter adjustment. Experimental results demonstrate that our
method can effectively thwart both known and unknown DoS attacks with flexible
parameter settings. Moreover, our method only introduces negligible additional
gas consumption for benign users.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06438</dc:identifier>
 <dc:identifier>In International Conference on Information Security Practice and
  Experience (ISPEC 2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06440</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Three IQs of AI Systems and their Testing Methods</dc:title>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Shi, Yong</dc:creator>
 <dc:creator>Liu, Ying</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The rapid development of artificial intelligence has brought the artificial
intelligence threat theory as well as the problem about how to evaluate the
intelligence level of intelligent products. Both need to find a quantitative
method to evaluate the intelligence level of intelligence systems, including
human intelligence. Based on the standard intelligence system and the extended
Von Neumann architecture, this paper proposes General IQ, Service IQ and Value
IQ evaluation methods for intelligence systems, depending on different
evaluation purposes. Among them, the General IQ of intelligence systems is to
answer the question of whether the artificial intelligence can surpass the
human intelligence, which is reflected in putting the intelligence systems on
an equal status and conducting the unified evaluation. The Service IQ and Value
IQ of intelligence systems are used to answer the question of how the
intelligent products can better serve the human, reflecting the intelligence
and required cost of each intelligence system as a product in the process of
serving human.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures</dc:description>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06442</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phylogenomics with Paralogs</dc:title>
 <dc:creator>Hellmuth, Marc</dc:creator>
 <dc:creator>Wieseke, Nicolas</dc:creator>
 <dc:creator>Lechner, Marcus</dc:creator>
 <dc:creator>Lenhof, Hans-Peter</dc:creator>
 <dc:creator>Middendorf, Martin</dc:creator>
 <dc:creator>Stadler, Peter F.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Phylogenomics heavily relies on well-curated sequence data sets that consist,
for each gene, exclusively of 1:1-orthologous. Paralogs are treated as a
dangerous nuisance that has to be detected and removed. We show here that this
severe restriction of the data sets is not necessary. Building upon recent
advances in mathematical phylogenetics we demonstrate that gene duplications
convey meaningful phylogenetic information and allow the inference of plausible
phylogenetic trees, provided orthologs and paralogs can be distinguished with a
degree of certainty. Starting from tree-free estimates of orthology, cograph
editing can sufficiently reduce the noise in order to find correct
event-annotated gene trees. The information of gene trees can then directly be
translated into constraints on the species trees. While the resolution is very
poor for individual gene families, we show that genome-wide data sets are
sufficient to generate fully resolved phylogenetic trees, even in the presence
of horizontal gene transfer.
  We demonstrate that the distribution of paralogs in large gene families
contains in itself sufficient phylogenetic signal to infer fully resolved
species phylogenies. This source of phylogenetic information is independent of
information contained in orthologous sequences and is resilient against
horizontal gene transfer. An important consequence is that phylogenomics data
sets need not be restricted to 1:1 orthologs.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06442</dc:identifier>
 <dc:identifier>PNAS 2015 112 (7) 2058-2063</dc:identifier>
 <dc:identifier>doi:10.1073/pnas.1412770112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06452</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic segmentation method of pelvic floor levator hiatus in
  ultrasound using a self-normalising neural network</dc:title>
 <dc:creator>Bonmati, Ester</dc:creator>
 <dc:creator>Hu, Yipeng</dc:creator>
 <dc:creator>Sindhwani, Nikhil</dc:creator>
 <dc:creator>Dietz, Hans Peter</dc:creator>
 <dc:creator>D'hooge, Jan</dc:creator>
 <dc:creator>Barratt, Dean</dc:creator>
 <dc:creator>Deprest, Jan</dc:creator>
 <dc:creator>Vercauteren, Tom</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmentation of the levator hiatus in ultrasound allows to extract biometrics
which are of importance for pelvic floor disorder assessment. In this work, we
present a fully automatic method using a convolutional neural network (CNN) to
outline the levator hiatus in a 2D image extracted from a 3D ultrasound volume.
In particular, our method uses a recently developed scaled exponential linear
unit (SELU) as a nonlinear self-normalising activation function, which for the
first time has been applied in medical imaging with CNN. SELU has important
advantages such as being parameter-free and mini-batch independent, which may
help to overcome memory constraints during training. A dataset with 91 images
from 35 patients during Valsalva, contraction and rest, all labelled by three
operators, is used for training and evaluation in a leave-one-patient-out
cross-validation. Results show a median Dice similarity coefficient of 0.90
with an interquartile range of 0.08, with equivalent performance to the three
operators (with a Williams' index of 1.03), and outperforming a U-Net
architecture without the need for batch normalisation. We conclude that the
proposed fully automatic method achieved equivalent accuracy in segmenting the
pelvic floor levator hiatus compared to a previous semi-automatic approach.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06452</dc:identifier>
 <dc:identifier>doi:10.1117/1.JMI.5.2.021206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06461</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meeting Energy-Efficient and QoS Requirements of 5G Using D2D
  Communications</dc:title>
 <dc:creator>Kelif, Jean-Marc</dc:creator>
 <dc:creator>Diego, William</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Device-to-device (D2D) communication is a promising technology for the future
wireless systems. It allows direct communication between devices, which
provides improvements in terms of delay, throughput and energy consumption.
Therefore, it can contribute to achieving the ambitious requirements of future
5G wireless system. In this sense, energy efficiency has become a key
requirement in the design of 5G technology. In this paper we analyze the
energy-efficiency improvement provided by D2D communications in an overlaying
scenario, in the context of a realistic wireless network system. This analysis
takes into account the two D2D phases, discovery and communication. A
centralized architecture is considered to manage discovery, which is a key
phase on D2D communications. Numerical evaluation shows improvement in terms of
energy-efficiency, reachable throughput and outage probability.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06463</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-Resolution with Deep Adaptive Image Resampling</dc:title>
 <dc:creator>Jia, Xu</dc:creator>
 <dc:creator>Chang, Hong</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning based methods have recently pushed the state-of-the-art on the
problem of Single Image Super-Resolution (SISR). In this work, we revisit the
more traditional interpolation-based methods, that were popular before, now
with the help of deep learning. In particular, we propose to use a
Convolutional Neural Network (CNN) to estimate spatially variant interpolation
kernels and apply the estimated kernels adaptively to each position in the
image. The whole model is trained in an end-to-end manner. We explore two ways
to improve the results for the case of large upscaling factors, and propose a
recursive extension of our basic model. This achieves results that are on par
with state-of-the-art methods. We visualize the estimated adaptive
interpolation kernels to gain more insight on the effectiveness of the proposed
method. We also extend the method to the task of joint image filtering and
again achieve state-of-the-art performance.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06467</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-modal Face Pose Estimation with Multi-task Manifold Deep Learning</dc:title>
 <dc:creator>Hong, Chaoqun</dc:creator>
 <dc:creator>Yu, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human face pose estimation aims at estimating the gazing direction or head
postures with 2D images. It gives some very important information such as
communicative gestures, saliency detection and so on, which attracts plenty of
attention recently. However, it is challenging because of complex background,
various orientations and face appearance visibility. Therefore, a descriptive
representation of face images and mapping it to poses are critical. In this
paper, we make use of multi-modal data and propose a novel face pose estimation
method that uses a novel deep learning framework named Multi-task Manifold Deep
Learning $M^2DL$. It is based on feature extraction with improved deep neural
networks and multi-modal mapping relationship with multi-task learning. In the
proposed deep learning based framework, Manifold Regularized Convolutional
Layers (MRCL) improve traditional convolutional layers by learning the
relationship among outputs of neurons. Besides, in the proposed mapping
relationship learning method, different modals of face representations are
naturally combined to learn the mapping function from face images to poses. In
this way, the computed mapping model with multiple tasks is improved.
Experimental results on three challenging benchmark datasets DPOSE, HPID and
BKHPD demonstrate the outstanding performance of $M^2DL$.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06468</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Different approaches to community detection</dc:title>
 <dc:creator>Rosvall, Martin</dc:creator>
 <dc:creator>Delvenne, Jean-Charles</dc:creator>
 <dc:creator>Schaub, Michael T.</dc:creator>
 <dc:creator>Lambiotte, Renaud</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A precise definition of what constitutes a community in networks has remained
elusive. Consequently, network scientists have compared community detection
algorithms on benchmark networks with a particular form of community structure
and classified them based on the mathematical techniques they employ. However,
this comparison can be misleading because apparent similarities in their
mathematical machinery can disguise different reasons for why we would want to
employ community detection in the first place. Here we provide a focused review
of these different motivations that underpin community detection. This
problem-driven classification is useful in applied network science, where it is
important to select an appropriate algorithm for the given purpose. Moreover,
highlighting the different approaches to community detection also delineates
the many lines of research and points out open directions and avenues for
future research.
</dc:description>
 <dc:description>Comment: 14 pages, 2 figures. Written as a chapter for forthcoming Advances in
  network clustering and blockmodeling, and based on an extended version of The
  many facets of community detection in complex networks, Appl. Netw. Sci. 2: 4
  (2017) by the same authors</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06471</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Products of Euclidean metrics and applications to proximity questions
  among curves</dc:title>
 <dc:creator>Emiris, Ioannis Z.</dc:creator>
 <dc:creator>Psarros, Ioannis</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  The problem of Approximate Nearest Neighbor (ANN) search is fundamental in
computer science and has benefited from significant progress in the past couple
of decades. However, most work has been devoted to pointsets whereas complex
shapes have not been sufficiently treated. Here, we focus on distance functions
between discretized curves in Euclidean space: they appear in a wide range of
applications, from road segments to time-series in general dimension. For
$\ell_p$-products of Euclidean metrics, for any $p$, we design simple and
efficient data structures for ANN, based on randomized projections, which are
of independent interest. They serve to solve proximity problems under a notion
of distance between discretized curves, which generalizes both discrete
Fr\'{e}chet and Dynamic Time Warping distances. These are the most popular and
practical approaches to comparing such curves. We offer the first data
structures and query algorithms for ANN with arbitrarily good approximation
factor, at the expense of increasing space usage and preprocessing time over
existing methods. Query time complexity is comparable or significantly improved
by our algorithms; our algorithm is especially efficient when the length of the
curves is bounded.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06473</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Power of Vertex Sparsifiers in Dynamic Graph Algorithms</dc:title>
 <dc:creator>Goranci, Gramoz</dc:creator>
 <dc:creator>Henzinger, Monika</dc:creator>
 <dc:creator>Peng, Pan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We introduce a new algorithmic framework for designing dynamic graph
algorithms in minor-free graphs, by exploiting the structure of such graphs and
a tool called vertex sparsification, which is a way to compress large graphs
into small ones that well preserve relevant properties among a subset of
vertices and has previously mainly been used in the design of approximation
algorithms.
  Using this framework, we obtain a Monte Carlo randomized fully dynamic
algorithm for $(1+\varepsilon)$-approximating the energy of electrical flows in
$n$-vertex planar graphs with $\tilde{O}(r\varepsilon^{-2})$ worst-case update
time and $\tilde{O}((r+\frac{n}{\sqrt{r}})\varepsilon^{-2})$ worst-case query
time, for any $r$ larger than some constant. For $r=n^{2/3}$, this gives
$\tilde{O}(n^{2/3}\varepsilon^{-2})$ update time and
$\tilde{O}(n^{2/3}\varepsilon^{-2})$ query time. We also extend this algorithm
to work for minor-free graphs with similar approximation and running time
guarantees. Furthermore, we illustrate our framework on the all-pairs max flow
and shortest path problems by giving corresponding dynamic algorithms in
minor-free graphs with both sublinear update and query times. To the best of
our knowledge, our results are the first to systematically establish such a
connection between dynamic graph algorithms and vertex sparsification.
  We also present both upper bound and lower bound for maintaining the energy
of electrical flows in the incremental subgraph model, where updates consist of
only vertex activations, which might be of independent interest.
</dc:description>
 <dc:description>Comment: A preliminary version was presented at the 25th Annual European
  Symposium on Algorithms (ESA 2017)</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06481</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>(Wireless) Scheduling, Graph Classes, and $c$-Colorable Subgraphs</dc:title>
 <dc:creator>Bentert, Matthias</dc:creator>
 <dc:creator>van Bevern, Ren&#xe9;</dc:creator>
 <dc:creator>Niedermeier, Rolf</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>05C85</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Inductive $k$-independent graphs are a generalization of chordal graphs and
have recently been advocated in the context of interference-avoiding wireless
communication scheduling. The NP-hard problem of finding maximum-weight induced
$c$-colorable subgraphs, which is a generalization of finding maximum
independent sets, naturally occurs when selecting $c$ sets of pairwise
non-conflicting jobs (modeled as graph vertices). We investigate the
parameterized complexity of this problem on inductive $k$-independent graphs.
We show that the Independent Set problem is W[1]-hard even on 2-simplicial
3-minoes---a subclass of inductive 2-independent graphs. On the contrary, we
prove that the more general Maximum $c$-Colorable Subgraph problem is
fixed-parameter tractable on edge-wise unions of cluster and chordal graphs,
which are 2-simplicial. In both cases, the parameter is the solution size.
Aside from this, we survey other graph classes between inductive 1-independent
and inductive 2-independent graphs with applications in scheduling.
</dc:description>
 <dc:description>Comment: Corrected meta data (abstract)</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06488</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invincible Strategies of Iterated Prisoner's Dilemma</dc:title>
 <dc:creator>Wang, Shiheng</dc:creator>
 <dc:creator>Lin, Fangzhen</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Iterated Prisoner's Dilemma(IPD) is a well-known benchmark for studying the
long term behaviors of rational agents, such as how cooperation can emerge
among selfish and unrelated agents that need to co-exist over long term. Many
well-known strategies have been studied, from the simple tit-for-tat(TFT)
strategy made famous by Axelrod after his influential tournaments to more
involved ones like zero determinant strategies studied recently by Press and
Dyson. In this paper, following Press and Dyson, we consider one memory
probabilistic strategies. We consider that we call invincible strategies: a
strategy is invincible if it never loses against any other strategy in terms of
average payoff in the limit, if the limit exists. We show a strategy is
invincible for infinite repeated iterated prisoner's dilemma.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06489</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Fidelity Reinforcement Learning with Gaussian Processes</dc:title>
 <dc:creator>Suryan, Varun</dc:creator>
 <dc:creator>Gondhalekar, Nahush</dc:creator>
 <dc:creator>Tokekar, Pratap</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper studies the problem of Reinforcement Learning (RL) using as few
real-world samples as possible. A naive application of RL algorithms can be
inefficient in large and continuous state spaces. We present two versions of
Multi-Fidelity Reinforcement Learning (MFRL) algorithm that leverage Gaussian
Processes (GPs) to learn the optimal policy in a real-world environment. In
MFRL framework, an agent uses multiple simulators of the real environment to
perform actions. With increasing fidelity in a simulator chain, the number of
samples used in successively higher simulators can be reduced. By incorporating
GPs in MFRL framework, further reduction in the number of learning samples can
be achieved as we move up the simulator chain. We examine the performance of
our algorithms with the help of real-world experiments for navigation with a
ground robot.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06492</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guiding human gaze with convolutional neural networks</dc:title>
 <dc:creator>Gatys, Leon A.</dc:creator>
 <dc:creator>K&#xfc;mmerer, Matthias</dc:creator>
 <dc:creator>Wallis, Thomas S. A.</dc:creator>
 <dc:creator>Bethge, Matthias</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The eye fixation patterns of human observers are a fundamental indicator of
the aspects of an image to which humans attend. Thus, manipulating fixation
patterns to guide human attention is an exciting challenge in digital image
processing. Here, we present a new model for manipulating images to change the
distribution of human fixations in a controlled fashion. We use the
state-of-the-art model for fixation prediction to train a convolutional neural
network to transform images so that they satisfy a given fixation distribution.
For network training, we carefully design a loss function to achieve a
perceptual effect while preserving naturalness of the transformed images.
Finally, we evaluate the success of our model by measuring human fixations for
a set of manipulated images. On our test images we can in-/decrease the
probability to fixate on selected objects on average by 43/22% but show that
the effectiveness of the model depends on the semantic content of the
manipulated images.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06496</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus in Self-similar Hierarchical Graphs and Sierpi\'nski Graphs:
  Convergence Speed, Delay Robustness, and Coherence</dc:title>
 <dc:creator>Qi, Yi</dc:creator>
 <dc:creator>Zhang, Zhongzhi</dc:creator>
 <dc:creator>Yi, Yuhao</dc:creator>
 <dc:creator>Li, Huan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The hierarchical graphs and Sierpi\'nski graphs are constructed iteratively,
which have the same number of vertices and edges at any iteration, but exhibit
quite different structural properties: the hierarchical graphs are non-fractal
and small-world, while the Sierpi\'nski graphs are fractal and &quot;large-world&quot;.
Both graphs have found broad applications. In this paper, we study consensus
problems in hierarchical graphs and Sierpi\'nski graphs, focusing on three
important quantities of consensus problems, that is, convergence speed, delay
robustness, and coherence for first-order (and second-order) dynamics, which
are, respectively, determined by algebraic connectivity, maximum eigenvalue,
and sum of reciprocal (and square of reciprocal) of each nonzero eigenvalue of
Laplacian matrix. For both graphs, based on the explicit recursive relation of
eigenvalues at two successive iterations, we evaluate the second smallest
eigenvalue, as well as the largest eigenvalue, and obtain the closed-form
solutions to the sum of reciprocals (and square of reciprocals) of all nonzero
eigenvalues. We also compare our obtained results for consensus problems on
both graphs and show that they differ in all quantities concerned, which is due
to the marked difference of their topological structures.
</dc:description>
 <dc:description>Comment: To be published on IEEE Transactions on Cybernetics</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06497</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HERO: Heterogeneous Embedded Research Platform for Exploring RISC-V
  Manycore Accelerators on FPGA</dc:title>
 <dc:creator>Kurth, Andreas</dc:creator>
 <dc:creator>Vogel, Pirmin</dc:creator>
 <dc:creator>Capotondi, Alessandro</dc:creator>
 <dc:creator>Marongiu, Andrea</dc:creator>
 <dc:creator>Benini, Luca</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Heterogeneous embedded systems on chip (HESoCs) co-integrate a standard host
processor with programmable manycore accelerators (PMCAs) to combine
general-purpose computing with domain-specific, efficient processing
capabilities. While leading companies successfully advance their HESoC
products, research lags behind due to the challenges of building a prototyping
platform that unites an industry-standard host processor with an open research
PMCA architecture. In this work we introduce HERO, an FPGA-based research
platform that combines a PMCA composed of clusters of RISC-V cores, implemented
as soft cores on an FPGA fabric, with a hard ARM Cortex-A multicore host
processor. The PMCA architecture mapped on the FPGA is silicon-proven,
scalable, configurable, and fully modifiable. HERO includes a complete software
stack that consists of a heterogeneous cross-compilation toolchain with support
for OpenMP accelerator programming, a Linux driver, and runtime libraries for
both host and PMCA. HERO is designed to facilitate rapid exploration on all
software and hardware layers: run-time behavior can be accurately analyzed by
tracing events, and modifications can be validated through fully automated hard
ware and software builds and executed tests. We demonstrate the usefulness of
HERO by means of case studies from our research.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06498</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Don't Rock the Boat: Algorithms for Balanced Dynamic Loading and
  Unloading</dc:title>
 <dc:creator>Fekete, S&#xe1;ndor P.</dc:creator>
 <dc:creator>von H&#xf6;veling, Sven</dc:creator>
 <dc:creator>Mitchell, Joseph S. B.</dc:creator>
 <dc:creator>Rieck, Christian</dc:creator>
 <dc:creator>Scheffer, Christian</dc:creator>
 <dc:creator>Schmidt, Arne</dc:creator>
 <dc:creator>Zuber, James R.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We consider dynamic loading and unloading problems for heavy geometric
objects. The challenge is to maintain balanced configurations at all times:
minimize the maximal motion of the overall center of gravity. While this
problem has been studied from an algorithmic point of view, previous work only
focuses on balancing the final center of gravity; we give a variety of results
for computing balanced loading and unloading schemes that minimize the maximal
motion of the center of gravity during the entire process. In particular, we
consider the one-dimensional case and distinguish between loading and
unloading. In the unloading variant, the positions of the intervals are given,
and we search for an optimal unloading order of the intervals. We prove that
the unloading variant is NP-complete and give a 2.7-approximation algorithm. In
the loading variant, we have to compute both the positions of the intervals and
their loading order. We give optimal approaches for several variants that model
different loading scenarios that may arise, e.g., in the loading of a transport
ship with containers.
</dc:description>
 <dc:description>Comment: 23 pages, 3 figures, full version of conference paper to appear in
  LATIN 2018</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06511</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensor Selection via Randomized Sampling</dc:title>
 <dc:creator>Bopardikar, Shaunak D.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Given a linear dynamical system, we consider the problem of selecting a
subset of sensors out of the total set in order to optimize two commonly used
metrics of observability, namely the maximum eigenvalue and the trace of the
observability Gramian. We apply a variant of a well-known randomized sampling
algorithm and derive novel lower bounds on the two metrics relative to the
total value with high probability. The computational complexity of the
algorithm is linear in the total number of sensors while the lower bounds are
independent of the total number of sensors. The empirical performance of the
proposed approach on synthetically generated datasets shows a remarkable
improvement over the theoretical bounds, especially in the regime of low number
of sensors selected.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06513</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global research collaboration: Networks and partners in South East Asia</dc:title>
 <dc:creator>Woolley, Richard</dc:creator>
 <dc:creator>Robinson-Garcia, Nicolas</dc:creator>
 <dc:creator>Costas, Rodrigo</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This is an empirical paper that addresses the role of bilateral and
multilateral international co-authorships in the six leading science systems
among the ASEAN group of countries (ASEAN6). The paper highlights the different
ways that bilateral and multilateral co-authorships structure global networks
and the collaborations of the ASEAN6. The paper looks at the influence of the
collaboration styles of major collaborating countries of the ASEAN6,
particularly the USA and Japan. It also highlights the role of bilateral and
multilateral co-authorships in the production of knowledge in the leading
specialisations of the ASEAN6. The discussion section offers some tentative
explanations for major dynamics evident in the results and summarises the next
steps in this research.
</dc:description>
 <dc:description>Comment: Working paper presented at the Globelics Conference 2017</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06530</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Weight Alignment for Convolutional Neural Networks</dc:title>
 <dc:creator>Iwana, Brian Kenji</dc:creator>
 <dc:creator>Uchida, Seiichi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we propose a method of improving Convolutional Neural Networks
(CNN) by determining the optimal alignment of weights and inputs using dynamic
programming. Conventional CNNs convolve learnable shared weights, or filters,
across the input data. The filters use a linear matching of weights to inputs
using an inner product between the filter and a window of the input. However,
it is possible that there exists a more optimal alignment of weights. Thus, we
propose the use of Dynamic Time Warping (DTW) to dynamically align the weights
to optimized input elements. This dynamic alignment is useful for time series
recognition due to the complexities of temporal relations and temporal
distortions. We demonstrate the effectiveness of the proposed architecture on
the Unipen online handwritten digit and character datasets, the UCI Spoken
Arabic Digit dataset, and the UCI Activities of Daily Life dataset.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06536</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonparametric Inference for Auto-Encoding Variational Bayes</dc:title>
 <dc:creator>Bodin, Erik</dc:creator>
 <dc:creator>Malik, Iman</dc:creator>
 <dc:creator>Ek, Carl Henrik</dc:creator>
 <dc:creator>Campbell, Neill D. F.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We would like to learn latent representations that are low-dimensional and
highly interpretable. A model that has these characteristics is the Gaussian
Process Latent Variable Model. The benefits and negative of the GP-LVM are
complementary to the Variational Autoencoder, the former provides interpretable
low-dimensional latent representations while the latter is able to handle large
amounts of data and can use non-Gaussian likelihoods. Our inspiration for this
paper is to marry these two approaches and reap the benefits of both. In order
to do so we will introduce a novel approximate inference scheme inspired by the
GP-LVM and the VAE. We show experimentally that the approximation allows the
capacity of the generative bottle-neck (Z) of the VAE to be arbitrarily large
without losing a highly interpretable representation, allowing reconstruction
quality to be unlimited by Z at the same time as a low-dimensional space can be
used to perform ancestral sampling from as well as a means to reason about the
embedded data.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Workshop on Advances in Approximate Bayesian
  Inference</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06541</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Size-Independent Sample Complexity of Neural Networks</dc:title>
 <dc:creator>Golowich, Noah</dc:creator>
 <dc:creator>Rakhlin, Alexander</dc:creator>
 <dc:creator>Shamir, Ohad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the sample complexity of learning neural networks, by providing new
bounds on their Rademacher complexity assuming norm constraints on the
parameter matrix of each layer. Compared to previous work, these complexity
bounds have improved dependence on the network depth, and under some additional
assumptions, are fully independent of the network size (both depth and width).
These results are derived using some novel techniques, which may be of
independent interest.
</dc:description>
 <dc:description>Comment: Discussion of Bartlett et al. [2017] and associated corollaries were
  updated, to reflect that paper's most recent version</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06559</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Power of Interpolation: Understanding the Effectiveness of SGD in
  Modern Over-parametrized Learning</dc:title>
 <dc:creator>Ma, Siyuan</dc:creator>
 <dc:creator>Bassily, Raef</dc:creator>
 <dc:creator>Belkin, Mikhail</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Stochastic Gradient Descent (SGD) with small mini-batch is a key component in
modern large-scale machine learning. However, its efficiency has not been easy
to analyze as most theoretical results require adaptive rates and show
convergence rates far slower than that for gradient descent, making
computational comparisons difficult.
  In this paper we aim to clarify the issue of fast SGD convergence. The key
observation is that most modern architectures are over-parametrized and are
trained to interpolate the data by driving the empirical loss (classification
and regression) close to zero. While it is still unclear why these interpolated
solutions perform well on test data, these regimes allow for very fast
convergence of SGD, comparable in the number of iterations to gradient descent.
  Specifically, consider the setting with quadratic objective function, or near
a minimum, where the quadratic term is dominant. We show that: (1) Mini-batch
size $1$ with constant step size is optimal in terms of computations to achieve
a given error. (2) There is a critical mini-batch size such that: (a. linear
scaling) SGD iteration with mini-batch size $m$ smaller than the critical size
is nearly equivalent to $m$ iterations of mini-batch size $1$. (b. saturation)
SGD iteration with mini-batch larger than the critical size is nearly
equivalent to a gradient descent step.
  The critical mini-batch size can be viewed as the limit for effective
mini-batch parallelization. It is also nearly independent of the data size,
implying $O(n)$ acceleration over GD per unit of computation.
  We give experimental evidence on real data, with the results closely
following our theoretical analyses.
  Finally, we show how the interpolation perspective and our results fit with
recent developments in training deep neural networks and discuss connections to
adaptive rates for SGD and variance reduction.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06560</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Exploration in Evolution Strategies for Deep Reinforcement
  Learning via a Population of Novelty-Seeking Agents</dc:title>
 <dc:creator>Conti, Edoardo</dc:creator>
 <dc:creator>Madhavan, Vashisht</dc:creator>
 <dc:creator>Such, Felipe Petroski</dc:creator>
 <dc:creator>Lehman, Joel</dc:creator>
 <dc:creator>Stanley, Kenneth O.</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Evolution strategies (ES) are a family of black-box optimization algorithms
able to train deep neural networks roughly as well as Q-learning and policy
gradient methods on challenging deep reinforcement learning (RL) problems, but
are much faster (e.g. hours vs. days) because they parallelize better. However,
many RL problems require directed exploration because they have reward
functions that are sparse or deceptive (i.e. contain local optima), and it is
not known how to encourage such exploration with ES. Here we show that
algorithms that have been invented to promote directed exploration in
small-scale evolved neural networks via populations of exploring agents,
specifically novelty search (NS) and quality diversity (QD) algorithms, can be
hybridized with ES to improve its performance on sparse or deceptive deep RL
tasks, while retaining scalability. Our experiments confirm that the resultant
new algorithms, NS-ES and a version of QD we call NSR-ES, avoid local optima
encountered by ES to achieve higher performance on tasks ranging from playing
Atari to simulated robots learning to walk around a deceptive trap. This paper
thus introduces a family of fast, scalable algorithms for reinforcement
learning that are capable of directed exploration. It also adds this new family
of exploration algorithms to the RL toolbox and raises the interesting
possibility that analogous algorithms with multiple simultaneous paths of
exploration might also combine well with existing RL algorithms outside ES.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06563</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe Mutations for Deep and Recurrent Neural Networks through Output
  Gradients</dc:title>
 <dc:creator>Lehman, Joel</dc:creator>
 <dc:creator>Chen, Jay</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:creator>Stanley, Kenneth O.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  While neuroevolution (evolving neural networks) has a successful track record
across a variety of domains from reinforcement learning to artificial life, it
is rarely applied to large, deep neural networks. A central reason is that
while random mutation generally works in low dimensions, a random perturbation
of thousands or millions of weights is likely to break existing functionality,
providing no learning signal even if some individual weight changes were
beneficial. This paper proposes a solution by introducing a family of safe
mutation (SM) operators that aim within the mutation operator itself to find a
degree of change that does not alter network behavior too much, but still
facilitates exploration. Importantly, these SM operators do not require any
additional interactions with the environment. The most effective SM variant
capitalizes on the intriguing opportunity to scale the degree of mutation of
each individual weight according to the sensitivity of the network's outputs to
that weight, which requires computing the gradient of outputs with respect to
the weights (instead of the gradient of error, as in conventional deep
learning). This safe mutation through gradients (SM-G) operator dramatically
increases the ability of a simple genetic algorithm-based neuroevolution method
to find solutions in high-dimensional domains that require deep and/or
recurrent neural networks (which tend to be particularly brittle to mutation),
including domains that require processing raw pixels. By improving our ability
to evolve deep neural networks, this new safer approach to mutation expands the
scope of domains amenable to neuroevolution.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06564</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Relationship Between the OpenAI Evolution Strategy and Stochastic
  Gradient Descent</dc:title>
 <dc:creator>Zhang, Xingwen</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:creator>Stanley, Kenneth O.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Because stochastic gradient descent (SGD) has shown promise optimizing neural
networks with millions of parameters and few if any alternatives are known to
exist, it has moved to the heart of leading approaches to reinforcement
learning (RL). For that reason, the recent result from OpenAI showing that a
particular kind of evolution strategy (ES) can rival the performance of
SGD-based deep RL methods with large neural networks provoked surprise. This
result is difficult to interpret in part because of the lingering ambiguity on
how ES actually relates to SGD. The aim of this paper is to significantly
reduce this ambiguity through a series of MNIST-based experiments designed to
uncover their relationship. As a simple supervised problem without domain noise
(unlike in most RL), MNIST makes it possible (1) to measure the correlation
between gradients computed by ES and SGD and (2) then to develop an SGD-based
proxy that accurately predicts the performance of different ES population
sizes. These innovations give a new level of insight into the real capabilities
of ES, and lead also to some unconventional means for applying ES to supervised
problems that shed further light on its differences from SGD. Incorporating
these lessons, the paper concludes by demonstrating that ES can achieve 99%
accuracy on MNIST, a number higher than any previously published result for any
evolutionary method. While not by any means suggesting that ES should
substitute for SGD in supervised learning, the suite of experiments herein
enables more informed decisions on the application of ES within RL and other
paradigms.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06566</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-point Vibration Measurement for Mode Identification of Bridge
  Structures using Video-based Motion Magnification</dc:title>
 <dc:creator>Shang, Zhexiong</dc:creator>
 <dc:creator>Shen, Zhigang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image-based vibration mode identification gained increased attentions in
civil and construction communities. A recent video-based motion magnification
method was developed to measure and visualize small structure motions. This new
approach presents a potential for low-cost vibration measurement and mode shape
identification. Pilot studies using this approach on simple rigid body
structures was reported. Its validity on complex outdoor structures have not
been investigated. The objective is to investigate the capacity of video-based
motion magnification approach in measuring the modal frequency and visualizing
the mode shapes of complex steel bridges. A novel method that increases the
performance of the current motion magnification for efficient structure modal
analysis is introduced. This method was tested in both indoor and outdoor
environments for validation. The results of the investigation show that motion
magnification can be an efficient tool for modal analysis on complex bridge
structures. With the developed method, mode frequencies of multiple structures
are simultaneously measured and mode shapes of each structure are automatically
visualized.
</dc:description>
 <dc:description>Comment: 15 pages including 9 figures and references</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06567</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative
  for Training Deep Neural Networks for Reinforcement Learning</dc:title>
 <dc:creator>Such, Felipe Petroski</dc:creator>
 <dc:creator>Madhavan, Vashisht</dc:creator>
 <dc:creator>Conti, Edoardo</dc:creator>
 <dc:creator>Lehman, Joel</dc:creator>
 <dc:creator>Stanley, Kenneth O.</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep artificial neural networks (DNNs) are typically trained via
gradient-based learning algorithms, namely backpropagation. Evolution
strategies (ES) can rival backprop-based algorithms such as Q-learning and
policy gradients on challenging deep reinforcement learning (RL) problems.
However, ES can be considered a gradient-based algorithm because it performs
stochastic gradient descent via an operation similar to a finite-difference
approximation of the gradient. That raises the question of whether
non-gradient-based evolutionary algorithms can work at DNN scales. Here we
demonstrate they can: we evolve the weights of a DNN with a simple,
gradient-free, population-based genetic algorithm (GA) and it performs well on
hard deep RL problems, including Atari and humanoid locomotion. The Deep GA
successfully evolves networks with over four million free parameters, the
largest neural networks ever evolved with a traditional evolutionary algorithm.
These results (1) expand our sense of the scale at which GAs can operate, (2)
suggest intriguingly that in some cases following the gradient is not the best
choice for optimizing performance, and (3) make immediately available the
multitude of techniques that have been developed in the neuroevolution
community to improve performance on RL problems. To demonstrate the latter, we
show that combining DNNs with novelty search, which was designed to encourage
exploration on tasks with deceptive or sparse reward functions, can solve a
high-dimensional problem on which reward-maximizing algorithms (e.g. DQN, A3C,
ES, and the GA) fail. Additionally, the Deep GA parallelizes better than ES,
A3C, and DQN, and enables a state-of-the-art compact encoding technique that
can represent million-parameter DNNs in thousands of bytes.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06568</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ES Is More Than Just a Traditional Finite-Difference Approximator</dc:title>
 <dc:creator>Lehman, Joel</dc:creator>
 <dc:creator>Chen, Jay</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:creator>Stanley, Kenneth O.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  An evolution strategy (ES) variant recently attracted significant attention
due to its surprisingly good performance at optimizing neural networks in
challenging deep reinforcement learning domains. It searches directly in the
parameter space of neural networks by generating perturbations to the current
set of parameters, checking their performance, and moving in the direction of
higher reward. The resemblance of this algorithm to a traditional
finite-difference approximation of the reward gradient in parameter space
naturally leads to the assumption that it is just that. However, this
assumption is incorrect. The aim of this paper is to definitively demonstrate
this point empirically. ES is a gradient approximator, but optimizes for a
different gradient than just reward (especially when the magnitude of candidate
perturbations is high). Instead, it optimizes for the average reward of the
entire population, often also promoting parameters that are robust to
perturbation. This difference can channel ES into significantly different areas
of the search space than gradient descent in parameter space, and also
consequently to networks with significantly different properties. This unique
robustness-seeking property, and its consequences for optimization, are
demonstrated in several domains. They include humanoid locomotion, where
networks from policy gradient-based reinforcement learning are far less robust
to parameter perturbation than ES-based policies that solve the same task.
While the implications of such robustness and robustness-seeking remain open to
further study, the main contribution of this work is to highlight that such
differences indeed exist and deserve attention.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06577</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Complexity of Forward and Backward Propagation</dc:title>
 <dc:creator>Naumov, Maxim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>68T05 (Primary) 65F99, 15B99 (Secondary)</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5.0</dc:subject>
 <dc:description>  We show that the forward and backward propagation can be formulated as a
solution of lower and upper triangular systems of equations. For standard
feedforward (FNNs) and recurrent neural networks (RNNs) the triangular systems
are always block bi-diagonal, while for a general computation graph (directed
acyclic graph) they can have a more complex triangular sparsity pattern. We
discuss direct and iterative parallel algorithms that can be used for their
solution and interpreted as different ways of performing model parallelism.
Also, we show that for FNNs and RNNs with $k$ layers and $\tau$ time steps the
backward propagation can be performed in parallel in O($\log k$) and O($\log k
\log \tau$) steps, respectively. Finally, we outline the generalization of this
technique using Jacobians that potentially allows us to handle arbitrary
layers.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06580</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Path loss, beamforming gain and time dynamics measurements at 28 GHz for
  90% indoor coverage</dc:title>
 <dc:creator>Chizhik, Dmitry</dc:creator>
 <dc:creator>Du, Jinfeng</dc:creator>
 <dc:creator>Feick, Rodolfo</dc:creator>
 <dc:creator>Rodriguez, Mauricio</dc:creator>
 <dc:creator>Castro, Guillermo</dc:creator>
 <dc:creator>Valenzuela, Reinaldo. A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Achieving adequate coverage with high gain antennas is key to realizing the
full promise of the wide bandwidth available at mm/cm bands. We report
extensive indoor measurements at 28 GHz, with over 1000 links with and without
Line-of-Sight (LOS) using a specialized narrowband channel sounder, capable of
reliable measurements up to 171 dB path loss to characterize 90% coverage.
Azimuthal power spectra were captured with 1-deg granularity using a 10-deg
receive horn spun at speeds up to 300 rpm. Measured path gain-distance
dependence in LOS and NLOS are well represented by power-law models, with 3.1
dB standard deviation in NLOS, and by a mode-diffusion model with 3.5 dB RMS
error. Excess loss at 28 GHz suffered in turning a corner or into a room was
found to be 30 and 32 dB respectively, in contrast to 20 dB found previously at
2 GHz. Degradation of azimuthal gain by scattering was within 4 dB in the
hallway and 7 dB inside a room with 90% probability. System simulations in a
canonical building indicate that every hallway needs an access point to provide
1 Gbps rate in 90% of locations using 1 GHz of bandwidth. For stationary
terminals, with temporal fading caused by pedestrians, long term
average-power-based aiming was within 3.7 dB of rapid beam switching in 90% of
high traffic locations.
</dc:description>
 <dc:description>Comment: Submitted to IEEE for possible publication. Part of the results
  reported here will be presented at IEEE EUCAP, 2018</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06583</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sum-Rate Analysis for High Altitude Platform (HAP) Drones with Tethered
  Balloon Relay</dc:title>
 <dc:creator>Sudheesh, P. G.</dc:creator>
 <dc:creator>Mozaffari, Mohammad</dc:creator>
 <dc:creator>Magarini, Maurizio</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Muthuchidambaranathan, P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  High altitude platform (HAP) drones can provide broadband wireless
connectivity to ground users in rural areas by establishing line-of-sight (LoS)
links and exploiting effective beamforming techniques. However, at high
altitudes, acquiring the channel state information (CSI) for HAPs, which is a
key component to perform beamforming, is challenging. In this paper, by
exploiting an interference alignment (IA) technique, a novel method for
achieving the maximum sum-rate in HAP-based communications without CSI is
proposed. In particular, to realize IA, a multiple-antenna tethered balloon is
used as a relay between multiple HAP drones and ground stations (GSs). Here, a
multiple-input multiple-output X network system is considered. The capacity of
the considered M*N X network with a tethered balloon relay is derived in
closed-form. Simulation results corroborate the theoretical findings and show
that the proposed approach yields the maximum sum-rate in multiple HAPs-GSs
communications in absence of CSI. The results also show the existence of an
optimal balloon's altitude for which the sum-rate is maximized.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Communications Letters</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06584</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Recovery of Human Shape and Pose</dc:title>
 <dc:creator>Kanazawa, Angjoo</dc:creator>
 <dc:creator>Black, Michael J.</dc:creator>
 <dc:creator>Jacobs, David W.</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We describe Human Mesh Recovery (HMR), an end-to-end framework for
reconstructing a full 3D mesh of a human body from a single RGB image. In
contrast to most current methods that compute 2D or 3D joint locations, we
produce a richer and more useful mesh representation that is parameterized by
shape and 3D joint angles. The main objective is to minimize the reprojection
loss of keypoints, which allow our model to be trained using in-the-wild images
that only have ground truth 2D annotations. However, reprojection loss alone is
highly under constrained. In this work we address this problem by introducing
an adversary trained to tell whether a human body parameter is real or not
using a large database of 3D human meshes. We show that HMR can be trained with
and without using any coupled 2D-to-3D supervision. We do not rely on
intermediate 2D keypoint detection and infer 3D pose and shape parameters
directly from image pixels. Our model runs in real-time given a bounding box
containing the person. We demonstrate our approach on various images
in-the-wild and out-perform previous optimizationbased methods that output 3D
meshes and show competitive results on tasks such as 3D joint location
estimation and part segmentation.
</dc:description>
 <dc:description>Comment: Project page: https://akanazawa.github.io/hmr/</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06585</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Third-order Smoothness Helps: Even Faster Stochastic Optimization
  Algorithms for Finding Local Minima</dc:title>
 <dc:creator>Yu, Yaodong</dc:creator>
 <dc:creator>Xu, Pan</dc:creator>
 <dc:creator>Gu, Quanquan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose stochastic optimization algorithms that can find local minima
faster than existing algorithms for nonconvex optimization problems, by
exploiting the third-order smoothness to escape non-degenerate saddle points
more efficiently. More specifically, the proposed algorithm only needs
$\tilde{O}(\epsilon^{-10/3})$ stochastic gradient evaluations to converge to an
approximate local minimum $\mathbf{x}$, which satisfies $\|\nabla
f(\mathbf{x})\|_2\leq\epsilon$ and $\lambda_{\min}(\nabla^2 f(\mathbf{x}))\geq
-\sqrt{\epsilon}$ in the general stochastic optimization setting, where
$\tilde{O}(\cdot)$ hides logarithm polynomial terms and constants. This
improves upon the $\tilde{O}(\epsilon^{-7/2})$ gradient complexity achieved by
the state-of-the-art stochastic local minima finding algorithms by a factor of
$\tilde{O}(\epsilon^{-1/6})$. For nonconvex finite-sum optimization, our
algorithm also outperforms the best known algorithms in a certain regime.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06587</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving satisfiability using inclusion-exclusion</dc:title>
 <dc:creator>Zaleski, Anthony</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68W40, 68R01</dc:subject>
 <dc:description>  Using Maple, we implement a SAT solver based on the principle of
inclusion-exclusion and the Bonferroni inequalities. Using randomly generated
input, we investigate the performance of our solver as a function of the number
of variables and number of clauses. We also test it against Maple's built-in
tautology procedure. Finally, we implement the Lov\'asz local lemma with Maple
and discuss its applicability to SAT.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures, Maple package available on author's site</dc:description>
 <dc:date>2017-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06634</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Better Algorithms for Hybrid Circuit and Packet Switching in Data
  Centers</dc:title>
 <dc:creator>Liu, Liang</dc:creator>
 <dc:creator>Gong, Long</dc:creator>
 <dc:creator>Yang, Sen</dc:creator>
 <dc:creator>Xu, Jun</dc:creator>
 <dc:creator>Fortnow, Lance</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Hybrid circuit and packet switching for data center networking (DCN) has
received considerable research attention recently. A hybrid-switched DCN
employs a much faster circuit switch that is reconfigurable with a nontrivial
cost, and a much slower packet switch that is reconfigurable with no cost, to
interconnect its racks of servers. The research problem is, given a traffic
demand matrix (between the racks), how to compute a good circuit switch
configuration schedule so that the vast majority of the traffic demand is
removed by the circuit switch, leaving a remaining demand matrix that contains
only small elements for the packet switch to handle. In this paper, we propose
two new hybrid switch scheduling algorithms under two different scheduling
constraints. Our first algorithm, called 2-hop Eclipse, strikes a much better
tradeoff between the resulting performance (of the hybrid switch) and the
computational complexity (of the algorithm) than the state of the art solution
Eclipse/Eclipse++. Our second algorithm, called BFF (best first fit), is the
first hybrid switching solution that exploits the potential partial
reconfiguration capability of the circuit switch for performance gains.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06646</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Not to Classify: Anomaly Detection of Attacks (ADA) on DNN
  Classifiers at Test Time</dc:title>
 <dc:creator>Miller, David J.</dc:creator>
 <dc:creator>Wang, Yulia</dc:creator>
 <dc:creator>Kesidis, George</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A significant threat to the recent, wide deployment of machine learning-based
systems, including deep neural networks (DNNs), for a host of application
domains is adversarial learning (Adv-L) attacks. The main focus here is on
exploits applied against (DNN-based) classifiers at test time. While much work
has focused on devising attacks that make perturbations to a test pattern
(e.g., an image) which are human-imperceptible and yet still induce a change in
the classifier's decision, there is relative paucity of work in defending
against such attacks. Moreover, our thesis is that most existing defense
approaches &quot;miss the mark&quot;, seeking to robustify the classifier to make
&quot;correct&quot; decisions on perturbed patterns. While, unlike some prior works, we
make explicit the motivation of such approaches, we argue that it is generally
much more actionable to detect the attack, rather than to &quot;correctly classify&quot;
in the face of it. We hypothesize that, even if human-imperceptible,
adversarial perturbations are machine-detectable. We propose a purely
unsupervised anomaly detector (AD), based on suitable (null hypothesis) density
models for the different DNN layers and a novel Kullback-Leibler &quot;distance&quot; AD
test statistic. Tested on MNIST and CIFAR10 image databases under the prominent
attack strategy proposed by Goodfellow et al. [5], our approach achieves
compelling ROC AUCs for attack detection of 0.992 on MNIST, 0.957 on noisy
MNIST images, and 0.924 on CIFAR10. We also show that a simple detector that
counts the number of white regions in the image achieves 0.97 AUC in detecting
the attack on MNIST proposed by Papernot et al. [12].
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06651</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Objects that Sound</dc:title>
 <dc:creator>Arandjelovi&#x107;, Relja</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper our objectives are, first, networks that can embed audio and
visual inputs into a common space that is suitable for cross-modal retrieval;
and second, a network that can localize the object that sounds in an image,
given the audio signal. We achieve both these objectives by training from
unlabelled video using only audio-visual correspondence (AVC) as the objective
function. This is a form of cross-modal self-supervision from video.
  To this end, we design new network architectures that can be trained using
the AVC task for these functionalities: for cross-modal retrieval, and for
localizing the source of a sound in an image. We make the following
contributions: (i) show that audio and visual embedding can be learnt that
enable both within-mode (e.g. audio-to-audio) and between-mode retrieval; (ii)
explore various architectures for the AVC task, including those for the visual
stream that ingest a single image, or multiple images, or a single image and
multi-frame optical flow; (iii) show that the semantic object that sounds
within an image can be localized (using only the sound, no motion or flow
information); and (iv) give a cautionary tale in how to avoid undesirable
shortcuts in the data preparation.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06654</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graphic Narrative with Interactive Stylization Design</dc:title>
 <dc:creator>Garcia-Dorado, Ignacio</dc:creator>
 <dc:creator>Getreuer, Pascal</dc:creator>
 <dc:creator>Le, Madison</dc:creator>
 <dc:creator>Debreuil, Robin</dc:creator>
 <dc:creator>Kauffmann, Alex</dc:creator>
 <dc:creator>Milanfar, Peyman</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a system to convert any set of images (e.g., a video clip or a
photo album) into a storyboard. We aim to create multiple pleasing graphic
representations of the content at interactive rates, so the user can explore
and find the storyboard (images, layout, and stylization) that best suits their
needs and taste. The main challenges of this work are: selecting the content
images, placing them into panels, and applying a stylization. For the latter,
we propose an interactive design tool to create new stylizations using a wide
range of filter blocks. This approach unleashes the creativity by allowing the
user to tune, modify, and intuitively design new sequences of filters. In
parallel to this manual design, we propose a novel procedural approach that
automatically assembles sequences of filters for innovative results. We aim to
keep the algorithm complexity as low as possible such that it can run
interactively on a mobile device. Our results include examples of styles
designed using both our interactive and procedural tools, as well as their
final composition into interesting and appealing storyboards.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06657</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Augmented Pathologist: Challenges of Explainable-AI in
  Digital Pathology</dc:title>
 <dc:creator>Holzinger, Andreas</dc:creator>
 <dc:creator>Malle, Bernd</dc:creator>
 <dc:creator>Kieseberg, Peter</dc:creator>
 <dc:creator>Roth, Peter M.</dc:creator>
 <dc:creator>M&#xfc;ller, Heimo</dc:creator>
 <dc:creator>Reihs, Robert</dc:creator>
 <dc:creator>Zatloukal, Kurt</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Digital pathology is not only one of the most promising fields of diagnostic
medicine, but at the same time a hot topic for fundamental research. Digital
pathology is not just the transfer of histopathological slides into digital
representations. The combination of different data sources (images, patient
records, and *omics data) together with current advances in artificial
intelligence/machine learning enable to make novel information accessible and
quantifiable to a human expert, which is not yet available and not exploited in
current medical settings. The grand goal is to reach a level of usable
intelligence to understand the data in the context of an application task,
thereby making machine decisions transparent, interpretable and explainable.
The foundation of such an &quot;augmented pathologist&quot; needs an integrated approach:
While machine learning algorithms require many thousands of training examples,
a human expert is often confronted with only a few data points. Interestingly,
humans can learn from such few examples and are able to instantly interpret
complex patterns. Consequently, the grand goal is to combine the possibilities
of artificial intelligence with human intelligence and to find a well-suited
balance between them to enable what neither of them could do on their own. This
can raise the quality of education, diagnosis, prognosis and prediction of
cancer and other diseases. In this paper we describe some (incomplete) research
issues which we believe should be addressed in an integrated and concerted
effort for paving the way towards the augmented pathologist.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06658</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MEBoost: Mixing Estimators with Boosting for Imbalanced Data
  Classification</dc:title>
 <dc:creator>Rayhan, Farshid</dc:creator>
 <dc:creator>Ahmed, Sajid</dc:creator>
 <dc:creator>Mahbub, Asif</dc:creator>
 <dc:creator>Jani, Md. Rafsan</dc:creator>
 <dc:creator>Shatabda, Swakkhar</dc:creator>
 <dc:creator>Farid, Dewan Md.</dc:creator>
 <dc:creator>Rahman, Chowdhury Mofizur</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Class imbalance problem has been a challenging research problem in the fields
of machine learning and data mining as most real life datasets are imbalanced.
Several existing machine learning algorithms try to maximize the accuracy
classification by correctly identifying majority class samples while ignoring
the minority class. However, the concept of the minority class instances
usually represents a higher interest than the majority class. Recently, several
cost sensitive methods, ensemble models and sampling techniques have been used
in literature in order to classify imbalance datasets. In this paper, we
propose MEBoost, a new boosting algorithm for imbalanced datasets. MEBoost
mixes two different weak learners with boosting to improve the performance on
imbalanced datasets. MEBoost is an alternative to the existing techniques such
as SMOTEBoost, RUSBoost, Adaboost, etc. The performance of MEBoost has been
evaluated on 12 benchmark imbalanced datasets with state of the art ensemble
methods like SMOTEBoost, RUSBoost, Easy Ensemble, EUSBoost, DataBoost.
Experimental results show significant improvement over the other methods and it
can be concluded that MEBoost is an effective and promising algorithm to deal
with imbalance datasets. The python version of the code is available here:
https://github.com/farshidrayhanuiu/
</dc:description>
 <dc:description>Comment: SKIMA-2017</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06674</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>word representation or word embedding in Persian text</dc:title>
 <dc:creator>Sarmady, Siamak</dc:creator>
 <dc:creator>Rahmani, Erfan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Text processing is one of the sub-branches of natural language processing.
Recently, the use of machine learning and neural networks methods has been
given greater consideration. For this reason, the representation of words has
become very important. This article is about word representation or converting
words into vectors in Persian text. In this research GloVe, CBOW and skip-gram
methods are updated to produce embedded vectors for Persian words. In order to
train a neural networks, Bijankhan corpus, Hamshahri corpus and UPEC corpus
have been compound and used. Finally, we have 342,362 words that obtained
vectors in all three models for this words. These vectors have many usage for
Persian natural language processing.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06676</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MARVELO: Wireless Virtual Network Embedding for Overlay Graphs with
  Loops</dc:title>
 <dc:creator>Afifi, Haitham</dc:creator>
 <dc:creator>Auroux, Sebastien</dc:creator>
 <dc:creator>Karl, Holger</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  When deploying resource-intensive signal processing applications in wireless
sensor or mesh networks, distributing processing blocks over multiple nodes
becomes promising. Such distributed applications need to solve the placement
problem (which block to run on which node), the routing problem (which link
between blocks to map on which path between nodes), and the scheduling problem
(which transmission is active when). We investigate a variant where the
application graph may contain feedback loops and we exploit wireless networks?
inherent multicast advantage. Thus, we propose Multicast-Aware Routing for
Virtual network Embedding with Loops in Overlays (MARVELO) to find efficient
solutions for scheduling and routing under a detailed interference model. We
cast this as a mixed integer quadratically constrained optimisation problem and
provide an efficient heuristic. Simulations show that our approach handles
complex scenarios quickly.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06679</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DecideNet: Counting Varying Density Crowds Through Attention Guided
  Detection and Density Estimation</dc:title>
 <dc:creator>Liu, Jiang</dc:creator>
 <dc:creator>Gao, Chenqiang</dc:creator>
 <dc:creator>Meng, Deyu</dc:creator>
 <dc:creator>Hauptmann, Alexander G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In real-world crowd counting applications, the crowd densities vary greatly
in spatial and temporal domains. A detection based counting method will
estimate crowds accurately in low density scenes, while its reliability in
congested areas is downgraded. A regression based approach, on the other hand,
captures the general density information in crowded regions. Without knowing
the location of each person, it tends to overestimate the count in low density
areas. Thus, exclusively using either one of them is not sufficient to handle
all kinds of scenes with varying densities. To address this issue, a novel
end-to-end crowd counting framework, named DecideNet (DEteCtIon and Density
Estimation Network) is proposed. It can adaptively decide the appropriate
counting mode for different locations on the image based on its real density
conditions. DecideNet starts with estimating the crowd density by generating
detection and regression based density maps separately. To capture inevitable
variation in densities, it incorporates an attention module, meant to
adaptively assess the reliability of the two types of estimations. The final
crowd counts are obtained with the guidance of the attention module to adopt
suitable estimations from the two kinds of density maps. Experimental results
show that our method achieves state-of-the-art performance on three challenging
crowd counting datasets.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06682</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesizing Novel Pairs of Image and Text</dc:title>
 <dc:creator>Xie, Jason</dc:creator>
 <dc:creator>Bao, Tingwen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generating novel pairs of image and text is a problem that combines computer
vision and natural language processing. In this paper, we present strategies
for generating novel image and caption pairs based on existing captioning
datasets. The model takes advantage of recent advances in generative
adversarial networks and sequence-to-sequence modeling. We make generalizations
to generate paired samples from multiple domains. Furthermore, we study cycles
-- generating from image to text then back to image and vise versa, as well as
its connection with autoencoders.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06687</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Technique for Non-blocking Trees</dc:title>
 <dc:creator>Brown, Trevor</dc:creator>
 <dc:creator>Ellen, Faith</dc:creator>
 <dc:creator>Ruppert, Eric</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We describe a general technique for obtaining provably correct, non-blocking
implementations of a large class of tree data structures where pointers are
directed from parents to children. Updates are permitted to modify any
contiguous portion of the tree atomically. Our non-blocking algorithms make use
of the LLX, SCX and VLX primitives, which are multi-word generalizations of the
standard LL, SC and VL primitives and have been implemented from single-word
CAS.
  To illustrate our technique, we describe how it can be used in a fairly
straightforward way to obtain a non-blocking implementation of a chromatic
tree, which is a relaxed variant of a red-black tree. The height of the tree at
any time is $O(c+ \log n)$, where $n$ is the number of keys and $c$ is the
number of updates in progress. We provide an experimental performance analysis
which demonstrates that our Java implementation of a chromatic tree rivals, and
often significantly outperforms, other leading concurrent dictionaries.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06688</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pragmatic Primitives for Non-blocking Data Structures</dc:title>
 <dc:creator>Brown, Trevor</dc:creator>
 <dc:creator>Ellen, Faith</dc:creator>
 <dc:creator>Ruppert, Eric</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We define a new set of primitive operations that greatly simplify the
implementation of non-blocking data structures in asynchronous shared-memory
systems. The new operations operate on a set of Data-records, each of which
contains multiple fields. The operations are generalizations of the well-known
load-link (LL) and store-conditional (SC) operations called LLX and SCX. The
LLX operation takes a snapshot of one Data-record. An SCX operation by a
process $p$ succeeds only if no Data-record in a specified set has been changed
since $p$ last performed an LLX on it. If successful, the SCX atomically
updates one specific field of a Data-record in the set and prevents any future
changes to some specified subset of those Data-records. We provide a provably
correct implementation of these new primitives from single-word
compare-and-swap. As a simple example, we show how to implement a non-blocking
multiset data structure in a straightforward way using LLX and SCX.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06690</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental Evaluation of Counting Subgraph Isomorphisms in Classes of
  Bounded Expansion</dc:title>
 <dc:creator>O'Brien, Michael P.</dc:creator>
 <dc:creator>Sullivan, Blair D.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Counting subgraph isomorphisms (also called motifs or graphlets) has been
used extensively as a tool for analyzing biological and social networks. Under
standard complexity assumptions there is no polynomial time algorithm for this
problem, which limits the applicability of these tools to large data sets.
Recent techniques from parameterized complexity have led to an algorithmic
framework for isomorphism counting whose worst case time complexity is linear
in the number of vertices, provided that the input graph has certain structural
characteristics, known as bounded expansion. Previous work has suggested that
the restrictions of bounded expansion structure--locally dense pockets in a
globally sparse graph--naturally coincide with common properties of real-world
networks such as clustering and heavy-tailed degree distributions. However,
there has been little work done in implementing and evaluating the performance
of this algorithmic pipeline. To this end we introduced CONCUSS, an open-source
software package for counting subgraph isomorphisms in classes of bounded
expansion. Through a broad set of experiments we evaluate implementations of
multiple stages of the pipeline and demonstrate that our structure-based
algorithm can be up to an order of magnitude faster than a popular algorithm
for isomorphism counting.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06695</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate Inference for Adaptive Linear Models</dc:title>
 <dc:creator>Deshpande, Yash</dc:creator>
 <dc:creator>Mackey, Lester</dc:creator>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:creator>Taddy, Matt</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Estimators computed from adaptively collected data do not behave like their
non-adaptive brethren. Rather, the sequential dependence of the collection
policy can lead to severe distributional biases that persist even in the
infinite data limit. We develop a general method decorrelation procedure --
W-decorrelation -- for transforming the bias of adaptive linear regression
estimators into variance. The method uses only coarse-grained information about
the data collection policy and does not need access to propensity scores or
exact knowledge of the policy. We bound the finite-sample bias and variance of
the W-estimator and develop asymptotically correct confidence intervals based
on a novel martingale central limit theorem. We then demonstrate the empirical
benefits of the generic W-decorrelation procedure in two different adaptive
data settings: the multi-armed bandits and autoregressive time series models.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06704</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilingual Topic Models</dc:title>
 <dc:creator>Krstovski, Kriste</dc:creator>
 <dc:creator>Kurtz, Michael J.</dc:creator>
 <dc:creator>Smith, David A.</dc:creator>
 <dc:creator>Accomazzi, Alberto</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Scientific publications have evolved several features for mitigating
vocabulary mismatch when indexing, retrieving, and computing similarity between
articles. These mitigation strategies range from simply focusing on high-value
article sections, such as titles and abstracts, to assigning keywords, often
from controlled vocabularies, either manually or through automatic annotation.
Various document representation schemes possess different cost-benefit
tradeoffs. In this paper, we propose to model different representations of the
same article as translations of each other, all generated from a common latent
representation in a multilingual topic model. We start with a methodological
overview on latent variable models for parallel document representations that
could be used across many information science tasks. We then show how solving
the inference problem of mapping diverse representations into a shared topic
space allows us to evaluate representations based on how topically similar they
are to the original article. In addition, our proposed approach provides means
to discover where different concept vocabularies require improvement.
</dc:description>
 <dc:description>Comment: 18 pages, 9 figures</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06706</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Algorithms for Delta-Separated Sparsity Projection</dc:title>
 <dc:creator>Bruhn, Henning</dc:creator>
 <dc:creator>Schaudt, Oliver</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We describe a fast approximation algorithm for the $\Delta$-separated
sparsity projection problem. The $\Delta$-separated sparsity model was
introduced by Hegde, Duarte and Cevher (2009) to capture the firing process of
a single Poisson neuron with absolute refractoriness. The running time of our
projection algorithm is linear for an arbitrary (but fixed) precision and it is
both a head and a tail approximation. This solves a problem of Hegde, Indyk and
Schmidt (2015). We also describe how our algorithm fits into the approximate
model iterative hard tresholding framework of Hegde, Indyk and Schmidt (2014)
that allows to recover $\Delta$-separated sparse signals from noisy random
linear measurements. The resulting recovery algorithm is substantially faster
than the existing one, at least for large data sets.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06709</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>No truthful mechanism can be better than $n$ approximate for two natural
  problems</dc:title>
 <dc:creator>Leucci, Stefano</dc:creator>
 <dc:creator>Mamageishvili, Akaki</dc:creator>
 <dc:creator>Penna, Paolo</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This work gives the first natural non-utilitarian problems for which the
trivial $n$ approximation via VCG mechanisms is the best possible. That is, no
truthful mechanism can be better than $n$ approximate, where $n$ is the number
of agents. The problems are the min-max variant of shortest path and (directed)
minimum spanning tree mechanism design problems. In these procurement auctions,
agents own the edges of a network, and the corresponding edge costs are
private. Instead of the total weight of the subnetwork, in the min-max variant
we aim to minimize the maximum agent cost.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06713</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game-Theoretic Electric Vehicle Charging Management Resilient to
  Non-Ideal User Behavior</dc:title>
 <dc:creator>Mediwaththe, Chathurika P.</dc:creator>
 <dc:creator>Smith, David B.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, an electric vehicle (EV) charging competition, among EV
aggregators that perform coordinated EV charging, is explored while taking into
consideration potential non-ideal actions of the aggregators. In the
coordinated EV charging strategy presented in this paper, each aggregator
determines EV charging start time and charging energy profiles to minimize
overall EV charging energy cost by including consideration of the actions of
the neighboring aggregators. The competitive interactions of the aggregators
are modeled by developing a two-stage non-cooperative game among the
aggregators. The game is then studied under prospect theory to examine the
impacts of non-ideal actions of the aggregators in selecting EV charging start
times according to subjectively evaluating their opponents' actions. It is
shown that the non-cooperative interactions among the aggregators lead to a
subgame perfect $\epsilon$-Nash equilibrium when the game is played with either
ideal, or non-ideal, actions of the aggregators. A case study presented
demonstrates that the benefits of the coordinated EV charging strategy, in
terms of energy cost savings and peak-to-average ratio reductions, are
significantly resilient to non-ideal actions of the aggregators.
</dc:description>
 <dc:description>Comment: Accepted to appear in IEEE Transactions on Intelligent Transportation
  Systems</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06715</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deformable Classifiers</dc:title>
 <dc:creator>Shen, Jiajun</dc:creator>
 <dc:creator>Amit, Yali</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Geometric variations of objects, which do not modify the object class, pose a
major challenge for object recognition. These variations could be rigid as well
as non-rigid transformations. In this paper, we design a framework for training
deformable classifiers, where latent transformation variables are introduced,
and a transformation of the object image to a reference instantiation is
computed in terms of the classifier output, separately for each class. The
classifier outputs for each class, after transformation, are compared to yield
the final decision. As a by-product of the classification this yields a
transformation of the input object to a reference pose, which can be used for
downstream tasks such as the computation of object support. We apply a two-step
training mechanism for our framework, which alternates between optimizing over
the latent transformation variables and the classifier parameters to minimize
the loss function. We show that multilayer perceptrons, also known as deep
networks, are well suited for this approach and achieve state of the art
results on the rotated MNIST and the Google Earth dataset, and produce
competitive results on MNIST and CIFAR-10 when training on smaller subsets of
training data.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06742</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PixelBNN: Augmenting the PixelCNN with batch normalization and the
  presentation of a fast architecture for retinal vessel segmentation</dc:title>
 <dc:creator>Leopold, Henry A</dc:creator>
 <dc:creator>Orchard, Jeff</dc:creator>
 <dc:creator>Zelek, John S</dc:creator>
 <dc:creator>Lakshminarayanan, Vasudevan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Analysis of retinal fundus images is essential for eye-care physicians in the
diagnosis, care and treatment of patients. Accurate fundus and/or retinal
vessel maps give rise to longitudinal studies able to utilize multimedia image
registration and disease/condition status measurements, as well as applications
in surgery preparation and biometrics. The segmentation of retinal morphology
has numerous applications in assessing ophthalmologic and cardiovascular
disease pathologies. The early detection of many such conditions is often the
most effective method for reducing patient risk. Computer aided segmentation of
the vasculature has proven to be a challenge, mainly due to inconsistencies
such as noise and variations in hue and brightness that can greatly reduce the
quality of fundus images. This paper presents PixelBNN, a highly efficient deep
method for automating the segmentation of fundus morphologies. The model was
trained, tested and cross tested on the DRIVE, STARE and CHASE\_DB1 retinal
vessel segmentation datasets. Performance was evaluated using G-mean, Mathews
Correlation Coefficient and F1-score. The network was 8.5 times faster than the
current state-of-the-art at test time and performed comparatively well,
considering a 5 to 19 times reduction in information from resizing images
during preprocessing.
</dc:description>
 <dc:description>Comment: Manuscript accepted into SPIE Journal of Medical Imaging special
  section on Radiomics and Deep Learning</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06745</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Algorithms for Searching the Minimum Information Partition in
  Integrated Information Theory</dc:title>
 <dc:creator>Kitazono, Jun</dc:creator>
 <dc:creator>Kanai, Ryota</dc:creator>
 <dc:creator>Oizumi, Masafumi</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The ability to integrate information in the brain is considered to be an
essential property for cognition and consciousness. Integrated Information
Theory (IIT) hypothesizes that the amount of integrated information ($\Phi$) in
the brain is related to the level of consciousness. IIT proposes that to
quantify information integration in a system as a whole, integrated information
should be measured across the partition of the system at which information loss
caused by partitioning is minimized, called the Minimum Information Partition
(MIP). The computational cost for exhaustively searching for the MIP grows
exponentially with system size, making it difficult to apply IIT to real neural
data. It has been previously shown that if a measure of $\Phi$ satisfies a
mathematical property, submodularity, the MIP can be found in a polynomial
order by an optimization algorithm. However, although the first version of
$\Phi$ is submodular, the later versions are not. In this study, we empirically
explore to what extent the algorithm can be applied to the non-submodular
measures of $\Phi$ by evaluating the accuracy of the algorithm in simulated
data and real neural data. We find that the algorithm identifies the MIP in a
nearly perfect manner even for the non-submodular measures. Our results show
that the algorithm allows us to measure $\Phi$ in large systems within a
practical amount of time.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06747</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for low-distortion embeddings into arbitrary 1-dimensional
  spaces</dc:title>
 <dc:creator>Carpenter, Timothy</dc:creator>
 <dc:creator>Fomin, Fedor V.</dc:creator>
 <dc:creator>Lokshtanov, Daniel</dc:creator>
 <dc:creator>Saurabh, Saket</dc:creator>
 <dc:creator>Sidiropoulos, Anastasios</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We study the problem of finding a minimum-distortion embedding of the
shortest path metric of an unweighted graph into a &quot;simpler&quot; metric $X$.
Computing such an embedding (exactly or approximately) is a non-trivial task
even when $X$ is the metric induced by a path, or, equivalently, into the real
line. In this paper we give approximation and fixed-parameter tractable (FPT)
algorithms for minimum-distortion embeddings into the metric of a subdivision
of some fixed graph $H$, or, equivalently, into any fixed 1-dimensional
simplicial complex. More precisely, we study the following problem: For given
graphs $G$, $H$ and integer $c$, is it possible to embed $G$ with distortion
$c$ into a graph homeomorphic to $H$? Then embedding into the line is the
special case $H=K_2$, and embedding into the cycle is the case $H=K_3$, where
$K_k$ denotes the complete graph on $k$ vertices. For this problem we give
  -an approximation algorithm, which in time $f(H)\cdot \text{poly} (n)$, for
some function $f$, either correctly decides that there is no embedding of $G$
with distortion $c$ into any graph homeomorphic to $H$, or finds an embedding
with distortion $\text{poly}(c)$;
  -an exact algorithm, which in time $f'(H, c)\cdot \text{poly} (n)$, for some
function $f'$, either correctly decides that there is no embedding of $G$ with
distortion $c$ into any graph homeomorphic to $H$, or finds an embedding with
distortion $c$.
  Prior to our work, $\text{poly}(\mathsf{OPT})$-approximation or FPT
algorithms were known only for embedding into paths and trees of bounded
degrees.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06750</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Tradeoff Between Transmission Diversity and Content Diversity
  in Multi-Cell Edge Caching</dc:title>
 <dc:creator>Liu, Kangqi</dc:creator>
 <dc:creator>Tao, Meixia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Caching in multi-cell networks faces a well-known dilemma, i.e., to cache
same contents among multiple edge nodes to enable transmission
cooperation/diversity for higher transmission efficiency, or to cache different
contents to enable content diversity for higher cache hit rate. In this work,
we introduce a partition-based caching to exploit the tradeoff between
transmission diversity and content diversity in a multi-cell edge caching
networks with single user only. The performance is characterized by the system
average outage probability, which can be viewed as weighted sum between cache
hit outage probability and cache miss probability. We show that (i) In the low
SNR region, the edge nodes are encouraged to cache more fractions of the most
popular files so as to better exploit the transmission diversity for the most
popular content; (ii) In the high SNR region, the edge nodes are encouraged to
cache more files with less fractions of each so as to better exploit the
content diversity.
</dc:description>
 <dc:description>Comment: We have to withdraw the submission of our paper, because we found
  that we have not yet studied this work completely. Also, I didn't get the
  authorization of one of the authors</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06751</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HotFlip: White-Box Adversarial Examples for NLP</dc:title>
 <dc:creator>Ebrahimi, Javid</dc:creator>
 <dc:creator>Rao, Anyi</dc:creator>
 <dc:creator>Lowd, Daniel</dc:creator>
 <dc:creator>Dou, Dejing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Adversarial examples expose vulnerabilities of machine learning models. We
propose an efficient method to generate white-box adversarial examples that
trick character-level and word-level neural models. Our method, HotFlip, relies
on an atomic flip operation, which swaps one token for another, based on the
gradients of the one-hot input vectors. In experiments on text classification
and machine translation, we find that only a few manipulations are needed to
greatly increase the error rates. We analyze the properties of these examples,
and show that employing these adversarial examples in training can improve
test-time accuracy on clean examples, as well as defend the models against
adversarial examples.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06760</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neighbors Do Help: Deeply Exploiting Local Structures of Point Clouds</dc:title>
 <dc:creator>Shen, Yiru</dc:creator>
 <dc:creator>Feng, Chen</dc:creator>
 <dc:creator>Yang, Yaoqing</dc:creator>
 <dc:creator>Tian, Dong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unlike on images, semantic learning on 3D point clouds using a deep network
is challenging due to the naturally unordered data structure. Among existing
works, PointNet has achieved promising results by directly learning on point
sets. However, it does not take full advantage of a point's local neighborhood
that contains fine-grained structural information which turns out to be helpful
towards better semantic learning. In this regard, we present two new operations
to improve PointNet with more efficient exploitation of local structures. The
first one focuses on local 3D geometric structures. In analogy with a
convolution kernel for images, we define a point-set kernel as a set of
learnable points that jointly respond to a set of neighboring data points
according to their geometric affinity measured by kernel correlation, adapted
from a similar technique for point cloud registration. The second one exploits
local feature structures by recursive feature aggregation on a
nearest-neighbor-graph computed from 3D positions. Experiments show that our
network is able to robustly capture local information and efficiently achieve
better performance on major datasets.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06761</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MovieGraphs: Towards Understanding Human-Centric Situations from Videos</dc:title>
 <dc:creator>Vicol, Paul</dc:creator>
 <dc:creator>Tapaswi, Makarand</dc:creator>
 <dc:creator>Castrejon, Lluis</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  There is growing interest in artificial intelligence to build socially
intelligent robots. This requires machines to have the ability to &quot;read&quot;
people's emotions, motivations, and other factors that affect behavior. Towards
this goal, we introduce a novel dataset called MovieGraphs which provides
detailed, graph-based annotations of social situations depicted in movie clips.
Each graph consists of several types of nodes, to capture who is present in the
clip, their emotional and physical attributes, their relationships (i.e.,
parent/child), and the interactions between them. Most interactions are
associated with topics that provide additional details, and reasons that give
motivations for actions. In addition, most interactions and many attributes are
grounded in the video with time stamps. We provide a thorough analysis of our
dataset, showing interesting common-sense correlations between different social
aspects of scenes, as well as across scenes over time. We propose a method for
querying videos and text with graphs, and show that: 1) our graphs contain rich
and sufficient information to summarize and localize each scene; and 2)
subgraphs allow us to describe situations at an abstract level and retrieve
multiple semantically relevant situations. We also propose methods for
interaction understanding via ordering, and reason understanding. MovieGraphs
is the first benchmark to focus on inferred properties of human-centric
situations, and opens up an exciting avenue towards socially-intelligent AI
agents.
</dc:description>
 <dc:description>Comment: 23 pages, 22 figures, 10 tables. Webpage:
  http://moviegraphs.cs.toronto.edu</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06763</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A tight lower bound for an online hypercube packing problem and bounds
  for prices of anarchy of a related game</dc:title>
 <dc:creator>Kohayakawa, Y.</dc:creator>
 <dc:creator>Miyazawa, F. K.</dc:creator>
 <dc:creator>Wakabayashi, Y.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We prove a tight lower bound on the asymptotic performance ratio $\rho$ of
the bounded space online $d$-hypercube bin packing problem, solving an open
question raised in 2005. In the classic $d$-hypercube bin packing problem, we
are given a sequence of $d$-dimensional hypercubes and we have an unlimited
number of bins, each of which is a $d$-dimensional unit hypercube. The goal is
to pack (orthogonally) the given hypercubes into the minimum possible number of
bins, in such a way that no two hypercubes in the same bin overlap. The bounded
space online $d$-hypercube bin packing problem is a variant of the
$d$-hypercube bin packing problem, in which the hypercubes arrive online and
each one must be packed in an open bin without the knowledge of the next
hypercubes. Moreover, at each moment, only a constant number of open bins are
allowed (whenever a new bin is used, it is considered open, and it remains so
until it is considered closed, in which case, it is not allowed to accept new
hypercubes). Epstein and van Stee [SIAM J. Comput. 35 (2005), no. 2, 431-448]
showed that $\rho$ is $\Omega(\log d)$ and $O(d/\log d)$, and conjectured that
it is $\Theta(\log d)$. We show that $\rho$ is in fact $\Theta(d/\log d)$. To
obtain this result, we elaborate on some ideas presented by those authors, and
go one step further showing how to obtain better (offline) packings of certain
special instances for which one knows how many bins any bounded space algorithm
has to use. Our main contribution establishes the existence of such packings,
for large enough $d$, using probabilistic arguments. Such packings also lead to
lower bounds for the prices of anarchy of the selfish $d$-hypercube bin packing
game. We present a lower bound of $\Omega(d/\log d)$ for the pure price of
anarchy of this game, and we also give a lower bound of $\Omega(\log d)$ for
its strong price of anarchy.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06766</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Work-conserving Bandwidth Guarantees for Multi-tenant
  Datacenters via Dynamic Tenant-Queue Binding</dc:title>
 <dc:creator>Liu, Zhuotao</dc:creator>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:creator>Wu, Haitao</dc:creator>
 <dc:creator>Hu, Shuihai</dc:creator>
 <dc:creator>Hu, Yih-Chun</dc:creator>
 <dc:creator>Wang, Yi</dc:creator>
 <dc:creator>Zhang, Gong</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Today's cloud networks are shared among many tenants. Bandwidth guarantees
and work conservation are two key properties to ensure predictable performance
for tenant applications and high network utilization for providers. Despite
significant efforts, very little prior work can really achieve both properties
simultaneously even some of them claimed so.
  In this paper, we present QShare, an in-network based solution to achieve
bandwidth guarantees and work conservation simultaneously. QShare leverages
weighted fair queuing on commodity switches to slice network bandwidth for
tenants, and solves the challenge of queue scarcity through balanced tenant
placement and dynamic tenant-queue binding. QShare is readily implementable
with existing switching chips. We have implemented a QShare prototype and
evaluated it via both testbed experiments and simulations. Our results show
that QShare ensures bandwidth guarantees while driving network utilization to
over 91% even under unpredictable traffic demands.
</dc:description>
 <dc:description>Comment: The initial work is published in IEEE INFOCOM 2018</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06768</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User modeling for point-of-interest recommendations in location-based
  social networks: the state-of-the-art</dc:title>
 <dc:creator>Liu, Shudong</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The rapid growth of location-based services(LBSs)has greatly enriched
people's urban lives and attracted millions of users in recent years.
Location-based social networks(LBSNs)allow users to check-in at a physical
location and share daily tips on points-of-interest (POIs) with their friends
anytime and anywhere. Such check-in behavior can make daily real-life
experiences spread quickly through the Internet. Moreover, such check-in data
in LBSNs can be fully exploited to understand the basic laws of human daily
movement and mobility. This paper focuses on reviewing the taxonomy of user
modeling for POI recommendations through the data analysis of LBSNs. First, we
briefly introduce the structure and data characteristics of LBSNs,then we
present a formalization of user modeling for POI recommendations in LBSNs.
Depending on which type of LBSNs data was fully utilized in user modeling
approaches for POI recommendations, we divide user modeling algorithms into
four categories: pure check-in data-based user modeling, geographical
information-based user modeling, spatio-temporal information-based user
modeling, and geo-social information-based user modeling. Finally,summarizing
the existing works, we point out the future challenges and new directions in
five possible aspects
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06770</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A generalization of Sch\&quot;{o}nemann's theorem via a graph theoretic
  method</dc:title>
 <dc:creator>Bibak, Khodakhast</dc:creator>
 <dc:creator>Kapron, Bruce M.</dc:creator>
 <dc:creator>Srinivasan, Venkatesh</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  Recently, Grynkiewicz et al. [{\it Israel J. Math.} {\bf 193} (2013),
359--398], using tools from additive combinatorics and group theory, proved
necessary and sufficient conditions under which the linear congruence
$a_1x_1+\cdots +a_kx_k\equiv b \pmod{n}$, where $a_1,\ldots,a_k,b,n$ ($n\geq
1$) are arbitrary integers, has a solution $\langle x_1,\ldots,x_k \rangle \in
\Z_{n}^k$ with all $x_i$ distinct modulo $n$. So, it would be an interesting
problem to give an explicit formula for the number of such solutions. Quite
surprisingly, this problem was first considered, in a special case, by
Sch\&quot;{o}nemann almost two centuries ago(!) but his result seems to have been
forgotten. Sch\&quot;{o}nemann [{\it J. Reine Angew. Math.} {\bf 1839} (1839),
231--243] proved an explicit formula for the number of such solutions when
$b=0$, $n=p$ a prime, and $\sum_{i=1}^k a_i \equiv 0 \pmod{p}$ but $\sum_{i \in
I} a_i \not\equiv 0 \pmod{p}$ for all $I\varsubsetneq \lbrace 1, \ldots,
k\rbrace$. In this paper, we generalize Sch\&quot;{o}nemann's theorem using a result
on the number of solutions of linear congruences due to D. N. Lehmer and also a
result on graph enumeration recently obtained by Ardila et al. [{\it Int. Math.
Res. Not.} {\bf 2015} (2015), 3830--3877]. This seems to be a rather uncommon
method in the area; besides, our proof technique or its modifications may be
useful for dealing with other cases of this problem (or even the general case)
or other relevant problems.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06778</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Representations from Road Network for End-to-End Urban Growth
  Simulation</dc:title>
 <dc:creator>Pal, Saptarshi</dc:creator>
 <dc:creator>Ghosh, Soumya K</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  From our experiences in the past, we have seen that the growth of cities is
very much dependent on the transportation networks. In mega cities,
transportation networks determine to a significant extent as to where the
people will move and houses will be built. Hence, transportation network data
is crucial to an urban growth prediction system. Existing works have used
manually derived distance based features based on the road networks to build
models on urban growth. But due to the non-generic and laborious nature of the
manual feature engineering process, we can shift to End-to-End systems which do
not rely on manual feature engineering. In this paper, we propose a method to
integrate road network data to an existing Rule based End-to-End framework
without manual feature engineering. Our method employs recurrent neural
networks to represent road networks in a structured way such that it can be
plugged into the previously proposed End-to-End framework. The proposed
approach enhances the performance in terms of Figure of Merit, Producer's
accuracy, User's accuracy and Overall accuracy of the existing Rule based
End-to-End framework.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06780</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking objects using 3D object proposals</dc:title>
 <dc:creator>Pahwa, Ramanpreet Singh</dc:creator>
 <dc:creator>Ng, Tian Tsong</dc:creator>
 <dc:creator>Do, Minh N.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3D object proposals, quickly detected regions in a 3D scene that likely
contain an object of interest, are an effective approach to improve the
computational efficiency and accuracy of the object detection framework. In
this work, we propose a novel online method that uses our previously developed
3D object proposals, in a RGB-D video sequence, to match and track static
objects in the scene using shape matching. Our main observation is that depth
images provide important information about the geometry of the scene that is
often ignored in object matching techniques. Our method takes less than a
second in MATLAB on the UW-RGBD scene dataset on a single thread CPU and thus,
has potential to be used in low-power chips in Unmanned Aerial Vehicles (UAVs),
quadcopters, and drones.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, published in APSIPA 2017</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06782</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient implementations of the Multivariate Decomposition Method for
  approximating infinite-variate integrals</dc:title>
 <dc:creator>Gilbert, Alexander D.</dc:creator>
 <dc:creator>Kuo, Frances Y.</dc:creator>
 <dc:creator>Nuyens, Dirk</dc:creator>
 <dc:creator>Wasilkowski, Grzegorz W.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  In this paper we focus on efficient implementations of the Multivariate
Decomposition Method (MDM) for approximating integrals of $\infty$-variate
functions. Such $\infty$-variate integrals occur for example as expectations in
uncertainty quantification. Starting with the anchored decomposition $f =
\sum_{\mathfrak{u}\subset\mathbb{N}} f_\mathfrak{u}$, where the sum is over all
finite subsets of $\mathbb{N}$ and each $f_\mathfrak{u}$ depends only on the
variables $x_j$ with $j\in\mathfrak{u}$, our MDM algorithm approximates the
integral of $f$ by first truncating the sum to some `active set' and then
approximating the integral of the remaining functions $f_\mathfrak{u}$
term-by-term using Smolyak or (randomized) quasi-Monte Carlo (QMC) quadratures.
The anchored decomposition allows us to compute $f_\mathfrak{u}$ explicitly by
function evaluations of $f$. Given the specification of the active set and
theoretically derived parameters of the quadrature rules, we exploit structures
in both the formula for computing $f_\mathfrak{u}$ and the quadrature rules to
develop computationally efficient strategies to implement the MDM in various
scenarios. In particular, we avoid repeated function evaluations at the same
point. We provide numerical results for a test function to demonstrate the
effectiveness of the algorithm.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06787</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Predictive BESS Control for Demand Charge Management and
  PV-Utilization Improvement</dc:title>
 <dc:creator>Raoufat, M. E.</dc:creator>
 <dc:creator>Asghari, B.</dc:creator>
 <dc:creator>Sharma, R.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Adoption of battery energy storage systems for behind-the-meters application
offers valuable benefits for demand charge management as well as increasing
PV-utilization. The key point is that while the benefit/cost ratio for a single
application may not be favorable for economic benefits of storage systems,
stacked services can provide multiple revenue streams for the same investment.
Under this framework, we propose a model predictive controller to reduce demand
charge cost and enhance PV-utilization level simultaneously. Different load
patterns have been considered in this study and results are compared to the
conventional rule-based controller. The results verified that the proposed
controller provides satisfactory performance by improving the PV-utilization
rate between 60% to 80% without significant changes in demand charge (DC)
saving. Furthermore, our results suggest that batteries can be used for
stacking multiple services to improve their benefits. Quantitative analysis for
PV-utilization as a function of battery size and prediction time window has
also been carried out.
</dc:description>
 <dc:description>Comment: Accepted in: Conference on Innovative Smart Grid Technology (ISGT),
  Washington, DC, 2018</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06790</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Docker-Enabled Build and Execution Environment (BEE): an Encapsulated
  Environment Enabling HPC Applications Running Everywhere</dc:title>
 <dc:creator>Chen, Jieyang</dc:creator>
 <dc:creator>Guan, Qiang</dc:creator>
 <dc:creator>Liang, Xin</dc:creator>
 <dc:creator>Vernon, Louis James</dc:creator>
 <dc:creator>McPherson, Allen</dc:creator>
 <dc:creator>Lo, Li-Ta</dc:creator>
 <dc:creator>Chen, Zizhong</dc:creator>
 <dc:creator>Ahrens, James Paul</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Variations in High Performance Computing (HPC) system software configurations
mean that applications are typically configured and built for specific HPC
environments. Building applications can require a significant investment of
time and effort for application users and requires application users to have
additional technical knowledge. Container technologies like Docker bring great
benefits to the application development, build and deployment processes. While
much cloud computing infrastructure is already designed to support Docker,
little work has been done to support production Docker deployment on HPC
systems. In this work, we propose a Docker-enabled Build and Execution
Environment (BEE) for HPC systems and detail a standard backend for BEE using
virtual machines, the BEE-VM. This brings many of the benefits of Docker to
existing HPC machines in user-space without the requirement of specialized
pre-installed software and with no system administrator configuration. We show
that current HPC application can be easily configured to run within BEE,
eliminating the need to reconfigure and rebuild applications for different
systems while preserving comparable performance.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06793</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-dimensional Anti-jamming Mobile Communication Based on Reinforcement
  Learning</dc:title>
 <dc:creator>Xiao, Liang</dc:creator>
 <dc:creator>Han, Guoan</dc:creator>
 <dc:creator>Jiang, Donghua</dc:creator>
 <dc:creator>Zhu, Hongzi</dc:creator>
 <dc:creator>Zhang, Yanyong</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  By using smart radio devices, a jammer can dynamically change its jamming
policy based on opposing security mechanisms; it can even induce the mobile
device to enter a specific communication mode and then launch the jamming
policy accordingly. On the other hand, mobile devices can exploit spread
spectrum and user mobility to address both jamming and interference. In this
paper, a two-dimensional anti-jamming mobile communication scheme is proposed
in which a mobile device leaves a heavily jammed/interfered-with frequency or
area. It is shown that, by applying reinforcement learning techniques, a mobile
device can achieve an optimal communication policy without the need to know the
jamming and interference model and the radio channel model in a dynamic game
framework. More specifically, a hotbooting deep Q-network based two-dimensional
mobile communication scheme is proposed that exploits experiences in similar
scenarios to reduce the exploration time at the beginning of the game, and
applies deep convolutional neural network and macro-action techniques to
accelerate the learning speed in dynamic situations. Several real-world
scenarios are simulated to evaluate the proposed method. These simulation
results show that our proposed scheme can improve both the
signal-to-interference-plus-noise ratio of the signals and the utility of the
mobile devices against cooperative jamming compared with benchmark schemes.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06794</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Downlink macro-diversity precoding-aided spatial modulation</dc:title>
 <dc:creator>Mohaisen, Manar</dc:creator>
 <dc:creator>Pruks, Vitalii</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a downlink macro-diversity precodingaided spatial modulation
(MD-PSM) scheme is proposed, in which two base stations (BSs) communicate
simultaneously with a single mobile station (MS). As such, the proposed scheme
achieved twice the spectral efficiency of the conventional PSM scheme. To
render the demodulation possible, the two signal constellation sets used at the
two BSs should be disjoint. Also, since the two BSs use the same spatial
dimension, i.e., indices of receive antennas, the Minkowski sum of the two
constellation sets should include unrepeated symbols. This is achieved through
rotating the constellation set used by the second BS, where the error rate is
also minimized. After obtaining the optimal rotation angles for several
scenarios, a reduced complexity maximum-likelihood receiver is introduced. For
an equal number of transmit and receive antennas of 4 and at a target BER of
10^{-4}, the simulation results show that the proposed MD-PSM scheme
outperforms the conventional PSM by about 17.3 dB and 12.4 dB, while achieving
the same and double the spectral efficiency, respectively. Also, due to the
distributed nature of MDPSM, it is shown that the diversity order of the novel
MD-PSM scheme is twice that of the conventional PSM.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures, 3 tables (Journal of Communications and
  Networks), accepted on 2017, September 12</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06796</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Built to Last or Built Too Fast? Evaluating Prediction Models for Build
  Times</dc:title>
 <dc:creator>Bisong, Ekaba</dc:creator>
 <dc:creator>Tran, Eric</dc:creator>
 <dc:creator>Baysal, Olga</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Automated builds are integral to the Continuous Integration (CI) software
development practice. In CI, developers are encouraged to integrate early and
often. However, long build times can be an issue when integrations are
frequent. This research focuses on finding a balance between integrating often
and keeping developers productive. We propose and analyze models that can
predict the build time of a job. Such models can help developers to better
manage their time and tasks. Also, project managers can explore different
factors to determine the best setup for a build job that will keep the build
wait time to an acceptable level. Software organizations transitioning to CI
practices can use the predictive models to anticipate build times before CI is
implemented. The research community can modify our predictive models to further
understand the factors and relationships affecting build times.
</dc:description>
 <dc:description>Comment: 4 paged version published in the Proceedings of the IEEE/ACM 14th
  International Conference on Mining Software Repositories (MSR) Pages 487-490.
  MSR 2017</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06796</dc:identifier>
 <dc:identifier>doi:10.1109/MSR.2017.36</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06802</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of Individual Micro Data from Aggregated Open Data</dc:title>
 <dc:creator>Yoo, Han-mook</dc:creator>
 <dc:creator>Kim, Han-joon</dc:creator>
 <dc:creator>Chun, Jonghoon</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In this paper, we propose a method of estimating individual micro data from
aggregated open data based on semi-supervised learning and conditional
probability. Firstly, the proposed method collects aggregated open data and
support data, which are related to the individual micro data to be estimated.
Then, we perform the locality sensitive hashing (LSH) algorithm to find a
subset of the support data that is similar to the aggregated open data and then
classify them by using the Ensemble classification model, which is learned by
semi-supervised learning. Finally, we use conditional probability to estimate
the individual micro data by finding the most suitable record for the
probability distribution of the individual micro data among the classification
results. To evaluate the performance of the proposed method, we estimated the
individual building data where the fire occurred using the aggregated fire open
data. According to the experimental results, the micro data estimation
performance of the proposed method is 59.41% on average in terms of accuracy.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06804</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Coupling and Its Applications in Information Theory</dc:title>
 <dc:creator>Yu, Lei</dc:creator>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  A coupling of two distributions $P_{X}$ and $P_{Y}$ is a joint distribution
$P_{XY}$ with marginal distributions equal to $P_{X}$ and $P_{Y}$. Given
marginals $P_{X}$ and $P_{Y}$ and a real-valued function $f(P_{XY})$ of the
joint distribution $P_{XY}$, what is its minimum over all couplings $P_{XY}$ of
$P_{X}$ and $P_{Y}$? We study the asymptotics of such coupling problems with
different $f$'s. These include the maximal coupling, minimum distance coupling,
maximal guessing coupling, and minimum entropy coupling problems. We
characterize the limiting values of these coupling problems as the number of
copies of $X$ and $Y$ tends to infinity. We show that they typically converge
at least exponentially fast to their limits. Moreover, for the problems of
maximal coupling and minimum excess-distance probability coupling, we also
characterize (or bound) the optimal convergence rates (exponents). Furthermore,
for the maximal guessing coupling problem we show that it is equivalent to the
probability distribution approximation problem. Therefore, some existing
results the latter problem can be used to derive the asymptotics of the maximal
guessing coupling problem. We also study the asymptotics of the maximal
guessing coupling problem for two \emph{general} sources and a generalization
of this problem, named the \emph{maximal guessing coupling through a channel
problem}. We apply the preceding results to several new information-theoretic
problems, including exact intrinsic randomness, exact resolvability, channel
capacity with input distribution constraint, and perfect stealth and secrecy
communication.
</dc:description>
 <dc:description>Comment: 27 pages, 2 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06820</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Cross Network for Person Re-identification</dc:title>
 <dc:creator>Hsu, Huan-Cheng</dc:creator>
 <dc:creator>Chen, Ching-Hang</dc:creator>
 <dc:creator>Tyan, Hsiao-Rong</dc:creator>
 <dc:creator>Liao, Hong-Yuan Mark</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person re-identification (person re-ID) aims at matching target person(s)
grabbed from different and non-overlapping camera views. It plays an important
role for public safety and has application in various tasks such as, human
retrieval, human tracking, and activity analysis. In this paper, we propose a
new network architecture called Hierarchical Cross Network (HCN) to perform
person re-ID. In addition to the backbone model of a conventional CNN, HCN is
equipped with two additional maps called hierarchical cross feature maps. The
maps of an HCN are formed by merging layers with different resolutions and
semantic levels. With the hierarchical cross feature maps, an HCN can
effectively uncover additional semantic features which could not be discovered
by a conventional CNN. Although the proposed HCN can discover features with
higher semantics, its representation power is still limited. To derive more
general representations, we augment the data during the training process by
combining multiple datasets. Experiment results show that the proposed method
outperformed several state-of-the-art methods.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06830</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single Image Deraining using Scale-Aware Multi-Stage Recurrent Network</dc:title>
 <dc:creator>Li, Ruoteng</dc:creator>
 <dc:creator>Cheong, Loong-Fah</dc:creator>
 <dc:creator>Tan, Robby T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given a single input rainy image, our goal is to visually remove rain streaks
and the veiling effect caused by scattering and transmission of rain streaks
and rain droplets. We are particularly concerned with heavy rain, where rain
streaks of various sizes and directions can overlap each other and the veiling
effect reduces contrast severely. To achieve our goal, we introduce a
scale-aware multi-stage convolutional neural network. Our main idea here is
that different sizes of rain-streaks visually degrade the scene in different
ways. Large nearby streaks obstruct larger regions and are likely to reflect
specular highlights more prominently than smaller distant streaks. These
different effects of different streaks have their own characteristics in their
image features, and thus need to be treated differently. To realize this, we
create parallel sub-networks that are trained and made aware of these different
scales of rain streaks. To our knowledge, this idea of parallel sub-networks
that treats the same class of objects according to their unique sub-classes is
novel, particularly in the context of rain removal. To verify our idea, we
conducted experiments on both synthetic and real images, and found that our
method is effective and outperforms the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 9 pages, CVPR 2018</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06833</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Feasibility Metric for Trajectory Optimization of Legged Robots using
  Wrench Polytopes</dc:title>
 <dc:creator>Orsolino, Romeo</dc:creator>
 <dc:creator>Focchi, Michele</dc:creator>
 <dc:creator>Mastalli, Carlos</dc:creator>
 <dc:creator>Dai, Hongkai</dc:creator>
 <dc:creator>Caldwell, Darwin G.</dc:creator>
 <dc:creator>Semini, Claudio</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Motion planning in multi-contact scenarios has recently gathered interest
within the legged robotics community, however actuator force/torque limits are
rarely considered. We believe that these limits gain paramount importance when
the complexity of the terrains to be traversed increases. For this reason we
propose two new six-dimensional bounded polytopes named the Actuation Wrench
Polytope (AWP) and the Feasible Wrench Polytope (FWP). We define the AWP as the
set of all the wrenches that a robot can generate on its own Center of Mass
(CoM) while considering its actuation limits. This considers the admissible
contact forces that the robot can generate given its current configuration and
actuation capabilities but does not include features of the environment such as
the contact normal or the friction coefficient. These are considered by the
Contact Wrench Cone (CWC); the AWP can therefore be seen as complementary with
respect to the CWC. The intersection of the AWP and of the CWC results in a
polytope, the FWP, which turns out to be more descriptive of the real robot
capabilities, while maintaining the same compact representation. We explain how
to efficiently compute the vertex-description of the FWP and we also introduce
a new locomotion stability metric based on the FWP, that we call feasibility
margin, which allows us to optimize for robustness to external disturbance
wrenches. Based on this, we present an implementation of a motion planner for
our quadruped robot HyQ that provides online CoM trajectories that are
guaranteed to be stable and actuation-consistent.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06837</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Stereo: Constrained, Non-rigid, Wide-baseline Stereo Vision for
  Fixed-wing Aerial Platforms</dc:title>
 <dc:creator>Hinzmann, Timo</dc:creator>
 <dc:creator>Taubner, Tim</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a computationally efficient method to estimate the
time-varying relative pose between two visual-inertial sensor rigs mounted on
the flexible wings of a fixed-wing unmanned aerial vehicle (UAV). The estimated
relative poses are used to generate highly accurate depth maps in real-time and
can be employed for obstacle avoidance in low-altitude flights or landing
maneuvers. The approach is structured as follows: Initially, a wing model is
identified by fitting a probability density function to measured deviations
from the nominal relative baseline transformation. At run-time, the prior
knowledge about the wing model is fused in an Extended Kalman filter~(EKF)
together with relative pose measurements obtained from solving a relative
perspective N-point problem (PNP), and the linear accelerations and angular
velocities measured by the two inertial measurement units (IMU) which are
rigidly attached to the cameras. Results obtained from extensive synthetic
experiments demonstrate that our proposed framework is able to estimate highly
accurate baseline transformations and depth maps.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures, 2 tables</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06840</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Fan-Crossing Graphs</dc:title>
 <dc:creator>Brandenburg, Franz J.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A fan is a set of edges with a single common endpoint. A graph is
fan-crossing if it admits a drawing in the plane so that each edge is crossed
by edges of a fan. It is fan-planar if, in addition, the common endpoint is on
the same side of the crossed edge. A graph is adjacency-crossing if it admits a
drawing so that crossing edges are adjacent. Then it excludes independent
crossings which are crossings by edges with no common endpoint.
Adjacency-crossing allows triangle-crossings in which an edge crosses the edges
of a triangle, which is excluded at fan-crossing graphs.
  We show that every adjacency-crossing graph is fan-crossing. Thus
triangle-crossings can be avoided. On the other hand, there are fan-crossing
graphs that are not fan-planar, whereas for every fan-crossing graph there is a
fan-planar graph on the same set of vertices and with the same number of edges.
Hence, fan-crossing and fan-planar graphs are different, but they do not differ
in their density with at most 5n - 10 edges for graphs of size n.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06842</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dimension of nonbinary antiprimitive BCH codes</dc:title>
 <dc:creator>Li, Ruihu</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Guo, Luobin</dc:creator>
 <dc:creator>Song, Hao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>11T71</dc:subject>
 <dc:description>  Bose-Chaudhuri-Hocquenghem (BCH) codes have been widely employed in satellite
communications, compact disc players, DVDs, disk drives, solid-state drives,
two-dimensional bar codes and in cryptography more recently. However, there is
only a little known about primitive BCH codes, let alone nonprimitive ones. In
this paper, dimension of a special class of nonprimitive BCH codes of length
$n=q^{m}+1$ ( which are also called antiprimitive BCH codes) are studied. Some
new approaches, such as iterative algorithm, partition and scaling, are adopted
to determine the first several largest coset leaders modulo $n=q^{2t+1}+1$
along with coset leaders of $C_{x}$ modulo $n=q^{m}+1$ for $q^{\lceil
\frac{m}{2}\rceil}&lt;x&lt;2(q^{\lceil \frac{m}{2} \rceil}+q)$. After deriving the
cardinalities of these cyclotomic cosets, we shall calculate precisely
dimension of some antiprimitive BCH codes.
</dc:description>
 <dc:description>Comment: 17pages</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06843</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Exploratory Survey of Hybrid Testing Techniques Involving Symbolic
  Execution and Fuzzing</dc:title>
 <dc:creator>Ognawala, Saahil</dc:creator>
 <dc:creator>Petrovska, Ana</dc:creator>
 <dc:creator>Beckers, Kristian</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Recent efforts in practical symbolic execution have successfully mitigated
the path-explosion problem to some extent with search-based heuristics and
compositional approaches. Similarly, due to an increase in the performance of
cheap multi-core commodity computers, fuzzing as a viable method of random
mutation-based testing has also seen promise. However, the possibility of
combining symbolic execution and fuzzing, thereby providing an opportunity to
mitigate drawbacks in each other, has not been sufficiently explored. Fuzzing
could, for example, expedite path-exploration in symbolic execution, and
symbolic execution could make seed input generation in fuzzing more efficient.
There have only been, in our view, very few hybrid solution proposals with
symbolic execution and fuzzing at their centre. By analyzing 77 relevant and
systematically selected papers, we (1) present an overview of hybrid solution
proposals of symbolic execution and fuzzing, (2) perform a gap analysis in
research of hybrid techniques to improve both, plain symbolic execution and
fuzzing, (3) propose new ideas for hybrid test-case generation techniques.
</dc:description>
 <dc:description>Comment: Author's preprint</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06848</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MUDA: A Truthful Multi-Unit Double-Auction Mechanism</dc:title>
 <dc:creator>Segal-Halevi, Erel</dc:creator>
 <dc:creator>Hassidim, Avinatan</dc:creator>
 <dc:creator>Aumann, Yonatan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In a seminal paper, McAfee (1992) presented a truthful mechanism for double
auctions, attaining asymptotically-optimal gain-from-trade without any prior
information on the valuations of the traders. McAfee's mechanism handles
single-parametric agents, allowing each seller to sell a single unit and each
buyer to buy a single unit. This paper presents a double-auction mechanism that
handles multi-parametric agents and allows multiple units per trader, as long
as the valuation functions of all traders have decreasing marginal returns. The
mechanism is prior-free, ex-post individually-rational, dominant-strategy
truthful and strongly-budget-balanced. Its gain-from-trade approaches the
optimum when the market size is sufficiently large.
</dc:description>
 <dc:description>Comment: Accepted to the AAAI2018 conference</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06850</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A comparison of web privacy protection techniques</dc:title>
 <dc:creator>Mazel, Johan</dc:creator>
 <dc:creator>Garnier, Richard</dc:creator>
 <dc:creator>Fukuda, Kensuke</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  A comparison of web privacy protection techniques
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06855</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subword and Crossword Units for CTC Acoustic Models</dc:title>
 <dc:creator>Zenkel, Thomas</dc:creator>
 <dc:creator>Sanabria, Ramon</dc:creator>
 <dc:creator>Metze, Florian</dc:creator>
 <dc:creator>Waibel, Alex</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper proposes a novel approach to create an unit set for CTC based
speech recognition systems. By using Byte Pair Encoding we learn an unit set of
an arbitrary size on a given training text. In contrast to using characters or
words as units this allows us to find a good trade-off between the size of our
unit set and the available training data. We evaluate both Crossword units,
that may span multiple word, and Subword units. By combining this approach with
decoding methods using a separate language model we are able to achieve state
of the art results for grapheme based CTC systems.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06861</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end weakly-supervised semantic alignment</dc:title>
 <dc:creator>Rocco, Ignacio</dc:creator>
 <dc:creator>Arandjelovi&#x107;, Relja</dc:creator>
 <dc:creator>Sivic, Josef</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We tackle the task of semantic alignment where the goal is to compute dense
semantic correspondence aligning two images depicting objects of the same
category. This is a challenging task due to large intra-class variation,
changes in viewpoint and background clutter. We present the following three
principal contributions. First, we develop a convolutional neural network
architecture for semantic alignment that is trainable in an end-to-end manner
from weak image-level supervision in the form of matching image pairs. The
outcome is that parameters are learnt from rich appearance variation present in
different but semantically related images without the need for tedious manual
annotation of correspondences at training time. Second, the main component of
this architecture is a differentiable soft inlier scoring module, inspired by
the RANSAC inlier scoring procedure, that computes the quality of the alignment
based on only geometrically consistent correspondences thereby reducing the
effect of background clutter. Third, we demonstrate that the proposed approach
achieves state-of-the-art performance on multiple standard benchmarks for
semantic alignment.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06863</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pattern recognition techniques for Boson Sampling validation</dc:title>
 <dc:creator>Agresti, Iris</dc:creator>
 <dc:creator>Viggianiello, Niko</dc:creator>
 <dc:creator>Flamini, Fulvio</dc:creator>
 <dc:creator>Spagnolo, Nicol&#xf2;</dc:creator>
 <dc:creator>Crespi, Andrea</dc:creator>
 <dc:creator>Osellame, Roberto</dc:creator>
 <dc:creator>Wiebe, Nathan</dc:creator>
 <dc:creator>Sciarrino, Fabio</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The difficulty of validating large-scale quantum devices, such as Boson
Samplers, poses a major challenge for any research program that aims to show
quantum advantages over classical hardware. To address this problem, we propose
a novel data-driven approach wherein models are trained to identify common
pathologies using unsupervised machine learning methods. We illustrate this
idea by training a classifier that exploits K-means clustering to distinguish
between Boson Samplers that use indistinguishable photons from those that do
not. We train the model on numerical simulations of small-scale Boson Samplers
and then validate the pattern recognition technique on larger numerical
simulations as well as on photonic chips in both traditional Boson Sampling and
scattershot experiments. The effectiveness of such method relies on
particle-type-dependent internal correlations present in the output
distributions. This approach performs substantially better on the test data
than previous methods and underscores the ability to further generalize its
operation beyond the scope of the examples that it was trained on.
</dc:description>
 <dc:description>Comment: 11+5 pages, 5+4 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06865</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Correlation Clustering Using Same-Cluster Queries</dc:title>
 <dc:creator>Ailon, Nir</dc:creator>
 <dc:creator>Bhattacharya, Anup</dc:creator>
 <dc:creator>Jaiswal, Ragesh</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Ashtiani et al. (NIPS 2016) introduced a semi-supervised framework for
clustering (SSAC) where a learner is allowed to make same-cluster queries. More
specifically, in their model, there is a query oracle that answers queries of
the form given any two vertices, do they belong to the same optimal cluster?.
Ashtiani et al. showed the usefulness of such a query framework by giving a
polynomial time algorithm for the k-means clustering problem where the input
dataset satisfies some separation condition. Ailon et al. extended the above
work to the approximation setting by giving an efficient (1+\eps)-approximation
algorithm for k-means for any small \eps &gt; 0 and any dataset within the SSAC
framework. In this work, we extend this line of study to the correlation
clustering problem. Correlation clustering is a graph clustering problem where
pairwise similarity (or dissimilarity) information is given for every pair of
vertices and the objective is to partition the vertices into clusters that
minimise the disagreement (or maximises agreement) with the pairwise
information given as input. These problems are popularly known as MinDisAgree
and MaxAgree problems, and MinDisAgree[k] and MaxAgree[k] are versions of these
problems where the number of optimal clusters is at most k. There exist
Polynomial Time Approximation Schemes (PTAS) for MinDisAgree[k] and MaxAgree[k]
where the approximation guarantee is (1+\eps) for any small \eps and the
running time is polynomial in the input parameters but exponential in k and
1/\eps. We obtain an (1+\eps)-approximation algorithm for any small \eps with
running time that is polynomial in the input parameters and also in k and
1/\eps. We also give non-trivial upper and lower bounds on the number of
same-cluster queries, the lower bound being based on the Exponential Time
Hypothesis (ETH).
</dc:description>
 <dc:description>Comment: To appear in LATIN 2018</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06866</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Error Probability of Sparse Superposition Codes with Approximate
  Message Passing Decoding</dc:title>
 <dc:creator>Rush, Cynthia</dc:creator>
 <dc:creator>Venkataramanan, Ramji</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Sparse superposition codes, or sparse regression codes (SPARCs), are a recent
class of codes for reliable communication over the AWGN channel at rates
approaching the channel capacity. Approximate message passing (AMP) decoding, a
computationally efficient technique for decoding SPARCs, has been proven to be
asymptotically capacity-achieving for the AWGN channel. In this paper, we
refine the asymptotic result by deriving a large deviations bound on the
probability of AMP decoding error. This bound gives insight into the error
performance of the AMP decoder for large but finite problem sizes, giving an
error exponent as well as guidance on how the code parameters should be chosen
at finite block lengths. For an appropriate choice of code parameters, it is
shown that for any fixed rate less than the channel capacity, the decoding
error probability decays exponentially in $n/(\log n)^{2T}$, where $T$, the
number of AMP iterations required for successful decoding, is bounded in terms
of the gap from capacity.
</dc:description>
 <dc:description>Comment: 44 pages. A shorter version appeared in ISIT 2017</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06868</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heinrich Behmann's Contributions to Second-Order Quantifier Elimination
  from the View of Computational Logic</dc:title>
 <dc:creator>Wernhard, Christoph</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  For relational monadic formulas (the L\&quot;owenheim class) second-order
quantifier elimination, which is closely related to computation of uniform
interpolants, projection and forgetting - operations that currently receive
much attention in knowledge processing - always succeeds. The decidability
proof for this class by Heinrich Behmann from 1922 explicitly proceeds by
elimination with equivalence preserving formula rewriting. Here we reconstruct
the results from Behmann's publication in detail and discuss related issues
that are relevant in the context of modern approaches to second-order
quantifier elimination in computational logic. In addition, an extensive
documentation of the letters and manuscripts in Behmann's bequest that concern
second-order quantifier elimination is given, including a commented register
and English abstracts of the German sources with focus on technical material.
In the late 1920s Behmann attempted to develop an elimination-based decision
method for formulas with predicates whose arity is larger than one. His
manuscripts and the correspondence with Wilhelm Ackermann show technical
aspects that are still of interest today and give insight into the genesis of
Ackermann's landmark paper &quot;Untersuchungen \&quot;uber das Eliminationsproblem der
mathematischen Logik&quot; from 1935, which laid the foundation of the two
prevailing modern approaches to second-order quantifier elimination.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06875</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effects of update rules on networked N-player trust game dynamics</dc:title>
 <dc:creator>Chica, Manuel</dc:creator>
 <dc:creator>Chiong, Raymond</dc:creator>
 <dc:creator>Ramasco, Jose</dc:creator>
 <dc:creator>Abbass, Hussein</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We investigate the effects of update rules on the dynamics of an evolutionary
game-theoretic model - the N-player evolutionary trust game - consisting of
three types of players: investors, trustworthy trustees, and untrustworthy
trustees. Interactions between players are limited to local neighborhoods
determined by predefined spatial or social network topologies. We compare
evolutionary update rules based on the payoffs obtained by their neighbors.
Specifically, we investigate the dynamics generated when players use a
deterministic strategic rule (i.e., unconditional imitation with and without
using a noise process induced by a voter model), a stochastic pairwise
payoff-based strategy (i.e., proportional imitation), and stochastic local
Moran processes. We explore the system dynamics under these update rules based
on different social networks and different levels of game difficulty. We
observe that there are significant differences on the promoted trust and global
net wealth depending on the update rule. If the game is harder, rules based on
unconditional imitation achieve the highest global net wealth in the
population. Besides a global perspective, we also study the spatial and
temporal dynamics induced by the rules and we find important spatio-temporal
correlations in the system for all rules. Indeed, the update rules lead to the
formation of fractal structures on a lattice and, when the rules are
stochastic, also the emergence of low frequencies in the output signal of the
system (i.e., long-term memory).
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06878</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analysis of Packet Fragmentation Impact in LPWAN</dc:title>
 <dc:creator>Suciu, Ioana</dc:creator>
 <dc:creator>Vilajosana, Xavier</dc:creator>
 <dc:creator>Adelantado, Ferran</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Packet fragmentation has mostly been addressed in the literature when
referring to splitting data that does not fit a frame. It has received
attention in the IoT community after the 6LoWPAN working group of IETF started
studying the fragmentation headers to allow IPv6 1280 B MTU to be sent over
IEEE 802.15.4 networks supporting a 127 B MTU. In this paper, and following
some of the recent directions taken by the IETF LPWAN WG, an analysis of packet
fragmentation in LPWANs has been done. We aim to identify the impact of sending
the data in smaller fragments considering the restrictions of industrial
duty-cycled networks. The analyzed parameters were the energy consumption,
throughput, goodput and end to end delay introduced by fragmentation. The
results of our analysis show that packet fragmentation can increase the
reliability of the communication in duty-cycle restricted networks. This is of
especial relevance when densifying the network. We observed relevant impact in
energy consumption and extra latency, and identified the need for
acknowledgements from the gateway/sink to exploit some of the benefits raised
by fragmentation.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06880</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analogy Mining for Specific Design Needs</dc:title>
 <dc:creator>Gilon, Karni</dc:creator>
 <dc:creator>Ng, Felicia Y</dc:creator>
 <dc:creator>Chan, Joel</dc:creator>
 <dc:creator>Assaf, Hila Lifshitz</dc:creator>
 <dc:creator>Kittur, Aniket</dc:creator>
 <dc:creator>Shahaf, Dafna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Finding analogical inspirations in distant domains is a powerful way of
solving problems. However, as the number of inspirations that could be matched
and the dimensions on which that matching could occur grow, it becomes
challenging for designers to find inspirations relevant to their needs.
Furthermore, designers are often interested in exploring specific aspects of a
product-- for example, one designer might be interested in improving the
brewing capability of an outdoor coffee maker, while another might wish to
optimize for portability. In this paper we introduce a novel system for
targeting analogical search for specific needs. Specifically, we contribute a
novel analogical search engine for expressing and abstracting specific design
needs that returns more distant yet relevant inspirations than alternate
approaches.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06882</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of fingerprint authentication algorithms for small imaging
  sensors</dc:title>
 <dc:creator>Bourjot, Mathilde</dc:creator>
 <dc:creator>Perrier, Regis</dc:creator>
 <dc:creator>Mainguet, Jean Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The demand for biometric systems has been increasing with the growth of the
smartphone market. Biometric devices allow the user to authenticate easily
while securing its private data without the need to remember any access code.
Amongst them, fingerprint sensors are the most widespread because they seem to
provide a good balance between reliability, cost and ease of use. According to
smartphone manufacturers, the security level is guaranteed to be high. However,
the size of those sensors, which is only a few millimeters squared, prevents
the use of minutiae algorithms. To the best of our knowledge, very few studies
shed light onto this problem, though many pattern recognition algorithms
already exist as well as commercial solutions which are supposedly robust. In
this article we try to provide insights on how to tackle this problem by
analyzing the performance of three algorithms dedicated to pattern recognition.
</dc:description>
 <dc:description>Comment: On going work which will be improved with more experimental results</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06890</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uplink Sounding Reference Signal Coordination to Combat Pilot
  Contamination in 5G Massive MIMO</dc:title>
 <dc:creator>Giordano, Lorenzo Galati</dc:creator>
 <dc:creator>Campanalonga, Luca</dc:creator>
 <dc:creator>Lopez-Perez, David</dc:creator>
 <dc:creator>Garcia-Rodriguez, Adrian</dc:creator>
 <dc:creator>Geraci, Giovanni</dc:creator>
 <dc:creator>Baracca, Paolo</dc:creator>
 <dc:creator>Magarini, Maurizio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To guarantee the success of massive multiple-input multiple-output (MIMO),
one of the main challenges to solve is the efficient management of pilot
contamination. Allocation of fully orthogonal pilot sequences across the
network would provide a solution to the problem, but the associated overhead
would make this approach infeasible in practical systems. Ongoing
fifth-generation (5G) standardisation activities are debating the amount of
resources to be dedicated to the transmission of pilot sequences, focussing on
uplink sounding reference signals (UL SRSs) design. In this paper, we
extensively evaluate the performance of various UL SRS allocation strategies in
practical deployments, shedding light on their strengths and weaknesses.
Furthermore, we introduce a novel UL SRS fractional reuse (FR) scheme, denoted
neighbour-aware FR (FR-NA). The proposed FR-NA generalizes the fixed reuse
paradigm, and entails a tradeoff between i) aggressively sharing some UL SRS
resources, and ii) protecting other UL SRS resources with the aim of relieving
neighbouring BSs from pilot contamination. Said features result in a cell
throughput improvement over both fixed reuse and state-of-the-art FR based on a
cell-centric perspective.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06897</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Fixation Point Strategy for Object Detection and Classification</dc:title>
 <dc:creator>Lyu, Jie</dc:creator>
 <dc:creator>Yuan, Zejian</dc:creator>
 <dc:creator>Chen, Dapeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel recurrent attentional structure to localize and recognize
objects jointly. The network can learn to extract a sequence of local
observations with detailed appearance and rough context, instead of sliding
windows or convolutions on the entire image. Meanwhile, those observations are
fused to complete detection and classification tasks. On training, we present a
hybrid loss function to learn the parameters of the multi-task network
end-to-end. Particularly, the combination of stochastic and object-awareness
strategy, named SA, can select more abundant context and ensure the last
fixation close to the object. In addition, we build a real-world dataset to
verify the capacity of our method in detecting the object of interest including
those small ones. Our method can predict a precise bounding box on an image,
and achieve high speed on large images without pooling operations. Experimental
results indicate that the proposed method can mine effective context by several
local observations. Moreover, the precision and speed are easily improved by
changing the number of recurrent steps. Finally, we will open the source code
of our proposed approach.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06899</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Evaluation of Video Keyframe Summaries using User Ground Truth</dc:title>
 <dc:creator>Kuncheva, Ludmila I.</dc:creator>
 <dc:creator>Yousefi, Paria</dc:creator>
 <dc:creator>Gunn, Iain A. D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.4.9</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:description>  Given the great interest in creating keyframe summaries from video, it is
surprising how little has been done to formalise their evaluation and
comparison. User studies are often carried out to demonstrate that a proposed
method generates a more appealing summary than one or two rival methods. But
larger comparison studies cannot feasibly use such user surveys. Here we
propose a discrimination capacity measure as a formal way to quantify the
improvement over the uniform baseline, assuming that one or more ground truth
summaries are available. Using the VSUMM video collection, we examine 10 video
feature types, including CNN and SURF, and 6 methods for matching frames from
two summaries. Our results indicate that a simple frame representation through
hue histograms suffices for the purposes of comparing keyframe summaries. We
subsequently propose a formal protocol for comparing summaries when ground
truth is available.
</dc:description>
 <dc:description>Comment: 12 pages, 10 figures, 2 tables</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06901</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A topological interpretation of three Leibnizian principles within the
  functional extensions</dc:title>
 <dc:creator>Forti, Marco</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - General Topology</dc:subject>
 <dc:subject>03A05, 03H05, 03E65</dc:subject>
 <dc:description>  Three philosophical principles are often quoted in connection with Leibniz:
objects sharing the same properties are the same object (Identity of
indiscernibles), everything can possibly exist, unless it yields contradiction
(Possibility as consistency), and the ideal elements correctly determine the
real things (Transfer). Here we give a precise logico-mathematical formulation
of these principles within the framework of the Functional Extensions,
mathematical structures that generalize at once compactifications, completions,
and elementary extensions of models. In this context, the above Leibnizian
principles appear as topological or algebraic properties, namely: a property of
separation, a property of compactness, and a property of directeness,
respectively. Abiding by this interpretation, we obtain the somehow surprising
conclusion that these Leibnizian principles may be fulfilled in pairs, but not
all three together.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1012.4341 this
  article supersedes arXiv:1012.4341</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06906</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixin Composition Synthesis based on Intersection Types</dc:title>
 <dc:creator>Bessai, Jan</dc:creator>
 <dc:creator>Chen, Tzu-Chun</dc:creator>
 <dc:creator>Dudenhefner, Andrej</dc:creator>
 <dc:creator>D&#xfc;dder, Boris</dc:creator>
 <dc:creator>de'Liguoro, Ugo</dc:creator>
 <dc:creator>Rehof, Jakob</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We present a method for synthesizing compositions of mixins using type
inhabitation in intersection types. First, recursively defined classes and
mixins, which are functions over classes, are expressed as terms in a lambda
calculus with records. Intersection types with records and record-merge are
used to assign meaningful types to these terms without resorting to recursive
types. Second, typed terms are translated to a repository of typed combinators.
We show a relation between record types with record-merge and intersection
types with constructors. This relation is used to prove soundness and partial
completeness of the translation with respect to mixin composition synthesis.
Furthermore, we demonstrate how a translated repository and goal type can be
used as input to an existing framework for composition synthesis in bounded
combinatory logic via type inhabitation. The computed result is a class typed
by the goal type and generated by a mixin composition applied to an existing
class.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06907</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasi-Cyclic Constructions of Quantum Codes</dc:title>
 <dc:creator>Galindo, Carlos</dc:creator>
 <dc:creator>Hernando, Fernando</dc:creator>
 <dc:creator>Matsumoto, Ryutaroh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>94B65, 94B15, 81P70</dc:subject>
 <dc:description>  We give sufficient conditions for self-orthogonality with respect to
symplectic, Euclidean and Hermitian inner products of a wide family of
quasi-cyclic codes of index two. We provide lower bounds for the symplectic
weight and the minimum distance of the involved codes. Supported in the
previous results, we show algebraic constructions of good quantum codes and
determine their parameters.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06908</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-language Framework for Word Recognition and Spotting of Indic
  Scripts</dc:title>
 <dc:creator>Bhunia, Ayan Kumar</dc:creator>
 <dc:creator>Roy, Partha Pratim</dc:creator>
 <dc:creator>Mohta, Akash</dc:creator>
 <dc:creator>Pal, Umapada</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Handwritten word recognition and spotting of low-resource scripts are
difficult as sufficient training data is not available and it is often
expensive for collecting data of such scripts. This paper presents a novel
cross language platform for handwritten word recognition and spotting for such
low-resource scripts where training is performed with a sufficiently large
dataset of an available script (considered as source script) and testing is
done on other scripts (considered as target script). Training with one source
script and testing with another script to have a reasonable result is not easy
in handwriting domain due to the complex nature of handwriting variability
among scripts. Also it is difficult in mapping between source and target
characters when they appear in cursive word images. The proposed Indic cross
language framework exploits a large resource of dataset for training and uses
it for recognizing and spotting text of other target scripts where sufficient
amount of training data is not available. Since, Indic scripts are mostly
written in 3 zones, namely, upper, middle and lower, we employ zone-wise
character (or component) mapping for efficient learning purpose. The
performance of our cross-language framework depends on the extent of similarity
between the source and target scripts. Hence, we devise an entropy based script
similarity score using source to target character mapping that will provide a
feasibility of cross language transcription. We have tested our approach in
three Indic scripts, namely, Bangla, Devanagari and Gurumukhi, and the
corresponding results are reported.
</dc:description>
 <dc:description>Comment: Pattern Recognition(Minor Revision)</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06909</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ComboGAN: Unrestrained Scalability for Image Domain Translation</dc:title>
 <dc:creator>Anoosheh, Asha</dc:creator>
 <dc:creator>Agustsson, Eirikur</dc:creator>
 <dc:creator>Timofte, Radu</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This year alone has seen unprecedented leaps in the area of learning-based
image translation, namely CycleGAN, by Zhu et al. But experiments so far have
been tailored to merely two domains at a time, and scaling them to more would
require an quadratic number of models to be trained. And with two-domain models
taking days to train on current hardware, the number of domains quickly becomes
limited by the time and resources required to process them. In this paper, we
propose a multi-component image translation model and training scheme which
scales linearly - both in resource consumption and time required - with the
number of domains. We demonstrate its capabilities on a dataset of paintings by
14 different artists and on images of the four different seasons in the Alps.
Note that 14 data groups would need (14 choose 2) = 91 different CycleGAN
models: a total of 182 generator/discriminator pairs; whereas our model
requires only 14 generator/discriminator pairs.
</dc:description>
 <dc:description>Comment: Source code provided here: https://github.com/AAnoosheh/ComboGAN</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06914</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bipartite Graph Matching for Keyframe Summary Evaluation</dc:title>
 <dc:creator>Gunn, Iain A. D.</dc:creator>
 <dc:creator>Kuncheva, Ludmila I.</dc:creator>
 <dc:creator>Yousefi, Paria</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10, I.4.9, G.2.2</dc:subject>
 <dc:description>  A keyframe summary, or &quot;static storyboard&quot;, is a collection of frames from a
video designed to summarise its semantic content. Many algorithms have been
proposed to extract such summaries automatically. How best to evaluate these
outputs is an important but little-discussed question. We review the current
methods for matching frames between two summaries in the formalism of graph
theory. Our analysis revealed different behaviours of these methods, which we
illustrate with a number of case studies. Based on the results, we recommend a
greedy matching algorithm due to Kannappan et al.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06919</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Production Oriented Approach for Vandalism Detection in Wikidata - The
  Buffaloberry Vandalism Detector at WSDM Cup 2017</dc:title>
 <dc:creator>Crescenzi, Rafael</dc:creator>
 <dc:creator>Fernandez, Marcelo</dc:creator>
 <dc:creator>Calabria, Federico A. Garcia</dc:creator>
 <dc:creator>Albani, Pablo</dc:creator>
 <dc:creator>Tauziet, Diego</dc:creator>
 <dc:creator>Baravalle, Adriana</dc:creator>
 <dc:creator>D'Ambrosio, Andr&#xe9;s Sebasti&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  Wikidata is a free and open knowledge base from the Wikimedia Foundation,
that not only acts as a central storage of structured data for other projects
of the organization, but also for a growing array of information systems,
including search engines. Like Wikipedia, Wikidata's content can be created and
edited by anyone; which is the main source of its strength, but also allows for
malicious users to vandalize it, risking the spreading of misinformation
through all the systems that rely on it as a source of structured facts. Our
task at the WSDM Cup 2017 was to come up with a fast and reliable prediction
system that narrows down suspicious edits for human revision. Elaborating on
previous works by Heindorf et al. we were able to outperform all other
contestants, while incorporating new interesting features, unifying the
programming language used to only Python and refactoring the feature extractor
into a simpler and more compact code base.
</dc:description>
 <dc:description>Comment: Vandalism Detector at WSDM Cup 2017, see arXiv:1712.05956</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06920</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Vandalism Detection with Linear Classifiers - The
  Conkerberry Vandalism Detector at WSDM Cup 2017</dc:title>
 <dc:creator>Grigorev, Alexey</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  Nowadays many artificial intelligence systems rely on knowledge bases for
enriching the information they process. Such Knowledge Bases are usually
difficult to obtain and therefore they are crowdsourced: they are available for
everyone on the internet to suggest edits and add new information.
Unfortunately, they are sometimes targeted by vandals who put inaccurate or
offensive information there. This is especially bad for the systems that use
these Knowledge Bases: for them it is important to use reliable information to
make correct inferences.
  One of such knowledge bases is Wikidata, and to fight vandals the organizers
of WSDM Cup 2017 challenged participants to build a model for detecting
mistrustful edits. In this paper we present the second place solution to the
cup: we show that it is possible to achieve competitive performance with simple
linear classification. With our approach we can achieve AU ROC of 0.938 on the
test data. Additionally, compared to other approaches, ours is significantly
faster. The solution is made available on GitHub.
</dc:description>
 <dc:description>Comment: Vandalism Detector at WSDM Cup 2017, see arXiv:1712.05956</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06921</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Models for Detecting Wikidata Vandalism with Stacking - Team
  Honeyberry Vandalism Detector at WSDM Cup 2017</dc:title>
 <dc:creator>Yamazaki, Tomoya</dc:creator>
 <dc:creator>Sasaki, Mei</dc:creator>
 <dc:creator>Murakami, Naoya</dc:creator>
 <dc:creator>Makabe, Takuya</dc:creator>
 <dc:creator>Iwasawa, Hiroki</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  The WSDM Cup 2017 is a binary classification task for classifying Wikidata
revisions into vandalism and non-vandalism. This paper describes our method
using some machine learning techniques such as under-sampling, feature
selection, stacking and ensembles of models. We confirm the validity of each
technique by calculating AUC-ROC of models using such techniques and not using
them. Additionally, we analyze the results and gain useful insights into
improving models for the vandalism detection task. The AUC-ROC of our final
submission after the deadline resulted in 0.94412.
</dc:description>
 <dc:description>Comment: Vandalism Detector at WSDM Cup 2017, see arXiv:1712.05956</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06922</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wikidata Vandalism Detection - The Loganberry Vandalism Detector at WSDM
  Cup 2017</dc:title>
 <dc:creator>Zhu, Qi</dc:creator>
 <dc:creator>Ng, Hongwei</dc:creator>
 <dc:creator>Liu, Liyuan</dc:creator>
 <dc:creator>Ji, Ziwei</dc:creator>
 <dc:creator>Jiang, Bingjie</dc:creator>
 <dc:creator>Shen, Jiaming</dc:creator>
 <dc:creator>Gui, Huan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  Wikidata is the new, large-scale knowledge base of the Wikimedia Foundation.
As it can be edited by anyone, entries frequently get vandalized, leading to
the possibility that it might spread of falsified information if such posts are
not detected. The WSDM 2017 Wiki Vandalism Detection Challenge requires us to
solve this problem by computing a vandalism score denoting the likelihood that
a revision corresponds to an act of vandalism and performance is measured using
the ROC-AUC obtained on a held-out test set. This paper provides the details of
our submission that obtained an ROC-AUC score of 0.91976 in the final
evaluation.
</dc:description>
 <dc:description>Comment: Vandalism Detector at WSDM Cup 2017, see arXiv:1712.05956</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06924</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe Policy Improvement with Baseline Bootstrapping</dc:title>
 <dc:creator>Laroche, Romain</dc:creator>
 <dc:creator>Trichelair, Paul</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A common goal in Reinforcement Learning is to derive a good strategy given a
limited batch of data. In this paper, we adopt the safe policy improvement
(SPI) approach: we compute a target policy guaranteed to perform at least as
well as a given baseline policy. Our SPI strategy, inspired by the
knows-what-it-knows paradigms, consists in bootstrapping the target policy with
the baseline policy when it does not know. We develop two computationally
efficient bootstrapping algorithms, a value-based and a policy-based, both
accompanied with theoretical SPI bounds. Three algorithm variants are proposed.
We empirically show the literature algorithms limits on a small stochastic
gridworld problem, and then demonstrate that our five algorithms not only
improve the worst case scenarios, but also the mean performance.
</dc:description>
 <dc:description>Comment: 8+2+11 pages</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06930</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scale-Space Anisotropic Total Variation for Limited Angle Tomography</dc:title>
 <dc:creator>Huang, Yixing</dc:creator>
 <dc:creator>Taubmann, Oliver</dc:creator>
 <dc:creator>Huang, Xiaolin</dc:creator>
 <dc:creator>Haase, Viktor</dc:creator>
 <dc:creator>Lauritsch, Guenter</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses streak reduction in limited angle tomography. Although
the iterative reweighted total variation (wTV) algorithm reduces small streaks
well, it is rather inept at eliminating large ones since total variation (TV)
regularization is scale-dependent and may regard these streaks as homogeneous
areas. Hence, the main purpose of this paper is to reduce streak artifacts at
various scales. We propose the scale-space anisotropic total variation (ssaTV)
algorithm in two different implementations. The first implementation (ssaTV-1)
utilizes an anisotropic gradient-like operator which uses 2s neighboring pixels
along the streaks' normal direction at each scale s. The second implementation
(ssaTV-2) makes use of anisotropic down-sampling and up-sampling operations,
similarly oriented along the streaks' normal direction, to apply TV
regularization at various scales. Experiments on numerical and clinical data
demonstrate that both ssaTV algorithms reduce streak artifacts more effectively
and efficiently than wTV, particularly when using multiple scales.
</dc:description>
 <dc:description>Comment: 8 pages, 12 figures (48 subfigrues in total)</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06933</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An anthropological account of the Vim text editor: features and tweaks
  after 10 years of usage</dc:title>
 <dc:creator>Fabbri, Renato</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:description>  The Vim text editor is very rich in capabilities and thus complex. This
article is a description of Vim and a set of considerations about its usage and
design. It results from more than ten years of experience in using Vim for
writing and editing various types of documents, e.g. Python, C++, JavaScript,
ChucK programs; \LaTeX, Markdown, HTML, RDF, Make and other markup files; % TTM
binary files. It is commonplace, in the Vim users and developers communities,
to say that it takes about ten years to master (or start mastering) this text
editor, and I find that other experienced users have a different view of Vim
and that they use a different set of features. Therefore, this document exposes
my understandings in order to confront my usage with that of other Vim users.
Another goal is to make available a reference document with which new users can
grasp a sound overview by reading it and the discussions that it might
generate. Also, it should be useful for users of any degree of experience,
including me, as a compendium of commands, namespaces and tweaks. Upon
feedback, and maturing of my Vim usage, this document might be enhanced and
expanded.
</dc:description>
 <dc:description>Comment: Scripts and other files are in this repository:
  https://github.com/ttm/vim</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06934</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effect of NBTI/PBTI Aging and Process Variations on Write Failures in
  MOSFET and FinFET Flip-Flops</dc:title>
 <dc:creator>Khalid, Usman</dc:creator>
 <dc:creator>Mastrandrea, Antonio</dc:creator>
 <dc:creator>Olivieri, Mauro</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  The assessment of noise margins and the related probability of failure in
digital cells has growingly become essential, as nano-scale CMOS and FinFET
technologies are confronting reliability issues caused by aging mechanisms,
such as NBTI, and variability in process parameters. The influence of such
phenomena is particularly associated to the Write Noise Margins (WNM) in memory
elements, since a wrong stored logic value can result in an upset of the system
state. In this work, we calculated and compared the effect of process
variations and NBTI aging over the years on the actual WNM of various CMOS and
FinFET based flip-flop cells. The massive transistor-level Monte Carlo
simulations produced both nominal (i.e. mean) values and associated standard
deviations of the WNM of the chosen flip-flops. This allowed calculating the
consequent write failure probability as a function of an input voltage shift on
the flip-flop cells, and assessing a comparison for robustness among different
circuit topologies and technologies.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06934</dc:identifier>
 <dc:identifier>Microelectronics Reliability 55(12), August 2015, Elsevier</dc:identifier>
 <dc:identifier>doi:10.1016/j.microrel.2015.07.050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06935</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Smart Card Data for Travelers' Mini Activities</dc:title>
 <dc:creator>Chidlovskii, Boris</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In the context of public transport modeling and simulation, we address the
problem of mismatch between simulated transit trips and observed ones. We point
to the weakness of the current travel demand modeling process; the trips it
generates are over-optimistic and do not reflect the real passenger choices. We
introduce the notion of mini activities the travelers do during the trips; they
can explain the deviation of simulated trips from the observed trips. We
propose to mine the smart card data to extract the mini activities. We develop
a technique to integrate them in the generated trips and learn such an
integration from two available sources, the trip history and trip planner
recommendations. For an input travel demand, we build a Markov chain over the
trip collection and apply the Monte Carlo Markov Chain algorithm to integrate
mini activities in such a way that the selected characteristics converge to the
desired distributions. We test our method in different settings on the
passenger trip collection of Nancy, France. We report experimental results
demonstrating a very important mismatch reduction.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06951</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coverless Information Hiding Based on Generative adversarial networks</dc:title>
 <dc:creator>Liu, Ming-ming</dc:creator>
 <dc:creator>Zhang, Min-qing</dc:creator>
 <dc:creator>Liu, Jia</dc:creator>
 <dc:creator>Zhang, Ying-nan</dc:creator>
 <dc:creator>Ke, Yan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Traditional image steganography modifies the content of the image more or
less, it is hard to resist the detection of image steganalysis tools. To
address this problem, a novel method named generative coverless information
hiding method based on generative adversarial networks is proposed in this
paper. The main idea of the method is that the class label of generative
adversarial networks is replaced with the secret information as a driver to
generate hidden image directly, and then extract the secret information from
the hidden image through the discriminator. It's the first time that the
coverless information hiding is achieved by generative adversarial networks.
Compared with the traditional image steganography, this method does not modify
the content of the original image. therefore, this method can resist image
steganalysis tools effectively. In terms of steganographic capacity,
anti-steganalysis, safety and reliability, the experimen shows that this hidden
algorithm performs well.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1703.05502 by other authors</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06952</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Pentapods with a Simple Singularity Variety</dc:title>
 <dc:creator>Rasoulzadeh, Arvin</dc:creator>
 <dc:creator>Nawratil, Georg</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  There exists a bijection between the configuration space of a linear pentapod
and all points $(u,v,w,p_x,p_y,p_z)\in\mathbb{R}^{6}$ located on the singular
quadric $\Gamma: u^2+v^2+w^2=1$, where $(u,v,w)$ determines the orientation of
the linear platform and $(p_x,p_y,p_z)$ its position. Then the set of all
singular robot configurations is obtained by intersecting $\Gamma$ with a cubic
hypersurface $\Sigma$ in $\mathbb{R}^{6}$, which is only quadratic in the
orientation variables and position variables, respectively. This article
investigates the restrictions to be imposed on the design of this mechanism in
order to obtain a reduction in degree. In detail we study the cases where
$\Sigma$ is (1) linear in position variables, (2) linear in orientation
variables and (3) quadratic in total. The resulting designs of linear pentapods
have the advantage of considerably simplified computation of singularity-free
spheres in the configuration space. Finally we propose three kinematically
redundant designs of linear pentapods with a simple singularity surface.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06956</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Laguerre-Intersection Method for Implicit Solvation</dc:title>
 <dc:creator>Hummel, Michelle Hatch</dc:creator>
 <dc:creator>Yu, Bihua</dc:creator>
 <dc:creator>Simmerling, Carlos</dc:creator>
 <dc:creator>Coutsias, Evangelos A.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  Laguerre tessellations of macromolecules capture properties such as molecular
interface surfaces, volumes and cavities. Explicit solvent molecular dynamics
simulations of a macromolecule are slow as the number of solvent atoms
considered typically increases by order of magnitude. Implicit methods model
the solvent via continuous corrections to the force field based on estimates of
the solvent exposed surface areas of individual atoms, gaining speed at the
expense of accuracy. However, Laguerre cells of exterior atoms tend to be
overly large or unbounded. Our method, the Laguerre-Intersection method, caps
cells in a physically accurate manner by considering the intersection of the
space-filling diagram with the Laguerre tessellation. This method optimizes an
adjustable parameter, the weight, to ensure the areas and volumes of capped
cells exposed to solvent are as close as possible, on average, to those
computed from equilibrated explicit solvent simulations. The contact planes are
radical planes, meaning that as the solvent weight is varied, cells remain
constant. We test the consistency of our model using a high-quality trajectory
of HIV-protease, a dimer with flexible loops and open-close transitions. We
also compare our results with interval-arithmetic Gauss-Bonnet based method.
Optimal solvent parameters quickly converge, which we use to illustrate the
increased accuracy of the Laguerre-Intersection method over two recently
proposed methods as compared to the explicit model.
</dc:description>
 <dc:description>Comment: 39 pages</dc:description>
 <dc:date>2017-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06957</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MURA Dataset: Towards Radiologist-Level Abnormality Detection in
  Musculoskeletal Radiographs</dc:title>
 <dc:creator>Rajpurkar, Pranav</dc:creator>
 <dc:creator>Irvin, Jeremy</dc:creator>
 <dc:creator>Bagul, Aarti</dc:creator>
 <dc:creator>Ding, Daisy</dc:creator>
 <dc:creator>Duan, Tony</dc:creator>
 <dc:creator>Mehta, Hershel</dc:creator>
 <dc:creator>Yang, Brandon</dc:creator>
 <dc:creator>Zhu, Kaylie</dc:creator>
 <dc:creator>Laird, Dillon</dc:creator>
 <dc:creator>Ball, Robyn L.</dc:creator>
 <dc:creator>Langlotz, Curtis</dc:creator>
 <dc:creator>Shpanskaya, Katie</dc:creator>
 <dc:creator>Lungren, Matthew P.</dc:creator>
 <dc:creator>Ng, Andrew</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce MURA, a large dataset of musculoskeletal radiographs containing
40,895 images from 14,982 studies, where each study is manually labeled by
radiologists as either normal or abnormal. On this dataset, we train a
169-layer densely connected convolutional network to detect and localize
abnormalities. To evaluate our model robustly and to get an estimate of
radiologist performance, we collect additional labels from board-certified
Stanford radiologists on the test set, consisting of 209 musculoskeletal
studies. We compared our model and radiologists on the Cohen's kappa statistic,
which expresses the agreement of our model and of each radiologist with the
gold standard, defined as the majority vote of a disjoint group of
radiologists. We find that our model achieves performance comparable to that of
radiologists. Model performance is higher than the best radiologist performance
in detecting abnormalities on finger studies and equivalent on wrist studies.
However, model performance is lower than best radiologist performance in
detecting abnormalities on elbow, forearm, hand, humerus, and shoulder studies,
indicating that the task is a good challenge for future research. To encourage
advances, we have made our dataset freely available at
https://stanfordmlgroup.github.io/projects/mura
</dc:description>
 <dc:date>2017-12-11</dc:date>
 <dc:date>2018-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06957</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06959</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructing an orthonormal set of eigenvectors for DFT matrix using
  Gramians and determinants</dc:title>
 <dc:creator>Zaliva, Vadim</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  The problem of constructing an orthogonal set of eigenvectors for a DFT
matrix is well studied. An elegant solution is mentioned by Matveev in his
paper &quot;Interwining relations between the Fourier transfom and discrete Fourier
transform, the related functional identities and beyond&quot;. In this paper, we
present a distilled form of his solution including some steps unexplained in
his paper, along with correction of typos and errors using more consistent
notation. Then we compare the computational complexity of his method with the
more traditional method involving direct application of the Gram-Schmidt
process. Finally, we present our implementation of Matveev's method as a
Mathematica module.
</dc:description>
 <dc:description>Comment: includes Mathematica code</dc:description>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06961</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Word Mapping Using Structural Similarities in Monolingual
  Embeddings</dc:title>
 <dc:creator>Aldarmaki, Hanan</dc:creator>
 <dc:creator>Mohan, Mahesh</dc:creator>
 <dc:creator>Diab, Mona</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Most existing methods of automatic bilingual dictionary induction rely on
prior alignments between the source and target languages, such as parallel
corpora or seed dictionaries. For many language pairs, such supervised
alignments are not readily available. We propose an unsupervised approach for
learning a bilingual dictionary for a pair of languages given their
independently-learned monolingual word embeddings. The proposed method exploits
local and global structures in monolingual vector spaces to align them such
that similar words are mapped to each other. We show experimentally that the
performance of the bilingual alignments learned using the unsupervised method
is comparable to supervised bilingual alignments using a seed dictionary.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06970</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enumerating maximal cliques in link streams with durations</dc:title>
 <dc:creator>Viard, Tiphaine</dc:creator>
 <dc:creator>Magnien, Cl&#xe9;mence</dc:creator>
 <dc:creator>Latapy, Matthieu</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Link streams model interactions over time, and a clique in a link stream is
defined as a set of nodes and a time interval such that all pairs of nodes in
this set interact permanently during this time interval. This notion was
introduced recently in the case where interactions are instantaneous. We
generalize it to the case of interactions with durations and show that the
instantaneous case actually is a particular case of the case with durations. We
propose an algorithm to detect maximal cliques that improves our previous one
for instantaneous link streams, and performs better than the state of the art
algorithms in several cases of interest.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06979</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Automorphic Distance Metric and its Application to Node Embedding for
  Role Mining</dc:title>
 <dc:creator>Mart&#xed;nez, V&#xed;ctor</dc:creator>
 <dc:creator>Berzal, Fernando</dc:creator>
 <dc:creator>Cubero, Juan-Carlos</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Role is a fundamental concept in the analysis of the behavior and function of
interacting entities represented by network data. Role discovery is the task of
uncovering hidden roles. Node roles are commonly defined in terms of
equivalence classes, where two nodes have the same role if they fall within the
same equivalence class. Automorphic equivalence, where two nodes are equivalent
when they can swap their labels to form an isomorphic graph, captures this
common notion of role. The binary concept of equivalence is too restrictive and
nodes in real-world networks rarely belong to the same equivalence class.
Instead, a relaxed definition in terms of similarity or distance is commonly
used to compute the degree to which two nodes are equivalent. In this paper, we
propose a novel distance metric called automorphic distance, which measures how
far two nodes are of being automorphically equivalent. We also study its
application to node embedding, showing how our metric can be used to generate
vector representations of nodes preserving their roles for data visualization
and machine learning. Our experiments confirm that the proposed metric
outperforms the RoleSim automorphic equivalence-based metric in the generation
of node embeddings for different networks.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06989</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Faster Drop-in Implementation for Leaf-wise Exact Greedy Induction of
  Decision Tree Using Pre-sorted Deque</dc:title>
 <dc:creator>Ye, Jianbo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This short article presents a new implementation for decision trees. By
introducing pre-sorted deques, the leaf-wise greedy tree growing strategy no
longer needs to re-sort data at each node, and takes O(kn) time and O(1) extra
memory locating the best split and branching. The consistent, superior
performance - plus its simplicity and guarantee in producing the same
classification results as the standard decision trees - makes the new
implementation a drop-in replacement for depth-wise tree induction with strong
performance.
</dc:description>
 <dc:description>Comment: 4 pages, updated with new statistics and fix typos</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06994</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepNorm-A Deep Learning Approach to Text Normalization</dc:title>
 <dc:creator>Zare, Maryam</dc:creator>
 <dc:creator>Rohatgi, Shaurya</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents an simple yet sophisticated approach to the challenge by
Sproat and Jaitly (2016)- given a large corpus of written text aligned to its
normalized spoken form, train an RNN to learn the correct normalization
function. Text normalization for a token seems very straightforward without
it's context. But given the context of the used token and then normalizing
becomes tricky for some classes. We present a novel approach in which the
prediction of our classification algorithm is used by our sequence to sequence
model to predict the normalized text of the input token. Our approach takes
very less time to learn and perform well unlike what has been reported by
Google (5 days on their GPU cluster). We have achieved an accuracy of 97.62
which is impressive given the resources we use. Our approach is using the best
of both worlds, gradient boosting - state of the art in most classification
tasks and sequence to sequence learning - state of the art in machine
translation. We present our experiments and report results with various
parameter settings.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1611.00068 by other authors</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06996</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation algorithms for stochastic and risk-averse optimization</dc:title>
 <dc:creator>Byrka, Jaroslaw</dc:creator>
 <dc:creator>Srinivasan, Aravind</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W20, 68W25, 90C15</dc:subject>
 <dc:description>  We present improved approximation algorithms in stochastic optimization. We
prove that the multi-stage stochastic versions of covering integer programs
(such as set cover and vertex cover) admit essentially the same approximation
algorithms as their standard (non-stochastic) counterparts; this improves upon
work of Swamy \&amp; Shmoys which shows an approximability that depends
multiplicatively on the number of stages. We also present approximation
algorithms for facility location and some of its variants in the $2$-stage
recourse model, improving on previous approximation guarantees. We give a
$2.2975$-approximation algorithm in the standard polynomial-scenario model and
an algorithm with an expected per-scenario $2.4957$-approximation guarantee,
which is applicable to the more general black-box distribution model.
</dc:description>
 <dc:description>Comment: Extension of a SODA'07 paper. To appear in SIAM J. Discrete Math</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06997</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum impossible differential and truncated differential cryptanalysis</dc:title>
 <dc:creator>Xie, Huiqin</dc:creator>
 <dc:creator>Yang, Li</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We study applications of BV algorithm and present quantum versions of
impossible differential cryptanalysis and truncated differential cryptanalysis
based on it. Afterwards, we analyze their efficiencies and success
probabilities rigorously. In traditional impossible differential attack or
truncated differential attack, it is difficult to extend the differential path,
which usually limits the number of rounds that can be attacked. By contrast,
our approach treats the first $r-1$ rounds of the cipher as a whole and applies
BV algorithm on them directly. Thus extending the number of rounds is not a
problem for our algorithm.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.06997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07003</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bilinear residual Neural Network for the identification and forecasting
  of dynamical systems</dc:title>
 <dc:creator>Fablet, Ronan</dc:creator>
 <dc:creator>Ouala, Said</dc:creator>
 <dc:creator>Herzet, Cedric</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Due to the increasing availability of large-scale observation and simulation
datasets, data-driven representations arise as efficient and relevant
computation representations of dynamical systems for a wide range of
applications, where model-driven models based on ordinary differential equation
remain the state-of-the-art approaches. In this work, we investigate neural
networks (NN) as physically-sound data-driven representations of such systems.
Reinterpreting Runge-Kutta methods as graphical models, we consider a residual
NN architecture and introduce bilinear layers to embed non-linearities which
are intrinsic features of dynamical systems. From numerical experiments for
classic dynamical systems, we demonstrate the relevance of the proposed
NN-based architecture both in terms of forecasting performance and model
identification.
</dc:description>
 <dc:description>Comment: Submitted</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07004</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Any-gram Kernels for Sentence Classification: A Sentiment Analysis Case
  Study</dc:title>
 <dc:creator>Kaljahi, Rasoul</dc:creator>
 <dc:creator>Foster, Jennifer</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Any-gram kernels are a flexible and efficient way to employ bag-of-n-gram
features when learning from textual data. They are also compatible with the use
of word embeddings so that word similarities can be accounted for. While the
original any-gram kernels are implemented on top of tree kernels, we propose a
new approach which is independent of tree kernels and is more efficient. We
also propose a more effective way to make use of word embeddings than the
original any-gram formulation. When applied to the task of sentiment
classification, our new formulation achieves significantly better performance.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07008</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-Preserving Adversarial Networks</dc:title>
 <dc:creator>Tripathy, Ardhendu</dc:creator>
 <dc:creator>Wang, Ye</dc:creator>
 <dc:creator>Ishwar, Prakash</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>94A15, 68T05, 62B10</dc:subject>
 <dc:description>  We propose a data-driven framework for optimizing privacy-preserving data
release mechanisms toward the information-theoretically optimal tradeoff
between minimizing distortion of useful data and concealing sensitive
information. Our approach employs adversarially-trained neural networks to
implement randomized mechanisms and to perform a variational approximation of
mutual information privacy. We empirically validate our Privacy-Preserving
Adversarial Networks (PPAN) framework with experiments conducted on discrete
and continuous synthetic data, as well as the MNIST handwritten digits dataset.
With the synthetic data, we find that our model-agnostic PPAN approach achieves
tradeoff points very close to the optimal tradeoffs that are
analytically-derived from model knowledge. In experiments with the MNIST data,
we visually demonstrate a learned tradeoff between minimizing the pixel-level
distortion versus concealing the written digit.
</dc:description>
 <dc:description>Comment: 22 pages, 11 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07019</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PSO-Optimized Hopfield Neural Network-Based Multipath Routing for Mobile
  Ad-hoc Networks</dc:title>
 <dc:creator>Sheikhan, Mansour</dc:creator>
 <dc:creator>Hemmati, Ehsan</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobile ad-hoc network (MANET) is a dynamic collection of mobile computers
without the need for any existing infrastructure. Nodes in a MANET act as hosts
and routers. Designing of robust routing algorithms for MANETs is a challenging
task. Disjoint multipath routing protocols address this problem and increase
the reliability, security and lifetime of network. However, selecting an
optimal multipath is an NP-complete problem. In this paper, Hopfield neural
network (HNN) which its parameters are optimized by particle swarm optimization
(PSO) algorithm is proposed as multipath routing algorithm. Link expiration
time (LET) between each two nodes is used as the link reliability estimation
metric. This approach can find either node-disjoint or link-disjoint paths in
single phase route discovery. Simulation results confirm that PSO-HNN routing
algorithm has better performance as compared to backup path set selection
algorithm (BPSA) in terms of the path set reliability and number of paths in
the set.
</dc:description>
 <dc:description>Comment: Mobile ad-hoc networks; Reliability; Multipath routing; Neural
  networks; Particle swarm optimization (PSO)</dc:description>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07019</dc:identifier>
 <dc:identifier>International Journal of Computational Intelligence Systems, Year
  2012, Volume 5, Number 3, Pages 568-581</dc:identifier>
 <dc:identifier>doi:10.1080/18756891.2012.696921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07020</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online human aggregation under pressure moves beyond preferential
  attachment</dc:title>
 <dc:creator>Cao, Zhenfeng</dc:creator>
 <dc:creator>Zheng, Minzhang</dc:creator>
 <dc:creator>Manrique, Pedro D.</dc:creator>
 <dc:creator>He, Zhou</dc:creator>
 <dc:creator>Johnson, Neil F.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  There is a significant amount of online human activity which is either
clandestine or illicit in nature, and hence where individuals operate under
fear of exposure or capture. Yet there is little theoretical understanding of
what models best describe the resulting dynamics. Here we address this gap, by
analyzing the evolutionary dynamics of the supporters behind the 95 pro-ISIS
online communities (i.e. self-organized social media groups) that appeared
recently on a global social media site. We show that although they do not
follow a conventional (i.e. size-based) preferential attachment (PA) model,
their dynamical evolution can be explained by a new variant that we introduce
here, which we refer to as active attraction model (AA). This AA model takes
into account the locality and group heterogeneity which undoubtedly feature in
humans' online behavior under pressure, but which are not contained in
conventional PA models. The AA model captures both group-specific and
macroscopic observations over all size ranges -- as opposed to just the tail
for large groups or groups' initial growth -- suggesting that heterogeneity and
locality play a crucial role in the dynamics of online extremist support. We
derive approximate expressions for the group size distributions in two simple
systems that involve simultaneously the mechanisms of group joining (governed
by either PA or AA), group leaving, and account banning, and show how these
processes influence the group size distributions. We believe this work will
serve in helping understand a broad spectrum of online human activities which
are either clandestine or illicit in nature, and hence where individuals
operate under fear of exposure or capture.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07021</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cache-Aided Private Information Retrieval with Partially Known Uncoded
  Prefetching: Fundamental Limits</dc:title>
 <dc:creator>Wei, Yi-Peng</dc:creator>
 <dc:creator>Banawan, Karim</dc:creator>
 <dc:creator>Ulukus, Sennur</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider the problem of private information retrieval (PIR) from $N$
non-colluding and replicated databases, when the user is equipped with a cache
that holds an uncoded fraction $r$ of the symbols from each of the $K$ stored
messages in the databases. This model operates in a two-phase scheme, namely,
the prefetching phase where the user acquires side information and the
retrieval phase where the user privately downloads the desired message. In the
prefetching phase, the user receives $\frac{r}{N}$ uncoded fraction of each
message from the $n$th database. This side information is known only to the
$n$th database and unknown to the remaining databases, i.e., the user possesses
\emph{partially known} side information. We investigate the optimal normalized
download cost $D^*(r)$ in the retrieval phase as a function of $K$, $N$, $r$.
We develop lower and upper bounds for the optimal download cost. The bounds
match in general for the cases of very low caching ratio ($r \leq
\frac{1}{N^{K-1}}$) and very high caching ratio ($r \geq
\frac{K-2}{N^2-3N+KN}$). We fully characterize the optimal download cost
caching ratio tradeoff for $K=3$. For general $K$, $N$, and $r$, we show that
the largest gap between the achievability and the converse bounds is
$\frac{5}{32}$.
</dc:description>
 <dc:description>Comment: Submitted for publication, December 2017. arXiv admin note:
  substantial text overlap with arXiv:1709.01056</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07022</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Renal Segmentation in DCE-MRI using Convolutional Neural
  Networks</dc:title>
 <dc:creator>Haghighi, Marzieh</dc:creator>
 <dc:creator>Warfield, Simon K.</dc:creator>
 <dc:creator>Kurugol, Sila</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Kidney function evaluation using dynamic contrast-enhanced MRI (DCE-MRI)
images could help in diagnosis and treatment of kidney diseases of children.
Automatic segmentation of renal parenchyma is an important step in this
process. In this paper, we propose a time and memory efficient fully automated
segmentation method which achieves high segmentation accuracy with running time
in the order of seconds in both normal kidneys and kidneys with hydronephrosis.
The proposed method is based on a cascaded application of two 3D convolutional
neural networks that employs spatial and temporal information at the same time
in order to learn the tasks of localization and segmentation of kidneys,
respectively. Segmentation performance is evaluated on both normal and abnormal
kidneys with varying levels of hydronephrosis. We achieved a mean dice
coefficient of 91.4 and 83.6 for normal and abnormal kidneys of pediatric
patients, respectively.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07027</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Snake: a Stochastic Proximal Gradient Algorithm for Regularized Problems
  over Large Graphs</dc:title>
 <dc:creator>Salim, Adil</dc:creator>
 <dc:creator>Bianchi, Pascal</dc:creator>
 <dc:creator>Hachem, Walid</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A regularized optimization problem over a large unstructured graph is
studied, where the regularization term is tied to the graph geometry. Typical
regularization examples include the total variation and the Laplacian
regularizations over the graph. When applying the proximal gradient algorithm
to solve this problem, there exist quite affordable methods to implement the
proximity operator (backward step) in the special case where the graph is a
simple path without loops. In this paper, an algorithm, referred to as &quot;Snake&quot;,
is proposed to solve such regularized problems over general graphs, by taking
benefit of these fast methods. The algorithm consists in properly selecting
random simple paths in the graph and performing the proximal gradient algorithm
over these simple paths. This algorithm is an instance of a new general
stochastic proximal gradient algorithm, whose convergence is proven.
Applications to trend filtering and graph inpainting are provided among others.
Numerical experiments are conducted over large graphs.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07029</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sonification of Network Traffic Flow for Monitoring and Situational
  Awareness</dc:title>
 <dc:creator>Debashi, Mohamed</dc:creator>
 <dc:creator>Vickers, Paul</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  Maintaining situational awareness of what is happening within a network is
challenging, not least because the behaviour happens within computers and
communications networks, but also because data traffic speeds and volumes are
beyond human ability to process. Visualisation is widely used to present
information about the dynamics of network traffic dynamics. Although it
provides operators with an overall view and specific information about
particular traffic or attacks on the network, it often fails to represent the
events in an understandable way. Visualisations require visual attention and so
are not well suited to continuous monitoring scenarios in which network
administrators must carry out other tasks. Situational awareness is critical
and essential for decision-making in the domain of computer network monitoring
where it is vital to be able to identify and recognize network environment
behaviours.Here we present SoNSTAR (Sonification of Networks for SiTuational
AwaReness), a real-time sonification system to be used in the monitoring of
computer networks to support the situational awareness of network
administrators. SoNSTAR provides an auditory representation of all the TCP/IP
protocol traffic within a network based on the different traffic flows between
between network hosts. SoNSTAR raises situational awareness levels for computer
network defence by allowing operators to achieve better understanding and
performance while imposing less workload compared to visual techniques. SoNSTAR
identifies the features of network traffic flows by inspecting the status flags
of TCP/IP packet headers and mapping traffic events to recorded sounds to
generate a soundscape representing the real-time status of the network traffic
environment. Listening to the soundscape allows the administrator to recognise
anomalous behaviour quickly and without having to continuously watch a computer
screen.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures plus supplemental material in Github repository</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07040</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The NarrativeQA Reading Comprehension Challenge</dc:title>
 <dc:creator>Ko&#x10d;isk&#xfd;, Tom&#xe1;&#x161;</dc:creator>
 <dc:creator>Schwarz, Jonathan</dc:creator>
 <dc:creator>Blunsom, Phil</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Hermann, Karl Moritz</dc:creator>
 <dc:creator>Melis, G&#xe1;bor</dc:creator>
 <dc:creator>Grefenstette, Edward</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Reading comprehension (RC)---in contrast to information retrieval---requires
integrating information and reasoning about events, entities, and their
relations across a full document. Question answering is conventionally used to
assess RC ability, in both artificial agents and children learning to read.
However, existing RC datasets and tasks are dominated by questions that can be
solved by selecting answers using superficial information (e.g., local context
similarity or global term frequency); they thus fail to test for the essential
integrative aspect of RC. To encourage progress on deeper comprehension of
language, we present a new dataset and set of tasks in which the reader must
answer questions about stories by reading entire books or movie scripts. These
tasks are designed so that successfully answering their questions requires
understanding the underlying narrative rather than relying on shallow pattern
matching or salience. We show that although humans solve the tasks easily,
standard RC models struggle on the tasks presented here. We provide an analysis
of the dataset and the challenges it presents.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07041</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The cavity approach for Steiner trees Packing problems</dc:title>
 <dc:creator>Braunstein, Alfredo</dc:creator>
 <dc:creator>Muntoni, Anna Paola</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:description>  The Belief Propagation approximation, or cavity method, has been recently
applied to several combinatorial optimization problems in its zero-temperature
implementation, the Max-Sum algorithm. In particular, recent developments to
solve the Edge-Disjoint paths problem and the Prize collecting Steiner tree
Problem on graphs have shown remarkable results for several classes of graphs
and for benchmark instances. Here we propose a generalization of these
techniques for two variants of the Steiner trees packing problem where multiple
&quot;interacting&quot; trees have to be sought within a given graph. Depending on the
interaction among trees we distinguish the Vertex-Disjoint Steiner trees
Problem, where trees cannot share nodes, from the Edge-Disjoint Steiner trees
Problem, where edges cannot be shared by trees but nodes can be members of
multiple trees. Several practical problems of huge interest in network design
can be mapped into these two variants, for instance, the physical design of
Very Large Scale Integration (VLSI) chips. The formalism described here relies
on two components edge-variables that allows us to formulate a massage-passing
algorithm for the V-DStP and two algorithms for the E-DStP differing in the
scaling of the computational time with respect to some relevant parameters. We
will show that one of the two formalisms used for the edge-disjoint variant
allow us to map the Max-Sum update equations into a weighted maximum matching
problem over proper bipartite graphs. We developed a heuristic procedure based
on the Max-Sum equations that shows excellent performance in synthetic networks
(in particular outperforming standard multi-step greedy procedures by large
margins) and on large benchmark instances of VLSI for which the optimal
solution is known, on which the algorithm found the optimum in two cases and
the gap to optimality was never larger than 4 %.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07042</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development and evaluation of a deep learning model for protein-ligand
  binding affinity prediction</dc:title>
 <dc:creator>Stepniewska-Dziubinska, Marta M.</dc:creator>
 <dc:creator>Zielenkiewicz, Piotr</dc:creator>
 <dc:creator>Siedlecki, Pawel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:description>  Structure based ligand discovery is one of the most successful approaches for
augmenting the drug discovery process. Currently, there is a notable shift
towards machine learning (ML) methodologies to aid such procedures. Deep
learning has recently gained considerable attention as it allows the model to
&quot;learn&quot; to extract features that are relevant for the task at hand. We have
developed a novel deep neural network estimating the binding affinity of
ligand-receptor complexes. The complex is represented with a 3D grid, and the
model utilizes a 3D convolution to produce a feature map of this
representation, treating the atoms of both proteins and ligands in the same
manner. Our network was tested on the CASF &quot;scoring power&quot; benchmark and Astex
Diverse Set and outperformed classical scoring functions. The model, together
with usage instructions and examples, is available as a git repository at
http://gitlab.com/cheminfIBB/pafnucy
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07046</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic behavior of memristive circuits and combinatorial
  optimization</dc:title>
 <dc:creator>Caravelli, Francesco</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Physics - Applied Physics</dc:subject>
 <dc:description>  The interest in memristors has risen due to their possible application both
as memory units and as computational devices in combination with CMOS. This is
in part due to their nonlinear dynamics and a strong dependence on the circuit
topology. We provide evidence that also purely memristive circuits can be
employed for computational purposes. We show that a Lyapunov function,
polynomial in the internal memory parameters, exists for the case of DC
controlled memristors. Such Lyapunov function can be asymptotically mapped to
quadratic combinatorial optimization problems. This shows a direct parallel
between memristive circuits and the Hopfield-Little model. In the case of
Erdos-Renyi random circuits, we provide numerical evidence that the
distribution of the matrix elements of the couplings can be roughly
approximated by a Gaussian distribution, and that they scale with the inverse
square root of the number of elements. This provides an approximated but direct
connection to the physics of disordered system and, in particular, of mean
field spin glasses. Using this and the fact that the interaction is controlled
by a projector operator on the loop space of the circuit, we estimate the
number of stationary points of the Lyapunov function, and provide a scaling
formula as an upper bound in terms of the circuit topology only. In order to
put these ideas into practice, we provide an instance of optimization of the
Nikkei 225 dataset in the Markowitz framework, and show that it is competitive
compared to exponential annealing.
</dc:description>
 <dc:description>Comment: 21 pages, 8 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07056</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PAPR Reduction of OFDM Through Pilot Shifting</dc:title>
 <dc:creator>Hossain, Md. Sakir</dc:creator>
 <dc:creator>Shimamura, Tetsuya</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Peak to Average Power Ratio (PAPR) of Orthogonal Frequency Division
Multiplexing (OFDM) is a long-standing problem which has been hindering its
performance for decades. In this paper, we propose a new PAPR reduction scheme
based on shifting pilot locations among the data symbols. Since no side
information is sent to the receiver about the pilot locations, a novel pilot
detection algorithm is devised here exploiting the pilot power and the relative
constant distance property of pilots. The proposed scheme attains around 1.5 dB
PAPR reduction. The pilot detection accuracy is shown to be very excellent
ranging from 80% to 99% at 0 dB of Signal to Noise Ratio (SNR) in different
parameters. This scheme is very spectrally efficient with reduced complexity
without degrading BER performance significantly
</dc:description>
 <dc:description>Comment: 6 pages, Proc. of 26th IEEE International Symposium on Personal,
  Indoor, and Mobile Radio Communication (PIMRC), Hong Kong, Aug-September
  2015, pp. 77-82</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07056</dc:identifier>
 <dc:identifier>Proc. of 26th IEEE International Symposium on Personal, Indoor,
  and Mobile Radio Communication (PIMRC), Hong Kong, Aug-September 2015, pp.
  77-82</dc:identifier>
 <dc:identifier>doi:10.1109/PIMRC.2015.7343272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07060</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decoding Algorithm for Rank Metric Codes</dc:title>
 <dc:creator>Randrianarisoa, Tovohery Hajatiana</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work we will present algorithms for decoding rank metric codes. First
we will look at a new decoding algorithm for Gabidulin codes using the property
of Dickson matrices corresponding to linearized polynomials. We will be using a
Berlekamp-Massey-like algorithm in the process. We will show the difference
between our and existing algorithms. Apart from being a new algorithm, it is
also interesting that it can be modified to get a decoding algorithm for
general twisted Gabidulin codes.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07062</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Covert Wireless Communication with a Poisson Field of Interferers</dc:title>
 <dc:creator>He, Biao</dc:creator>
 <dc:creator>Yan, Shihao</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Jafarkhani, Hamid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study covert communication in wireless networks consisting
of a transmitter, Alice, an intended receiver, Bob, a warden, Willie, and a
Poisson field of interferers. Bob and Willie are subject to uncertain shot
noise due to the ambient signals from interferers in the network. With the aid
of stochastic geometry, we analyze the throughput of the covert communication
between Alice and Bob subject to given requirements on the covertness against
Willie and the reliability of decoding at Bob. We consider non-fading and
fading channels. We analytically obtain interesting findings on the impacts of
the density and the transmit power of the concurrent interferers on the covert
throughput. That is, the density and the transmit power of the interferers have
no impact on the covert throughput as long as the network stays in the
interference-limited regime, for both the non-fading and the fading cases. When
the interference is sufficiently small and comparable with the receiver noise,
the covert throughput increases as the density or the transmit power of the
concurrent interferers increases.
</dc:description>
 <dc:description>Comment: Submitted for possible journal publication on 30-Nov-2017</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07065</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint model-based recognition and localization of overlapped acoustic
  events using a set of distributed small microphone arrays</dc:title>
 <dc:creator>Chakraborty, Rupayan</dc:creator>
 <dc:creator>Nadeu, Climent</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In the analysis of acoustic scenes, often the occurring sounds have to be
detected in time, recognized, and localized in space. Usually, each of these
tasks is done separately. In this paper, a model-based approach to jointly
carry them out for the case of multiple simultaneous sources is presented and
tested. The recognized event classes and their respective room positions are
obtained with a single system that maximizes the combination of a large set of
scores, each one resulting from a different acoustic event model and a
different beamformer output signal, which comes from one of several
arbitrarily-located small microphone arrays. By using a two-step method, the
experimental work for a specific scenario consisting of meeting-room acoustic
events, either isolated or overlapped with speech, is reported. Tests carried
out with two datasets show the advantage of the proposed approach with respect
to some usual techniques, and that the inclusion of estimated priors brings a
further performance improvement.
</dc:description>
 <dc:description>Comment: Computational acoustic scene analysis, microphone array signal
  processing, acoustic event detection</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07078</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tables, bounds and graphics of short linear codes with covering radius 3
  and codimension 4 and 5</dc:title>
 <dc:creator>Bartoli, Daniele</dc:creator>
 <dc:creator>Davydov, Alexander A.</dc:creator>
 <dc:creator>Marcugini, Stefano</dc:creator>
 <dc:creator>Pambianco, Fernanda</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>94B05, 51E21, 51E22</dc:subject>
 <dc:description>  The length function $\ell_q(r,R)$ is the smallest length of a $ q $-ary
linear code of covering radius $R$ and codimension $r$. In this work, by
computer search in wide regions of $q$, we obtained short $[n,n-4,5]_q3$
quasiperfect MDS codes and $[n,n-5,5]_q3$ quasiperfect Almost MDS codes with
covering radius $R=3$. The new codes imply the following upper bounds:
\begin{align*} &amp;\ell_q(4,3)&lt;2.8\sqrt[3]{q\ln q}\text{ for }8\le q\le3323\text{
and }q=3511,3761,4001;\\ &amp;\ell_q(5,3)&lt;3\sqrt[3]{q^2\ln q}\text{ for }5\le
q\le563. \end{align*} For $r\neq 3t$ and $q\neq (q^{\prime})^3$, the new bounds
have the form \begin{align*} \ell_q(r,3)&lt; c\sqrt[3]{\ln q}\cdot
q^{(r-3)/3},~~c\text{ is a universal constant},~~r=4,5. \end{align*} As far as
it is known to the authors, such bounds have not been previously described in
the literature. In computer search, we use the leximatrix algorithm to obtain
parity check matrices of codes. The algorithm is a version of the recursive
g-parity check algorithm for greedy codes.
</dc:description>
 <dc:description>Comment: 22 pages, 7 figures, 2 tables, 24 references</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07081</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Column Generation for Interaction Coverage in Combinatorial Software
  Testing</dc:title>
 <dc:creator>Kadioglu, Serdar</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper proposes a novel column generation framework for combinatorial
software testing. In particular, it combines Mathematical Programming and
Constraint Programming in a hybrid decomposition to generate covering arrays.
The approach allows generating parameterized test cases with coverage
guarantees between parameter interactions of a given application. Compared to
exhaustive testing, combinatorial test case generation reduces the number of
tests to run significantly. Our column generation algorithm is generic and can
accommodate mixed coverage arrays over heterogeneous alphabets. The algorithm
is realized in practice as a cloud service and recognized as one of the five
winners of the company-wide cloud application challenge at Oracle. The service
is currently helping software developers from a range of different product
teams in their testing efforts while exposing declarative constraint models and
hybrid optimization techniques to a broader audience.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07084</identifier>
 <datestamp>2017-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Reinforcement-Learning Approach to Proactive Caching in Wireless
  Networks</dc:title>
 <dc:creator>Somuyiwa, Samuel O.</dc:creator>
 <dc:creator>Gyorgy, Andras</dc:creator>
 <dc:creator>Gunduz, Deniz</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider a mobile user accessing contents in a dynamic environment, where
new contents are generated over time (by the user's contacts), and remain
relevant to the user for random lifetimes. The user, equipped with a
finite-capacity cache memory, randomly accesses the system, and requests all
the relevant contents at the time of access. The system incurs an energy cost
associated with the number of contents downloaded and the channel quality at
that time. Assuming causal knowledge of the channel quality, the content
profile, and the user-access behavior, we model the proactive caching problem
as a Markov decision process with the goal of minimizing the long-term average
energy cost. We first prove the optimality of a threshold-based proactive
caching scheme, which dynamically caches or removes appropriate contents from
the memory, prior to being requested by the user, depending on the channel
state. The optimal threshold values depend on the system state, and hence, are
computationally intractable. Therefore, we propose parametric representations
for the threshold values, and use reinforcement-learning algorithms to find
near-optimal parametrizations. We demonstrate through simulations that the
proposed schemes significantly outperform classical reactive downloading, and
perform very close to a genie-aided lower bound.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07086</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transversals of Longest Paths</dc:title>
 <dc:creator>Cerioli, M&#xe1;rcia R.</dc:creator>
 <dc:creator>Fernandes, Cristina G.</dc:creator>
 <dc:creator>G&#xf3;mez, Renzo</dc:creator>
 <dc:creator>Guti&#xe9;rrez, Juan</dc:creator>
 <dc:creator>Lima, Paloma T.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Let $\lpt(G)$ be the minimum cardinality of a set of vertices that intersects
all longest paths in a graph $G$. Let $\omega(G)$ be the size of a maximum
clique in $G$, and $\tw(G)$ be the treewidth of $G$. We prove that $ \lpt(G)
\leq \max\{1,\omega(G)-2\}$ when $G$ is a connected chordal graph; that
$\lpt(G) =1$ when $G$ is a connected bipartite permutation graph or a connected
full substar graph; and that $\lpt(G) \leq \tw(G)$ for any connected graph $G$.
</dc:description>
 <dc:description>Comment: 19 pages, 9 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07087</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bibliometric Approximation of a Scientific Specialty by Combining Key
  Sources, Title Words, Authors and References</dc:title>
 <dc:creator>Rons, Nadine</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Bibliometric methods for the analysis of highly specialized subjects are
increasingly investigated and debated. Information and assessments well-focused
at the specialty level can help make important decisions in research and
innovation policy. This paper presents a novel method to approximate the
specialty to which a given publication record belongs. The method partially
combines sets of key values for four publication data fields: source, title,
authors and references. The approach is founded in concepts defining research
disciplines and scholarly communication, and in empirically observed
regularities in publication data. The resulting specialty approximation
consists of publications associated to the investigated publication record via
key values for at least three of the four data fields. This paper describes the
method and illustrates it with an application to publication records of
individual scientists. The illustration also successfully tests the focus of
the specialty approximation in terms of its ability to connect and help
identify peers. Potential tracks for further investigation include analyses
involving other kinds of specialized publication records, studies for a broader
range of specialties, and exploration of the potential for diverse applications
in research and research policy context.
</dc:description>
 <dc:description>Comment: 31 pages, 7 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07087</dc:identifier>
 <dc:identifier>Journal of Informetrics, 12(1), 113-132, 2018</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2017.12.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07099</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Collection of Lower Bounds for Online Matching on the Line</dc:title>
 <dc:creator>Antoniadis, Antonios</dc:creator>
 <dc:creator>Fischer, Carsten</dc:creator>
 <dc:creator>T&#xf6;nnis, Andreas</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the online matching on the line problem, the task is to match a set of
requests $R$ online to a given set of servers $S$. The distance metric between
any two points in $R\,\cup\, S$ is a line metric and the objective for the
online algorithm is to minimize the sum of distances between matched
server-request pairs. This problem is well-studied and - despite recent
improvements - there is still a large gap between the best known lower and
upper bounds: The best known deterministic algorithm for the problem is
$O(\log^2n)$-competitive, while the best known deterministic lower bound is
$9.001$. The lower and upper bounds for randomized algorithms are $4.5$ and
$O(\log n)$ respectively.
  We prove that any deterministic online algorithm which in each round: $(i)$
bases the matching decision only on information local to the current request,
and $(ii)$ is symmetric (in the sense that the decision corresponding to the
mirror image of some instance $I$ is the mirror image of the decision
corresponding to instance $I$), must be $\Omega(\log n)$-competitive. We then
extend the result by showing that it also holds when relaxing the symmetry
property so that the algorithm might prefer one side over the other, but only
up to some degree. This proves a barrier of $\Omega(\log n)$ on the competitive
ratio for a large class of &quot;natural&quot; algorithms. This class includes all
deterministic online algorithms found in the literature so far.
  Furthermore, we show that our result can be extended to randomized algorithms
that locally induce a symmetric distribution over the chosen servers. The
$\Omega(\log n)$-barrier on the competitive ratio holds for this class of
algorithms as well.
</dc:description>
 <dc:description>Comment: to appear in LATIN 2018</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07101</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving End-to-End Speech Recognition with Policy Learning</dc:title>
 <dc:creator>Zhou, Yingbo</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Connectionist temporal classification (CTC) is widely used for maximum
likelihood learning in end-to-end speech recognition models. However, there is
usually a disparity between the negative maximum likelihood and the performance
metric used in speech recognition, e.g., word error rate (WER). This results in
a mismatch between the objective function and metric during training. We show
that the above problem can be mitigated by jointly training with maximum
likelihood and policy gradient. In particular, with policy learning we are able
to directly optimize on the (otherwise non-differentiable) performance metric.
We show that joint training improves relative performance by 4% to 13% for our
end-to-end model as compared to the same model learned through maximum
likelihood. The model achieves 5.53% WER on Wall Street Journal dataset, and
5.42% and 14.70% on Librispeech test-clean and test-other set, respectively.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07102</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Data-Dependent Random Features for Improved Generalization in
  Supervised Learning</dc:title>
 <dc:creator>Shahrampour, Shahin</dc:creator>
 <dc:creator>Beirami, Ahmad</dc:creator>
 <dc:creator>Tarokh, Vahid</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The randomized-feature approach has been successfully employed in large-scale
kernel approximation and supervised learning. The distribution from which the
random features are drawn impacts the number of features required to
efficiently perform a learning task. Recently, it has been shown that employing
data-dependent randomization improves the performance in terms of the required
number of random features. In this paper, we are concerned with the
randomized-feature approach in supervised learning for good generalizability.
We propose the Energy-based Exploration of Random Features (EERF) algorithm
based on a data-dependent score function that explores the set of possible
features and exploits the promising regions. We prove that the proposed score
function with high probability recovers the spectrum of the best fit within the
model class. Our empirical results on several benchmark datasets further verify
that our method requires smaller number of random features to achieve a certain
generalization error compared to the state-of-the-art while introducing
negligible pre-processing overhead. EERF can be implemented in a few lines of
code and requires no additional tuning parameters.
</dc:description>
 <dc:description>Comment: 12 pages; (pages 1-8) to appear in Proc. of AAAI Conference on
  Artificial Intelligence (AAAI), 2018</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07106</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring High-Dimensional Structure via Axis-Aligned Decomposition of
  Linear Projections</dc:title>
 <dc:creator>Thiagarajan, Jayaraman J.</dc:creator>
 <dc:creator>Liu, Shusen</dc:creator>
 <dc:creator>Ramamurthy, Karthikeyan Natesan</dc:creator>
 <dc:creator>Bremer, Peer-Timo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Two-dimensional embeddings remain the dominant approach to visualize high
dimensional data. The choice of embeddings ranges from highly non-linear ones,
which can capture complex relationships but are difficult to interpret
quantitatively, to axis-aligned projections, which are easy to interpret but
are limited to bivariate relationships. Linear project can be considered as a
compromise between complexity and interpretability, as they allow explicit axes
labels, yet provide significantly more degrees of freedom compared to
axis-aligned projections. Nevertheless, interpreting the axes directions, which
are linear combinations often with many non-trivial components, remains
difficult. To address this problem we introduce a structure aware decomposition
of (multiple) linear projections into sparse sets of axis aligned projections,
which jointly capture all information of the original linear ones. In
particular, we use tools from Dempster-Shafer theory to formally define how
relevant a given axis aligned project is to explain the neighborhood relations
displayed in some linear projection. Furthermore, we introduce a new approach
to discover a diverse set of high quality linear projections and show that in
practice the information of $k$ linear projections is often jointly encoded in
$\sim k$ axis aligned plots. We have integrated these ideas into an interactive
visualization system that allows users to jointly browse both linear
projections and their axis aligned representatives. Using a number of case
studies we show how the resulting plots lead to more intuitive visualizations
and new insight.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07107</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Examples: Attacks and Defenses for Deep Learning</dc:title>
 <dc:creator>Yuan, Xiaoyong</dc:creator>
 <dc:creator>He, Pan</dc:creator>
 <dc:creator>Zhu, Qile</dc:creator>
 <dc:creator>Bhat, Rajendra Rana</dc:creator>
 <dc:creator>Li, Xiaolin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  With rapid progress and great successes in a wide spectrum of applications,
deep learning is being applied in many safety-critical environments. However,
deep neural networks have been recently found vulnerable to well-designed input
samples, called \textit{adversarial examples}. Adversarial examples are
imperceptible to human but can easily fool deep neural networks in the
testing/deploying stage. The vulnerability to adversarial examples becomes one
of the major risks for applying deep neural networks in safety-critical
scenarios. Therefore, the attacks and defenses on adversarial examples draw
great attention.
  In this paper, we review recent findings on adversarial examples against deep
neural networks, summarize the methods for generating adversarial examples, and
propose a taxonomy of these methods. Under the taxonomy, applications and
countermeasures for adversarial examples are investigated. We further elaborate
on adversarial examples and explore the challenges and the potential solutions.
</dc:description>
 <dc:description>Comment: 21 pages, 13 figures, Github:
  https://github.com/chbrian/awesome-adversarial-examples-dl</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07108</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Regularization Techniques for End-to-End Speech Recognition</dc:title>
 <dc:creator>Zhou, Yingbo</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Regularization is important for end-to-end speech models, since the models
are highly flexible and easy to overfit. Data augmentation and dropout has been
important for improving end-to-end models in other domains. However, they are
relatively under explored for end-to-end speech models. Therefore, we
investigate the effectiveness of both methods for end-to-end trainable, deep
speech recognition models. We augment audio data through random perturbations
of tempo, pitch, volume, temporal alignment, and adding random noise.We further
investigate the effect of dropout when applied to the inputs of all layers of
the network. We show that the combination of data augmentation and dropout give
a relative performance improvement on both Wall Street Journal (WSJ) and
LibriSpeech dataset of over 20%. Our model performance is also competitive with
other end-to-end speech models on both datasets.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07113</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query-Efficient Black-box Adversarial Examples</dc:title>
 <dc:creator>Ilyas, Andrew</dc:creator>
 <dc:creator>Engstrom, Logan</dc:creator>
 <dc:creator>Athalye, Anish</dc:creator>
 <dc:creator>Lin, Jessy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Current neural network-based image classifiers are susceptible to adversarial
examples, even in the black-box setting, where the attacker is limited to query
access without access to gradients. Previous methods --- substitute networks
and coordinate-based finite-difference methods --- are either unreliable or
query-inefficient, making these methods impractical for certain problems.
  We introduce a new method for reliably generating adversarial examples under
more restricted, practical black-box threat models. First, we apply natural
evolution strategies to perform black-box attacks using two to three orders of
magnitude fewer queries than previous methods. Second, we introduce a new
algorithm to perform targeted adversarial attacks in the partial-information
setting, where the attacker only has access to a limited number of target
classes. Using these techniques, we successfully perform the first targeted
adversarial attack against a commercially deployed machine learning system, the
Google Cloud Vision API, in the partial information setting.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07116</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection and classification of masses in mammographic images in a
  multi-kernel approach</dc:title>
 <dc:creator>de Lima, Sidney Marlon Lopes</dc:creator>
 <dc:creator>Filho, Abel Guilhermino da Silva</dc:creator>
 <dc:creator>Santos, Wellington Pinheiro dos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  According to the World Health Organization, breast cancer is the main cause
of cancer death among adult women in the world. Although breast cancer occurs
indiscriminately in countries with several degrees of social and economic
development, among developing and underdevelopment countries mortality rates
are still high, due to low availability of early detection technologies. From
the clinical point of view, mammography is still the most effective diagnostic
technology, given the wide diffusion of the use and interpretation of these
images. Herein this work we propose a method to detect and classify
mammographic lesions using the regions of interest of images. Our proposal
consists in decomposing each image using multi-resolution wavelets. Zernike
moments are extracted from each wavelet component. Using this approach we can
combine both texture and shape features, which can be applied both to the
detection and classification of mammary lesions. We used 355 images of fatty
breast tissue of IRMA database, with 233 normal instances (no lesion), 72
benign, and 83 malignant cases. Classification was performed by using SVM and
ELM networks with modified kernels, in order to optimize accuracy rates,
reaching 94.11%. Considering both accuracy rates and training times, we defined
the ration between average percentage accuracy and average training time in a
reverse order. Our proposal was 50 times higher than the ratio obtained using
the best method of the state-of-the-art. As our proposed model can combine high
accuracy rate with low learning time, whenever a new data is received, our work
will be able to save a lot of time, hours, in learning process in relation to
the best method of the state-of-the-art.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07116</dc:identifier>
 <dc:identifier>Computer Methods and Programs in Biomedicine, 134 (2016), 11-29</dc:identifier>
 <dc:identifier>doi:10.1016/j.cmpb.2016.04.029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07120</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continual Prediction of Notification Attendance with Classical and Deep
  Network Approaches</dc:title>
 <dc:creator>Katevas, Kleomenis</dc:creator>
 <dc:creator>Leontiadis, Ilias</dc:creator>
 <dc:creator>Pielot, Martin</dc:creator>
 <dc:creator>Serr&#xe0;, Joan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We investigate to what extent mobile use patterns can predict -- at the
moment it is posted -- whether a notification will be clicked within the next
10 minutes. We use a data set containing the detailed mobile phone usage logs
of 279 users, who over the course of 5 weeks received 446,268 notifications
from a variety of apps. Besides using classical gradient-boosted trees, we
demonstrate how to make continual predictions using a recurrent neural network
(RNN). The two approaches achieve a similar AUC of ca. 0.7 on unseen users,
with a possible operation point of 50% sensitivity and 80% specificity
considering all notification types (an increase of 40% with respect to a
probabilistic baseline). These results enable automatic, intelligent handling
of mobile phone notifications without the need for user feedback or
personalization. Furthermore, they showcase how forego feature-extraction by
using RNNs for continual predictions directly on mobile usage logs. To the best
of our knowledge, this is the first work that leverages mobile sensor data for
continual, context-aware predictions of interruptibility using deep neural
networks.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07121</identifier>
 <datestamp>2018-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automata Minimization: a Functorial Approach</dc:title>
 <dc:creator>Colcombet, Thomas</dc:creator>
 <dc:creator>Petri&#x15f;an, Daniela</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  In this paper we regard languages and their acceptors - such as deterministic
or weighted automata, transducers, or monoids - as functors from input
categories that specify the type of the languages and of the machines to
categories that specify the type of outputs. Our results are as follows:
  A) We provide sufficient conditions on the output category so that
minimization of the corresponding automata is guaranteed.
  B) We show how to lift adjunctions between the categories for output values
to adjunctions between categories of automata.
  C) We show how this framework can be instantiated to unify several phenomena
in automata theory, starting with determinization, minimization and syntactic
algebras. We provide explanations of Choffrut's minimization algorithm for
subsequential transducers and of Brzozowski's minimization algorithm in this
setting.
</dc:description>
 <dc:description>Comment: submitted journal version of the CALCO 2017 paper arXiv:1711.03063</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07122</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time 3D Reconstruction on Construction Site using Visual SLAM and
  UAV</dc:title>
 <dc:creator>Shang, Zhexiong</dc:creator>
 <dc:creator>Shen, Zhigang</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3D reconstruction can be used as a platform to monitor the performance of
activities on construction site, such as construction progress monitoring,
structure inspection and post-disaster rescue. Comparing to other sensors, RGB
image has the advantages of low-cost, texture rich and easy to implement that
has been used as the primary method for 3D reconstruction in construction
industry. However, the image-based 3D reconstruction always requires extended
time to acquire and/or to process the image data, which limits its application
on time critical projects. Recent progress in Visual Simultaneous Localization
and Mapping (SLAM) make it possible to reconstruct a 3D map of construction
site in real-time. Integrated with Unmanned Aerial Vehicle (UAV), the obstacles
areas that are inaccessible for the ground equipment can also be sensed.
Despite these advantages of visual SLAM and UAV, until now, such technique has
not been fully investigated on construction site. Therefore, the objective of
this research is to present a pilot study of using visual SLAM and UAV for
real-time construction site reconstruction. The system architecture and the
experimental setup are introduced, and the preliminary results and the
potential applications using Visual SLAM and UAV on construction site are
discussed.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, conference paper submitted to CRC 2018</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07136</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Imprinted Weights</dc:title>
 <dc:creator>Qi, Hang</dc:creator>
 <dc:creator>Brown, Matthew</dc:creator>
 <dc:creator>Lowe, David G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human vision is able to immediately recognize novel visual categories after
seeing just one or a few training examples. We describe how to add a similar
capability to ConvNet classifiers by directly setting the final layer weights
from novel training examples during low-shot learning. We call this process
weight imprinting as it directly sets weights for a new category based on an
appropriately scaled copy of the embedding layer activations for that training
example. The imprinting process provides a valuable complement to training with
stochastic gradient descent, as it provides immediate good classification
performance and an initialization for any further fine-tuning in the future. We
show how this imprinting process is related to proxy-based embeddings. However,
it differs in that only a single imprinted weight vector is learned for each
novel category, rather than relying on a nearest-neighbor distance to training
instances as typically used with embedding methods. Our experiments show that
using averaging of imprinted weights provides better generalization than using
nearest-neighbor instance embeddings.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07143</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning for Vehicular Networks</dc:title>
 <dc:creator>Ye, Hao</dc:creator>
 <dc:creator>Liang, Le</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:creator>Kim, JoonBeom</dc:creator>
 <dc:creator>Lu, Lu</dc:creator>
 <dc:creator>Wu, May</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The emerging vehicular networks are expected to make everyday vehicular
operation safer, greener, and more efficient, and pave the path to autonomous
driving in the advent of the fifth generation (5G) cellular system. Machine
learning, as a major branch of artificial intelligence, has been recently
applied to wireless networks to provide a data-driven approach to solve
traditionally challenging problems. In this article, we review recent advances
in applying machine learning in vehicular networks and attempt to bring more
attention to this emerging area. After a brief overview of the major concept of
machine learning, we present some application examples of machine learning in
solving problems arising in vehicular networks. We finally discuss and
highlight several open issues that warrant further research.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures, 1 table, submitted to IEEE Vehicular Technology
  Magazine</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07148</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct Positioning with Channel Database Assistance</dc:title>
 <dc:creator>Mailaender, Laurence</dc:creator>
 <dc:creator>Molev-Shteiman, Arkady</dc:creator>
 <dc:creator>Qi, Xiao-Feng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  When we have knowledge of the positions of nearby walls and buildings,
estimating the source location becomes a very efficient way of characterizing
and estimating a radio channel. We consider localization performance with and
without this knowledge. We treat the multipath channel as a set of &quot;virtual
receivers&quot; whose positions can be pre-stored in a channel database. Using wall
knowledge, we develop a generalized MUSIC algorithm that treats the wall
reflection parameter as a nuisance variable. We compare this to a classic MVDR
direct positioning algorithm that lacks wall knowledge. In a simple scenario,
we find that lack of wall knowledge can increase location error by 7-100x,
depending on the number of antennas, SNR, and true reflection parameter.
Interestingly, as the number of antennas increases, the value of wall knowledge
decreases.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07149</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Massive MIMO Channel Estimation and Channel Database
  Assistance</dc:title>
 <dc:creator>Molev-Shteiman, Arkady</dc:creator>
 <dc:creator>Mailaender, Laurence</dc:creator>
 <dc:creator>Qi, Xiao-Feng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Due to the low per-antenna SNR and high signaling overhead, channel
estimation is a major bottleneck in Massive MIMO systems. Spatial constraints
can improve estimation performance by exploiting sparsity. Solutions exist for
far field - beam domain channel estimation based on angle of arrival
estimation. However, there is no equivalent solution for near field and
distributed MIMO spatial channel estimation. We present a solution- source
domain channel estimation- that is based on source location estimation. We
extend this to employ a &quot;Channel Database&quot; incorporating information about the
physical scattering environment into channel estimation. We present methods for
generation, storage and usage of the Channel Database to assist localization
and communication.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07161</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Block Coding for Efficient Beam Discovery in Millimeter Wave
  Communication Networks</dc:title>
 <dc:creator>Shabara, Yahia</dc:creator>
 <dc:creator>Koksal, C. Emre</dc:creator>
 <dc:creator>Ekici, Eylem</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The surge in mobile broadband data demands is expected to surpass the
available spectrum capacity below 6 GHz. This expectation has prompted the
exploration of millimeter wave (mm-wave) frequency bands as a candidate
technology for next generation wireless networks. However, numerous challenges
to deploying mm-wave communication systems, including channel estimation, need
to be met before practical deployments are possible. This work addresses the
mm-wave channel estimation problem and treats it as a beam discovery problem in
which locating beams with strong path reflectors is analogous to locating
errors in linear block codes. We show that a significantly small number of
measurements (compared to the original dimensions of the channel matrix) is
sufficient to reliably estimate the channel. We also show that this can be
achieved using a simple and energy-efficient transceiver architecture.
</dc:description>
 <dc:description>Comment: To appear in the proceedings of IEEE INFOCOM '18</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07165</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scale-invariant temporal history (SITH): optimal slicing of the past in
  an uncertain world</dc:title>
 <dc:creator>Spears, Tyler A.</dc:creator>
 <dc:creator>Jacques, Brandon G.</dc:creator>
 <dc:creator>Howard, Marc W.</dc:creator>
 <dc:creator>Sederberg, Per B.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In both the human brain and any general artificial intelligence (AI), a
representation of the past is necessary to predict the future. However, perfect
storage of all experiences is not possible. One possibility, utilized in many
applications, is to retain information about the past in a buffer. A limitation
of this approach is that although events in the buffer are represented with
perfect accuracy, the resources necessary to represent information at a
particular time scale go up rapidly. Here we present a neurally-plausible,
compressed, scale-free memory representation we call Scale-Invariant Temporal
History (SITH). This representation covers an exponentially large period of
time in the past at the cost of sacrificing temporal accuracy for events
further in the past. The form of this decay is scale-invariant and can be shown
to be optimal in that it is able to respond to worlds with a wide range of time
scales. We demonstrate the utility of this representation in learning to play a
simple video game. In this environment, SITH exhibits better learning
performance than a fixed-size buffer history representation. Whereas the buffer
performs well as long as the temporal dependencies can be represented within
the buffer, SITH performs well over a much larger range of time scales for the
same amount of resources. Finally, we discuss how the application of SITH,
along with other human-inspired models of cognition, could improve
reinforcement and machine learning algorithms in general.
</dc:description>
 <dc:description>Comment: Preprint for submission to Neural Computation. Submitted to Neural
  Computation for review on December 18, 2017. 16 pages long, 8 figures, 13
  references</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07168</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time deep hair matting on mobile devices</dc:title>
 <dc:creator>Levinshtein, Alex</dc:creator>
 <dc:creator>Chang, Cheng</dc:creator>
 <dc:creator>Phung, Edmund</dc:creator>
 <dc:creator>Kezele, Irina</dc:creator>
 <dc:creator>Guo, Wenzhangzhi</dc:creator>
 <dc:creator>Aarabi, Parham</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Augmented reality is an emerging technology in many application domains.
Among them is the beauty industry, where live virtual try-on of beauty products
is of great importance. In this paper, we address the problem of live hair
color augmentation. To achieve this goal, hair needs to be segmented quickly
and accurately. We show how a modified MobileNet CNN architecture can be used
to segment the hair in real-time. Instead of training this network using large
amounts of accurate segmentation data, which is difficult to obtain, we use
crowd sourced hair segmentation data. While such data is much simpler to
obtain, the segmentations there are noisy and coarse. Despite this, we show how
our system can produce accurate and fine-detailed hair mattes, while running at
over 30 fps on an iPad Pro tablet.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, submitted to CRV 2018</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07177</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Profile Maximum Likelihood</dc:title>
 <dc:creator>Pavlichin, Dmitri S.</dc:creator>
 <dc:creator>Jiao, Jiantao</dc:creator>
 <dc:creator>Weissman, Tsachy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose an efficient algorithm for approximate computation of the profile
maximum likelihood (PML), a variant of maximum likelihood maximizing the
probability of observing a sufficient statistic rather than the empirical
sample. The PML has appealing theoretical properties, but is difficult to
compute exactly. Inspired by observations gleaned from exactly solvable cases,
we look for an approximate PML solution, which, intuitively, clumps comparably
frequent symbols into one symbol. This amounts to lower-bounding a certain
matrix permanent by summing over a subgroup of the symmetric group rather than
the whole group during the computation. We extensively experiment with the
approximate solution, and find the empirical performance of our approach is
competitive and sometimes significantly better than state-of-the-art
performance for various estimation problems.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07182</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic lattice codes for linear fading channels</dc:title>
 <dc:creator>Luzzi, Laura</dc:creator>
 <dc:creator>Vehkalahti, Roope</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  In the decades following Shannon's work, the quest to design codes for the
additive white Gaussian noise (AWGN) channel led to the development of a rich
theory, revealing a number of beautiful connections between information theory
and geometry of numbers. One of the most striking examples is the connection
between classical lattice sphere packing and the capacity of the AWGN channel.
The main result states that any family of lattice codes with linearly growing
Hermite invariant achieves a constant gap to capacity. These classical results
and many more can be found in the comprehensive book by Conway and Sloane
[5].....
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07185</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Wasserstein Reinforcement Learning and the Fokker-Planck equation</dc:title>
 <dc:creator>Richemond, Pierre H.</dc:creator>
 <dc:creator>Maginnis, Brendan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Policy gradients methods often achieve better performance when the change in
policy is limited to a small Kullback-Leibler divergence. We derive policy
gradients where the change in policy is limited to a small Wasserstein distance
(or trust region). This is done in the discrete and continuous multi-armed
bandit settings with entropy regularisation. We show that in the small steps
limit with respect to the Wasserstein distance $W_2$, policy dynamics are
governed by the Fokker-Planck (heat) equation, following the
Jordan-Kinderlehrer-Otto result. This means that policies undergo diffusion and
advection, concentrating near actions with high reward. This helps elucidate
the nature of convergence in the probability matching setup, and provides
justification for empirical practices such as Gaussian policy priors and
additive gradient noise.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07194</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Y-net: 3D intracranial artery segmentation using a convolutional
  autoencoder</dc:title>
 <dc:creator>Chen, Li</dc:creator>
 <dc:creator>Xie, Yanjun</dc:creator>
 <dc:creator>Sun, Jie</dc:creator>
 <dc:creator>Balu, Niranjan</dc:creator>
 <dc:creator>Mossa-Basha, Mahmud</dc:creator>
 <dc:creator>Pimentel, Kristi</dc:creator>
 <dc:creator>Hatsukami, Thomas S.</dc:creator>
 <dc:creator>Hwang, Jenq-Neng</dc:creator>
 <dc:creator>Yuan, Chun</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated segmentation of intracranial arteries on magnetic resonance
angiography (MRA) allows for quantification of cerebrovascular features, which
provides tools for understanding aging and pathophysiological adaptations of
the cerebrovascular system. Using a convolutional autoencoder (CAE) for
segmentation is promising as it takes advantage of the autoencoder structure in
effective noise reduction and feature extraction by representing high
dimensional information with low dimensional latent variables. In this report,
an optimized CAE model (Y-net) was trained to learn a 3D segmentation model of
intracranial arteries from 49 cases of MRA data. The trained model was shown to
perform better than the three traditional segmentation methods in both binary
classification and visual evaluation.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, an improved version after accepted by IEEE
  International Conference on Bioinformatics and Biomedicine, Kansas City, MO,
  USA, November 13 - 16, 2017</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07195</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Regression Forests for Age Estimation</dc:title>
 <dc:creator>Shen, Wei</dc:creator>
 <dc:creator>Guo, Yilu</dc:creator>
 <dc:creator>Wang, Yan</dc:creator>
 <dc:creator>Zhao, Kai</dc:creator>
 <dc:creator>Wang, Bo</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Age estimation from facial images is typically cast as a nonlinear regression
problem. The main challenge of this problem is the facial feature space w.r.t.
ages is heterogeneous, due to the large variation in facial appearance across
different persons of the same age and the non-stationary property of aging
patterns. In this paper, we propose Deep Regression Forests (DRFs), an
end-to-end model, for age estimation. DRFs connect the split nodes to a fully
connected layer of a convolutional neural network (CNN) and deal with
heterogeneous data by jointly learning input-dependant data partitions at the
split nodes and data abstractions at the leaf nodes. This joint learning
follows an alternating strategy: First, by fixing the leaf nodes, the split
nodes as well as the CNN parameters are optimized by Back-propagation; Then, by
fixing the split nodes, the leaf nodes are optimized by iterating a step-size
free and fast-converging update rule derived from Variational Bounding. We
verify the proposed DRFs on three standard age estimation benchmarks and
achieve state-of-the-art results on all of them.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07196</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Calibrating Noise to Variance in Adaptive Data Analysis</dc:title>
 <dc:creator>Feldman, Vitaly</dc:creator>
 <dc:creator>Steinke, Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Datasets are often used multiple times and each successive analysis may
depend on the outcome of previous analyses. Standard techniques for ensuring
generalization and statistical validity do not account for this adaptive
dependence. A recent line of work studies the challenges that arise from such
adaptive data reuse by considering the problem of answering a sequence of
&quot;queries&quot; about the data distribution where each query may depend arbitrarily
on answers to previous queries.
  The strongest results obtained for this problem rely on differential privacy
-- a strong notion of algorithmic stability with the important property that it
&quot;composes&quot; well when data is reused. However the notion is rather strict, as it
requires stability under replacement of an arbitrary data element. The simplest
algorithm is to add Gaussian (or Laplace) noise to distort the empirical
answers. However, analysing this technique using differential privacy yields
suboptimal accuracy guarantees when the queries have low variance. Here we
propose a relaxed notion of stability that also composes adaptively. We
demonstrate that a simple and natural algorithm based on adding noise scaled to
the standard deviation of the query provides our notion of stability. This
implies an algorithm that can answer statistical queries about the dataset with
substantially improved accuracy guarantees for low-variance queries. The only
previous approach that provides such accuracy guarantees is based on a more
involved differentially private median-of-means algorithm and its analysis
exploits stronger &quot;group&quot; stability of the algorithm.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07199</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cognitive Database: A Step towards Endowing Relational Databases with
  Artificial Intelligence Capabilities</dc:title>
 <dc:creator>Bordawekar, Rajesh</dc:creator>
 <dc:creator>Bandyopadhyay, Bortik</dc:creator>
 <dc:creator>Shmueli, Oded</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose Cognitive Databases, an approach for transparently enabling
Artificial Intelligence (AI) capabilities in relational databases. A novel
aspect of our design is to first view the structured data source as meaningful
unstructured text, and then use the text to build an unsupervised neural
network model using a Natural Language Processing (NLP) technique called word
embedding. This model captures the hidden inter-/intra-column relationships
between database tokens of different types. For each database token, the model
includes a vector that encodes contextual semantic relationships. We seamlessly
integrate the word embedding model into existing SQL query infrastructure and
use it to enable a new class of SQL-based analytics queries called cognitive
intelligence (CI) queries. CI queries use the model vectors to enable complex
queries such as semantic matching, inductive reasoning queries such as
analogies, predictive queries using entities not present in a database, and,
more generally, using knowledge from external sources. We demonstrate unique
capabilities of Cognitive Databases using an Apache Spark based prototype to
execute inductive reasoning CI queries over a multi-modal database containing
text and images. We believe our first-of-a-kind system exemplifies using AI
functionality to endow relational databases with capabilities that were
previously very hard to realize in practice.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07203</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovery of Shifting Patterns in Sequence Classification</dc:title>
 <dc:creator>Jia, Xiaowei</dc:creator>
 <dc:creator>Khandelwal, Ankush</dc:creator>
 <dc:creator>Karpatne, Anuj</dc:creator>
 <dc:creator>Kumar, Vipin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we investigate the multi-variate sequence classification
problem from a multi-instance learning perspective. Real-world sequential data
commonly show discriminative patterns only at specific time periods. For
instance, we can identify a cropland during its growing season, but it looks
similar to a barren land after harvest or before planting. Besides, even within
the same class, the discriminative patterns can appear in different periods of
sequential data. Due to such property, these discriminative patterns are also
referred to as shifting patterns. The shifting patterns in sequential data
severely degrade the performance of traditional classification methods without
sufficient training data.
  We propose a novel sequence classification method by automatically mining
shifting patterns from multi-variate sequence. The method employs a
multi-instance learning approach to detect shifting patterns while also
modeling temporal relationships within each multi-instance bag by an LSTM model
to further improve the classification performance. We extensively evaluate our
method on two real-world applications - cropland mapping and affective state
recognition. The experiments demonstrate the superiority of our proposed method
in sequence classification performance and in detecting discriminative shifting
patterns.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07204</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object-Orientation in Graph-Based Design Grammars</dc:title>
 <dc:creator>Vogel, Samuel</dc:creator>
 <dc:creator>Arnold, Peter</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The ongoing digital transformation in industry applies to all product life
cycle's stages. The design decisions and dimensioning carried out in the early
conceptual design stages determine a huge part of the product's life cycle
costs (LCC). The automation of the conceptual design phase promises therefore
huge gains in terms of LCC. Design grammars encode design processes in
production systems made up of rule sequences which automatically create an
abstract central product model (central data model) from given requirements.
Graph-based design languages use the Unified-Modeling-Language (UML) to define
the product entities (classes) supporting object-oriented inheritance.
Graphical rules instantiate the classes and iteratively assemble the central
model. This paper proposes to extend the design languages by introducing
methods (operations). This allows the use of object-oriented design patterns
and interface mechanisms as object-oriented principles are then fully
implemented. A graphical mechanism to model the method calls is presented which
integrates seamlessly into the graph-based design language's graphical rule
specification. The object oriented design grammar enables modularization and
reusability of engineering knowledge. The integration of engineering domains is
enhanced and multistakeholder collaboration with access control (information
security) becomes feasible.
</dc:description>
 <dc:description>Comment: 16 pages; 14 figures; Preprint version</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07206</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating the computation of FLAPW methods on heterogeneous
  architectures</dc:title>
 <dc:creator>Davidovi&#x107;, Davor</dc:creator>
 <dc:creator>Fabregat-Traver, Diego</dc:creator>
 <dc:creator>H&#xf6;hnerbach, Markus</dc:creator>
 <dc:creator>di Napoli, Edoardo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Legacy codes in computational science and engineering have been very
successful in providing essential functionality to researchers. However, they
are not capable of exploiting the massive parallelism provided by emerging
heterogeneous architectures. The lack of portable performance and scalability
puts them at high risk: either they evolve or they are doomed to disappear. One
example of legacy code which would heavily benefit from a modern design is
FLEUR, a software for electronic structure calculations. In previous work, the
computational bottleneck of FLEUR was partially re-engineered to have a modular
design that relies on standard building blocks, namely BLAS and LAPACK. In this
paper, we demonstrate how the initial redesign enables the portability to
heterogeneous architectures. More specifically, we study different approaches
to port the code to architectures consisting of multi-core CPUs equipped with
one or more coprocessors such as Nvidia GPUs and Intel Xeon Phis. Our final
code attains over 70\% of the architectures' peak performance, and outperforms
Nvidia's and Intel's libraries. Finally, on JURECA, the supercomputer where
FLEUR is often executed, the code takes advantage of the full power of the
computing nodes, attaining $5\times$ speedup over the sole use of the CPUs.
</dc:description>
 <dc:description>Comment: 22 pages, submitted to special issue of CCPE</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07211</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Quantum Algorithm for Solving Multivariate Quadratic Equations</dc:title>
 <dc:creator>Faug`ere, Jean-Charles</dc:creator>
 <dc:creator>Horan, Kelsey</dc:creator>
 <dc:creator>Kahrobaei, Delaram</dc:creator>
 <dc:creator>Kaplan, Marc</dc:creator>
 <dc:creator>Kashefi, Elham</dc:creator>
 <dc:creator>Perret, Ludovic</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  In August 2015 the cryptographic world was shaken by a sudden and surprising
announcement by the US National Security Agency NSA concerning plans to
transition to post-quantum algorithms. Since this announcement post-quantum
cryptography has become a topic of primary interest for several standardization
bodies. The transition from the currently deployed public-key algorithms to
post-quantum algorithms has been found to be challenging in many aspects. In
particular the problem of evaluating the quantum-bit security of such
post-quantum cryptosystems remains vastly open. Of course this question is of
primarily concern in the process of standardizing the post-quantum
cryptosystems. In this paper we consider the quantum security of the problem of
solving a system of {\it $m$ Boolean multivariate quadratic equations in $n$
variables} (\MQb); a central problem in post-quantum cryptography. When $n=m$,
under a natural algebraic assumption, we present a Las-Vegas quantum algorithm
solving \MQb{} that requires the evaluation of, on average, $O(2^{0.462n})$
quantum gates. To our knowledge this is the fastest algorithm for solving
\MQb{}.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07217</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Feasibility of Wearable Exotendon Networks for Whole-Hand
  Movement Patterns in Stroke Patients</dc:title>
 <dc:creator>Park, Sangwoo</dc:creator>
 <dc:creator>Bishop, Lauri</dc:creator>
 <dc:creator>Post, Tara</dc:creator>
 <dc:creator>Xiao, Yuchen</dc:creator>
 <dc:creator>Stein, Joel</dc:creator>
 <dc:creator>Ciocarlie, Matei</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Fully wearable hand rehabilitation and assistive devices could extend
training and improve quality of life for patients affected by hand impairments.
However, such devices must deliver meaningful manipulation capabilities in a
small and lightweight package. In this context, this paper investigates the
capability of single-actuator devices to assist whole-hand movement patterns
through a network of exotendons. Our prototypes combine a single linear
actuator (mounted on a forearm splint) with a network of exotendons (routed on
the surface of a soft glove). We investigated two possible tendon network
configurations: one that produces full finger extension (overcoming flexor
spasticity), and one that combines proximal flexion with distal extension at
each finger. In experiments with stroke survivors, we measured the force levels
needed to overcome various levels of spasticity and open the hand for grasping
using the first of these configurations, and qualitatively demonstrated the
ability to execute fingertip grasps using the second. Our results support the
feasibility of developing future wearable devices able to assist a range of
manipulation tasks.
</dc:description>
 <dc:description>Comment: Appeared at the 2016 IEEE Intl. Conf. on Robotics and Automation</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07221</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Practical File Packetizations in Wireless Device-to-Device
  Caching Networks</dc:title>
 <dc:creator>Woolsey, Nicholas</dc:creator>
 <dc:creator>Chen, Rong-Rong</dc:creator>
 <dc:creator>Ji, Mingyue</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider wireless device-to-device (D2D) caching networks with single-hop
transmissions. Previous work has demonstrated that caching and coded
multicasting can significantly increase per user throughput. However, the
state-of-the-art coded caching schemes for D2D networks are generally
impractical because content files are partitioned into an exponential number of
packets with respect to the number of users if both library and memory sizes
are fixed. In this paper, we present two novel combinatorial approaches to
coded caching design in D2D networks with the goal of reducing the required
packetization while keeping the desired throughput gain compared to the
conventional uncoded unicasting. The first proposed approach is based on a
novel &quot;hypercube&quot; design, where each user caches a &quot;hyperplane&quot; in this
hypercube and the intersections of &quot;hyperplanes&quot; lead to coded multicasting
codewords. In addition, we also extend this centralized scheme to a
decentralized design. The second approach uses the Ruzsa-Szemeredi graph to
define the cache placement and disjoint matchings on this graph represent coded
multicasting opportunities. Both approaches yield an exponential reduction of
packetizations with respect to the number of users while providing a per-user
throughput that is comparable to the state-of-the-art designs in the
literature. Furthermore, by using the spatial reuse in D2D networks, besides
further reducing the required packetizations, we demonstrate that the per user
throughput can be improved significantly for some parameter regimes.
</dc:description>
 <dc:description>Comment: 30 pages, 5 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07222</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Codes Correcting Two Deletions</dc:title>
 <dc:creator>Gabrys, Ryan</dc:creator>
 <dc:creator>Sala, Frederic</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we investigate the problem of constructing codes capable of
correcting two deletions. In particular, we construct a code that requires
redundancy approximately 8 log n + O(log log n) bits of redundancy, where n is
the length of the code. To the best of the author's knowledge, this represents
the best known construction in that it requires the lowest number of redundant
bits for a code correcting two deletions.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07223</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical Comparison of Leja and Clenshaw-Curtis Dimension-Adaptive
  Collocation for Stochastic Parametric Electromagnetic Field Problems</dc:title>
 <dc:creator>Loukrezis, Dimitrios</dc:creator>
 <dc:creator>R&#xf6;mer, Ulrich</dc:creator>
 <dc:creator>De Gersem, Herbert</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We consider the problem of approximating the output of a parametric
electromagnetic field model in the presence of a large number of uncertain
input parameters. Given a sufficiently smooth output with respect to the input
parameters, such problems are often tackled with interpolation-based
approaches, such as the stochastic collocation method on tensor-product or
isotropic sparse grids. Due to the so-called curse of dimensionality, those
approaches result in increased or even forbidding computational costs. In order
to reduce the growth in complexity with the number of dimensions, we employ a
dimension-adaptive, hierarchical interpolation scheme, based on nested
univariate interpolation nodes. Clenshaw-Curtis and Leja nodes satisfy the
nestedness property and have been found to provide accurate interpolations when
the parameters follow uniform distributions. The dimension-adaptive algorithm
constructs the approximation based on the observation that not all parameters
or interactions among them are equally important regarding their impact on the
model's output. Our goal is to exploit this anisotropy in order to construct
accurate polynomial surrogate models at a reduced computational cost compared
to isotropic sparse grids. We apply the stochastic collocation method to two
electromagnetic field models with medium- to high-dimensional input
uncertainty. The performances of isotropic and adaptively constructed,
anisotropic sparse grids based on both Clenshaw-Curtis and Leja interpolation
nodes are examined. All considered approaches are compared with one another
regarding the surrogate models' approximation accuracies using a
cross-validation error metric.
</dc:description>
 <dc:description>Comment: 20 pages, 6 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07229</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attentive Memory Networks: Efficient Machine Reading for Conversational
  Search</dc:title>
 <dc:creator>Kenter, Tom</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent advances in conversational systems have changed the search paradigm.
Traditionally, a user poses a query to a search engine that returns an answer
based on its index, possibly leveraging external knowledge bases and
conditioning the response on earlier interactions in the search session. In a
natural conversation, there is an additional source of information to take into
account: utterances produced earlier in a conversation can also be referred to
and a conversational IR system has to keep track of information conveyed by the
user during the conversation, even if it is implicit.
  We argue that the process of building a representation of the conversation
can be framed as a machine reading task, where an automated system is presented
with a number of statements about which it should answer questions. The
questions should be answered solely by referring to the statements provided,
without consulting external knowledge. The time is right for the information
retrieval community to embrace this task, both as a stand-alone task and
integrated in a broader conversational search setting.
  In this paper, we focus on machine reading as a stand-alone task and present
the Attentive Memory Network (AMN), an end-to-end trainable machine reading
algorithm. Its key contribution is in efficiency, achieved by having an
hierarchical input encoder, iterating over the input only once. Speed is an
important requirement in the setting of conversational search, as gaps between
conversational turns have a detrimental effect on naturalness. On 20 datasets
commonly used for evaluating machine reading algorithms we show that the AMN
achieves performance comparable to the state-of-the-art models, while using
considerably fewer computations.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07229</dc:identifier>
 <dc:identifier>Proceedings of 1st International Workshop on Conversational
  Approaches to Information Retrieval, Tokyo, Japan, August 11, 2017 (CAIR'17)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07230</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fusing Multifaceted Transaction Data for User Modeling and Demographic
  Prediction</dc:title>
 <dc:creator>Resheff, Yehezkel S.</dc:creator>
 <dc:creator>Shahar, Moni</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Inferring user characteristics such as demographic attributes is of the
utmost importance in many user-centric applications. Demographic data is an
enabler of personalization, identity security, and other applications. Despite
that, this data is sensitive and often hard to obtain. Previous work has shown
that purchase history can be used for multi-task prediction of many demographic
fields such as gender and marital status. Here we present an embedding based
method to integrate multifaceted sequences of transaction data, together with
auxiliary relational tables, for better user modeling and demographic
prediction.
</dc:description>
 <dc:description>Comment: IFUP 2018 (WSDM workshop)</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07233</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperparameters Optimization in Deep Convolutional Neural Network /
  Bayesian Approach with Gaussian Process Prior</dc:title>
 <dc:creator>Murugan, Pushparaja</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Convolutional Neural Network is known as ConvNet have been extensively used
in many complex machine learning tasks. However, hyperparameters optimization
is one of a crucial step in developing ConvNet architectures, since the
accuracy and performance are reliant on the hyperparameters. This multilayered
architecture parameterized by a set of hyperparameters such as the number of
convolutional layers, number of fully connected dense layers &amp; neurons, the
probability of dropout implementation, learning rate. Hence the searching the
hyperparameter over the hyperparameter space are highly difficult to build such
complex hierarchical architecture. Many methods have been proposed over the
decade to explore the hyperparameter space and find the optimum set of
hyperparameter values. Reportedly, Gird search and Random search are said to be
inefficient and extremely expensive, due to a large number of hyperparameters
of the architecture. Hence, Sequential model-based Bayesian Optimization is a
promising alternative technique to address the extreme of the unknown cost
function. The recent study on Bayesian Optimization by Snoek in nine
convolutional network parameters is achieved the lowerest error report in the
CIFAR-10 benchmark. This article is intended to provide the overview of the
mathematical concept behind the Bayesian Optimization over a Gaussian prior.
</dc:description>
 <dc:description>Comment: 10 Pages</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07242</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Time Clustering for High Dimensional Mixtures of Gaussian Clouds</dc:title>
 <dc:creator>Kushnir, Dan</dc:creator>
 <dc:creator>Jalali, Shirin</dc:creator>
 <dc:creator>Saniee, Iraj</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Clustering mixtures of Gaussian distributions is a fundamental and
challenging problem that is ubiquitous in various high-dimensional data
processing tasks. In this paper, we propose a novel and efficient clustering
algorithm for $n$ points drawn from a mixture of two Gaussian distributions in
$\mathbb{R}^p$. The algorithm involves performing random 1-dimensional
projections until a direction is found that yields the user-specified
clustering error $e$. For a 1-dimensional separability parameter $\gamma$
satisfying $\gamma=Q^{-1}(e)$, the expected number of such projections is shown
to be bounded by $o(\log p)$, when $\gamma$ satisfies $\gamma\leq
c\log{\log{p}}$, with $c$ as the separability parameter of the two Gaussians in
$\mathbb{R}^p$. It is shown that the square of the 1-dimensional separability
resulting from a random projection is in expectation equal to $c^2$, thus
guaranteeing a small number of projections in realistic scenarios.
Consequently, the expected overall running time of the algorithm is linear in
$n$ and quasi-linear in $p$. This result stands in contrast to prior works
which learn the parameters of the Gaussian mixture model and provide polynomial
or at-best quadratic running time in $p$ and $n$. The new scheme is
particularly appealing in the challenging setup where the ambient dimension of
the data, $p$, is very large and yet the number of sample points, $n$, is small
or of the same order as $p$. We show that the bound on the expected number of
1-dimensional projections extends to the case of three or more Gaussian mixture
distributions. Finally, we validate these results with numerical experiments in
which the proposed algorithm is shown to perform within the prescribed accuracy
and running time bounds.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07246</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Further limitations of the known approaches for matrix multiplication</dc:title>
 <dc:creator>Alman, Josh</dc:creator>
 <dc:creator>Williams, Virginia Vassilevska</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the techniques behind the current best algorithms for matrix
multiplication. Our results are threefold.
  (1) We provide a unifying framework, showing that all known matrix
multiplication running times since 1986 can be achieved from a single very
natural tensor - the structural tensor $T_q$ of addition modulo an integer $q$.
  (2) We show that if one applies a generalization of the known techniques
(arbitrary zeroing out of tensor powers to obtain independent matrix products
in order to use the asymptotic sum inequality of Sch\&quot;{o}nhage) to an arbitrary
monomial degeneration of $T_q$, then there is an explicit lower bound,
depending on $q$, on the bound on the matrix multiplication exponent $\omega$
that one can achieve. We also show upper bounds on the value $\alpha$ that one
can achieve, where $\alpha$ is such that $n\times n^\alpha \times n$ matrix
multiplication can be computed in $n^{2+o(1)}$ time.
  (3) We show that our lower bound on $\omega$ approaches $2$ as $q$ goes to
infinity. This suggests a promising approach to improving the bound on
$\omega$: for variable $q$, find a monomial degeneration of $T_q$ which, using
the known techniques, produces an upper bound on $\omega$ as a function of $q$.
Then, take $q$ to infinity. It is not ruled out, and hence possible, that one
can obtain $\omega=2$ in this way.
</dc:description>
 <dc:description>Comment: 16 pages. To appear in 9th Innovations in Theoretical Computer
  Science Conference (ITCS 2018)</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07249</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Learning from Demonstration Approach fusing Torque Controllers</dc:title>
 <dc:creator>Silv&#xe9;rio, Jo&#xe3;o</dc:creator>
 <dc:creator>Huang, Yanlong</dc:creator>
 <dc:creator>Rozo, Leonel</dc:creator>
 <dc:creator>Calinon, Sylvain</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Torque controllers have become commonplace in the new generation of robots,
allowing for complex robot motions involving physical contact with the
surroundings in addition to task constraints at Cartesian and joint levels.
When learning such skills from demonstrations, one is often required to think
in advance about the appropriate task representation (usually either
operational or configuration space). We here propose a probabilistic approach
for simultaneously learning and synthesizing control commands which take into
account task, joint space and force constraints. We treat the problem by
considering different torque controllers acting on the robot, whose relevance
is learned from demonstrations. This information is used to combine the
controllers by exploiting the properties of Gaussian distributions, generating
torque commands that satisfy the important features of the task. We validate
the approach in two experimental scenarios using 7-DoF torque-controlled
manipulators, with tasks requiring the fusion of multiple controllers to be
properly executed.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07257</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-shot Pedestrian Re-identification via Sequential Decision Making</dc:title>
 <dc:creator>Zhang, Jianfu</dc:creator>
 <dc:creator>Wang, Naiyan</dc:creator>
 <dc:creator>Zhang, Liqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Multi-shot pedestrian re-identification problem is at the core of
surveillance video analysis. It matches two tracks of pedestrians from
different cameras. In contrary to existing works that aggregate single frames
features by time series model such as recurrent neural network, in this paper,
we propose an interpretable reinforcement learning based approach to this
problem. Particularly, we train an agent to verify a pair of images at each
time. The agent could choose to output the result (same or different) or
request another pair of images to see (unsure). By this way, our model
implicitly learns the difficulty of image pairs, and postpone the decision when
the model does not accumulate enough evidence. Moreover, by adjusting the
reward for unsure action, we can easily trade off between speed and accuracy.
In three open benchmarks, our method are competitive with the state-of-the-art
methods while only using 3% to 6% images. These promising results demonstrate
that our method is favorable in both efficiency and performance.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07262</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FoldingNet: Interpretable Unsupervised Learning on 3D Point Clouds</dc:title>
 <dc:creator>Yang, Yaoqing</dc:creator>
 <dc:creator>Feng, Chen</dc:creator>
 <dc:creator>Shen, Yiru</dc:creator>
 <dc:creator>Tian, Dong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent deep networks that directly handle points in a point set, e.g.,
PointNet, have been state-of-the-art for supervised semantic learning tasks on
point clouds such as classification and segmentation. In this work, a novel
end-to-end deep auto-encoder is proposed to address unsupervised learning
challenges on point clouds. On the encoder side, a graph-based enhancement is
enforced to promote local structures on top of PointNet. Then, a novel
folding-based approach is proposed in the decoder, which folds a 2D grid onto
the underlying 3D object surface of a point cloud. The proposed decoder only
uses about 7\% parameters of a decoder with fully-connected neural networks,
yet leads to a more discriminative representation that achieves higher linear
SVM classification accuracy than the benchmark. In addition, the proposed
decoder structure is shown, in theory, to be a generic architecture that is
able to reconstruct an arbitrary point cloud from a 2D grid. Finally, this
folding-based decoder is interpretable since the reconstruction could be viewed
as a fine granular warping from the 2D grid to the point cloud surface.
</dc:description>
 <dc:description>Comment: submitted</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07269</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind High Dynamic Range Quality estimation by disentangling perceptual
  and noise features in images</dc:title>
 <dc:creator>Kottayil, Navaneeth Kamballur</dc:creator>
 <dc:creator>Valenzise, Giuseppe</dc:creator>
 <dc:creator>Dufaux, Frederic</dc:creator>
 <dc:creator>Cheng, Irene</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Assessing the visual quality of High Dynamic Range (HDR) images is an
unexplored and an interesting research topic that has become relevant with the
current boom in HDR technology. We propose a new convolutional neural network
based model for No reference image quality assessment(NR-IQA) on HDR data. This
model predicts the amount and location of noise, perceptual influence of image
pixels on the noise, and the perceived quality, of a distorted image without
any reference image. The proposed model extracts numerical values corresponding
to the noise present in any given distorted image, and the perceptual effects
exhibited by a human eye when presented with the same. These two measures are
extracted separately yet sequentially and combined in a mixing function to
compute the quality of the distorted image perceived by a human eye. Our
training process derives the the component that computes perceptual effects
from a real world image quality dataset, rather than using results of
psycovisual experiments. With the proposed model, we demonstrate state of the
art performance for HDR NR-IQA and our results show performance similar to HDR
Full Reference Image Quality Assessment algorithms (FR-IQA).
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07269</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2778570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07271</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Sight from Sound: Ambient Sound Provides Supervision for Visual
  Learning</dc:title>
 <dc:creator>Owens, Andrew</dc:creator>
 <dc:creator>Wu, Jiajun</dc:creator>
 <dc:creator>McDermott, Josh H.</dc:creator>
 <dc:creator>Freeman, William T.</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The sound of crashing waves, the roar of fast-moving cars -- sound conveys
important information about the objects in our surroundings. In this work, we
show that ambient sounds can be used as a supervisory signal for learning
visual models. To demonstrate this, we train a convolutional neural network to
predict a statistical summary of the sound associated with a video frame. We
show that, through this process, the network learns a representation that
conveys information about objects and scenes. We evaluate this representation
on several recognition tasks, finding that its performance is comparable to
that of other state-of-the-art unsupervised learning methods. Finally, we show
through visualizations that the network learns units that are selective to
objects that are often associated with characteristic sounds. This paper
extends an earlier conference paper, Owens et al. 2016, with additional
experiments and discussion.
</dc:description>
 <dc:description>Comment: Journal preprint of arXiv:1608.07017 (unpublished submission to IJCV)</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07276</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform Diagonalization Theorem for Complexity Classes of Promise
  Problems including Randomized and Quantum Classes</dc:title>
 <dc:creator>Dziemba, Friederike Anna</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Diagonalization in the spirit of Cantor's diagonal arguments is a widely used
tool in theoretical computer sciences to obtain structural results about
computational problems and complexity classes by indirect proofs. The Uniform
Diagonalization Theorem allows the construction of problems outside complexity
classes while still being reducible to a specific decision problem. This paper
provides a generalization of the Uniform Diagonalization Theorem by extending
it to promise problems and the complexity classes they form, e.g. randomized
and quantum complexity classes. The theorem requires from the underlying
computing model not only the decidability of its acceptance and rejection
behaviour but also of its promise-contradicting indifferent behaviour - a
property that we will introduce as &quot;total decidability&quot; of promise problems.
  Implications of the Uniform Diagonalization Theorem are mainly of two kinds:
1. Existence of intermediate problems (e.g. between BQP and QMA) - also known
as Ladner's Theorem - and 2. Undecidability if a problem of a complexity class
is contained in a subclass (e.g. membership of a QMA-problem in BQP). Like the
original Uniform Diagonalization Theorem the extension applies besides BQP and
QMA to a large variety of complexity class pairs, including combinations from
deterministic, randomized and quantum classes.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07286</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LVreID: Person Re-Identification with Long Sequence Videos</dc:title>
 <dc:creator>Li, Jianing</dc:creator>
 <dc:creator>Zhang, Shiliang</dc:creator>
 <dc:creator>Wang, Jingdong</dc:creator>
 <dc:creator>Gao, Wen</dc:creator>
 <dc:creator>Tian, Qi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper mainly establishes a large-scale Long sequence Video database for
person re-IDentification (LVreID). Different from existing datasets, LVreID
presents many important new features. (1) long sequences: the average sequence
length is 200 frames, which convey more abundant cues like pose and viewpoint
changes that can be explored for feature learning. (2) complex lighting, scene,
and background variations: it is captured by 15 cameras located in both indoor
and outdoor scenes in 12 time slots. (3) currently the largest size: it
contains 3,772 identities and about 3 million bounding boxes. Those unique
features in LVreID define a more challenging and realistic person ReID task.
Spatial Aligned Temporal Pyramid Pooling (SATPP) network is proposed as a
baseline algorithm to leverage the rich visual-temporal cues in LVreID for
feature learning. SATPP jointly handles the misalignment issues in detected
bounding boxes and efficiently aggregates the discriminative cues embedded in
sequential video frames. Extensive experiments show feature extracted by SATPP
outperforms several widely used video features. Our experiments also prove the
ReID accuracy increases substantially along with longer sequence length. This
demonstrates the advantage and necessity of using longer video sequences for
person ReID.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07294</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical and Interpretable Skill Acquisition in Multi-task
  Reinforcement Learning</dc:title>
 <dc:creator>Shu, Tianmin</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Learning policies for complex tasks that require multiple different skills is
a major challenge in reinforcement learning (RL). It is also a requirement for
its deployment in real-world scenarios. This paper proposes a novel framework
for efficient multi-task reinforcement learning. Our framework trains agents to
employ hierarchical policies that decide when to use a previously learned
policy and when to learn a new skill. This enables agents to continually
acquire new skills during different stages of training. Each learned task
corresponds to a human language description. Because agents can only access
previously learned skills through these descriptions, the agent can always
provide a human-interpretable description of its choices. In order to help the
agent learn the complex temporal dependencies necessary for the hierarchical
policy, we provide it with a stochastic temporal grammar that modulates when to
rely on previously learned skills and when to execute new skills. We validate
our approach on Minecraft games designed to explicitly test the ability to
reuse previously learned skills while simultaneously learning new skills.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07296</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Block-diagonal Hessian-free Optimization for Training Neural Networks</dc:title>
 <dc:creator>Zhang, Huishuai</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Bradbury, James</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Second-order methods for neural network optimization have several advantages
over methods based on first-order gradient descent, including better scaling to
large mini-batch sizes and fewer updates needed for convergence. But they are
rarely applied to deep learning in practice because of high computational cost
and the need for model-dependent algorithmic variations. We introduce a variant
of the Hessian-free method that leverages a block-diagonal approximation of the
generalized Gauss-Newton matrix. Our method computes the curvature
approximation matrix only for pairs of parameters from the same layer or block
of the neural network and performs conjugate gradient updates independently for
each block. Experiments on deep autoencoders, deep convolutional networks, and
multilayer LSTMs demonstrate better convergence and generalization compared to
the original Hessian-free approach and the Adam method.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07297</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A distributed-memory hierarchical solver for general sparse linear
  systems</dc:title>
 <dc:creator>Chen, Chao</dc:creator>
 <dc:creator>Pouransari, Hadi</dc:creator>
 <dc:creator>Rajamanickam, Sivasankaran</dc:creator>
 <dc:creator>Boman, Erik G.</dc:creator>
 <dc:creator>Darve, Eric</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65F50</dc:subject>
 <dc:description>  We present a parallel hierarchical solver for general sparse linear systems
on distributed-memory machines. For large-scale problems, this fully algebraic
algorithm is faster and more memory-efficient than sparse direct solvers
because it exploits the low-rank structure of fill-in blocks. Depending on the
accuracy of low-rank approximations, the hierarchical solver can be used either
as a direct solver or as a preconditioner. The parallel algorithm is based on
data decomposition and requires only local communication for updating boundary
data on every processor. Moreover, the computation-to-communication ratio of
the parallel algorithm is approximately the volume-to-surface-area ratio of the
subdomain owned by every processor. We present various numerical results to
demonstrate the versatility and scalability of the parallel algorithm.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07299</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-efficient Hybrid CMOS-NEMS LIF Neuron Circuit in 28 nm CMOS
  Process</dc:title>
 <dc:creator>Moradi, Saber</dc:creator>
 <dc:creator>Bhave, Sunil A.</dc:creator>
 <dc:creator>Manohar, Rajit</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Designing analog sub-threshold neuromorphic circuits in deep sub-micron
technologies e.g. 28 nm can be a daunting task due to the problem of excessive
leakage current. We propose novel energy-efficient hybrid CMOS-nano
electro-mechanical switches (NEMS) Leaky Integrate and Fire (LIF) neuron and
synapse circuits and investigate the impact of NEM switches on the leakage
power and overall energy consumption. We analyze the performance of
biologically-inspired neuron circuit in terms of leakage power consumption and
present new energy-efficient neural circuits that operate with biologically
plausible firing rates. Our results show the proposed CMOS-NEMS neuron circuit
is, on average, 35% more energy-efficient than its CMOS counterpart with same
complexity in 28 nm process. Moreover, we discuss how NEM switches can be
utilized to further improve the scalability of mixed-signal neuromorphic
circuits.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07300</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plug-in Electric Vehicle Charging Congestion Analysis Using Taxi Travel
  Data in the Central Area of Beijing</dc:title>
 <dc:creator>Chen, Huimiao</dc:creator>
 <dc:creator>Zhang, Hongcai</dc:creator>
 <dc:creator>Hu, Zechun</dc:creator>
 <dc:creator>Liang, Yunyi</dc:creator>
 <dc:creator>Luo, Haocheng</dc:creator>
 <dc:creator>Wang, Yinhai</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Recharging a plug-in electric vehicle is more time-consuming than refueling
an internal combustion engine vehicle. As a result, charging stations may face
serious congestion problems during peak traffic hours in the near future with
the rapid growth of plug-in electric vehicle population. Considering that
drivers' time costs are usually expensive, charging congestion will be a
dominant factor that affect a charging station's quality of service. Hence, it
is indispensable to conduct adequate congestion analysis when designing
charging stations in order to guarantee acceptable quality of service in the
future. This paper proposes a data-driven approach for charging congestion
analysis of plug-in electric vehicle charging stations. Based on a data-driven
plug-in electric vehicle charging station planning model, we adopt the queuing
theory to model and analyze the charging congestion phenomenon in these
planning results. We simulate and analyze the proposed method for charging
stations servicing shared-use electric taxis in the central area of Beijing
leveraging real-world taxi travel data.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07305</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting the Master-Slave Architecture in Multi-Agent Deep
  Reinforcement Learning</dc:title>
 <dc:creator>Kong, Xiangyu</dc:creator>
 <dc:creator>Xin, Bo</dc:creator>
 <dc:creator>Liu, Fangchen</dc:creator>
 <dc:creator>Wang, Yizhou</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Many tasks in artificial intelligence require the collaboration of multiple
agents. We exam deep reinforcement learning for multi-agent domains. Recent
research efforts often take the form of two seemingly conflicting perspectives,
the decentralized perspective, where each agent is supposed to have its own
controller; and the centralized perspective, where one assumes there is a
larger model controlling all agents. In this regard, we revisit the idea of the
master-slave architecture by incorporating both perspectives within one
framework. Such a hierarchical structure naturally leverages advantages from
one another. The idea of combining both perspectives is intuitive and can be
well motivated from many real world systems, however, out of a variety of
possible realizations, we highlights three key ingredients, i.e. composed
action representation, learnable communication and independent reasoning. With
network designs to facilitate these explicitly, our proposal consistently
outperforms latest competing methods both in synthetic experiments and when
applied to challenging StarCraft micromanagement tasks.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07307</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Cache Design under Stationary Requests: Challenges, Algorithms
  and Experiments</dc:title>
 <dc:creator>Panigrahy, Nitish K.</dc:creator>
 <dc:creator>Li, Jian</dc:creator>
 <dc:creator>Towsley, Don</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The design of caching algorithms to maximize hit probability has been
extensively studied. However, the value of high hit probabilities can vary
across contents due to differential service requirements. In this paper, we
associate each content with a utility, which is a function of the corresponding
content hit rate or hit probability. We formulate a cache optimization problem
to maximize the sum of utilities over all contents under stationary and ergodic
request process, which is non-convex in general. We find that the problem can
be reformulated as a convex optimization problem if the inter-request
distribution has a non-increasing hazard rate function. We provide explicit
optimal solutions for some inter-request distributions, and compare the
solutions to the hit-rate based (HRB) and hit-probability based (HPB) problems.
We also propose distributed algorithms that not only can adapt to changes in
the system with limited information but also provide solutions in a
decentralized way. We find that distributed algorithms that solve HRB are more
robust than distributed HPB algorithms. Informed by these results, we further
propose a lightweight Poisson approximate online algorithm, which is accurate
and efficient in achieving exact hit rates and hit probabilities, and also
improves the aggregate utilities.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07308</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpolatory Model Reduction of Parameterized Bilinear Dynamical
  Systems</dc:title>
 <dc:creator>Rodriguez, Andrea Carracedo</dc:creator>
 <dc:creator>Gugercin, Serkan</dc:creator>
 <dc:creator>Borggaard, Jeff</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Interpolatory projection methods for model reduction of nonparametric linear
dynamical systems have been successfully extended to nonparametric bilinear
dynamical systems. However, this is not the case for parametric bilinear
systems. In this work, we aim to close this gap by providing a natural
extension of interpolatory projections to model reduction of parametric
bilinear dynamical systems. We introduce necessary conditions that the
projection subspaces must satisfy to obtain parametric tangential interpolation
of each subsystem transfer function. These conditions also guarantee that the
parameter sensitivities (Jacobian) of each subsystem transfer function is
matched tangentially by those of the corresponding reduced order model transfer
function. Similarly, we obtain conditions for interpolating the parameter
Hessian of the transfer function by including extra vectors in the projection
subspaces. As in the parametric linear case, the basis construction for
two-sided projections does not require computing the Jacobian or the Hessian.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07312</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of supervised and semi-supervised GrowCut applied to
  segmentation of masses in mammography images</dc:title>
 <dc:creator>Cordeiro, Filipe Rolim</dc:creator>
 <dc:creator>Santos, Wellington Pinheiro dos</dc:creator>
 <dc:creator>Filho, Abel Guilhermino da Silva</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Breast cancer is already one of the most common form of cancer worldwide.
Mammography image analysis is still the most effective diagnostic method to
promote the early detection of breast cancer. Accurately segmenting tumors in
digital mammography images is important to improve diagnosis capabilities of
health specialists and avoid misdiagnosis. In this work, we evaluate the
feasibility of applying GrowCut to segment regions of tumor and we propose two
GrowCut semi-supervised versions. All the analysis was performed by evaluating
the application of segmentation techniques to a set of images obtained from the
Mini-MIAS mammography image database. GrowCut segmentation was compared to
Region Growing, Active Contours, Random Walks and Graph Cut techniques.
Experiments showed that GrowCut, when compared to the other techniques, was
able to acquire better results for the metrics analyzed. Moreover, the proposed
semi-supervised versions of GrowCut was proved to have a clinically
satisfactory quality of segmentation.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07312</dc:identifier>
 <dc:identifier>Computer Methods in Biomechanics and Biomedical Engineering:
  Imaging &amp; Visualization, v. 5, p. 1-19, 2017</dc:identifier>
 <dc:identifier>doi:10.1080/21681163.2015.1127775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07315</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rhythmic Representations: Learning Periodic Patterns for Scalable Place
  Recognition at a Sub-Linear Storage Cost</dc:title>
 <dc:creator>Yu, Litao</dc:creator>
 <dc:creator>Jacobson, Adam</dc:creator>
 <dc:creator>Milford, Michael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robotic and animal mapping systems share many challenges and characteristics:
they must function in a wide variety of environmental conditions, enable the
robot or animal to navigate effectively to find food or shelter, and be
computationally tractable from both a speed and storage perspective. With
regards to map storage, the mammalian brain appears to take a diametrically
opposed approach to all current robotic mapping systems. Where robotic mapping
systems attempt to solve the data association problem to minimise
representational aliasing, neurons in the brain intentionally break data
association by encoding large (potentially unlimited) numbers of places with a
single neuron. In this paper, we propose a novel method based on supervised
learning techniques that seeks out regularly repeating visual patterns in the
environment with mutually complementary co-prime frequencies, and an encoding
scheme that enables storage requirements to grow sub-linearly with the size of
the environment being mapped. To improve robustness in challenging real-world
environments while maintaining storage growth sub-linearity, we incorporate
both multi-exemplar learning and data augmentation techniques. Using large
benchmark robotic mapping datasets, we demonstrate the combined system
achieving high-performance place recognition with sub-linear storage
requirements, and characterize the performance-storage growth trade-off curve.
The work serves as the first robotic mapping system with sub-linear storage
scaling properties, as well as the first large-scale demonstration in
real-world environments of one of the proposed memory benefits of these
neurons.
</dc:description>
 <dc:description>Comment: Pre-print of article that will appear in the IEEE Robotics and
  Automation Letters</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07316</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Flexible Approach to Automated RNN Architecture Generation</dc:title>
 <dc:creator>Schrimpf, Martin</dc:creator>
 <dc:creator>Merity, Stephen</dc:creator>
 <dc:creator>Bradbury, James</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The process of designing neural architectures requires expert knowledge and
extensive trial and error. While automated architecture search may simplify
these requirements, the recurrent neural network (RNN) architectures generated
by existing methods are limited in both flexibility and components. We propose
a domain-specific language (DSL) for use in automated architecture search which
can produce novel RNNs of arbitrary depth and width. The DSL is flexible enough
to define standard architectures such as the Gated Recurrent Unit and Long
Short Term Memory and allows the introduction of non-standard RNN components
such as trigonometric curves and layer normalization. Using two different
candidate generation techniques, random search with a ranking function and
reinforcement learning, we explore the novel architectures produced by the RNN
DSL for language modeling and machine translation domains. The resulting
architectures do not follow human intuition yet perform well on their targeted
tasks, suggesting the space of usable RNN architectures is far larger than
previously assumed.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07322</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lost in Time: Temporal Analytics for Long-Term Video Surveillance</dc:title>
 <dc:creator>Khor, Huai-Qian</dc:creator>
 <dc:creator>See, John</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video surveillance is a well researched area of study with substantial work
done in the aspects of object detection, tracking and behavior analysis. With
the abundance of video data captured over a long period of time, we can
understand patterns in human behavior and scene dynamics through data-driven
temporal analytics. In this work, we propose two schemes to perform descriptive
and predictive analytics on long-term video surveillance data. We generate
heatmap and footmap visualizations to describe spatially pooled trajectory
patterns with respect to time and location. We also present two approaches for
anomaly prediction at the day-level granularity: a trajectory-based statistical
approach, and a time-series based approach. Experimentation with one year data
from a single camera demonstrates the ability to uncover interesting insights
about the scene and to predict anomalies reasonably well.
</dc:description>
 <dc:description>Comment: To Appear in Springer LNEE</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07325</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-Based Clustering of Time-Evolving Networks through Temporal
  Exponential-Family Random Graph Models</dc:title>
 <dc:creator>Lee, Kevin H.</dc:creator>
 <dc:creator>Xue, Lingzhou</dc:creator>
 <dc:creator>Hunter, David R.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Dynamic networks are a general language for describing time-evolving complex
systems, and discrete time network models provide an emerging statistical
technique for various applications. It is a fundamental research question to
detect the community structure in time-evolving networks. However, due to
significant computational challenges and difficulties in modeling communities
of time-evolving networks, there is little progress in the current literature
to effectively find communities in time-evolving networks. In this work, we
propose a novel model-based clustering framework for time-evolving networks
based on discrete time exponential-family random graph models. To choose the
number of communities, we use conditional likelihood to construct an effective
model selection criterion. Furthermore, we propose an efficient variational
expectation-maximization (EM) algorithm to find approximate maximum likelihood
estimates of network parameters and mixing proportions. By using variational
methods and minorization-maximization (MM) techniques, our method has appealing
scalability for large-scale time-evolving networks. The power of our method is
demonstrated in simulation studies and empirical applications to international
trade networks and the collaboration networks of a large American research
university.
</dc:description>
 <dc:description>Comment: 30 pages, 4 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07329</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Diversity of Realistic Image Synthesis</dc:title>
 <dc:creator>Yang, Zichen</dc:creator>
 <dc:creator>Liu, Haifeng</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many image processing tasks can be formulated as translating images between
two image domains, such as colorization, super resolution and conditional image
synthesis. In most of these tasks, an input image may correspond to multiple
outputs. However, current existing approaches only show very minor diversity of
the outputs. In this paper, we present a novel approach to synthesize diverse
realistic images corresponding to a semantic layout. We introduce a diversity
loss objective, which maximizes the distance between synthesized image pairs
and links the input noise to the semantic segments in the synthesized images.
Thus, our approach can not only produce diverse images, but also allow users to
manipulate the output images by adjusting the noise manually. Experimental
results show that images synthesized by our approach are significantly more
diverse than that of the current existing works and equipping our diversity
loss does not degrade the reality of the base networks.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07344</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Models of Linear Logic based on the Schwartz $\varepsilon$-product</dc:title>
 <dc:creator>Dabrowski, Yoann</dc:creator>
 <dc:creator>Kerjean, Marie</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>03B47, 46A20, 46M05, 18D15, 46E50</dc:subject>
 <dc:description>  From the interpretation of Linear Logic multiplicative disjunction as the
$\varepsilon$-product defined by Laurent Schwartz, we construct several models
of Differential Linear Logic based on usual mathematical notions of smooth
maps. This improves on previous results, by R. Blute, T. Ehrhard and C. Tasson,
based on convenient smoothness where only intuitionist models were built. We
isolate a completeness condition, called k-quasi-completeness, and an
associated notion stable by duality called k-reflexivity, allowing for a
$*$-autonomous category of k-reflexive spaces in which the dual of the tensor
product is the reflexive version of the $\varepsilon$ product. We adapt Meise's
definition of Smooth maps into a first model of Differential Linear Logic, made
of k-reflexive spaces. We also build two new models of Linear Logic with
conveniently smooth maps, on categories made respectively of Mackey-complete
Schwartz spaces and Mackey-complete Nuclear Spaces (with extra reflexivity
conditions). Varying slightly the notion of smoothness, one also recovers
models of DiLL on the same $*$-autonomous categories. Throughout the article,
we work within the setting of Dialogue categories where the tensor product is
exactly the $\varepsilon$-product (without reflexivization).
</dc:description>
 <dc:description>Comment: 82 pages</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07365</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intelligent Power Control for Spectrum Sharing in Cognitive Radios: A
  Deep Reinforcement Learning Approach</dc:title>
 <dc:creator>Li, Xingjian</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:creator>Cheng, Wen</dc:creator>
 <dc:creator>Duan, Huiping</dc:creator>
 <dc:creator>Chen, Zhi</dc:creator>
 <dc:creator>Li, Hongbin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of spectrum sharing in a cognitive radio system
consisting of a primary user and a secondary user. The primary user and the
secondary user work in a non-cooperative manner. Specifically, the primary user
is assumed to update its transmit power based on a pre-defined power control
policy. The secondary user does not have any knowledge about the primary user's
transmit power, or its power control strategy. The objective of this paper is
to develop a learning-based power control method for the secondary user in
order to share the common spectrum with the primary user. To assist the
secondary user, a set of sensor nodes are spatially deployed to collect the
received signal strength information at different locations in the wireless
environment. We develop a deep reinforcement learning-based method, which the
secondary user can use to intelligently adjust its transmit power such that
after a few rounds of interaction with the primary user, both users can
transmit their own data successfully with required qualities of service. Our
experimental results show that the secondary user can interact with the primary
user efficiently to reach a goal state (defined as a state in which both users
can successfully transmit their data) from any initial states within a few
number of steps.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07374</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Structured Prediction for Multivariate Measures</dc:title>
 <dc:creator>Wang, Hong</dc:creator>
 <dc:creator>Rezaei, Ashkan</dc:creator>
 <dc:creator>Ziebart, Brian D.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many predicted structured objects (e.g., sequences, matchings, trees) are
evaluated using the F-score, alignment error rate (AER), or other multivariate
performance measures. Since inductively optimizing these measures using
training data is typically computationally difficult, empirical risk
minimization of surrogate losses is employed, using, e.g., the hinge loss for
(structured) support vector machines. These approximations often introduce a
mismatch between the learner's objective and the desired application
performance, leading to inconsistency. We take a different approach:
adversarially approximate training data while optimizing the exact F-score or
AER. Structured predictions under this formulation result from solving zero-sum
games between a predictor seeking the best performance and an adversary seeking
the worst while required to (approximately) match certain structured properties
of the training data. We explore this approach for word alignment (AER
evaluation) and named entity recognition (F-score evaluation) with linear-chain
constraints.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07384</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepFuse: A Deep Unsupervised Approach for Exposure Fusion with Extreme
  Exposure Image Pairs</dc:title>
 <dc:creator>Prabhakar, K. Ram</dc:creator>
 <dc:creator>Srikar, V. Sai</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel deep learning architecture for fusing static
multi-exposure images. Current multi-exposure fusion (MEF) approaches use
hand-crafted features to fuse input sequence. However, the weak hand-crafted
representations are not robust to varying input conditions. Moreover, they
perform poorly for extreme exposure image pairs. Thus, it is highly desirable
to have a method that is robust to varying input conditions and capable of
handling extreme exposure without artifacts. Deep representations have known to
be robust to input conditions and have shown phenomenal performance in a
supervised setting. However, the stumbling block in using deep learning for MEF
was the lack of sufficient training data and an oracle to provide the
ground-truth for supervision. To address the above issues, we have gathered a
large dataset of multi-exposure image stacks for training and to circumvent the
need for ground truth images, we propose an unsupervised deep learning
framework for MEF utilizing a no-reference quality metric as loss function. The
proposed approach uses a novel CNN architecture trained to learn the fusion
operation without reference ground truth image. The model fuses a set of common
low level features extracted from each image to generate artifact-free
perceptually pleasing results. We perform extensive quantitative and
qualitative evaluation and show that the proposed technique outperforms
existing state-of-the-art approaches for a variety of natural images.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07388</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kayak: Safe Semantic Refactoring to Java Streams</dc:title>
 <dc:creator>David, Cristina</dc:creator>
 <dc:creator>Kesseli, Pascal</dc:creator>
 <dc:creator>Kroening, Daniel</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Refactorings are structured changes to existing software that leave its
externally observable behaviour unchanged. Their intent is to improve
readability, performance or other non-behavioural properties. State-of-the-art
automatic refactoring tools are syntax-driven and, therefore, overly
conservative. In this paper we explore semantics-driven refactoring, which
enables much more sophisticated refactoring schemata. As an exemplar of this
broader idea, we present Kayak, an automatic refactoring tool that transforms
Java with external iteration over collections into code that uses Streams, a
new abstraction introduced by Java 8. Our refactoring procedure performs
semantic reasoning and search in the space of possible refactorings using
automated program synthesis. Our experimental results support the conjecture
that semantics-driven refactorings are more precise and are able to rewrite
more complex code scenarios when compared to syntax-driven refactorings.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07392</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementation of mixed-dimensional models for flow in fractured porous
  media</dc:title>
 <dc:creator>Keilegavlen, Eirik</dc:creator>
 <dc:creator>Fumagalli, Alessio</dc:creator>
 <dc:creator>Berge, Runar</dc:creator>
 <dc:creator>Stefansson, Ivar</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Models that involve coupled dynamics in a mixed-dimensional geometry are of
increasing interest in several applications. Here, we describe the development
of a simulation model for flow in fractured porous media, where the fractures
and their intersections form a hierarchy of interacting subdomains. We discuss
the implementation of a simulation framework, with an emphasis on reuse of
existing discretization tools for mono-dimensional problems. The key
ingredients are the representation of the mixed-dimensional geometry as a
graph, which allows for convenient discretization and data storage, and a
non-intrusive coupling of dimensions via boundary conditions and source terms.
This approach is applicable for a wide class of mixed-dimensional problems. We
show simulation results for a flow problem in a three-dimensional fracture
geometry, applying both finite volume and virtual finite element
discretizations.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07394</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Light Field Segmentation From Super-pixel Graph Representation</dc:title>
 <dc:creator>Lv, Xianqiang</dc:creator>
 <dc:creator>Zhu, Hao</dc:creator>
 <dc:creator>Wang, Qing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68U10</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:description>  Efficient and accurate segmentation of light field is an important task in
computer vision and graphics. The large volume of input data and the redundancy
of light field make it an open challenge. In the paper, we propose a novel
graph representation for interactive light field segmentation based on light
field super-pixel (LFSP). The LFSP not only maintains light field redundancy,
but also greatly reduces the graph size. These advantages make LFSP useful to
improve segmentation efficiency. Based on LFSP graph structure, we present an
efficient light field segmentation algorithm using graph-cuts. Experimental
results on both synthetic and real dataset demonstrate that our method is
superior to previous light field segmentation algorithms with respect to
accuracy and efficiency.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07406</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Representation of SysML/KAOS Domain Model (Complete Version)</dc:title>
 <dc:creator>Tueno, Steve</dc:creator>
 <dc:creator>Laleau, R&#xe9;gine</dc:creator>
 <dc:creator>Mammar, Amel</dc:creator>
 <dc:creator>Frappier, Marc</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Nowadays, the usefulness of a formal language for ensuring the consistency of
requirements is well established. The work presented here is part of the
definition of a formally-grounded, model-based requirements engineering method
for critical and complex systems. Requirements are captured through the
SysML/KAOS method and the targeted formal specification is written using the
Event-B method. Firstly, an Event-B skeleton is produced from the goal
hierarchy provided by the SysML/KAOS goal model. This skeleton is then
completed in a second step by the Event-B specification obtained from system
application domain properties that gives rise to the system structure.
Considering that the domain is represented using ontologies through the
SysML/KAOS Domain Model method, is it possible to automatically produce the
structural part of system Event-B models ? This paper proposes a set of generic
rules that translate SysML/KAOS domain ontologies into an Event-B
specification. The rules have been expressed, verified and validated through
the Rodin tool using the Event-B method. They are illustrated through a case
study dealing with a landing gear system. Our proposition makes it possible to
automatically obtain, from a representation of the system application domain in
the form of ontologies, the structural part of the Event-B specification which
will be used to formally validate the consistency of system requirements.
</dc:description>
 <dc:description>Comment: 54 pages</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07408</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automaton Semigroups and Groups: on the Undecidability of Problems
  Related to Freeness and Finiteness</dc:title>
 <dc:creator>D'Angeli, Daniele</dc:creator>
 <dc:creator>Rodaro, Emanuele</dc:creator>
 <dc:creator>W&#xe4;chter, Jan Philipp</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>08A99, 20E08, 20F05, 20F10, 20M05, 20A99, 20M30</dc:subject>
 <dc:subject>F.4.m</dc:subject>
 <dc:description>  In this paper, we study algorithmic problems for automaton semigroups and
automaton groups related to freeness and finiteness. In the course of this
study, we also exhibit some connections between the algebraic structure of
automaton (semi)groups and their dynamics on the boundary.
  First, we show that it is undecidable to check whether the group generated by
a given invertible automaton has a positive relation, i. e. a relation p = 1
such that p only contains positive generators. Besides its obvious relation to
the freeness of the group, the absence of positive relations has previously
been studied and is connected to the triviality of some stabilizers of the
boundary. We show that the emptiness of the set of positive relations is
equivalent to the dynamical property that all (directed positive) orbital
graphs centered at non-singular points are acyclic. Our approach also works to
show undecidability of the freeness problem for automaton semigroups; in fact,
it shows undecidability of a strengthened version where the input automaton is
complete and invertible.
  Gillibert showed that the finiteness problem for automaton semigroups is
undecidable. In the second part of the paper, we show that this undecidability
result also holds if the input is restricted to be bi-reversible and invertible
(but, in general, not complete). As an immediate consequence, we obtain that
the finiteness problem for automaton subsemigroups of semigroups generated by
invertible, yet partial automata, so called automaton-inverse semigroups, is
also undecidable.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07411</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization of stochastic lossy transport networks and applications to
  power grids</dc:title>
 <dc:creator>Zocca, Alessandro</dc:creator>
 <dc:creator>Zwart, Bert</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Motivated by developments in renewable energy and smart grids, we formulate a
stylized mathematical model of a transport network with stochastic load
fluctuations. Using an affine control rule, we explore the trade-off between
the number of controllable resources in a lossy transport network and the
performance gain they yield in terms of expected transportation losses. Our
results are explicit and reveal the interaction between the level of
flexibility, the intrinsic load uncertainty and the network structure.
</dc:description>
 <dc:description>Comment: 28 pages, 6 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07416</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorics of Beacon-based Routing in Three Dimensions</dc:title>
 <dc:creator>Cleve, Jonas</dc:creator>
 <dc:creator>Mulzer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  A beacon is a point-like object which can be enabled to exert a magnetic pull
on other point-like objects in space. Those objects then move towards the
beacon in a greedy fashion until they are either stuck at an obstacle or reach
the beacon's location. Beacons placed inside polyhedra can be used to route
point-like objects from one location to another. A second use case is to cover
a polyhedron such that every point-like object at an arbitrary location in the
polyhedron can reach at least one of the beacons once the latter is activated.
  The notion of beacon-based routing and guarding was introduced by Biro et al.
[FWCG'11] in 2011 and covered in detail by Biro in his PhD thesis [SUNY-SB'13],
which focuses on the two-dimensional case.
  We extend Biro's result to three dimensions by considering beacon routing in
polyhedra. We show that $\lfloor\frac{m+1}{3}\rfloor$ beacons are always
sufficient and sometimes necessary to route between any pair of points in a
given polyhedron $P$, where $m$ is the number of tetrahedra in a tetrahedral
decomposition of $P$. This is one of the first results that show that beacon
routing is also possible in three dimensions.
</dc:description>
 <dc:description>Comment: submitted to &quot;LATIN 2018: Theoretical Informatics&quot;</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07419</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling Algorithms for Minimizing Age of Information in Wireless
  Broadcast Networks with Random Arrivals</dc:title>
 <dc:creator>Hsu, Yu-Pin</dc:creator>
 <dc:creator>Modiano, Eytan</dc:creator>
 <dc:creator>Duan, Lingjie</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Age of information is a newly proposed metric that captures packet delay to
end-users from an application layer perspective. The age measures the amount of
time that elapsed since the latest information was generated at a source. In
this context, we study an age minimisation problem over a broadcast network to
keep many users updated on timely information, where only one user can be
served at a time. We formulate a Markov decision process (MDP) to find dynamic
scheduling algorithms, with the purpose of minimizing the long-run average age.
We show that an optimal scheduling algorithm for the MDP is a simple stationary
switch type. However, the optimal scheduling algorithm is not easy to implement
due to the MDP's infinite state-space. Using a sequence of finite-state
approximate MDPs, we successfully develop both optimal off-line and on-line
scheduling algorithms. We validate the algorithms via numerical studies, and
surprisingly show that the performance of no-buffer networks is very close to
that of networks with buffers.
</dc:description>
 <dc:description>Comment: 34 pages, submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07420</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Competitive Network Architectures Within a Day Using UCT</dc:title>
 <dc:creator>Wistuba, Martin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The design of neural network architectures for a new data set is a laborious
task which requires human deep learning expertise. In order to make deep
learning available for a broader audience, automated methods for finding a
neural network architecture are vital. Recently proposed methods can already
achieve human expert level performances. However, these methods have run times
of months or even years of GPU computing time, ignoring hardware constraints as
faced by many researchers and companies. We propose the use of Monte Carlo
planning in combination with two different UCT (upper confidence bound applied
to trees) derivations to search for network architectures. We adapt the UCT
algorithm to the needs of network architecture search by proposing two ways of
sharing information between different branches of the search tree. In an
empirical study we are able to demonstrate that this method is able to find
competitive networks for MNIST, SVHN and CIFAR-10 in just a single GPU day.
Extending the search time to five GPU days, we are able to outperform human
architectures and our competitors which consider the same types of layers.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07424</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ADINE: An Adaptive Momentum Method for Stochastic Gradient Descent</dc:title>
 <dc:creator>Srinivasan, Vishwak</dc:creator>
 <dc:creator>Sankar, Adepu Ravi</dc:creator>
 <dc:creator>Balasubramanian, Vineeth N</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Two major momentum-based techniques that have achieved tremendous success in
optimization are Polyak's heavy ball method and Nesterov's accelerated
gradient. A crucial step in all momentum-based methods is the choice of the
momentum parameter $m$ which is always suggested to be set to less than $1$.
Although the choice of $m &lt; 1$ is justified only under very strong theoretical
assumptions, it works well in practice even when the assumptions do not
necessarily hold. In this paper, we propose a new momentum based method
$\textit{ADINE}$, which relaxes the constraint of $m &lt; 1$ and allows the
learning algorithm to use adaptive higher momentum. We motivate our hypothesis
on $m$ by experimentally verifying that a higher momentum ($\ge 1$) can help
escape saddles much faster. Using this motivation, we propose our method
$\textit{ADINE}$ that helps weigh the previous updates more (by setting the
momentum parameter $&gt; 1$), evaluate our proposed algorithm on deep neural
networks and show that $\textit{ADINE}$ helps the learning algorithm to
converge much faster without compromising on the generalization error.
</dc:description>
 <dc:description>Comment: 8 + 1 pages, 12 figures, accepted at CoDS-COMAD 2018</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07431</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text Indexing and Searching in Sublinear Time</dc:title>
 <dc:creator>Munro, J. Ian</dc:creator>
 <dc:creator>Navarro, Gonzalo</dc:creator>
 <dc:creator>Nekrich, Yakov</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We introduce the first index that can be built in $o(n)$ time for a text of
length $n$, and also queried in $o(m)$ time for a pattern of length $m$. On a
constant-size alphabet, for example, our index uses
$O(n\log^{1/2+\varepsilon}n)$ bits, is built in $O(n/\log^{1/2-\varepsilon} n)$
deterministic time, and finds the $\mathrm{occ}$ pattern occurrences in time
$O(m/\log n + \sqrt{\log n}\log\log n + \mathrm{occ})$, where $\varepsilon&gt;0$
is an arbitrarily small constant. As a comparison, the most recent classical
text index uses $O(n\log n)$ bits, is built in $O(n)$ time, and searches in
time $O(m/\log n + \log\log n + \mathrm{occ})$. We build on a novel text
sampling based on difference covers, which enjoys properties that allow us
efficiently computing longest common prefixes in constant time. We extend our
results to the secondary memory model as well, where we give the first
construction in $o(Sort(n))$ time of a data structure with suffix array
functionality, which can search for patterns in the almost optimal time, with
an additive penalty of $O(\sqrt{\log_{M/B} n}\log\log n)$, where $M$ is the
size of main memory available and $B$ is the disk block size.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07435</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Molecular Signal Modeling of a Partially Counting Absorbing Spherical
  Receiver</dc:title>
 <dc:creator>Akdeniz, Bayram Cevdet</dc:creator>
 <dc:creator>Turgut, Nafi Ahmet</dc:creator>
 <dc:creator>Yilmaz, H. Birkan</dc:creator>
 <dc:creator>Chae, Chan-Byoung</dc:creator>
 <dc:creator>Tugcu, Tuna</dc:creator>
 <dc:creator>Pusane, Ali Emre</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  To communicate at the nanoscale, researchers have proposed molecular
communication as an energy-efficient solution. The drawback to this solution is
that the histogram of the molecules' hitting times, which constitute the
molecular signal at the receiver, has a heavy tail. Reducing the effects of
this heavy tail, inter-symbol interference (ISI), has been the focus of most
prior research. In this paper, a novel way of decreasing the ISI by defining a
counting region on the spherical receiver's surface facing towards the
transmitter node is proposed. The beneficial effect comes from the fact that
the molecules received from the back lobe of the receiver are more likely to be
coming through longer paths that contribute to ISI. In order to justify this
idea, the joint distribution of the arrival molecules with respect to angle and
time is derived. Using this distribution, the channel model function is
approximated for the proposed system, i.e., the partially counting absorbing
spherical receiver. After validating the channel model function, the
characteristics of the molecular signal are investigated and improved
performance is presented. Moreover, the optimal counting region in terms of bit
error rate is found analytically.
</dc:description>
 <dc:description>Comment: submitted to Transactions on Communications</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07436</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Adversarial Domain Adaptation</dc:title>
 <dc:creator>Wulfmeier, Markus</dc:creator>
 <dc:creator>Bewley, Alex</dc:creator>
 <dc:creator>Posner, Ingmar</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Continuous appearance shifts such as changes in weather and lighting
conditions can impact the performance of deployed machine learning models.
Unsupervised domain adaptation aims to address this challenge, though current
approaches do not utilise the continuity of the occurring shifts. Many robotic
applications exhibit these conditions and thus facilitate the potential to
incrementally adapt a learnt model over minor shifts which integrate to massive
differences over time. Our work presents an adversarial approach for lifelong,
incremental domain adaptation which benefits from unsupervised alignment to a
series of sub-domains which successively diverge from the labelled source
domain. We demonstrate on a drivable-path segmentation task that our
incremental approach can better handle large appearance changes, e.g. day to
night, compared with a prior single alignment step approach. Furthermore, by
approximating the marginal feature distribution for the source domain with a
generative adversarial network, the deployment module can be rendered fully
independent of retaining potentially large amounts of the related source
training data for only a minor reduction in performance.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07438</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CameraTransform: a Scientific Python Package for Perspective Camera
  Corrections</dc:title>
 <dc:creator>Gerum, Richard</dc:creator>
 <dc:creator>Richter, Sebastian</dc:creator>
 <dc:creator>Winterl, Alexander</dc:creator>
 <dc:creator>Fabry, Ben</dc:creator>
 <dc:creator>Zitterbart, Daniel</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Scientific applications often require an exact reconstruction of object
positions and distances from digital images. Therefore, the images need to be
corrected for perspective distortions. We present \textit{CameraTransform}, a
python package that performs a perspective image correction whereby the height,
tilt/roll angle and heading of the camera can be automatically obtained from
the images if additional information such as GPS coordinates or object sizes
are provided. We present examples of images of penguin colonies that are
recorded with stationary cameras and from a helicopter.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07440</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Relation of External and Internal Feature Interactions: A Case
  Study</dc:title>
 <dc:creator>Kolesnikov, Sergiy</dc:creator>
 <dc:creator>Siegmund, Norbert</dc:creator>
 <dc:creator>K&#xe4;stner, Christian</dc:creator>
 <dc:creator>Apel, Sven</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Detecting feature interactions is imperative for accurately predicting
performance of highly-configurable systems. State-of-the-art performance
prediction techniques rely on supervised machine learning for detecting feature
interactions, which, in turn, relies on time consuming performance measurements
to obtain training data. By providing information about potentially interacting
features, we can reduce the number of required performance measurements and
make the overall performance prediction process more time efficient. We expect
that the information about potentially interacting features can be obtained by
statically analyzing the source code of a highly-configurable system, which is
computationally cheaper than performing multiple performance measurements. To
this end, we conducted a qualitative case study in which we explored the
relation between control-flow feature interactions (detected through static
program analysis) and performance feature interactions (detected by performance
prediction techniques using performance measurements). We found that a relation
exists, which can potentially be exploited to predict performance interactions.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07445</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boolean Tensor Decomposition for Conjunctive Queries with Negation</dc:title>
 <dc:creator>Khamis, Mahmoud Abo</dc:creator>
 <dc:creator>Ngo, Hung Q.</dc:creator>
 <dc:creator>Olteanu, Dan</dc:creator>
 <dc:creator>Suciu, Dan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We propose an algorithm for answering conjunctive queries with negation,
where the negated relations are sparse. Its data complexity matches that of the
best known algorithms for the positive subquery of the input query and is
expressed in terms of the fractional hypertree width and the submodular width.
The query complexity depends on the structure of the negated subquery; in
general it is exponential in the number of join variables occurring in negated
relations yet it becomes polynomial for several classes of queries.
  This algorithm relies on several contributions. We show how to rewrite
queries with negation on sparse relations into equivalent conjunctive queries
with not-all-equal (NAE) predicates, which are a multi-dimensional analog of
disequality. We then generalize the known color-coding technique to
conjunctions of NAE predicates and explain it via a Boolean tensor
decomposition of conjunctions of NAE predicates. This decomposition can be
achieved via a probabilistic construction that can be derandomized efficiently.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07447</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dataflow Matrix Machines and V-values: a Bridge between Programs and
  Neural Nets</dc:title>
 <dc:creator>Bukatin, Michael</dc:creator>
 <dc:creator>Anthony, Jon</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Dataflow matrix machines generalize neural nets by replacing streams of
numbers with streams of vectors (or other kinds of linear streams admitting a
notion of linear combination of several streams) and adding a few more changes
on top of that, namely arbitrary input and output arities for activation
functions, countable-sized networks with finite dynamically changeable active
part capable of unbounded growth, and a very expressive self-referential
mechanism.
  While recurrent neural networks are Turing-complete, they form an esoteric
programming platform, not conductive for practical general-purpose programming.
Dataflow matrix machines are more suitable as a general-purpose programming
platform, although it remains to be seen whether this platform can be made
fully competitive with more traditional programming platforms currently in use.
At the same time, dataflow matrix machines retain the key property of recurrent
neural networks: programs are expressed via matrices of real numbers, and
continuous changes to those matrices produce arbitrarily small variations in
the programs associated with those matrices.
  Spaces of vector-like elements are of particular importance in this context.
In particular, we focus on the vector space $V$ of finite linear combinations
of strings, which can be also understood as the vector space of finite prefix
trees with numerical leaves, the vector space of &quot;mixed rank tensors&quot;, or the
vector space of recurrent maps.
  This space, and a family of spaces of vector-like elements derived from it,
are sufficiently expressive to cover all cases of interest we are currently
aware of, and allow a compact and streamlined version of dataflow matrix
machines based on a single space of vector-like elements and variadic neurons.
We call elements of these spaces V-values. Their role in our context is
somewhat similar to the role of S-expressions in Lisp.
</dc:description>
 <dc:description>Comment: 28 pages, 5 figures; appeared in &quot;K + K = 120: Papers dedicated to
  L\'aszl\'o K\'alm\'an and Andr\'as Kornai on the occasion of their 60th
  birthdays&quot; Festschrift</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07449</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In silico generation of novel, drug-like chemical matter using the LSTM
  neural network</dc:title>
 <dc:creator>Ertl, Peter</dc:creator>
 <dc:creator>Lewis, Richard</dc:creator>
 <dc:creator>Martin, Eric</dc:creator>
 <dc:creator>Polyakov, Valery</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  The exploration of novel chemical spaces is one of the most important tasks
of cheminformatics when supporting the drug discovery process. Properly
designed and trained deep neural networks can provide a viable alternative to
brute-force de novo approaches or various other machine-learning techniques for
generating novel drug-like molecules. In this article we present a method to
generate molecules using a long short-term memory (LSTM) neural network and
provide an analysis of the results, including a virtual screening test. Using
the network one million drug-like molecules were generated in 2 hours. The
molecules are novel, diverse (contain numerous novel chemotypes), have good
physicochemical properties and have good synthetic accessibility, even though
these qualities were not specific constraints. Although novel, their structural
features and functional groups remain closely within the drug-like space
defined by the bioactive molecules from ChEMBL. Virtual screening using the
profile QSAR approach confirms that the potential of these novel molecules to
show bioactivity is comparable to the ChEMBL set from which they were derived.
The molecule generator written in Python used in this study is available on
request.
</dc:description>
 <dc:description>Comment: in this version fixed some reference numbers</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07452</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Supervised Damage-Avoiding Manipulation Strategy Optimization via
  Mental Simulation</dc:title>
 <dc:creator>Fromm, Tobias</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Everyday robotics are challenged to deal with autonomous product handling in
applications like logistics or retail, possibly causing damage on the items
during manipulation. Traditionally, most approaches try to minimize physical
interaction with goods. However, we propose to take into account any unintended
motion of objects in the scene and to learn manipulation strategies in a
self-supervised way which minimize the potential damage. The presented approach
consists of a planning method that determines the optimal sequence to
manipulate a number of objects in a scene with respect to possible damage by
simulating interaction and hence anticipating scene dynamics. The planned
manipulation sequences are taken as input to a machine learning process which
generalizes to new, unseen scenes in the same application scenario. This
learned manipulation strategy is continuously refined in a self-supervised
optimization cycle dur- ing load-free times of the system. Such a
simulation-in-the-loop setup is commonly known as mental simulation and allows
for efficient, fully automatic generation of training data as opposed to
classical supervised learning approaches. In parallel, the generated
manipulation strategies can be deployed in near-real time in an anytime
fashion. We evaluate our approach on one industrial scenario (autonomous
container unloading) and one retail scenario (autonomous shelf replenishment).
</dc:description>
 <dc:description>Comment: submitted to Journal of Intelligent and Robotic Systems (JINT)</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07454</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast kNN mode seeking clustering applied to active learning</dc:title>
 <dc:creator>Duin, Robert P. W.</dc:creator>
 <dc:creator>Verzakov, Sergey</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A significantly faster algorithm is presented for the original kNN mode
seeking procedure. It has the advantages over the well-known mean shift
algorithm that it is feasible in high-dimensional vector spaces and results in
uniquely, well defined modes. Moreover, without any additional computational
effort it may yield a multi-scale hierarchy of clusterings. The time complexity
is just O(n^1.5). resulting computing times range from seconds for 10^4 objects
to minutes for 10^5 objects and to less than an hour for 10^6 objects. The
space complexity is just O(n). The procedure is well suited for finding large
sets of small clusters and is thereby a candidate to analyze thousands of
clusters in millions of objects.
  The kNN mode seeking procedure can be used for active learning by assigning
the clusters to the class of the modal objects of the clusters. Its feasibility
is shown by some examples with up to 1.5 million handwritten digits. The
obtained classification results based on the clusterings are compared with
those obtained by the nearest neighbor rule and the support vector classifier
based on the same labeled objects for training. It can be concluded that using
the clustering structure for classification can be significantly better than
using the trained classifiers. A drawback of using the clustering for
classification, however, is that no classifier is obtained that may be used for
out-of-sample objects.
</dc:description>
 <dc:description>Comment: 23 pages, 12 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07458</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disruptive events in high-density cellular networks</dc:title>
 <dc:creator>Keeler, H. Paul</dc:creator>
 <dc:creator>Jahnel, Benedikt</dc:creator>
 <dc:creator>Maye, Oliver</dc:creator>
 <dc:creator>Brzozowski, Marcin</dc:creator>
 <dc:creator>Aschenbach, Daniel</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>60F10</dc:subject>
 <dc:description>  Stochastic geometry models are used to study wireless networks, particularly
cellular phone networks, but most of the research focuses on the typical user,
often ignoring atypical events, which can be highly disruptive and of interest
to network operators. We examine atypical events when a unexpected large
proportion of users are disconnected or connected by proposing a hybrid
approach based on ray launching simulation and point process theory. This work
is motivated by recent results using large deviations theory applied to the
signal-to-interference ratio. This theory provides a tool for the stochastic
analysis of atypical but disruptive events, particularly when the density of
transmitters is high. For a section of a European city, we introduce a new
stochastic model of a single network cell that uses ray launching data
generated with the open source RaLaNS package, giving deterministic path loss
values. We collect statistics on the fraction of (dis)connected users in the
uplink, and observe that the probability of an unexpected large proportion of
disconnected users decreases exponentially when the transmitter density
increases. This observation implies that denser networks become more stable in
the sense that the probability of the fraction of (dis)connected users
deviating from its mean, is exponentially small. We also empirically obtain and
illustrate the density of users for network configurations in the disruptive
event, which highlights the fact that such bottleneck behaviour not only stems
from too many users at the cell boundary, but also from the near-far effect of
many users in the immediate vicinity of the base station. We discuss the
implications of these findings and outline possible future research directions.
</dc:description>
 <dc:description>Comment: 8 pages, 11 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07464</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selfishness need not be bad</dc:title>
 <dc:creator>Zijun, Wu</dc:creator>
 <dc:creator>H., Moehring Rolf</dc:creator>
 <dc:creator>Yanyan, Chen</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This article studies the user selfish behavior in non-atomic congestion games
(NCG). We prove that the price of anarchy of general NCGs tends to 1 as number
of users tends to infinity. This generalizes a recent result in the literature.
Although our result is general, the proof appears simpler.
  For routing games with BPR travel time functions, we prove that every system
optimum strategy profile is an $\epsilon$-approximate Nash equilibrium, where
$\epsilon$ is a small constant depending on the travel demands. Moreover, we
prove that the price of anarchy of these games equal $1+O(T^{-\beta}),$ where
$T$ is the total travel demand and $\beta$ is the degree of the BPR functions.
This confirms a conjecture proposed by O'Here et al. In addition, we proved
that the cost of both, system optimum and Nash equilibrium, depends mainly on
the distribution of users among OD pairs, when the total travel time is large.
This does not only supply an approximate method for computing these cost, but
also give insights how to reduce the total travel time, when the total travel
demand is large.
  To empirically verify our theoretical findings, we have taken real traffic
data within the 2nd ring road of Beijing as an instance in an experimental
study. Our empirical results definitely validate our findings. In addition,
they show that the current traffic in Beijing within that area is already far
beyond saturation, and no route guidance policy can significantly reduce the
total travel time for the current huge total travel demand.
  In summary, selfishness in a congestion game with a large number of users
need not be bad. It may be the best choice in a bad environment.
</dc:description>
 <dc:description>Comment: 51 pages, 8 figures, and 1 table</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07465</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Attentional Reinforcement Learning for Multi-label Image
  Recognition</dc:title>
 <dc:creator>Chen, Tianshui</dc:creator>
 <dc:creator>Wang, Zhouxia</dc:creator>
 <dc:creator>Li, Guanbin</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognizing multiple labels of images is a fundamental but challenging task
in computer vision, and remarkable progress has been attained by localizing
semantic-aware image regions and predicting their labels with deep
convolutional neural networks. The step of hypothesis regions (region
proposals) localization in these existing multi-label image recognition
pipelines, however, usually takes redundant computation cost, e.g., generating
hundreds of meaningless proposals with non-discriminative information and
extracting their features, and the spatial contextual dependency modeling among
the localized regions are often ignored or over-simplified. To resolve these
issues, this paper proposes a recurrent attention reinforcement learning
framework to iteratively discover a sequence of attentional and informative
regions that are related to different semantic objects and further predict
label scores conditioned on these regions. Besides, our method explicitly
models long-term dependencies among these attentional regions that help to
capture semantic label co-occurrence and thus facilitate multi-label
recognition. Extensive experiments and comparisons on two large-scale
benchmarks (i.e., PASCAL VOC and MS-COCO) show that our model achieves superior
performance over existing state-of-the-art methods in both performance and
efficiency as well as explicitly identifying image-level semantic labels to
specific object regions.
</dc:description>
 <dc:description>Comment: Accepted at AAAI 2018</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07472</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate 3D Reconstruction of Dynamic Scenes from Monocular Image
  Sequences with Severe Occlusions</dc:title>
 <dc:creator>Golyanik, Vladislav</dc:creator>
 <dc:creator>Fetzer, Torben</dc:creator>
 <dc:creator>Stricker, Didier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The paper introduces an accurate solution to dense orthographic Non-Rigid
Structure from Motion (NRSfM) in scenarios with severe occlusions or, likewise,
inaccurate correspondences. We integrate a shape prior term into variational
optimisation framework. It allows to penalize irregularities of the
time-varying structure on the per-pixel level if correspondence quality
indicator such as an occlusion tensor is available. We make a realistic
assumption that several non-occluded views of the scene are sufficient to
estimate an initial shape prior, though the entire observed scene may exhibit
non-rigid deformations. Experiments on synthetic and real image data show that
the proposed framework significantly outperforms state of the art methods for
correspondence establishment in combination with the state of the art NRSfM
methods. Together with the profound insights into optimisation methods,
implementation details for heterogeneous platforms are provided.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07473</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private Distributed Learning for Language Modeling Tasks</dc:title>
 <dc:creator>Popov, Vadim</dc:creator>
 <dc:creator>Kudinov, Mikhail</dc:creator>
 <dc:creator>Piontkovskaya, Irina</dc:creator>
 <dc:creator>Vytovtov, Petr</dc:creator>
 <dc:creator>Nevidomsky, Alex</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  One of the big challenges in machine learning applications is that training
data can be different from the real-world data faced by the algorithm. In
language modeling, users' language (e.g. in private messaging) could change in
a year and be completely different from what we observe in publicly available
data. At the same time, public data can be used for obtaining general knowledge
(i.e. general model of English). We study approaches to distributed fine-tuning
of a general model on user private data with the additional requirements of
maintaining the quality on the general data and minimization of communication
costs. We propose a novel technique that significantly improves prediction
quality on users' language compared to a general model and outperforms gradient
compression methods in terms of communication efficiency. The proposed
procedure is fast and leads to an almost 70% perplexity reduction and 8.7
percentage point improvement in keystroke saving rate on informal English
texts. Finally, we propose an experimental framework for evaluating
differential privacy of distributed training of language models and show that
our approach has good privacy guarantees.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07474</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can one design a geometry engine? On the (un)decidability of affine
  Euclidean geometries</dc:title>
 <dc:creator>Makowsky, J. A.</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>03, 03D35</dc:subject>
 <dc:description>  We survey the status of decidabilty of the consequence relation in various
axiomatizations of Euclidean geometry. We draw attention to a widely overlooked
result by Martin Ziegler from 1980, which proves Tarski's conjecture on the
undecidability of finitely axiomatizable theories of fields. We elaborate on
how to use Ziegler's theorem to show that the consequence relations for the
first order theory of the Hilbert plane and the Euclidean plane are
undecidable. As new results we add: (A) The first order consequence relations
for Wu's orthogonal and metric geometries (Wen-Ts\&quot;un Wu, 1984), and for the
axiomatization of Origami geometry (J. Justin 1986, H. Huzita 1991)are
undecidable.
  It was already known that the universal theory of Hilbert planes and Wu's
orthogonal geometry is decidable. We show here using elementary model theoretic
tools that (B) the universal first order consequences of any geometric theory
$T$ of Pappian planes which is consistent with the analytic geometry of the
reals is decidable.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07476</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The graph tessellation cover number: extremal bounds, efficient
  algorithms and hardness</dc:title>
 <dc:creator>Abreu, A.</dc:creator>
 <dc:creator>Cunha, L.</dc:creator>
 <dc:creator>Fernandes, T.</dc:creator>
 <dc:creator>de Figueiredo, C.</dc:creator>
 <dc:creator>Kowada, L.</dc:creator>
 <dc:creator>Marquezino, F.</dc:creator>
 <dc:creator>Posner, D.</dc:creator>
 <dc:creator>Portugal, R.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  A tessellation of a graph is a partition of its vertices into vertex disjoint
cliques. A tessellation cover of a graph is a set of tessellations that covers
all of its edges. The $t$-tessellability problem aims to decide whether there
is a tessellation cover of the graph with $t$ tessellations. This problem is
motivated by its applications to quantum walk models, in especial, the
evolution operator of the staggered model is obtained from a graph tessellation
cover. We establish upper bounds on the tessellation cover number given by the
minimum between the chromatic index of the graph and the chromatic number of
its clique graph and we show graph classes for which these bounds are tight. We
prove $\mathcal{NP}$-completeness for $t$-tessellability if the instance is
restricted to planar graphs, chordal (2,1)-graphs, (1,2)-graphs, diamond-free
graphs with diameter five, or for any fixed $t$ at least 3. On the other hand,
we improve the complexity for 2-tessellability to a linear-time algorithm.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figs, accepted in Latin 2018</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07485</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the one method of a third-degree bezier type spline curve
  construction</dc:title>
 <dc:creator>Stelia, O.</dc:creator>
 <dc:creator>Potapenko, L.</dc:creator>
 <dc:creator>Sirenko, I.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>65D07, 65D07</dc:subject>
 <dc:description>  A method is proposed for constructing a spline curve of the Bezier type,
which is continuous along with its first derivative by a piecewise polynomial
function. Conditions for its existence and uniqueness are given. The
constructed curve lies inside the convex hull of the control points, and the
segments of the broken line connecting the control points are tangent to the
curve. To construct the curve, we use the approach proposed earlier for
constructing a parabolic spline. The idea is to use additional points with
unknown values of some function. Additional points are used as spline nodes,
and the function values are determined from the condition of the first
derivative continuity of a piecewise polynomial curve. In multiple
interpolation nodes, the function takes the given values and the values of the
first derivative, which are determined by the control points. Examples of
constructing a spline curve are given.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07487</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attribute CNNs for Word Spotting in Handwritten Documents</dc:title>
 <dc:creator>Sudholt, Sebastian</dc:creator>
 <dc:creator>Fink, Gernot</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Word spotting has become a field of strong research interest in document
image analysis over the last years. Recently, AttributeSVMs were proposed which
predict a binary attribute representation. At their time, this influential
method defined the state-of-the-art in segmentation-based word spotting. In
this work, we present an approach for learning attribute representations with
Convolutional Neural Networks (CNNs). By taking a probabilistic perspective on
training CNNs, we derive two different loss functions for binary and
real-valued word string embeddings. In addition, we propose two different CNN
architectures, specifically designed for word spotting. These architectures are
able to be trained in an end-to-end fashion. In a number of experiments, we
investigate the influence of different word string embeddings and optimization
strategies. We show our Attribute CNNs to achieve state-of-the-art results for
segmentation-based word spotting on a large variety of data sets.
</dc:description>
 <dc:description>Comment: under review at IJDAR</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07488</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Labeled Gastric Tumor Segmentation via patch-based Reiterative
  Learning</dc:title>
 <dc:creator>Nan, Yang</dc:creator>
 <dc:creator>Coppola, Gianmarc</dc:creator>
 <dc:creator>Liang, Qiaokang</dc:creator>
 <dc:creator>Zou, Kunglin</dc:creator>
 <dc:creator>Sun, Wei</dc:creator>
 <dc:creator>Zhang, Dan</dc:creator>
 <dc:creator>Wang, Yaonan</dc:creator>
 <dc:creator>Yu, Guanzhen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Gastric cancer is the second leading cause of cancer-related deaths
worldwide, and the major hurdle in biomedical image analysis is the
determination of the cancer extent. This assignment has high clinical relevance
and would generally require vast microscopic assessment by pathologists. Recent
advances in deep learning have produced inspiring results on biomedical image
segmentation, while its outcome is reliant on comprehensive annotation. This
requires plenty of labor costs, for the ground truth must be annotated
meticulously by pathologists. In this paper, a reiterative learning framework
was presented to train our network on partial annotated biomedical images, and
superior performance was achieved without any pre-trained or further manual
annotation. We eliminate the boundary error of patch-based model through our
overlapped region forecast algorithm. Through these advisable methods, a mean
intersection over union coefficient (IOU) of 0.883 and mean accuracy of 91.09%
on the partial labeled dataset was achieved, which made us win the 2017 China
Big Data &amp; Artificial Intelligence Innovation and Entrepreneurship
Competitions.
</dc:description>
 <dc:description>Comment: 16 pages,9 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07493</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Wavelet-like Auto-Encoder to Accelerate Deep Neural Networks</dc:title>
 <dc:creator>Chen, Tianshui</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Zuo, Wangmeng</dc:creator>
 <dc:creator>Luo, Xiaonan</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accelerating deep neural networks (DNNs) has been attracting increasing
attention as it can benefit a wide range of applications, e.g., enabling mobile
systems with limited computing resources to own powerful visual recognition
ability. A practical strategy to this goal usually relies on a two-stage
process: operating on the trained DNNs (e.g., approximating the convolutional
filters with tensor decomposition) and fine-tuning the amended network, leading
to difficulty in balancing the trade-off between acceleration and maintaining
recognition performance. In this work, aiming at a general and comprehensive
way for neural network acceleration, we develop a Wavelet-like Auto-Encoder
(WAE) that decomposes the original input image into two low-resolution channels
(sub-images) and incorporate the WAE into the classification neural networks
for joint training. The two decomposed channels, in particular, are encoded to
carry the low-frequency information (e.g., image profiles) and high-frequency
(e.g., image details or noises), respectively, and enable reconstructing the
original input image through the decoding process. Then, we feed the
low-frequency channel into a standard classification network such as VGG or
ResNet and employ a very lightweight network to fuse with the high-frequency
channel to obtain the classification result. Compared to existing DNN
acceleration solutions, our framework has the following advantages: i) it is
tolerant to any existing convolutional neural networks for classification
without amending their structures; ii) the WAE provides an interpretable way to
preserve the main components of the input image for classification.
</dc:description>
 <dc:description>Comment: Accepted at AAAI 2018</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07495</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Frank-Wolfe Framework for Learning Low-Rank Matrices with
  the Trace Norm</dc:title>
 <dc:creator>Zheng, Wenjie</dc:creator>
 <dc:creator>Bellet, Aur&#xe9;lien</dc:creator>
 <dc:creator>Gallinari, Patrick</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of learning a high-dimensional but low-rank matrix
from a large-scale dataset distributed over several machines, where
low-rankness is enforced by a convex trace norm constraint. We propose
DFW-Trace, a distributed Frank-Wolfe algorithm which leverages the low-rank
structure of its updates to achieve efficiency in time, memory and
communication usage. The step at the heart of DFW-Trace is solved approximately
using a distributed version of the power method. We provide a theoretical
analysis of the convergence of DFW-Trace, showing that we can ensure sublinear
convergence in expectation to an optimal solution with few power iterations per
epoch. We implement DFW-Trace in the Apache Spark distributed programming
framework and validate the usefulness of our approach on synthetic and real
data, including the ImageNet dataset with high-dimensional features extracted
from a deep neural network.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07504</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Counting Perfect Matchings in General Graphs</dc:title>
 <dc:creator>&#x160;tefankovi&#x10d;, Daniel</dc:creator>
 <dc:creator>Vigoda, Eric</dc:creator>
 <dc:creator>Wilmes, John</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68Q25, 60J10</dc:subject>
 <dc:description>  Counting perfect matchings has played a central role in the theory of
counting problems. The permanent, corresponding to bipartite graphs, was shown
to be #P-complete to compute exactly by Valiant (1979), and a fully polynomial
randomized approximation scheme (FPRAS) was presented by Jerrum, Sinclair, and
Vigoda (2004) using a Markov chain Monte Carlo (MCMC) approach. However, it has
remained an open question whether there exists an FPRAS for counting perfect
matchings in general graphs. In fact, it was unresolved whether the same Markov
chain defined by JSV is rapidly mixing in general. In this paper, we show that
it is not. We prove torpid mixing for any weighting scheme on hole patterns in
the JSV chain. As a first step toward overcoming this obstacle, we introduce a
new algorithm for counting matchings based on the Gallai-Edmonds decomposition
of a graph, and give an FPRAS for counting matchings in graphs that are
sufficiently close to bipartite. In particular, we obtain a fixed-parameter
tractable algorithm for counting matchings in general graphs, parameterized by
the greatest &quot;order&quot; of a factor-critical subgraph.
</dc:description>
 <dc:description>Comment: To appear in LATIN 2018</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07509</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficiently Decodable Non-Adaptive Threshold Group Testing</dc:title>
 <dc:creator>Bui, Thach V.</dc:creator>
 <dc:creator>Kuribayashi, Minoru</dc:creator>
 <dc:creator>Cheraghchi, Mahdi</dc:creator>
 <dc:creator>Echizen, Isao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The basic goal of group testing is to identify at most very specific $d$
defective items among $N$ items, where $d$ is usually much smaller than $N$.
Because testing each item to identify whether it is defective takes time and is
expensive, pooling subsets of $N$ items is more preferable. Normally, if there
is at least one defective item in a subset, the test outcome of that subset
would be positive, and otherwise. However, in many biological applications, it
needs more than one defective item in a test in order to get a positive
outcome. In this paper, we consider non-adaptive threshold group testing in
which a test would be positive if it contains at least $u \leq d$ defective
items, and negative otherwise, and all tests are designed in advance.
  In this model, at most $d$ defective items can be identified using $t = O
\left( \frac{d^2}{d^2 - u^2} \left( \frac{\mathrm{e} (d - u)}{u} \right)^u
\left(u \ln{\frac{d}{u}} + \ln{\frac{1}{\epsilon}} \right) \cdot d^2 \log{N}
\right)$ tests with probability at least $1 - \epsilon$ for any $\epsilon &gt; 0$
or $t = O \left( \frac{d^2}{d^2 - u^2} \left( \frac{\mathrm{e} (d-u)}{u}
\right)^u \cdot \left( d\ln{\frac{N}{d}} + u\ln{\frac{d}{u}} \right) \cdot d^2
\log{N} \right)$ tests with probability of 1. The decoding time is
$\frac{t}{O(d^2 \log{N})} \times poly(d^2 \log{N})$, where $poly(\cdot)$ is a
polynomial of the input. This result significantly improves the best known
results on decoding non-adaptive threshold group testing, which are $O(N\log{N}
+ N \log{\frac{1}{\epsilon}})$ for probabilistic decoding, where $\epsilon &gt;
0$, and $O(N^u \log{N})$ for deterministic decoding.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07511</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coalgebraic Behavioral Metrics</dc:title>
 <dc:creator>Baldan, Paolo</dc:creator>
 <dc:creator>Bonchi, Filippo</dc:creator>
 <dc:creator>Kerstan, Henning</dc:creator>
 <dc:creator>K&#xf6;nig, Barbara</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We study different behavioral metrics, such as those arising from both
branching and linear-time semantics, in a coalgebraic setting. Given a
coalgebra $\alpha\colon X \to HX$ for a functor $H \colon \mathrm{Set}\to
\mathrm{Set}$, we define a framework for deriving pseudometrics on $X$ which
measure the behavioral distance of states.
  A crucial step is the lifting of the functor $H$ on $\mathrm{Set}$ to a
functor $\overline{H}$ on the category $\mathrm{PMet}$ of pseudometric spaces.
We present two different approaches which can be viewed as generalizations of
the Kantorovich and Wasserstein pseudometrics for probability measures. We show
that the pseudometrics provided by the two approaches coincide on several
natural examples, but in general they differ.
  If $H$ has a final coalgebra, every lifting $\overline{H}$ yields in a
canonical way a behavioral distance which is usually branching-time, i.e., it
generalizes bisimilarity. In order to model linear-time metrics (generalizing
trace equivalences), we show sufficient conditions for lifting distributive
laws and monads. These results enable us to employ the generalized powerset
construction.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07512</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ethical Questions in NLP Research: The (Mis)-Use of Forensic Linguistics</dc:title>
 <dc:creator>Singh, Anil Kumar</dc:creator>
 <dc:creator>Sudhakar, Akhilesh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Ideas from forensic linguistics are now being used frequently in Natural
Language Processing (NLP), using machine learning techniques. While the role of
forensic linguistics was more benign earlier, it is now being used for purposes
which are questionable. Certain methods from forensic linguistics are employed,
without considering their scientific limitations and ethical concerns. While we
take the specific case of forensic linguistics as an example of such trends in
NLP and machine learning, the issue is a larger one and present in many other
scientific and data-driven domains. We suggest that such trends indicate that
some of the applied sciences are exceeding their legal and scientific briefs.
We highlight how carelessly implemented practices are serving to short-circuit
the due processes of law as well breach ethical codes.
</dc:description>
 <dc:description>Comment: 4 pages, submitted to AIES-2018</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07525</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Use of Deep Learning in Modern Recommendation System: A Summary of
  Recent Works</dc:title>
 <dc:creator>Singhal, Ayush</dc:creator>
 <dc:creator>Sinha, Pradeep</dc:creator>
 <dc:creator>Pant, Rakesh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  With the exponential increase in the amount of digital information over the
internet, online shops, online music, video and image libraries, search engines
and recommendation system have become the most convenient ways to find relevant
information within a short time. In the recent times, deep learning's advances
have gained significant attention in the field of speech recognition, image
processing and natural language processing. Meanwhile, several recent studies
have shown the utility of deep learning in the area of recommendation systems
and information retrieval as well. In this short review, we cover the recent
advances made in the field of recommendation using various variants of deep
learning technology. We organize the review in three parts: Collaborative
system, Content based system and Hybrid system. The review also discusses the
contribution of deep learning integrated recommendation systems into several
application domains. The review concludes by discussion of the impact of deep
learning in recommendation system in various domain and whether deep learning
has shown any significant improvement over the conventional systems for
recommendation. Finally, we also provide future directions of research which
are possible based on the current state of use of deep learning in
recommendation systems.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, 1 table, &quot;Published with International Journal of
  Computer Applications (IJCA)&quot;</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07525</dc:identifier>
 <dc:identifier>International Journal of Computer Applications 180(7):17-22,
  December 2017</dc:identifier>
 <dc:identifier>doi:10.5120/ijca2017916055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07540</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Registration Techniques: A Survey</dc:title>
 <dc:creator>Nag, Sayan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Image Registration is the process of aligning two or more images of the same
scene with reference to a particular image. The images are captured from
various sensors at different times and at multiple view-points. Thus to get a
better picture of any change of a scene or object over a considerable period of
time image registration is important. Image registration finds application in
medical sciences, remote sensing and in computer vision. This paper presents a
detailed review of several approaches which are classified accordingly along
with their contributions and drawbacks. The main steps of an image registration
procedure are also discussed. Different performance measures are presented that
determine the registration quality and accuracy. The scope for the future
research are presented as well.
</dc:description>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07540</dc:identifier>
 <dc:identifier>doi:10.17605/OSF.IO/RV65C</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07542</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symbol-Level Selective Full-Duplex Relaying with Power and Location
  Optimization</dc:title>
 <dc:creator>Hou, Jiancao</dc:creator>
 <dc:creator>Narayanan, Sandeep</dc:creator>
 <dc:creator>Yi, Na</dc:creator>
 <dc:creator>Ma, Yi</dc:creator>
 <dc:creator>Shikh-Bahaei, Mohammad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a symbol-level selective transmission for full-duplex (FD)
relaying networks is proposed to mitigate error propagation effects and improve
system spectral efficiency. The idea is to allow the FD relay node to predict
the correctly decoded symbols of each frame, based on the generalized square
deviation method, and discard the erroneously decoded symbols, resulting in
fewer errors being forwarded to the destination node. Using the capability for
simultaneous transmission and reception at the FD relay node, our proposed
strategy can improve the transmission efficiency without extra cost of
signalling overhead. In addition, targeting on the derived expression for
outage probability, we compare it with half-duplex (HD) relaying case, and
provide the transmission power and relay location optimization strategy to
further enhance system performance. The results show that our proposed scheme
outperforms the classic relaying protocols, such as cyclic redundancy check
based selective decode-and-forward (S-DF) relaying and threshold based S-DF
relaying in terms of outage probability and bit-error-rate performances.
Moreover, the performances with optimal power allocation is better than that
with equal power allocation, especially when the FD relay node encounters
strong self-interference and/or it is close to the destination node.
</dc:description>
 <dc:description>Comment: 34 pages (single-column), 14 figures, 2 tables</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07548</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive model predictive control for constrained, linear time varying
  systems</dc:title>
 <dc:creator>Tanaskovic, M.</dc:creator>
 <dc:creator>Fagiano, L.</dc:creator>
 <dc:creator>Gligorovski, V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This manuscript contains technical details of recent results developed by the
authors on adaptive model predictive control for constrained linear, time
varying systems.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07552</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anchored Network Users: Stochastic Evolutionary Dynamics of Cognitive
  Radio Network Selection</dc:title>
 <dc:creator>Lim, Ik Soo</dc:creator>
 <dc:creator>Wittek, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  To solve the spectrum scarcity problem, the cognitive radio technology
involves licensed users and unlicensed users. A fundamental issue for the
network users is whether it is better to act as a licensed user by using a
primary network or an unlicensed user by using a secondary network. To model
the network selection process by the users, the deterministic replicator
dynamics is often used, but in a less practical way that it requires each user
to know global information on the network state for reaching a Nash
equilibrium. This paper addresses the network selection process in a more
practical way such that only noise-prone estimation of local information is
required and, yet, it obtains an efficient system performance.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07557</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private Federated Learning: A Client Level Perspective</dc:title>
 <dc:creator>Geyer, Robin C.</dc:creator>
 <dc:creator>Klein, Tassilo</dc:creator>
 <dc:creator>Nabi, Moin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Federated learning is a recent advance in privacy protection. In this
context, a trusted curator aggregates parameters optimized in decentralized
fashion by multiple clients. The resulting model is then distributed back to
all clients, ultimately converging to a joint representative model without
explicitly having to share the data. However, the protocol is vulnerable to
differential attacks, which could originate from any party contributing during
federated optimization. In such an attack, a client's contribution during
training and information about their data set is revealed through analyzing the
distributed model. We tackle this problem and propose an algorithm for client
sided differential privacy preserving federated optimization. The aim is to
hide clients' contributions during training, balancing the trade-off between
privacy loss and model performance. Empirical studies suggest that given a
sufficiently large number of participating clients, our proposed procedure can
maintain client-level differential privacy at only a minor cost in model
performance.
</dc:description>
 <dc:description>Comment: NIPS 2017 Workshop: Machine Learning on the Phone and other Consumer
  Devices</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07558</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Ensemble Model with Ranking for Social Dialogue</dc:title>
 <dc:creator>Papaioannou, Ioannis</dc:creator>
 <dc:creator>Curry, Amanda Cercas</dc:creator>
 <dc:creator>Part, Jose L.</dc:creator>
 <dc:creator>Shalyminov, Igor</dc:creator>
 <dc:creator>Xu, Xinnuo</dc:creator>
 <dc:creator>Yu, Yanchao</dc:creator>
 <dc:creator>Du&#x161;ek, Ond&#x159;ej</dc:creator>
 <dc:creator>Rieser, Verena</dc:creator>
 <dc:creator>Lemon, Oliver</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Open-domain social dialogue is one of the long-standing goals of Artificial
Intelligence. This year, the Amazon Alexa Prize challenge was announced for the
first time, where real customers get to rate systems developed by leading
universities worldwide. The aim of the challenge is to converse &quot;coherently and
engagingly with humans on popular topics for 20 minutes&quot;. We describe our Alexa
Prize system (called 'Alana') consisting of an ensemble of bots, combining
rule-based and machine learning systems, and using a contextual ranking
mechanism to choose a system response. The ranker was trained on real user
feedback received during the competition, where we address the problem of how
to train on the noisy and sparse feedback obtained during the competition.
</dc:description>
 <dc:description>Comment: NIPS 2017 Workshop on Conversational AI</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07559</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognizing Generalized Transmission Graphs of Line Segments and
  Circular Sectors</dc:title>
 <dc:creator>Klost, Katharina</dc:creator>
 <dc:creator>Mulzer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Suppose we have an arrangement $\mathcal{A}$ of $n$ geometric objects $x_1,
\dots, x_n \subseteq \mathbb{R}^2$ in the plane, with a distinguished point
$p_i$ in each object $x_i$. The generalized transmission graph of $\mathcal{A}$
has vertex set $\{x_1, \dots, x_n\}$ and a directed edge $x_ix_j$ if and only
if $p_j \in x_i$. Generalized transmission graphs provide a generalized model
of the connectivity in networks of directional antennas.
  The complexity class $\exists \mathbb{R}$ contains all problems that can be
reduced in polynomial time to an existential sentence of the form $\exists x_1,
\dots, x_n: \phi(x_1,\dots, x_n)$, where $x_1,\dots, x_n$ range over
$\mathbb{R}$ and $\phi$ is a propositional formula with signature $(+, -,
\cdot, 0, 1)$. The class $\exists \mathbb{R}$ aims to capture the complexity of
the existential theory of the reals. It lies between $\mathbf{NP}$ and
$\mathbf{PSPACE}$.
  Many geometric decision problems, such as recognition of disk graphs and of
intersection graphs of lines, are complete for $\exists \mathbb{R}$. Continuing
this line of research, we show that the recognition problem of generalized
transmission graphs of line segments and of circular sectors is hard for
$\exists \mathbb{R}$. As far as we know, this constitutes the first such result
for a class of directed graphs.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07564</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Propagation on Permissionless Blockchains</dc:title>
 <dc:creator>Ersoy, Oguzhan</dc:creator>
 <dc:creator>Ren, Zhijie</dc:creator>
 <dc:creator>Erkin, Zekeriya</dc:creator>
 <dc:creator>Lagendijk, Reginald L.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Blockchain technology, as a decentralized and non-hierarchical platform, has
the potential to replace centralized systems. Yet, there are several challenges
inherent in the blockchain structure. One of the deficiencies of the existing
blockchains is a convenient information propagation technique enhancing
incentive-compatibility and bandwidth efficiency. The transition from a
centralized system into distributed one brings along game theoretical concerns.
Especially for the permissionless blockchains, information propagation should
be incentive-compatible just like any other communication or computational
costly operation. Another important issue is that information is relayed via
gossip-like protocols causing excessive bandwidth usage. Each information is
propagated at least twice: first to advertise its existence, second to announce
that it is final and validated, i.e., added to the block.
  In this work, we investigate two distinct aspects of the information
propagation of the blockchains: incentive and routing mechanisms. For the
former part, we analyze the necessary and sufficient conditions of the
Sybil-proof incentive-compatible propagation methodology. We show the
impossibility result of the Sybil-proofness in 1-connected network model. For
the rest, we prove that the propagation decision is independent of the
capabilities of the receiving side. Then, we formulate the generic fee sharing
function which encourages rational participants to propagate information.
Regarding the bandwidth efficiency, we study a special type of consensus
protocols where the block owner (round leader) is validated before the block is
created. We present a smart routing mechanism which the redundant communication
cost from the size of the network to the scale of average shortest path length.
Finally, we combine the incentive and routing mechanisms in a storage-efficient
way.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07570</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental Phase Estimation Enhanced By Machine Learning</dc:title>
 <dc:creator>Lumino, Alessandro</dc:creator>
 <dc:creator>Polino, Emanuele</dc:creator>
 <dc:creator>Rab, Adil S.</dc:creator>
 <dc:creator>Milani, Giorgio</dc:creator>
 <dc:creator>Spagnolo, Nicol&#xf2;</dc:creator>
 <dc:creator>Wiebe, Nathan</dc:creator>
 <dc:creator>Sciarrino, Fabio</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Phase estimation protocols provide a fundamental benchmark for the field of
quantum metrology. The latter represents one of the most relevant applications
of quantum theory, potentially enabling the capability of measuring unknown
physical parameters with improved precision over classical strategies. Within
this context, most theoretical and experimental studies have focused on
determining the fundamental bounds and how to achieve them in the asymptotic
regime where a large number of resources is employed. However, in most
applications it is necessary to achieve optimal precisions by performing only a
limited number of measurements. To this end, machine learning techniques can be
applied as a powerful optimization tool. Here, we implement experimentally
single-photon adaptive phase estimation protocols enhanced by machine learning,
showing the capability of reaching optimal precision after a small number of
trials. In particular, we introduce a new approach for Bayesian estimation that
exhibit best performances for very low number of photons N. Furthermore, we
study the resilience to noise of the tested methods, showing that the optimized
Bayesian approach is very robust in the presence of imperfections. Application
of this methodology can be envisaged in the more general multiparameter case,
that represents a paradigmatic scenario for several tasks including imaging or
Hamiltonian learning.
</dc:description>
 <dc:description>Comment: 10+4 pages, 6+3 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07576</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Act Properly: Predicting and Explaining Affordances from
  Images</dc:title>
 <dc:creator>Chuang, Ching-Yao</dc:creator>
 <dc:creator>Li, Jiaman</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address the problem of affordance reasoning in diverse scenes that appear
in the real world. Affordances relate the agent's actions to their effects when
taken on the surrounding objects. In our work, we take the egocentric view of
the scene, and aim to reason about action-object affordances that respect both
the physical world as well as the social norms imposed by the society. We also
aim to teach artificial agents why some actions should not be taken in certain
situations, and what would likely happen if these actions would be taken. We
collect a new dataset that builds upon ADE20k, referred to as ADE-Affordance,
which contains annotations enabling such rich visual reasoning. We propose a
model that exploits Graph Neural Networks to propagate contextual information
from the scene in order to perform detailed affordance reasoning about each
object. Our model is showcased through various ablation studies, pointing to
successes and challenges in this complex task.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07581</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Riemann-Theta Boltzmann Machine</dc:title>
 <dc:creator>Krefl, Daniel</dc:creator>
 <dc:creator>Carrazza, Stefano</dc:creator>
 <dc:creator>Haghighat, Babak</dc:creator>
 <dc:creator>Kahlen, Jens</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>High Energy Physics - Theory</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  A general Boltzmann machine with continuous visible and discrete integer
valued hidden states is introduced. Under mild assumptions about the connection
matrices, the probability density function of the visible units can be solved
for analytically, yielding a novel parametric density function involving a
ratio of Riemann-Theta functions. The conditional expectation of a hidden state
for given visible states can also be calculated analytically, yielding a
derivative of the logarithmic Riemann-Theta function. The conditional
expectation can be used as activation function in a feedforward neural network,
thereby increasing the modelling capacity of the network. Both the Boltzmann
machine and the derived feedforward neural network can be successfully trained
via standard gradient- and non-gradient-based optimization techniques.
</dc:description>
 <dc:description>Comment: 26 pages, 11 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07590</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Discrete Spatial Compression for Beamspace Massive MIMO Signals</dc:title>
 <dc:creator>Jiang, Zhiyuan</dc:creator>
 <dc:creator>Zhou, Sheng</dc:creator>
 <dc:creator>Niu, Zhisheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Deploying massive number of antennas at the base station side can boost the
cellular system performance dramatically. Meanwhile, it however involves
significant additional radio-frequency (RF) front-end complexity, hardware cost
and power consumption. To address this issue, the
beamspace-multiple-input-multiple-output (beamspace-MIMO) based approach is
considered as a promising solution. In this paper, we first show that the
traditional beamspace-MIMO suffers from spatial power leakage and imperfect
channel statistics estimation. A beam combination module is hence proposed,
which consists of a small number (compared with the number of antenna elements)
of low-resolution (possibly one-bit) digital (discrete) phase shifters after
the beamspace transformation to further compress the beamspace signal
dimensionality, such that the number of RF chains can be reduced beyond
beamspace transformation and beam selection. The optimum discrete beam
combination weights for the uplink are obtained based on the branch-and-bound
(BB) approach. The key to the BB-based solution is to solve the embodied
sub-problem, whose solution is derived in a closed-form. Based on the solution,
a sequential greedy beam combination scheme with linear-complexity (w.r.t. the
number of beams in the beamspace) is proposed. Link-level simulation results
based on realistic channel models and long-term-evolution (LTE) parameters are
presented which show that the proposed schemes can reduce the number of RF
chains by up to $25\%$ with a one-bit digital phase-shifter-network.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Trans. Signal Process</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07600</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative analysis of two discretizations of Ricci curvature for
  complex networks</dc:title>
 <dc:creator>Samal, Areejit</dc:creator>
 <dc:creator>Sreejith, R. P.</dc:creator>
 <dc:creator>Gu, Jiao</dc:creator>
 <dc:creator>Liu, Shiping</dc:creator>
 <dc:creator>Saucan, Emil</dc:creator>
 <dc:creator>Jost, J&#xfc;rgen</dc:creator>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We have performed an empirical comparison of two distinct notions of discrete
Ricci curvature for graphs or networks, namely, the Forman-Ricci curvature and
Ollivier-Ricci curvature. Importantly, the two discretizations of the Ricci
curvature, Forman-Ricci and Ollivier-Ricci, were developed based on different
properties of the classical smooth notion, and thus, the two notions shed light
on different aspects of network structure and behavior. Nevertheless, our
extensive computational analysis in wide-range of both model and real-world
networks shows that the two discretizations of Ricci curvature are
statistically well correlated. Besides the potential theoretical implications
of these observations, the close relationship between the two discretizations
has practical implications whereby Forman-Ricci curvature can be employed in
place of Ollivier-Ricci curvature for faster computation in larger networks
whenever coarse analysis suffices.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures, 3 tables</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07601</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analytical Perspective to Traffic Engineering in Anonymous
  Communication Systems</dc:title>
 <dc:creator>Nia, Mehran Alidoost</dc:creator>
 <dc:creator>Babulak, Eduard</dc:creator>
 <dc:creator>Fabian, Benjamin</dc:creator>
 <dc:creator>Atani, Reza Ebrahimi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Anonymous communication systems (ACS) offer privacy and anonymity through the
Internet. They are mostly free tools and are popular among users all over the
world. In the recent years, anonymity applications faced many problems
regarding traffic engineering methods. Even though they ensure privacy under
some conditions, their anonymity will be endangered by high performance
processing units. To address these issues, this study is devoted to
investigating traffic-engineering methods in anonymous communication systems,
and proposes an analytical view of the current issues in ACS privacy and
anonymity. Our study also indicates new types of solutions for these current
issues with ACS.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07610</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MATE robots simplifying my work: benefits and socio-ethical implications</dc:title>
 <dc:creator>Villani, Valeria</dc:creator>
 <dc:creator>Sabattini, Lorenzo</dc:creator>
 <dc:creator>Czerniak, Julia N.</dc:creator>
 <dc:creator>Mertens, Alexander</dc:creator>
 <dc:creator>Fantuzzi, Cesare</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  With the increasing complexity of modern industrial automatic and robotic
systems, an increasing burden is put on the operators, who are requested to
supervise and interact with very complex systems, typically under challenging
and stressful conditions. To overcome this issue, it is necessary to adopt a
responsible approach based on the anthropocentric design methodology, such that
machines adapt to the humans capabilities, and not vice versa. Moving along
these lines, in this paper we consider an integrated methodological design
approach, which we call MATE, consisting in devising complex automatic or
robotic solutions that measure current operator's status, adapting the
interaction accordingly, and providing her/him with proper training to improve
the interaction and learn lacking skills and expertise. Accordingly, a MATE
system is intended to be easily usable for all users, thus meeting the
principles of inclusive design. Using such a MATE system gives rise to several
ethical and social implications, which are discussed in this paper.
Additionally, a discussion about which factors in the organization of companies
are critical with respect to the introduction of a MATE system is presented.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07610</dc:identifier>
 <dc:identifier>IEEE Robotics and Automation Magazine, 2018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07612</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advanced EMT and Phasor-Domain Hybrid Simulation with Simulation Mode
  Switching Capability for Transmission and Distribution Systems</dc:title>
 <dc:creator>Huang, Qiuhua</dc:creator>
 <dc:creator>Vittal, Vijay</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Conventional electromagnetic transient (EMT) and phasor-domain hybrid
simulation approaches presently exist for trans-mission system level studies.
Their simulation efficiency is generally constrained by the EMT simulation.
With an increasing number of distributed energy resources and non-conventional
loads being installed in distribution systems, it is imperative to extend the
hybrid simulation application to include distribution systems and integrated
transmission and distribution systems. Meanwhile, it is equally important to
improve the simulation efficiency as the modeling scope and complexity of the
detailed system in the EMT simulation increases. To meet both requirements,
this paper introduces an advanced EMT and phasor-domain hybrid simulation
approach. This approach has two main features: 1) a comprehensive phasor-domain
modeling framework which supports positive-sequence, three-sequence,
three-phase and mixed three-sequence/three-phase representations and 2) a
robust and flexible simulation mode switching scheme. The developed scheme
enables simulation switching from hybrid simulation mode back to pure
phasor-domain dynamic simulation mode to achieve significantly improved
simulation efficiency. The proposed method has been tested on integrated
transmission and distribution systems. The results show that with the developed
simulation switching feature, the total computational time is significantly
reduced compared to running the hybrid simulation for the whole simulation
period, while maintaining good simulation accuracy.
</dc:description>
 <dc:description>Comment: 10 pages,submitted to IEEE TRANSACTIONS ON POWER SYSTEMS</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07612</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07622</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal logic control of general Markov decision processes by
  approximate policy refinement</dc:title>
 <dc:creator>Haesaert, Sofie</dc:creator>
 <dc:creator>Soudjani, Sadegh</dc:creator>
 <dc:creator>Abate, Alessandro</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>93E03, 93E20, 68W25</dc:subject>
 <dc:description>  The formal verification and controller synthesis for Markov decision
processes that evolve over uncountable state spaces are computationally hard
and thus generally rely on the use of approximations. In this work, we consider
the correct-by-design control of general Markov decision processes (gMDPs) with
respect to temporal logic properties by leveraging approximate probabilistic
relations between the original model and its abstraction. We newly work with a
robust satisfaction for the construction and verification of control
strategies, which allows for both deviations in the outputs of the gMDPs and in
the probabilistic transitions. The computation is done over the reduced or
abstracted models, such that when a property is robustly satisfied on the
abstract model, it is also satisfied on the original model with respect to a
refined control strategy.
</dc:description>
 <dc:description>Comment: 22 pages, 3 figures, submitted to the 24th International Conference
  on Tools and Algorithms for the Construction and Analysis of Systems (TACAS),
  2018</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07628</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Generalization Performance by Switching from Adam to SGD</dc:title>
 <dc:creator>Keskar, Nitish Shirish</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Despite superior training outcomes, adaptive optimization methods such as
Adam, Adagrad or RMSprop have been found to generalize poorly compared to
Stochastic gradient descent (SGD). These methods tend to perform well in the
initial portion of training but are outperformed by SGD at later stages of
training. We investigate a hybrid strategy that begins training with an
adaptive method and switches to SGD when appropriate. Concretely, we propose
SWATS, a simple strategy which switches from Adam to SGD when a triggering
condition is satisfied. The condition we propose relates to the projection of
Adam steps on the gradient subspace. By design, the monitoring process for this
condition adds very little overhead and does not increase the number of
hyperparameters in the optimizer. We report experiments on several standard
benchmarks such as: ResNet, SENet, DenseNet and PyramidNet for the CIFAR-10 and
CIFAR-100 data sets, ResNet on the tiny-ImageNet data set and language modeling
with recurrent networks on the PTB and WT2 data sets. The results show that our
strategy is capable of closing the generalization gap between SGD and Adam on a
majority of the tasks.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07629</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SuperPoint: Self-Supervised Interest Point Detection and Description</dc:title>
 <dc:creator>DeTone, Daniel</dc:creator>
 <dc:creator>Malisiewicz, Tomasz</dc:creator>
 <dc:creator>Rabinovich, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a self-supervised framework for training interest point
detectors and descriptors suitable for a large number of multiple-view geometry
problems in computer vision. As opposed to patch-based neural networks, our
fully-convolutional model operates on full-sized images and jointly computes
pixel-level interest point locations and associated descriptors in one forward
pass. We introduce Homographic Adaptation, a multi-scale, multi-homography
approach for boosting interest point detection repeatability and performing
cross-domain adaptation (e.g., synthetic-to-real). Our model, when trained on
the MS-COCO generic image dataset using Homographic Adaptation, is able to
repeatedly detect a much richer set of interest points than the initial
pre-adapted deep model and any other traditional corner detector. The final
system gives rise to state-of-the-art homography estimation results on HPatches
when compared to LIFT, SIFT and ORB.
</dc:description>
 <dc:description>Comment: Added new quantitative and qualitative evaluation versus Yi et. al.'s
  LIFT algorithm (EECV 2016 work)</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07632</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning with Lung Segmentation and Bone Shadow Exclusion
  Techniques for Chest X-Ray Analysis of Lung Cancer</dc:title>
 <dc:creator>Gordienko, Yu.</dc:creator>
 <dc:creator>Gang, Peng</dc:creator>
 <dc:creator>Hui, Jiang</dc:creator>
 <dc:creator>Zeng, Wei</dc:creator>
 <dc:creator>Kochura, Yu.</dc:creator>
 <dc:creator>Alienin, O.</dc:creator>
 <dc:creator>Rokovyi, O.</dc:creator>
 <dc:creator>Stirenko, S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recent progress of computing, machine learning, and especially deep
learning, for image recognition brings a meaningful effect for automatic
detection of various diseases from chest X-ray images (CXRs). Here efficiency
of lung segmentation and bone shadow exclusion techniques is demonstrated for
analysis of 2D CXRs by deep learning approach to help radiologists identify
suspicious lesions and nodules in lung cancer patients. Training and validation
was performed on the original JSRT dataset (dataset #01), BSE-JSRT dataset,
i.e. the same JSRT dataset, but without clavicle and rib shadows (dataset #02),
original JSRT dataset after segmentation (dataset #03), and BSE-JSRT dataset
after segmentation (dataset #04). The results demonstrate the high efficiency
and usefulness of the considered pre-processing techniques in the simplified
configuration even. The pre-processed dataset without bones (dataset #02)
demonstrates the much better accuracy and loss results in comparison to the
other pre-processed datasets after lung segmentation (datasets #02 and #03).
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures; The First International Conference on Computer
  Science, Engineering and Education Applications (ICCSEEA2018)
  (www.uacnconf.org/iccseea2018) (accepted)</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07639</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Segmentation to Distinguish Between Overlapping Human Chromosomes</dc:title>
 <dc:creator>Hu, R. Lily</dc:creator>
 <dc:creator>Karnowski, Jeremy</dc:creator>
 <dc:creator>Fadely, Ross</dc:creator>
 <dc:creator>Pommier, Jean-Patrick</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In medicine, visualizing chromosomes is important for medical diagnostics,
drug development, and biomedical research. Unfortunately, chromosomes often
overlap and it is necessary to identify and distinguish between the overlapping
chromosomes. A segmentation solution that is fast and automated will enable
scaling of cost effective medicine and biomedical research. We apply neural
network-based image segmentation to the problem of distinguishing between
partially overlapping DNA chromosomes. A convolutional neural network is
customized for this problem. The results achieved intersection over union (IOU)
scores of 94.7% for the overlapping region and 88-94% on the non-overlapping
chromosome regions.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Machine Learning for Health</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07640</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Evolutionary Game Theoretic Model of Rhino Horn Devaluation</dc:title>
 <dc:creator>Glynatsi, Nikoleta E.</dc:creator>
 <dc:creator>Knight, Vincent</dc:creator>
 <dc:creator>Lee, Tamsin E.</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91A22, 91A40, 91A80</dc:subject>
 <dc:description>  Rhino populations are at a critical level due to the demand for rhino horn
and the subsequent poaching. Wild life managers attempt to secure rhinos with
approaches such as devaluing the horn. The most common strategy of devaluing
horns is dehorning. Game theory has been used before to examine the interaction
of poachers and wild life managers. A manager can either `dehorn' their rhinos
or leave the horn attached. Poachers may chose to to behave `selectively' or
`indiscriminately'. The approach described in this paper builds on this
previous work and investigates the interactions between the poachers. Using
evolutionary game theory, we determine which strategy is preferred by a poacher
in various different populations of poachers. The purpose of this work is to
discover whether conditions which encourage the poachers to behave selectively
exist, that is, they only kill those rhinos with full horns. Notwithstanding,
the analytical results prove that poachers will never adopt a selective
strategy as long as there is gain from a partial horn. Additionally, poachers
behaving indiscriminately is stable and robust. However, the model is adapted
further to include a disincentive factor, which may represent factors such as
harsher punishment, or lower demand for horn. With a disincentive, poachers can
be encouraged to behave selectively, but only when there are few devalued
rhinos. This paper aims to contribute to the necessary research needed for
informed discussion about the lively debate on legalising rhino horn trade.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07642</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sim2Real View Invariant Visual Servoing by Recurrent Control</dc:title>
 <dc:creator>Sadeghi, Fereshteh</dc:creator>
 <dc:creator>Toshev, Alexander</dc:creator>
 <dc:creator>Jang, Eric</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Humans are remarkably proficient at controlling their limbs and tools from a
wide range of viewpoints and angles, even in the presence of optical
distortions. In robotics, this ability is referred to as visual servoing:
moving a tool or end-point to a desired location using primarily visual
feedback. In this paper, we study how viewpoint-invariant visual servoing
skills can be learned automatically in a robotic manipulation scenario. To this
end, we train a deep recurrent controller that can automatically determine
which actions move the end-point of a robotic arm to a desired object. The
problem that must be solved by this controller is fundamentally ambiguous:
under severe variation in viewpoint, it may be impossible to determine the
actions in a single feedforward operation. Instead, our visual servoing system
must use its memory of past movements to understand how the actions affect the
robot motion from the current viewpoint, correcting mistakes and gradually
moving closer to the target. This ability is in stark contrast to most visual
servoing methods, which either assume known dynamics or require a calibration
phase. We show how we can learn this recurrent controller using simulated data
and a reinforcement learning objective. We then describe how the resulting
model can be transferred to a real-world robot by disentangling perception from
control and only adapting the visual layers. The adapted model can servo to
previously unseen objects from novel viewpoints on a real-world Kuka IIWA
robotic arm. For supplementary videos, see:
https://fsadeghi.github.io/Sim2RealViewInvariantServo
</dc:description>
 <dc:description>Comment: Supplementary video:
  https://fsadeghi.github.io/Sim2RealViewInvariantServo</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07671</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Cyber Adversaries with Adaptive Indicators of Compromise</dc:title>
 <dc:creator>Doak, Justin E.</dc:creator>
 <dc:creator>Ingram, Joe B.</dc:creator>
 <dc:creator>Mulder, Sam A.</dc:creator>
 <dc:creator>Naegle, John H.</dc:creator>
 <dc:creator>Cox, Jonathan A.</dc:creator>
 <dc:creator>Aimone, James B.</dc:creator>
 <dc:creator>Dixon, Kevin R.</dc:creator>
 <dc:creator>James, Conrad D.</dc:creator>
 <dc:creator>Follett, David R.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A forensics investigation after a breach often uncovers network and host
indicators of compromise (IOCs) that can be deployed to sensors to allow early
detection of the adversary in the future. Over time, the adversary will change
tactics, techniques, and procedures (TTPs), which will also change the data
generated. If the IOCs are not kept up-to-date with the adversary's new TTPs,
the adversary will no longer be detected once all of the IOCs become invalid.
Tracking the Known (TTK) is the problem of keeping IOCs, in this case regular
expressions (regexes), up-to-date with a dynamic adversary. Our framework
solves the TTK problem in an automated, cyclic fashion to bracket a previously
discovered adversary. This tracking is accomplished through a data-driven
approach of self-adapting a given model based on its own detection
capabilities.
  In our initial experiments, we found that the true positive rate (TPR) of the
adaptive solution degrades much less significantly over time than the naive
solution, suggesting that self-updating the model allows the continued
detection of positives (i.e., adversaries). The cost for this performance is in
the false positive rate (FPR), which increases over time for the adaptive
solution, but remains constant for the naive solution. However, the difference
in overall detection performance, as measured by the area under the curve
(AUC), between the two methods is negligible. This result suggests that
self-updating the model over time should be done in practice to continue to
detect known, evolving adversaries.
</dc:description>
 <dc:description>Comment: This was presented at the 4th Annual Conf. on Computational Science &amp;
  Computational Intelligence (CSCI'17) held Dec 14-16, 2017 in Las Vegas,
  Nevada, USA</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07671</dc:identifier>
 <dc:identifier>This will be in the proceedings of the 4th Annual Conf. on
  Computational Science &amp; Computational Intelligence (CSCI'17) held Dec 14-16,
  2017 in Las Vegas, Nevada, USA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07672</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PKC-PC: A Variant of the McEliece Public Key Cryptosystem based on Polar
  Codes</dc:title>
 <dc:creator>Hooshmand, Reza</dc:creator>
 <dc:creator>Shooshtari, Masoumeh Koochak</dc:creator>
 <dc:creator>Aref, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Polar codes are novel and efficient error correcting codes with low encoding
and decoding complexities. These codes have a channel dependent generator
matrix which is determined by the code dimension, code length and transmission
channel parameters. This paper studies a variant of the McEliece public key
cryptosystem based on polar codes, called &quot;PKC-PC&quot;. Due to the fact that the
structure of polar codes' generator matrix depends on the parameters of
channel, we used an efficient approach to conceal their generator matrix. Then,
by the help of the characteristics of polar codes and also introducing an
efficient approach, we reduced the public and private key sizes of the PKC-PC
and increased its information rate compared to the McEliece cryptosystem. It
was shown that polar codes are able to yield an increased security level
against conventional attacks and possible vulnerabilities on the code-based
public key cryptosystems. Moreover, it is indicated that the security of the
PKC-PC is reduced to solve NP-complete problems. Compared to other post-quantum
public key schemes, we believe that the PKC-PC is a promising candidate for
NIST post-quantum crypto standardization.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07682</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep metric learning for multi-labelled radiographs</dc:title>
 <dc:creator>Annarumma, Mauro</dc:creator>
 <dc:creator>Montana, Giovanni</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many radiological studies can reveal the presence of several co-existing
abnormalities, each one represented by a distinct visual pattern. In this
article we address the problem of learning a distance metric for plain
radiographs that captures a notion of &quot;radiological similarity&quot;: two chest
radiographs are considered to be similar if they share similar abnormalities.
Deep convolutional neural networks (DCNs) are used to learn a low-dimensional
embedding for the radiographs that is equipped with the desired metric. Two
loss functions are proposed to deal with multi-labelled images and potentially
noisy labels. We report on a large-scale study involving over 745,000 chest
radiographs whose labels were automatically extracted from free-text
radiological reports through a natural language processing system. Using 4,500
validated exams, we demonstrate that the methodology performs satisfactorily on
clustering and image retrieval tasks. Remarkably, the learned metric separates
normal exams from those having radiological abnormalities.
</dc:description>
 <dc:description>Comment: SAC 2018</dc:description>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07686</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pseudorehearsal in actor-critic agents with neural network function
  approximation</dc:title>
 <dc:creator>Marochko, Vladimir</dc:creator>
 <dc:creator>Johard, Leonard</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Longo, Luca</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Catastrophic forgetting has a significant negative impact in reinforcement
learning. The purpose of this study is to investigate how pseudorehearsal can
change performance of an actor-critic agent with neural-network function
approximation. We tested agent in a pole balancing task and compared different
pseudorehearsal approaches. We have found that pseudorehearsal can assist
learning and decrease forgetting.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07691</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring User Interests in Microblogging Social Networks: A Survey</dc:title>
 <dc:creator>Piao, Guangyuan</dc:creator>
 <dc:creator>Breslin, John G.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  With the popularity of microblogging services such as Twitter in recent
years, an increasing number of users use these services in their daily lives.
The huge volume of information generated by users raises new opportunities in
various applications and areas. Inferring user interests plays a significant
role in providing personalized recommendations on microblogging services, and
third-party applications providing social logins via these services, especially
in cold-start situations. In this survey, we review user modeling strategies
with respect to inferring user interests in previous studies. To this end, we
focus on four dimensions of inferring user interest profiles: (1) data
collection, (2) representation of user interest profiles, (3) construction and
enhancement of user interest profiles, and (4) the evaluation of the
constructed profiles. Through this survey, we aim to provide an overview of
state-of-the-art user modeling strategies for inferring user interest profiles
on microblogging social networks with respect to the four dimensions. For each
dimension, we review and summarize previous studies based on specified
criteria. Finally, we discuss some challenges and opportunities for future work
in this research domain.
</dc:description>
 <dc:description>Comment: journal submission</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07694</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intel SGX Enabled Key Manager Service with OpenStack Barbican</dc:title>
 <dc:creator>Chakrabarti, Somnath</dc:creator>
 <dc:creator>Baker, Brandon</dc:creator>
 <dc:creator>Vij, Mona</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Protecting data in the cloud continues to gain in importance, with encryption
being used to achieve the desired data protection. While there is desire to use
encryption, various cloud components do not want to deal with key management,
which points to a strong need for a separate key management system. OpenStack
Barbican is a platform developed by the OpenStack community aimed at providing
cryptographic functions useful for all environments, including large ephemeral
clouds. Barbican exposes REST APIs designed for the secure storage,
provisioning and management of secrets such as passwords, encryption keys, and
X.509 certificates, and supports plugins for a variety of crypto solutions in
the backend. Crypto plugins store secrets as encrypted blobs within the
Barbican database. Software based crypto plugins offer a scalable solution, but
are vulnerable to system software attacks. Hardware Security Module or HSM
plugins offer strong security guarantees, but they are expensive and don't
scale well. We propose to build an Intel Software Guard Extension or SGX based
software crypto plugin that offers security similar to an HSM with the low cost
and scalability of a software based solution. We extend OpenStack Barbican API
to support attestation of an Intel SGX crypto plugin, to allow clients higher
confidence in the software they are using for storing keys. In addition, the
API provides support for mutual attestation for Intel SGX enabled clients,
multi-user key distribution, and extensions for protecting the confidentiality
and integrity of the backend database.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07695</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Synthesis Learning Enables Segmentation Without Target
  Modality Ground Truth</dc:title>
 <dc:creator>Huo, Yuankai</dc:creator>
 <dc:creator>Xu, Zhoubing</dc:creator>
 <dc:creator>Bao, Shunxing</dc:creator>
 <dc:creator>Assad, Albert</dc:creator>
 <dc:creator>Abramson, Richard G.</dc:creator>
 <dc:creator>Landman, Bennett A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A lack of generalizability is one key limitation of deep learning based
segmentation. Typically, one manually labels new training images when
segmenting organs in different imaging modalities or segmenting abnormal organs
from distinct disease cohorts. The manual efforts can be alleviated if one is
able to reuse manual labels from one modality (e.g., MRI) to train a
segmentation network for a new modality (e.g., CT). Previously, two stage
methods have been proposed to use cycle generative adversarial networks
(CycleGAN) to synthesize training images for a target modality. Then, these
efforts trained a segmentation network independently using synthetic images.
However, these two independent stages did not use the complementary information
between synthesis and segmentation. Herein, we proposed a novel end-to-end
synthesis and segmentation network (EssNet) to achieve the unpaired MRI to CT
image synthesis and CT splenomegaly segmentation simultaneously without using
manual labels on CT. The end-to-end EssNet achieved significantly higher median
Dice similarity coefficient (0.9188) than the two stages strategy (0.8801), and
even higher than canonical multi-atlas segmentation (0.9125) and ResNet method
(0.9107), which used the CT manual labels.
</dc:description>
 <dc:description>Comment: IEEE International Symposium on Biomedical Imaging (ISBI) 2018</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07697</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Renaissance: Self-Stabilizing Distributed SDN Control Plane</dc:title>
 <dc:creator>Canini, Marco</dc:creator>
 <dc:creator>Salem, Iosif</dc:creator>
 <dc:creator>Schiff, Liron</dc:creator>
 <dc:creator>Schiller, Elad Michael</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  By introducing programmability, automated verification, and innovative
debugging tools, Software-Defined Networks (SDNs) are poised to meet the
increasingly stringent dependability requirements of today's communication
networks. However, the design of fault-tolerant SDNs remains an open challenge.
This paper considers the design of dependable SDNs through the lenses of
self-stabilization - a very strong notion of fault-tolerance. In particular, we
develop algorithms for an in-band and distributed control plane for SDNs,
called Renaissance, which tolerate a wide range of (concurrent) controller,
link, and communication failures. Our self-stabilizing algorithms ensure that
after the occurrence of an arbitrary combination of failures, (i) every
non-faulty SDN controller can eventually reach any switch in the network within
a bounded communication delay (in the presence of a bounded number of
concurrent failures) and (ii) every switch is managed by at least one
non-faulty controller. We evaluate Renaissance through a rigorous worst-case
analysis as well as a prototype implementation (based on OVS and Floodlight),
and we report on our experiments using Mininet.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07705</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Optimal Repairs for Functional Dependencies</dc:title>
 <dc:creator>Livshits, Ester</dc:creator>
 <dc:creator>Kimelfeld, Benny</dc:creator>
 <dc:creator>Roy, Sudeepa</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We investigate the complexity of computing an optimal repair of an
inconsistent database, in the case where integrity constraints are Functional
Dependencies (FDs). We focus on two types of repairs: an optimal subset repair
(optimal S-repair) that is obtained by a minimum number of tuple deletions, and
an optimal update repair (optimal U-repair) that is obtained by a minimum
number of value (cell) updates. For computing an optimal S-repair, we present a
polynomial-time algorithm that succeeds on certain sets of FDs and fails on
others. We prove the following about the algorithm. When it succeeds, it can
also incorporate weighted tuples and duplicate tuples. When it fails, the
problem is NP-hard, and in fact, APX-complete (hence, cannot be approximated
better than some constant). Thus, we establish a dichotomy in the complexity of
computing an optimal S-repair. We present general analysis techniques for the
complexity of computing an optimal U-repair, some based on the dichotomy for
S-repairs. We also draw a connection to a past dichotomy in the complexity of
finding a &quot;most probable database&quot; that satisfies a set of FDs with a single
attribute on the left hand side; the case of general FDs was left open, and we
show how our dichotomy provides the missing generalization and thereby settles
the open problem.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07708</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causal Feature Selection for Individual Characteristics Prediction</dc:title>
 <dc:creator>Ding, Tao</dc:creator>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:creator>Bos, Maarten</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  People can be characterized by their demographic information and personality
traits. Characterizing people accurately can help predict their preferences,
and aid recommendations and advertising. A growing number of studies infer
people's characteristics from behavioral data. However, context factors make
behavioral data noisy, making these data harder to use for predictive
analytics. In this paper, we demonstrate how to employ causal identification on
feature selection and how to predict individuals' characteristics based on
these selected features. We use visitors' choice data from a large theme park,
combined with personality measurements, to investigate the causal relationship
between visitors' characteristics and their choices in the park. We demonstrate
the benefit of feature selection based on causal identification in a supervised
prediction task for individual characteristics. Based on our evaluation, our
models that trained with features selected based on causal identification
outperformed existing methods.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07709</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Tri-Relationship for Fake News Detection</dc:title>
 <dc:creator>Shu, Kai</dc:creator>
 <dc:creator>Wang, Suhang</dc:creator>
 <dc:creator>Liu, Huan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social media for news consumption is becoming popular nowadays. The low cost,
easy access and rapid information dissemination of social media bring benefits
for people to seek out news timely. However, it also causes the widespread of
fake news, i.e., low-quality news pieces that are intentionally fabricated. The
fake news brings about several negative effects on individual consumers, news
ecosystem, and even society trust. Previous fake news detection methods mainly
focus on news contents for deception classification or claim fact-checking.
Recent Social and Psychology studies show potential importance to utilize
social media data: 1) Confirmation bias effect reveals that consumers prefer to
believe information that confirms their existing stances; 2) Echo chamber
effect suggests that people tend to follow likeminded users and form segregated
communities on social media. Even though users' social engagements towards news
on social media provide abundant auxiliary information for better detecting
fake news, but existing work exploiting social engagements is rather limited.
In this paper, we explore the correlations of publisher bias, news stance, and
relevant user engagements simultaneously, and propose a Tri-Relationship Fake
News detection framework (TriFN). We also provide two comprehensive real-world
fake news datasets to facilitate fake news research. Experiments on these
datasets demonstrate the effectiveness of the proposed approach.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07711</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Classification of Technologies</dc:title>
 <dc:creator>Coccia, Mario</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This study here suggests a classification of technologies based on taxonomic
characteristics of interaction between technologies in complex systems that is
not a studied research field in economics of technical change. The proposed
taxonomy here categorizes technologies in four typologies, in a broad analogy
with the ecology: 1) technological parasitism is a relationship between two
technologies T1 and T2 in a complex system S where one technology T1 benefits
from the interaction with T2, whereas T2 has a negative side from interaction
with T1; 2) technological commensalism is a relationship between two
technologies in S where one technology benefits from the other without
affecting it; 3) technological mutualism is a relationship in which each
technology benefits from the activity of the other within complex systems; 4)
technological symbiosis is a long-term interaction between two (or more)
technologies that evolve together in complex systems. This taxonomy
systematizes the typologies of interactive technologies within complex systems
and predicts their evolutionary pathways that generate stepwise coevolutionary
processes of complex systems of technology. This study here begins the process
of generalizing, as far as possible, critical typologies of interactive
technologies that explain the long-run evolution of technology. The theoretical
framework developed here opens the black box of the interaction between
technologies that affects, with different types of technologies, the
evolutionary pathways of complex systems of technology over time and space.
Overall, then, this new theoretical framework may be useful for bringing a new
perspective to categorize the gradient of benefit to technologies from
interaction with other technologies that can be a ground work for development
of more sophisticated concepts to clarify technological and economic change in
human society.
</dc:description>
 <dc:description>Comment: figure 1 table 1</dc:description>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07721</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Order Preserving Bilinear Model for Person Detection in Multi-Modal
  Data</dc:title>
 <dc:creator>Ulutan, Oytun</dc:creator>
 <dc:creator>Riggan, Benjamin S.</dc:creator>
 <dc:creator>Nasrabadi, Nasser M.</dc:creator>
 <dc:creator>Manjunath, B. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new order preserving bilinear framework that exploits
low-resolution video for person detection in a multi-modal setting using deep
neural networks. In this setting cameras are strategically placed such that
less robust sensors, e.g. geophones that monitor seismic activity, are located
within the field of views (FOVs) of cameras. The primary challenge is being
able to leverage sufficient information from videos where there are less than
40 pixels on targets, while also taking advantage of less discriminative
information from other modalities, e.g. seismic. Unlike state-of-the-art
methods, our bilinear framework retains spatio-temporal order when computing
the vector outer products between pairs of features. Despite the high
dimensionality of these outer products, we demonstrate that our order
preserving bilinear framework yields better performance than recent orderless
bilinear models and alternative fusion methods.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07727</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PERS: A Personalized and Explainable POI Recommender System</dc:title>
 <dc:creator>Baral, Ramesh</dc:creator>
 <dc:creator>Li, Tao</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The Location-Based Social Networks (LBSN) (e.g., Facebook) have many factors
(for instance, ratings, check-in time, etc.) that play a crucial role for the
Point-of-Interest (POI) recommendations. Unlike ratings, the reviews can help
users to elaborate their opinion and share the extent of consumption experience
in terms of the relevant factors of interest (aspects). Though some of the
existing recommendation systems have been using the user reviews, most of them
are less transparent and non-interpretable. These reasons have induced
considerable attention towards explainable and interpretable recommendation. To
the best of our knowledge, this is the first paper to exploit the user reviews
to incorporate the sentiment and opinions on different aspects for the
personalized and explainable POI recommendation. In this paper, we propose a
model termed as PERS (Personalized Explainable POI Recommender System) which
models the review-aspect category correlation by exploiting deep neural
network, formulates the user-aspect category bipartite relation as a bipartite
graph, and models the explainable recommendation using bipartite core-based and
ranking-based methods. The major contributions of this paper are: (i) it models
users and locations based on the aspects posted by user via reviews, (ii) it
exploits a deep neural network to model the review-aspect category correlation,
(iii) it provisions the incorporation of multiple contexts (e.g., categorical,
spatial, etc.) in the POI recommendation model, (iv) it formulates the
preference of users' on aspect category as a bipartite relation, represents it
as a location-aspect category bipartite graph, and models the explainable
recommendation with the notion of ordered dense subgraph extraction using
bipartite core-based and ranking-based approaches, and (v) it evaluates the
generated recommendation with three real-world datasets.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07732</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhance Visual Recognition under Adverse Conditions via Deep Networks</dc:title>
 <dc:creator>Liu, Ding</dc:creator>
 <dc:creator>Cheng, Bowen</dc:creator>
 <dc:creator>Wang, Zhangyang</dc:creator>
 <dc:creator>Zhang, Haichao</dc:creator>
 <dc:creator>Huang, Thomas S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual recognition under adverse conditions is a very important and
challenging problem of high practical value, due to the ubiquitous existence of
quality distortions during image acquisition, transmission, or storage. While
deep neural networks have been extensively exploited in the techniques of
low-quality image restoration and high-quality image recognition tasks
respectively, few studies have been done on the important problem of
recognition from very low-quality images. This paper proposes a deep learning
based framework for improving the performance of image and video recognition
models under adverse conditions, using robust adverse pre-training or its
aggressive variant. The robust adverse pre-training algorithms leverage the
power of pre-training and generalizes conventional unsupervised pre-training
and data augmentation methods. We further develop a transfer learning approach
to cope with real-world datasets of unknown adverse conditions. The proposed
framework is comprehensively evaluated on a number of image and video
recognition benchmarks, and obtains significant performance improvements under
various single or mixed adverse conditions. Our visualization and analysis
further add to the explainability of results.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07733</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Asymptotic Analysis of Area Spectral Efficiency in Ultradense
  Cellular Networks</dc:title>
 <dc:creator>AlAmmouri, Ahmad</dc:creator>
 <dc:creator>Andrews, Jeffrey G.</dc:creator>
 <dc:creator>Baccelli, Francois</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the asymptotic properties of area spectral efficiency
(ASE) of a downlink cellular network in the limit of very dense base station
(BS) and user densities. This asymptotic analysis relies on three assumptions:
(1) interference is treated as noise; (2) the BS locations are drawn from a
Poisson point process; (3) the path loss function is bounded above satisfying
mild regularity conditions. We consider three possible definitions of the ASE,
all of which give units of bits per second per unit area. When there is no
constraint on the minimum operational SINR and instantaneous full channel state
information is available at the transmitter, the ASE is proven to saturate to a
constant, which we derive in closed form. For the other two ASE definitions,
wherein either a minimum SINR is enforced or full CSI is not available, the ASE
is instead shown to collapse to zero at high BS density. We provide several
familiar case studies for the class of considered path loss models, and
demonstrate that our results cover most previous models and results on
ultradense networks as special cases.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07734</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sheaf-Theoretic Stratification Learning</dc:title>
 <dc:creator>Brown, Adam</dc:creator>
 <dc:creator>Wang, Bei</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:description>  In this paper, we investigate a sheaf-theoretic interpretation of
stratification learning. Motivated by the work of Alexandroff (1937) and McCord
(1978), we aim to redirect efforts in the computational topology of
triangulated compact polyhedra to the much more computable realm of sheaves on
partially ordered sets. Our main result is the construction of stratification
learning algorithms framed in terms of a sheaf on a partially ordered set with
the Alexandroff topology. We prove that the resulting decomposition is the
unique minimal stratification for which the strata are homogeneous and the
given sheaf is constructible. In particular, when we choose to work with the
local homology sheaf, our algorithm gives an alternative to the local homology
transfer algorithm given in Bendich et al. (2012), and the cohomology
stratification algorithm given in Nanda (2017). We envision that our
sheaf-theoretic algorithm could give rise to a larger class of stratification
beyond homology-based stratification. This approach also points toward future
applications of sheaf theory in the study of topological data analysis by
illustrating the utility of the language of sheaf theory in generalizing
existing algorithms.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07738</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving User's Experience through Simultaneous Multi-WLAN Connections</dc:title>
 <dc:creator>Ca&#xf1;izares, Guillem</dc:creator>
 <dc:creator>Bellalta, Boris</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In highly-dense IEEE 802.11 deployments, areas covered by multiple Wireless
Local Area Networks (WLANs) will be common. This opens the door for stations
equipped with multiple IEEE 802.11 interfaces to use several WLANs
simultaneously, which not only may improve user experience, achieving a better
connection with higher throughput and resilience; but it may also improve the
network utilization. In this paper we investigate such a scenario. First, using
a test-bed, consisting of a single station equipped with two interfaces and two
access points, we observe that the file transfer time between the station and a
destination server can be significantly reduced, studying with special
attention the case in which both links do not have the same available
bandwidth. Then, using a Markovian model that captures the scenario's dynamics
in presence of multiple stations, we observe that in addition to improve
individual station's performance, we can also improve the utilization of a
multi-Access Points network despite increasing the contention level.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07740</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Securing Edge Networks with Securebox</dc:title>
 <dc:creator>Hafeez, Ibbad</dc:creator>
 <dc:creator>Ding, Aaron Yi</dc:creator>
 <dc:creator>Tarkoma, Sasu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The number of mobile and IoT devices connected to home and enterprise
networks is growing fast. These devices offer new services and experiences for
the users; however, they also present new classes of security threats
pertaining to data and device safety and user privacy. In this article, we
first analyze the potential threats presented by these devices connected to
edge networks. We then propose Securebox: a new cloud-driven, low cost
Security-as-a-Service solution that applies Software-Defined Networking (SDN)
to improve network monitoring, security and management. Securebox enables
remote management of networks through a cloud security service (CSS) with
minimal user intervention required. To reduce costs and improve the
scalability, Securebox is based on virtualized middleboxes provided by CSS. Our
proposal differs from the existing solutions by integrating the SDN and cloud
into a unified edge security solution, and by offering a collaborative
protection mechanism that enables rapid security policy dissemination across
all connected networks in mitigating new threats or attacks detected by the
system. We have implemented two Securebox prototypes, using a low-cost
Raspberry-PI and off-the-shelf fanless PC. Our system evaluation has shown that
Securebox can achieve automatic network security and be deployed incrementally
to the infrastructure with low management overhead.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07742</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mechanism Design for Demand Response Programs</dc:title>
 <dc:creator>Muthirayan, Deepan</dc:creator>
 <dc:creator>Kalathil, Dileep</dc:creator>
 <dc:creator>Poolla, Kameshwar</dc:creator>
 <dc:creator>Varaiya, Pravin</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Demand Response (DR) programs serve to reduce the consumption of electricity
at times when the supply is scarce and expensive. The utility informs the
aggregator of an anticipated DR event. The aggregator calls on a subset of its
pool of recruited agents to reduce their electricity use. Agents are paid for
reducing their energy consumption from contractually established baselines.
Baselines are counter-factual consumption estimates of the energy an agent
would have consumed if they were not participating in the DR program. Baselines
are used to determine payments to agents. This creates an incentive for agents
to inflate their baselines. We propose a novel self-reported baseline mechanism
(SRBM) where each agent reports its baseline and marginal utility. These
reports are strategic and need not be truthful. Based on the reported
information, the aggregator selects or calls on agents to meet the load
reduction target. Called agents are paid for observed reductions from their
self- reported baselines. Agents who are not called face penalties for
consumption shortfalls below their baselines. The mechanism is specified by the
probability with which agents are called, reward prices for called agents, and
penalty prices for agents who are not called. Under SRBM, we show that truthful
reporting of baseline consumption and marginal utility is a dominant strategy.
Thus, SRBM eliminates the incentive for agents to inflate baselines. SRBM is
assured to meet the load reduction target. SRBM is also nearly efficient since
it selects agents with the smallest marginal utilities, and each called agent
contributes maximally to the load reduction target. Finally, we show that SRBM
is almost optimal in the metric of average cost of DR provision faced by the
aggregator.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07745</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-aware Path Ranking for Knowledge Base Completion</dc:title>
 <dc:creator>Mazumder, Sahisnu</dc:creator>
 <dc:creator>Liu, Bing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Knowledge base (KB) completion aims to infer missing facts from existing ones
in a KB. Among various approaches, path ranking (PR) algorithms have received
increasing attention in recent years. PR algorithms enumerate paths between
entity pairs in a KB and use those paths as features to train a model for
missing fact prediction. Due to their good performances and high model
interpretability, several methods have been proposed. However, most existing
methods suffer from scalability (high RAM consumption) and feature explosion
(trains on an exponentially large number of features) problems. This paper
proposes a Context-aware Path Ranking (C-PR) algorithm to solve these problems
by introducing a selective path exploration strategy. C-PR learns global
semantics of entities in the KB using word embedding and leverages the
knowledge of entity semantics to enumerate contextually relevant paths using
bidirectional random walk. Experimental results on three large KBs show that
the path features (fewer in number) discovered by C-PR not only improve
predictive performance but also are more interpretable than existing baselines.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07745</dc:identifier>
 <dc:identifier>Published in IJCAI 2017</dc:identifier>
 <dc:identifier>doi:10.24963/ijcai.2017/166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07746</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On finitely generated submonoids of free groups</dc:title>
 <dc:creator>Silva, Pedro V.</dc:creator>
 <dc:creator>Zakharov, Alexander</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We prove that the classes of graded monoids, regular monoids and Kleene
monoids coincide for submonoids of free groups. We also prove that it is
decidable whether or not a finitely generated submonoid of a free group is
graded, and solve the homomorphism and isomorphism problems for graded
submonoids of free groups. This generalizes earlier results for submonoids of
free monoids.
</dc:description>
 <dc:description>Comment: 21 pages, 1 figure</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07752</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards an unanimous international regulatory body for responsible use
  of Artificial Intelligence [UIRB-AI]</dc:title>
 <dc:creator>Chidambaram, Rajesh</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Artificial Intelligence (AI), is once again in the phase of drastic
advancements. Unarguably, the technology itself can revolutionize the way we
live our everyday life. But the exponential growth of technology poses a
daunting task for policy researchers and law makers in making amendments to the
existing norms. In addition, not everyone in the society is studying the
potential socio-economic intricacies and cultural drifts that AI can bring
about. It is prudence to reflect from our historical past to propel the
development of technology in the right direction. To benefit the society of the
present and future, I scientifically explore the societal impact of AI. While
there are many public and private partnerships working on similar aspects, here
I describe the necessity for an Unanimous International Regulatory Body for all
applications of AI (UIRB-AI). I also discuss the benefits and drawbacks of such
an organization. To combat any drawbacks in the formation of an UIRB-AI, both
idealistic and pragmatic perspectives are discussed alternatively. The paper
further advances the discussion by proposing novel policies on how such
organization should be structured and how it can bring about a win-win
situation for everyone in the society.
</dc:description>
 <dc:description>Comment: Based on the numerous reviews I have received, the figures
  illustrated in the paper are highly incorrect and vague. This might guide a
  novice reader towards a wrong direction and lead to improper understanding of
  the subject. Also, the paper covers a diverse range of topics but doesn't get
  into the details of any and hence the proposals remain pragmatically
  irrelevant</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07754</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving DRAM Performance by Parallelizing Refreshes with Accesses</dc:title>
 <dc:creator>Chang, Kevin K.</dc:creator>
 <dc:creator>Lee, Donghyuk</dc:creator>
 <dc:creator>Chishti, Zeshan</dc:creator>
 <dc:creator>Alameldeen, Alaa R.</dc:creator>
 <dc:creator>Wilkerson, Chris</dc:creator>
 <dc:creator>Kim, Yoongu</dc:creator>
 <dc:creator>Mutlu, Onur</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Modern DRAM cells are periodically refreshed to prevent data loss due to
leakage. Commodity DDR DRAM refreshes cells at the rank level. This degrades
performance significantly because it prevents an entire rank from serving
memory requests while being refreshed. DRAM designed for mobile platforms,
LPDDR DRAM, supports an enhanced mode, called per-bank refresh, that refreshes
cells at the bank level. This enables a bank to be accessed while another in
the same rank is being refreshed, alleviating part of the negative performance
impact of refreshes. However, there are two shortcomings of per-bank refresh.
First, the per-bank refresh scheduling scheme does not exploit the full
potential of overlapping refreshes with accesses across banks because it
restricts the banks to be refreshed in a sequential round-robin order. Second,
accesses to a bank that is being refreshed have to wait.
  To mitigate the negative performance impact of DRAM refresh, we propose two
complementary mechanisms, DARP (Dynamic Access Refresh Parallelization) and
SARP (Subarray Access Refresh Parallelization). The goal is to address the
drawbacks of per-bank refresh by building more efficient techniques to
parallelize refreshes and accesses within DRAM. First, instead of issuing
per-bank refreshes in a round-robin order, DARP issues per-bank refreshes to
idle banks in an out-of-order manner. Furthermore, DARP schedules refreshes
during intervals when a batch of writes are draining to DRAM. Second, SARP
exploits the existence of mostly-independent subarrays within a bank. With
minor modifications to DRAM organization, it allows a bank to serve memory
accesses to an idle subarray while another subarray is being refreshed.
Extensive evaluations show that our mechanisms improve system performance and
energy efficiency compared to state-of-the-art refresh policies and the benefit
increases as DRAM density increases.
</dc:description>
 <dc:description>Comment: The original paper published in the International Symposium on
  High-Performance Computer Architecture (HPCA) contains an error. The arxiv
  version has an erratum that describes the error and the fix for it</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07754</dc:identifier>
 <dc:identifier>2014 IEEE 20th International Symposium on High Performance
  Computer Architecture (HPCA), Orlando, FL, 2014, pp. 356-367</dc:identifier>
 <dc:identifier>doi:10.1109/HPCA.2014.6835946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07756</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error-Free Communication Over State-Dependent Channels with
  Variable-Length Feedback</dc:title>
 <dc:creator>Kova&#x10d;evi&#x107;, Mladen</dc:creator>
 <dc:creator>Wang, Carol</dc:creator>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A24, 94A45, 68P30</dc:subject>
 <dc:description>  The zero-error capacity of state-dependent channels with noiseless feedback
is determined, under the assumption that the transmitter and the receiver are
allowed to use variable-length coding schemes. Various cases are analyzed, with
the employed coding schemes having either bounded or unbounded codeword lengths
and with state information revealed to the encoder and/or decoder in a strictly
causal, causal, or non-causal manner. In each of these settings, necessary and
sufficient conditions for positivity of the zero-error capacity are obtained
and it is shown that, whenever the zero-error capacity is positive, it equals
the conventional vanishing-error capacity. Moreover, it is shown that the
vanishing-error capacity of state-dependent channels is not increased by the
use of feedback and variable-length coding. A comparison of the results with
the recently solved fixed-length case is also given.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07758</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Estimation of Ice Bottom Surfaces from Radar Imagery</dc:title>
 <dc:creator>Xu, Mingze</dc:creator>
 <dc:creator>Crandall, David J</dc:creator>
 <dc:creator>Fox, Geoffrey C</dc:creator>
 <dc:creator>Paden, John D</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Ground-penetrating radar on planes and satellites now makes it practical to
collect 3D observations of the subsurface structure of the polar ice sheets,
providing crucial data for understanding and tracking global climate change.
But converting these noisy readings into useful observations is generally done
by hand, which is impractical at a continental scale. In this paper, we propose
a computer vision-based technique for extracting 3D ice-bottom surfaces by
viewing the task as an inference problem on a probabilistic graphical model. We
first generate a seed surface subject to a set of constraints, and then
incorporate additional sources of evidence to refine it via discrete energy
minimization. We evaluate the performance of the tracking algorithm on 7
topographic sequences (each with over 3000 radar images) collected from the
Canadian Arctic Archipelago with respect to human-labeled ground truth.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, published in ICIP 2017</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07759</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>POSIX-based Operating System in the environment of NVM/SCM memory</dc:title>
 <dc:creator>Dubeyko, Vyacheslav</dc:creator>
 <dc:creator>Guyot, Cyril</dc:creator>
 <dc:creator>Cargnini, Luis</dc:creator>
 <dc:creator>Manzanares, Adam</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Modern Operating Systems are typically POSIX-compliant. The system calls are
the fundamental layer of interaction between user-space applications and the OS
kernel and its implementation of fundamental abstractions and primitives used
in modern computing. The next generation of NVM/SCM memory raises critical
questions about the efficiency of modern OS architecture. This paper
investigates how the POSIX API drives performance for a system with NVM/SCM
memory. We show that OS and metadata related system calls represent the most
important area of optimization. However, the synchronization related system
calls (poll(), futex(), wait4()) are the most time-consuming overhead that even
a RAMdisk platform fails to eliminate. Attempting to preserve the POSIX-based
approach will likely result in fundamental inefficiencies for any future
applications of NVM/SCM memory.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07770</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bit-Vector Model Counting using Statistical Estimation</dc:title>
 <dc:creator>Kim, Seonmo</dc:creator>
 <dc:creator>McCamant, Stephen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Approximate model counting for bit-vector SMT formulas (generalizing \#SAT)
has many applications such as probabilistic inference and quantitative
information-flow security, but it is computationally difficult. Adding random
parity constraints (XOR streamlining) and then checking satisfiability is an
effective approximation technique, but it requires a prior hypothesis about the
model count to produce useful results. We propose an approach inspired by
statistical estimation to continually refine a probabilistic estimate of the
model count for a formula, so that each XOR-streamlined query yields as much
information as possible. We implement this approach, with an approximate
probability model, as a wrapper around an off-the-shelf SMT solver or SAT
solver. Experimental results show that the implementation is faster than the
most similar previous approaches which used simpler refinement strategies. The
technique also lets us model count formulas over floating-point constraints,
which we demonstrate with an application to a vulnerability in differential
privacy mechanisms.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07773</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlled Information Fusion with Risk-Averse CVaR Social Sensors</dc:title>
 <dc:creator>Bhatt, Sujay</dc:creator>
 <dc:creator>Krishnamurthy, Vikram</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Consider a multi-agent network comprised of risk averse social sensors and a
controller that jointly seek to estimate an unknown state of nature, given
noisy measurements. The network of social sensors perform Bayesian social
learning - each sensor fuses the information revealed by previous social
sensors along with its private valuation using Bayes' rule - to optimize a
local cost function. The controller sequentially modifies the cost function of
the sensors by discriminatory pricing (control inputs) to realize long term
global objectives. We formulate the stochastic control problem faced by the
controller as a Partially Observed Markov Decision Process (POMDP) and derive
structural results for the optimal control policy as a function of the
risk-aversion factor in the Conditional Value-at-Risk (CVaR) cost function of
the sensors. We show that the optimal price sequence when the sensors are risk-
averse is a super-martingale; i.e, it decreases on average over time.
</dc:description>
 <dc:description>Comment: IEEE CDC 2017</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07775</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local optima of the Sherrington-Kirkpatrick Hamiltonian</dc:title>
 <dc:creator>Addario-Berry, Louigi</dc:creator>
 <dc:creator>Devroye, Luc</dc:creator>
 <dc:creator>Lugosi, Gabor</dc:creator>
 <dc:creator>Oliveira, Roberto Imbuzeiro</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We study local optima of the Hamiltonian of the Sherrington-Kirkpatrick
model. We compute the exponent of the expected number of local optima and
determine the &quot;typical&quot; value of the Hamiltonian.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07778</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-Aware Semantic Inpainting</dc:title>
 <dc:creator>Li, Haofeng</dc:creator>
 <dc:creator>Li, Guanbin</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Yu, Yizhou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently image inpainting has witnessed rapid progress due to generative
adversarial networks (GAN) that are able to synthesize realistic contents.
However, most existing GAN-based methods for semantic inpainting apply an
auto-encoder architecture with a fully connected layer, which cannot accurately
maintain spatial information. In addition, the discriminator in existing GANs
struggle to understand high-level semantics within the image context and yield
semantically consistent content. Existing evaluation criteria are biased
towards blurry results and cannot well characterize edge preservation and
visual authenticity in the inpainting results. In this paper, we propose an
improved generative adversarial network to overcome the aforementioned
limitations. Our proposed GAN-based framework consists of a fully convolutional
design for the generator which helps to better preserve spatial structures and
a joint loss function with a revised perceptual loss to capture high-level
semantics in the context. Furthermore, we also introduce two novel measures to
better assess the quality of image inpainting results. Experimental results
demonstrate that our method outperforms the state of the art under a wide range
of criteria.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07781</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Outage Analysis and Finite SNR Diversity-Multiplexing Tradeoff of
  Hybrid-Duplex Systems for Aeronautical Communications</dc:title>
 <dc:creator>Ernest, Tan Zheng Hui</dc:creator>
 <dc:creator>Madhukumar, A S</dc:creator>
 <dc:creator>Sirigina, Rajendra Prasad</dc:creator>
 <dc:creator>Krishna, Anoop Kumar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A hybrid-duplex aeronautical communication system (HBD-ACS) consisting of a
full-duplex (FD) enabled ground station (GS), and two half-duplex (HD)
air-stations (ASs) is proposed as a direct solution to the spectrum crunch
faced by the aviation industry. Closed-form outage probability and finite
signal-to-noise ratio (SNR) diversity gain expressions in aeronautical
communications over Rician fading channels are derived for a successive
interference cancellation (SIC) detector. Similar expressions are also
presented for an interference ignorant (II) detector and HD-equivalent modes at
GS and ASs. Through outage and finite SNR diversity gain analysis conducted at
the nodes, and system level, residual SI and inter-AS interference are found to
be the primary limiting factors in the proposed HBD-ACS. Additional analysis
also revealed that the II and SIC detectors in the proposed HBD-ACS are
suitable for weak and strong interference scenarios, respectively. When
compared to HD-ACS, the proposed HBD-ACS achieves lower outage probability and
higher diversity gains at higher multiplexing gains when operating at low SNRs.
Finite SNR analysis also showed the possibility of the proposed HBD-ACS being
able to attain interference-free diversity gains through proper management of
residual SI. Hence, the proposed HBD-ACS is more reliable and can provide
better throughput compared to existing HD-ACS at low-to-moderate SNRs.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07783</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skew cyclic codes over $\mathbb{F}_{p}+u\mathbb{F}_{p}$</dc:title>
 <dc:creator>Dastbasteh, Reza</dc:creator>
 <dc:creator>Mousavi, Seyyed Hamed</dc:creator>
 <dc:creator>Abualrub, Taher</dc:creator>
 <dc:creator>Aydin, Nuh</dc:creator>
 <dc:creator>Haghighat, Javad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study skew cyclic codes with arbitrary length over the ring
$R=\mathbb{F}_{p}+u\mathbb{F}_{p}$ where $p$ is an odd prime and $% u^{2}=0$.
We characterize all skew cyclic codes of length $n$ as left $% R[x;\theta
]$-submodules of $R_{n}=R[x;\theta ]/\langle x^{n}-1\rangle $. We find all
generator polynomials for these codes and describe their minimal spanning sets.
Moreover, an encoding and decoding algorithm is presented for skew cyclic codes
over the ring $R$. Finally, based on the theory we developed in this paper, we
provide examples of codes with good parameters over $F_{p}$ with different odd
prime $p.$ In fact, example 25 in our paper is a new ternary code in the class
of quasi-twisted codes. The other examples we provided are examples of optimal
codes.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07788</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Unsupervised Clustering Using Mixture of Autoencoders</dc:title>
 <dc:creator>Zhang, Dejiao</dc:creator>
 <dc:creator>Sun, Yifan</dc:creator>
 <dc:creator>Eriksson, Brian</dc:creator>
 <dc:creator>Balzano, Laura</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Unsupervised clustering is one of the most fundamental challenges in machine
learning. A popular hypothesis is that data are generated from a union of
low-dimensional nonlinear manifolds; thus an approach to clustering is
identifying and separating these manifolds. In this paper, we present a novel
approach to solve this problem by using a mixture of autoencoders. Our model
consists of two parts: 1) a collection of autoencoders where each autoencoder
learns the underlying manifold of a group of similar objects, and 2) a mixture
assignment neural network, which takes the concatenated latent vectors from the
autoencoders as input and infers the distribution over clusters. By jointly
optimizing the two parts, we simultaneously assign data to clusters and learn
the underlying manifolds of each cluster.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07793</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Dissipativity Theory to Compositional Construction of Finite Markov
  Decision Processes</dc:title>
 <dc:creator>Lavaei, Abolfazl</dc:creator>
 <dc:creator>Soudjani, Sadegh</dc:creator>
 <dc:creator>Zamani, Majid</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper is concerned with a compositional approach for constructing finite
Markov decision processes of interconnected discrete-time stochastic control
systems. The proposed approach leverages the interconnection topology and a
notion of so-called stochastic storage functions describing joint
dissipativity-type properties of subsystems and their abstractions. In the
first part of the paper, we derive dissipativity-type compositional conditions
for quantifying the error between the interconnection of stochastic control
subsystems and that of their abstractions. In the second part of the paper, we
propose an approach to construct finite Markov decision processes together with
their corresponding stochastic storage functions for classes of discrete-time
control systems satisfying some incremental passivablity property. Under this
property, one can construct finite Markov decision processes by a suitable
discretization of the input and state sets. Moreover, we show that for linear
stochastic control systems, the aforementioned property can be readily checked
by some matrix inequality. We apply our proposed results to the temperature
regulation in a circular building by constructing compositionally a finite
Markov decision process of a network containing 200 rooms in which the
compositionality condition does not require any constraint on the number or
gains of the subsystems. We employ the constructed finite Markov decision
process as a substitute to synthesize policies regulating the temperature in
each room for a bounded time horizon.
</dc:description>
 <dc:description>Comment: This work is accepted at the 21st ACM International Conference on
  Hybrid Systems: Computation and Control (HSCC),to be held in Porto from 11 to
  13 April, 2018</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07794</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Character Thinks Ahead: creative writing with deep learning nets and
  its stylistic assessment</dc:title>
 <dc:creator>Dean, Roger T.</dc:creator>
 <dc:creator>Smith, Hazel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We discuss how to control outputs from deep learning models of text corpora
so as to create contemporary poetic works. We assess whether these controls are
successful in the immediate sense of creating stylo- metric distinctiveness.
The specific context is our piece The Character Thinks Ahead (2016/17); the
potential applications are broad.
</dc:description>
 <dc:description>Comment: A 2 page paper in press in Leonardo Vol 51, 2018. Yet to be
  copy-edited</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07798</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep learning for predicting refractive error from retinal fundus images</dc:title>
 <dc:creator>Varadarajan, Avinash V.</dc:creator>
 <dc:creator>Poplin, Ryan</dc:creator>
 <dc:creator>Blumer, Katy</dc:creator>
 <dc:creator>Angermueller, Christof</dc:creator>
 <dc:creator>Ledsam, Joe</dc:creator>
 <dc:creator>Chopra, Reena</dc:creator>
 <dc:creator>Keane, Pearse A.</dc:creator>
 <dc:creator>Corrado, Greg S.</dc:creator>
 <dc:creator>Peng, Lily</dc:creator>
 <dc:creator>Webster, Dale R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Refractive error, one of the leading cause of visual impairment, can be
corrected by simple interventions like prescribing eyeglasses. We trained a
deep learning algorithm to predict refractive error from the fundus photographs
from participants in the UK Biobank cohort, which were 45 degree field of view
images and the AREDS clinical trial, which contained 30 degree field of view
images. Our model use the &quot;attention&quot; method to identify features that are
correlated with refractive error. Mean absolute error (MAE) of the algorithm's
prediction compared to the refractive error obtained in the AREDS and UK
Biobank. The resulting algorithm had a MAE of 0.56 diopters (95% CI: 0.55-0.56)
for estimating spherical equivalent on the UK Biobank dataset and 0.91 diopters
(95% CI: 0.89-0.92) for the AREDS dataset. The baseline expected MAE (obtained
by simply predicting the mean of this population) was 1.81 diopters (95% CI:
1.79-1.84) for UK Biobank and 1.63 (95% CI: 1.60-1.67) for AREDS. Attention
maps suggested that the foveal region was one of the most important areas used
by the algorithm to make this prediction, though other regions also contribute
to the prediction. The ability to estimate refractive error with high accuracy
from retinal fundus photos has not been previously known and demonstrates that
deep learning can be applied to make novel predictions from medical images.
Given that several groups have recently shown that it is feasible to obtain
retinal fundus photos using mobile phones and inexpensive attachments, this
work may be particularly relevant in regions of the world where autorefractors
may not be readily available.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07799</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Deep Improviser: a prototype deep learning post-tonal free
  music generator</dc:title>
 <dc:creator>Dean, Roger T.</dc:creator>
 <dc:creator>Forth, Jamie</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Two modest-sized symbolic corpora of post-tonal and post-metric keyboard
music have been constructed, one algorithmic, the other improvised. Deep
learning models of each have been trained and largely optimised. Our purpose is
to obtain a model with sufficient generalisation capacity that in response to a
small quantity of separate fresh input seed material, it can generate outputs
that are distinctive, rather than recreative of the learned corpora or the seed
material. This objective has been first assessed statistically, and as judged
by k-sample Anderson-Darling and Cramer tests, has been achieved. Music has
been generated using the approach, and informal judgements place it roughly on
a par with algorithmic and composed music in related forms. Future work will
aim to enhance the model such that it can be evaluated in relation to
expression, meaning and utility in real-time performance.
</dc:description>
 <dc:description>Comment: 13 pages, 1 Figure, 3 Tables</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07800</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-Based Clustering of Nonparametric Weighted Networks</dc:title>
 <dc:creator>Agarwal, Amal</dc:creator>
 <dc:creator>Xue, Lingzhou</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Water pollution is a major global environmental problem, and it poses a great
environmental risk to public health and biological diversity. This work is
motivated by assessing the potential environmental threat of coal mining
through increased sulfate concentrations in river networks, which do not belong
to any simple parametric distribution. However, existing network models mainly
focus on binary or discrete networks and weighted networks with known
parametric weight distributions. We propose a principled nonparametric weighted
network model based on exponential-family random graph models and local
likelihood estimation and study its model-based clustering with application to
large-scale water pollution network analysis. We do not require any parametric
distribution assumption on network weights. The proposed method greatly extends
the methodology and applicability of statistical network models. Furthermore,
it is scalable to large and complex networks in large-scale environmental
studies and geoscientific research. The power of our proposed methods is
demonstrated in simulation studies.
</dc:description>
 <dc:description>Comment: 21 pages, 3 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07804</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ARJA: Automated Repair of Java Programs via Multi-Objective Genetic
  Programming</dc:title>
 <dc:creator>Yuan, Yuan</dc:creator>
 <dc:creator>Banzhaf, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Recent empirical studies show that the performance of GenProg is not
satisfactory, particularly for Java. In this paper, we propose ARJA, a new GP
based repair approach for automated repair of Java programs. To be specific, we
present a novel lower-granularity patch representation that properly decouples
the search subspaces of likely-buggy locations, operation types and potential
fix ingredients, enabling GP to explore the search space more effectively.
Based on this new representation, we formulate automated program repair as a
multi-objective search problem and use NSGA-II to look for simpler repairs. To
reduce the computational effort and search space, we introduce a test filtering
procedure that can speed up the fitness evaluation of GP and three types of
rules that can be applied to avoid unnecessary manipulations of the code.
Moreover, we also propose a type matching strategy that can create new
potential fix ingredients by exploiting the syntactic patterns of the existing
statements. We conduct a large-scale empirical evaluation of ARJA along with
its variants on both seeded bugs and real-world bugs in comparison with several
state-of-the-art repair approaches. Our results verify the effectiveness and
efficiency of the search mechanisms employed in ARJA and also show its
superiority over the other approaches. In particular, compared to jGenProg (an
implementation of GenProg for Java), an ARJA version fully following the
redundancy assumption can generate a test-suite adequate patch for more than
twice the number of bugs (from 27 to 59), and a correct patch for nearly four
times of the number (from 5 to 18), on 224 real-world bugs considered in
Defects4J. Furthermore, ARJA is able to correctly fix several real
multi-location bugs that are hard to be repaired by most of the existing repair
approaches.
</dc:description>
 <dc:description>Comment: 30 pages, 26 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07805</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wolf in Sheep's Clothing - The Downscaling Attack Against Deep Learning
  Applications</dc:title>
 <dc:creator>Xiao, Qixue</dc:creator>
 <dc:creator>Li, Kang</dc:creator>
 <dc:creator>Zhang, Deyue</dc:creator>
 <dc:creator>Jin, Yier</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper considers security risks buried in the data processing pipeline in
common deep learning applications. Deep learning models usually assume a fixed
scale for their training and input data. To allow deep learning applications to
handle a wide range of input data, popular frameworks, such as Caffe,
TensorFlow, and Torch, all provide data scaling functions to resize input to
the dimensions used by deep learning models. Image scaling algorithms are
intended to preserve the visual features of an image after scaling. However,
common image scaling algorithms are not designed to handle human crafted
images. Attackers can make the scaling outputs look dramatically different from
the corresponding input images.
  This paper presents a downscaling attack that targets the data scaling
process in deep learning applications. By carefully crafting input data that
mismatches with the dimension used by deep learning models, attackers can
create deceiving effects. A deep learning application effectively consumes data
that are not the same as those presented to users. The visual inconsistency
enables practical evasion and data poisoning attacks to deep learning
applications. This paper presents proof-of-concept attack samples to popular
deep-learning-based image classification applications. To address the
downscaling attacks, the paper also suggests multiple potential mitigation
strategies.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07807</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fault Tolerance of Random Graphs with respect to Connectivity: Phase
  Transition in Logarithmic Average Degree</dc:title>
 <dc:creator>Takabe, Satoshi</dc:creator>
 <dc:creator>Nakano, Takafumi</dc:creator>
 <dc:creator>Wadayama, Tadashi</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The fault tolerance of random graphs with unbounded degrees with respect to
connectivity is investigated. It is related to the reliability of wireless
sensor networks with unreliable relay nodes. The model evaluates the network
breakdown probability that a graph is disconnected after stochastic node
removal. To establish a mean-field approximation for the model, the cavity
method for finite systems is proposed. Then the asymptotic analysis is applied.
As a result, the former enables us to obtain an approximation formula for any
number of nodes and an arbitrary and degree distribution. In addition, the
latter reveals that the phase transition occurs on random graphs with
logarithmic average degrees. Those results, which are supported by numerical
simulations, coincide with the mathematical results, indicating successful
predictions by mean-field approximation for unbounded but not dense random
graphs.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07810</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Steering to Manage Interference</dc:title>
 <dc:creator>Li, Zhao</dc:creator>
 <dc:creator>Guo, Fengjuan</dc:creator>
 <dc:creator>Shin, Kang G</dc:creator>
 <dc:creator>Liu, Yinghou</dc:creator>
 <dc:creator>Liu, Jia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To enable densely deployed base stations (BSs) or access points (APs) to
serve an increasing number of users and provide diverse mobile services, we
need to improve spectrum utilization in wireless communication networks.
Although spectral efficiency (SE) can be enhanced via smart and dynamic
resource allocation, interference has become a major impediment in improving
SE. There have been numerous interference management (IM) proposals at the
interfering transmitter or the victim transmitter/receiver separately or
cooperatively. Moreover, the existing IM schemes rely mainly on the use of
channel state information (CSI). However, in some communication scenarios, the
option to adjust the interferer is not available, and, in the case of downlink
transmission, it is always difficult or even impossible for the victim receiver
to acquire necessary information for IM. Based on the above observations, we
first propose a novel IM technique, called interference steering (IS). By
making use of both CSI w.r.t. and data carried in the interfering signal, IS
generates a signal to modify the spatial feature of the original interference,
so that the steered interference at the victim receiver is orthogonal to its
intended signal. We then apply IS to an infrastructurebased enterprise wireless
local area network (WLAN) in which the same frequency band is reused by
adjacent basic service sets (BSSs) with overlapping areas. With IS, multiple
nearby APs could simultaneously transmit data on the same channel to their
mobile stations (STAs), thus enhancing spectrum reuse. Our in-depth simulation
results show that IS significantly improves network SE over existing IM
schemes.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07811</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-dimensional Graph Fourier Transform</dc:title>
 <dc:creator>Kurokawa, Takashi</dc:creator>
 <dc:creator>Oki, Taihei</dc:creator>
 <dc:creator>Nagao, Hiromichi</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many signals on Cartesian product graphs appear in the real world, such as
digital images, sensor observation time series, and movie ratings on Netflix.
These signals are &quot;multi-dimensional&quot; and have directional characteristics
along each factor graph. However, the existing graph Fourier transform does not
distinguish these directions, and assigns 1-D spectra to signals on product
graphs. Further, these spectra are often multi-valued at some frequencies. Our
main result is a multi-dimensional graph Fourier transform that solves such
problems associated with the conventional GFT. Using algebraic properties of
Cartesian products, the proposed transform rearranges 1-D spectra obtained by
the conventional GFT into the multi-dimensional frequency domain, of which each
dimension represents a directional frequency along each factor graph. Thus, the
multi-dimensional graph Fourier transform enables directional frequency
analysis, in addition to frequency analysis with the conventional GFT.
Moreover, this rearrangement resolves the multi-valuedness of spectra in some
cases. The multi-dimensional graph Fourier transform is a foundation of novel
filterings and stationarities that utilize dimensional information of graph
signals, which are also discussed in this study. The proposed methods are
applicable to a wide variety of data that can be regarded as signals on
Cartesian product graphs. This study also notes that multivariate graph signals
can be regarded as 2-D univariate graph signals. This correspondence provides
natural definitions of the multivariate graph Fourier transform and the
multivariate stationarity based on their 2-D univariate versions.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07814</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Indoor Sound Source Localization with Probabilistic Neural Network</dc:title>
 <dc:creator>Sun, Yingxiang</dc:creator>
 <dc:creator>Chen, Jiajia</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:creator>Rahardja, Susanto</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  It is known that adverse environments such as high reverberation and low
signal-to-noise ratio (SNR) pose a great challenge to indoor sound source
localization. To address this challenge, in this paper, we propose a sound
source localization algorithm based on probabilistic neural network, namely
Generalized cross correlation Classification Algorithm (GCA). Experimental
results for adverse environments with high reverberation time T60 up to 600ms
and low SNR such as -10dB show that, the average azimuth angle error and
elevation angle error by GCA are only 4.6 degrees and 3.1 degrees respectively.
Compared with three recently published algorithms, GCA has increased the
success rate on direction of arrival estimation significantly with good
robustness to environmental changes. These results show that the proposed GCA
can localize accurately and robustly for diverse indoor applications where the
site acoustic features can be studied prior to the localization stage.
</dc:description>
 <dc:description>Comment: 10 pages, accepted by IEEE Transactions on Industrial Electronics</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07814</dc:identifier>
 <dc:identifier>doi:10.1109/TIE.2017.2786219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07816</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acoustic Denial of Service Attacks on HDDs</dc:title>
 <dc:creator>Shahrad, Mohammad</dc:creator>
 <dc:creator>Mosenia, Arsalan</dc:creator>
 <dc:creator>Song, Liwei</dc:creator>
 <dc:creator>Chiang, Mung</dc:creator>
 <dc:creator>Wentzlaff, David</dc:creator>
 <dc:creator>Mittal, Prateek</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Among storage components, hard disk drives (HDDs) have become the most
commonly-used type of non-volatile storage due to their recent technological
advances, including, enhanced energy efficacy and significantly-improved areal
density. Such advances in HDDs have made them an inevitable part of numerous
computing systems, including, personal computers, closed-circuit television
(CCTV) systems, medical bedside monitors, and automated teller machines (ATMs).
Despite the widespread use of HDDs and their critical role in real-world
systems, there exist only a few research studies on the security of HDDs. In
particular, prior research studies have discussed how HDDs can potentially leak
critical private information through acoustic or electromagnetic emanations.
Borrowing theoretical principles from acoustics and mechanics, we propose a
novel denial-of-service (DoS) attack against HDDs that exploits a physical
phenomenon, known as acoustic resonance. We perform a comprehensive examination
of physical characteristics of several HDDs and create acoustic signals that
cause significant vibrations in HDD's internal components. We demonstrate that
such vibrations can negatively influence the performance of HDDs embedded in
real-world systems. We show the feasibility of the proposed attack in two
real-world case studies, namely, personal computers and CCTVs.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07822</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometrical Insights for Implicit Generative Modeling</dc:title>
 <dc:creator>Bottou, Leon</dc:creator>
 <dc:creator>Arjovsky, Martin</dc:creator>
 <dc:creator>Lopez-Paz, David</dc:creator>
 <dc:creator>Oquab, Maxime</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning algorithms for implicit generative models can optimize a variety of
criteria that measure how the data distribution differs from the implicit model
distribution, including the Wasserstein distance, the Energy distance, and the
Maximum Mean Discrepancy criterion. A careful look at the geometries induced by
these distances on the space of probability measures reveals interesting
differences. In particular, we can establish surprising approximate global
convergence guarantees for the $1$-Wasserstein distance,even when the
parametric generator has a nonconvex parametrization.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07834</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DropMax: Adaptive Stochastic Softmax</dc:title>
 <dc:creator>Lee, Hae Beom</dc:creator>
 <dc:creator>Lee, Juho</dc:creator>
 <dc:creator>Yang, Eunho</dc:creator>
 <dc:creator>Hwang, Sung Ju</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose DropMax, a stochastic version of softmax classifier which at each
iteration drops non-target classes with some probability, for each instance.
Specifically, we overlay binary masking variables over class output
probabilities, which are learned based on the input via regularized variational
inference. This stochastic regularization has an effect of building an ensemble
classifier out of exponential number of classifiers with different decision
boundaries. Moreover, the learning of dropout probabilities for non-target
classes on each instance allows the classifier to focus more on classification
against the most confusing classes. We validate our model on multiple public
datasets for classification, on which it obtains improved accuracy over regular
softmax classifier and other baselines. Further analysis of the learned dropout
masks shows that our model indeed selects confusing classes more often when it
performs classification.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07835</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Models and Data for Remote Sensing Image Caption Generation</dc:title>
 <dc:creator>Lu, Xiaoqiang</dc:creator>
 <dc:creator>Wang, Binqiang</dc:creator>
 <dc:creator>Zheng, Xiangtao</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68</dc:subject>
 <dc:description>  Inspired by recent development of artificial satellite, remote sensing images
have attracted extensive attention. Recently, noticeable progress has been made
in scene classification and target detection.However, it is still not clear how
to describe the remote sensing image content with accurate and concise
sentences. In this paper, we investigate to describe the remote sensing images
with accurate and flexible sentences. First, some annotated instructions are
presented to better describe the remote sensing images considering the special
characteristics of remote sensing images. Second, in order to exhaustively
exploit the contents of remote sensing images, a large-scale aerial image data
set is constructed for remote sensing image caption. Finally, a comprehensive
review is presented on the proposed data set to fully advance the task of
remote sensing caption. Extensive experiments on the proposed data set
demonstrate that the content of the remote sensing image can be completely
described by generating language descriptions. The data set is available at
https://github.com/201528014227051/RSICD_optimal
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07840</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Methodological Framework for Determining the Land Eligibility of
  Renewable Energy Sources</dc:title>
 <dc:creator>Ryberg, David Severin</dc:creator>
 <dc:creator>Robinius, Martin</dc:creator>
 <dc:creator>Stolten, Detlef</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  The quantity and distribution of land which is eligible for renewable energy
sources is fundamental to the role these technologies will play in future
energy systems. As it stands, however, the current state of land eligibility
investigation is found to be insufficient to meet the demands of the future
energy modelling community. Three key areas are identified as the predominate
causes of this; inconsistent criteria definitions, inconsistent or unclear
methodologies, and inconsistent dataset usage. To combat these issues, a land
eligibility framework is developed and described in detail. The validity of
this framework is then shown via the recreation of land eligibility results
found in the literature, showing strong agreement in the majority of cases.
Following this, the framework is used to perform an evaluation of land
eligibility criteria within the European context whereby the relative
importance of commonly considered criteria are compared.
</dc:description>
 <dc:description>Comment: Methodology, validation, and meta application of GLAES model, 35
  Pages, 7 Figures, 6 Tables, 2 Appendixes</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07844</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory-induced mechanism for self-sustaining activity in networks</dc:title>
 <dc:creator>Allahverdyan, A. E.</dc:creator>
 <dc:creator>Steeg, G. Ver</dc:creator>
 <dc:creator>Galstyan, A.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We study a mechanism of activity sustaining on networks inspired by a
well-known model of neuronal dynamics. Our primary focus is the emergence of
self-sustaining collective activity patterns, where no single node can stay
active by itself, but the activity provided initially is sustained within the
collective of interacting agents. In contrast to existing models of
self-sustaining activity that are caused by (long) loops present in the
network, here we focus on tree--like structures and examine activation
mechanisms that are due to temporal memory of the nodes. This approach is
motivated by applications in social media, where long network loops are rare or
absent. Our results suggest that under a weak behavioral noise, the nodes
robustly split into several clusters, with partial synchronization of nodes
within each cluster. We also study the randomly-weighted version of the models
where the nodes are allowed to change their connection strength (this can model
attention redistribution), and show that it does facilitate the self-sustained
activity.
</dc:description>
 <dc:description>Comment: 23 pages, 12 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07844</dc:identifier>
 <dc:identifier>Physical Review E 92, 062824 (2015)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.92.062824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07846</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Exploitation Precoding Made Practical: Closed-Form
  Solutions with Optimal Performance</dc:title>
 <dc:creator>Li, Ang</dc:creator>
 <dc:creator>Masouros, Christos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose closed-form precoding schemes with optimal
performance for constructive interference (CI) exploitation in the multiuser
multiple-input single-output (MU-MISO) downlink. We first consider an
optimization where we maximize the distance between the constructive region and
the detection thresholds. The cases of both strict and non-strict phase
rotation are considered and can further be formulated as convex optimization
problems. For optimization with strict phase rotation, we mathematically derive
the optimal beamforming structure with Lagrangian and Karush-Kuhn-Tucker (KKT)
conditions. By formulating its dual problem, the optimization problem is
further shown to be equivalent to a quadratic programming (QP) over a simplex,
which can be solved more efficiently. We then extend our analysis to the case
of non-strict phase rotation, where it is mathematically shown that a
K-dimensional optimization for non-strict phase rotation is equivalent to a
2K-dimensional optimization for strict phase rotation in terms of the problem
formulation. The connection with the conventional zero-forcing (ZF) precoding
is also discussed. Based on the above analysis, we further propose an iterative
closed-form scheme to obtain the optimal beamforming matrix, where within each
iteration a closed-form solution can be obtained. Numerical results validate
our analysis and the optimality of the proposed iterative scheme, and further
show that the proposed closed-form scheme is more efficient than the
conventional QP algorithms with interior-point methods, which motivates the use
of CI beamforming in practical wireless systems.
</dc:description>
 <dc:description>Comment: submitted to IEEE transactions</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07856</identifier>
 <datestamp>2018-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bisymmetric and quasitrivial operations: characterizations and
  enumerations</dc:title>
 <dc:creator>Devillet, Jimmy</dc:creator>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>06A05, 20M10, 20M14 (Primary), 05A15, 39B72 (Secondary)</dc:subject>
 <dc:description>  We investigate the class of bisymmetric and quasitrivial binary operations on
a given set $X$ and provide various characterizations of this class as well as
the subclass of bisymmetric, quasitrivial, and order-preserving binary
operations. We also determine explicitly the sizes of these classes when the
set $X$ is finite.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1709.09162</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07861</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PHOEG Helps Obtaining Extremal Graphs</dc:title>
 <dc:creator>Devillez, Gauvain</dc:creator>
 <dc:creator>Hauweele, Pierre</dc:creator>
 <dc:creator>M&#xe9;lot, Hadrien</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Extremal Graph Theory aims to determine bounds for graph invariants as well
as the graphs attaining those bounds.
  We are currently developping PHOEG, an ecosystem of tools designed to help
researchers in Extremal Graph Theory.
  It uses a big relational database of undirected graphs and works with the
convex hull of the graphs as points in the invariants space in order to exactly
obtain the extremal graphs and optimal bounds on the invariants for some fixed
parameters. The results obtained on the restricted finite class of graphs can
later be used to infer conjectures. This database also allows us to make
queries on those graphs. Once the conjecture defined, PHOEG goes one step
further by helping in the process of designing a proof guided by successive
applications of transformations from any graph to an extremal graph. To this
aim, we use a second database based on a graph data model.
  The paper presents ideas and techniques used in PHOEG to assist the study of
Extremal Graph Theory.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures, 1 table, technical paper</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07863</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Information Dimension of Multivariate Gaussian Processes</dc:title>
 <dc:creator>Geiger, Bernhard C.</dc:creator>
 <dc:creator>Koch, Tobias</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The authors have recently defined the R\'enyi information dimension rate
$d(\{X_t\})$ of a stationary stochastic process $\{X_t,\,t\in\mathbb{Z}\}$ as
the entropy rate of the uniformly-quantized process divided by minus the
logarithm of the quantizer step size $1/m$ in the limit as $m\to\infty$ (B.
Geiger and T. Koch, &quot;On the information dimension rate of stochastic
processes,&quot; in Proc. IEEE Int. Symp. Inf. Theory (ISIT), Aachen, Germany, June
2017). For Gaussian processes with a given spectral distribution function
$F_X$, they showed that the information dimension rate equals the Lebesgue
measure of the set of harmonics where the derivative of $F_X$ is positive. This
paper extends this result to multivariate Gaussian processes with a given
matrix-valued spectral distribution function $F_{\mathbf{X}}$. It is
demonstrated that the information dimension rate equals the average rank of the
derivative of $F_{\mathbf{X}}$. As a side result, it is shown that the scale
and translation invariance of information dimension carries over from random
variables to stochastic processes.
</dc:description>
 <dc:description>Comment: This work will be presented in part at the 2018 International Zurich
  Seminar on Information and Communication</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07867</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smallest snarks with oddness 4 and cyclic connectivity 4 have order 44</dc:title>
 <dc:creator>Goedgebeur, Jan</dc:creator>
 <dc:creator>M&#xe1;&#x10d;ajov&#xe1;, Edita</dc:creator>
 <dc:creator>&#x160;koviera, Martin</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The family of snarks -- connected bridgeless cubic graphs that cannot be
3-edge-coloured -- is well-known as a potential source of counterexamples to
several important and long-standing conjectures in graph theory. These include
the cycle double cover conjecture, Tutte's 5-flow conjecture, Fulkerson's
conjecture, and several others. One way of approaching these conjectures is
through the study of structural properties of snarks and construction of small
examples with given properties. In this paper we deal with the problem of
determining the smallest order of a nontrivial snark (that is, one which is
cyclically 4-edge-connected and has girth at least 5) of oddness at least 4.
Using a combination of structural analysis with extensive computations we prove
that the smallest order of a snark with oddness at least 4 and cyclic
connectivity 4 is 44. Formerly it was known that such a snark must have at
least 38 vertices [J. Combin. Theory Ser. B 103 (2013), 468--488] and one such
snark on 44 vertices was constructed by Lukot'ka et al. [Electron. J. Combin.
22 (2015), #P1.51]. The proof requires determining all cyclically
4-edge-connected snarks on 36 vertices, which extends the previously compiled
list of all such snarks up to 34 vertices [J. Combin. Theory Ser. B, loc.
cit.]. As a by-product, we use this new list to test the validity of several
conjectures where snarks can be smallest counterexamples.
</dc:description>
 <dc:description>Comment: 20 pages; submitted for publication</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07880</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enumeration Complexity of Conjunctive Queries with Functional
  Dependencies</dc:title>
 <dc:creator>Carmeli, Nofar</dc:creator>
 <dc:creator>Kr&#xf6;ll, Markus</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:description>  We study the complexity of enumerating the answers of Conjunctive Queries
(CQs) in the presence of Functional Dependencies (FDs). Our focus is on the
ability to list output tuples with a constant delay in between, following a
linear-time preprocessing. A known dichotomy classifies the acyclic
self-join-free CQs into those that admit such enumeration, and those that do
not. However, this classification no longer holds in the common case where the
database exhibits dependencies among attributes. That is, some queries that are
classified as hard are in fact tractable if dependencies are accounted for. We
establish a generalization of the dichotomy to accommodate FDs; hence, our
classification determines which combination of a CQ and a set of FDs admits
constant-delay enumeration with a linear-time preprocessing.
  In addition, we generalize a hardness result for cyclic CQs to accommodate a
common type of FDs. Further conclusions of our development include a dichotomy
for enumeration with linear delay, and a dichotomy for CQs with disequalities.
Finally, we show that all our results apply to the known class of &quot;cardinality
dependencies&quot; that generalize FDs (e.g., by stating an upper bound on the
number of genres per movies, or friends per person).
</dc:description>
 <dc:description>Comment: Full version of an article to be published in ICDT 2018</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07881</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulating Patho-realistic Ultrasound Images using Deep Generative
  Networks with Adversarial Learning</dc:title>
 <dc:creator>Tom, Francis</dc:creator>
 <dc:creator>Sheet, Debdoot</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Ultrasound imaging makes use of backscattering of waves during their
interaction with scatterers present in biological tissues. Simulation of
synthetic ultrasound images is a challenging problem on account of inability to
accurately model various factors of which some include intra-/inter scanline
interference, transducer to surface coupling, artifacts on transducer elements,
inhomogeneous shadowing and nonlinear attenuation. Current approaches typically
solve wave space equations making them computationally expensive and slow to
operate. We propose a generative adversarial network (GAN) inspired approach
for fast simulation of patho-realistic ultrasound images. We apply the
framework to intravascular ultrasound (IVUS) simulation. A stage 0 simulation
performed using pseudo B-mode ultrasound image simulator yields speckle mapping
of a digitally defined phantom. The stage I GAN subsequently refines them to
preserve tissue specific speckle intensities. The stage II GAN further refines
them to generate high resolution images with patho-realistic speckle profiles.
We evaluate patho-realism of simulated images with a visual Turing test
indicating an equivocal confusion in discriminating simulated from real. We
also quantify the shift in tissue specific intensity distributions of the real
and simulated images to prove their similarity.
</dc:description>
 <dc:description>Comment: To appear in the Proceedings of the 2018 IEEE International Symposium
  on Biomedical Imaging (ISBI 2018)</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07882</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Pyramid Scheme: Oblivious RAM for Trusted Processors</dc:title>
 <dc:creator>Costa, Manuel</dc:creator>
 <dc:creator>Esswood, Lawrence</dc:creator>
 <dc:creator>Ohrimenko, Olga</dc:creator>
 <dc:creator>Schuster, Felix</dc:creator>
 <dc:creator>Wagh, Sameer</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Modern processors, e.g., Intel SGX, allow applications to isolate secret code
and data in encrypted memory regions called enclaves. While encryption
effectively hides the contents of memory, the sequence of address references
issued by the secret code leaks information. This is a serious problem because
these leaks can easily break the confidentiality guarantees of enclaves.
  In this paper, we explore Oblivious RAM (ORAM) designs that prevent these
information leaks under the constraints of modern SGX processors. Most ORAMs
are a poor fit for these processors because they have high constant overhead
factors or require large private memories, which are not available in these
processors. We address these limitations with a new hierarchical ORAM
construction, the Pyramid ORAM, that is optimized towards online bandwidth cost
and small blocks. It uses a new hashing scheme that circumvents the complexity
of previous hierarchical schemes.
  We present an efficient x64-optimized implementation of Pyramid ORAM that
uses only the processor's registers as private memory. We compare Pyramid ORAM
with Circuit ORAM, a state-of-the-art tree-based ORAM scheme that also uses
constant private memory. Pyramid ORAM has better online asymptotical complexity
than Circuit ORAM. Our implementation of Pyramid ORAM and Circuit ORAM
validates this: as all hierarchical schemes, Pyramid ORAM has high variance of
access latencies; although latency can be high for some accesses, for typical
configurations Pyramid ORAM provides access latencies that are 8X better than
Circuit ORAM for 99% of accesses. Although the best known hierarchical ORAM has
better asymptotical complexity, Pyramid ORAM has significantly lower constant
overhead factors, making it the preferred choice in practice.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07886</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximally Distant Cross Domain Generators for Estimating Per-Sample
  Error</dc:title>
 <dc:creator>Benaim, Sagie</dc:creator>
 <dc:creator>Galanti, Tomer</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  While in supervised learning, the validation error is an unbiased estimator
of the generalization (test) error and complexity-based generalization bounds
are abundant, no such bounds exist for learning a mapping in an unsupervised
way. As a result, when training GANs and specifically when using GANs for
learning to map between domains in a completely unsupervised way, one is forced
to select the hyperparameters and the stopping epoch by subjectively examining
multiple options. We propose a novel bound for predicting the success of
unsupervised cross domain mapping methods, which is motivated by the recently
proposed simplicity hypothesis. The bound can be applied both in expectation,
for comparing hyperparameters, or per sample, in order to predict the success
of a specific cross-domain translation. The utility of the bound is
demonstrated in an extensive set of experiments employing multiple recent
algorithms.
</dc:description>
 <dc:description>Comment: The first and second authors contributed equally</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07887</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiagent-based Participatory Urban Simulation through Inverse
  Reinforcement Learning</dc:title>
 <dc:creator>Suzuki, Soma</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The multiagent-based participatory simulation features prominently in urban
planning as the acquired model is considered as the hybrid system of the domain
and the local knowledge. However, the key problem of generating realistic
agents for particular social phenomena invariably remains. The existing models
have attempted to dictate the factors involving human behavior, which appeared
to be intractable. In this paper, Inverse Reinforcement Learning (IRL) is
introduced to address this problem. IRL is developed for computational modeling
of human behavior and has achieved great successes in robotics, psychology and
machine learning. The possibilities presented by this new style of modeling are
drawn out as conclusions, and the relative challenges with this modeling are
highlighted.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07890</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Recursive Construction of Permutation Polynomials over
  $\mathbb{F}_{q^2}$ with Odd Characteristic from R\'{e}dei Functions</dc:title>
 <dc:creator>Fu, Shihui</dc:creator>
 <dc:creator>Feng, Xiutao</dc:creator>
 <dc:creator>Lin, Dongdai</dc:creator>
 <dc:creator>Wang, Qiang</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>11T06, 11T55, 05A05</dc:subject>
 <dc:description>  In this paper, we construct two classes of permutation polynomials over
$\mathbb{F}_{q^2}$ with odd characteristic from rational R\'{e}dei functions. A
complete characterization of their compositional inverses is also given. These
permutation polynomials can be generated recursively. As a consequence, we can
generate recursively permutation polynomials with arbitrary number of terms.
More importantly, the conditions of these polynomials being permutations are
very easy to characterize. For wide applications in practice, several classes
of permutation binomials and trinomials are given. With the help of a computer,
we find that the number of permutation polynomials of these types is very
large.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07893</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Policy Inference Q-Network for Multi-Agent Systems</dc:title>
 <dc:creator>Hong, Zhang-Wei</dc:creator>
 <dc:creator>Su, Shih-Yang</dc:creator>
 <dc:creator>Shann, Tzu-Yun</dc:creator>
 <dc:creator>Chang, Yi-Hsiang</dc:creator>
 <dc:creator>Lee, Chun-Yi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present DPIQN, a deep policy inference Q-network that targets multi-agent
systems composed of controllable agents, collaborators, and opponents that
interact with each other. We focus on one challenging issue in such
systems---modeling agents with varying strategies---and propose to employ
&quot;policy features&quot; learned from raw observations (e.g., raw images) of
collaborators and opponents by inferring their policies. DPIQN incorporates the
learned policy features as a hidden vector into its own deep Q-network (DQN),
such that it is able to predict better Q values for the controllable agents
than the state-of-the-art deep reinforcement learning models. We further
propose an enhanced version of DPIQN, called deep recurrent policy inference
Q-network (DRPIQN), for handling partial observability. Both DPIQN and DRPIQN
are trained by an adaptive training procedure, which adjusts the network's
attention to learn the policy features and its own Q-values at different phases
of the training process. We present a comprehensive analysis of DPIQN and
DRPIQN, and highlight their effectiveness and generalizability in various
multi-agent settings. Our models are evaluated in a classic soccer game
involving both competitive and collaborative scenarios. Experimental results
performed on 1 vs. 1 and 2 vs. 2 games show that DPIQN and DRPIQN demonstrate
superior performance to the baseline DQN and deep recurrent Q-network (DRQN)
models. We also explore scenarios in which collaborators or opponents
dynamically change their policies, and show that DPIQN and DRPIQN do lead to
better overall performance in terms of stability and mean scores.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07897</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-convex Optimization for Machine Learning</dc:title>
 <dc:creator>Jain, Prateek</dc:creator>
 <dc:creator>Kar, Purushottam</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  A vast majority of machine learning algorithms train their models and perform
inference by solving optimization problems. In order to capture the learning
and prediction problems accurately, structural constraints such as sparsity or
low rank are frequently imposed or else the objective itself is designed to be
a non-convex function. This is especially true of algorithms that operate in
high-dimensional spaces or that train non-linear models such as tensor models
and deep networks.
  The freedom to express the learning problem as a non-convex optimization
problem gives immense modeling power to the algorithm designer, but often such
problems are NP-hard to solve. A popular workaround to this has been to relax
non-convex problems to convex ones and use traditional methods to solve the
(convex) relaxed optimization problems. However this approach may be lossy and
nevertheless presents significant challenges for large scale optimization.
  On the other hand, direct approaches to non-convex optimization have met with
resounding success in several domains and remain the methods of choice for the
practitioner, as they frequently outperform relaxation-based techniques -
popular heuristics include projected gradient descent and alternating
minimization. However, these are often poorly understood in terms of their
convergence and other properties.
  This monograph presents a selection of recent advances that bridge a
long-standing gap in our understanding of these heuristics. The monograph will
lead the reader through several widely used non-convex optimization techniques,
as well as applications thereof. The goal of this monograph is to both,
introduce the rich literature in this area, as well as equip the reader with
the tools and techniques needed to analyze these simple procedures for
non-convex problems.
</dc:description>
 <dc:description>Comment: The official publication is available from now publishers via
  http://dx.doi.org/10.1561/2200000058</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07897</dc:identifier>
 <dc:identifier>Foundations and Trends in Machine Learning: Vol. 10: No. 3-4, pp
  142-336 (2017)</dc:identifier>
 <dc:identifier>doi:10.1561/2200000058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07901</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improvements to Inference Compilation for Probabilistic Programming in
  Large-Scale Scientific Simulators</dc:title>
 <dc:creator>Casado, Mario Lezcano</dc:creator>
 <dc:creator>Baydin, Atilim Gunes</dc:creator>
 <dc:creator>Rubio, David Martinez</dc:creator>
 <dc:creator>Le, Tuan Anh</dc:creator>
 <dc:creator>Wood, Frank</dc:creator>
 <dc:creator>Heinrich, Lukas</dc:creator>
 <dc:creator>Louppe, Gilles</dc:creator>
 <dc:creator>Cranmer, Kyle</dc:creator>
 <dc:creator>Ng, Karen</dc:creator>
 <dc:creator>Bhimji, Wahid</dc:creator>
 <dc:creator>Prabhat</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>68T37, 68T05, 62P35</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  We consider the problem of Bayesian inference in the family of probabilistic
models implicitly defined by stochastic generative models of data. In
scientific fields ranging from population biology to cosmology, low-level
mechanistic components are composed to create complex generative models. These
models lead to intractable likelihoods and are typically non-differentiable,
which poses challenges for traditional approaches to inference. We extend
previous work in &quot;inference compilation&quot;, which combines universal
probabilistic programming and deep learning methods, to large-scale scientific
simulators, and introduce a C++ based probabilistic programming library called
CPProb. We successfully use CPProb to interface with SHERPA, a large code-base
used in particle physics. Here we describe the technical innovations realized
and planned for this library.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07906</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds on the Entropy of a Function of a Random Variable and their
  Applications</dc:title>
 <dc:creator>Cicalese, Ferdinando</dc:creator>
 <dc:creator>Gargano, Luisa</dc:creator>
 <dc:creator>Vaccaro, Ugo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  It is well known that the entropy $H(X)$ of a discrete random variable $X$ is
always greater than or equal to the entropy $H(f(X))$ of a function $f$ of $X$,
with equality if and only if $f$ is one-to-one. In this paper, we give tight
bounds on $H(f(X))$ when the function $f$ is not one-to-one, and we illustrate
a few scenarios where this matters. As an intermediate step towards our main
result, we derive a lower bound on the entropy of a probability distribution,
when only a bound on the ratio between the maximal and minimal probabilities is
known. The lower bound improves on previous results in the literature, and it
could find applications outside the present scenario.
</dc:description>
 <dc:description>Comment: Accepted for publications to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07919</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Flips in Diagonal Rectangulations</dc:title>
 <dc:creator>Cardinal, Jean</dc:creator>
 <dc:creator>Sacrist&#xe1;n, Vera</dc:creator>
 <dc:creator>Silveira, Rodrigo I.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Rectangulations are partitions of a square into axis-aligned rectangles. A
number of results provide bijections between combinatorial equivalence classes
of rectangulations and families of pattern-avoiding permutations. Other results
deal with local changes involving a single edge of a rectangulation, referred
to as flips, edge rotations, or edge pivoting. Such operations induce a graph
on equivalence classes of rectangulations, related to so-called flip graphs on
triangulations and other families of geometric partitions. In this note, we
consider a family of flip operations on the equivalence classes of diagonal
rectangulations, and their interpretation as transpositions in the associated
Baxter permutations, avoiding the vincular patterns { 3{14}2, 2{41}3 }. This
complements results from Law and Reading (JCTA, 2012) and provides a complete
characterization of flip operations on diagonal rectangulations, in both
geometric and combinatorial terms.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07920</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Track, then Decide: Category-Agnostic Vision-based Multi-Object Tracking</dc:title>
 <dc:creator>O&#x161;ep, Aljo&#x161;a</dc:creator>
 <dc:creator>Mehner, Wolfgang</dc:creator>
 <dc:creator>Voigtlaender, Paul</dc:creator>
 <dc:creator>Leibe, Bastian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The most common paradigm for vision-based multi-object tracking is
tracking-by-detection, due to the availability of reliable detectors for
several important object categories such as cars and pedestrians. However,
future mobile systems will need a capability to cope with rich human-made
environments, in which obtaining detectors for every possible object category
would be infeasible. In this paper, we propose a model-free multi-object
tracking approach that uses a category-agnostic image segmentation method to
track objects. We present an efficient segmentation mask-based tracker which
associates pixel-precise masks reported by the segmentation. Our approach can
utilize semantic information whenever it is available for classifying objects
at the track level, while retaining the capability to track generic unknown
objects in the absence of such information. We demonstrate experimentally that
our approach achieves performance comparable to state-of-the-art
tracking-by-detection methods for popular object categories such as cars and
pedestrians. Additionally, we show that the proposed method can discover and
robustly track a large variety of other objects.
</dc:description>
 <dc:description>Comment: ICRA'18 submission</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07923</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding CNN Activations for Writer Recognition</dc:title>
 <dc:creator>Christlein, Vincent</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The encoding of local features is an essential part for writer identification
and writer retrieval. While CNN activations have already been used as local
features in related works, the encoding of these features has attracted little
attention so far. In this work, we compare the established VLAD encoding with
triangulation embedding. We further investigate generalized max pooling as an
alternative to sum pooling and the impact of decorrelation and Exemplar SVMs.
With these techniques, we set new standards on two publicly available datasets
(ICDAR13, KHATT).
</dc:description>
 <dc:description>Comment: (revised) DAS2018 submission</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07924</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A continuous framework for fairness</dc:title>
 <dc:creator>Hacker, Philipp</dc:creator>
 <dc:creator>Wiedemann, Emil</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Increasingly, discrimination by algorithms is perceived as a societal and
legal problem. As a response, a number of criteria for implementing algorithmic
fairness in machine learning have been developed in the literature. This paper
proposes the Continuous Fairness Algorithm (CFA$\theta$) which enables a
continuous interpolation between different fairness definitions. More
specifically, we make three main contributions to the existing literature.
First, our approach allows the decision maker to continuously vary between
concepts of individual and group fairness. As a consequence, the algorithm
enables the decision maker to adopt intermediate &quot;worldviews&quot; on the degree of
discrimination encoded in algorithmic processes, adding nuance to the extreme
cases of &quot;we're all equal&quot; (WAE) and &quot;what you see is what you get&quot; (WYSIWYG)
proposed so far in the literature. Second, we use optimal transport theory, and
specifically the concept of the barycenter, to maximize decision maker utility
under the chosen fairness constraints. Third, the algorithm is able to handle
cases of intersectionality, i.e., of multi-dimensional discrimination of
certain groups on grounds of several criteria. We discuss three main examples
(college admissions; credit application; insurance contracts) and map out the
policy implications of our approach. The explicit formalization of the
trade-off between individual and group fairness allows this post-processing
approach to be tailored to different situational contexts in which one or the
other fairness criterion may take precedence.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07935</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A non-commutative algorithm for multiplying (7 $\times$ 7) matrices
  using 250 multiplications</dc:title>
 <dc:creator>Sedoglavic, Alexandre</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We present a non-commutative algorithm for multiplying (7x7) matrices using
250 multiplications and a non-commutative algorithm for multiplying (9x9)
matrices using 520 multiplications. These algorithms are obtained using the
same divide-and-conquer technique.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07941</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-Distributed Spatial Filtering Based Noise Reduction in Wireless
  Acoustic Sensor Networks</dc:title>
 <dc:creator>Zhang, Jie</dc:creator>
 <dc:creator>Heusdens, Richard</dc:creator>
 <dc:creator>Hendriks, Richard C.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In wireless acoustic sensor networks (WASNs), sensors typically have a
limited energy budget as they are often battery driven. Energy efficiency is
therefore essential to the design of algorithms in WASNs. One way to reduce
energy costs is to only select the sensors which are most informative, a
problem known as {\it sensor selection}. In this way, only sensors that
significantly contribute to the task at hand will be involved. In this work, we
consider a more general approach, which is based on rate-distributed spatial
filtering. Together with the distance over which transmission takes place, bit
rate directly influences the energy consumption. We try to minimize the battery
usage due to transmission, while constraining the noise reduction performance.
This results in an efficient rate allocation strategy, which depends on the
underlying signal statistics, as well as the distance from sensors to a fusion
center (FC). Under the utilization of a linearly constrained minimum variance
(LCMV) beamformer, the problem is derived as a semi-definite program.
Furthermore, we show that rate allocation is more general than sensor
selection, and sensor selection can be seen as a special case of the presented
rate-allocation solution, e.g., the best microphone subset can be determined by
thresholding the rates. Finally, numerical simulations for the application of
estimating several target sources in a WASN demonstrate that the proposed
method outperforms the microphone subset selection based approaches in the
sense of energy usage, and we find that the sensors close to the FC and close
to point sources are allocated with higher rates.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Audio, Speech and Language
  Processing</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07944</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Study of Different Source Code Metrics and Machine
  Learning Algorithms for Predicting Change Proneness of Object Oriented
  Systems</dc:title>
 <dc:creator>Kumar, Lov</dc:creator>
 <dc:creator>Sureka, Ashish</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Change-prone classes or modules are defined as software components in the
source code which are likely to change in the future. Change-proneness
prediction is useful to the maintenance team as they can optimize and focus
their testing resources on the modules which have a higher likelihood of
change. Change-proneness prediction model can be built by using source code
metrics as predictors or features within a machine learning classification
framework. In this paper, twenty one source code metrics are computed to
develop a statistical model for predicting change-proneness modules. Since the
performance of the change-proneness model depends on the source code metrics,
they are used as independent variables or predictors for the change-proneness
model. Eleven different feature selection techniques (including the usage of
all the $21$ proposed source code metrics described in the paper) are used to
remove irrelevant features and select the best set of features. The
effectiveness of the set of source code metrics are evaluated using eighteen
different classiffication techniques and three ensemble techniques.
Experimental results demonstrate that the model based on selected set of source
code metrics after applying feature selection techniques achieves better
results as compared to the model using all source code metrics as predictors.
Our experimental results reveal that the predictive model developed using
LSSVM-RBF yields better result as compared to other classification techniques
</dc:description>
 <dc:description>Comment: Extended version of our previous papers on Predicting Change
  Proneness of Object Oriented Systems</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07945</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wadge Degrees of $\omega$-Languages of Petri Nets</dc:title>
 <dc:creator>Finkel, Olivier</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  We prove that $\omega$-languages of (non-deterministic) Petri nets and
$\omega$-languages of (non-deterministic) Turing machines have the same
topological complexity: the Borel and Wadge hierarchies of the class of
$\omega$-languages of (non-deterministic) Petri nets are equal to the Borel and
Wadge hierarchies of the class of $\omega$-languages of (non-deterministic)
Turing machines which also form the class of effective analytic sets. In
particular, for each non-null recursive ordinal $\alpha &lt; \omega\_1^{{\rm CK}}
$ there exist some ${\bf \Sigma}^0\_\alpha$-complete and some ${\bf
\Pi}^0\_\alpha$-complete $\omega$-languages of Petri nets, and the supremum of
the set of Borel ranks of $\omega$-languages of Petri nets is the ordinal
$\gamma\_2^1$, which is strictly greater than the first non-recursive ordinal
$\omega\_1^{{\rm CK}}$. We also prove that there are some ${\bf
\Sigma}\_1^1$-complete, hence non-Borel, $\omega$-languages of Petri nets, and
that it is consistent with ZFC that there exist some $\omega$-languages of
Petri nets which are neither Borel nor ${\bf \Sigma}\_1^1$-complete. This
answers the question of the topological complexity of $\omega$-languages of
(non-deterministic) Petri nets which was left open in [DFR14,FS14].
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:0712.1359, arXiv:0804.3266</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07947</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Transportation and Charging Scheduling in Public Vehicle Systems -
  A Game Theoretic Approach</dc:title>
 <dc:creator>Zhu, Ming</dc:creator>
 <dc:creator>Liu, Xiao-Yang</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Public vehicle (PV) systems are promising transportation systems for future
smart cities which provide dynamic ride-sharing services according to
passengers' requests. PVs are driverless/self-driving electric vehicles which
require frequent recharging from smart grids. For such systems, the challenge
lies in both the efficient scheduling scheme to satisfy transportation demands
with service guarantee and the cost-effective charging strategy under the
real-time electricity pricing. In this paper, we study the joint transportation
and charging scheduling for PV systems to balance the transportation and
charging demands, ensuring the long-term operation. We adopt a cake cutting
game model to capture the interactions among PV groups, the cloud and smart
grids. The cloud announces strategies to coordinate the allocation of
transportation and energy resources among PV groups. All the PV groups try to
maximize their joint transportation and charging utilities. We propose an
algorithm to obtain the unique normalized Nash equilibrium point for this
problem. Simulations are performed to confirm the effects of our scheme under
the real taxi and power grid data sets of New York City. Our results show that
our scheme achieves almost the same transportation performance compared with a
heuristic scheme, namely, transportation with greedy charging; however, the
average energy price of the proposed scheme is 10.86% lower than the latter
one.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.07947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08002</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Action Recognition: Pose-based Attention draws focus to Hands</dc:title>
 <dc:creator>Baradel, Fabien</dc:creator>
 <dc:creator>Wolf, Christian</dc:creator>
 <dc:creator>Mille, Julien</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new spatio-temporal attention based mechanism for human action
recognition able to automatically attend to the hands most involved into the
studied action and detect the most discriminative moments in an action.
Attention is handled in a recurrent manner employing Recurrent Neural Network
(RNN) and is fully-differentiable. In contrast to standard soft-attention based
mechanisms, our approach does not use the hidden RNN state as input to the
attention model. Instead, attention distributions are extracted using external
information: human articulated pose. We performed an extensive ablation study
to show the strengths of this approach and we particularly studied the
conditioning aspect of the attention mechanism. We evaluate the method on the
largest currently available human action recognition dataset, NTU-RGB+D, and
report state-of-the-art results. Other advantages of our model are certain
aspects of explanability, as the spatial and temporal attention distributions
at test time allow to study and verify on which parts of the input data the
method focuses.
</dc:description>
 <dc:description>Comment: ICCV 2017 Workshop &quot;Hands in action&quot;. arXiv admin note: text overlap
  with arXiv:1703.10106</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08002</dc:identifier>
 <dc:identifier>ICCV 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08032</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SimulaQron - A simulator for developing quantum internet software</dc:title>
 <dc:creator>Dahlberg, Axel</dc:creator>
 <dc:creator>Wehner, Stephanie</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We introduce a simulator for a quantum internet with the specific goal to
support software development. A quantum internet consists of local quantum
processors, which are interconnected by quantum communication channels that
enable the transmission of qubits between the different processors. While many
simulators exist for local quantum processors, there is presently no simulator
for a quantum internet tailored towards software development. Quantum internet
protocols require both classical as well as quantum information to be exchanged
between the network nodes, next to the execution of gates and measurements on a
local quantum processor. This requires quantum internet software to integrate
classical communication programming practises with novel quantum ones.
  SimulaQron is built to enable application development and explore software
engineering practises for a quantum internet. SimulaQron can be run on one or
more classical computers to simulate local quantum processors, which are
transparently connected in the background to enable the transmission of qubits
or the generation of entanglement between remote processors. Application
software can access the simulated local quantum processors to execute local
quantum instructions and measurements, but also to transmit qubits to remote
nodes in the network. SimulaQron features a modular design that performs a
distributed simulation based on any existing simulation of a quantum computer
capable of integrating with Python. Programming libraries for Python and C are
provided to facilitate application development.
</dc:description>
 <dc:description>Comment: 9 pages, For online documentation see http://www.simulaqron.org</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08034</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Use of a Spectral Glottal Model for the Source-filter Separation
  of Speech</dc:title>
 <dc:creator>Perrotin, Olivier</dc:creator>
 <dc:creator>McLoughlin, Ian Vince</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  The estimation of glottal flow from a speech waveform is a key method for
speech analysis and parameterization. Significant research effort has been made
to dissociate the first vocal tract resonance from the glottal formant (the
low-frequency resonance describing the open-phase of the vocal fold vibration).
However few methods cope with estimation of high-frequency spectral tilt to
describe the return-phase of the vocal fold vibration, which is crucial to the
perception of vocal effort. This paper proposes an improved version of the
well-known Iterative Adaptive Inverse Filtering (IAIF) called GFM-IAIF.
GFM-IAIF includes a full spectral model of the glottis that incorporates both
glottal formant and spectral tilt features. Comparisons with the standard IAIF
method show that while GFM-IAIF maintains good performance on vocal tract
removal, it significantly improves the perceptive timbral variations associated
to vocal effort.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08036</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Siamese Neural Networks for One-shot detection of Railway Track Switches</dc:title>
 <dc:creator>Rao, Dattaraj J</dc:creator>
 <dc:creator>Mittal, Shruti</dc:creator>
 <dc:creator>Ritika, S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Learning methods have been extensively used to analyze video data to
extract valuable information by classifying image frames and detecting objects.
We describe a unique approach for using video feed from a moving Locomotive to
continuously monitor the Railway Track and detect significant assets like
Switches on the Track. The technique used here is called Siamese Networks,
which uses 2 identical networks to learn the similarity between of 2 images.
Here we will use a Siamese network to continuously compare Track images and
detect any significant difference in the Track. Switch will be one of those
images that will be different and we will find a mapping that clearly
distinguishes the Switch from other possible Track anomalies. The same method
will then be extended to detect any abnormalities on the Railway Track. Railway
Transportation is unique in the sense that is has wheeled vehicles, Trains
pulled by Locomotives, running on guided Rails at very high speeds nearing 200
mph. Multiple Tracks on the Rail network are connected to each other using an
equipment called Switch or a Turnout. Switch is either operated manually or
automatically through command from a Control center and it governs the movement
of Trains on different Tracks of the network. Accurate location of these
Switches is very important for the railroad and getting a true picture of their
state in field is important. Modern trains use high definition video cameras
facing the Track that continuously record video from track. Using a Siamese
network and comparing to benchmark images, we describe a method to monitor the
Track and highlight anomalies.
</dc:description>
 <dc:description>Comment: 6 pages and 7 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08037</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation of conventional cold-formed steel sections formed from
  Advanced High Strength Steel (AHSS)</dc:title>
 <dc:creator>Foroughi, Hamid</dc:creator>
 <dc:creator>Schafer, Benjamin W.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The objective of this paper is to explore the potential impact of the use of
advanced high strength steel (AHSS) to form traditional cold-formed steel
structural members. In this study, shell finite element models are constructed,
and geometric and material nonlinear collapse analysis performed, on simulated
lipped channel cross-section cold-formed steel members roll-formed from AHSS.
AHSS sheet is currently being used in automotive applications with thickness
ranging from 0.35 to 0.8 mm (0.0138 to 0.0315 in.) and yield strengths from 350
to 1250 MPa (51 to 181 ksi). However, AHSS has not yet been employed in
cold-formed steel construction. To assess the impact of the adoption of AHSS on
cold-formed steel member strength a group of forty standard structural lipped
channel cross-sections are chosen from the Steel Framing Industry Association
product list and simulated with AHSS material properties. The stress-strain
models used in this study are based on AHSS in production, including dual-phase
and martensitic steels. The simulations consider compression with work on
bending about the major axis in progress. Three different bracing conditions
are employed so that the impact of local, distortional, and global buckling,
including interactions can be explored. Due to the higher yield stresses of
AHSS the potential for interaction and mode switching is anticipated to be
greater in these members compared with conventional mild steels. The
simulations provide a direct means to assess the increase in strength created
by the application of AHSS, while also allowing for future exploration of the
increase in buckling mode interaction, imperfection sensitivity, and strain
demands inherent in the larger capacities. The work is intended to be an
initial step in a longer-term effort to foster innovation in the application of
new steels in cold-formed steel construction.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08037</dc:identifier>
 <dc:identifier>Annual Stability Conference Structural Stability Research Council,
  At San Antonio, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08062</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Note on Attacking Object Detectors with Adversarial Stickers</dc:title>
 <dc:creator>Eykholt, Kevin</dc:creator>
 <dc:creator>Evtimov, Ivan</dc:creator>
 <dc:creator>Fernandes, Earlence</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:creator>Kohno, Tadayoshi</dc:creator>
 <dc:creator>Rahmati, Amir</dc:creator>
 <dc:creator>Prakash, Atul</dc:creator>
 <dc:creator>Tramer, Florian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning has proven to be a powerful tool for computer vision and has
seen widespread adoption for numerous tasks. However, deep learning algorithms
are known to be vulnerable to adversarial examples. These adversarial inputs
are created such that, when provided to a deep learning algorithm, they are
very likely to be mislabeled. This can be problematic when deep learning is
used to assist in safety critical decisions. Recent research has shown that
classifiers can be attacked by physical adversarial examples under various
physical conditions. Given the fact that state-of-the-art objection detection
algorithms are harder to be fooled by the same set of adversarial examples,
here we show that these detectors can also be attacked by physical adversarial
examples. In this note, we briefly show both static and dynamic test results.
We design an algorithm that produces physical adversarial inputs, which can
fool the YOLO object detector and can also attack Faster-RCNN with relatively
high success rate based on transferability. Furthermore, our algorithm can
compress the size of the adversarial inputs to stickers that, when attached to
the targeted object, result in the detector either mislabeling or not detecting
the object a high percentage of the time. This note provides a small set of
results. Our upcoming paper will contain a thorough evaluation on other object
detectors, and will present the algorithm.
</dc:description>
 <dc:description>Comment: Short Note</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08066</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A general construction of permutation polynomials of the form $
  (x^{2^m}+x+\delta)^{i(2^m-1)+1}+x$ over $\F_{2^{2m}}$</dc:title>
 <dc:creator>Wang, Libo</dc:creator>
 <dc:creator>Wu, Baofeng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recently, there has been a lot of work on constructions of permutation
polynomials of the form $(x^{2^m}+x+\delta)^{s}+x$ over the finite field
$\F_{2^{2m}}$, especially in the case when $s$ is of the form $s=i(2^m-1)+1$
(Niho exponent). In this paper, we further investigate permutation polynomials
with this form. Instead of seeking for sporadic constructions of the parameter
$i$, we give a general sufficient condition on $i$ such that
$(x^{2^m}+x+\delta)^{i(2^m-1)+1}+x$ permutes $\F_{2^{2m}}$, that is, $(2^k+1)i
\equiv 1 ~\textrm{or}~ 2^k~(\textrm{mod}~ 2^m+1)$, where $1 \leq k \leq m-1$ is
any integer. This generalizes a recent result obtained by Gupta and Sharma who
actually dealt with the case $k=2$. It turns out that most of previous
constructions of the parameter $i$ are covered by our result, and it yields
many new classes of permutation polynomials as well.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08076</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing public health interventions using Web content</dc:title>
 <dc:creator>Lampos, Vasileios</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Public health interventions are a fundamental tool for mitigating the spread
of an infectious disease. However, it is not always possible to obtain a
conclusive estimate for the impact of an intervention, especially in situations
where the effects are fragmented in population parts that are under-represented
within traditional public health surveillance schemes. To this end, online user
activity can be used as a complementary sensor to establish alternative
measures. Here, we provide a summary of our research on formulating statistical
frameworks for assessing public health interventions based on data from social
media and search engines (Lampos et al., 2015 [20]; Wagner et al., 2017 [37]).
Our methodology has been applied in two real-world case studies: the 2013/14
and 2014/15 flu vaccination campaigns in England, where school-age children
were vaccinated in a number of locations aiming to reduce the overall
transmission of the virus. Disease models from online data combined with
historical patterns of disease prevalence across different areas allowed us to
quantify the impact of the intervention. In addition, a qualitative evaluation
of our impact estimates demonstrated that they were in line with independent
assessments from public health authorities.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08081</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overview of the Triple Scoring Task at the WSDM Cup 2017</dc:title>
 <dc:creator>Bast, Hannah</dc:creator>
 <dc:creator>Buchhold, Bj&#xf6;rn</dc:creator>
 <dc:creator>Haussmann, Elmar</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper provides an overview of the triple scoring task at the WSDM Cup
2017, including a description of the task and the dataset, an overview of the
participating teams and their results, and a brief account of the methods
employed. In a nutshell, the task was to compute relevance scores for
knowledge-base triples from relations, where such scores make sense. Due to the
way the ground truth was constructed, scores were required to be integers from
the range 0..7. For example, reasonable scores for the triples &quot;Tim Burton
profession Director&quot; and &quot;Tim Burton profession Actor&quot; would be 7 and 2,
respectively, because Tim Burton is well-known as a director, but he acted only
in a few lesser known movies.
  The triple scoring task attracted considerable interest, with 52 initial
registrations and 21 teams who submitted a valid run before the deadline. The
winning team achieved an accuracy of 87%, that is, for that fraction of the
triples from the test set (which was revealed only after the deadline) the
difference to the score from the ground truth was at most 2. The best result
for the average difference from the test set scores was 1.50.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08083</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long-Term Mobile Traffic Forecasting Using Deep Spatio-Temporal Neural
  Networks</dc:title>
 <dc:creator>Zhang, Chaoyun</dc:creator>
 <dc:creator>Patras, Paul</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Forecasting with high accuracy the volume of data traffic that mobile users
will consume is becoming increasingly important for precision traffic
engineering, demand-aware network resource allocation, as well as public
transportation. Measurements collection in dense urban deployments is however
complex and expensive, and the post-processing required to make predictions is
highly non-trivial, given the intricate spatio-temporal variability of mobile
traffic due to user mobility. To overcome these challenges, in this paper we
harness the exceptional feature extraction abilities of deep learning and
propose a Spatio-Temporal neural Network (STN) architecture purposely designed
for precise network-wide mobile traffic forecasting. We present a mechanism
that fine tunes the STN and enables its operation with only limited ground
truth observations. We then introduce a Double STN technique (D-STN), which
uniquely combines the STN predictions with historical statistics, thereby
making faithful long-term mobile traffic projections. Experiments we conduct
with real-world mobile traffic data sets, collected over 60 days in both urban
and rural areas, demonstrate that the proposed (D-)STN schemes perform up to
10-hour long predictions with remarkable accuracy, irrespective of the time of
day when they are triggered. Specifically, our solutions achieve up to 61%
smaller prediction errors as compared to widely used forecasting approaches,
while operating with up to 600 times shorter measurement intervals.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08084</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AVEID: Automatic Video System for Measuring Engagement In Dementia</dc:title>
 <dc:creator>Parekh, Viral</dc:creator>
 <dc:creator>Foong, Pin Sym</dc:creator>
 <dc:creator>Zhao, Shendong</dc:creator>
 <dc:creator>Subramanian, Ramanathan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Engagement in dementia is typically measured using behavior observational
scales (BOS) that are tedious and involve intensive manual labor to annotate,
and are therefore not easily scalable. We propose AVEID, a low cost and
easy-to-use video-based engagement measurement tool to determine the engagement
level of a person with dementia (PwD) during digital interaction. We show that
the objective behavioral measures computed via AVEID correlate well with
subjective expert impressions for the popular MPES and OME BOS, confirming its
viability and effectiveness. Moreover, AVEID measures can be obtained for a
variety of engagement designs, thereby facilitating large-scale studies with
PwD populations.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08087</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Intelligent Dialogs for Bounding Box Annotation</dc:title>
 <dc:creator>Konyushkova, Ksenia</dc:creator>
 <dc:creator>Uijlings, Jasper</dc:creator>
 <dc:creator>Lampert, Christoph</dc:creator>
 <dc:creator>Ferrari, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce Intelligent Annotation Dialogs for bounding box annotation. We
train an agent to automatically choose a sequence of actions for a human
annotator to produce a bounding box in a minimal amount of time. Specifically,
we consider two actions: box verification [37], where the annotator verifies a
box generated by an object detector, and manual box drawing. We explore two
kinds of agents, one based on predicting the probability that a box will be
positively verified, and the other based on reinforcement learning. We
demonstrate that (1) our agents are able to learn efficient annotation
strategies in several scenarios, automatically adapting to the difficulty of an
input image, the desired quality of the boxes, the strength of the detector,
and other factors; (2) in all scenarios the resulting annotation dialogs speed
up annotation compared to manual box drawing alone and box verification alone,
while also out- performing any fixed combination of verification and draw- ing
in most scenarios; (3) in a realistic scenario where the detector is
iteratively re-trained, our agents evolve a series of strategies that reflect
the shifting trade-off between verification and drawing as the detector grows
stronger.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08091</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiview Deep Learning for Predicting Twitter Users' Location</dc:title>
 <dc:creator>Do, Tien Huu</dc:creator>
 <dc:creator>Nguyen, Duc Minh</dc:creator>
 <dc:creator>Tsiligianni, Evaggelia</dc:creator>
 <dc:creator>Cornelis, Bruno</dc:creator>
 <dc:creator>Deligiannis, Nikos</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The problem of predicting the location of users on large social networks like
Twitter has emerged from real-life applications such as social unrest detection
and online marketing. Twitter user geolocation is a difficult and active
research topic with a vast literature. Most of the proposed methods follow
either a content-based or a network-based approach. The former exploits
user-generated content while the latter utilizes the connection or interaction
between Twitter users. In this paper, we introduce a novel method combining the
strength of both approaches. Concretely, we propose a multi-entry neural
network architecture named MENET leveraging the advances in deep learning and
multiview learning. The generalizability of MENET enables the integration of
multiple data representations. In the context of Twitter user geolocation, we
realize MENET with textual, network, and metadata features. Considering the
natural distribution of Twitter users across the concerned geographical area,
we subdivide the surface of the earth into multi-scale cells and train MENET
with the labels of the cells. We show that our method outperforms the state of
the art by a large margin on three benchmark datasets.
</dc:description>
 <dc:description>Comment: Submitted to the IEEE Transactions on Big Data</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08101</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Profit Driven Decision Trees for Churn Prediction</dc:title>
 <dc:creator>H&#xf6;ppner, Sebastiaan</dc:creator>
 <dc:creator>Stripling, Eugen</dc:creator>
 <dc:creator>Baesens, Bart</dc:creator>
 <dc:creator>Broucke, Seppe vanden</dc:creator>
 <dc:creator>Verdonck, Tim</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Customer retention campaigns increasingly rely on predictive models to detect
potential churners in a vast customer base. From the perspective of machine
learning, the task of predicting customer churn can be presented as a binary
classification problem. Using data on historic behavior, classification
algorithms are built with the purpose of accurately predicting the probability
of a customer defecting. The predictive churn models are then commonly selected
based on accuracy related performance measures such as the area under the ROC
curve (AUC). However, these models are often not well aligned with the core
business requirement of profit maximization, in the sense that, the models fail
to take into account not only misclassification costs, but also the benefits
originating from a correct classification. Therefore, the aim is to construct
churn prediction models that are profitable and preferably interpretable too.
The recently developed expected maximum profit measure for customer churn
(EMPC) has been proposed in order to select the most profitable churn model. We
present a new classifier that integrates the EMPC metric directly into the
model construction. Our technique, called ProfTree, uses an evolutionary
algorithm for learning profit driven decision trees. In a benchmark study with
real-life data sets from various telecommunication service providers, we show
that ProfTree achieves significant profit improvements compared to classic
accuracy driven tree-based methods.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08107</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Learning Interpretable Classifier for Diabetic Retinopathy
  Disease Grading</dc:title>
 <dc:creator>de la Torre, Jordi</dc:creator>
 <dc:creator>Valls, Aida</dc:creator>
 <dc:creator>Puig, Domenec</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  Deep neural network models have been proven to be very successful in image
classification tasks, also for medical diagnosis, but their main concern is its
lack of interpretability. They use to work as intuition machines with high
statistical confidence but unable to give interpretable explanations about the
reported results. The vast amount of parameters of these models make difficult
to infer a rationale interpretation from them. In this paper we present a
diabetic retinopathy interpretable classifier able to classify retine images
into the different levels of disease severity and of explaining its results by
assigning a score for every point in the hidden and input space, evaluating its
contribution to the final classification in a linear way. The generated visual
maps can be interpreted by an expert in order to compare its own knowledge with
the interpretation given by the model.
</dc:description>
 <dc:description>Comment: Submitted to Elsevier</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08111</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving science yield for NASA Swift with automated planning
  technologies</dc:title>
 <dc:creator>Tohuvavohu, Aaron</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The Swift Gamma-Ray Burst Explorer is a uniquely capable mission, with three
on-board instruments and rapid slewing capabilities. It serves as a
fast-response satellite observatory for everything from gravitational-wave
counterpart searches to cometary science. Swift averages 125 different
observations per day, and is consistently over-subscribed, responding to about
one-hundred Target of Oportunity (ToO) requests per month from the general
astrophysics community, as well as co-pointing and follow-up agreements with
many other observatories. Since launch in 2004, the demands put on the
spacecraft have grown consistently in terms of number and type of targets as
well as schedule complexity. To facilitate this growth, various scheduling
tools and helper technologies have been built by the Swift team to continue
improving the scientific yield of the Swift mission. However, these tools have
been used only to assist humans in exploring the local pareto surface and for
fixing constraint violations. Because of the computational complexity of the
scheduling task, no automation tool has been able to produce a plan of equal or
higher quality than that produced by a well-trained human, given the necessary
time constraints. In this proceeding we formalize the Swift Scheduling Problem
as a dynamic fuzzy Constraint Satisfaction Problem (DF-CSP) and explore the
global solution space. We detail here several approaches towards achieving the
goal of surpassing human quality schedules using classical optimization and
algorithmic techniques, as well as machine learning and recurrent neural
network (RNN) methods. We then briefly discuss the increased scientific yield
and benefit to the wider astrophysics community that would result from the
further development and adoption of these technologies.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure. Submitted for the proceedings of the 18th
  International Workshop on Advanced Computing and Analysis Techniques in
  Physics Research (ACAT 2017)</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08113</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Error Correcting Delivery Scheme for Coded Caching with
  Symmetric Batch Prefetching</dc:title>
 <dc:creator>Karat, Nujoom Sageer</dc:creator>
 <dc:creator>Thomas, Anoop</dc:creator>
 <dc:creator>Rajan, B. Sundar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Coded caching is used to reduce network congestion during peak hours. A
single server is connected to a set of users through a bottleneck link, which
generally is assumed to be error-free. During non-peak hours, all the users
have full access to the files and they fill their local cache with portions of
the files available. During delivery phase, each user requests a file and the
server delivers coded transmissions to meet the demands taking into
consideration their cache contents. In this paper we assume that the shared
link is error prone. A new delivery scheme is required to meet the demands of
each user even after receiving finite number of transmissions in error. We
characterize the minimum average rate and minimum peak rate for this problem.
We find closed form expressions of these rates for a particular caching scheme
namely \textit{symmetric batch prefetching}. We also propose an optimal error
correcting delivery scheme for coded caching problem with symmetric batch
prefetching.
</dc:description>
 <dc:description>Comment: 9 pages and 4 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08125</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying Map and Landmark Based Representations for Visual Navigation</dc:title>
 <dc:creator>Gupta, Saurabh</dc:creator>
 <dc:creator>Fouhey, David</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This works presents a formulation for visual navigation that unifies map
based spatial reasoning and path planning, with landmark based robust plan
execution in noisy environments. Our proposed formulation is learned from data
and is thus able to leverage statistical regularities of the world. This allows
it to efficiently navigate in novel environments given only a sparse set of
registered images as input for building representations for space. Our
formulation is based on three key ideas: a learned path planner that outputs
path plans to reach the goal, a feature synthesis engine that predicts features
for locations along the planned path, and a learned goal-driven closed loop
controller that can follow plans given these synthesized features. We test our
approach for goal-driven navigation in simulated real world environments and
report performance gains over competitive baseline approaches.
</dc:description>
 <dc:description>Comment: Project page with videos: https://s-gupta.github.io/cmpl/</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08129</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fault Localization in Large-Scale Network Policy Deployment</dc:title>
 <dc:creator>Tammana, Praveen</dc:creator>
 <dc:creator>Nagarajan, Chandra</dc:creator>
 <dc:creator>Mamillapalli, Pavan</dc:creator>
 <dc:creator>Kompella, Ramana Rao</dc:creator>
 <dc:creator>Lee, Myungjin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The recent advances in network management automation and Software-Defined
Networking (SDN) are easing network policy management tasks. At the same time,
these new technologies create a new mode of failure in the management cycle
itself. Network policies are presented in an abstract model at a centralized
controller and deployed as low-level rules across network devices. Thus, any
software and hardware element in that cycle can be a potential cause of
underlying network problems. In this paper, we present and solve a network
policy fault localization problem that arises in operating policy management
frameworks for a production network. We formulate our problem via risk modeling
and propose a greedy algorithm that quickly localizes faulty policy objects in
the network policy. We then design and develop SCOUT---a fully-automated system
that produces faulty policy objects and further pinpoints physical-level
failures which made the objects faulty. Evaluation results using a real testbed
and extensive simulations demonstrate that SCOUT detects faulty objects with
small false positives and false negatives.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures, IEEE format, Conference, SDN, Network Policy</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08130</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast Algorithm for Separated Sparsity via Perturbed Lagrangians</dc:title>
 <dc:creator>M&#x105;dry, Aleksander</dc:creator>
 <dc:creator>Mitrovi&#x107;, Slobodan</dc:creator>
 <dc:creator>Schmidt, Ludwig</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Sparsity-based methods are widely used in machine learning, statistics, and
signal processing. There is now a rich class of structured sparsity approaches
that expand the modeling power of the sparsity paradigm and incorporate
constraints such as group sparsity, graph sparsity, or hierarchical sparsity.
While these sparsity models offer improved sample complexity and better
interpretability, the improvements come at a computational cost: it is often
challenging to optimize over the (non-convex) constraint sets that capture
various sparsity structures. In this paper, we make progress in this direction
in the context of separated sparsity -- a fundamental sparsity notion that
captures exclusion constraints in linearly ordered data such as time series.
While prior algorithms for computing a projection onto this constraint set
required quadratic time, we provide a perturbed Lagrangian relaxation approach
that computes provably exact projection in only nearly-linear time. Although
the sparsity constraint is non-convex, our perturbed Lagrangian approach is
still guaranteed to find a globally optimal solution. In experiments, our new
algorithms offer a 10$\times$ speed-up already on moderately-size inputs.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08132</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Reinforcement Learning-Based Framework for Content Caching</dc:title>
 <dc:creator>Zhong, Chen</dc:creator>
 <dc:creator>Gursoy, M. Cenk</dc:creator>
 <dc:creator>Velipasalar, Senem</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Content caching at the edge nodes is a promising technique to reduce the data
traffic in next-generation wireless networks. Inspired by the success of Deep
Reinforcement Learning (DRL) in solving complicated control problems, this work
presents a DRL-based framework with Wolpertinger architecture for content
caching at the base station. The proposed framework is aimed at maximizing the
long-term cache hit rate, and it requires no knowledge of the content
popularity distribution. To evaluate the proposed framework, we compare the
performance with other caching algorithms, including Least Recently Used (LRU),
Least Frequently Used (LFU), and First-In First-Out (FIFO) caching strategies.
Meanwhile, since the Wolpertinger architecture can effectively limit the action
space size, we also compare the performance with Deep Q-Network to identify the
impact of dropping a portion of the actions. Our results show that the proposed
framework can achieve improved short-term cache hit rate and improved and
stable long-term cache hit rate in comparison with LRU, LFU, and FIFO schemes.
Additionally, the performance is shown to be competitive in comparison to Deep
Q-learning, while the proposed framework can provide significant savings in
runtime.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08136</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete Gradient Line Fields on Surfaces</dc:title>
 <dc:creator>Lewiner, Thomas</dc:creator>
 <dc:creator>Novello, Tiago</dc:creator>
 <dc:creator>Paixao, Joao</dc:creator>
 <dc:creator>Tomei, Carlos</dc:creator>
 <dc:subject>Mathematics - Geometric Topology</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A line field on a manifold is a smooth map which assigns a tangent line to
all but a finite number of points of the manifold. As such, it can be seen as a
generalization of vector fields. They model a number of geometric and physical
properties, e.g. the principal curvature directions dynamics on surfaces or the
stress flux in elasticity.
  We propose a discretization of a Morse-Smale line field on surfaces,
extending Forman's construction for discrete vector fields. More general
critical elements and their indices are defined from local matchings, for which
Euler theorem and the characterization of homotopy type in terms of critical
cells still hold.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08146</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multisensor Poisson Multi-Bernoulli Filtering with Uncertain Sensor
  States</dc:title>
 <dc:creator>Fr&#xf6;hle, Markus</dc:creator>
 <dc:creator>Lindberg, Christopher</dc:creator>
 <dc:creator>Granst&#xf6;m, Karl</dc:creator>
 <dc:creator>Wymeersch, Henk</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  In a typical multitarget tracking (MTT) scenario, the sensor state is either
assumed known, or tracking is performed based on the sensor's (relative)
coordinate frame. This assumption becomes violated when the MTT sensor, such as
a vehicular radar, is mounted on a vehicle, and the target state should be
represented in a global (absolute) coordinate frame. Then it is important to
consider the uncertain sensor location for MTT. Furthermore, in a multisensor
scenario, where multiple sensors observe a common set of targets, state
information from one sensor can be utilized to improve the state of another
sensor. In this paper, we present a Poisson multi-Bernoulli MTT filter, which
models the uncertain sensor state. The multisensor case is addressed in an
asynchronous way, where measurements are incorporated sequentially based on the
arrival of new sensor measurements. In doing so, targets observed from a well
localized sensor reduce the state uncertainty at another poorly localized
sensor, provided that a common non-empty subset of features is observed. The
proposed MTT filter has low computational demands due to its parametric
implementation. Numerical results demonstrate the performance benefits of
modeling the uncertain sensor state in feature tracking as well as the
reduction of sensor state uncertainty in a multisensor scenario compared to a
per sensor Kalman filter. Scalability results display the linear increase of
computation time with number of sensors or features present.
</dc:description>
 <dc:description>Comment: 13 pages, 12 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08147</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Hardness for Shortest Cycles and Paths in Sparse Graphs</dc:title>
 <dc:creator>Lincoln, Andrea</dc:creator>
 <dc:creator>Williams, Virginia Vassilevska</dc:creator>
 <dc:creator>Williams, Ryan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Fine-grained reductions have established equivalences between many core
problems with $\tilde{O}(n^3)$-time algorithms on $n$-node weighted graphs,
such as Shortest Cycle, All-Pairs Shortest Paths (APSP), Radius, Replacement
Paths, Second Shortest Paths, and so on. These problems also have
$\tilde{O}(mn)$-time algorithms on $m$-edge $n$-node weighted graphs, and such
algorithms have wider applicability. Are these $mn$ bounds optimal when $m \ll
n^2$?
  Starting from the hypothesis that the minimum weight $(2\ell+1)$-Clique
problem in edge weighted graphs requires $n^{2\ell+1-o(1)}$ time, we prove that
for all sparsities of the form $m = \Theta(n^{1+1/\ell})$, there is no $O(n^2 +
mn^{1-\epsilon})$ time algorithm for $\epsilon&gt;0$ for \emph{any} of the below
problems:
  Minimum Weight $(2\ell+1)$-Cycle in a directed weighted graph,
  Shortest Cycle in a directed weighted graph,
  APSP in a directed or undirected weighted graph,
  Radius (or Eccentricities) in a directed or undirected weighted graph,
  Wiener index of a directed or undirected weighted graph,
  Replacement Paths in a directed weighted graph,
  Second Shortest Path in a directed weighted graph,
  Betweenness Centrality of a given node in a directed weighted graph.
  That is, we prove hardness for a variety of sparse graph problems from the
hardness of a dense graph problem. Our results also lead to new conditional
lower bounds from several related hypothesis for unweighted sparse graph
problems including $k$-cycle, shortest cycle, Radius, Wiener index and APSP.
</dc:description>
 <dc:description>Comment: Changed citation of Thm 1.1 on page 2</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08160</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Static and Dynamic Features for Multivariate Sequence
  Classification</dc:title>
 <dc:creator>Leontjeva, Anna</dc:creator>
 <dc:creator>Kuzovkin, Ilya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Model precision in a classification task is highly dependent on the feature
space that is used to train the model. Moreover, whether the features are
sequential or static will dictate which classification method can be applied as
most of the machine learning algorithms are designed to deal with either one or
another type of data. In real-life scenarios, however, it is often the case
that both static and dynamic features are present, or can be extracted from the
data. In this work, we demonstrate how generative models such as Hidden Markov
Models (HMM) and Long Short-Term Memory (LSTM) artificial neural networks can
be used to extract temporal information from the dynamic data. We explore how
the extracted information can be combined with the static features in order to
improve the classification performance. We evaluate the existing techniques and
suggest a hybrid approach, which outperforms other methods on several public
datasets.
</dc:description>
 <dc:description>Comment: Presented at IEEE DSAA 2016</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08160</dc:identifier>
 <dc:identifier>doi:10.1109/DSAA.2016.10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08162</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A C++ interface to QCDNUM</dc:title>
 <dc:creator>Bertone, Valerio</dc:creator>
 <dc:creator>Botje, Michiel</dc:creator>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  In this document we report on the recent development of a C++ interface to
the FORTRAN-based evolution program QCDNUM. A short description of the
interface is given with a few basic examples of its usage.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08163</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reachable Set Computation and Safety Verification for Neural Networks
  with ReLU Activations</dc:title>
 <dc:creator>Xiang, Weiming</dc:creator>
 <dc:creator>Tran, Hoang-Dung</dc:creator>
 <dc:creator>Johnson, Taylor T.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Neural networks have been widely used to solve complex real-world problems.
Due to the complicate, nonlinear, non-convex nature of neural networks, formal
safety guarantees for the output behaviors of neural networks will be crucial
for their applications in safety-critical systems.In this paper, the output
reachable set computation and safety verification problems for a class of
neural networks consisting of Rectified Linear Unit (ReLU) activation functions
are addressed. A layer-by-layer approach is developed to compute output
reachable set. The computation is formulated in the form of a set of
manipulations for a union of polyhedra, which can be efficiently applied with
the aid of polyhedron computation tools. Based on the output reachable set
computation results, the safety verification for a ReLU neural network can be
performed by checking the intersections of unsafe regions and output reachable
set described by a union of polyhedra. A numerical example of a randomly
generated ReLU neural network is provided to show the effectiveness of the
approach developed in this paper.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08164</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-task learning of time series and its application to the travel
  demand</dc:title>
 <dc:creator>Chidlovskii, Boris</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We address the problem of modeling and prediction of a set of temporal events
in the context of intelligent transportation systems. To leverage the
information shared by different events, we propose a multi-task learning
framework. We develop a support vector regression model for joint learning of
mutually dependent time series. It is the regularization-based multi-task
learning previously developed for the classification case and extended to time
series. We discuss the relatedness of observed time series and first deploy the
dynamic time warping distance measure to identify groups of similar series.
Then we take into account both time and scale warping and propose to align
multiple time series by inferring their common latent representation. We test
the proposed models on the problem of travel demand prediction in Nancy
(France) public transport system and analyze the benefits of multi-task
learning.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08189</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adjacency Matrix and Co-occurrence Tensor of General Hypergraphs: Two
  Well Separated Notions</dc:title>
 <dc:creator>Ouvrard, Xavier</dc:creator>
 <dc:creator>Marchand-Maillet, St&#xe9;phane</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Adjacency and co-occurrence are two well separated notions: even if they are
the same for graphs, they start to be two different notions for uniform
hypergraphs. After having done the difference between the two notions, this
paper contributes in the definition of a co-occurrence tensor reflecting the
general hypergraph structure. It is a challenging issue that can have many
applications if properly achieved, as it will allow the study of the spectra of
such general hypergraph. In most of the applications only an hypermatrix
associated to the tensor is needed. In this article, a novel way of building a
symmetric co-occurrence hypermatrix is proposed that captures also the
cardinality of the hyperedges and allows full separation of the different
layers of the hypergraph.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08195</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Choreographic and Somatic Approaches for the Development of Expressive
  Robotic Systems</dc:title>
 <dc:creator>LaViers, Amy</dc:creator>
 <dc:creator>Cuan, Catie</dc:creator>
 <dc:creator>Heimerdinger, Madison</dc:creator>
 <dc:creator>Huzaifa, Umer</dc:creator>
 <dc:creator>Maguire, Catherine</dc:creator>
 <dc:creator>McNish, Reika</dc:creator>
 <dc:creator>Nilles, Alexandra</dc:creator>
 <dc:creator>Pakrasi, Ishaan</dc:creator>
 <dc:creator>Bradley, Karen</dc:creator>
 <dc:creator>Mata, Kim Brooks</dc:creator>
 <dc:creator>Chakraborty, Novoneel</dc:creator>
 <dc:creator>Vidrin, Ilya</dc:creator>
 <dc:creator>Zurawski, Alexander</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  As robotic systems are moved out of factory work cells into human-facing
environments questions of choreography become central to their design,
placement, and application. With a human viewer or counterpart present, a
system will automatically be interpreted within context, style of movement, and
form factor by human beings as animate elements of their environment. The
interpretation by this human counterpart is critical to the success of the
system's integration: knobs on the system need to make sense to a human
counterpart; an artificial agent should have a way of notifying a human
counterpart of a change in system state, possibly through motion profiles; and
the motion of a human counterpart may have important contextual clues for task
completion. Thus, professional choreographers, dance practitioners, and
movement analysts are critical to research in robotics. They have design
methods for movement that align with human audience perception, can identify
simplified features of movement for human-robot interaction goals, and have
detailed knowledge of the capacity of human movement. This article provides
approaches employed by one research lab, specific impacts on technical and
artistic projects within, and principles that may guide future such work. The
background section reports on choreography, somatic perspectives,
improvisation, the Laban/Bartenieff Movement System, and robotics. From this
context methods including embodied exercises, writing prompts, and community
building activities have been developed to facilitate interdisciplinary
research. The results of this work is presented as an overview of a smattering
of projects in areas like high-level motion planning, software development for
rapid prototyping of movement, artistic output, and user studies that help
understand how people interpret movement. Finally, guiding principles for other
groups to adopt are posited.
</dc:description>
 <dc:description>Comment: Under review at MDPI Arts Special Issue &quot;The Machine as Artist (for
  the 21st Century)&quot;
  http://www.mdpi.com/journal/arts/special_issues/Machine_Artist</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08197</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fair Forests: Regularized Tree Induction to Minimize Model Bias</dc:title>
 <dc:creator>Raff, Edward</dc:creator>
 <dc:creator>Sylvester, Jared</dc:creator>
 <dc:creator>Mills, Steven</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The potential lack of fairness in the outputs of machine learning algorithms
has recently gained attention both within the research community as well as in
society more broadly. Surprisingly, there is no prior work developing
tree-induction algorithms for building fair decision trees or fair random
forests. These methods have widespread popularity as they are one of the few to
be simultaneously interpretable, non-linear, and easy-to-use. In this paper we
develop, to our knowledge, the first technique for the induction of fair
decision trees. We show that our &quot;Fair Forest&quot; retains the benefits of the
tree-based approach, while providing both greater accuracy and fairness than
other alternatives, for both &quot;group fairness&quot; and &quot;individual fairness.'&quot; We
also introduce new measures for fairness which are able to handle multinomial
and continues attributes as well as regression problems, as opposed to binary
attributes and labels only. Finally, we demonstrate a new, more robust
evaluation procedure for algorithms that considers the dataset in its entirety
rather than only a specific protected attribute.
</dc:description>
 <dc:description>Comment: To appear in the first AAAI / ACM conference on Artificial
  Intelligence, Ethics, and Society (AIES) 2018</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08198</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursive Programs for Document Spanners</dc:title>
 <dc:creator>Peterfreund, Liat</dc:creator>
 <dc:creator>Cate, Balder ten</dc:creator>
 <dc:creator>Fagin, Ronald</dc:creator>
 <dc:creator>Kimelfeld, Benny</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  A document spanner models a program for Information Extraction (IE) as a
function that takes as input a text document (string over a finite alphabet)
and produces a relation of spans (intervals in the document) over a predefined
schema. A well studied language for expressing spanners is that of the regular
spanners: relational algebra over regex formulas, which are obtained by adding
capture variables to regular expressions. Equivalently, the regular spanners
are the ones expressible in non-recursive Datalog over regex formulas
(extracting relations that play the role of EDBs from the input document). In
this paper, we investigate the expressive power of recursive Datalog over regex
formulas. Our main result is that such programs capture precisely the document
spanners computable in polynomial time. Additional results compare recursive
programs to known formalisms such as the language of core spanners (that
extends regular spanners by allowing to test for string equality) and its
closure under difference. Finally, we extend our main result to a recently
proposed framework that generalizes both the relational model and document
spanners.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08201</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilevel LDPC Lattices with Efficient Encoding and Decoding and a
  Generalization of Construction D'</dc:title>
 <dc:creator>da Silva, Paulo Ricardo Branco</dc:creator>
 <dc:creator>Silva, Danilo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Lattice codes are elegant and powerful structures that not only can achieve
the capacity of the AWGN channel but also are a key ingredient to many
multiterminal schemes that exploit linearity properties. However, constructing
lattice codes that can realize these benefits with low complexity is still a
challenging problem. In this paper, efficient encoding and decoding algorithms
are proposed for multilevel binary LDPC lattices constructed via Construction
D' whose complexity is linear in the total number of coded bits. Moreover, a
generalization of Construction D' is proposed that relaxes some of the nesting
constraints on the component codes, leading to a simpler and improved design.
Based on this construction, low-complexity multilevel LDPC lattices are
designed whose performance under multistage lattice decoding is comparable to
that of polar lattices on the power-unconstrained AWGN channel and close to
that of conventional (non-lattice) coded modulation schemes on the
power-constrained AWGN channel.
</dc:description>
 <dc:description>Comment: 27 pages, 3 figures. Submitted to the IEEE Transactions on
  Information Theory</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08205</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practically-Self-Stabilizing Vector Clocks in the Absence of Execution
  Fairness</dc:title>
 <dc:creator>Salem, Iosif</dc:creator>
 <dc:creator>Schiller, Elad Michael</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Vector clock algorithms are basic wait-free building blocks that facilitate
causal ordering of events. As wait-free algorithms, they are guaranteed to
complete their operations within a finite number of steps. Stabilizing
algorithms allow the system to recover after the occurrence of transient
faults, such as soft errors and arbitrary violations of the assumptions
according to which the system was designed to behave. We present the first, to
the best of our knowledge, stabilizing vector clock algorithm for asynchronous
crash-prone message-passing systems that can recover in a wait-free manner
after the occurrence of transient faults. In these settings, it is challenging
to demonstrate a finite and wait-free recovery from (communication and crash
failures as well as) transient faults, bound the message and storage sizes,
deal with the removal of all stale information without blocking, and deal with
counter overflow events (which occur at different network nodes concurrently).
  We present an algorithm that never violates safety in the absence of
transient faults and provides bounded time recovery during fair executions that
follow the last transient fault. The novelty is that in the absence of
execution fairness, the algorithm guarantees a bound on the number of times in
which the system might violate safety (while existing algorithms might block
forever due to the presence of both transient faults and crash failures).
  Since vector clocks facilitate a number of elementary synchronization
building blocks (without requiring remote replica synchronization) in
asynchronous systems, we believe that our analytical insights are useful for
the design of other systems that cannot guarantee execution fairness.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08207</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Attention for Sequence-to-Sequence Models</dc:title>
 <dc:creator>Bahuleyan, Hareesh</dc:creator>
 <dc:creator>Mou, Lili</dc:creator>
 <dc:creator>Vechtomova, Olga</dc:creator>
 <dc:creator>Poupart, Pascal</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The variational encoder-decoder (VED) encodes source information as a set of
random variables using a neural network, which in turn is decoded into target
data using another neural network. In natural language processing,
sequence-to-sequence (Seq2Seq) models typically serve as encoder-decoder
networks. When combined with a traditional (deterministic) attention mechanism,
the variational latent space may be bypassed by the attention model, making the
generated sentences less diversified. In our paper, we propose a variational
attention mechanism for VED, where the attention vector is modeled as normally
distributed random variables. Experiments show that variational attention
increases diversity while retaining high quality. We also show that the model
is not sensitive to hyperparameters.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08209</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On State Observers for Nonlinear Systems: A New Design and a Unifying
  Framework</dc:title>
 <dc:creator>Yi, Bowen</dc:creator>
 <dc:creator>Ortega, Romeo</dc:creator>
 <dc:creator>Zhang, Weidong</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we propose a new observer design technique for nonlinear
systems. It combines the well-known Kazantzis-Kravaris-Luenberger observer and
the recently introduced parameter estimation-based observer, which become
special cases of it---extending the realm of applicability of both methods. A
second contribution of the paper is the proof that these designs can be recast
as particular cases of immersion and invariance observers---providing in this
way a unified framework for their analysis and design. Simulation results of a
physical system that illustrates the superior performance of the proposed
observer compared to other existing observers are presented.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08212</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Submodular Optimization for Consensus Networks with Noise-Corrupted
  Leaders</dc:title>
 <dc:creator>Mackin, Erika</dc:creator>
 <dc:creator>Patterson, Stacy</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider the leader selection problem in a network with consensus dynamics
where both leader and follower agents are subject to stochastic external
disturbances. The performance of the system is quantified by the total
steady-state variance of the node states, and the goal is to identify the set
of leaders that minimizes this variance. We first show that this performance
measure can be expressed as a submodular set function over the nodes in the
network. We then use this result to analyze the performance of two greedy,
polynomial-time algorithms for leader selection, showing that the leader sets
produced by the greedy algorithms are within provable bounds of optimal.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08221</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FLIP: Federation support for Long range low power Internet of things
  Protocols</dc:title>
 <dc:creator>Delbruel, St&#xe9;phane</dc:creator>
 <dc:creator>Small, Nicolas</dc:creator>
 <dc:creator>Hughes, Danny</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  There is growing interest in the Internet of Things (IoT) and especially
Low-Power Wide Area Networks (LPWAN), which are rapidly being rolled-out
globally. Within the LPWAN market, LoRaWAN is considered a leading solution
which has achieved significant success. Despite the rapid uptake of LoRaWAN,
scalability concerns arising from interference and contention are also growing.
While the current LoRaWAN protocol includes basic techniques to deal with these
problems, recent research has shown that these mechanisms are ineffective at
large scale. This paper addresses this problem by proposing FLIP, a novel,
fully distributed and open architecture for LoRaWAN, that transforms standard
LoRa gateways into a federated network, while preserving the privacy and
security properties of the original LoRaWAN architecture. FLIP tackles the
scalability limitations of LoRaWAN using consensus-driven and localised
resource sharing between gateways, while also providing inherent support for
the roaming of LoRa devices across the federation. Critically, the FLIP
architecture is fully backwards compatible with all existing LoRa gateways and
requires no modifications to the firmware of LoRa end-devices, facilitating its
rapid adoption.
</dc:description>
 <dc:description>Comment: tech_report</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08222</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Economic Study of the Effect of Android Platform Fragmentation on
  Security Updates</dc:title>
 <dc:creator>Farhang, Sadegh</dc:creator>
 <dc:creator>Laszka, Aron</dc:creator>
 <dc:creator>Grossklags, Jens</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Vendors in the Android ecosystem typically customize their devices by
modifying Android Open Source Project (AOSP) code, adding in-house developed
proprietary software, and pre-installing third-party applications. However,
research has documented how various security problems are associated with this
customization process.
  We develop a model of the Android ecosystem utilizing the concepts of game
theory and product differentiation to capture the competition involving two
vendors customizing the AOSP platform. We show how the vendors are incentivized
to differentiate their products from AOSP and from each other, and how prices
are shaped through this differentiation process. We also consider two types of
consumers: security-conscious consumers who understand and care about security,
and na\&quot;ive consumers who lack the ability to correctly evaluate security
properties of vendor-supplied Android products or simply ignore security. It is
evident that vendors shirk on security investments in the latter case.
  Regulators such as the U.S. Federal Trade Commission have sanctioned Android
vendors for underinvestment in security, but the exact effects of these
sanctions are difficult to disentangle with empirical data. Here, we model the
impact of a regulator-imposed fine that incentivizes vendors to match a minimum
security standard. Interestingly, we show how product prices will decrease for
the same cost of customization in the presence of a fine, or a higher level of
regulator-imposed minimum security.
</dc:description>
 <dc:description>Comment: 22nd International Conference on Financial Cryptography and Data
  Security (FC 2018)</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08226</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Primal-Dual Method for Optimal Control and Trajectory Generation in
  High-Dimensional Systems</dc:title>
 <dc:creator>Kirchner, Matthew R.</dc:creator>
 <dc:creator>Hewer, Gary</dc:creator>
 <dc:creator>Darbon, Jerome</dc:creator>
 <dc:creator>Osher, Stanley</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Presented is a method for efficient computation of the Hamilton-Jacobi (HJ)
equation for time-optimal control problems using the generalized Hopf formula.
Typically, numerical methods to solve the HJ equation rely on a discrete grid
of the solution space and exhibit exponential scaling with dimension. The
generalized Hopf formula avoids the use of grids and numerical gradients by
formulating an unconstrained convex optimization problem. The solution at each
point is completely independent, and allows a massively parallel implementation
if solutions at multiple points are desired. This work presents a primal-dual
method for efficient numeric solution and presents how the resulting optimal
trajectory can be generated directly from the solution of the Hopf formula,
without further optimization. Examples presented have execution times on the
order of milliseconds and experiments show computation scales approximately
polynomial in dimension with very small high-order coefficients.
</dc:description>
 <dc:description>Comment: Updated figures, corrected some minor typos, and updated the
  formatting to comply with conference template</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08228</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Generation of Bounds for Polynomial Systems with Application
  to the Lorenz System</dc:title>
 <dc:creator>R&#xf6;benack, Klaus</dc:creator>
 <dc:creator>Vo&#xdf;winkel, Rick</dc:creator>
 <dc:creator>Richter, Hendrik</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>34D45, 37C70, 37C75</dc:subject>
 <dc:description>  This study covers an analytical approach to calculate positively invariant
sets of dynamical systems. Using Lyapunov techniques and quantifier elimination
methods, an automatic procedure for determining bounds in the state space as an
enclosure of attractors is proposed. The available software tools permit an
algorithmizable process, which normally requires a good insight into the
systems dynamics and experience. As a result we get an estimation of the
attractor, whose conservatism only results from the initial choice of the
Lyapunov candidate function. The proposed approach is illustrated on the
well-known Lorenz system.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08230</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Block-Diagonal and LT Codes for Distributed Computing With Straggling
  Servers</dc:title>
 <dc:creator>Severinson, Albin</dc:creator>
 <dc:creator>Amat, Alexandre Graell i</dc:creator>
 <dc:creator>Rosnes, Eirik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose two coded schemes for the distributed computing problem of
multiplying a matrix by a set of vectors. The first scheme is based on
partitioning the matrix into submatrices and applying maximum distance
separable (MDS) codes to each submatrix. For this scheme, we prove that up to a
given number of partitions the communication load and the computational delay
(not including the encoding and decoding delay) are identical to those of the
scheme recently proposed by Li et al., based on a single, long MDS code.
However, due to the use of shorter MDS codes, our scheme yields a significantly
lower overall computational delay when the delay incurred by encoding and
decoding is also considered. We further propose a second coded scheme based on
Luby Transform (LT) codes under inactivation decoding. Interestingly, LT codes
may reduce the delay over the partitioned scheme at the expense of an increased
communication load. We also consider distributed computing under a deadline and
show numerically that the proposed schemes outperform other schemes in the
literature, with the LT code-based scheme yielding the best performance.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Communications</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08232</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smart, Sparse Contours to Represent and Edit Images</dc:title>
 <dc:creator>Dekel, Tali</dc:creator>
 <dc:creator>Gan, Chuang</dc:creator>
 <dc:creator>Krishnan, Dilip</dc:creator>
 <dc:creator>Liu, Ce</dc:creator>
 <dc:creator>Freeman, William T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of reconstructing an image from information stored at
sparse contour locations. Existing contour-based image reconstruction methods
struggle to balance contour sparsity and reconstruction fidelity. Therefore,
denser contours are needed to capture subtle texture information even though
contours were not meant for textures. We propose a novel image representation
where image content is characterized by contours with gradient information via
an encoder-decoder network, while image details are modeled by a conditional
generative adversarial network. We show that high-quality reconstructions with
high fidelity to the source image can be obtained from extremely sparse input,
e.g., comprising less than 6% of image pixels. Our model synthesizes texture,
details and fine structures in regions where no input information is provided.
The semantic knowledge encoded into our model and the sparsity of the input
allows using contours as an intuitive interface for semantically-aware image
manipulation: local edits in contour domain such as scaling, translation and
erasing, translate to long-range and coherent changes in the pixel space.
Experiments on a variety of datasets verify the versatility and convenience
afforded by our models.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08238</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interventions over Predictions: Reframing the Ethical Debate for
  Actuarial Risk Assessment</dc:title>
 <dc:creator>Barabas, Chelsea</dc:creator>
 <dc:creator>Dinakar, Karthik</dc:creator>
 <dc:creator>Virza, Joichi Ito. Madars</dc:creator>
 <dc:creator>Zittrain, Jonathan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Actuarial risk assessments might be unduly perceived as a neutral way to
counteract implicit bias and increase the fairness of decisions made at almost
every juncture of the criminal justice system, from pretrial release to
sentencing, parole and probation. In recent times these assessments have come
under increased scrutiny, as critics claim that the statistical techniques
underlying them might reproduce existing patterns of discrimination and
historical biases that are reflected in the data. Much of this debate is
centered around competing notions of fairness and predictive accuracy, resting
on the contested use of variables that act as &quot;proxies&quot; for characteristics
legally protected against discrimination, such as race and gender. We argue
that a core ethical debate surrounding the use of regression in risk
assessments is not simply one of bias or accuracy. Rather, it's one of purpose.
If machine learning is operationalized merely in the service of predicting
individual future crime, then it becomes difficult to break cycles of
criminalization that are driven by the iatrogenic effects of the criminal
justice system itself. We posit that machine learning should not be used for
prediction, but rather to surface covariates that are fed into a causal model
for understanding the social, structural and psychological drivers of crime. We
propose an alternative application of machine learning and causal inference
away from predicting risk scores to risk mitigation.
</dc:description>
 <dc:description>Comment: Accepted paper (not camera-ready version) of FATML 2018 conference</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08238</dc:identifier>
 <dc:identifier>Fairness, Accountability and Transparency in Machine Learning,
  2018, Proceedings of Machine Learning Research</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08244</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Well Can Generative Adversarial Networks (GAN) Learn Densities: A
  Nonparametric View</dc:title>
 <dc:creator>Liang, Tengyuan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We study in this paper the rate of convergence for learning densities under
the Generative Adversarial Networks (GANs) framework, borrowing insights from
nonparametric statistics. We introduce an improved GAN estimator that achieves
a faster rate, through leveraging the level of smoothness in the target density
and the evaluation metric, which in theory remedies the mode collapse problem
reported in the literature. A minimax lower bound is constructed to show that
when the dimension is large, the exponent in the rate for the new GAN estimator
is near optimal. One can view our results as answering in a quantitative way
how well GAN learns a wide range of densities with different smoothness
properties, under a hierarchy of evaluation metrics. As a byproduct, we also
obtain improved bounds for GAN with deeper ReLU discriminator network.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08248</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explicit Reference Governor for the Constrained Control of Time-Delayed
  Linear Systems</dc:title>
 <dc:creator>Nicotra, Marco M.</dc:creator>
 <dc:creator>Nguyen, Tam</dc:creator>
 <dc:creator>Garone, Emanuele</dc:creator>
 <dc:creator>Kolmanovsky, Ilya V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper introduces an explicit reference governor approach for controlling
time delay linear systems subject to state and input constraints. The proposed
framework relies on suitable invariant sets that can be built using both
Lyapunov-Razumikhin and Lyapunov-Krasovskii arguments. The proposed method is
validated both numerically and experimentally using several alternative
formulations.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08249</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Clustering with Dynamic Embedding</dc:title>
 <dc:creator>Yang, Carl</dc:creator>
 <dc:creator>Liu, Mengxiong</dc:creator>
 <dc:creator>Wang, Zongyi</dc:creator>
 <dc:creator>Liu, Liyuan</dc:creator>
 <dc:creator>Han, Jiawei</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Graph clustering (or community detection) has long drawn enormous attention
from the research on web mining and information networks. Recent literature on
this topic has reached a consensus that node contents and link structures
should be integrated for reliable graph clustering, especially in an
unsupervised setting. However, existing methods based on shallow models often
suffer from content noise and sparsity. In this work, we propose to utilize
deep embedding for graph clustering, motivated by the well-recognized power of
neural networks in learning intrinsic content representations. Upon that, we
capture the dynamic nature of networks through the principle of influence
propagation and calculate the dynamic network embedding. Network clusters are
then detected based on the stable state of such an embedding. Unlike most
existing embedding methods that are task-agnostic, we simultaneously solve for
the underlying node representations and the optimal clustering assignments in
an end-to-end manner. To provide more insight, we theoretically analyze our
interpretation of network clusters and find its underlying connections with two
widely applied approaches for network modeling. Extensive experimental results
on six real-world datasets including both social networks and citation networks
demonstrate the superiority of our proposed model over the state-of-the-art.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08250</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ReabsNet: Detecting and Revising Adversarial Examples</dc:title>
 <dc:creator>Chen, Jiefeng</dc:creator>
 <dc:creator>Meng, Zihang</dc:creator>
 <dc:creator>Sun, Changtian</dc:creator>
 <dc:creator>Tang, Wei</dc:creator>
 <dc:creator>Zhu, Yinglun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Though deep neural network has hit a huge success in recent studies and
applica- tions, it still remains vulnerable to adversarial perturbations which
are imperceptible to humans. To address this problem, we propose a novel
network called ReabsNet to achieve high classification accuracy in the face of
various attacks. The approach is to augment an existing classification network
with a guardian network to detect if a sample is natural or has been
adversarially perturbed. Critically, instead of simply rejecting adversarial
examples, we revise them to get their true labels. We exploit the observation
that a sample containing adversarial perturbations has a possibility of
returning to its true class after revision. We demonstrate that our ReabsNet
outperforms the state-of-the-art defense method under various adversarial
attacks.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08254</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>T-count and Qubit Optimized Quantum Circuit Design of the Non-Restoring
  Square Root Algorithm</dc:title>
 <dc:creator>Mu&#xf1;oz-Coreas, Edgard</dc:creator>
 <dc:creator>Thapliyal, Himanshu</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Quantum circuits for basic mathematical functions such as the square root are
required to implement scientific computing algorithms on quantum computers.
Quantum circuits that are based on Clifford+T gates can be made fault tolerant
in nature but the T gate is very costly to implement. As a result. reducing
T-count has become an important optimization goal. Further, quantum circuits
with many qubits are difficult to realize making designs that save qubits and
produce no garbage outputs desirable. In this work, we present a T-count
optimized quantum square root circuit with only $2 \cdot n +1$ qubits and no
garbage output. To have fair comparison against existing work, the Bennett's
garbage removal scheme is used to remove garbage output from existing works. We
determined that the proposed design achieves an average T-count savings of
$40.91 \%$, $98.88 \%$, $39.25 \%$ and $26.11 \%$ as well as qubit savings of
$85.46 \%$, $95.16 \%$, $90.59 \%$ and $86.77 \%$ compared to existing work.
</dc:description>
 <dc:description>Comment: 19 pages, 11 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08259</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear centralization classifier</dc:title>
 <dc:creator>Bonyadi, Mohammad Reza</dc:creator>
 <dc:creator>Vegh, Viktor</dc:creator>
 <dc:creator>Reutens, David C.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A classification algorithm, called the Linear Centralization Classifier
(LCC), is introduced. The algorithm seeks to find a transformation that best
maps instances from the feature space to a space where they concentrate towards
the center of their own classes, while maximimizing the distance between class
centers. We formulate the classifier as a quadratic program with quadratic
constraints. We then simplify this formulation to a linear program that can be
solved effectively using a linear programming solver (e.g., simplex-dual). We
extend the formulation for LCC to enable the use of kernel functions for
non-linear classification applications. We compare our method with two standard
classification methods (support vector machine and linear discriminant
analysis) and four state-of-the-art classification methods when they are
applied to eight standard classification datasets. Our experimental results
show that LCC is able to classify instances more accurately (based on the area
under the receiver operating characteristic) in comparison to other tested
methods on the chosen datasets. We also report the results for LCC with a
particular kernel to solve for synthetic non-linear classification problems.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08263</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using LIP to Gloss Over Faces in Single-Stage Face Detection Networks</dc:title>
 <dc:creator>Yang, Siqi</dc:creator>
 <dc:creator>Wiliem, Arnold</dc:creator>
 <dc:creator>Chen, Shaokang</dc:creator>
 <dc:creator>Lovell, Brian C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work shows that it is possible to fool/attack recent state-of-the-art
face detectors which are based on the single-stage networks. Successfully
attacking face detectors could be a serious malware vulnerability when
deploying a smart surveillance system utilizing face detectors. We show that
existing adversarial perturbation methods are not effective to perform such an
attack, especially when there are multiple faces in the input image. This is
because the adversarial perturbation specifically generated for one face may
disrupt the adversarial perturbation for another face. In this paper, we call
this problem the Instance Perturbation Interference (IPI) problem. This IPI
problem is addressed by studying the relationship between the deep neural
network receptive field and the adversarial perturbation. As such, we propose
the Localized Instance Perturbation (LIP) that uses adversarial perturbation
constrained to the Effective Receptive Field (ERF) of a target to perform the
attack. Experiment results show the LIP method massively outperforms existing
adversarial perturbation generation methods -- often by a factor of 2 to 10.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08266</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Federated Control with Hierarchical Multi-Agent Deep Reinforcement
  Learning</dc:title>
 <dc:creator>Kumar, Saurabh</dc:creator>
 <dc:creator>Shah, Pararth</dc:creator>
 <dc:creator>Hakkani-Tur, Dilek</dc:creator>
 <dc:creator>Heck, Larry</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present a framework combining hierarchical and multi-agent deep
reinforcement learning approaches to solve coordination problems among a
multitude of agents using a semi-decentralized model. The framework extends the
multi-agent learning setup by introducing a meta-controller that guides the
communication between agent pairs, enabling agents to focus on communicating
with only one other agent at any step. This hierarchical decomposition of the
task allows for efficient exploration to learn policies that identify globally
optimal solutions even as the number of collaborating agents increases. We show
promising initial experimental results on a simulated distributed scheduling
problem.
</dc:description>
 <dc:description>Comment: Hierarchical Reinforcement Learning Workshop at the 31st Conference
  on Neural Information Processing Systems</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08268</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond saliency: understanding convolutional neural networks from
  saliency prediction on layer-wise relevance propagation</dc:title>
 <dc:creator>Li, Heyi</dc:creator>
 <dc:creator>Mueller, Klaus</dc:creator>
 <dc:creator>Chen, Xin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite the tremendous achievements of deep convolutional neural
networks~(CNNs) in most of computer vision tasks, understanding how they
actually work remains a significant challenge. In this paper, we propose a
novel two-step visualization method that aims to shed light on how deep CNNs
recognize images and the objects therein. We start out with a layer-wise
relevance propagation (LRP) step which estimates a pixel-wise relevance map
over the input image. Following, we construct a context-aware saliency map from
the LRP-generated map which predicts regions close to the foci of attention. We
show that our algorithm clearly and concisely identifies the key pixels that
contribute to the underlying neural network's comprehension of images.
Experimental results using the ILSVRC2012 validation dataset in conjunction
with two well-established deep CNNs demonstrate that combining the LRP with the
visual salience estimation can give great insight into how a CNNs model
perceives and understands a presented scene, in relation to what it has learned
in the prior training phase.
</dc:description>
 <dc:description>Comment: 28 pages, 13 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08273</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Pixel Embedding for Instance Grouping</dc:title>
 <dc:creator>Kong, Shu</dc:creator>
 <dc:creator>Fowlkes, Charless</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  We introduce a differentiable, end-to-end trainable framework for solving
pixel-level grouping problems such as instance segmentation consisting of two
novel components. First, we regress pixels into a hyper-spherical embedding
space so that pixels from the same group have high cosine similarity while
those from different groups have similarity below a specified margin. We
analyze the choice of embedding dimension and margin, relating them to
theoretical results on the problem of distributing points uniformly on the
sphere. Second, to group instances, we utilize a variant of mean-shift
clustering, implemented as a recurrent neural network parameterized by kernel
bandwidth. This recurrent grouping module is differentiable, enjoys convergent
dynamics and probabilistic interpretability. Backpropagating the group-weighted
loss through this module allows learning to focus on only correcting embedding
errors that won't be resolved during subsequent clustering. Our framework,
while conceptually simple and theoretically abundant, is also practically
effective and computationally efficient. We demonstrate substantial
improvements over state-of-the-art instance segmentation for object proposal
generation, as well as demonstrating the benefits of grouping loss for
classification tasks such as boundary detection and semantic segmentation.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08277</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A variational inequality framework for network games: Existence,
  uniqueness, convergence and sensitivity analysis</dc:title>
 <dc:creator>Parise, Francesca</dc:creator>
 <dc:creator>Ozdaglar, Asuman</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We provide a unified variational inequality framework for the study of
fundamental properties of the Nash equilibrium in network games. We identify
several conditions on the underlying network (in terms of spectral norm,
infinity norm and minimum eigenvalue of its adjacency matrix) that guarantee
existence, uniqueness, convergence and continuity of equilibrium in general
network games with multidimensional and possibly constrained strategy sets. We
delineate the relations between these conditions and characterize classes of
networks that satisfy each of these conditions.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08282</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Response-Function-Based Coordination Method for
  Transmission-Distribution-Coupled AC OPF</dc:title>
 <dc:creator>Li, Zhengshuo</dc:creator>
 <dc:creator>Guo, Qinglai</dc:creator>
 <dc:creator>Sun, Hongbin</dc:creator>
 <dc:creator>Wang, Jianhui</dc:creator>
 <dc:creator>Xu, Tong</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  With distributed generation highly integrated into the grid, the
transmission-distribution-coupled AC OPF (TDOPF) becomes increasingly
important. This paper proposes a response-function-based coordination method to
solve the TDOPF. Different from typical decomposition methods, this method
employs approximate response functions of the power injections with respect to
the bus voltage magnitude in the transmission-distribution (T-D) interface to
reflect the &quot;reaction&quot; of the distribution to the transmission system control.
By using the response functions, only one or two iterations between the
transmission system operator (TSO) and the distribution system operator(s)
(DSO(s)) are required to attain a nearly optimal TDOPF solution. Numerical
tests confirm that, relative to a typical decomposition method, the proposed
method does not only enjoy a cheaper computational cost but is workable even
when the objectives of the TSO and the DSO(s) are in distinct scales.
</dc:description>
 <dc:description>Comment: This paper will appear at 2018 IEEE PES Transmission and Distribution
  Conference and Exposition</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08283</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bidirectional Adaptive Bandwidth Mean Shift Strategy for Clustering</dc:title>
 <dc:creator>Meng, Fanyang</dc:creator>
 <dc:creator>Liu, Hong</dc:creator>
 <dc:creator>Liang, Yongsheng</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:creator>Pei, Jihong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The bandwidth of a kernel function is a crucial parameter in the mean shift
algorithm. This paper proposes a novel adaptive bandwidth strategy which
contains three main contributions. (1) The differences among different adaptive
bandwidth are analyzed. (2) A new mean shift vector based on bidirectional
adaptive bandwidth is defined, which combines the advantages of different
adaptive bandwidth strategies. (3) A bidirectional adaptive bandwidth mean
shift (BAMS) strategy is proposed to improve the ability to escape from the
local maximum density. Compared with contemporary adaptive bandwidth mean shift
strategies, experiments demonstrate the effectiveness of the proposed strategy.
</dc:description>
 <dc:description>Comment: Accepted by ICIP 2017</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08285</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grand Challenge: Optimized Stage Processing for Anomaly Detection on
  Numerical Data Streams</dc:title>
 <dc:creator>Amariei, Ciprian</dc:creator>
 <dc:creator>Diac, Paul</dc:creator>
 <dc:creator>Onica, Emanuel</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The 2017 Grand Challenge focused on the problem of automatic detection of
anomalies for manufacturing equipment. This paper reports the technical details
of a solution focused on particular optimizations of the processing stages.
These included customized input parsing, fine tuning of a k-means clustering
algorithm and probability analysis using a lazy flavor of a Markov chain. We
have observed in our custom implementation that carefully tweaking these
processing stages at single node level by leveraging various data stream
characteristics can yield good performance results. We start the paper with
several observations concerning the input data stream, following with our
solution description with details on particular optimizations, and we conclude
with evaluation and a discussion of obtained results.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08285</dc:identifier>
 <dc:identifier>DEBS 2017, Proceedings of the 11th ACM International Conference on
  Distributed and Event-based Systems, Pages 286-291</dc:identifier>
 <dc:identifier>doi:10.1145/3093742.3095101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08286</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Algorithm for Computing Lipschitz Inner Functions in Kolmogorov's
  Superposition Theorem</dc:title>
 <dc:creator>Actor, Jonas</dc:creator>
 <dc:creator>Knepley, Matthew G.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Kolmogorov famously proved that multivariate continuous functions can be
represented as a superposition of a small number of univariate continuous
functions, $$ f(x_1,\dots,x_n) = \sum_{q=0}^{2n+1} \chi^q \left( \sum_{p=1}^n
\psi^{pq}(x_p) \right).$$ Fridman \cite{fridman} posed the best smoothness
bound for the functions $\psi^{pq}$, that such functions can be constructed to
be Lipschitz continuous with constant 1. Previous algorithms to describe these
inner functions have only been H\&quot;older continuous, such as those proposed by
K\&quot;oppen and Braun and Griebel. This is problematic, as pointed out by Griebel,
in that non-smooth functions have very high storage/evaluation complexity, and
this makes Kolmogorov's representation (KR) impractical using the standard
definition of the inner functions.
  To date, no one has presented a method to compute a Lipschitz continuous
inner function. In this paper, we revisit Kolmogorov's theorem along with
Fridman's result. We examine a simple Lipschitz function which appear to
satisfy the necessary criteria for Kolmogorov's representation, but fails in
the limit. We then present a full solution to the problem, including an
algorithm that computes such a Lipschitz function.
</dc:description>
 <dc:description>Comment: 18 pages, 5 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08289</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint IDs Embedding and its Applications in E-commerce</dc:title>
 <dc:creator>Zhao, Kui</dc:creator>
 <dc:creator>Li, Yuechuan</dc:creator>
 <dc:creator>Shuai, Zhaoqian</dc:creator>
 <dc:creator>Yang, Cheng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  E-commerce has become an important part of our daily lives and there are
great challenges due to its dynamic and complex business environment. Many
machine intelligence techniques are developed to overcome these challenges. One
of the essential elements in those techniques is the representation of data,
especially for ID-type data, e.g. item ID, product ID, store ID, brand ID,
category ID etc. The classical one-hot encoding suffers sparsity problems due
to its high dimension. Moreover, it cannot reflect the relationships among IDs,
either homogeneous or heterogeneous ones. In this paper, we propose a novel
hierarchical embedding model to jointly learn low-dimensional representations
for different types of IDs from the implicit feedback of users. Our approach
incorporates the structural information among IDs and embeds all types of IDs
into a semantic space. The low-dimensional representations can be effectively
extended to many applications including recommendation and forecast etc. We
evaluate our approach in several scenarios of &quot;Hema App&quot; and the experimental
results validate the effectiveness of our approach.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08290</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CSGNet: Neural Shape Parser for Constructive Solid Geometry</dc:title>
 <dc:creator>Sharma, Gopal</dc:creator>
 <dc:creator>Goyal, Rishabh</dc:creator>
 <dc:creator>Liu, Difan</dc:creator>
 <dc:creator>Kalogerakis, Evangelos</dc:creator>
 <dc:creator>Maji, Subhransu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present a neural architecture that takes as input a 2D or 3D shape and
induces a program to generate it. The in- structions in our program are based
on constructive solid geometry principles, i.e., a set of boolean operations on
shape primitives defined recursively. Bottom-up techniques for this task that
rely on primitive detection are inherently slow since the search space over
possible primitive combi- nations is large. In contrast, our model uses a
recurrent neural network conditioned on the input shape to produce a sequence
of instructions in a top-down manner and is sig- nificantly faster. It is also
more effective as a shape detec- tor than existing state-of-the-art detection
techniques. We also demonstrate that our network can be trained on novel
datasets without ground-truth program annotations through policy gradient
techniques.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08291</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TFW, DamnGina, Juvie, and Hotsie-Totsie: On the Linguistic and Social
  Aspects of Internet Slang</dc:title>
 <dc:creator>Kulkarni, Vivek</dc:creator>
 <dc:creator>Wang, William Yang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Slang is ubiquitous on the Internet. The emergence of new social contexts
like micro-blogs, question-answering forums, and social networks has enabled
slang and non-standard expressions to abound on the web. Despite this, slang
has been traditionally viewed as a form of non-standard language -- a form of
language that is not the focus of linguistic analysis and has largely been
neglected. In this work, we use UrbanDictionary to conduct the first
large-scale linguistic analysis of slang and its social aspects on the Internet
to yield insights into this variety of language that is increasingly used all
over the world online.
  We begin by computationally analyzing the phonological, morphological and
syntactic properties of slang. We then study linguistic patterns in four
specific categories of slang namely alphabetisms, blends, clippings, and
reduplicatives. Our analysis reveals that slang demonstrates extra-grammatical
rules of phonological and morphological formation that markedly distinguish it
from the standard form shedding insight into its generative patterns. Next, we
analyze the social aspects of slang by studying subject restriction and
stereotyping in slang usage. Analyzing tens of thousands of such slang words
reveals that the majority of slang on the Internet belongs to two major
categories: sex and drugs. We also noted that not only is slang usage not
immune to prevalent social biases and prejudices but also reflects such biases
and stereotypes more intensely than the standard variety.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures,4 tables</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08296</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intelligent Device Discovery in the Internet of Things - Enabling the
  Robot Society</dc:title>
 <dc:creator>Sunthonlap, James</dc:creator>
 <dc:creator>Nguyen, Phuoc</dc:creator>
 <dc:creator>Ye, Zilong</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The Internet of Things (IoT) is continuously growing to connect billions of
smart devices anywhere and anytime in an Internet-like structure, which enables
a variety of applications, services and interactions between human and objects.
In the future, the smart devices are supposed to be able to autonomously
discover a target device with desired features and generate a set of entirely
new services and applications that are not supervised or even imagined by human
beings. The pervasiveness of smart devices, as well as the heterogeneity of
their design and functionalities, raise a major concern: How can a smart device
efficiently discover a desired target device? In this paper, we propose a
Social-Aware and Distributed (SAND) scheme that achieves a fast, scalable and
efficient device discovery in the IoT. The proposed SAND scheme adopts a novel
device ranking criteria that measures the device's degree, social relationship
diversity, clustering coefficient and betweenness. Based on the device ranking
criteria, the discovery request can be guided to travel through critical
devices that stand at the major intersections of the network, and thus quickly
reach the desired target device by contacting only a limited number of
intermediate devices. With the help of such an intelligent device discovery as
SAND, the IoT devices, as well as other computing facilities, software and data
on the Internet, can autonomously establish new social connections with each
other as human being do. They can formulate self-organized computing groups to
perform required computing tasks, facilitate a fusion of a variety of computing
service, network service and data to generate novel applications and services,
evolve from the individual aritificial intelligence to the collaborative
intelligence, and eventually enable the birth of a robot society.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08297</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SFCN-OPI: Detection and Fine-grained Classification of Nuclei Using
  Sibling FCN with Objectness Prior Interaction</dc:title>
 <dc:creator>Zhou, Yanning</dc:creator>
 <dc:creator>Dou, Qi</dc:creator>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Qin, Jing</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cell nuclei detection and fine-grained classification have been fundamental
yet challenging problems in histopathology image analysis. Due to the nuclei
tiny size, significant inter-/intra-class variances, as well as the inferior
image quality, previous automated methods would easily suffer from limited
accuracy and robustness. In the meanwhile, existing approaches usually deal
with these two tasks independently, which would neglect the close relatedness
of them. In this paper, we present a novel method of sibling fully
convolutional network with prior objectness interaction (called SFCN-OPI) to
tackle the two tasks simultaneously and interactively using a unified
end-to-end framework. Specifically, the sibling FCN branches share features in
earlier layers while holding respective higher layers for specific tasks. More
importantly, the detection branch outputs the objectness prior which
dynamically interacts with the fine-grained classification sibling branch
during the training and testing processes. With this mechanism, the
fine-grained classification successfully focuses on regions with high
confidence of nuclei existence and outputs the conditional probability, which
in turn benefits the detection through back propagation. Extensive experiments
on colon cancer histology images have validated the effectiveness of our
proposed SFCN-OPI and our method has outperformed the state-of-the-art methods
by a large margin.
</dc:description>
 <dc:description>Comment: Accepted at AAAI 2018</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08302</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Source-side Prediction for Neural Headline Generation</dc:title>
 <dc:creator>Kiyono, Shun</dc:creator>
 <dc:creator>Takase, Sho</dc:creator>
 <dc:creator>Suzuki, Jun</dc:creator>
 <dc:creator>Okazaki, Naoaki</dc:creator>
 <dc:creator>Inui, Kentaro</dc:creator>
 <dc:creator>Nagata, Masaaki</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The encoder-decoder model is widely used in natural language generation
tasks. However, the model sometimes suffers from repeated redundant generation,
misses important phrases, and includes irrelevant entities. Toward solving
these problems we propose a novel source-side token prediction module. Our
method jointly estimates the probability distributions over source and target
vocabularies to capture a correspondence between source and target tokens. The
experiments show that the proposed model outperforms the current
state-of-the-art method in the headline generation task. Additionally, we show
that our method has an ability to learn a reasonable token-wise correspondence
without knowing any true alignments.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08303</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>COOJA Network Simulator: Exploring the Infinite Possible Ways to Compute
  the Performance Metrics of IOT Based Smart Devices to Understand the Working
  of IOT Based Compression &amp; Routing Protocols</dc:title>
 <dc:creator>Mehmood, Tayyab</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper demonstrates the scheme regarding Internet of Things (IOT) which
is well thought-out the next generation of Internet. IOT explicitly elaborates
the assimilation of human beings and physical systems, as they can cooperate
with each other so leading towards a sort of encroachment in networking by
interconnecting things together while making use of wireless embedded systems,
said to be the building blocks of IOT, that are capable to be given an IP
address and thus making them part of the global internet. Several essential
approaches that entail in IOT and supports this innovation are being argued in
this paper. 6LoWPAN (IPV6 Low Power Personal Area Networks) is a protocol used
to appropriately and efficiently use IPV6 addresses. Control messages of RPL
routing protocol for low power devices are discussed to understand the working
of RPL protocol. In the end Contiki OS based COOJA Network simulator is used to
demonstrate the working of how these routing and compression protocol works in
real time simulation.
</dc:description>
 <dc:description>Comment: 7 Pages, 7 Figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08304</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding and Improving the Latency of DRAM-Based Memory Systems</dc:title>
 <dc:creator>Chang, Kevin K.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Over the past two decades, the storage capacity and access bandwidth of main
memory have improved tremendously, by 128x and 20x, respectively. These
improvements are mainly due to the continuous technology scaling of DRAM
(dynamic random-access memory), which has been used as the physical substrate
for main memory. In stark contrast with capacity and bandwidth, DRAM latency
has remained almost constant, reducing by only 1.3x in the same time frame.
Therefore, long DRAM latency continues to be a critical performance bottleneck
in modern systems. Increasing core counts, and the emergence of increasingly
more data-intensive and latency-critical applications further stress the
importance of providing low-latency memory access.
  In this dissertation, we identify three main problems that contribute
significantly to long latency of DRAM accesses. To address these problems, we
present a series of new techniques. Our new techniques significantly improve
both system performance and energy efficiency. We also examine the critical
relationship between supply voltage and latency in modern DRAM chips and
develop new mechanisms that exploit this voltage-latency trade-off to improve
energy efficiency.
  The key conclusion of this dissertation is that augmenting DRAM architecture
with simple and low-cost features, and developing a better understanding of
manufactured DRAM chips together lead to significant memory latency reduction
as well as energy efficiency improvement. We hope and believe that the proposed
architectural techniques and the detailed experimental data and observations on
real commodity DRAM chips presented in this dissertation will enable
development of other new mechanisms to improve the performance, energy
efficiency, or reliability of future memory systems.
</dc:description>
 <dc:description>Comment: PhD Dissertation</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08305</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An HMM-based Multi-sensor Approach for Continuous Mobile Authentication</dc:title>
 <dc:creator>Roy, Aditi</dc:creator>
 <dc:creator>Halevi, Tzipora</dc:creator>
 <dc:creator>Memon, Nasir</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the increased popularity of smart phones, there is a greater need to
have a robust authentication mechanism that handles various security threats
and privacy leakages effectively. This paper studies continuous authentication
for touch interface based mobile devices. A Hidden Markov Model (HMM) based
behavioral template training approach is presented, which does not require
training data from other subjects other than the owner of the mobile device and
can get updated with new data over time. The gesture patterns of the user are
modeled from multiple sensors - touch, accelerometer and gyroscope data using a
continuous left-right HMM. The approach models the tap and stroke patterns of a
user since these are the basic and most frequently used interactions on a
mobile device. To evaluate the effectiveness of the proposed method a new data
set has been created from 42 users who interacted with off-the-shelf
applications on their smart phones. Results show that the performance of the
proposed approach is promising and potentially better than other
state-of-the-art approaches.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08305</dc:identifier>
 <dc:identifier>doi:10.1109/MILCOM.2015.7357626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08307</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An HMM-based behavior modeling approach for continuous mobile
  authentication</dc:title>
 <dc:creator>Roy, Aditi</dc:creator>
 <dc:creator>Halevi, Tzipora</dc:creator>
 <dc:creator>Memon, Nasir</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper studies continuous authentication for touch interface based mobile
devices. A Hidden Markov Model (HMM) based behavioral template training
approach is presented, which does not require training data from other subjects
other than the owner of the mobile. The stroke patterns of a user are modeled
using a continuous left-right HMM. The approach models the horizontal and
vertical scrolling patterns of a user since these are the basic and mostly used
interactions on a mobile device. The effectiveness of the proposed method is
evaluated through extensive experiments using the Toucha-lytics database which
comprises of touch data over time. The results show that the performance of the
proposed approach is better than the state-of-the-art method.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08307</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2014.6854310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08310</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Work Analysis with Resource-Aware Session Types</dc:title>
 <dc:creator>Das, Ankush</dc:creator>
 <dc:creator>Hoffmann, Jan</dc:creator>
 <dc:creator>Pfenning, Frank</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  While there exist several successful techniques for supporting programmers in
deriving static resource bounds for sequential code, analyzing the resource
usage of message-passing concurrent processes poses additional challenges. To
meet these challenges, this article presents an analysis for statically
deriving worst-case bounds on the total work performed by message-passing
processes. To decompose interacting processes into components that can be
analyzed in isolation, the analysis is based on novel resource-aware session
types, which describe protocols and resource contracts for inter-process
communication. A key innovation is that both messages and processes carry
potential to share and amortize cost while communicating. To symbolically
express resource usage in a setting without static data structures and
intrinsic sizes, resource contracts describe bounds that are functions of
interactions between processes. Resource-aware session types combine standard
binary session types and type-based amortized resource analysis in a linear
type system. This type system is formulated for a core session-type calculus of
the language SILL and proved sound with respect to a multiset-based operational
cost semantics that tracks the total number of messages that are exchanged in a
system. The effectiveness of the analysis is demonstrated by analyzing standard
examples from amortized analysis and the literature on session types and by a
comparative performance analysis of different concurrent programs implementing
the same interface.
</dc:description>
 <dc:description>Comment: 25 pages, 2 pages of references, 11 pages of appendix</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08314</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking Decoupled Neural Interfaces with Synthetic Gradients</dc:title>
 <dc:creator>Bisong, Ekaba</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Artifical Neural Networks are a particular class of learning systems modeled
after biological neural functions with an interesting penchant for Hebbian
learning, that is &quot;neurons that wire together, fire together&quot;. However, unlike
their natural counterparts, artificial neural networks have a close and
stringent coupling between the modules of neurons in the network. This coupling
or locking imposes upon the network a strict and inflexible structure that
prevent layers in the network from updating their weights until a full
feed-forward and backward pass has occurred. Such a constraint though may have
sufficed for a while, is now no longer feasible in the era of very-large-scale
machine learning, coupled with the increased desire for parallelization of the
learning process across multiple computing infrastructures. To solve this
problem, synthetic gradients (SG) with decoupled neural interfaces (DNI) are
introduced as a viable alternative to the backpropagation algorithm. This paper
performs a speed benchmark to compare the speed and accuracy capabilities of
SG-DNI as opposed to a standard neural interface using multilayer perceptron
MLP. SG-DNI shows good promise, in that it not only captures the learning
problem, it is also over 3-fold faster due to it asynchronous learning
capabilities.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:date>2018-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08315</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Hashing with Category Mask for Fast Video Retrieval</dc:title>
 <dc:creator>Liu, Xu</dc:creator>
 <dc:creator>Zhao, Lili</dc:creator>
 <dc:creator>Ding, Dajun</dc:creator>
 <dc:creator>Dong, Yajiao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes an end-to-end deep hashing framework with category mask
for fast video retrieval. We train our network in a supervised way by fully
exploiting inter-class diversity and intra-class identity. Classification loss
is optimized to maximize inter-class diversity, while intra-pair is introduced
to learn representative intra-class identity. We investigate the binary bits
distribution related to categories and find out that the effectiveness of
binary bits is highly related to categories, and certain bits may degrade
classification performance of some categories. We then design hash code
generation scheme with category mask to filter out bits with negative
contribution. Experimental results demonstrate the proposed method outperforms
state-of-the-arts under various evaluation metrics on public datasets. We are
making our code and models public online.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08319</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual Sensor Modelling using Neural Networks with Coefficient-based
  Adaptive Weights and Biases Search Algorithm for Diesel Engines</dc:title>
 <dc:creator>Rastogi, Kushagra</dc:creator>
 <dc:creator>Saini, Navreet</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  With the explosion in the field of Big Data and introduction of more
stringent emission norms every three to five years, automotive companies must
not only continue to enhance the fuel economy ratings of their products, but
also provide valued services to their customers such as delivering engine
performance and health reports at regular intervals. A reasonable solution to
both issues is installing a variety of sensors on the engine. Sensor data can
be used to develop fuel economy features and will directly indicate engine
performance. However, mounting a plethora of sensors is impractical in a very
cost-sensitive industry. Thus, virtual sensors can replace physical sensors by
reducing cost while capturing essential engine data.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08324</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards dense object tracking in a 2D honeybee hive</dc:title>
 <dc:creator>Bozek, Katarzyna</dc:creator>
 <dc:creator>Hebert, Laetitia</dc:creator>
 <dc:creator>Mikheyev, Alexander S</dc:creator>
 <dc:creator>Stephens, Greg J</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  From human crowds to cells in tissue, the detection and efficient tracking of
multiple objects in dense configurations is an important and unsolved problem.
In the past, limitations of image analysis have restricted studies of dense
groups to tracking a single or subset of marked individuals, or to
coarse-grained group-level dynamics, all of which yield incomplete information.
Here, we combine convolutional neural networks (CNNs) with the model
environment of a honeybee hive to automatically recognize all individuals in a
dense group from raw image data. We create new, adapted individual labeling and
use the segmentation architecture U-Net with a loss function dependent on both
object identity and orientation. We additionally exploit temporal regularities
of the video recording in a recurrent manner and achieve near human-level
performance while reducing the network size by 94% compared to the original
U-Net architecture. Given our novel application of CNNs, we generate extensive
problem-specific image data in which labeled examples are produced through a
custom interface with Amazon Mechanical Turk. This dataset contains over
375,000 labeled bee instances across 720 video frames at 2 FPS, representing an
extensive resource for the development and testing of tracking methods. We
correctly detect 96% of individuals with a location error of ~7% of a typical
body dimension, and orientation error of 12 degrees, approximating the
variability of human raters. Our results provide an important step towards
efficient image-based dense object tracking by allowing for the accurate
determination of object location and orientation across time-series image data
efficiently within one network architecture.
</dc:description>
 <dc:description>Comment: 15 pages, including supplementary figures. 1 supplemental movie
  available as an ancillary file</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08328</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A simple introduction to Karmarkar's Algorithm for Linear Programming</dc:title>
 <dc:creator>Saxena, Sanjeev</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  An extremely simple, description of Karmarkar's algorithm with very few
technical terms is given.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08336</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Music of Brain and Music on Brain: A Novel EEG Sonification approach</dc:title>
 <dc:creator>Nag, Sayan</dc:creator>
 <dc:creator>Sanyal, Shankha</dc:creator>
 <dc:creator>Banerjee, Archi</dc:creator>
 <dc:creator>Sengupta, Ranjan</dc:creator>
 <dc:creator>Ghosh, Dipak</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Can we hear the sound of our brain? Is there any technique which can enable
us to hear the neuro-electrical impulses originating from the different lobes
of brain? The answer to all these questions is YES. In this paper we present a
novel method with which we can sonify the Electroencephalogram (EEG) data
recorded in rest state as well as under the influence of a simplest acoustical
stimuli - a tanpura drone. The tanpura drone has a very simple yet very complex
acoustic features, which is generally used for creation of an ambiance during a
musical performance. Hence, for this pilot project we chose to study the
correlation between a simple acoustic stimuli (tanpura drone) and sonified EEG
data. Till date, there have been no study which deals with the direct
correlation between a bio-signal and its acoustic counterpart and how that
correlation varies under the influence of different types of stimuli. This is
the first of its kind study which bridges this gap and looks for a direct
correlation between music signal and EEG data using a robust mathematical
microscope called Multifractal Detrended Cross Correlation Analysis (MFDXA).
For this, we took EEG data of 10 participants in 2 min 'rest state' (i.e. with
white noise) and in 2 min 'tanpura drone' (musical stimulus) listening
condition. Next, the EEG signals from different electrodes were sonified and
MFDXA technique was used to assess the degree of correlation (or the cross
correlation coefficient) between tanpura signal and EEG signals. The variation
of {\gamma}x for different lobes during the course of the experiment also
provides major interesting new information. Only music stimuli has the ability
to engage several areas of the brain significantly unlike other stimuli (which
engages specific domains only).
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures; Presented in the International Symposium on
  Frontiers of Research in speech and Music (FRSM)-2017, held at NIT, Rourkela
  in 15-16 December 2017</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08337</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A proposal for a quantitative indicator of original research output</dc:title>
 <dc:creator>Onofrio, Roberto</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The use of quantitative indicators of scientific productivity seems now quite
widespread for assessing researchers and research institutions. There is a
general perception, however, that these indicators are not necessarily
representative of the originality of the research carried out, being primarily
indicative of a more or less prolific scientific activity and of the size of
the targeted scientific subcommunity. We first discuss some of the drawbacks of
the broadly adopted $h$-index and of the fact that it represents, in an average
sense, an indicator derivable from the total number of citations. Then we
propose an indicator which, although not immune from biases, seems more in line
with the general expectations for quantifying what is typically considered
original work. Qualitative arguments on how different indicators may shape the
future of science are finally discussed.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08341</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Behavioral software engineering - guidelines for qualitative studies</dc:title>
 <dc:creator>Lenberg, Per</dc:creator>
 <dc:creator>Feldt, Robert</dc:creator>
 <dc:creator>Tengberg, Lars G&#xf6;ran Wallgren</dc:creator>
 <dc:creator>Tidefors, Inga</dc:creator>
 <dc:creator>Graziotin, Daniel</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Researchers are increasingly recognizing the importance of human aspects in
software development and since qualitative methods are used to, in-depth,
explore human behavior, we believe that studies using such techniques will
become more common.
  Existing qualitative software engineering guidelines do not cover the full
breadth of qualitative methods and knowledge on using them found in the social
sciences. The aim of this study was thus to extend the software engineering
research community's current body of knowledge regarding available qualitative
methods and provide recommendations and guidelines for their use.
  With the support of a literature review, we suggest that future research
would benefit from (1) utilizing a broader set of research methods, (2) more
strongly emphasizing reflexivity, and (3) employing qualitative guidelines and
quality criteria.
  We present an overview of three qualitative methods commonly used in social
sciences but rarely seen in software engineering research, namely
interpretative phenomenological analysis, narrative analysis, and discourse
analysis. Furthermore, we discuss the meaning of reflexivity in relation to the
software engineering context and suggest means of fostering it.
  Our paper will help software engineering researchers better select and then
guide the application of a broader set of qualitative research methods.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08342</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event-based Failure Prediction in Distributed Business Processes</dc:title>
 <dc:creator>Borkowski, Michael</dc:creator>
 <dc:creator>Fdhila, Walid</dc:creator>
 <dc:creator>Nardelli, Matteo</dc:creator>
 <dc:creator>Rinderle-Ma, Stefanie</dc:creator>
 <dc:creator>Schulte, Stefan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>H.4.3</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:description>  Traditionally, research in Business Process Management has put a strong focus
on centralized and intra-organizational processes. However, today's business
processes are increasingly distributed, deviating from a centralized layout,
and therefore calling for novel methodologies of detecting and responding to
unforeseen events, such as errors occurring during process runtime. In this
article, we demonstrate how to employ event-based failure prediction in
business processes. This approach allows to make use of the best of both
traditional Business Process Management Systems and event-based systems. Our
approach employs machine learning techniques and considers various types of
events. We evaluate our solution using two business process data sets,
including one from a real-world event log, and show that we are able to detect
errors and predict failures with high accuracy.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08342</dc:identifier>
 <dc:identifier>doi:10.1016/j.is.2017.12.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08345</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings Third Workshop on Graphs as Models</dc:title>
 <dc:creator>Kehrer, Timo</dc:creator>
 <dc:creator>Miller, Alice</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Graphs are used as models in many areas of computer science and computer
engineering. For example graphs are used to represent syntax, control and data
flow, dependency, state spaces, models such as UML and other types of
domain-specific models, and social network graphs. In all of these examples,
the graph serves as an intuitive yet mathematically precise foundation for many
purposes, both in theory building as well as in practical applications.
Graph-based models serve as an abstract communication medium and are used to
describe various concepts and phenomena. Moreover, once such graph-based models
are constructed, they can be analyzed and transformed to verify the correctness
of static and dynamic properties, to discover new properties, to deeply study a
particular domain of interest or to produce new equivalent and/or optimized
versions of graph-based models.
  The Graphs as Models (GaM) workshop series combines the strengths of two
pre-existing workshop series: GT-VMT (Graph Transformation and Visual Modelling
Techniques) and GRAPHITE (Graph Inspection and Traversal Engineering), but also
solicits research from other related areas, such as social network analysis.
GaM offers a platform for exchanging new ideas and results for active
researchers in these areas, with a particular aim of boosting inter- and
transdisciplinary research exploiting new applications of graphs as models in
any area of computational science. This year (2017), the third edition of the
GaM workshop was co-located with the European Joint Conferences on Theory and
Practice of Software 2017 (ETAPS'17), held in Uppsala, Sweden.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08345</dc:identifier>
 <dc:identifier>EPTCS 263, 2017</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08348</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Software Development For Social Robotics Systems</dc:title>
 <dc:creator>Sun, Chong</dc:creator>
 <dc:creator>Zhang, Jiongyan</dc:creator>
 <dc:creator>Liu, Cong</dc:creator>
 <dc:creator>King, Barry Chew Bao</dc:creator>
 <dc:creator>Zhang, Yuwei</dc:creator>
 <dc:creator>Galle, Matthew</dc:creator>
 <dc:creator>Spichkova, Maria</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper we introduce the core results of the project on software
development for social robotics systems. The usability of maintenance and
control features is crucial for many kinds of systems, but in the case of
social robotics we also have to take into account that (1) the humanoid robot
physically interacts with humans, (2) the conversation with children might have
different requirements in comparison to the conversation with adults. The
results of our work were implement for the humanoid PAL REEM robot, but their
core ideas can be applied for other types of humanoid robots. We developed a
web-based solution that supports the management of robot-guided tours, provides
recommendations for the users as well as allows for a visual analysis of the
data on previous tours.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08349</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking the Diffusion of Named Entities</dc:title>
 <dc:creator>Derczynski, Leon</dc:creator>
 <dc:creator>Rowe, Matthew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Existing studies of how information diffuses across social networks have thus
far concentrated on analysing and recovering the spread of deterministic
innovations such as URLs, hashtags, and group membership. However investigating
how mentions of real-world entities appear and spread has yet to be explored,
largely due to the computationally intractable nature of performing large-scale
entity extraction. In this paper we present, to the best of our knowledge, one
of the first pieces of work to closely examine the diffusion of named entities
on social media, using Reddit as our case study platform. We first investigate
how named entities can be accurately recognised and extracted from discussion
posts. We then use these extracted entities to study the patterns of entity
cascades and how the probability of a user adopting an entity (i.e. mentioning
it) is associated with exposures to the entity. We put these pieces together by
presenting a parallelised diffusion model that can forecast the probability of
entity adoption, finding that the influence of adoption between users can be
characterised by their prior interactions -- as opposed to whether the users
propagated entity-adoptions beforehand. Our findings have important
implications for researchers studying influence and language, and for community
analysts who wish to understand entity-level influence dynamics.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08350</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding People's Professions and Nationalities Using Distant Supervision
  - The FMI@SU &quot;goosefoot&quot; team at the WSDM Cup 2017 Triple Scoring Task</dc:title>
 <dc:creator>Zmiycharov, Valentin</dc:creator>
 <dc:creator>Alexandrov, Dimitar</dc:creator>
 <dc:creator>Nakov, Preslav</dc:creator>
 <dc:creator>Koychev, Ivan</dc:creator>
 <dc:creator>Kiprov, Yasen</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  We describe the system that our FMI@SU student's team built for participating
in the Triple Scoring task at the WSDM Cup 2017. Given a triple from a
&quot;type-like&quot; relation, profession or nationality, the goal is to produce a
score, on a scale from 0 to 7, that measures the relevance of the statement
expressed by the triple: e.g., how well does the profession of an Actor fit for
Quentin Tarantino? We propose a distant supervision approach using information
crawled from Wikipedia, DeletionPedia, and DBpedia, together with task-specific
word embeddings, TF-IDF weights, and role occurrence order, which we combine in
a linear regression model. The official evaluation ranked our submission 1st on
Kendall's Tau, 7th on Average score difference, and 9th on Accuracy, out of 21
participating teams.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08351</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Triple Scoring with Crowdsourcing-specific Features - The
  fiddlehead Triple Scorer at WSDM Cup 2017</dc:title>
 <dc:creator>Sato, Masahiro</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  The Triple Scoring Task at the WSDM Cup 2017 involves the prediction of the
relevance scores between persons and professions/nationalities. The ground
truth of the relevance scores was obtained by counting the vote of seven
crowdworkers. I confirmed that features related to task difficulty correlate
with the discrepancy among crowdworkers' judgement. This means such features
are useful for predicting whether a score is in the middle or not. Hence, the
features were incorporated into the prediction model of the crowdsourced
relevance scores. The introduced features improve the average score difference
of the prediction. The final ranking of my prediction was 4th for average score
difference and 12th for both accuracy and Kendall's tau.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08352</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Triple Scoring Using a Hybrid Fact Validation Approach - The Catsear
  Triple Scorer at WSDM Cup 2017</dc:title>
 <dc:creator>Marx, Edgard</dc:creator>
 <dc:creator>Soru, Tommaso</dc:creator>
 <dc:creator>Valdestilhas, Andr&#xe9;</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  With the continuous increase of data daily published in knowledge bases
across the Web, one of the main issues is regarding information relevance. In
most knowledge bases, a triple (i.e., a statement composed by subject,
predicate, and object) can be only true or false. However, triples can be
assigned a score to have information sorted by relevance. In this work, we
describe the participation of the Catsear team in the Triple Scoring Challenge
at the WSDM Cup 2017. The Catsear approach scores triples by combining the
answers coming from three different sources using a linear regression
classifier. We show how our approach achieved an Accuracy2 value of 79.58% and
the overall 4th place.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08353</identifier>
 <datestamp>2017-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relevance Score of Triplets Using Knowledge Graph Embedding - The
  Pigweed Triple Scorer at WSDM Cup 2017</dc:title>
 <dc:creator>Kanojia, Vibhor</dc:creator>
 <dc:creator>Togashi, Riku</dc:creator>
 <dc:creator>Maeda, Hideyuki</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  Collaborative Knowledge Bases such as Freebase and Wikidata mention multiple
professions and nationalities for a particular entity. The goal of the WSDM Cup
2017 Triplet Scoring Challenge was to calculate relevance scores between an
entity and its professions/nationalities. Such scores are a fundamental
ingredient when ranking results in entity search. This paper proposes a novel
approach to ensemble an advanced Knowledge Graph Embedding Model with a simple
bag-of-words model. The former deals with hidden pragmatics and deep semantics
whereas the latter handles text-based retrieval and low-level semantics.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08354</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supervised Ranking of Triples for Type-Like Relations - The Cress Triple
  Scorer at the WSDM Cup 2017</dc:title>
 <dc:creator>Hasibi, Faegheh</dc:creator>
 <dc:creator>Garigliotti, Dar&#xed;o</dc:creator>
 <dc:creator>Zhang, Shuo</dc:creator>
 <dc:creator>Balog, Krisztian</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  This paper describes our participation in the Triple Scoring task of WSDM Cup
2017, which aims at ranking triples from a knowledge base for two type-like
relations: profession and nationality. We introduce a supervised ranking method
along with the features we designed for this task. Our system has been top
ranked with respect to average score difference and 2nd best in terms of
Kendall's tau.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08355</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranking Triples using Entity Links in a Large Web Crawl - The Chicory
  Triple Scorer at WSDM Cup 2017</dc:title>
 <dc:creator>Dorssers, Frank</dc:creator>
 <dc:creator>de Vries, Arjen P.</dc:creator>
 <dc:creator>Alink, Wouter</dc:creator>
 <dc:creator>Cornacchia, Roberto</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  This paper describes the participation of team Chicory in the Triple Ranking
Challenge of the WSDM Cup 2017. Our approach deploys a large collection of
entity tagged web data to estimate the correctness of the relevance relation
expressed by the triples, in combination with a baseline approach using
Wikipedia abstracts following [1]. Relevance estimations are drawn from
ClueWeb12 annotated by Google's entity linker, available publicly as the FACC1
dataset. Our implementation is automatically generated from a so-called 'search
strategy' that specifies declaratively how the input data are combined into a
final ranking of triples.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08356</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Text and Knowledge Bases for Triple Scoring: An Ensemble
  Approach - The BOKCHOY Triple Scorer at WSDM Cup 2017</dc:title>
 <dc:creator>Ding, Boyang</dc:creator>
 <dc:creator>Wang, Quan</dc:creator>
 <dc:creator>Wang, Bin</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  We present our winning solution for the WSDM Cup 2017 triple scoring task. We
devise an ensemble of four base scorers, so as to leverage the power of both
text and knowledge bases for that task. Then we further refine the outputs of
the ensemble by trigger word detection, achieving even better predictive
accuracy. The code is available at https://github.com/wsdm-cup-2017/bokchoy.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08357</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Knowledge from Latent and Explicit Features for Triple
  Scoring - Team Radicchio's Triple Scorer at WSDM Cup 2017</dc:title>
 <dc:creator>Chen, Liang-Wei</dc:creator>
 <dc:creator>Mangipudi, Bhargav</dc:creator>
 <dc:creator>Bandlamudi, Jayachandu</dc:creator>
 <dc:creator>Sehgal, Richa</dc:creator>
 <dc:creator>Hao, Yun</dc:creator>
 <dc:creator>Jiang, Meng</dc:creator>
 <dc:creator>Gui, Huan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  The objective of the triple scoring task in WSDM Cup 2017 is to compute
relevance scores for knowledge-base triples of type-like relations. For
example, consider Julius Caesar who has had various professions, including
Politician and Author. For two given triples (Julius Caesar, profession,
Politician) and (Julius Caesar, profession, Author), the former triple is
likely to have a higher relevance score (also called &quot;triple score&quot;) because
Julius Caesar was well-known as a politician and not as an author. Accurate
prediction of such triple scores greatly benefits real-world applications, such
as information retrieval or knowledge base query. In these scenarios, being
able to rank all relations (Profession/Nationality) can help improve the user
experience. We propose a triple scoring model which integrates knowledge from
both latent features and explicit features via an ensemble approach. The latent
features consist of representations for a person learned by using a word2vec
model and representations for profession/nationality values extracted from a
pre-trained GloVe embedding model. In addition, we extract explicit features
for person entities from the Freebase knowledge base. Experimental results show
that the proposed method performs competitively at WSDM Cup 2017, ranking at
the third place with an accuracy of 79.72% for predicting within two places of
the ground truth score.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08359</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Relevance Scores for Triples from Type-Like Relations using
  Neural Embedding - The Cabbage Triple Scorer at WSDM Cup 2017</dc:title>
 <dc:creator>Brumer, Yael</dc:creator>
 <dc:creator>Shapira, Bracha</dc:creator>
 <dc:creator>Rokach, Lior</dc:creator>
 <dc:creator>Barkan, Oren</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  The WSDM Cup 2017 Triple scoring challenge is aimed at calculating and
assigning relevance scores for triples from type-like relations. Such scores
are a fundamental ingredient for ranking results in entity search. In this
paper, we propose a method that uses neural embedding techniques to accurately
calculate an entity score for a triple based on its nearest neighbor. We strive
to develop a new latent semantic model with a deep structure that captures the
semantic and syntactic relations between words. Our method has been ranked
among the top performers with accuracy - 0.74, average score difference - 1.74,
and average Kendall's Tau - 0.35.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08360</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Triple Scoring Using Paragraph Vector - The Gailan Triple Scorer at WSDM
  Cup 2017</dc:title>
 <dc:creator>Ali, Esraa</dc:creator>
 <dc:creator>Caputo, Annalina</dc:creator>
 <dc:creator>Lawless, S&#xe9;amus</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  In this paper we describe our solution to the WSDM Cup 2017 Triple Scoring
task. Our approach generates a relevance score based on the textual description
of the triple's subject and value (Object). It measures how similar (related)
the text description of the subject is to the text description of its values.
The generated similarity score can then be used to rank the multiple values
associated with this subject. We utilize the Paragraph Vector algorithm to
represent the unstructured text into fixed length vectors. The fixed length
representation is then employed to calculate the similarity (relevance) score
between the subject and its multiple values. Our experimental results have
shown that the suggested approach is promising and suitable to solve this
problem.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08362</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connected Vertex Cover for $(sP_1+P_5)$-Free Graphs</dc:title>
 <dc:creator>Johnson, Matthew</dc:creator>
 <dc:creator>Paesani, Giacomo</dc:creator>
 <dc:creator>Paulusma, Daniel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The Connected Vertex Cover problem is to decide if a graph $G$ has a vertex
cover of size at most $k$ that induces a connected subgraph of $G$. A graph is
$H$-free if it does not contain $H$ as an induced subgraph. We prove that
Connected Vertex Cover is polynomial-time solvable for $(sP_1+P_5)$-free graphs
for all $s\geq 0$.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08363</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Using Backpropagation for Speech Texture Generation and Voice
  Conversion</dc:title>
 <dc:creator>Chorowski, Jan</dc:creator>
 <dc:creator>Weiss, Ron J.</dc:creator>
 <dc:creator>Saurous, Rif A.</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Inspired by recent work on neural network image generation which rely on
backpropagation towards the network inputs, we present a proof-of-concept
system for speech texture synthesis and voice conversion based on two
mechanisms: approximate inversion of the representation learned by a speech
recognition neural network, and on matching statistics of neuron activations
between different source and target utterances. Similar to image texture
synthesis and neural style transfer, the system works by optimizing a cost
function with respect to the input waveform samples. To this end we use a
differentiable mel-filterbank feature extraction pipeline and train a
convolutional CTC speech recognition network. Our system is able to extract
speaker characteristics from very limited amounts of target speaker data, as
little as a few seconds, and can be used to generate realistic speech babble or
reconstruct an utterance in a different voice.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08364</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential geometry and stochastic dynamics with deep learning
  numerics</dc:title>
 <dc:creator>K&#xfc;hnel, Line</dc:creator>
 <dc:creator>Arnaudon, Alexis</dc:creator>
 <dc:creator>Sommer, Stefan</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>53A35, 53C17, 53C44, 70H05, 22E30</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>G.1.4</dc:subject>
 <dc:description>  In this paper, we demonstrate how deterministic and stochastic dynamics on
manifolds, as well as differential geometric constructions can be implemented
concisely and efficiently using modern computational frameworks that mix
symbolic expressions with efficient numerical computations. In particular, we
use the symbolic expression and automatic differentiation features of the
python library Theano, originally developed for high-performance computations
in deep learning. We show how various aspects of differential geometry and Lie
group theory, connections, metrics, curvature, left/right invariance, geodesics
and parallel transport can be formulated with Theano using the automatic
computation of derivatives of any order. We will also show how symbolic
stochastic integrators and concepts from non-linear statistics can be
formulated and optimized with only a few lines of code. We will then give
explicit examples on low-dimensional classical manifolds for visualization and
demonstrate how this approach allows both a concise implementation and
efficient scaling to high dimensional problems.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08367</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ADWISE: Adaptive Window-based Streaming Edge Partitioning for High-Speed
  Graph Processing</dc:title>
 <dc:creator>Mayer, Christian</dc:creator>
 <dc:creator>Mayer, Ruben</dc:creator>
 <dc:creator>Tariq, Muhammad Adnan</dc:creator>
 <dc:creator>Geppert, Heiko</dc:creator>
 <dc:creator>Laich, Larissa</dc:creator>
 <dc:creator>Rieger, Lukas</dc:creator>
 <dc:creator>Rothermel, Kurt</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In recent years, the graph partitioning problem gained importance as a
mandatory preprocessing step for distributed graph processing on very large
graphs. Existing graph partitioning algorithms minimize partitioning latency by
assigning individual graph edges to partitions in a streaming manner --- at the
cost of reduced partitioning quality. However, we argue that the mere
minimization of partitioning latency is not the optimal design choice in terms
of minimizing total graph analysis latency, i.e., the sum of partitioning and
processing latency. Instead, for complex and long-running graph processing
algorithms that run on very large graphs, it is beneficial to invest more time
into graph partitioning to reach a higher partitioning quality --- which
drastically reduces graph processing latency. In this paper, we propose ADWISE,
a novel window-based streaming partitioning algorithm that increases the
partitioning quality by always choosing the best edge from a set of edges for
assignment to a partition. In doing so, ADWISE controls the partitioning
latency by adapting the window size dynamically at run-time. Our evaluations
show that ADWISE can reach the sweet spot between graph partitioning latency
and graph processing latency, reducing the total latency of partitioning plus
processing by up to 23-47 percent compared to the state-of-the-art.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08370</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Music Genre Classification with Paralleling Recurrent Convolutional
  Neural Network</dc:title>
 <dc:creator>Feng, Lin</dc:creator>
 <dc:creator>Liu, Shenlan</dc:creator>
 <dc:creator>Yao, Jianing</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Deep learning has been demonstrated its effectiveness and efficiency in music
genre classification. However, the existing achievements still have several
shortcomings which impair the performance of this classification task. In this
paper, we propose a hybrid architecture which consists of the paralleling CNN
and Bi-RNN blocks. They focus on spatial features and temporal frame orders
extraction respectively. Then the two outputs are fused into one powerful
representation of musical signals and fed into softmax function for
classification. The paralleling network guarantees the extracting features
robust enough to represent music. Moreover, the experiments prove our proposed
architecture improve the music genre classification performance and the
additional Bi-RNN block is a supplement for CNNs.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08373</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Notes on complexity of packing coloring</dc:title>
 <dc:creator>Kim, Minki</dc:creator>
 <dc:creator>Lidick&#xfd;, Bernard</dc:creator>
 <dc:creator>Masa&#x159;&#xed;k, Tom&#xe1;&#x161;</dc:creator>
 <dc:creator>Pfender, Florian</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A packing $k$-coloring for some integer $k$ of a graph $G=(V,E)$ is a mapping
  $\varphi:V\to\{1,\ldots,k\}$ such that any two vertices $u, v$ of color
$\varphi(u)=\varphi(v)$ are in distance at least $\varphi(u)+1$. This concept
is motivated by frequency assignment problems. The \emph{packing chromatic
number} of $G$ is the smallest $k$ such that there exists a packing
$k$-coloring of $G$.
  Fiala and Golovach showed that determining the packing chromatic number for
chordal graphs is \NP-complete for diameter exactly 5. While the problem is
easy to solve for diameter 2, we show \NP-completeness for any diameter at
least 3. Our reduction also shows that the packing chromatic number is hard to
approximate within $n^{{1/2}-\varepsilon}$ for any $\varepsilon &gt; 0$.
  In addition, we design an \FPT algorithm for interval graphs of bounded
diameter. This leads us to exploring the problem of finding a partial coloring
that maximizes the number of colored vertices.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08381</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Compositional Coalgebraic Semantics of Strategic Games</dc:title>
 <dc:creator>Blumensath, Achim</dc:creator>
 <dc:creator>Winschel, Viktor</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We provide a compositional coalgebraic semantics for strategic games. In our
framework, like in the semantics of functional programming languages,
coalgebras represent the observable behaviour of systems derived from the
behaviour of the parts over an unobservable state space. We use coalgebras to
describe and program stage games, finitely and potentially infinitely repeated
hierarchical or parallel games with imperfect and incomplete information based
on deterministic, non-deterministic or probabilistic decisions of learning
agents in possibly endogenous networks. Our framework is compositional in that
arbitrarily complex network of games can be composed. The coalgebraic approach
allows to represent self-referential or reflexive structures like institutional
dynamics, strategic network formation from within the network, belief
formation, learning agents or other self-referential phenomena that
characterise complex social systems of cognitive agents. And finally our games
represent directly runnable code in functional programming languages that can
also be analysed by sophisticated verification and logical tools of software
engineering.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08394</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The ParallelEye Dataset: Constructing Large-Scale Artificial Scenes for
  Traffic Vision Research</dc:title>
 <dc:creator>Li, Xuan</dc:creator>
 <dc:creator>Wang, Kunfeng</dc:creator>
 <dc:creator>Tian, Yonglin</dc:creator>
 <dc:creator>Yan, Lan</dc:creator>
 <dc:creator>Wang, Fei-Yue</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video image datasets are playing an essential role in design and evaluation
of traffic vision algorithms. Nevertheless, a longstanding inconvenience
concerning image datasets is that manually collecting and annotating
large-scale diversified datasets from real scenes is time-consuming and prone
to error. For that virtual datasets have begun to function as a proxy of real
datasets. In this paper, we propose to construct large-scale artificial scenes
for traffic vision research and generate a new virtual dataset called
&quot;ParallelEye&quot;. First of all, the street map data is used to build 3D scene
model of Zhongguancun Area, Beijing. Then, the computer graphics, virtual
reality, and rule modeling technologies are utilized to synthesize large-scale,
realistic virtual urban traffic scenes, in which the fidelity and geography
match the real world well. Furthermore, the Unity3D platform is used to render
the artificial scenes and generate accurate ground-truth labels, e.g.,
semantic/instance segmentation, object bounding box, object tracking, optical
flow, and depth. The environmental conditions in artificial scenes can be
controlled completely. As a result, we present a viable implementation pipeline
for constructing large-scale artificial scenes for traffic vision research. The
experimental results demonstrate that this pipeline is able to generate
photorealistic virtual datasets with low modeling time and high accuracy
labeling.
</dc:description>
 <dc:description>Comment: To be published in IEEE ITSC 2017</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08409</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection and Tracking of General Movable Objects in Large 3D Maps</dc:title>
 <dc:creator>Bore, Nils</dc:creator>
 <dc:creator>Ekekrantz, Johan</dc:creator>
 <dc:creator>Jensfelt, Patric</dc:creator>
 <dc:creator>Folkesson, John</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper studies the problem of detection and tracking of general objects
with long-term dynamics, observed by a mobile robot moving in a large
environment. A key problem is that due to the environment scale, it can only
observe a subset of the objects at any given time. Since some time passes
between observations of objects in different places, the objects might be moved
when the robot is not there. We propose a model for this movement in which the
objects typically only move locally, but with some small probability they jump
longer distances, through what we call global motion. For filtering, we
decompose the posterior over local and global movements into two linked
processes. The posterior over the global movements and measurement associations
is sampled, while we track the local movement analytically using Kalman
filters. This novel filter is evaluated on point cloud data gathered
autonomously by a mobile robot over an extended period of time. We show that
tracking jumping objects is feasible, and that the proposed probabilistic
treatment outperforms previous methods when applied to real world data. The key
to efficient probabilistic tracking in this scenario is focused sampling of the
object posteriors.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08416</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Integration of Optical Flow and Action Recognition</dc:title>
 <dc:creator>Sevilla-Lara, Laura</dc:creator>
 <dc:creator>Liao, Yiyi</dc:creator>
 <dc:creator>Guney, Fatma</dc:creator>
 <dc:creator>Jampani, Varun</dc:creator>
 <dc:creator>Geiger, Andreas</dc:creator>
 <dc:creator>Black, Michael J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most of the top performing action recognition methods use optical flow as a
&quot;black box&quot; input. Here we take a deeper look at the combination of flow and
action recognition, and investigate why optical flow is helpful, what makes a
flow method good for action recognition, and how we can make it better. In
particular, we investigate the impact of different flow algorithms and input
transformations to better understand how these affect a state-of-the-art action
recognition method. Furthermore, we fine tune two neural-network flow methods
end-to-end on the most widely used action recognition dataset (UCF101). Based
on these experiments, we make the following five observations: 1) optical flow
is useful for action recognition because it is invariant to appearance, 2)
optical flow methods are optimized to minimize end-point-error (EPE), but the
EPE of current methods is not well correlated with action recognition
performance, 3) for the flow methods tested, accuracy at boundaries and at
small displacements is most correlated with action recognition performance, 4)
training optical flow to minimize classification error instead of minimizing
EPE improves recognition performance, and 5) optical flow learned for the task
of action recognition differs from traditional optical flow especially inside
the human body and at the boundary of the body. These observations may
encourage optical flow researchers to look beyond EPE as a goal and guide
action recognition researchers to seek better motion cues, leading to a tighter
integration of the optical flow and action recognition communities.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08425</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple Methods for Scanner Drift Normalization Validated for Automatic
  Segmentation of Knee Magnetic Resonance Imaging - with data from the
  Osteoarthritis Initiative</dc:title>
 <dc:creator>Dam, Erik B</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scanner drift is a well-known magnetic resonance imaging (MRI) artifact
characterized by gradual signal degradation and scan intensity changes over
time. In addition, hardware and software updates may imply abrupt changes in
signal. The combined effects are particularly challenging for automatic image
analysis methods used in longitudinal studies. The implication is increased
measurement variation and a risk of bias in the estimations (e.g. in the volume
change for a structure). We proposed two quite different approaches for scanner
drift normalization and demonstrated the performance for segmentation of knee
MRI using the fully automatic KneeIQ framework. The validation included a total
of 1975 scans from both high-field and low-field MRI. The results demonstrated
that the pre-processing method denoted Atlas Affine Normalization significantly
removed scanner drift effects and ensured that the cartilage volume change
quantifications became consistent with manual expert scores.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08427</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contour: A Practical System for Binary Transparency</dc:title>
 <dc:creator>Al-Bassam, Mustafa</dc:creator>
 <dc:creator>Meiklejohn, Sarah</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Transparency is crucial in security-critical applications that rely on
authoritative information, as it provides a robust mechanism for holding these
authorities accountable for their actions. A number of solutions have emerged
in recent years that provide transparency in the setting of certificate
issuance, and Bitcoin provides an example of how to enforce transparency in a
financial setting. In this work we shift to a new setting, the distribution of
software package binaries, and present a system for so-called &quot;binary
transparency.&quot; Our solution, Contour, uses proactive methods for providing
transparency, privacy, and availability, even in the face of persistent
man-in-the-middle attacks. We also demonstrate, via benchmarks and a test
deployment for the Debian software repository, that Contour is the only system
for binary transparency that satisfies the efficiency and coordination
requirements that would make it possible to deploy today.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08428</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Relay Selection for Heterogeneous UAV Communication Networks
  Using A Many-to-Many Matching Game Without Substitutability</dc:title>
 <dc:creator>Liu, Dianxiong</dc:creator>
 <dc:creator>Xu, Yuhua</dc:creator>
 <dc:creator>Xu, Yitao</dc:creator>
 <dc:creator>Wu, Qihui</dc:creator>
 <dc:creator>Jing, Jianjun</dc:creator>
 <dc:creator>Zhang, Yuanhui</dc:creator>
 <dc:creator>Anpalagan, Alagan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper proposes a distributed multiple relay selection scheme to maximize
the satisfaction experiences of unmanned aerial vehicles (UAV) communication
networks. The multi-radio and multi-channel (MRMC) UAV communication system is
considered in this paper. One source UAV can select one or more relay radios,
and each relay radio can be shared by multiple source UAVs equally. Without the
center controller, source UAVs with heterogeneous requirements compete for
channels dominated by relay radios. In order to optimize the global
satisfaction performance, we model the UAV communication network as a
many-to-many matching market without substitutability. We design a potential
matching approach to address the optimization problem, in which the optimizing
of local matching process will lead to the improvement of global matching
results. Simulation results show that the proposed distributed matching
approach yields good matching performance of satisfaction, which is close to
the global optimum result. Moreover, the many-to-many potential matching
approach outperforms existing schemes sufficiently in terms of global
satisfaction within a reasonable convergence time.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, conference</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08437</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Model of Optimal Network Structure for Decentralized Nearest Neighbor
  Search</dc:title>
 <dc:creator>Ponomarenko, Alexander</dc:creator>
 <dc:creator>Utkina, Irina</dc:creator>
 <dc:creator>Batsyn, Mikhail</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  One of the approaches for the nearest neighbor search problem is to build a
network which nodes correspond to the given set of indexed objects. In this
case the search of the closest object can be thought as a search of a node in a
network. A procedure in a network is called decentralized if it uses only local
information about visited nodes and its neighbors. Networks, which structure
allows efficient performing the nearest neighbour search by a decentralised
search procedure started from any node, are of particular interest especially
for pure distributed systems. Several algorithms that construct such networks
have been proposed in literature. However, the following questions arise: &quot;Are
there network models in which decentralised search can be performed faster?&quot;;
&quot;What are the optimal networks for the decentralised search?&quot;; &quot;What are their
properties?&quot;. In this paper we partially give answers to these questions. We
propose a mathematical programming model for the problem of determining an
optimal network structure for decentralized nearest neighbor search. We have
found an exact solution for a regular lattice of size 4x4 and heuristic
solutions for sizes from 5x5 to 7x7. As a distance function we use L1 , L2 and
L_inf metrics. We hope that our results and the proposed model will initiate
study of optimal network structures for decentralised nearest neighbour search.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08439</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Novel Ranking-Based Lexical Similarity Measure for Word Embedding</dc:title>
 <dc:creator>Dutkiewicz, Jakub</dc:creator>
 <dc:creator>J&#x119;drzejek, Czes&#x142;aw</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Distributional semantics models derive word space from linguistic items in
context. Meaning is obtained by defining a distance measure between vectors
corresponding to lexical entities. Such vectors present several problems. In
this paper we provide a guideline for post process improvements to the baseline
vectors. We focus on refining the similarity aspect, address imperfections of
the model by applying the hubness reduction method, implementing relational
knowledge into the model, and providing a new ranking similarity definition
that give maximum weight to the top 1 component value. This feature ranking is
similar to the one used in information retrieval. All these enrichments
outperform current literature results for joint ESL and TOEF sets comparison.
Since single word embedding is a basic element of any semantic task one can
expect a significant improvement of results for these tasks. Moreover, our
improved method of text processing can be translated to continuous distributed
representation of biological sequences for deep proteomics and genomics.
</dc:description>
 <dc:description>Comment: 7 pages; 1 page of references</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08443</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverse Classification for Comparison-based Interpretability in Machine
  Learning</dc:title>
 <dc:creator>Laugel, Thibault</dc:creator>
 <dc:creator>Lesot, Marie-Jeanne</dc:creator>
 <dc:creator>Marsala, Christophe</dc:creator>
 <dc:creator>Renard, Xavier</dc:creator>
 <dc:creator>Detyniecki, Marcin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In the context of post-hoc interpretability, this paper addresses the task of
explaining the prediction of a classifier, considering the case where no
information is available, neither on the classifier itself, nor on the
processed data (neither the training nor the test data). It proposes an
instance-based approach whose principle consists in determining the minimal
changes needed to alter a prediction: given a data point whose classification
must be explained, the proposed method consists in identifying a close
neighbour classified differently, where the closeness definition integrates a
sparsity constraint. This principle is implemented using observation generation
in the Growing Spheres algorithm. Experimental results on two datasets
illustrate the relevance of the proposed approach that can be used to gain
knowledge about the classifier.
</dc:description>
 <dc:description>Comment: preprint</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08447</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Reduced Input-Output Dynamic Mode Decomposition</dc:title>
 <dc:creator>Benner, Peter</dc:creator>
 <dc:creator>Himpe, Christian</dc:creator>
 <dc:creator>Mitchell, Tim</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>93B30, 90C99</dc:subject>
 <dc:description>  The identification of reduced-order models from high-dimensional data is a
challenging task, and even more so if the identified system should not only be
suitable for a certain data set, but generally approximate the input-output
behavior of the data source. In this work, we consider the input-output dynamic
mode decomposition method for system identification. We compare excitation
approaches for the data-driven identification process and describe an
optimization-based stabilization strategy for the identified systems.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08448</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A simple script language for choreography of multiple, synchronizing
  non-anthropomorphic robots</dc:title>
 <dc:creator>Christiansen, Henning</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The scripting language described in this document is (in the first place)
intended to be used on robots developed by Anja M{\o}lle Lindelof and Henning
Christiansen as part of a research project about robots performing on stage.
  The target robots are expected to appear as familiar domestic objects that
take their own life, so to speak, and perhaps perform together with human
players, creating at illusion of a communication between them. In the current
version, these robots' common behaviour is determined uniquely by a script
written in the language described here -- the only possible autonomy for the
robots is action to correct dynamically for inaccuracies that arise during a
performance.
  The present work is preliminary and has not been compared to properly to
other research work in this area, and the testing is still limited. A first
implementation on small Lego Mindstorms based robots is under development by
Mads Saustrup Fox as part of his master thesis work.
</dc:description>
 <dc:description>Comment: work in progress</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08449</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>True Asymptotic Natural Gradient Optimization</dc:title>
 <dc:creator>Ollivier, Yann</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We introduce a simple algorithm, True Asymptotic Natural Gradient
Optimization (TANGO), that converges to a true natural gradient descent in the
limit of small learning rates, without explicit Fisher matrix estimation.
  For quadratic models the algorithm is also an instance of averaged stochastic
gradient, where the parameter is a moving average of a &quot;fast&quot;, constant-rate
gradient descent. TANGO appears as a particular de-linearization of averaged
SGD, and is sometimes quite different on non-quadratic models. This further
connects averaged SGD and natural gradient, both of which are arguably optimal
asymptotically.
  In large dimension, small learning rates will be required to approximate the
natural gradient well. Still, this shows it is possible to get arbitrarily
close to exact natural gradient descent with a lightweight algorithm.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08455</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Varieties of Ordered Automata</dc:title>
 <dc:creator>Kl&#xed;ma, Ond&#x159;ej</dc:creator>
 <dc:creator>Pol&#xe1;k, Libor</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68Q70, 20M35</dc:subject>
 <dc:description>  The classical Eilenberg correspondence, based on the concept of the syntactic
monoid, relates varieties of regular languages with pseudovarieties of finite
monoids. Various modifications of this correspondence appeared, with more
general classes of regular languages on one hand and classes of more complex
algebraic structures on the other hand. For example, classes of languages need
not be closed under complementation or all preimages under homomorphisms, while
monoids can be equipped with a compatible order or they can have a
distinguished set of generators. Such generalized varieties and pseudovarieties
also have natural counterparts formed by classes of finite (ordered) automata.
In this paper the previous approaches are combined. The notion of positive
$\mathcal C$-varieties of ordered semiautomata (i.e. no initial and final
states are specified) is introduced and their correspondence with positive
$\mathcal C$-varieties of languages is proved.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08467</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Eigenvalue Shaping for Nonlinear Fourier Transform
  Transmission</dc:title>
 <dc:creator>Buchberger, Andreas</dc:creator>
 <dc:creator>Amat, Alexandre Graell i</dc:creator>
 <dc:creator>Aref, Vahid</dc:creator>
 <dc:creator>Schmalen, Laurent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a nonlinear Fourier transform (NFT)-based transmission scheme,
where data is embedded into the imaginary part of the nonlinear discrete
spectrum. Inspired by probabilistic amplitude shaping, we propose a
probabilistic eigenvalue shaping (PES) scheme as a means to increase the data
rate of the system. We exploit the fact that for an NFTbased transmission
scheme the pulses in the time domain are of unequal duration by transmitting
them with a dynamic symbol interval and find a capacity-achieving distribution.
The PES scheme shapes the information symbols according to the
capacity-achieving distribution and transmits them together with the parity
symbols at the output of a low-density parity-check encoder, suitably
modulated, via time-sharing. We furthermore derive an achievable rate for the
proposed PES scheme. We verify our results with simulations of the
discrete-time model as well as with split-step Fourier simulations.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08470</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training and Testing Object Detectors with Virtual Images</dc:title>
 <dc:creator>Tian, Yonglin</dc:creator>
 <dc:creator>Li, Xuan</dc:creator>
 <dc:creator>Wang, Kunfeng</dc:creator>
 <dc:creator>Wang, Fei-Yue</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the area of computer vision, deep learning has produced a variety of
state-of-the-art models that rely on massive labeled data. However, collecting
and annotating images from the real world has a great demand for labor and
money investments and is usually too passive to build datasets with specific
characteristics, such as small area of objects and high occlusion level. Under
the framework of Parallel Vision, this paper presents a purposeful way to
design artificial scenes and automatically generate virtual images with precise
annotations. A virtual dataset named ParallelEye is built, which can be used
for several computer vision tasks. Then, by training the DPM (Deformable Parts
Model) and Faster R-CNN detectors, we prove that the performance of models can
be significantly improved by combining ParallelEye with publicly available
real-world datasets during the training phase. In addition, we investigate the
potential of testing the trained models from a specific aspect using
intentionally designed virtual datasets, in order to discover the flaws of
trained models. From the experimental results, we conclude that our virtual
dataset is viable to train and test the object detectors.
</dc:description>
 <dc:description>Comment: To be published in IEEE/CAA Journal of Automatica Sinica</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08482</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding Watermark Numbers as Reducible Permutation Graphs using
  Self-inverting Permutations</dc:title>
 <dc:creator>Chroni, Maria</dc:creator>
 <dc:creator>Nikolopoulos, Stavros D.</dc:creator>
 <dc:creator>Palios, Leonidas</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Several graph theoretic watermark methods have been proposed to encode
numbers as graph structures in software watermarking environments. In this
paper, we propose an efficient and easily implementable codec system for
encoding watermark numbers as reducible permutation flow-graphs and, thus, we
extend the class of graphs used in such a watermarking environment. More
precisely, we present an algorithm for encoding a watermark number $w$ as a
self-inverting permutation $\pi^*$, an algorithm for encoding the
self-inverting permutation $\pi^*$ into a reducible permutation graph
$F[\pi^*]$ whose structure resembles the structure of real program graphs, as
well as decoding algorithms which extract the permutation $\pi^*$ from the
reducible permutation graph $F[\pi^*]$ and the number $w$ from $\pi^*$. Both
the encoding and the decoding process takes time and space linear in the length
of the binary representation of $w$. The two main components of our proposed
codec system, i.e., the self-inverting permutation $\pi^*$ and the reducible
permutation graph $F[\pi^*]$, incorporate the binary representation of the
watermark~$w$ in their structure and possess important structural properties,
which make our system resilient to attacks; to this end, we experimentally
evaluated our system under edge modification attacks on the graph $F[\pi^*]$
and the results show that we can detect such attacks with high probability.
</dc:description>
 <dc:description>Comment: 27 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:1110.1194</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08493</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diversifying Support Vector Machines for Boosting using Kernel
  Perturbation: Applications to Class Imbalance and Small Disjuncts</dc:title>
 <dc:creator>Datta, Shounak</dc:creator>
 <dc:creator>Nag, Sayak</dc:creator>
 <dc:creator>Mullick, Sankha Subhra</dc:creator>
 <dc:creator>Das, Swagatam</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The diversification (generating slightly varying separating discriminators)
of Support Vector Machines (SVMs) for boosting has proven to be a challenge due
to the strong learning nature of SVMs. Based on the insight that perturbing the
SVM kernel may help in diversifying SVMs, we propose two kernel perturbation
based boosting schemes where the kernel is modified in each round so as to
increase the resolution of the kernel-induced Reimannian metric in the vicinity
of the datapoints misclassified in the previous round. We propose a method for
identifying the disjuncts in a dataset, dispelling the dependence on rule-based
learning methods for identifying the disjuncts. We also present a new
performance measure called Geometric Small Disjunct Index (GSDI) to quantify
the performance on small disjuncts for balanced as well as class imbalanced
datasets. Experimental comparison with a variety of state-of-the-art algorithms
is carried out using the best classifiers of each type selected by a new
approach inspired by multi-criteria decision making. The proposed method is
found to outperform the contending state-of-the-art methods on different
datasets (ranging from mildly imbalanced to highly imbalanced and characterized
by varying number of disjuncts) in terms of three different performance indices
(including the proposed GSDI).
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08500</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Perfect Privacy and Maximal Correlation</dc:title>
 <dc:creator>Rassouli, Borzoo</dc:creator>
 <dc:creator>Gunduz, Deniz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of private data disclosure is studied from an information
theoretic perspective. Considering a pair of correlated random variables
$(X,Y)$, where $Y$ denotes the observed data while $X$ denotes the private
latent variables, the following problem is addressed: What is the maximum
information that can be revealed about $Y$, while disclosing no information
about $X$? Assuming that a Markov kernel maps $Y$ to the revealed information
$U$, it is shown that the maximum mutual information between $Y$ and $U$, i.e.,
$I(Y;U)$, can be obtained as the solution of a standard linear program, when
$X$ and $U$ are required to be independent, called \textit{perfect privacy}.
This solution is shown to be greater than or equal to the \textit{non-private
information about $X$ carried by $Y$.} Maximal information disclosure under
perfect privacy is is shown to be the solution of a linear program also when
the utility is measured by the reduction in the mean square error,
$\mathbb{E}[(Y-U)^2]$, or the probability of error, $\mbox{Pr}\{Y\neq U\}$. For
jointly Gaussian $(X,Y)$, it is shown that perfect privacy is not possible if
the kernel is applied to only $Y$; whereas perfect privacy can be achieved if
the mapping is from both $X$ and $Y$; that is, if the private latent variables
can also be observed at the encoder. Next, measuring the utility and privacy by
$I(Y;U)$ and $I(X;U)$, respectively, the slope of the optimal utility-privacy
trade-off curve is studied when $I(X;U)=0$. Finally, through a similar but
independent analysis, an alternative characterization of the maximal
correlation between two random variables is provided.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08507</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Limits for Rumor Spreading in stochastic populations</dc:title>
 <dc:creator>Boczkowski, Lucas</dc:creator>
 <dc:creator>Feinerman, Ofer</dc:creator>
 <dc:creator>Korman, Amos</dc:creator>
 <dc:creator>Natale, Emanuele</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Biological systems can share and collectively process information to yield
emergent effects, despite inherent noise in communication. While man-made
systems often employ intricate structural solutions to overcome noise, the
structure of many biological systems is more amorphous. It is not well
understood how communication noise may affect the computational repertoire of
such groups. To approach this question we consider the basic collective task of
rumor spreading, in which information from few knowledgeable sources must
reliably flow into the rest of the population.
  In order to study the effect of communication noise on the ability of groups
that lack stable structures to efficiently solve this task, we consider a noisy
version of the uniform PULL model. We prove a lower bound which implies that,
in the presence of even moderate levels of noise that affect all facets of the
communication, no scheme can significantly outperform the trivial one in which
agents have to wait until directly interacting with the sources. Our results
thus show an exponential separation between the uniform PUSH and PULL
communication models in the presence of noise. Such separation may be
interpreted as suggesting that, in order to achieve efficient rumor spreading,
a system must exhibit either some degree of structural stability or,
alternatively, some facet of the communication which is immune to noise.
  We corroborate our theoretical findings with a new analysis of experimental
data regarding recruitment in Cataglyphis niger desert ants.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08509</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinitely Split Nash Equilibrium Problems in Repeated Games</dc:title>
 <dc:creator>Li, Jinlu</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>49J40, 49J52, 91A10, 91A25, 91A80</dc:subject>
 <dc:description>  In this paper, we introduce the concept of infinitely split Nash equilibrium
in repeated games in which the profile sets are chain-complete posets. Then by
using a fixed point theorem on posets in [8], we prove an existence theorem. As
an application, we study the repeated extended Bertrant duopoly model of price
competition.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08519</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Heisenberg Defense: Proactively Defending SGX Enclaves against
  Page-Table-Based Side-Channel Attacks</dc:title>
 <dc:creator>Strackx, Raoul</dc:creator>
 <dc:creator>Piessens, Frank</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Protected-module architectures (PMAs) have been proposed to provide strong
isolation guarantees, even on top of a compromised system. Unfortunately, Intel
SGX -- the only publicly available high-end PMA -- has been shown to only
provide limited isolation. An attacker controlling the untrusted page tables,
can learn enclave secrets by observing its page access patterns.
  Fortifying existing protected-module architectures in a real-world setting
against side-channel attacks is an extremely difficult task as system software
(hypervisor, operating system, ...) needs to remain in full control over the
underlying hardware. Most state-of-the-art solutions propose a reactive defense
that monitors for signs of an attack. Such approaches unfortunately cannot
detect the most novel attacks, suffer from false-positives, and place an
extraordinary heavy burden on enclave-developers when an attack is detected.
  We present Heisenberg, a proactive defense that provides complete protection
against page table based side channels. We guarantee that any attack will
either be prevented or detected automatically before {\em any} sensitive
information leaks. Consequently, Heisenberg can always securely resume enclave
execution -- even when the attacker is still present in the system.
  We present two implementations. Heisenberg-HW relies on very limited hardware
features to defend against page-table-based attacks. We use the x86/SGX
platform as an example, but the same approach can be applied when
protected-module architectures are ported to different platforms as well.
  Heisenberg-SW avoids these hardware modifications and can readily be applied.
Unfortunately, it's reliance on Intel Transactional Synchronization Extensions
(TSX) may lead to significant performance overhead under real-life conditions.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08521</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Incremental Self-Organizing Architecture for Sensorimotor Learning
  and Prediction</dc:title>
 <dc:creator>Mici, Luiza</dc:creator>
 <dc:creator>Parisi, German I.</dc:creator>
 <dc:creator>Wermter, Stefan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  During visuomotor tasks, robots have to compensate for the temporal delays
inherent in their sensorimotor processing systems. This capability becomes
crucial in a dynamic environment where the visual input is constantly changing,
e.g. when interacting with humans. For this purpose, the robot should be
equipped with a prediction mechanism able to use the acquired perceptual
experience in order to estimate possible future motor commands. In this paper,
we present a novel neural network architecture that learns prototypical
visuomotor representations and provides reliable predictions to compensate for
the delayed robot behavior in an online manner. We investigate the performance
of our method in the context of a synchronization task, where a humanoid robot
has to generate visually perceived arm motion trajectories in synchrony with a
human demonstrator. We evaluate the prediction accuracy in terms of mean
prediction error and analyze the response of the network to novel movement
demonstrations. Additionally, we provide experiments with the system receiving
incomplete data sequences, showing the robustness of the proposed architecture
in the case of a noisy and faulty visual sensor.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08523</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contemporary machine learning: a guide for practitioners in the physical
  sciences</dc:title>
 <dc:creator>Spears, Brian K.</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  Machine learning is finding increasingly broad application in the physical
sciences. This most often involves building a model relationship between a
dependent, measurable output and an associated set of controllable, but
complicated, independent inputs. We present a tutorial on current techniques in
machine learning -- a jumping-off point for interested researchers to advance
their work. We focus on deep neural networks with an emphasis on demystifying
deep learning. We begin with background ideas in machine learning and some
example applications from current research in plasma physics. We discuss
supervised learning techniques for modeling complicated functions, beginning
with familiar regression schemes, then advancing to more sophisticated deep
learning methods. We also address unsupervised learning and techniques for
reducing the dimensionality of input spaces. Along the way, we describe methods
for practitioners to help ensure that their models generalize from their
training data to as-yet-unseen test data. We describe classes of tasks --
predicting scalars, handling images, fitting time-series -- and prepare the
reader to choose an appropriate technique. We finally point out some
limitations to modern machine learning and speculate on some ways that
practitioners from the physical sciences may be particularly suited to help.
</dc:description>
 <dc:description>Comment: 29 pages, 16 figures</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08526</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Companions, Causality and Codensity</dc:title>
 <dc:creator>Pous, Damien</dc:creator>
 <dc:creator>Rot, Jurriaan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In the context of abstract coinduction in complete lattices, the notion of
compatible function makes it possible to introduce enhancements of the
coinduction proof principle. The largest compatible function, called the
companion, subsumes most enhancements and has been proved to enjoy many good
properties. Here we move to universal coalgebra, where the corresponding notion
is that of a final distributive law. We show that when it exists the final
distributive law is a monad, and that it coincides with the codensity monad of
the final sequence of the given functor. On sets, we moreover characterise this
codensity monad using a new abstract notion of causality. In particular, we
recover the fact that on streams, the functions definable by a distributive law
or GSOS specification are precisely the causal functions. Going back to
enhancements of the coinductive proof principle, we finally obtain that any
causal function gives rise to a valid up-to-context technique.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08538</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Graphs for Belief Propagation Decoding of Polar Codes</dc:title>
 <dc:creator>Cammerer, Sebastian</dc:creator>
 <dc:creator>Ebada, Moustafa</dc:creator>
 <dc:creator>Elkelesh, Ahmed</dc:creator>
 <dc:creator>Brink, Stephan ten</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We describe a novel approach to interpret a polar code as a low-density
parity-check (LDPC)-like code with an underlying sparse decoding graph. This
sparse graph is based on the encoding factor graph of polar codes and is
suitable for conventional belief propagation (BP) decoding. We discuss several
pruning techniques based on the check node decoder (CND) and variable node
decoder (VND) update equations, significantly reducing the size (i.e., decoding
complexity) of the parity-check matrix. As a result, iterative polar decoding
can then be conducted on a sparse graph, akin to the traditional
well-established LDPC decoding, e.g., using a fully parallel sum product
algorithm (SPA). We show that the proposed iterative polar decoder has a
negligible performance loss for short-to-intermediate codelengths compared to
Ar{\i}kan's original BP decoder. Finally, the proposed decoder is shown to
benefit from a reduced complexity and reduced memory requirements and, thus, it
is more suitable for hardware implementations.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08550</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DancingLines: An Analytical Scheme to Depict Cross-Platform Event
  Popularity</dc:title>
 <dc:creator>Gao, Tianxiang</dc:creator>
 <dc:creator>Bao, Weiming</dc:creator>
 <dc:creator>Li, Jinning</dc:creator>
 <dc:creator>Gao, Xiaofeng</dc:creator>
 <dc:creator>Kong, Boyuan</dc:creator>
 <dc:creator>Tang, Yan</dc:creator>
 <dc:creator>Chen, Guihai</dc:creator>
 <dc:creator>Li, Xuan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Nowadays, events usually burst and are propagated online through multiple
modern media like social networks and search engines. There exists various
research discussing the event dissemination trends on individual medium, while
few studies focus on event popularity analysis from a cross-platform
perspective. Challenges come from the vast diversity of events and media,
limited access to aligned datasets across different media and a great deal of
noise in the datasets. In this paper, we design DancingLines, an innovative
scheme that captures and quantitatively analyzes event popularity between
pairwise text media. It contains two models: TF-SW, a semantic-aware popularity
quantification model, based on an integrated weight coefficient leveraging
Word2Vec and TextRank; and wDTW-CD, a pairwise event popularity time series
alignment model matching different event phases adapted from Dynamic Time
Warping. We also propose three metrics to interpret event popularity trends
between pairwise social platforms. Experimental results on eighteen real-world
event datasets from an influential social network and a popular search engine
validate the effectiveness and applicability of our scheme. DancingLines is
demonstrated to possess broad application potentials for discovering the
knowledge of various aspects related to events and different media.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08555</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Load Balancing in Networked Systems: Universality Properties
  and Stochastic Coupling Methods</dc:title>
 <dc:creator>van der Boor, Mark</dc:creator>
 <dc:creator>Borst, Sem C.</dc:creator>
 <dc:creator>van Leeuwaarden, Johan S. H.</dc:creator>
 <dc:creator>Mukherjee, Debankur</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We present an overview of scalable load balancing algorithms which provide
favorable delay performance in large-scale systems, and yet only require
minimal implementation overhead. Aimed at a broad audience, the paper starts
with an introduction to the basic load balancing scenario, consisting of a
single dispatcher where tasks arrive that must immediately be forwarded to one
of $N$ single-server queues.
  A popular class of load balancing algorithms are so-called power-of-$d$ or
JSQ($d$) policies, where an incoming task is assigned to a server with the
shortest queue among $d$ servers selected uniformly at random. This class
includes the Join-the-Shortest-Queue (JSQ) policy as a special case ($d = N$),
which has strong stochastic optimality properties and yields a mean waiting
time that vanishes as $N$ grows large for any fixed subcritical load. However,
a nominal implementation of the JSQ policy involves a prohibitive communication
burden in large-scale deployments. In contrast, a random assignment policy ($d
= 1$) does not entail any communication overhead, but the mean waiting time
remains constant as $N$ grows large for any fixed positive load.
  In order to examine the fundamental trade-off between performance and
implementation overhead, we consider an asymptotic regime where $d(N)$ depends
on $N$. We investigate what growth rate of $d(N)$ is required to match the
performance of the JSQ policy on fluid and diffusion scale. The results
demonstrate that the asymptotics for the JSQ($d(N)$) policy are insensitive to
the exact growth rate of $d(N)$, as long as the latter is sufficiently fast,
implying that the optimality of the JSQ policy can asymptotically be preserved
while dramatically reducing the communication overhead. We additionally show
how the communication overhead can be reduced yet further by the so-called
Join-the-Idle-Queue scheme, leveraging memory at the dispatcher.
</dc:description>
 <dc:description>Comment: Survey paper. Contribution to the Proceedings of the ICM 2018</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08558</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice-based Locality Sensitive Hashing is Optimal</dc:title>
 <dc:creator>Chandrasekaran, Karthekeyan</dc:creator>
 <dc:creator>Dadush, Daniel</dc:creator>
 <dc:creator>Gandikota, Venkata</dc:creator>
 <dc:creator>Grigorescu, Elena</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Locality sensitive hashing (LSH) was introduced by Indyk and Motwani (STOC
`98) to give the first sublinear time algorithm for the c-approximate nearest
neighbor (ANN) problem using only polynomial space. At a high level, an LSH
family hashes &quot;nearby&quot; points to the same bucket and &quot;far away&quot; points to
different buckets. The quality of measure of an LSH family is its LSH exponent,
which helps determine both query time and space usage.
  In a seminal work, Andoni and Indyk (FOCS `06) constructed an LSH family
based on random ball partitioning of space that achieves an LSH exponent of
1/c^2 for the l_2 norm, which was later shown to be optimal by Motwani, Naor
and Panigrahy (SIDMA `07) and O'Donnell, Wu and Zhou (TOCT `14). Although
optimal in the LSH exponent, the ball partitioning approach is computationally
expensive. So, in the same work, Andoni and Indyk proposed a simpler and more
practical hashing scheme based on Euclidean lattices and provided computational
results using the 24-dimensional Leech lattice. However, no theoretical
analysis of the scheme was given, thus leaving open the question of finding the
exponent of lattice based LSH.
  In this work, we resolve this question by showing the existence of lattices
achieving the optimal LSH exponent of 1/c^2 using techniques from the geometry
of numbers. At a more conceptual level, our results show that optimal LSH space
partitions can have periodic structure. Understanding the extent to which
additional structure can be imposed on these partitions, e.g. to yield low
space and query complexity, remains an important open problem.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08560</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monotone Difference Schemes for Convection-Dominated Diffusion-Reaction
  Equations Based on Quadratic Spline</dc:title>
 <dc:creator>Stelia, O.</dc:creator>
 <dc:creator>Potapenko, L.</dc:creator>
 <dc:creator>Sirenko, I.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65Nxx</dc:subject>
 <dc:description>  A three-point monotone difference scheme is proposed for solving a
one-dimensional non-stationary convection-diffusion-reaction equation with
variable coefficients. The scheme is based on a parabolic spline and allows to
linearly reproduce the numerical solution of the boundary value problem over
the integral segment in the form of the function which continuous with its
first derivative. The constructed difference scheme give a highly effective
tool for solving problems with a small parameter at the older derivative in a
wide range of output data of the problem. In the test case, numerical and exact
solutions of the problem are compared with the significant dominance of the
convective term of the equation over the diffusion. Numerous calculations
showed the high efficiency of the new monotonous scheme developed.
</dc:description>
 <dc:description>Comment: 8 pp., 1 fig</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08566</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extended Product and Integrated Interleaved Codes</dc:title>
 <dc:creator>Blaum, Mario</dc:creator>
 <dc:creator>Hetzler, Steven</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A new class of codes, Extended Product (EPC) Codes, consisting of a product
code with a number of extra parities added, is presented and applications for
erasure decoding are discussed. An upper bound on the minimum distance of EPC
codes is given, as well as constructions meeting the bound for some relevant
cases. A special case of EPC codes, Extended Integrated Interleaved (EII)
codes, which naturally unify Integrated Interleaved (II) codes and product
codes, is defined and studied in detail. It is shown that EII codes often
improve the minimum distance of II codes with the same rate, and they enhance
the decoding algorithm by allowing decoding on columns as well as on rows. It
is also shown that EII codes allow for encoding II codes with an uniform
distribution of the parity symbols.
</dc:description>
 <dc:description>Comment: 24 pages. arXiv admin note: text overlap with arXiv:1610.04273</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08573</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Longest common substring with approximately $k$ mismatches</dc:title>
 <dc:creator>Kociumaka, Tomasz</dc:creator>
 <dc:creator>Radoszewski, Jakub</dc:creator>
 <dc:creator>Starikovskaya, Tatiana</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the longest common substring problem we are given two strings of length
$n$ and must find a substring of maximal length that occurs in both strings. It
is well-known that the problem can be solved in linear time, but the solution
is not robust and can vary greatly when the input strings are changed even by
one letter. To circumvent this, Leimeister and Morgenstern introduced the
problem of the longest common substring with $k$ mismatches. Lately, this
problem has received a lot of attention in the literature. In this paper we
first show a conditional lower bound based on the SETH hypothesis implying that
there is little hope to improve existing solutions. We then introduce a new but
closely related problem of the longest common substring with approximately $k$
mismatches and use computational geometry techniques to show that it admits a
solution with strongly subquadratic running time. We also apply these results
to obtain a strongly subquadratic approximation algorithm for the longest
common substring with $k$ mismatches problem and show conditional hardness of
improving its approximation ratio.
</dc:description>
 <dc:description>Comment: extended version of a paper from CPM 2016</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08577</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Stochastic Dual Coordinate Ascent for Conditional Random Fields</dc:title>
 <dc:creator>Priol, R&#xe9;mi Le</dc:creator>
 <dc:creator>Touati, Ahmed</dc:creator>
 <dc:creator>Lacoste-Julien, Simon</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This work investigates training Conditional Random Fields (CRF) by Stochastic
Dual Coordinate Ascent (SDCA). SDCA enjoys a linear convergence rate and a
strong empirical performance for independent classification problems. However,
it has never been used to train CRF. Yet it benefits from an exact line search
with a single marginalization oracle call, unlike previous approaches. In this
paper, we adapt SDCA to train CRF and we enhance it with an adaptive
non-uniform sampling strategy. Our preliminary experiments suggest that this
method matches state-of-the-art CRF optimization techniques.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08578</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Golden codes: quantum LDPC codes built from regular tessellations of
  hyperbolic 4-manifolds</dc:title>
 <dc:creator>Londe, Vivien</dc:creator>
 <dc:creator>Leverrier, Anthony</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We adapt a construction of Guth and Lubotzky [arXiv:1310.5555] to obtain a
family of quantum LDPC codes with non-vanishing rate and minimum distance
scaling like $n^{0.2}$ where $n$ is the number of physical qubits. Similarly as
in [arXiv:1310.5555], our homological code family stems from tessellated
hyperbolic 4-manifolds. The main novelty of this work is that we consider a
regular tessellation consisting of hypercubes. We exploit this strong local
structure to design and analyze an efficient decoding algorithm.
</dc:description>
 <dc:description>Comment: 21 pages, 4 figures</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08583</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of PPG Biometrics for Authentication in different states</dc:title>
 <dc:creator>Yadav, Umang</dc:creator>
 <dc:creator>Abbas, Sherif N</dc:creator>
 <dc:creator>Hatzinakos, Dimitrios</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Amongst all medical biometric traits, Photoplethysmograph (PPG) is the
easiest to acquire. PPG records the blood volume change with just combination
of Light Emitting Diode and Photodiode from any part of the body. With IoT and
smart homes' penetration, PPG recording can easily be integrated with other
vital wearable devices. PPG represents peculiarity of hemodynamics and
cardiovascular system for each individual. This paper presents non-fiducial
method for PPG based biometric authentication. Being a physiological signal,
PPG signal alters with physical/mental stress and time. For robustness, these
variations cannot be ignored. While, most of the previous works focused only on
single session, this paper demonstrates extensive performance evaluation of PPG
biometrics against single session data, different emotions, physical exercise
and time-lapse using Continuous Wavelet Transform (CWT) and Direct Linear
Discriminant Analysis (DLDA). When evaluated on different states and datasets,
equal error rate (EER) of $0.5\%$-$6\%$ was achieved for $45$-$60$s average
training time. Our CWT/DLDA based technique outperformed all other
dimensionality reduction techniques and previous work.
</dc:description>
 <dc:description>Comment: Accepted at 11th IAPR/IEEE International Conference on Biometrics,
  2018. 6 pages, 6 figures</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08585</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denoising of image gradients and total generalized variation denoising</dc:title>
 <dc:creator>Komander, Birgit</dc:creator>
 <dc:creator>Lorenz, Dirk A.</dc:creator>
 <dc:creator>Vestweber, Lena</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We revisit total variation denoising and study an augmented model where we
assume that an estimate of the image gradient is available. We show that this
increases the image reconstruction quality and derive that the resulting model
resembles the total generalized variation denoising method, thus providing a
new motivation for this model. Further, we propose to use a constraint
denoising model and develop a variational denoising model that is basically
parameter free, i.e. all model parameters are estimated directly from the noisy
image.
  Moreover, use Chambolle-Pock's primal dual method as well as the
Douglas-Rachford method for the new models. For the latter one has to solve
large discretizations of partial differential equations and we derive
preconditioners to do so. Numerical experiments show that the resulting method
has good denoising properties and also that preconditioning does increase
convergence significantly.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08588</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rank Pruning for Dominance Queries in CP-Nets</dc:title>
 <dc:creator>Laing, Kathryn</dc:creator>
 <dc:creator>Thwaites, Peter Adam</dc:creator>
 <dc:creator>Gosling, John Paul</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>68T30 (Primary), 68T20 (Secondary)</dc:subject>
 <dc:description>  Conditional preference networks (CP-nets) are a graphical representation of a
person's (conditional) preferences over a set of discrete variables. In this
paper, we introduce a novel method of quantifying preference for any given
outcome based on a CP-net representation of a user's preferences. We
demonstrate that these values are useful for reasoning about user preferences.
In particular, they allow us to order (any subset of) the possible outcomes in
accordance with the user's preferences. Further, these values can be used to
improve the efficiency of outcome dominance testing. That is, given a pair of
outcomes, we can determine which the user prefers more efficiently. We show
that these results also hold for CP-nets that express indifference between
variable values.
</dc:description>
 <dc:description>Comment: 43 pages, 4 figures</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08589</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Survey of Spectrum Sharing for Inter-Technology Coexistence</dc:title>
 <dc:creator>Voicu, Andra M.</dc:creator>
 <dc:creator>Simi&#x107;, Ljiljana</dc:creator>
 <dc:creator>Petrova, Marina</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Increasing capacity demands in emerging wireless technologies are expected to
be met by network densification and spectrum bands open to multiple
technologies. These will, in turn, increase the level of interference and also
result in more complex inter-technology interactions, which will need to be
managed through spectrum sharing mechanisms. Consequently, novel spectrum
sharing mechanisms should be designed to allow spectrum access for multiple
technologies, while efficiently utilizing the spectrum resources overall.
Importantly, it is not trivial to design efficient spectrum sharing mechanisms,
not only due to technical aspects, but also due to regulatory and business
model constraints. In this survey we address spectrum sharing mechanisms for
wireless inter-technology coexistence by means of a technology circle that
incorporates in a unified, system-level view the technical and non-technical
aspects. We thus systematically explore the spectrum sharing design space
consisting of parameters at different layers. Using this framework, we present
a literature review on inter-technology coexistence with a focus on wireless
technologies with the same spectrum access rights, i.e. (i) primary/primary,
(ii) secondary/secondary, and (iii) technologies operating in a spectrum
commons. Moreover, we reflect on our literature review to identify possible
spectrum sharing design solutions and performance evaluation approaches useful
for future coexistence cases. Finally, we discuss spectrum sharing design
challenges and suggest potential future research directions.
</dc:description>
 <dc:description>Comment: 28 pages, 6 figures</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08597</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning the Kernel for Classification and Regression</dc:title>
 <dc:creator>Li, Chen</dc:creator>
 <dc:creator>Venturi, Luca</dc:creator>
 <dc:creator>Xu, Ruitu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We investigate a series of learning kernel problems with polynomial
combinations of base kernels, which will help us solve regression and
classification problems. We also perform some numerical experiments of
polynomial kernels with regression and classification tasks on different
datasets.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08604</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Surgical Skill Assessment in RMIS Training</dc:title>
 <dc:creator>Zia, Aneeq</dc:creator>
 <dc:creator>Essa, Irfan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Purpose: Manual feedback in basic RMIS training can consume a significant
amount of time from expert surgeons' schedule and is prone to subjectivity.
While VR-based training tasks can generate automated score reports, there is no
mechanism of generating automated feedback for surgeons performing basic
surgical tasks in RMIS training. In this paper, we explore the usage of
different holistic features for automated skill assessment using only robot
kinematic data and propose a weighted feature fusion technique for improving
score prediction performance.
  Methods: We perform our experiments on the publicly available JIGSAWS dataset
and evaluate four different types of holistic features from robot kinematic
data - Sequential Motion Texture (SMT), Discrete Fourier Transform (DFT),
Discrete Cosine Transform (DCT) and Approximate Entropy (ApEn). The features
are then used for skill classification and exact skill score prediction. Along
with using these features individually, we also evaluate the performance using
our proposed weighted combination technique.
  Results: Our results demonstrate that these holistic features outperform all
previous HMM based state-of-the-art methods for skill classification on the
JIGSAWS dataset. Also, our proposed feature fusion strategy significantly
improves performance for skill score predictions achieving up to 0.61 average
spearman correlation coefficient.
  Conclusions: Holistic features capturing global information from robot
kinematic data can successfully be used for evaluating surgeon skill in basic
surgical tasks on the da Vinci robot. Using the framework presented can
potentially allow for real time score feedback in RMIS training.
</dc:description>
 <dc:description>Comment: Accepted at IPCAI 2018</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08608</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning in the Machine: the Symmetries of the Deep Learning Channel</dc:title>
 <dc:creator>Baldi, Pierre</dc:creator>
 <dc:creator>Sadowski, Peter</dc:creator>
 <dc:creator>Lu, Zhiqin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In a physical neural system, learning rules must be local both in space and
time. In order for learning to occur, non-local information must be
communicated to the deep synapses through a communication channel, the deep
learning channel. We identify several possible architectures for this learning
channel (Bidirectional, Conjoined, Twin, Distinct) and six symmetry challenges:
1) symmetry of architectures; 2) symmetry of weights; 3) symmetry of neurons;
4) symmetry of derivatives; 5) symmetry of processing; and 6) symmetry of
learning rules. Random backpropagation (RBP) addresses the second and third
symmetry, and some of its variations, such as skipped RBP (SRBP) address the
first and the fourth symmetry. Here we address the last two desirable
symmetries showing through simulations that they can be achieved and that the
learning channel is particularly robust to symmetry variations. Specifically,
random backpropagation and its variations can be performed with the same
non-linear neurons used in the main input-output forward channel, and the
connections in the learning channel can be adapted using the same algorithm
used in the forward channel, removing the need for any specialized hardware in
the learning channel. Finally, we provide mathematical results in simple cases
showing that the learning equations in the forward and backward channels
converge to fixed points, for almost any initial conditions. In symmetric
architectures, if the weights in both channels are small at initialization,
adaptation in both channels leads to weights that are essentially symmetric
during and after learning. Biological connections are discussed.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08618</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Extraction and Feature Selection: Reducing Data Complexity with
  Apache Spark</dc:title>
 <dc:creator>Sisiaridis, Dimitrios</dc:creator>
 <dc:creator>Markowitch, Olivier</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Feature extraction and feature selection are the first tasks in
pre-processing of input logs in order to detect cyber security threats and
attacks while utilizing machine learning. When it comes to the analysis of
heterogeneous data derived from different sources, these tasks are found to be
time-consuming and difficult to be managed efficiently. In this paper, we
present an approach for handling feature extraction and feature selection for
security analytics of heterogeneous data derived from different network
sensors. The approach is implemented in Apache Spark, using its python API,
named pyspark.
</dc:description>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08618</dc:identifier>
 <dc:identifier>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.9, No.6, November 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08622</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis and Implementation of a Hourly Billing Mechanism for Demand
  Response Management</dc:title>
 <dc:creator>Jacquot, Paulin</dc:creator>
 <dc:creator>Beaude, Olivier</dc:creator>
 <dc:creator>Gaubert, St&#xe9;phane</dc:creator>
 <dc:creator>Oudjane, Nadia</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  An important part of the Smart Grid literature on residential Demand Response
deals with game-theoretic consumption models. Among those papers, the hourly
billing model is of special interest as an intuitive and fair mechanism. We
focus on this model and answer to several theoretical and practical questions.
First, we prove the uniqueness of the consumption profile corresponding to the
Nash equilibrium, and we analyze its efficiency by providing a bound on the
Price of Anarchy. Next, we address the computational issue of the equilibrium
profile by providing two algorithms: the cycling best response dynamics and a
projected gradient descent method, and by giving an upper bound on their
convergence rate to the equilibrium. Last, we simulate this demand response
framework in a stochastic environment where the parameters depend on forecasts.
We show numerically the relevance of an online demand response procedure, which
reduces the impact of inaccurate forecasts.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures, submitted to IEEE Transactions on Smart Grid</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08626</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Obtaining Accurate Probabilistic Causal Inference by Post-Processing
  Calibration</dc:title>
 <dc:creator>Jabbari, Fattaneh</dc:creator>
 <dc:creator>Naeini, Mahdi Pakdaman</dc:creator>
 <dc:creator>Cooper, Gregory F.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Discovery of an accurate causal Bayesian network structure from observational
data can be useful in many areas of science. Often the discoveries are made
under uncertainty, which can be expressed as probabilities. To guide the use of
such discoveries, including directing further investigation, it is important
that those probabilities be well-calibrated. In this paper, we introduce a
novel framework to derive calibrated probabilities of causal relationships from
observational data. The framework consists of three components: (1) an
approximate method for generating initial probability estimates of the edge
types for each pair of variables, (2) the availability of a relatively small
number of the causal relationships in the network for which the truth status is
known, which we call a calibration training set, and (3) a calibration method
for using the approximate probability estimates and the calibration training
set to generate calibrated probabilities for the many remaining pairs of
variables. We also introduce a new calibration method based on a shallow neural
network. Our experiments on simulated data support that the proposed approach
improves the calibration of causal edge predictions. The results also support
that the approach often improves the precision and recall of predictions.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08634</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Data Colocation Grid Framework for Big Data Medical Image Processing -
  Backend Design</dc:title>
 <dc:creator>Bao, Shunxing</dc:creator>
 <dc:creator>Huo, Yuankai</dc:creator>
 <dc:creator>Parvathaneni, Prasanna</dc:creator>
 <dc:creator>Plassard, Andrew J.</dc:creator>
 <dc:creator>Bermudez, Camilo</dc:creator>
 <dc:creator>Yao, Yuang</dc:creator>
 <dc:creator>Llyu, Ilwoo</dc:creator>
 <dc:creator>Gokhale, Aniruddha</dc:creator>
 <dc:creator>Landman, Bennett A.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  When processing large medical imaging studies, adopting high performance grid
computing resources rapidly becomes important. We recently presented a &quot;medical
image processing-as-a-service&quot; grid framework that offers promise in utilizing
the Apache Hadoop ecosystem and HBase for data colocation by moving computation
close to medical image storage. However, the framework has not yet proven to be
easy to use in a heterogeneous hardware environment. Furthermore, the system
has not yet validated when considering variety of multi-level analysis in
medical imaging. Our target criteria are (1) improving the framework's
performance in a heterogeneous cluster, (2) performing population based summary
statistics on large datasets, and (3) introducing a table design scheme for
rapid NoSQL query. In this paper, we present a backend interface application
program interface design for Hadoop &amp; HBase for Medical Image Processing. The
API includes: Upload, Retrieve, Remove, Load balancer and MapReduce templates.
A dataset summary statistic model is discussed and implemented by MapReduce
paradigm. We introduce a HBase table scheme for fast data query to better
utilize the MapReduce model. Briefly, 5153 T1 images were retrieved from a
university secure database and used to empirically access an in-house grid with
224 heterogeneous CPU cores. Three empirical experiments results are presented
and discussed: (1) load balancer wall-time improvement of 1.5-fold compared
with a framework with built-in data allocation strategy, (2) a summary
statistic model is empirically verified on grid framework and is compared with
the cluster when deployed with a standard Sun Grid Engine, which reduces 8-fold
of wall clock time and 14-fold of resource time, and (3) the proposed HBase
table scheme improves MapReduce computation with 7 fold reduction of wall time
compare with a na\&quot;ive scheme when datasets are relative small.
</dc:description>
 <dc:description>Comment: Accepted and awaiting publication at SPIE Medical Imaging,
  International Society for Optics and Photonics, 2018</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08636</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Find the Conversation Killers: a Predictive Study of Thread-ending Posts</dc:title>
 <dc:creator>Jiao, Yunhao</dc:creator>
 <dc:creator>Li, Cheng</dc:creator>
 <dc:creator>Wu, Fei</dc:creator>
 <dc:creator>Mei, Qiaozhu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  How to improve the quality of conversations in online communities has
attracted considerable attention recently. Having engaged, urbane, and reactive
online conversations has a critical effect on the social life of Internet
users. In this study, we are particularly interested in identifying a post in a
multi-party conversation that is unlikely to be further replied to, which
therefore kills that thread of the conversation. For this purpose, we propose a
deep learning model called the ConverNet. ConverNet is attractive due to its
capability of modeling the internal structure of a long conversation and its
appropriate encoding of the contextual information of the conversation, through
effective integration of attention mechanisms. Empirical experiments on
real-world datasets demonstrate the effectiveness of the proposal model. For
the widely concerned topic, our analysis also offers implications for improving
the quality and user experience of online conversations.
</dc:description>
 <dc:description>Comment: Accepted by WWW 2018 (The Web Conference, 2018)</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08637</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the relationships between bibliographic characteristics of scientific
  documents and citation and Mendeley readership counts: A large-scale analysis
  of Web of Science publications</dc:title>
 <dc:creator>Zahedi, Zohreh</dc:creator>
 <dc:creator>Haustein, Stefanie</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  In this paper we present a first large-scale analysis of the relationship
between Mendeley readership and citation counts with particular documents
bibliographic characteristics. A data set of 1.3 million publications from
different fields published in journals covered by the Web of Science (WoS) has
been analyzed. This work reveals that document types that are often excluded
from citation analysis due to their lower citation values, like editorial
materials, letters, or news items, are strongly covered and saved in Mendeley,
suggesting that Mendeley readership can reliably inform the analysis of these
document types. Findings show that collaborative papers are frequently saved in
Mendeley, which is similar to what is observed for citations. The relationship
between readership and the length of titles and number of pages, however, is
weaker than for the same relationship observed for citations. The analysis of
different disciplines also points to different patterns in the relationship
between several document characteristics, readership, and citation counts.
Overall, results highlight that although disciplinary differences exist,
readership counts are related to similar bibliographic characteristics as those
related to citation counts, reinforcing the idea that Mendeley readership and
citations capture a similar concept of impact, although they cannot be
considered as equivalent indicators.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08637</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2017.12.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08641</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Geometry of Continuous Latent Space Models for Network Data</dc:title>
 <dc:creator>Smith, Anna L.</dc:creator>
 <dc:creator>Asta, Dena M.</dc:creator>
 <dc:creator>Calder, Catherine A.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We review the class of continuous latent space (statistical) models for
network data, paying particular attention to the role of the geometry of the
latent space. In these models, the presence/absence of network dyadic ties are
assumed to be conditionally independent given the dyads? unobserved positions
in a latent space. In this way, these models provide a probabilistic framework
for embedding network nodes in a continuous space equipped with a geometry that
facilitates the description of dependence between random dyadic ties.
Specifically, these models naturally capture homophilous tendencies and triadic
clustering, among other common properties of observed networks. In addition to
reviewing the literature on continuous latent space models from a geometric
perspective, we highlight the important role the geometry of the latent space
plays on properties of networks arising from these models via intuition and
simulation. Finally, we discuss results from spectral graph theory that allow
us to explore the role of the geometry of the latent space, independent of
network size. We conclude with conjectures about how these results might be
used to infer the appropriate latent space geometry from observed networks.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08642</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Least-Squares Temporal Difference Learning for the Linear Quadratic
  Regulator</dc:title>
 <dc:creator>Tu, Stephen</dc:creator>
 <dc:creator>Recht, Benjamin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Reinforcement learning (RL) has been successfully used to solve many
continuous control tasks. Despite its impressive results however, fundamental
questions regarding the sample complexity of RL on continuous problems remain
open. We study the performance of RL in this setting by considering the
behavior of the Least-Squares Temporal Difference (LSTD) estimator on the
classic Linear Quadratic Regulator (LQR) problem from optimal control. We give
the first finite-time analysis of the number of samples needed to estimate the
value function for a fixed static state-feedback policy to within
$\varepsilon$-relative error. In the process of deriving our result, we give a
general characterization for when the minimum eigenvalue of the empirical
covariance matrix formed along the sample path of a fast-mixing stochastic
process concentrates above zero, extending a result by Koltchinskii and
Mendelson in the independent covariates setting. Finally, we provide
experimental evidence indicating that our analysis correctly captures the
qualitative behavior of LSTD on several LQR instances.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08644</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepPicar: A Low-cost Deep Neural Network-based Autonomous Car</dc:title>
 <dc:creator>Bechtel, Michael Garrett</dc:creator>
 <dc:creator>McEllhiney, Elise</dc:creator>
 <dc:creator>Yun, Heechul</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  We present DeepPicar, a low-cost deep neural network (DNN) based autonomous
car platform. DeepPicar is a small scale replication of a real self-driving car
called Dave-2 by NVIDIA, which drove on public roads using a deep convolutional
neural network (CNN), that takes images from a front-facing camera as input and
produces car steering angles as output. DeepPicar uses the exact same network
architecture---9 layers, 27 million connections and 250K parameters---and can
be trained to drive itself, in real-time, using a web camera and a modest
Raspberry Pi 3 quad-core platform. Using DeepPicar, we analyze the Pi 3's
computing capabilities to support end-to-end deep learning based real-time
control of autonomous vehicles. We also systematically compare other
contemporary embedded computing platforms using the DeepPicar's CNN based
real-time control software as a workload. We find all tested platforms,
including the Pi 3, are capable of supporting deep-learning based real-time
control, from 20 Hz up to 100 Hz depending on hardware platform. However,
shared resource contention remains an important issue that must be considered
in applying deep-learning models on shared memory based embedded computing
platforms.
</dc:description>
 <dc:description>Comment: 10 pages, 15 figures, 3 tables</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08645</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dropout Feature Ranking for Deep Learning Models</dc:title>
 <dc:creator>Chang, Chun-Hao</dc:creator>
 <dc:creator>Rampasek, Ladislav</dc:creator>
 <dc:creator>Goldenberg, Anna</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks are a promising technology achieving state-of-the-art
results in biological and healthcare domains. Unfortunately, DNNs are notorious
for their non-interpretability. Clinicians are averse to black boxes and thus
interpretability is paramount to broadly adopting this technology. We aim to
close this gap by proposing a new general feature ranking method for deep
learning. We show that our method outperforms LASSO, Elastic Net, Deep Feature
Selection and various heuristics on a simulated dataset. We also compare our
method in a multivariate clinical time-series dataset and demonstrate our
ranking rivals or outperforms other methods in Recurrent Neural Network
setting. Finally, we apply our feature ranking to the Variational Autoencoder
recently proposed to predict drug response in cell lines and show that it
identifies meaningful genes corresponding to the drug response.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08647</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emo, Love, and God: Making Sense of Urban Dictionary, a Crowd-Sourced
  Online Dictionary</dc:title>
 <dc:creator>Nguyen, Dong</dc:creator>
 <dc:creator>McGillivray, Barbara</dc:creator>
 <dc:creator>Yasseri, Taha</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The Internet facilitates large-scale collaborative projects. The emergence of
Web~2.0 platforms, where producers and consumers of content unify, has
drastically changed the information market. On the one hand, the promise of the
&quot;wisdom of the crowd&quot; has inspired successful projects such as Wikipedia, which
has become the primary source of crowd-based information in many languages. On
the other hand, the decentralized and often un-monitored environment of such
projects may make them susceptible to systematic malfunction and misbehavior.
In this work, we focus on Urban Dictionary, a crowd-sourced online dictionary.
We combine computational methods with qualitative annotation and shed light on
the overall features of Urban Dictionary in terms of growth, coverage and types
of content. We measure a high presence of opinion-focused entries, as opposed
to the meaning-focused entries that we expect from traditional dictionaries.
Furthermore, Urban Dictionary covers many informal, unfamiliar words as well as
proper nouns. There is also a high presence of offensive content, but highly
offensive content tends to receive lower scores through the voting system. Our
study highlights that Urban Dictionary has a higher content heterogeneity than
found in traditional dictionaries, which poses challenges in terms in
processing but also offers opportunities to analyze and track language
innovation.
</dc:description>
 <dc:description>Comment: Under review, data available upon request</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08650</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A short variational proof of equivalence between policy gradients and
  soft Q learning</dc:title>
 <dc:creator>Richemond, Pierre H.</dc:creator>
 <dc:creator>Maginnis, Brendan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Two main families of reinforcement learning algorithms, Q-learning and policy
gradients, have recently been proven to be equivalent when using a softmax
relaxation on one part, and an entropic regularization on the other. We relate
this result to the well-known convex duality of Shannon entropy and the softmax
function. Such a result is also known as the Donsker-Varadhan formula. This
provides a short proof of the equivalence. We then interpret this duality
further, and use ideas of convex analysis to prove a new policy inequality
relative to soft Q-learning.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08667</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WNOS: An Optimization-based Wireless Network Operating System</dc:title>
 <dc:creator>Guan, Zhangyu</dc:creator>
 <dc:creator>Bertizzolo, Lorenzo</dc:creator>
 <dc:creator>Demirors, Emrecan</dc:creator>
 <dc:creator>Melodia, Tommaso</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This article investigates the basic design principles for a new Wireless
Network Operating System (WNOS), a radically different approach to
software-defined networking (SDN) for infrastructure-less wireless networks.
Departing from well-understood approaches inspired by OpenFlow, WNOS provides
the network designer with an abstraction hiding (i) the lower-level details of
the wireless protocol stack and (ii) the distributed nature of the network
operations. Based on this abstract representation, the WNOS takes network
control programs written on a centralized, high-level view of the network and
automatically generates distributed cross-layer control programs based on
distributed optimization theory that are executed by each individual node on an
abstract representation of the radio hardware.
  We first discuss the main architectural principles of WNOS. Then, we discuss
a new approach to generate solution algorithms for each of the resulting
subproblems in an automated fashion. Finally, we illustrate a prototype
implementation of WNOS on software-defined radio devices and test its
effectiveness by considering specific cross-layer control problems.
Experimental results indicate that, based on the automatically generated
distributed control programs, WNOS achieves 18%, 56% and 80.4% utility gain in
networks with low, medium and high levels of interference; maybe more
importantly, we illustrate how the global network behavior can be controlled by
modifying a few lines of code on a centralized abstraction.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08672</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Utility Maximization in Adversarial Environments</dc:title>
 <dc:creator>Liang, Qingkai</dc:creator>
 <dc:creator>Modiano, Eytan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Stochastic models have been dominant in network optimization theory for over
two decades, due to their analytical tractability. However, these models fail
to capture non-stationary or even adversarial network dynamics which are of
increasing importance for modeling the behavior of networks under malicious
attacks or characterizing short-term transient behavior. In this paper, we
consider the network utility maximization problem in adversarial network
settings. In particular, we focus on the tradeoffs between total queue length
and utility regret which measures the difference in network utility between a
causal policy and an &quot;oracle&quot; that knows the future within a finite time
horizon. Two adversarial network models are developed to characterize the
adversary's behavior. We provide lower bounds on the tradeoff between utility
regret and queue length under these adversarial models, and analyze the
performance of two control policies (i.e., the Drift-plus-Penalty algorithm and
the Tracking Algorithm).
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08673</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relevance Scoring of Triples Using Ordinal Logistic Classification - The
  Celosia Triple Scorer at WSDM Cup 2017</dc:title>
 <dc:creator>Fatma, Nausheen</dc:creator>
 <dc:creator>Chinnakotla, Manoj K.</dc:creator>
 <dc:creator>Shrivastava, Manish</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  In this paper, we report our participation in the Task 2: Triple Scoring of
WSDM Cup challenge 2017. In this task, we were provided with triples of
&quot;type-like&quot; relations which were given human-annotated relevance scores ranging
from 0 to 7, with 7 being the &quot;most relevant&quot; and 0 being the &quot;least relevant&quot;.
The task focuses on two such relations: profession and nationality. We built a
system which could automatically predict the relevance scores for unseen
triples. Our model is primarily a supervised machine learning based one in
which we use well-designed features which are used to a make a Logistic Ordinal
Regression based classification model. The proposed system achieves an overall
accuracy score of 0.73 and Kendall's tau score of 0.36.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08674</identifier>
 <datestamp>2017-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RelSifter: Scoring Triples from Type-like Relations - The Samphire
  Triple Scorer at WSDM Cup 2017</dc:title>
 <dc:creator>Shiralkar, Prashant</dc:creator>
 <dc:creator>Avram, Mihai</dc:creator>
 <dc:creator>Ciampaglia, Giovanni Luca</dc:creator>
 <dc:creator>Menczer, Filippo</dc:creator>
 <dc:creator>Flammini, Alessandro</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  We present RelSifter, a supervised learning approach to the problem of
assigning relevance scores to triples expressing type-like relations such as
'profession' and 'nationality.' To provide additional contextual information
about individuals and relations we supplement the data provided as part of the
WSDM 2017 Triple Score contest with Wikidata and DBpedia, two large-scale
knowledge graphs (KG). Our hypothesis is that any type relation, i.e., a
specific profession like 'actor' or 'scientist,' can be described by the set of
typical &quot;activities&quot; of people known to have that type relation. For example,
actors are known to star in movies, and scientists are known for their academic
affiliations. In a KG, this information is to be found on a properly defined
subset of the second-degree neighbors of the type relation. This form of local
information can be used as part of a learning algorithm to predict relevance
scores for new, unseen triples. When scoring 'profession' and 'nationality'
triples our experiments based on this approach result in an accuracy equal to
73% and 78%, respectively. These performance metrics are roughly equivalent or
only slightly below the state of the art prior to the present contest. This
suggests that our approach can be effective for evaluating facts, despite the
skewness in the number of facts per individual mined from KGs.
</dc:description>
 <dc:description>Comment: Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08675</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boundary-sensitive Network for Portrait Segmentation</dc:title>
 <dc:creator>Du, Xianzhi</dc:creator>
 <dc:creator>Davis, Larry</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Compared to the general semantic segmentation problem, portrait segmentation
has higher precision requirement on boundary area. However, this problem has
not been well studied in previous works. In this paper, we propose a
boundary-sensitive deep neural network (BSN) for portrait segmentation. BSN
introduces three novel techniques. First, an individual boundary-sensitive
kernel is proposed by dilating the contour line and assigning the boundary
pixels with multi-class labels. Second, a global boundary-sensitive kernel is
employed as a position sensitive prior to further constrain the overall shape
of the segmentation map. Third, we train a boundary-sensitive attribute
classifier jointly with the segmentation network to reinforce the network with
semantic boundary shape information. We have evaluated BSN on the current
largest public portrait segmentation dataset,~\ie, the PFCN dataset, as well as
the portrait images collected from other three popular image segmentation
datasets: COCO, COCO-Stuff, and PASCAL VOC. Our method achieves the superior
quantitative and qualitative performance over state-of-the-arts on all the
datasets, especially on the boundary area.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08685</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Node Similarity by Sampling Streaming Bipartite Graphs</dc:title>
 <dc:creator>Ahmed, Nesreen K.</dc:creator>
 <dc:creator>Duffield, Nick</dc:creator>
 <dc:creator>Xia, Liangzhen</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Bipartite graph data increasingly occurs as a stream of edges that represent
transactions, e.g., purchases by retail customers. Applications such as
recommender systems employ neighborhood-based measures of node similarity, such
as the pairwise number of common neighbors (CN) and related metrics. While the
number of node pairs that share neighbors is potentially enormous, in real-word
graphs only a relatively small proportion of all pairs have a large number of
common neighbors. This motivates finding a weighted sampling approach that
preferentially samples such node pairs.
  This paper presents a new sampling algorithm that provides a fixed size
unbiased estimate of the similarity (or projected) graph on a bipartite edge
stream. The algorithm has two components. First, it maintains a reservoir of
sampled bipartite edges with sampling weights that favor selection of high
similarity nodes. Second, arriving edges generate a stream of similarity
updates based on their adjacency with the current sample. These updates are
aggregated in a second reservoir sample-based stream aggregator to yield the
final unbiased estimate. Experiments on real world graphs show that a 10%
sample ar each stages yields estimates of high similarity edges with weighted
relative errors of about 10^{-2}
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08689</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study of Iterative Detection and Decoding for Large-Scale MIMO Systems
  with 1-Bit ADCs</dc:title>
 <dc:creator>Shao, Z.</dc:creator>
 <dc:creator>Landau, L.</dc:creator>
 <dc:creator>de Lamare, R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present a novel iterative detection and decoding scheme for the uplink of
large-scale multiuser multiple-antenna systems. In order to reduce the
receiver's energy consumption and computational complexity, 1-bit
analog-to-digital converters are used in the front-end. The performance loss
due to the 1-bit quantization can be mitigated by using large-scale antenna
arrays. We propose a linear low-resolution-aware minimum mean square error
detector for soft multiuser interference mitigation. Moreover, short block
length low-density parity-check codes are considered for avoiding high latency.
In the channel decoder, a quasi-uniform quantizer with scaling factors is
devised to lower the error floor of LDPC codes. Simulations show good
performance of the system in terms of bit error rate as compared to prior work.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08690</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aerial Spectral Super-Resolution using Conditional Adversarial Networks</dc:title>
 <dc:creator>Rangnekar, Aneesh</dc:creator>
 <dc:creator>Mokashi, Nilay</dc:creator>
 <dc:creator>Ientilucci, Emmett</dc:creator>
 <dc:creator>Kanan, Christopher</dc:creator>
 <dc:creator>Hoffman, Matthew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Inferring spectral signatures from ground based natural images has acquired a
lot of interest in applied deep learning. In contrast to the spectra of ground
based images, aerial spectral images have low spatial resolution and suffer
from higher noise interference. In this paper, we train a conditional
adversarial network to learn an inverse mapping from a trichromatic space to 31
spectral bands within 400 to 700 nm. The network is trained on AeroCampus, a
first of its kind aerial hyperspectral dataset. AeroCampus consists of high
spatial resolution color images and low spatial resolution hyperspectral images
(HSI). Color images synthesized from 31 spectral bands are used to train our
network. With a baseline root mean square error of 2.48 on the synthesized RGB
test data, we show that it is possible to generate spectral signatures in
aerial imagery.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08697</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable Counting for Visual Question Answering</dc:title>
 <dc:creator>Trott, Alexander</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Questions that require counting a variety of objects in images remain a major
challenge in visual question answering (VQA). The most common approaches to VQA
involve either classifying answers based on fixed length representations of
both the image and question or summing fractional counts estimated from each
section of the image. In contrast, we treat counting as a sequential decision
process and force our model to make discrete choices of what to count.
Specifically, the model sequentially selects from detected objects and learns
interactions between objects that influence subsequent selections. A
distinction of our approach is its intuitive and interpretable output, as
discrete counts are automatically grounded in the image. Furthermore, our
method outperforms the state of the art architecture for VQA on multiple
metrics that evaluate counting.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08702</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Universality of Memcomputing Machines</dc:title>
 <dc:creator>Pei, Yan Ru</dc:creator>
 <dc:creator>Traversa, Fabio L.</dc:creator>
 <dc:creator>Di Ventra, Massimiliano</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Universal memcomputing machines (UMMs) [IEEE Trans. Neural Netw. Learn. Syst.
26, 2702 (2015)] represent a novel computational model in which memory (time
non-locality) accomplishes both tasks of storing and processing of information.
UMMs have been shown to be Turing-complete, namely they can simulate any Turing
machine. In this paper, using set theory and cardinality arguments, we compare
them with liquid-state machines (or &quot;reservoir computing&quot;) and quantum machines
(&quot;quantum computing&quot;). We show that UMMs can simulate both types of machines,
hence they are both &quot;liquid-&quot; or &quot;reservoir-complete&quot; and &quot;quantum-complete&quot;.
Of course, these statements pertain only to the type of problems these machines
can solve, and not to the amount of resources required for such simulations.
Nonetheless, the method presented here provides a general framework in which to
describe the relation between UMMs and any other type of computational model.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08707</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Freebase-triples: A Methodology for Processing the Freebase Data Dumps</dc:title>
 <dc:creator>Chah, Niel</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The Freebase knowledge base was a significant Semantic Web and linked data
technology during its years of operations since 2007. Following its acquisition
by Google in 2010 and its shutdown in 2016, Freebase data is contained in a
data dump of billions of RDF triples. In this research, an exploration of the
Freebase data dumps will show best practices in understanding and using the
Freebase data and also present a general methodology for parsing the linked
data. The analysis is done with limited computing resources and the use of
open-source Unix-like tools. The results showcase the efficiency of the
technique and highlight redundancies in the data, with the possibility of
restructuring nearly 60% of the original data. As an archival dataset that has
not changed since 2015, Freebase's semantic structured data has applications in
other prominent fields, such as information retrieval (IR) and knowledge-based
question answering (KBQA). Freebase can also serve as a gateway to other
structured datasets, such as DBpedia, Wikidata, and YAGO.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08708</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Autoencoders for Learning Latent Representations of Speech
  Emotion</dc:title>
 <dc:creator>Latif, Siddique</dc:creator>
 <dc:creator>Rana, Rajib</dc:creator>
 <dc:creator>Qadir, Junaid</dc:creator>
 <dc:creator>Epps, Julien</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Latent representation of data in unsupervised fashion is a very interesting
process. It provides more relevant features that can enhance the performance of
a classifier. For speech emotion recognition tasks generating effective
features is very crucial. Recently, deep generative models such as Variational
Autoencoders (VAEs) have gained enormous success to model natural images. Being
inspired by that in this paper, we use VAE for the modeling of emotions in
human speech. We derive the latent representation of speech signal and use this
for classification of emotions. We demonstrate that features learned by VAEs
can achieve state-of-the-art emotion recognition results.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08709</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distance Labelings on Random Power Law Graphs</dc:title>
 <dc:creator>Yu, Huacheng</dc:creator>
 <dc:creator>Zhang, Hongyang</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A {\it Distance Labeling} scheme is a data structure that can answer shortest
path queries on a graph. Experiment results from several recent studies (Akiba
et al.'13, Delling et al.'14) found very efficient and very accurate labeling
schemes, which scale to social and information networks with tens of millions
of vertices and edges. Such a finding is not expected in the worst case, since
even for graphs with maximum degree $3$, it is known that any distance labeling
requires $\Omega{(n^{3/2})}$ space (Gavoille et al.'03). On the other hand,
social and information networks have a heavy-tailed degree distribution and
small average distance, which are not captured in the worst case.
  In this paper, we fill in the gap between empirical and worst case results.
We consider distance labeling schemes on random graph models with a power law
degree distribution. For such graphs, we show that simple breadth-first-search
based algorithm can find near optimal labeling schemes. The intuition behind
our proof reveals that the distances between different pairs of vertices are
almost independent, even for polynomially many pairs.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08712</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persistence of the Jordan center in Random Growing Trees</dc:title>
 <dc:creator>Pattathil, Sarath</dc:creator>
 <dc:creator>Karamchandani, Nikhil</dc:creator>
 <dc:creator>Shah, Dhruti</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The Jordan center of a graph is defined as a vertex whose maximum distance to
other nodes in the graph is minimal, and it finds applications in facility
location and source detection problems. We study properties of the Jordan
Center in the case of random growing trees. In particular, we consider a
regular tree graph on which an infection starts from a root node and then
spreads along the edges of the graph according to various random spread models.
For the Independent Cascade (IC) model and the discrete Susceptible Infected
(SI) model, both of which are discrete time models, we show that as the
infected subgraph grows with time, the Jordan center persists on a single
vertex after a finite number of timesteps. Finally, we also study the
continuous time version of the SI model and bound the maximum distance between
the Jordan center and the root node at any time.
</dc:description>
 <dc:description>Comment: 28 pages, 14 figures</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08713</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query-limited Black-box Attacks to Classifiers</dc:title>
 <dc:creator>Suya, Fnu</dc:creator>
 <dc:creator>Tian, Yuan</dc:creator>
 <dc:creator>Evans, David</dc:creator>
 <dc:creator>Papotti, Paolo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study black-box attacks on machine learning classifiers where each query
to the model incurs some cost or risk of detection to the adversary. We focus
explicitly on minimizing the number of queries as a major objective.
Specifically, we consider the problem of attacking machine learning classifiers
subject to a budget of feature modification cost while minimizing the number of
queries, where each query returns only a class and confidence score. We
describe an approach that uses Bayesian optimization to minimize the number of
queries, and find that the number of queries can be reduced to approximately
one tenth of the number needed through a random strategy for scenarios where
the feature modification cost budget is low.
</dc:description>
 <dc:description>Comment: 5 Pages, 2017 NIPS workshop on machine learning and computer security
  (12/08/2017-12/09/2017)</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08714</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Structured Analysis of Broadcast Badminton Videos</dc:title>
 <dc:creator>Ghosh, Anurag</dc:creator>
 <dc:creator>Singh, Suriya</dc:creator>
 <dc:creator>Jawahar, C. V.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Sports video data is recorded for nearly every major tournament but remains
archived and inaccessible to large scale data mining and analytics. It can only
be viewed sequentially or manually tagged with higher-level labels which is
time consuming and prone to errors. In this work, we propose an end-to-end
framework for automatic attributes tagging and analysis of sport videos. We use
commonly available broadcast videos of matches and, unlike previous approaches,
does not rely on special camera setups or additional sensors.
  Our focus is on Badminton as the sport of interest. We propose a method to
analyze a large corpus of badminton broadcast videos by segmenting the points
played, tracking and recognizing the players in each point and annotating their
respective badminton strokes. We evaluate the performance on 10 Olympic matches
with 20 players and achieved 95.44% point segmentation accuracy, 97.38% player
detection score (mAP@0.5), 97.98% player identification accuracy, and stroke
segmentation edit scores of 80.48%. We further show that the automatically
annotated videos alone could enable the gameplay analysis and inference by
computing understandable metrics such as player's reaction time, speed, and
footwork around the court, etc.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08716</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Parable of the Fruit Sellers Or, A Game of Random Variables</dc:title>
 <dc:creator>Hulko, Artem</dc:creator>
 <dc:creator>Whitmeyer, Mark</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:description>  This paper analyzes a simple game with $n$ players. We fix a mean in the
interval $[0, 1]$ and let each player choose any random variable distributed on
that interval with the given mean. The winner of the zero-sum game is the
player whose random variable has the highest realization. We show that the
position of the mean within the interval is paramount. Remarkably, if the given
mean is above a crucial threshold then the unique equilibrium must contain a
point mass on $1$. The cutoff is strictly decreasing in the number of players,
$n$; and for fixed $\mu$, as the number of players is increased, each player
places more weight on $1$ at equilibrium. We characterize the equilibrium as
the number of players goes to infinity.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08720</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiaccess Communication via a Broadcast Approach Adapted to the
  Multiuser Channel</dc:title>
 <dc:creator>Kazemi, Samia</dc:creator>
 <dc:creator>Tajer, Ali</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A broadcast strategy for multiple access communication over slowly fading
channels is introduced, in which the channel state information is known to only
the receiver. In this strategy, the transmitters split their information
streams into multiple independent information streams, each adapted to a
specific actual channel realization. The major distinction between the proposed
strategy and the existing ones is that in the existing approaches, each
transmitter adapts its transmission strategy only to the fading process of its
direct channel to the receiver, hence directly adopting a single-user strategy
previously designed for the single-user channels. However, the contribution of
each user to a network-wide measure (e.g., sum-rate capacity) depends not only
on the user's direct channel to the receiver, but also on the qualities of
other channels. Driven by this premise, this paper proposes an alternative
broadcast strategy in which the transmitters adapt their transmissions to the
combined states resulting from all users' channels. This leads to generating a
larger number of information streams by each transmitter and adopting a
different decoding strategy by the receiver. An achievable rate region and an
outer bound that capture the trade-off among the rates of different information
layers are established, and it is shown that the achievable rate region
subsumes the existing known capacity regions obtained based on adapting the
broadcast approach to the single-user channels.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08721</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding the Submodularity Hidden in Symmetric Difference</dc:title>
 <dc:creator>Nakashima, Junpei</dc:creator>
 <dc:creator>Yamauchi, Yukiko</dc:creator>
 <dc:creator>Kijima, Shuji</dc:creator>
 <dc:creator>Yamashita, Masafumi</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A fundamental property of convex functions in continuous space is that the
convexity is preserved under affine transformations. A set function $f$ on a
finite set $V$ is {\em submodular} if $f(X) + f(Y) \geq f(X \cup Y) - f(X \cap
Y)$ for any pair $X, Y \subseteq V$. The {\em symmetric difference
transformation} ({\em SD-transformation}) of $f$ by a {\em canonical set} $S
\subseteq V$ is a set function $g$ given by $g(X) = f(X \vartriangle S)$ for $X
\subseteq V$, where $X \vartriangle S = (X \setminus S) \cup (S \setminus X)$
is the {\it symmetric difference} between $X$ and $S$. Despite that submodular
functions and SD-transformations are regarded as counterparts of convex
functions and affine transformations in finite discrete space, not all
SD-transformations do not preserve the submodularity. Starting with a
characterization of SD-stransformations that preserve the submodularity, this
paper investigates the problem of discovering a canonical set $S$, given the
SD-transformation $g$ of a submodular function $f$ by $S$, provided that $g(X)$
is given by an oracle. A submodular function $f$ on $V$ is said to be {\it
strict} if $f(X) + f(Y) &gt; f(X \cup Y) - f(X \cap Y)$ holds whenever both $X
\setminus Y$ and $Y \setminus X$ are nonempty. We show that the problem is
solvable by using ${\rm O}(|V|)$ oracle calls when $f$ is strictly submodular,
although it requires exponentially many oracle calls in general.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08726</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denoising of 3D magnetic resonance images with multi-channel residual
  learning of convolutional neural network</dc:title>
 <dc:creator>Jiang, Dongsheng</dc:creator>
 <dc:creator>Dou, Weiqiang</dc:creator>
 <dc:creator>Vosters, Luc</dc:creator>
 <dc:creator>Xu, Xiayu</dc:creator>
 <dc:creator>Sun, Yue</dc:creator>
 <dc:creator>Tan, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The denoising of magnetic resonance (MR) images is a task of great importance
for improving the acquired image quality. Many methods have been proposed in
the literature to retrieve noise free images with good performances. Howerever,
the state-of-the-art denoising methods, all needs a time-consuming optimization
processes and their performance strongly depend on the estimated noise level
parameter. Within this manuscript we propose the idea of denoising MRI Rician
noise using a convolutional neural network. The advantage of the proposed
methodology is that the learning based model can be directly used in the
denosing process without optimization and even without the noise level
parameter. Specifically, a ten convolutional layers neural network combined
with residual learning and multi-channel strategy was proposed. Two training
ways: training on a specific noise level and training on a general level were
conducted to demonstrate the capability of our methods. Experimental results
over synthetic and real 3D MR data demonstrate our proposed network can achieve
superior performance compared with other methods in term of both of the peak
signal to noise ratio and the global of structure similarity index. Without
noise level parameter, our general noise-applicable model is also better than
the other compared methods in two datasets. Furthermore, our training model
shows good general applicability.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08730</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Weakly and Webly Supervised Learning for Classifying Food
  Images</dc:title>
 <dc:creator>Kaur, Parneet</dc:creator>
 <dc:creator>Sikka, Karan</dc:creator>
 <dc:creator>Divakaran, Ajay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Food classification from images is a fine-grained classification problem.
Manual curation of food images is cost, time and scalability prohibitive. On
the other hand, web data is available freely but contains noise. In this paper,
we address the problem of classifying food images with minimal data curation.
We also tackle a key problems with food images from the web where they often
have multiple cooccuring food types but are weakly labeled with a single label.
We first demonstrate that by sequentially adding a few manually curated samples
to a larger uncurated dataset from two web sources, the top-1 classification
accuracy increases from 50.3% to 72.8%. To tackle the issue of weak labels, we
augment the deep model with Weakly Supervised learning (WSL) that results in an
increase in performance to 76.2%. Finally, we show some qualitative results to
provide insights into the performance improvements using the proposed ideas.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08734</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Forecasting Matrix Factorization</dc:title>
 <dc:creator>Gultekin, San</dc:creator>
 <dc:creator>Paisley, John</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper the problem of forecasting high dimensional time series is
considered. Such time series can be modeled as matrices where each column
denotes a measurement. In addition, when missing values are present, low rank
matrix factorization approaches are suitable for predicting future values. This
paper formally defines and analyzes the forecasting problem in the online
setting, i.e. where the data arrives as a stream and only a single pass is
allowed. We present and analyze novel matrix factorization techniques which can
learn low-dimensional embeddings effectively in an online manner. Based on
these embeddings a recursive minimum mean square error estimator is derived,
which learns an autoregressive model on them. Experiments with two real
datasets with tens of millions of measurements show the benefits of the
proposed approach.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08735</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantized Precoding for Multi-Antenna Downlink Channels with MAGIQ</dc:title>
 <dc:creator>Nedelcu, Andrei</dc:creator>
 <dc:creator>Steiner, Fabian</dc:creator>
 <dc:creator>Staudacher, Markus</dc:creator>
 <dc:creator>Kramer, Gerhard</dc:creator>
 <dc:creator>Zirwas, Wolfgang</dc:creator>
 <dc:creator>Ganesan, Rakash Sivasiva</dc:creator>
 <dc:creator>Baracca, Paolo</dc:creator>
 <dc:creator>Wesemann, Stefan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A multi-antenna, greedy, iterative, and quantized (MAGIQ) precoding algorithm
is proposed for downlink channels. MAGIQ allows a straightforward integration
with orthogonal frequency-division multiplexing (OFDM). MAGIQ is compared to
three existing algorithms in terms of information rates and complexity:
quantized linear precoding (QLP), SQUID, and an ADMM-based algorithm. The
information rate is measured by using a lower bound for finite modulation sets,
and the complexity is measured by the number of multiplications and
comparisons. MAGIQ and ADMM achieve similar information rates with similar
complexity for Rayleigh flat-fading channels and one-bit quantization per real
dimension, and they outperform QLP and SQUID for higher order modulation.
</dc:description>
 <dc:description>Comment: extended abstract</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08738</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Protecting Real-Time GPU Applications on Integrated CPU-GPU SoC
  Platforms</dc:title>
 <dc:creator>Ali, Waqar</dc:creator>
 <dc:creator>Yun, Heechul</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Integrated CPU-GPU architecture provides excellent acceleration capabilities
for data parallel applications on embedded platforms while meeting the size,
weight and power (SWaP) requirements. However, sharing of main memory between
CPU applications and GPU kernels can severely affect the execution of GPU
kernels and diminish the performance gain provided by GPU. For example, in the
NVIDIA Tegra K1 platform which has the integrated CPU-GPU architecture, we
noticed that in the worst case scenario, the GPU kernels can suffer as much as
4X slowdown in the presence of co-running memory intensive CPU applications
compared to their solo execution. In this paper, we propose a software
mechanism, which we call BWLOCK++, to protect the performance of GPU kernels
from co-scheduled memory intensive CPU applications.
</dc:description>
 <dc:description>Comment: 10 Pages, 9 Figures</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08745</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene-Specific Pedestrian Detection Based on Parallel Vision</dc:title>
 <dc:creator>Zhang, Wenwen</dc:creator>
 <dc:creator>Wang, Kunfeng</dc:creator>
 <dc:creator>Qu, Hua</dc:creator>
 <dc:creator>Zhao, Jihong</dc:creator>
 <dc:creator>Wang, Fei-Yue</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As a special type of object detection, pedestrian detection in generic scenes
has made a significant progress trained with large amounts of labeled training
data manually. While the models trained with generic dataset work bad when they
are directly used in specific scenes. With special viewpoints, flow light and
backgrounds, datasets from specific scenes are much different from the datasets
from generic scenes. In order to make the generic scene pedestrian detectors
work well in specific scenes, the labeled data from specific scenes are needed
to adapt the models to the specific scenes. While labeling the data manually
spends much time and money, especially for specific scenes, each time with a
new specific scene, large amounts of images must be labeled. What's more, the
labeling information is not so accurate in the pixels manually and different
people make different labeling information. In this paper, we propose an
ACP-based method, with augmented reality's help, we build the virtual world of
specific scenes, and make people walking in the virtual scenes where it is
possible for them to appear to solve this problem of lacking labeled data and
the results show that data from virtual world is helpful to adapt generic
pedestrian detectors to specific scenes.
</dc:description>
 <dc:description>Comment: To be published in IEEE ITSC 2017</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08747</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Electric vehicle charging: a queueing approach</dc:title>
 <dc:creator>Aveklouris, Angelos</dc:creator>
 <dc:creator>Nakahira, Yorie</dc:creator>
 <dc:creator>Vlasiou, Maria</dc:creator>
 <dc:creator>Zwart, Bert</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The number of electric vehicles (EVs) is expected to increase. As a
consequence, more EVs will need charging, potentially causing not only
congestion at charging stations, but also in the distribution grid. Our goal is
to illustrate how this gives rise to resource allocation and performance
problems that are of interest to the Sigmetrics community.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08747</dc:identifier>
 <dc:identifier>ACM SIGMETRICS Performance Evaluation Review, Vol. 45, No. 2,
  September 2017, Pages 33-35</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08749</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cartesian trees and Lyndon trees</dc:title>
 <dc:creator>Crochemore, Maxime</dc:creator>
 <dc:creator>Russo, Luis M. S.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The article describes the structural and algorithmic relations between
Cartesian trees and Lyndon Trees. This leads to a uniform presentation of the
Lyndon table of a word corresponding to the Next Nearest Smaller table of a
sequence of numbers. It shows how to efficiently compute runs, that is, maximal
periodicities occurring in a word.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08753</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Presburger-Definable Parameterized Typestates</dc:title>
 <dc:creator>Mishra, Ashish</dc:creator>
 <dc:creator>Dsouza, Deepak</dc:creator>
 <dc:creator>Srikant, Y. N.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Typestates are good at capturing dynamic states of a program as compared to
normal types that can capture static structural properties of data and program.
Although useful, typestates are suitable only for specifying and verifying
program properties defined using finite-state abstractions. Many useful dynamic
properties of programs are not finite-state definable. To address these issues,
we introduce parameterized typestates (p-typestates). p-typestates associate a
logical property with each state of regular typestate, thereby allowing
specification of properties beyond finite-state abstractions. We present a
dependent type system to express and verify p-typestate properties and a
typestate-oriented core programming language incorporating these dependent
types. Automatic inductive type-checking of p-typestate properties usually
requires a programmer to provide loop invariants as annotations. Here we
propose a way to calculate loop invariants automatically, using loop
acceleration techniques for Presburger definable transition systems.
\keywords{Programming Languages, Typestates, Dependent Types, Non-Regular
Program Properties, Verification, Loop Invariants}
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08764</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Properties of the Compound Nodal Admittance Matrix of Polyphase
  Power Systems</dc:title>
 <dc:creator>Kettner, Andreas Martin</dc:creator>
 <dc:creator>Paolone, Mario</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Most techniques for power system analysis model the grid by exact electrical
circuits. For instance, in power flow study, state estimation, and voltage
stability assessment, the use of admittance parameters (i.e., the nodal
admittance matrix) and hybrid parameters is common. Moreover, network reduction
techniques (e.g., Kron reduction) are often applied to decrease the size of
large grid models (i.e., with hundreds or thousands of state variables),
thereby alleviating the computational burden. However, researchers normally
disregard the fact that the applicability of these methods is not generally
guaranteed. In reality, the nodal admittance must satisfy certain properties in
order for hybrid parameters to exist and Kron reduction to be feasible.
Recently, this problem was solved for the particular cases of monophase and
balanced triphase grids. This paper investigates the general case of unbalanced
polyphase grids. Firstly, conditions determining the rank of the so-called
compound nodal admittance matrix and its diagonal subblocks are deduced from
the characteristics of the electrical components and the network graph.
Secondly, the implications of these findings concerning the feasibility of Kron
reduction and the existence of hybrid parameters are discussed. In this regard,
this paper provides a rigorous theoretical foundation for various applications
in power system analysis.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08767</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complete MDP convolutional codes</dc:title>
 <dc:creator>Lieb, Julia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Maximum distance profile (MDP) convolutional codes have the property that
their column distances are as large as possible. It has been shown that,
transmitting over an erasure channel, these codes have optimal recovery rate
for windows of a certain length. Reverse MDP convolutional codes have the
additional advantage that they are suitable for forward and backward decoding
algorithms. Beyond that the subclass of complete MDP convolutional codes has
the ability to reduce the waiting time during decoding. The first main result
of this paper is to show the existence and genericity of complete MDP
convolutional codes for all code parameters. The second main contribution is
the presentation of two concrete construction techniques to obtain complete MDP
convolutional codes. These constructions work for all code parameters but
require that the size of the underlying base field is (sufficiently) large.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08768</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning-Based Computation Offloading for IoT Devices with Energy
  Harvesting</dc:title>
 <dc:creator>Min, Minghui</dc:creator>
 <dc:creator>Xu, Dongjin</dc:creator>
 <dc:creator>Xiao, Liang</dc:creator>
 <dc:creator>Tang, Yuliang</dc:creator>
 <dc:creator>Wu, Di</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Internet of Things (IoT) devices can apply mobile-edge computing (MEC) and
energy harvesting (EH) to provide the satisfactory quality of experiences for
computation intensive applications and prolong the battery lifetime. In this
article, we investigate the computation offloading for IoT devices with energy
harvesting in wireless networks with multiple MEC devices such as base stations
and access points, each with different computation resource and radio
communication capability. We propose a reinforcement learning based computation
offloading framework for an IoT device to choose the MEC device and determine
the offloading rate according to the current battery level, the previous radio
bandwidth to each MEC device and the predicted amount of the harvested energy.
A &quot;hotbooting&quot; Q-learning based computation offloading scheme is proposed for
an IoT device to achieve the optimal offloading performance without being aware
of the MEC model, the energy consumption and computation latency model. We also
propose a fast deep Q-network (DQN) based offloading scheme, which combines the
deep learning and hotbooting techniques to accelerate the learning speed of
Q-learning. We show that the proposed schemes can achieve the optimal
offloading policy after sufficiently long learning time and provide their
performance bounds under two typical MEC scenarios. Simulations are performed
for IoT devices that use wireless power transfer to capture the ambient
radio-frequency signals to charge the IoT batteries. Simulation results show
that the fast DQN-based offloading scheme reduces the energy consumption,
decreases the computation delay and the task drop ratio, and increases the
utility of the IoT device in dynamic MEC, compared with the benchmark
Q-learning based offloading.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08773</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Approximate Bayesian Long Short-Term Memory Algorithm for Outlier
  Detection</dc:title>
 <dc:creator>Chen, Chao</dc:creator>
 <dc:creator>Lin, Xiao</dc:creator>
 <dc:creator>Terejanu, Gabriel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Long Short-Term Memory networks trained with gradient descent and
back-propagation have received great success in various applications. However,
point estimation of the weights of the networks is prone to over-fitting
problems and lacks important uncertainty information associated with the
estimation. However, exact Bayesian neural network methods are intractable and
non-applicable for real-world applications. In this study, we propose an
approximate estimation of the weights uncertainty using Ensemble Kalman Filter,
which is easily scalable to a large number of weights. Furthermore, we optimize
the covariance of the noise distribution in the ensemble update step using
maximum likelihood estimation. To assess the proposed algorithm, we apply it to
outlier detection in five real-world events retrieved from the Twitter
platform.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08776</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Texture Object Segmentation Based on Affine Invariant Texture Detection</dc:title>
 <dc:creator>Zhang, Jianwei</dc:creator>
 <dc:creator>Chen, Xu</dc:creator>
 <dc:creator>Xiao, Xuezhong</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To solve the issue of segmenting rich texture images, a novel detection
methods based on the affine invariable principle is proposed. Considering the
similarity between the texture areas, we first take the affine transform to get
numerous shapes, and utilize the KLT algorithm to verify the similarity. The
transforms include rotation, proportional transformation and perspective
deformation to cope with a variety of situations. Then we propose an improved
LBP method combining canny edge detection to handle the boundary in the
segmentation process. Moreover, human-computer interaction of this method which
helps splitting the matched texture area from the original images is
user-friendly.
</dc:description>
 <dc:description>Comment: 6pages, 15 figures</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08784</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Geometry Modeling and Analysis of Single- and Multi-Cluster
  Wireless Networks</dc:title>
 <dc:creator>Azimi-Abarghouyi, Seyed Mohammad</dc:creator>
 <dc:creator>Makki, Behrooz</dc:creator>
 <dc:creator>Haenggi, Martin</dc:creator>
 <dc:creator>Nasiri-Kenari, Masoumeh</dc:creator>
 <dc:creator>Svensson, Tommy</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper develops a stochastic geometry-based approach for the modeling and
analysis of single- and multi-cluster wireless networks. We first define finite
homogeneous Poisson point processes to model the number and locations of the
transmitters in a confined region as a single-cluster wireless network. We
study the coverage probability for a reference receiver for two strategies;
closest-selection, where the receiver is served by the closest transmitter
among all transmitters, and uniform-selection, where the serving transmitter is
selected randomly with uniform distribution. Second, using Matern cluster
processes, we extend our model and analysis to multi-cluster wireless networks.
Here, the receivers are modeled in two types, namely, closed- and open-access.
Closed-access receivers are distributed around the cluster centers of the
transmitters according to a symmetric normal distribution and can be served
only by the transmitters of their corresponding clusters. Open-access
receivers, on the other hand, are placed independently of the transmitters and
can be served by all transmitters. In all cases, the link distance distribution
and the Laplace transform (LT) of the interference are derived. We also derive
closed-form lower bounds on the LT of the interference for single-cluster
wireless networks. The impact of different parameters on the performance is
also investigated.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08784</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08793</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are words easier to learn from infant- than adult-directed speech? A
  quantitative corpus-based investigation</dc:title>
 <dc:creator>Guevara-Rukoz, Adriana</dc:creator>
 <dc:creator>Cristia, Alejandrina</dc:creator>
 <dc:creator>Ludusan, Bogdan</dc:creator>
 <dc:creator>Thiolli&#xe8;re, Roland</dc:creator>
 <dc:creator>Martin, Andrew</dc:creator>
 <dc:creator>Mazuka, Reiko</dc:creator>
 <dc:creator>Dupoux, Emmanuel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We investigate whether infant-directed speech (IDS) could facilitate word
form learning when compared to adult-directed speech (ADS). To study this, we
examine the distribution of word forms at two levels, acoustic and
phonological, using a large database of spontaneous speech in Japanese. At the
acoustic level we show that, as has been documented before for phonemes, the
realizations of words are more variable and less discriminable in IDS than in
ADS. At the phonological level, we find an effect in the opposite direction:
the IDS lexicon contains more distinctive words (such as onomatopoeias) than
the ADS counterpart. Combining the acoustic and phonological metrics together
in a global discriminability score reveals that the bigger separation of
lexical categories in the phonological space does not compensate for the
opposite effect observed at the acoustic level. As a result, IDS word forms are
still globally less discriminable than ADS word forms, even though the effect
is numerically small. We discuss the implication of these findings for the view
that the functional role of IDS is to improve language learnability.
</dc:description>
 <dc:description>Comment: Draft</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08800</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-Rank Approach to Off-The-Grid Sparse Deconvolution</dc:title>
 <dc:creator>Catala, Paul</dc:creator>
 <dc:creator>Duval, Vincent</dc:creator>
 <dc:creator>Peyr&#xe9;, Gabriel</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We propose a new solver for the sparse spikes deconvolution problem over the
space of Radon measures. A common approach to off-the-grid deconvolution
considers semidefinite (SDP) relaxations of the total variation (the total mass
of the absolute value of the measure) minimization problem. The direct
resolution of this SDP is however intractable for large scale settings, since
the problem size grows as $f_c^{2d}$ where $f_c$ is the cutoff frequency of the
filter and $d$ the ambient dimension. Our first contribution introduces a
penalized formulation of this semidefinite lifting, which has low-rank
solutions. Our second contribution is a conditional gradient optimization
scheme with non-convex updates. This algorithm leverages both the low-rank and
the convolutive structure of the problem, resulting in an $O(f_c^d \log f_c)$
complexity per iteration. Numerical simulations are promising and show that the
algorithm converges in exactly $r$ steps, $r$ being the number of Diracs
composing the solution.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08800</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/904/1/012015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08807</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LEPA: Incentivizing Long-term Privacy-preserving Data Aggregation in
  Crowdsensing</dc:title>
 <dc:creator>Zhang, Zhikun</dc:creator>
 <dc:creator>He, Shibo</dc:creator>
 <dc:creator>Zhang, Mengyuan</dc:creator>
 <dc:creator>Chen, Jiming</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper, we study the incentive mechanism design for real-time data
aggregation, which holds a large spectrum of crowdsensing applications. Despite
extensive studies on static incentive mechanisms, none of these are applicable
to real-time data aggregation due to their incapability of maintaining PUs'
long-term participation. We emphasize that, to maintain PUs' long-term
participation, it is of significant importance to protect their privacy as well
as to provide them a desirable cumulative compensation. Thus motivated, in this
paper, we propose LEPA, an efficient incentive mechanism to stimulate long-term
participation in real-time data aggregation. Specifically, we allow PUs to
preserve their privacy by reporting noisy data, the impact of which on the
aggregation accuracy is quantified with proper privacy and accuracy measures.
Then, we provide a framework that jointly optimizes the incentive schemes in
different time slots to ensure desirable cumulative compensation for PUs and
thereby prevent PUs from leaving the system halfway. Considering PUs' strategic
behaviors and combinatorial nature of the sensing tasks, we propose a
computationally efficient on-line auction with close-to-optimal performance in
presence of NP-hardness of winner user selection. We further show that the
proposed on-line auction satisfies desirable properties of truthfulness and
individual rationality. The performance of LEPA is validated by both
theoretical analysis and extensive simulations.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08809</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The tractability frontier of well-designed SPARQL queries</dc:title>
 <dc:creator>Romero, Miguel</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:description>  We study the complexity of query evaluation of SPARQL queries. We focus on
the fundamental fragment of well-designed SPARQL restricted to the AND,
OPTIONAL and UNION operators. Our main result is a structural characterisation
of the classes of well-designed queries that can be evaluated in polynomial
time. In particular, we introduce a new notion of width called domination
width, which relies on the well-known notion of treewidth. We show that, under
some complexity theoretic assumptions, the classes of well-designed queries
that can be evaluated in polynomial time are precisely those of bounded
domination width.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08818</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Motifs for Device-to-Device Network Analysis (DNA) in Cellular
  Networks</dc:title>
 <dc:creator>Zeng, Tengchan</dc:creator>
 <dc:creator>Semiariy, Omid</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Thaiz, My T.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Device-to-device (D2D) communication is a promising approach to efficiently
disseminate critical or viral information. Reaping the benefits of D2D-enabled
networks is contingent upon choosing the optimal content dissemination policy
subject to resource and user distribution constraints. In this paper, a novel
D2D network analysis (DNA) framework is proposed to study the impacts of
frequently occurring subgraphs, known as motifs, on D2D network performance and
to determine an effective content dissemination strategy. In the proposed
framework, the distribution of devices in the D2D network is modeled as a
Thomas cluster process (TCP), and two graph structures, the star and chain
motifs, are studied in the communication graph. Based on the stochastic
properties of the TCP, closed-form analytical expressions for the statistical
significance, the outage probability, as well as the average throughput per
device, are derived. Simulation results corroborate the analytical derivations
and show the influence of different system topologies on the occurrence of
motifs and the D2D system throughput. More importantly, the results highlight
that, as the statistical significance of motifs increases, the system
throughput will initially increase, and, then, decrease. Hence, network
operators can obtain statistical significance regions for chain and star motifs
that map to the optimal content dissemination performance. Furthermore, using
the obtained regions and the analytical expressions for statistical
significance, network operators can effectively identify which clusters of
devices can be leveraged for D2D communications while determining the number of
serving devices in each identified cluster.
</dc:description>
 <dc:description>Comment: 30 pages, 9 figures, submitted to IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08819</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Enriching Lexical Semantic Resources with Distributional
  Semantics</dc:title>
 <dc:creator>Biemann, Chris</dc:creator>
 <dc:creator>Faralli, Stefano</dc:creator>
 <dc:creator>Panchenko, Alexander</dc:creator>
 <dc:creator>Ponzetto, Simone Paolo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present an approach to combining distributional semantic representations
induced from text corpora with manually constructed lexical-semantic networks.
While both kinds of semantic resources are available with high lexical
coverage, our aligned resource combines the domain specificity and availability
of contextual information from distributional models with the conciseness and
high quality of manually crafted lexical networks. We start with a
distributional representation of induced senses of vocabulary terms, which are
accompanied with rich context information given by related lexical items. We
then automatically disambiguate such representations to obtain a full-fledged
proto-conceptualization, i.e. a typed graph of induced word senses. In a final
step, this proto-conceptualization is aligned to a lexical ontology, resulting
in a hybrid aligned resource. Moreover, unmapped induced senses are associated
with a semantic type in order to connect them to the core resource. Manual
evaluations against ground-truth judgments for different stages of our method
as well as an extrinsic evaluation on a knowledge-based Word Sense
Disambiguation benchmark all indicate the high quality of the new hybrid
resource. Additionally, we show the benefits of enriching top-down lexical
knowledge resources with bottom-up distributional information from text for
addressing high-end knowledge acquisition tasks such as cleaning hypernym
graphs and learning taxonomies from scratch.
</dc:description>
 <dc:description>Comment: Accepted for publication in the journal of Natural Language
  Engineering, 2018</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08832</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Object Discovery and Detector Adaptation from Unlabeled
  Video</dc:title>
 <dc:creator>O&#x161;ep, Aljo&#x161;a</dc:creator>
 <dc:creator>Voigtlaender, Paul</dc:creator>
 <dc:creator>Luiten, Jonathon</dc:creator>
 <dc:creator>Breuers, Stefan</dc:creator>
 <dc:creator>Leibe, Bastian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We explore object discovery and detector adaptation based on unlabeled video
sequences captured from a mobile platform. We propose a fully automatic
approach for object mining from video which builds upon a generic object
tracking approach. By applying this method to three large video datasets from
autonomous driving and mobile robotics scenarios, we demonstrate its robustness
and generality. Based on the object mining results, we propose a novel approach
for unsupervised object discovery by appearance-based clustering. We show that
this approach successfully discovers interesting objects relevant to driving
scenarios. In addition, we perform self-supervised detector adaptation in order
to improve detection performance on the KITTI dataset for existing categories.
Our approach has direct relevance for enabling large-scale object learning for
autonomous driving.
</dc:description>
 <dc:description>Comment: CVPR'18 submission</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08838</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Texture Synthesis with Recurrent Variational Auto-Encoder</dc:title>
 <dc:creator>Chandra, Rohan</dc:creator>
 <dc:creator>Grover, Sachin</dc:creator>
 <dc:creator>Lee, Kyungjun</dc:creator>
 <dc:creator>Meshry, Moustafa</dc:creator>
 <dc:creator>Taha, Ahmed</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a recurrent variational auto-encoder for texture synthesis. A
novel loss function, FLTBNK, is used for training the texture synthesizer. It
is rotational and partially color invariant loss function. Unlike L2 loss,
FLTBNK explicitly models the correlation of color intensity between pixels. Our
texture synthesizer generates neighboring tiles to expand a sample texture and
is evaluated using various texture patterns from Describable Textures Dataset
(DTD). We perform both quantitative and qualitative experiments with various
loss functions to evaluate the performance of our proposed loss function
(FLTBNK) --- a mini-human subject study is used for the qualitative evaluation.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08841</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Long Short-Term Memory Networks for Sub-Character Representation
  Learning</dc:title>
 <dc:creator>He, Han</dc:creator>
 <dc:creator>Wu, Lei</dc:creator>
 <dc:creator>Yang, Xiaokun</dc:creator>
 <dc:creator>Yan, Hua</dc:creator>
 <dc:creator>Gao, Zhimin</dc:creator>
 <dc:creator>Feng, Yi</dc:creator>
 <dc:creator>Townsend, George</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Characters have commonly been regarded as the minimal processing unit in
Natural Language Processing (NLP). But many non-latin languages have
hieroglyphic writing systems, involving a big alphabet with thousands or
millions of characters. Each character is composed of even smaller parts, which
are often ignored by the previous work. In this paper, we propose a novel
architecture employing two stacked Long Short-Term Memory Networks (LSTMs) to
learn sub-character level representation and capture deeper level of semantic
meanings. To build a concrete study and substantiate the efficiency of our
neural architecture, we take Chinese Word Segmentation as a research case
example. Among those languages, Chinese is a typical case, for which every
character contains several components called radicals. Our networks employ a
shared radical level embedding to solve both Simplified and Traditional Chinese
Word Segmentation, without extra Traditional to Simplified Chinese conversion,
in such a highly end-to-end way the word segmentation can be significantly
simplified compared to the previous work. Radical level embeddings can also
capture deeper semantic meaning below character level and improve the system
performance of learning. By tying radical and character embeddings together,
the parameter count is reduced whereas semantic knowledge is shared and
transferred between two levels, boosting the performance largely. On 3 out of 4
Bakeoff 2005 datasets, our method surpassed state-of-the-art results by up to
0.4%. Our results are reproducible, source codes and corpora are available on
GitHub.
</dc:description>
 <dc:description>Comment: Accepted &amp; forthcoming at ITNG-2018</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08846</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Framework of Channel Estimation for Hybrid Analog-and-Digital Processing
  Enabled Massive MIMO Communications</dc:title>
 <dc:creator>Pan, Leyuan</dc:creator>
 <dc:creator>Liang, Le</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:creator>Dong, Xiaodai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate a general channel estimation problem in the massive
multiple-input multiple-output (MIMO) system which employs the hybrid
analog/digital precoding structure with limited radio-frequency (RF) chains. By
properly designing RF combiners and performing multiple trainings, the proposed
channel estimation can approach the performance of fully-digital estimations
depending on the degree of channel spatial correlation and the number of RF
chains. Dealing with the hybrid channel estimation, the optimal combiner is
theoretically derived by relaxing the constant-magnitude constraint in a
specific single-training scenario, which is then extended to the design of
combiners for multiple trainings by Sequential and Alternating methods.
Further, we develop a technique to generate the phase-only RF combiners based
on the corresponding unconstrained ones to satisfy the constant-magnitude
constraints. The performance of the proposed hybrid channel estimation scheme
is examined by simulations under both nonparametric and spatial channel models.
The simulation results demonstrate that the estimated CSI can approach the
performance of fully-digital estimations in terms of both mean square error and
spectral efficiency. Moreover, a practical spatial channel covariance
estimation method is proposed and its effectiveness in hybrid channel
estimation is verified by simulations.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08849</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-Cost Robust Distributed Linearly Constrained Beamformer for
  Wireless Acoustic Sensor Networks with Arbitrary Topology</dc:title>
 <dc:creator>Koutrouvelis, Andreas I.</dc:creator>
 <dc:creator>Sherson, Thomas W.</dc:creator>
 <dc:creator>Heusdens, Richard</dc:creator>
 <dc:creator>Hendriks, Richard C.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a new robust distributed linearly constrained beamformer (BF)
which utilizes a set of linear equality constraints to reduce the cross power
spectral density matrix to a block-diagonal form. The proposed BF has a
convenient objective function for use in arbitrary distributed network
topologies while having identical performance to a centralized implementation.
Moreover, the new optimization problem is robust to steering vector mismatches
(SVMs) and to voice activity detection errors. Two variants of the proposed BF
are presented and evaluated in the context of multi-microphone speech
enhancement in a wireless acoustic sensor network, and are compared with other
state-of-the-art distributed BFs in terms of communication costs and robustness
to SVMs.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08855</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Regression via Pairwise Similarity Regularization</dc:title>
 <dc:creator>Gress, Aubrey</dc:creator>
 <dc:creator>Davidson, Ian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Transfer learning methods address the situation where little labeled training
data from the &quot;target&quot; problem exists, but much training data from a related
&quot;source&quot; domain is available. However, the overwhelming majority of transfer
learning methods are designed for simple settings where the source and target
predictive functions are almost identical, limiting the applicability of
transfer learning methods to real world data. We propose a novel, weaker,
property of the source domain that can be transferred even when the source and
target predictive functions diverge. Our method assumes the source and target
functions share a Pairwise Similarity property, where if the source function
makes similar predictions on a pair of instances, then so will the target
function. We propose Pairwise Similarity Regularization Transfer, a flexible
graph-based regularization framework which can incorporate this modeling
assumption into standard supervised learning algorithms. We show how users can
encode domain knowledge into our regularizer in the form of spatial continuity,
pairwise &quot;similarity constraints&quot; and how our method can be scaled to large
data sets using the Nystrom approximation. Finally, we present positive and
negative results on real and synthetic data sets and discuss when our Pairwise
Similarity transfer assumption seems to hold in practice.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08858</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Collaborative Conceptual Exploration</dc:title>
 <dc:creator>Hanika, Tom</dc:creator>
 <dc:creator>Zumbr&#xe4;gel, Jens</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03G10 68T27</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  In domains with high knowledge distribution a natural objective is to create
principle foundations for collaborative interactive learning environments. We
present a first mathematical characterization of a collaborative learning
group, a consortium, based on closure systems of attribute sets and the
well-known attribute exploration algorithm from formal concept analysis. To
this end, we introduce (weak) local experts for subdomains of a given knowledge
domain. These entities are able to refute and potentially accept a given
(implicational) query for some closure system that is a restriction of the
whole domain. On this we build up a consortial expert and show first insights
about the ability of such an expert to answer queries. Furthermore, we depict
techniques on how to cope with falsely accepted implications and on combining
counterexamples. Using notions from combinatorial design theory we further
expand those insights as far as providing first results on the decidability
problem if a given consortium is able to explore some target domain.
Applications in conceptual knowledge acquisition as well as in collaborative
interactive ontology learning are at hand.
</dc:description>
 <dc:description>Comment: 15 pages, 1 figure</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08862</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network Multitask Learning for Traffic Flow Forecasting</dc:title>
 <dc:creator>Jin, Feng</dc:creator>
 <dc:creator>Sun, Shiliang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Traditional neural network approaches for traffic flow forecasting are
usually single task learning (STL) models, which do not take advantage of the
information provided by related tasks. In contrast to STL, multitask learning
(MTL) has the potential to improve generalization by transferring information
in training signals of extra tasks. In this paper, MTL based neural networks
are used for traffic flow forecasting. For neural network MTL, a
backpropagation (BP) network is constructed by incorporating traffic flows at
several contiguous time instants into an output layer. Nodes in the output
layer can be seen as outputs of different but closely related STL tasks.
Comprehensive experiments on urban vehicular traffic flow data and comparisons
with STL show that MTL in BP neural networks is a promising and effective
approach for traffic flow forecasting.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08862</dc:identifier>
 <dc:identifier>Proceedings of the International Joint Conference on Neural
  Networks (IJCNN), 2008. pp. 1898-1902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08865</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Biological Systems as Heterogeneous Information Networks: A Mini-review
  and Perspectives</dc:title>
 <dc:creator>Tsuyuzaki, Koki</dc:creator>
 <dc:creator>Nikaido, Itoshi</dc:creator>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In the real world, most objects and data have multiple types of attributes
and inter-connections. Such data structures are named &quot;Heterogeneous
Information Networks&quot; (HIN) and have been widely researched. Biological systems
are also considered to be highly complicated HIN. In this work, we review
various applications of HIN methods to biological and chemical data, discuss
some advanced topics, and describe some future research directions.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, HeteroNAM'18</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08868</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Use of Generative Adversarial Network for Cross-Domain Change Detection</dc:title>
 <dc:creator>Kousuke, Yamaguchi</dc:creator>
 <dc:creator>Kanji, Tanaka</dc:creator>
 <dc:creator>Takuma, Sugimoto</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the problem of cross-domain change detection from a
novel perspective of image-to-image translation. In general, change detection
aims to identify interesting changes between a given query image and a
reference image of the same scene taken at a different time. This problem
becomes a challenging one when query and reference images involve different
domains (e.g., time of the day, weather, and season) due to variations in
object appearance and a limited amount of training examples. In this study, we
address the above issue by leveraging a generative adversarial network (GAN).
Our key concept is to use a limited amount of training data to train a
GAN-based image translator that maps a reference image to a virtual image that
cannot be discriminated from query domain images. This enables us to treat the
cross-domain change detection task as an in-domain image comparison. This
allows us to leverage the large body of literature on in-domain generic change
detectors. In addition, we also consider the use of visual place recognition as
a method for mining more appropriate reference images over the space of virtual
images. Experiments validate efficacy of the proposed approach.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, technical report</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08875</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Rich Drug-Drug Interactions via Biomedical Knowledge Graphs
  and Text Jointly Embedding</dc:title>
 <dc:creator>Wang, Meng</dc:creator>
 <dc:creator>Chen, Yihe</dc:creator>
 <dc:creator>Qian, Buyue</dc:creator>
 <dc:creator>Liu, Jun</dc:creator>
 <dc:creator>Wang, Sen</dc:creator>
 <dc:creator>Long, Guodong</dc:creator>
 <dc:creator>Wang, Fei</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Minimizing adverse reactions caused by drug-drug interactions has always been
a momentous research topic in clinical pharmacology. Detecting all possible
interactions through clinical studies before a drug is released to the market
is a demanding task. The power of big data is opening up new approaches to
discover various drug-drug interactions. However, these discoveries contain a
huge amount of noise and provide knowledge bases far from complete and
trustworthy ones to be utilized. Most existing studies focus on predicting
binary drug-drug interactions between drug pairs but ignore other interactions.
In this paper, we propose a novel framework, called PRD, to predict drug-drug
interactions. The framework uses the graph embedding that can overcome data
incompleteness and sparsity issues to achieve multiple DDI label prediction.
First, a large-scale drug knowledge graph is generated from different sources.
Then, the knowledge graph is embedded with comprehensive biomedical text into a
common low dimensional space. Finally, the learned embeddings are used to
efficiently compute rich DDI information through a link prediction process. To
validate the effectiveness of the proposed framework, extensive experiments
were conducted on real-world datasets. The results demonstrate that our model
outperforms several state-of-the-art baseline methods in terms of capability
and accuracy.
</dc:description>
 <dc:description>Comment: 9pages, 10 figures</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08876</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing the Collective Learning Effects in Regional Economic
  Development</dc:title>
 <dc:creator>Gao, Jian</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:description>  Collective learning in economic development has been revealed by recent
empirical studies, however, investigations on how to benefit most from its
effects remain still lacking. In this paper, we explore the maximization of the
collective learning effects using a simple propagation model to study the
diversification of industries on real networks built on Brazilian labor data.
For the inter-regional learning, we find an optimal strategy that makes a
balance between core and periphery industries in the initial activation,
considering the core-periphery structure of the industry space--a network
representation of the relatedness between industries. For the inter-regional
learning, we find an optimal strategy that makes a balance between nearby and
distant regions in establishing new spatial connections, considering the
spatial structure of the integrated adjacent network that connects all regions.
Our findings suggest that the near to by random strategies are likely to make
the best use of the collective learning effects in advancing regional economic
development practices.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08876</dc:identifier>
 <dc:identifier>2017 14th ICCWAMTIP, IEEE, 2017, pp. 337-341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08877</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind Image Deblurring via Reweighted Graph Total Variation</dc:title>
 <dc:creator>Bai, Yuanchao</dc:creator>
 <dc:creator>Cheung, Gene</dc:creator>
 <dc:creator>Liu, Xianming</dc:creator>
 <dc:creator>Gao, Wen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Blind image deblurring, i.e., deblurring without knowledge of the blur
kernel, is a highly ill-posed problem. The problem can be solved in two parts:
i) estimate a blur kernel from the blurry image, and ii) given estimated blur
kernel, de-convolve blurry input to restore the target image. In this paper, by
interpreting an image patch as a signal on a weighted graph, we first argue
that a skeleton image---a proxy that retains the strong gradients of the target
but smooths out the details---can be used to accurately estimate the blur
kernel and has a unique bi-modal edge weight distribution. We then design a
reweighted graph total variation (RGTV) prior that can efficiently promote
bi-modal edge weight distribution given a blurry patch. However, minimizing a
blind image deblurring objective with RGTV results in a non-convex
non-differentiable optimization problem. We propose a fast algorithm that
solves for the skeleton image and the blur kernel alternately. Finally with the
computed blur kernel, recent non-blind image deblurring algorithms can be
applied to restore the target image. Experimental results show that our
algorithm can robustly estimate the blur kernel with large kernel size, and the
reconstructed sharp image is competitive against the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 5 pages, submitted to IEEE International Conference on Acoustics,
  Speech and Signal Processing, Calgary, Alberta, Canada, April, 2018</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08878</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Intelligent is your Intelligent Robot?</dc:title>
 <dc:creator>Winfield, Alan F. T.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  How intelligent is robot A compared with robot B? And how intelligent are
robots A and B compared with animals (or plants) X and Y? These are both
interesting and deeply challenging questions. In this paper we address the
question &quot;how intelligent is your intelligent robot?&quot; by proposing that
embodied intelligence emerges from the interaction and integration of four
different and distinct kinds of intelligence. We then suggest a simple
diagrammatic representation on which these kinds of intelligence are shown as
four axes in a star diagram. A crude qualitative comparison of the intelligence
graphs of animals and robots both exposes and helps to explain the chronic
intelligence deficit of intelligent robots. Finally we examine the options for
determining numerical values for the four kinds of intelligence in an effort to
move toward a quantifiable intelligence vector.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08880</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lectures on Randomized Numerical Linear Algebra</dc:title>
 <dc:creator>Drineas, Petros</dc:creator>
 <dc:creator>Mahoney, Michael W.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This chapter is based on lectures on Randomized Numerical Linear Algebra from
the 2016 Park City Mathematics Institute summer school on The Mathematics of
Data.
</dc:description>
 <dc:description>Comment: To appear in the edited volume of lectures from the 2016 PCMI summer
  school</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08883</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic Flow Forecasting Using a Spatio-Temporal Bayesian Network
  Predictor</dc:title>
 <dc:creator>Sun, Shiliang</dc:creator>
 <dc:creator>Zhang, Changshui</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  A novel predictor for traffic flow forecasting, namely spatio-temporal
Bayesian network predictor, is proposed. Unlike existing methods, our approach
incorporates all the spatial and temporal information available in a
transportation network to carry our traffic flow forecasting of the current
site. The Pearson correlation coefficient is adopted to rank the input
variables (traffic flows) for prediction, and the best-first strategy is
employed to select a subset as the cause nodes of a Bayesian network. Given the
derived cause nodes and the corresponding effect node in the spatio-temporal
Bayesian network, a Gaussian Mixture Model is applied to describe the
statistical relationship between the input and output. Finally, traffic flow
forecasting is performed under the criterion of Minimum Mean Square Error
(M.M.S.E.). Experimental results with the urban vehicular flow data of Beijing
demonstrate the effectiveness of our presented spatio-temporal Bayesian network
predictor.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08883</dc:identifier>
 <dc:identifier>The 15th International Conference on Artificial Neural Networks
  (ICANN), 2005, pp. 273-278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08885</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted Data Normalization Based on Eigenvalues for Artificial Neural
  Network Classification</dc:title>
 <dc:creator>Zhang, Qingjiu</dc:creator>
 <dc:creator>Sun, Shiliang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Artificial neural network (ANN) is a very useful tool in solving learning
problems. Boosting the performances of ANN can be mainly concluded from two
aspects: optimizing the architecture of ANN and normalizing the raw data for
ANN. In this paper, a novel method which improves the effects of ANN by
preprocessing the raw data is proposed. It totally leverages the fact that
different features should play different roles. The raw data set is firstly
preprocessed by principle component analysis (PCA), and then its principle
components are weighted by their corresponding eigenvalues. Several aspects of
analysis are carried out to analyze its theory and the applicable occasions.
Three classification problems are launched by an active learning algorithm to
verify the proposed method. From the empirical results, conclusion comes to the
fact that the proposed method can significantly improve the performance of ANN.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08885</dc:identifier>
 <dc:identifier>The 16th International Conference on Neural Information Processing
  (ICONIP), Lecture Notes in Computer Science, 2009, 5863: 349-356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08886</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on a conjecture of new binary cyclotomic sequences of length
  $p^n$</dc:title>
 <dc:creator>Ye, Zhifan</dc:creator>
 <dc:creator>Ke, Pinhui</dc:creator>
 <dc:creator>Wu, Chenhuang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  Recently, a conjecture on the linear complexity of a new class of generalized
cyclotomic binary sequences of period $p^n$ were proposed by Z. Xiao et al.
(Des. Codes Cryptogr. DOI 10.1007/s10623-017-0408-7). Later, for the case $f$
being the form $2^r$ with $r\ge 1$, Vladimir Edemskiy proved the conjecture
(arXiv:1712.03947). In this paper, we first introduce a generic construction of
$p^n$-periodic binary sequence based on the generalized cyclotomy, which admits
a flexible support set and includes Xiao's construction as a special case.
Then, under the assumption of $2$ being a primitive root modulo $p^2$, the
linear complexity of the new proposed sequence over $\mathrm {GF} (2) $ is
determined by using the Euler quotient. As a byproduct, in the case of $2$
being a primitive root modulo $p^2$, the conjecture given by Z. Xiao et al. is
proved to be correct for a general $f$.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08900</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PuRe: Robust pupil detection for real-time pervasive eye tracking</dc:title>
 <dc:creator>Santini, Thiago</dc:creator>
 <dc:creator>Fuhl, Wolfgang</dc:creator>
 <dc:creator>Kasneci, Enkelejda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Real-time, accurate, and robust pupil detection is an essential prerequisite
to enable pervasive eye-tracking and its applications -- e.g., gaze-based human
computer interaction, health monitoring, foveated rendering, and advanced
driver assistance. However, automated pupil detection has proved to be an
intricate task in real-world scenarios due to a large mixture of challenges
such as quickly changing illumination and occlusions. In this paper, we
introduce the Pupil Reconstructor PuRe, a method for pupil detection in
pervasive scenarios based on a novel edge segment selection and conditional
segment combination schemes; the method also includes a confidence measure for
the detected pupil. The proposed method was evaluated on over 316,000 images
acquired with four distinct head-mounted eye tracking devices. Results show a
pupil detection rate improvement of over 10 percentage points w.r.t.
state-of-the-art algorithms in the two most challenging data sets (6.46 for all
data sets), further pushing the envelope for pupil detection. Moreover, we
advance the evaluation protocol of pupil detection algorithms by also
considering eye images in which pupils are not present. In this aspect, PuRe
improved precision and specificity w.r.t. state-of-the-art algorithms by 25.05
and 10.94 percentage points, respectively, demonstrating the meaningfulness of
PuRe's confidence measure. PuRe operates in real-time for modern eye trackers
(at 120 fps).
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08907</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimality Program in Segment and String Graphs</dc:title>
 <dc:creator>Bonnet, &#xc9;douard</dc:creator>
 <dc:creator>Rz&#x105;&#x17c;ewski, Pawe&#x142;</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>68Q17, 68Q25</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Planar graphs are known to allow subexponential algorithms running in time
$2^{O(\sqrt n)}$ or $2^{O(\sqrt n \log n)}$ for most of the paradigmatic
problems, while the brute-force time $2^{\Theta(n)}$ is very likely to be
asymptotically best on general graphs. Intrigued by an algorithm packing curves
in $2^{O(n^{2/3}\log n)}$ by Fox and Pach [SODA'11], we investigate which
problems have subexponential algorithms on the intersection graphs of curves
(string graphs) or segments (segment intersection graphs) and which problems
have no such algorithms under the ETH (Exponential Time Hypothesis). Among our
results, we show that, quite surprisingly, 3-Coloring can also be solved in
time $2^{O(n^{2/3}\log^{O(1)}n)}$ on string graphs while an algorithm running
in time $2^{o(n)}$ for 4-Coloring even on axis-parallel segments (of unbounded
length) would disprove the ETH. For 4-Coloring of unit segments, we show a
weaker ETH lower bound of $2^{o(n^{2/3})}$ which exploits the celebrated
Erd\H{o}s-Szekeres theorem. The subexponential running time also carries over
to Min Feedback Vertex Set but not to Min Dominating Set and Min Independent
Dominating Set.
</dc:description>
 <dc:description>Comment: 19 pages, 15 figures</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08910</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Walrasian Dynamics in Multi-unit Markets</dc:title>
 <dc:creator>Br&#xe2;nzei, Simina</dc:creator>
 <dc:creator>Filos-Ratsikas, Aris</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In a multi-unit market, a seller brings multiple units of a good and tries to
sell them to a set of buyers equipped with monetary endowments. While a
Walrasian equilibrium does not always exist in this model, natural relaxations
of the concept that retain its desirable fairness properties do exist.
  We study the dynamics of (Walrasian) envy-free pricing algorithms in this
environment, showing that for any such pricing algorithm, the best response
dynamic process converges to a pure Nash equilibrium with small loss in revenue
and welfare. Moreover, we generalize these bounds to capture all the Nash
equilibria for a large class of (monotone) pricing algorithms.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08911</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Largest and Smallest Area Triangles on a Given Set of Imprecise Points</dc:title>
 <dc:creator>Keikha, Vahideh</dc:creator>
 <dc:creator>L&#xf6;ffler, Maarten</dc:creator>
 <dc:creator>Mohades, Ali</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In this paper we study the following problem: we are given a set of imprecise
points modeled as parallel line segments, and we wish to place a point on each
line segment such that the resulting point set maximizes/minimizes the size of
the largest/smallest area $k$-gon. We first study the problem for the case
$k=3$. We show that for a given set of parallel line segments of equal length
the largest possible area triangle can be found in $O(n \log n)$ time, and for
line segments of arbitrary length the problem can be solved in $O(n^2)$ time.
Also, we show that the smallest largest-area triangle can be found in $O(n^2
\log n)$ time. As for finding smallest-area triangles, we show that finding the
largest smallest-area triangle is NP-hard, but that the smallest possible area
triangle for a set of arbitrary length parallel line segments can be found in
$O(n^2)$ time. Finally, we discuss to what extent our results can be
generalized to larger values of $k$.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08914</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Nonparametric Causal Inference: Information Rates and Learning
  Algorithms</dc:title>
 <dc:creator>Alaa, Ahmed M.</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We investigate the problem of estimating the causal effect of a treatment on
individual subjects from observational data, this is a central problem in
various application domains, including healthcare, social sciences, and online
advertising. Within the Neyman Rubin potential outcomes model, we use the
Kullback Leibler (KL) divergence between the estimated and true distributions
as a measure of accuracy of the estimate, and we define the information rate of
the Bayesian causal inference procedure as the (asymptotic equivalence class of
the) expected value of the KL divergence between the estimated and true
distributions as a function of the number of samples. Using Fano method, we
establish a fundamental limit on the information rate that can be achieved by
any Bayesian estimator, and show that this fundamental limit is independent of
the selection bias in the observational data. We characterize the Bayesian
priors on the potential (factual and counterfactual) outcomes that achieve the
optimal information rate. As a consequence, we show that a particular class of
priors that have been widely used in the causal inference literature cannot
achieve the optimal information rate. On the other hand, a broader class of
priors can achieve the optimal information rate. We go on to propose a prior
adaptation procedure (which we call the information based empirical Bayes
procedure) that optimizes the Bayesian prior by maximizing an information
theoretic criterion on the recovered causal effects rather than maximizing the
marginal likelihood of the observed (factual) data. Building on our analysis,
we construct an information optimal Bayesian causal inference algorithm.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08917</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building a Sentiment Corpus of Tweets in Brazilian Portuguese</dc:title>
 <dc:creator>Brum, Henrico Bertini</dc:creator>
 <dc:creator>Nunes, Maria das Gra&#xe7;as Volpe</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The large amount of data available in social media, forums and websites
motivates researches in several areas of Natural Language Processing, such as
sentiment analysis. The popularity of the area due to its subjective and
semantic characteristics motivates research on novel methods and approaches for
classification. Hence, there is a high demand for datasets on different domains
and different languages. This paper introduces TweetSentBR, a sentiment corpora
for Brazilian Portuguese manually annotated with 15.000 sentences on TV show
domain. The sentences were labeled in three classes (positive, neutral and
negative) by seven annotators, following literature guidelines for ensuring
reliability on the annotation. We also ran baseline experiments on polarity
classification using three machine learning methods, reaching 80.99% on
F-Measure and 82.06% on accuracy in binary classification, and 59.85% F-Measure
and 64.62% on accuracy on three point classification.
</dc:description>
 <dc:description>Comment: Accepted for publication in 11th International Conference on Language
  Resources and Evaluation (LREC 2018)</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08919</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Massive MIMO CSI Feedback</dc:title>
 <dc:creator>Wen, Chao-Kai</dc:creator>
 <dc:creator>Shih, Wan-Ting</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In frequency division duplex mode, the downlink channel state information
(CSI) should be conveyed to the base station through feedback links so that the
potential gains of a massive multiple-input multiple-output can be exhibited.
However, the excessive feedback overhead remains a bottleneck in this regime.
In this letter, we use beep learning technology to develop CsiNet, a novel CSI
sensing and recovery network that learns to effectively use channel structure
from training samples. In particular, CsiNet learns a transformation from CSI
to a near-optimal number of representations (codewords) and an inverse
transformation from codewords to CSI. Experiments demonstrate that CsiNet can
recover CSI with significantly improved reconstruction quality compared with
existing compressive sensing (CS)-based methods. Even at excessively low
compression regions where CS-based methods cannot work, CsiNet retains
effective beamforming gain.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, 2 tables; submitted to a journal</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08924</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Canary in the City: Indicator Groups as Predictors of Urban Change</dc:title>
 <dc:creator>Steentoft, Aike Alexander</dc:creator>
 <dc:creator>Poorthuis, Ate</dc:creator>
 <dc:creator>Lee, Bu-Sung</dc:creator>
 <dc:creator>Schl&#xe4;pfer, Markus</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  As cities grow, certain neighborhoods experience a particularly high demand
for housing, resulting in escalating rents. Despite far-reaching socioeconomic
consequences, it remains difficult to predict when and where urban
neighborhoods will face such changes. To tackle this challenge, we adapt the
concept of `bioindicators', borrowed from ecology, to the urban context. The
objective is to use an `indicator group' of people to assess the quality of a
complex environment and its changes over time. Specifically, we analyze 92
million geolocated Twitter records across five US cities, allowing us to derive
socio-economic user profiles based on individual movement patterns. As a
proof-of-concept, we define users with a `high-income-profile' as an indicator
group and show that their visitation patterns are a suitable indicator for
expected future rent increases in different neighborhoods. The concept of
indicator groups highlights the potential of closely monitoring only a specific
subset of the population, rather than the population as a whole. If the
indicator group is defined appropriately for the phenomenon of interest, this
approach can yield early predictions while simultaneously reducing the amount
of data that needs to be collected and analyzed.
</dc:description>
 <dc:description>Comment: 20 pages, 6 figures</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08926</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Rudiment of Energy Internet: Coordinated Power Dispatching of Intra-
  and Inter- Local Area Packetized-Power Networks</dc:title>
 <dc:creator>Ma, Jinghuan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Local area packetized-power network (LAPPN) provides flexible local power
dispatching in the future Energy Internet. With interconnections among multiple
LAPPNs, power dispatching can be further extended to intra- and inter-LAPPN
power interchanges. It becomes a significant issue to schedule the two kinds of
power interchanges as, from a system perspective high utilization of available
scheduling time slots and low overall transmission loss should be guaranteed,
and from a subscriber perspective a high scheduled ratio of transmission
requests with a fair transmission sequence in terms of transmission urgency are
expected. To this end, we propose a cooperative power dispatching framework for
connected LAPPNs, including subscriber matching and two-layer power
transmission scheduling. The former matches subscribers from different LAPPNs,
considering both subscriber preferences and power transmission loss. The latter
coordinates the intra- and inter-LAPPN power packet transmission to maximize
the amount of energy delivered with a guaranteed fairness on user urgency.
Simulation results of a two-LAPPN system are provided, which demonstrate that
the proposed framework can achieve effective and efficient power dispatching in
terms of the mentioned concerns, and reveal facts on ideal system capacity and
how to manipulate the proportions of the two kinds of transmissions according
to network status.
</dc:description>
 <dc:description>Comment: 9 pages, 12 figures</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08933</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-automatic definite description annotation: a first report</dc:title>
 <dc:creator>Rocha, Danillo da Silva</dc:creator>
 <dc:creator>Lan, Alex Gwo Jen</dc:creator>
 <dc:creator>Paraboni, Ivandre</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Studies in Referring Expression Generation (REG) often make use of corpora of
definite descriptions produced by human subjects in controlled experiments.
Experiments of this kind, which are essential for the study of reference
phenomena and many others, may however include a considerable amount of noise.
Human subjects may easily lack attention, or may simply misunderstand the task
at hand and, as a result, the elicited data may include large proportions of
ambiguous or ill-formed descriptions. In addition to that, REG corpora are
usually collected for the study of semantics-related phenomena, and it is often
the case that the elicited descriptions (and their input contexts) need to be
annotated with their corresponding semantic properties. This, as in many other
fields, may require considerable time and skilled annotators. As a means to
tackle both kinds of difficulties - poor data quality and high annotation costs
- this work discusses a semi-automatic method for the annotation of definite
descriptions produced by human subjects in REG data collection experiments. The
method makes use of simple rules to establish associations between words and
meanings, and is intended to facilitate the design of experiments that produce
REG corpora.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08934</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of FPGA Based Neural Network Accelerator</dc:title>
 <dc:creator>Guo, Kaiyuan</dc:creator>
 <dc:creator>Zeng, Shulin</dc:creator>
 <dc:creator>Yu, Jincheng</dc:creator>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Yang, Huazhong</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Recent researches on neural network have shown great advantage in computer
vision over traditional algorithms based on handcrafted features and models.
Neural network is now widely adopted in regions like image, speech and video
recognition. But the great computation and storage complexity of neural network
based algorithms poses great difficulty on its application. CPU platforms are
hard to offer enough computation capacity. GPU platforms are the first choice
for neural network process because of its high computation capacity and easy to
use development frameworks.
  On the other hand, FPGA based neural network accelerator is becoming a
research topic. Because specific designed hardware is the next possible
solution to surpass GPU in speed and energy efficiency. Various FPGA based
accelerator designs have been proposed with software and hardware optimization
techniques to achieve high speed and energy efficiency. In this paper, we give
an overview of previous work on neural network accelerators based on FPGA and
summarize the main techniques used. Investigation from software to hardware,
from circuit level to system level is carried out to complete analysis of FPGA
based neural network accelerator design and serves as a guide to future work.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08939</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On tractable query evaluation for SPARQL</dc:title>
 <dc:creator>Mengel, Stefan</dc:creator>
 <dc:creator>Skritek, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Despite much work within the last decade on foundational properties of SPARQL
- the standard query language for RDF data - rather little is known about the
exact limits of tractability for this language. In particular, this is the case
for SPARQL queries that contain the OPTIONAL-operator, even though it is one of
the most intensively studied features of SPARQL. The aim of our work is to
provide a more thorough picture of tractable classes of SPARQL queries.
  In general, SPARQL query evaluation is PSPACE-complete in combined
complexity, and it remains PSPACE-hard already for queries containing only the
OPTIONAL-operator. To amend this situation, research has focused on
&quot;well-designed SPARQL queries&quot; and their recent generalization &quot;weakly
well-designed SPARQL queries&quot;. For these two fragments the evaluation problem
is coNP-complete in the absence of projection and SigmaP2-complete otherwise.
Moreover, they have been shown to contain most SPARQL queries asked in
practical settings.
  In this paper, we study tractable classes of weakly well-designed queries in
parameterized complexity considering the equivalent formulation as pattern
trees. We give a complete characterization of the tractable classes in the case
without projection. Moreover, we show a characterization of all tractable
classes of simple well-designed pattern trees in the presence of projection.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08940</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Studying the Impact of Managers on Password Strength and Reuse</dc:title>
 <dc:creator>Lyastani, Sanam Ghorbani</dc:creator>
 <dc:creator>Schilling, Michael</dc:creator>
 <dc:creator>Fahl, Sascha</dc:creator>
 <dc:creator>Bugiel, Sven</dc:creator>
 <dc:creator>Backes, Michael</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Despite their well-known security problems, passwords are still the incumbent
authentication method for virtually all online services. To remedy the
situation, end-users are very often referred to password managers as a solution
to the password reuse and password weakness problems. However, to date the
actual impact of password managers on password security and reuse has not been
studied systematically.
  In this paper, we provide the first large-scale study of the password
managers' influence on users' real-life passwords. From 476 participants of an
online survey on users' password creation and management strategies, we recruit
170 participants that allowed us to monitor their passwords in-situ through a
browser plugin. In contrast to prior work, we collect the passwords' entry
methods (e.g., human or password manager) in addition to the passwords and
their metrics. Based on our collected data and our survey, we gain a more
complete picture of the factors that influence our participants' passwords'
strength and reuse. We quantify for the first time that password managers
indeed benefit the password strength and uniqueness, however, also our results
also suggest that those benefits depend on the users' strategies and that
managers without password generators rather aggravate the existing problems.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08941</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative Opinion Mining: A Review</dc:title>
 <dc:creator>Varathan, Kasturi Dewi</dc:creator>
 <dc:creator>Giachanou, Anastasia</dc:creator>
 <dc:creator>Crestani, Fabio</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Opinion mining refers to the use of natural language processing, text
analysis and computational linguistics to identify and extract subjective
information in textual material. Opinion mining, also known as sentiment
analysis, has received a lot of attention in recent times, as it provides a
number of tools to analyse the public opinion on a number of different topics.
Comparative opinion mining is a subfield of opinion mining that deals with
identifying and extracting information that is expressed in a comparative form
(e.g.~&quot;paper X is better than the Y&quot;). Comparative opinion mining plays a very
important role when ones tries to evaluate something, as it provides a
reference point for the comparison. This paper provides a review of the area of
comparative opinion mining. It is the first review that cover specifically this
topic as all previous reviews dealt mostly with general opinion mining. This
survey covers comparative opinion mining from two different angles. One from
perspective of techniques and the other from perspective of comparative opinion
elements. It also incorporates preprocessing tools as well as dataset that were
used by the past researchers that can be useful to the future researchers in
the field of comparative opinion mining.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08941</dc:identifier>
 <dc:identifier>Journal of the Association for Information Science and Technology,
  68(4), 2017</dc:identifier>
 <dc:identifier>doi:10.1002/asi.23716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08948</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Change points, memory and epidemic spreading in temporal networks</dc:title>
 <dc:creator>Peixoto, Tiago P.</dc:creator>
 <dc:creator>Gauvin, Laetitia</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Dynamic networks exhibit temporal patterns that vary across different time
scales, all of which can potentially affect processes that take place on the
network. However, most data-driven approaches used to model time-varying
networks attempt to capture only a single characteristic time scale in
isolation --- typically associated with the short-time memory of a Markov chain
or with long-time abrupt changes caused by external or systemic events. Here we
propose a unified approach to model both aspects simultaneously, detecting
short and long-time behaviors of temporal networks. We do so by developing an
arbitrary-order mixed Markov model with change points, and using a
nonparametric Bayesian formulation that allows the Markov order and the
position of change points to be determined from data without overfitting. In
addition, we evaluate the quality of the multiscale model in its capacity to
reproduce the spreading of epidemics on the temporal network, and we show that
describing multiple time scales simultaneously has a synergistic effect, where
statistically significant features are uncovered that otherwise would remain
hidden by treating each time scale independently.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08963</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Profit Maximization for Online Social Network Providers</dc:title>
 <dc:creator>Tang, Jing</dc:creator>
 <dc:creator>Tang, Xueyan</dc:creator>
 <dc:creator>Yuan, Junsong</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Online Social Networks (OSNs) attract billions of users to share information
and communicate where viral marketing has emerged as a new way to promote the
sales of products. An OSN provider is often hired by an advertiser to conduct
viral marketing campaigns. The OSN provider generates revenue from the
commission paid by the advertiser which is determined by the spread of its
product information. Meanwhile, to propagate influence, the activities
performed by users such as viewing video ads normally induce diffusion cost to
the OSN provider. In this paper, we aim to find a seed set to optimize a new
profit metric that combines the benefit of influence spread with the cost of
influence propagation for the OSN provider. Under many diffusion models, our
profit metric is the difference between two submodular functions which is
challenging to optimize as it is neither submodular nor monotone. We design a
general two-phase framework to select seeds for profit maximization and develop
several bounds to measure the quality of the seed set constructed. Experimental
results with real OSN datasets show that our approach can achieve high
approximation guarantees and significantly outperform the baseline algorithms,
including state-of-the-art influence maximization algorithms.
</dc:description>
 <dc:description>Comment: INFOCOM 2018 (Full version), 12 pages</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08968</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spurious Local Minima are Common in Two-Layer ReLU Neural Networks</dc:title>
 <dc:creator>Safran, Itay</dc:creator>
 <dc:creator>Shamir, Ohad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the optimization problem associated with training simple ReLU
neural networks of the form $\mathbf{x}\mapsto
\sum_{i=1}^{k}\max\{0,\mathbf{w}_i^\top \mathbf{x}\}$ with respect to the
squared loss. We provide a computer-assisted proof that even if the input
distribution is standard Gaussian, even if the dimension is unrestricted, and
even if the target values are generated by such a network, with orthonormal
parameter vectors, the problem can still have spurious local minima once $k\geq
6$. By a continuity argument, this implies that in high dimensions,
\emph{nearly all} target networks of the relevant sizes lead to spurious local
minima. Moreover, we conduct experiments which show that the probability of
hitting such local minima is quite high, and increasing with the network size.
On the positive side, mild over-parameterization appears to drastically reduce
such local minima, indicating that an over-parameterization assumption is
necessary to get a positive result in this setting.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08969</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mean Field Residual Networks: On the Edge of Chaos</dc:title>
 <dc:creator>Yang, Greg</dc:creator>
 <dc:creator>Schoenholz, Samuel S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  We study randomly initialized residual networks using mean field theory and
the theory of difference equations. Classical feedforward neural networks, such
as those with tanh activations, exhibit exponential behavior on the average
when propagating inputs forward or gradients backward. The exponential forward
dynamics causes rapid collapsing of the input space geometry, while the
exponential backward dynamics causes drastic vanishing or exploding gradients.
We show, in contrast, that by adding skip connections, the network will,
depending on the nonlinearity, adopt subexponential forward and backward
dynamics, and in many cases in fact polynomial. The exponents of these
polynomials are obtained through analytic methods and proved and verified
empirically to be correct. In terms of the &quot;edge of chaos&quot; hypothesis, these
subexponential and polynomial laws allow residual networks to &quot;hover over the
boundary between stability and chaos,&quot; thus preserving the geometry of the
input space and the gradient information flow. In our experiments, for each
activation function we study here, we initialize residual networks with
different hyperparameters and train them on MNIST. Remarkably, our
initialization time theory can accurately predict test time performance of
these networks, by tracking either the expected amount of gradient explosion or
the expected squared distance between the images of two input vectors.
Importantly, we show, theoretically as well as empirically, that common
initializations such as the Xavier or the He schemes are not optimal for
residual networks, because the optimal initialization variances depend on the
depth. Finally, we have made mathematical contributions by deriving several new
identities for the kernels of powers of ReLU functions by relating them to the
zeroth Bessel function of the second kind.
</dc:description>
 <dc:description>Comment: NIPS 2017</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08971</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human-Centric Data Cleaning [Vision]</dc:title>
 <dc:creator>Rezig, El Kindi</dc:creator>
 <dc:creator>Ouzzani, Mourad</dc:creator>
 <dc:creator>Elmagarmid, Ahmed K.</dc:creator>
 <dc:creator>Aref, Walid G.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Data Cleaning refers to the process of detecting and fixing errors in the
data. Human involvement is instrumental at several stages of this process,
e.g., to identify and repair errors, to validate computed repairs, etc. There
is currently a plethora of data cleaning algorithms addressing a wide range of
data errors (e.g., detecting duplicates, violations of integrity constraints,
missing values, etc.). Many of these algorithms involve a human in the loop,
however, this latter is usually coupled to the underlying cleaning algorithms.
There is currently no end-to-end data cleaning framework that systematically
involves humans in the cleaning pipeline regardless of the underlying cleaning
algorithms. In this paper, we highlight key challenges that need to be
addressed to realize such a framework. We present a design vision and discuss
scenarios that motivate the need for such a framework to judiciously assist
humans in the cleaning process. Finally, we present directions to implement
such a framework.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:date>2017-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08973</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Better Half of Selling Separately</dc:title>
 <dc:creator>Hart, Sergiu</dc:creator>
 <dc:creator>Reny, Philip J.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Separate selling of two independent goods is shown to yield at least 62% of
the optimal revenue, and at least 73% when the goods satisfy the Myerson
regularity condition. This improves the 50% result of Hart and Nisan (2017,
originally circulated in 2012).
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08976</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How do you Command an Army of Intelligent Things?</dc:title>
 <dc:creator>Kott, Alexander</dc:creator>
 <dc:creator>Alberts, David</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Within a decade, probably less, we will need to find ways to work effectively
with ever growing numbers of intelligent things, including robots and
intelligent agents. The networked workforce of the near future will thus
consist of not only interconnected and interdependent humans but also of
intelligent things. This raises a number of challenging issues, none more
compelling and urgent than finding an answer to the question &quot;How to manage
this new organizational form?&quot; We consider these issues in a particularly
challenging domain of human endeavor -- warfare. Command and Control (C2) is
the term applied to management or governance of military organizations and
endeavors. We consider how human and other intelligent entities can best
contribute to ensuring that the decision makers, whether human or machine, have
the information they require and make good use of this information to
accomplish C2 functions. Commanders or managers of mixed human-thing
organizations will face several challenges that the discussion above has
highlighted. Things are challenged in a number of areas and will need humans to
provide these capabilities. These include their ability to explain, build
trust, bond, understand personal agendas, emotions, politics, and negotiate.
Things and people both to some extent have difficulty anticipating and coping
with the unusual and unexpected and to think of out-of-the-box solutions.
</dc:description>
 <dc:description>Comment: This is a version of the article that appears in IEEE Computer as:
  Kott, Alexander, and David S. Alberts. &quot;How Do You Command an Army of
  Intelligent Things?.&quot; Computer 12 (2017): 96-100</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08976</dc:identifier>
 <dc:identifier>Computer 12 (2017): 96-100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08980</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Internet of Battle Things</dc:title>
 <dc:creator>Kott, Alexander</dc:creator>
 <dc:creator>Swami, Ananthram</dc:creator>
 <dc:creator>West, Bruce J</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The battlefield of the future will be densely populated by a variety of
entities (&quot;things&quot;) -- some intelligent and some only marginally so --
performing a broad range of tasks: sensing, communicating, acting, and
collaborating with each other and human warfighters. We call this the Internet
of Battle Things, IoBT. In some ways, IoBT is already becoming a reality, but
20-30 years from now it is likely to become a dominant presence in warfare. To
become a reality, however, this bold vision will have to overcome a number of
major challenges. As one example of such a challenge, the communications among
things will have to be flexible and adaptive to rapidly changing situations and
military missions. In this paper, we explore this and several other major
challenges of IoBT, and outline key research directions and approaches towards
solving these challenges.
</dc:description>
 <dc:description>Comment: This is a version of the article that appears in IEEE Computer as:
  Kott, Alexander, Ananthram Swami, and Bruce J. West. &quot;The Internet of Battle
  Things.&quot; Computer 49.12 (2016): 70-75</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08980</dc:identifier>
 <dc:identifier>Computer 49.12 (2016): 70-75</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08987</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Run with Actor-Critic Ensemble</dc:title>
 <dc:creator>Huang, Zhewei</dc:creator>
 <dc:creator>Zhou, Shuchang</dc:creator>
 <dc:creator>Zhuang, BoEr</dc:creator>
 <dc:creator>Zhou, Xinyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce an Actor-Critic Ensemble(ACE) method for improving the
performance of Deep Deterministic Policy Gradient(DDPG) algorithm. At inference
time, our method uses a critic ensemble to select the best action from
proposals of multiple actors running in parallel. By having a larger candidate
set, our method can avoid actions that have fatal consequences, while staying
deterministic. Using ACE, we have won the 2nd place in NIPS'17 Learning to Run
competition, under the name of &quot;Megvii-hzwer&quot;.
</dc:description>
 <dc:description>Comment: 3 pages, 4 figures</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08992</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Native Language Speech for Accent Identification using Deep
  Siamese Networks</dc:title>
 <dc:creator>Siddhant, Aditya</dc:creator>
 <dc:creator>Jyothi, Preethi</dc:creator>
 <dc:creator>Ganapathy, Sriram</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  The problem of automatic accent identification is important for several
applications like speaker profiling and recognition as well as for improving
speech recognition systems. The accented nature of speech can be primarily
attributed to the influence of the speaker's native language on the given
speech recording. In this paper, we propose a novel accent identification
system whose training exploits speech in native languages along with the
accented speech. Specifically, we develop a deep Siamese network-based model
which learns the association between accented speech recordings and the native
language speech recordings. The Siamese networks are trained with i-vector
features extracted from the speech recordings using either an unsupervised
Gaussian mixture model (GMM) or a supervised deep neural network (DNN) model.
We perform several accent identification experiments using the CSLU Foreign
Accented English (FAE) corpus. In these experiments, our proposed approach
using deep Siamese networks yield significant relative performance improvements
of 15.4 percent on a 10-class accent identification task, over a baseline
DNN-based classification system that uses GMM i-vectors. Furthermore, we
present a detailed error analysis of the proposed accent identification system.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08996</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Android Malware Detection using Deep Learning on API Method Sequences</dc:title>
 <dc:creator>Karbab, ElMouatez Billah</dc:creator>
 <dc:creator>Debbabi, Mourad</dc:creator>
 <dc:creator>Derhab, Abdelouahid</dc:creator>
 <dc:creator>Mouheb, Djedjiga</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Android OS experiences a blazing popularity since the last few years. This
predominant platform has established itself not only in the mobile world but
also in the Internet of Things (IoT) devices. This popularity, however, comes
at the expense of security, as it has become a tempting target of malicious
apps. Hence, there is an increasing need for sophisticated, automatic, and
portable malware detection solutions. In this paper, we propose MalDozer, an
automatic Android malware detection and family attribution framework that
relies on sequences classification using deep learning techniques. Starting
from the raw sequence of the app's API method calls, MalDozer automatically
extracts and learns the malicious and the benign patterns from the actual
samples to detect Android malware. MalDozer can serve as a ubiquitous malware
detection system that is not only deployed on servers, but also on mobile and
even IoT devices. We evaluate MalDozer on multiple Android malware datasets
ranging from 1K to 33K malware apps, and 38K benign apps. The results show that
MalDozer can correctly detect malware and attribute them to their actual
families with an F1-Score of 96%-99% and a false positive rate of 0.06%-2%,
under all tested datasets and settings.
</dc:description>
 <dc:description>Comment: 17 pages, submitted to Elsevier Digital Investigations Journal</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.08996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09001</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernel Regression with Sparse Metric Learning</dc:title>
 <dc:creator>Huang, Rongqing</dc:creator>
 <dc:creator>Sun, Shiliang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Kernel regression is a popular non-parametric fitting technique. It aims at
learning a function which estimates the targets for test inputs as precise as
possible. Generally, the function value for a test input is estimated by a
weighted average of the surrounding training examples. The weights are
typically computed by a distance-based kernel function and they strongly depend
on the distances between examples. In this paper, we first review the latest
developments of sparse metric learning and kernel regression. Then a novel
kernel regression method involving sparse metric learning, which is called
kernel regression with sparse metric learning (KR$\_$SML), is proposed. The
sparse kernel regression model is established by enforcing a mixed $(2,1)$-norm
regularization over the metric matrix. It learns a Mahalanobis distance metric
by a gradient descent procedure, which can simultaneously conduct
dimensionality reduction and lead to good prediction results. Our work is the
first to combine kernel regression with sparse metric learning. To verify the
effectiveness of the proposed method, it is evaluated on 19 data sets for
regression. Furthermore, the new method is also applied to solving practical
problems of forecasting short-term traffic flows. In the end, we compare the
proposed method with other three related kernel regression methods on all test
data sets under two criterions. Experimental results show that the proposed
method is much more competitive.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09001</dc:identifier>
 <dc:identifier>Journal of Intelligent and Fuzzy Systems, 2013, 24(4): 775-787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09004</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RIDI: Robust IMU Double Integration</dc:title>
 <dc:creator>Yan, Hang</dc:creator>
 <dc:creator>Shan, Qi</dc:creator>
 <dc:creator>Furukawa, Yasutaka</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a novel data-driven approach for inertial navigation,
which learns to estimate trajectories of natural human motions just from an
inertial measurement unit (IMU) in every smartphone. The key observation is
that human motions are repetitive and consist of a few major modes (e.g.,
standing, walking, or turning). Our algorithm regresses a velocity vector from
the history of linear accelerations and angular velocities, then corrects
low-frequency bias in the linear accelerations, which are integrated twice to
estimate positions. We have acquired training data with ground-truth motions
across multiple human subjects and multiple phone placements (e.g., in a bag or
a hand). The qualitatively and quantitatively evaluations have demonstrated
that our algorithm has surprisingly shown comparable results to full Visual
Inertial navigation. To our knowledge, this paper is the first to integrate
sophisticated machine learning techniques with inertial navigation, potentially
opening up a new line of research in the domain of data-driven inertial
navigation. We will publicly share our code and data to facilitate further
research.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:date>2017-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09005</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Algorithms for t-distributed Stochastic Neighborhood Embedding</dc:title>
 <dc:creator>Linderman, George C.</dc:creator>
 <dc:creator>Rachh, Manas</dc:creator>
 <dc:creator>Hoskins, Jeremy G.</dc:creator>
 <dc:creator>Steinerberger, Stefan</dc:creator>
 <dc:creator>Kluger, Yuval</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  t-distributed Stochastic Neighborhood Embedding (t-SNE) is a method for
dimensionality reduction and visualization that has become widely popular in
recent years. Efficient implementations of t-SNE are available, but they scale
poorly to datasets with hundreds of thousands to millions of high dimensional
data-points. We present Fast Fourier Transform-accelerated Interpolation-based
t-SNE (FIt-SNE), which dramatically accelerates the computation of t-SNE. The
most time-consuming step of t-SNE is a convolution that we accelerate by
interpolating onto an equispaced grid and subsequently using the fast Fourier
transform to perform the convolution. We also optimize the computation of input
similarities in high dimensions using multi-threaded approximate nearest
neighbors. We further present a modification to t-SNE called &quot;late
exaggeration,&quot; which allows for easier identification of clusters in t-SNE
embeddings. Finally, for datasets that cannot be loaded into the memory, we
present out-of-core randomized principal component analysis (oocPCA), so that
the top principal components of a dataset can be computed without ever fully
loading the matrix, hence allowing for t-SNE of large datasets to be computed
on resource-limited machines.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09007</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Multi-armed Bandits in Constant Space</dc:title>
 <dc:creator>Liau, David</dc:creator>
 <dc:creator>Price, Eric</dc:creator>
 <dc:creator>Song, Zhao</dc:creator>
 <dc:creator>Yang, Ger</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the stochastic bandit problem in the sublinear space setting,
where one cannot record the win-loss record for all $K$ arms. We give an
algorithm using $O(1)$ words of space with regret \[
  \sum_{i=1}^{K}\frac{1}{\Delta_i}\log \frac{\Delta_i}{\Delta}\log T \] where
$\Delta_i$ is the gap between the best arm and arm $i$ and $\Delta$ is the gap
between the best and the second-best arms. If the rewards are bounded away from
$0$ and $1$, this is within an $O(\log 1/\Delta)$ factor of the optimum regret
possible without space constraints.
</dc:description>
 <dc:description>Comment: AISTATS 2018</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09008</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DMSS: A Robust Deep Meta Structure Based Similarity Measure in
  Heterogeneous Information Networks</dc:title>
 <dc:creator>Zhou, Yu</dc:creator>
 <dc:creator>Huang, Jianbin</dc:creator>
 <dc:creator>Sun, Heli</dc:creator>
 <dc:creator>Sun, Yizhou</dc:creator>
 <dc:creator>Chong, Hong</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Similarity measure as a fundamental task in heterogeneous information network
analysis has been applied to many areas, e.g. product recommendation,
clustering and web search. The state-of-the-art metrics depend on meta paths or
meta structures specified by users. In this paper, a novel similarity measure
on heterogeneous information networks, called Deep Meta Structure based
Similarity ($DMSS$), is proposed. The deep meta structure as a schematic
structure on heterogeneous information networks provides a unified framework
integrating all the meta paths and meta structures. It can be constructed
automatically. In order to formalize the semantics encapsulated in the deep
meta structure, we decompose it into several deep meta paths, and then combine
all the commuting matrices of these deep meta paths according to different
weights. It is noteworthy that the weights can be determined by the proposed
strategy. As a result, $DMSS$ is defined by virtue of the final commuting
matrix and therefore is robust to different schematic structures. Experimental
evaluations show that the state-of-the-art metrics are really sensitive to meta
paths or meta structures in terms of clustering and ranking. Besides, $DMSS$
outperforms the state-of-the-art metrics in terms of ranking and clustering in
the case of selecting an appropriate decaying parameter.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09010</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HelPal: A Search System for Mobile Crowd Service</dc:title>
 <dc:creator>Wu, Yao</dc:creator>
 <dc:creator>Wu, Tianzhen</dc:creator>
 <dc:creator>Xiong, Ziyi</dc:creator>
 <dc:creator>Wu, Yuncheng</dc:creator>
 <dc:creator>Chen, Hong</dc:creator>
 <dc:creator>Li, Cuiping</dc:creator>
 <dc:creator>Zhang, Xiaoying</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Proliferation of ubiquitous mobile devices makes location based services
prevalent. Mobile users are able to volunteer as providers of specific services
and in the meanwhile to search these services. For example, drivers may be
interested in tracking available nearby users who are willing to help with
motor repair or are willing to provide travel directions or first aid. With the
diffusion of mobile users, it is necessary to provide scalable means of
enabling such users to connect with other nearby users so that they can help
each other with specific services. Motivated by these observations, we design
and implement a general location based system HelPal for mobile users to
provide and enjoy instant service, which is called mobile crowd service. In
this demo, we introduce a mobile crowd service system featured with several
novel techniques. We sketch the system architecture and illustrate scenarios
via several cases. Demonstration shows the user-friendly search interface for
users to conveniently find skilled and qualified nearby service providers.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09014</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Null Dynamical State Models of Human Cognitive Dysfunction</dc:title>
 <dc:creator>Gagen, M. J.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The hard problem in artificial intelligence asks how the shuffling of
syntactical symbols in a program can lead to systems which experience semantics
and qualia. We address this question in three stages. First, we introduce a new
class of human semantic symbols which appears when unexpected and drastic
environmental change causes humans to become surprised, confused, uncertain,
and in extreme cases, unresponsive, passive and dysfunctional. For this class
of symbols, pre-learned programs become inoperative so these syntactical
programs cannot be the source of experienced qualia. Second, we model the
dysfunctional human response to a radically changed environment as being the
natural response of any learning machine facing novel inputs from well outside
its previous training set. In this situation, learning machines are unable to
extract information from their input and will typically enter a dynamical state
characterized by null outputs and a lack of response. This state immediately
predicts and explains the characteristics of the semantic experiences of humans
in similar circumstances. In the third stage, we consider learning machines
trained to implement multiple functions in simple sequential programs using
environmental data to specify subroutine names, control flow instructions,
memory calls, and so on. Drastic change in any of these environmental inputs
can again lead to inoperative programs. By examining changes specific to people
or locations we can model human cognitive symbols featuring these dependencies,
such as attachment and grief. Our approach links known dynamical machines
states with human qualia and thus offers new insight into the hard problem of
artificial intelligence.
</dc:description>
 <dc:description>Comment: 17 pages, 0 figures</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09022</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topological Representation of the Transit Sets of k-Point Crossover
  Operators</dc:title>
 <dc:creator>Changat, Manoj</dc:creator>
 <dc:creator>Narasimha-Shenoi, Prasanth G.</dc:creator>
 <dc:creator>Nezhad, Ferdoos Hossein</dc:creator>
 <dc:creator>Kov&#x161;e, Matja&#x17e;</dc:creator>
 <dc:creator>Mohandas, Shilpa</dc:creator>
 <dc:creator>Ramachandran, Abisha</dc:creator>
 <dc:creator>Stadler, Peter F.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  $k$-point crossover operators and their recombination sets are studied from
different perspectives. We show that transit functions of $k$-point crossover
generate, for all $k&gt;1$, the same convexity as the interval function of the
underlying graph. This settles in the negative an open problem by Mulder about
whether the geodesic convexity of a connected graph $G$ is uniquely determined
by its interval function $I$. The conjecture of Gitchoff and Wagner that for
each transit set $R_k(x,y)$ distinct from a hypercube there is a unique pair of
parents from which it is generated is settled affirmatively. Along the way we
characterize transit functions whose underlying graphs are Hamming graphs, and
those with underlying partial cube graphs. For general values of $k$ it is
shown that the transit sets of $k$-point crossover operators are the subsets
with maximal Vapnik-Chervonenkis dimension. Moreover, the transit sets of
$k$-point crossover on binary strings form topes of uniform oriented matroid of
VC-dimension $k+1$. The Topological Representation Theorem for oriented
matroids therefore implies that $k$-point crossover operators can be
represented by pseudosphere arrangements. This provides the tools necessary to
study the special case $k=2$ in detail.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09025</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain Adaptation Meets Disentangled Representation Learning and Style
  Transfer</dc:title>
 <dc:creator>Vu, Hoang Tran</dc:creator>
 <dc:creator>Huang, Ching-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In order to solve the unsupervised domain adaptation problem, some methods
based on adversarial learning are proposed recently. These methods greatly
attract people's eyes because of the better ability to learn the common
representation space so that the feature distributions among many domains are
ambiguous and non-discriminative. Although there are many discussions and
results, the success of the methods implicitly funds on the assumption that the
information of domains are fully transferrable. If the assumption is not
satisfied, the influence of negative transfer may degrade domain adaptation. In
this paper, we proposed to relieve the negative effects by not only adversarial
learning but also disentangled representation learning, and style transfer. In
detail, our architecture disentangles the learned features into common parts
and specific parts. The common parts represent the transferrable feature space,
whereas the specific parts characterize the unique style of each individual
domain. Moreover, we proposed to exchange specific feature parts across domains
for image style transfer. These designs allow us to introduce five types of
novel training objectives to enhance domain adaptation and realize style
transfer. In our experiments, we evaluated domain adaptation on two standard
digit data sets. The results show that our architecture can be adaptive well to
full transfer learning and partial transfer learning. As a side product, the
trained network also demonstrates high potential to generate style-transferred
images.
</dc:description>
 <dc:description>Comment: 21 pages, 9 figures, 3 tables</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09034</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimal Ordered Ramsey Graphs</dc:title>
 <dc:creator>Rollin, Jonathan</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C55</dc:subject>
 <dc:description>  An ordered graph is a graph equipped with a linear ordering of its vertex
set. A pair of ordered graphs is Ramsey finite if it has only finitely many
minimal ordered Ramsey graphs and Ramsey infinite otherwise. Here an ordered
graph F is an ordered Ramsey graph of a pair (H,H') of ordered graphs if for
any coloring of the edges of F in colors red and blue there is either a copy of
H with all edges colored red or a copy of H' with all edges colored blue. Such
an ordered Ramsey graph is minimal if neither of its proper subgraphs is an
ordered Ramsey graph of (H,H'). If H=H' then H itself is called Ramsey finite.
  We show that a connected ordered graph is Ramsey finite if and only if it is
a star with center being the first or the last vertex in the linear order. In
general we prove that each Ramsey finite (not necessarily connected) ordered
graph H has a pseudoforest as a Ramsey graph and therefore is a star forest
with strong restrictions on the positions of the centers of the stars. In the
asymmetric case we show that (H,H') is Ramsey finite whenever H is a so-called
monotone matching. Among several further results we show that there are Ramsey
finite pairs of ordered stars and ordered caterpillars of arbitrary size and
diameter. This is in contrast to the unordered setting where for any Ramsey
finite pair (H,H') of forests either one of H or H' is a matching or both are
star forests (with additional constraints).
  Several of our results give a relation between Ramsey finiteness and the
existence of sparse ordered Ramsey graphs. Motivated by these relations we
characterize all pairs of ordered graphs that have a forest as an ordered
Ramsey graph and all pairs of connected ordered graphs that have a pseudoforest
as a Ramsey graph.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09035</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Network Code for Adaptive and Active Attacks with No-Randomness
  in Intermediate Nodes</dc:title>
 <dc:creator>Cai, Ning</dc:creator>
 <dc:creator>Hayashi, Masahito</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We analyze the security for network code when the eavesdropper can
contaminate the information on the attacked edges (active attack) and can
choose the attacked edges adaptively (adaptive attack). We show that active and
adaptive attacks cannot improve the performance of the eavesdropper when the
code is linear. Further, we give an non-linear example, in which an adaptive
attack improves the performance of the eavesdropper. We derive the capacity for
the unicast case and the capacity region for the multicast case or the multiple
multicast case in several examples of relay networks, beyond the minimum cut
theorem, when no additional random number is allowed as scramble variables in
the intermediate nodes.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09037</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Phone Based Portable Field Sensor System for Real-Time In-situ
  River Water Quality Monitoring During Endangered Dolphin Monitoring Surveys</dc:title>
 <dc:creator>Manzoor, Sanaullah</dc:creator>
 <dc:creator>Ahmad, Farhan</dc:creator>
 <dc:creator>Mazhar, Suleman</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Mobile phone based potable water quality assessment device is developed to
analyze and study water pollution level at Indus river. Indus river is habitat
of endangered Indus river dolphin and water pollution is one of major causes of
survivability threats for this specie. We tested device performance at the six
locations of Lahore canal. pH of canal water deviates from the normal range of
the irrigation water. In future, we will study correlation between water
pollution level and habitat usage of Indus river dolphin using water quality
assessment device and hydrophone array based passive acoustic monitoring (PAM)
system.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09043</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Collaborative Autoencoder for Recommender Systems: A Unified
  Framework for Explicit and Implicit Feedback</dc:title>
 <dc:creator>Li, Qibing</dc:creator>
 <dc:creator>Zheng, Xiaolin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In recent years, deep neural networks have yielded state-of-the-art
performance on several tasks. Although some recent works have focused on
combining deep learning with recommendation, we highlight three issues of
existing works. First, most works perform deep content feature learning and
resort to matrix factorization, which cannot effectively model the highly
complex user-item interaction function. Second, due to the difficulty on
training deep neural networks, existing models utilize a shallow architecture,
and thus limit the expressiveness potential of deep learning. Third, neural
network models are easy to overfit on the implicit setting, because negative
interactions are not taken into account. To tackle these issues, we present a
novel recommender framework called Deep Collaborative Autoencoder (DCAE) for
both explicit feedback and implicit feedback, which can effectively capture the
relationship between interactions via its non-linear expressiveness. To
optimize the deep architecture of DCAE, we develop a three-stage pre-training
mechanism that combines supervised and unsupervised feature learning. Moreover,
we propose a popularity-based error reweighting module and a sparsity-aware
data-augmentation strategy for DCAE to prevent overfitting on the implicit
setting. Extensive experiments on three real-world datasets demonstrate that
DCAE can significantly advance the state-of-the-art.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09048</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Image Cropping for Visual Aesthetic Enhancement Using Deep
  Neural Networks and Cascaded Regression</dc:title>
 <dc:creator>Guo, Guanjun</dc:creator>
 <dc:creator>Wang, Hanzi</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Yan, Yan</dc:creator>
 <dc:creator>Liao, Hong-Yuan Mark</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite recent progress, computational visual aesthetic is still challenging.
Image cropping, which refers to the removal of unwanted scene areas, is an
important step to improve the aesthetic quality of an image. However, it is
challenging to evaluate whether cropping leads to aesthetically pleasing
results because the assessment is typically subjective. In this paper, we
propose a novel cascaded cropping regression (CCR) method to perform image
cropping by learning the knowledge from professional photographers. The
proposed CCR method improves the convergence speed of the cascaded method,
which directly uses random-ferns regressors. In addition, a two-step learning
strategy is proposed and used in the CCR method to address the problem of
lacking labelled cropping data. Specifically, a deep convolutional neural
network (CNN) classifier is first trained on large-scale visual aesthetic
datasets. The deep CNN model is then designed to extract features from several
image cropping datasets, upon which the cropping bounding boxes are predicted
by the proposed CCR method. Experimental results on public image cropping
datasets demonstrate that the proposed method significantly outperforms several
state-of-the-art image cropping methods.
</dc:description>
 <dc:description>Comment: 13 pages, 13 figures, To appear in IEEE Transactions on Multimedia,
  2017</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09052</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PWCT: Visual Language for IoT and Cloud Computing Applications and
  Systems</dc:title>
 <dc:creator>Fayed, Mahmoud S.</dc:creator>
 <dc:creator>Al-Qurishi, Muhammad</dc:creator>
 <dc:creator>Alamri, Atif</dc:creator>
 <dc:creator>Al-Daraiseh, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Developing IoT, Data Computing and Cloud Computing software requires
different programming skills and different programming languages. This cause a
problem for many companies and researchers that need to hires many programmers
to develop a complete solution. The problem is related directly to the
financial cost and the development time which are very important factors to
many research projects. In this paper we present and propose the PWCT visual
programming tool for developing IoT, Data Computing and Cloud Computing
Applications and Systems without writing textual code directly. Using PWCT
increase productivity and provide researchers with one visual programming tool
to develop different solutions.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09059</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Long and Short-term Information in Content-aware Movie
  Recommendation</dc:title>
 <dc:creator>Zhao, Wei</dc:creator>
 <dc:creator>Wang, Benyou</dc:creator>
 <dc:creator>Ye, Jianbo</dc:creator>
 <dc:creator>Gao, Yongqiang</dc:creator>
 <dc:creator>Yang, Min</dc:creator>
 <dc:creator>Zhao, Zhou</dc:creator>
 <dc:creator>Chen, Xiaojun</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Movie recommendation systems provide users with ranked lists of movies based
on individual's preferences and constraints. Two types of models are commonly
used to generate ranking results: long-term models and session-based models.
While long-term models represent the interactions between users and movies that
are supposed to change slowly across time, session-based models encode the
information of users' interests and changing dynamics of movies' attributes in
short terms. In this paper, we propose an LSIC model, leveraging Long and
Short-term Information in Content-aware movie recommendation using adversarial
training. In the adversarial process, we train a generator as an agent of
reinforcement learning which recommends the next movie to a user sequentially.
We also train a discriminator which attempts to distinguish the generated list
of movies from the real records. The poster information of movies is integrated
to further improve the performance of movie recommendation, which is
specifically essential when few ratings are available. The experiments
demonstrate that the proposed model has robust superiority over competitors and
sets the state-of-the-art. We will release the source code of this work after
publication.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09061</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal detection and error exponents for hidden multi-state processes
  via random duration model approach</dc:title>
 <dc:creator>Bajovi&#x107;, Dragana</dc:creator>
 <dc:creator>He, Kanghang</dc:creator>
 <dc:creator>Stankovi&#x107;, Lina</dc:creator>
 <dc:creator>Vukobratovi&#x107;, Dejan</dc:creator>
 <dc:creator>Stankovi&#x107;, Vladimir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study detection of random signals corrupted by noise that over time switch
their values (states) from a finite set of possible values, where the
switchings occur at unknown points in time. We model such signals by means of a
random duration model that to each possible state assigns a probability mass
function which controls the statistics of durations of that state occurrences.
Assuming two possible signal states and Gaussian noise, we derive optimal
likelihood ratio test and show that it has a computationally tractable form of
a matrix product, with the number of matrices involved in the product being the
number of process observations. Each matrix involved in the product is of
dimension equal to the sum of durations spreads of the two states, and it can
be decomposed as a product of a diagonal random matrix controlled by the
process observations and a sparse constant matrix which governs transitions in
the sequence of states. Using this result, we show that the Neyman-Pearson
error exponent is equal to the top Lyapunov exponent for the corresponding
random matrices. Using theory of large deviations, we derive a lower bound on
the error exponent. Finally, we show that this bound is tight by means of
numerical simulations.
</dc:description>
 <dc:description>Comment: 36 pages, 7 figures, submitted</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09078</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Blind Image Inpainting</dc:title>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Pan, Jinshan</dc:creator>
 <dc:creator>Su, Zhixun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image inpainting is a challenging problem as it needs to fill the information
of the corrupted regions. Most of the existing inpainting algorithms assume
that the positions of the corrupted regions are known. Different from the
existing methods that usually make some assumptions on the corrupted regions,
we present an efficient blind image inpainting algorithm to directly restore a
clear image from a corrupted input. Our algorithm is motivated by the residual
learning algorithm which aims to learn the missing infor- mation in corrupted
regions. However, directly using exist- ing residual learning algorithms in
image restoration does not well solve this problem as little information is
available in the corrupted regions. To solve this problem, we introduce an
encoder and decoder architecture to capture more useful information and develop
a robust loss function to deal with outliers. Our algorithm can predict the
missing information in the corrupted regions, thus facilitating the clear image
restoration. Both qualitative and quantitative experimental demonstrate that
our algorithm can deal with the corrupted regions of arbitrary shapes and
performs favorably against state-of-the-art methods.
</dc:description>
 <dc:description>Comment: conference, 9 pages, 10 figures</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09082</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guesswork Subject to a Total Entropy Budget</dc:title>
 <dc:creator>Rezaee, Arman</dc:creator>
 <dc:creator>Beirami, Ahmad</dc:creator>
 <dc:creator>Makhdoumi, Ali</dc:creator>
 <dc:creator>Medard, Muriel</dc:creator>
 <dc:creator>Duffy, Ken</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We consider an abstraction of computational security in password protected
systems where a user draws a secret string of given length with i.i.d.
characters from a finite alphabet, and an adversary would like to identify the
secret string by querying, or guessing, the identity of the string. The concept
of a &quot;total entropy budget&quot; on the chosen word by the user is natural,
otherwise the chosen password would have arbitrary length and complexity. One
intuitively expects that a password chosen from the uniform distribution is
more secure. This is not the case, however, if we are considering only the
average guesswork of the adversary when the user is subject to a total entropy
budget. The optimality of the uniform distribution for the user's secret string
holds when we have also a budget on the guessing adversary. We suppose that the
user is subject to a &quot;total entropy budget&quot; for choosing the secret string,
whereas the computational capability of the adversary is determined by his
&quot;total guesswork budget.&quot; We study the regime where the adversary's chances are
exponentially small in guessing the secret string chosen subject to a total
entropy budget. We introduce a certain notion of uniformity and show that a
more uniform source will provide better protection against the adversary in
terms of his chances of success in guessing the secret string. In contrast, the
average number of queries that it takes the adversary to identify the secret
string is smaller for the more uniform secret string subject to the same total
entropy budget.
</dc:description>
 <dc:description>Comment: In Proc. of Allerton 2017 (19 pages, 4 figures)</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09090</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Recursive Construction for Coded Caching Schemes</dc:title>
 <dc:creator>Cheng, Minquan</dc:creator>
 <dc:creator>Jiang, Jing</dc:creator>
 <dc:creator>Yao, Youzhi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  As a strategy to further reduce the transmission pressure during the peak
traffic times in wireless network, coded caching has been widely studied
recently. And several coded caching schemes are constructed focusing on the two
core problems in practice, i.e., the rate transmitted during the peak traffic
times and the packet number of each file divided during the off peak traffic
times. It is well known that there exits a tradeoff between the rate and the
packet number. In this paper, a novel recursive construction is proposed. As an
application, several new schemes are obtained. Comparing with previously known
schemes, new schemes could further reduce packet number by increasing little
rate. And for some parameters in coded caching systems, the packet number of
our new schemes are smaller than that of schemes generated by memory sharing
method which is widely used in the field of caching. By the way our new schemes
include all the results constructed by Tang et al., (IEEE ISIT, 2790-2794,
2017) as special cases.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09093</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brain Tumor Segmentation Based on Refined Fully Convolutional Neural
  Networks with A Hierarchical Dice Loss</dc:title>
 <dc:creator>Zhang, Jiachi</dc:creator>
 <dc:creator>Shen, Xiaolei</dc:creator>
 <dc:creator>Zhuo, Tianqi</dc:creator>
 <dc:creator>Zhou, Hong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As a basic task in computer vision, semantic segmentation can provide
fundamental information for object detection and instance segmentation to help
the artificial intelligence better understand real world. Since the proposal of
fully convolutional neural network (FCNN), it has been widely used in semantic
segmentation because of its high accuracy of pixel-wise classification as well
as high precision of localization. In this paper, we apply several famous FCNN
to brain tumor segmentation, making comparisons and adjusting network
architectures to achieve better performance measured by metrics such as
precision, recall, mean of intersection of union (mIoU) and dice score
coefficient (DSC). The adjustments to the classic FCNN include adding more
connections between convolutional layers, enlarging decoders after up sample
layers and changing the way shallower layers' information is reused. Besides
the structure modification, we also propose a new classifier with a
hierarchical dice loss. Inspired by the containing relationship between
classes, the loss function converts multiple classification to multiple binary
classification in order to counteract the negative effect caused by imbalance
data set. Massive experiments have been done on the training set and testing
set in order to assess our refined fully convolutional neural networks and new
types of loss function. Competitive figures prove they are more effective than
their predecessors.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures, 6 tables</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09097</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Connecting Stochastic Gradient MCMC and Differential Privacy</dc:title>
 <dc:creator>Li, Bai</dc:creator>
 <dc:creator>Chen, Changyou</dc:creator>
 <dc:creator>Liu, Hao</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Significant success has been realized recently on applying machine learning
to real-world applications. There have also been corresponding concerns on the
privacy of training data, which relates to data security and confidentiality
issues. Differential privacy provides a principled and rigorous privacy
guarantee on machine learning models. While it is common to design a model
satisfying a required differential-privacy property by injecting noise, it is
generally hard to balance the trade-off between privacy and utility. We show
that stochastic gradient Markov chain Monte Carlo (SG-MCMC) -- a class of
scalable Bayesian posterior sampling algorithms proposed recently -- satisfies
strong differential privacy with carefully chosen step sizes. We develop theory
on the performance of the proposed differentially-private SG-MCMC method. We
conduct experiments to support our analysis and show that a standard SG-MCMC
sampler without any modification (under a default setting) can reach
state-of-the-art performance in terms of both privacy and utility on Bayesian
learning.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09098</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SoA-Fog: Secure Service-Oriented Edge Computing Architecture for Smart
  Health Big Data Analytics</dc:title>
 <dc:creator>Barik, Rabindra K.</dc:creator>
 <dc:creator>Dubey, Harishchandra</dc:creator>
 <dc:creator>Mankodiya, Kunal</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The smart health paradigms employ Internet-connected wearables for
telemonitoring, diagnosis for providing inexpensive healthcare solutions. Fog
computing reduces latency and increases throughput by processing data near the
body sensor network. In this paper, we proposed a secure serviceorientated edge
computing architecture that is validated on recently released public dataset.
Results and discussions support the applicability of proposed architecture for
smart health applications. We proposed SoA-Fog i.e. a three-tier secure
framework for efficient management of health data using fog devices. It discuss
the security aspects in client layer, fog layer and the cloud layer. We design
the prototype by using win-win spiral model with use case and sequence diagram.
Overlay analysis was performed using proposed framework on malaria vector borne
disease positive maps of Maharastra state in India from 2011 to 2014. The
mobile clients were taken as test case. We performed comparative analysis
between proposed secure fog framework and state-of-the art cloud-based
framework.
</dc:description>
 <dc:description>Comment: 6 pages, 2 Figures, 1 Table. 5th IEEE Global Conference on Signal and
  Information Processing GlobalSIP 2017, November 14-16, 2017, Montreal, Canada</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09104</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Density-aware Dynamic Mobile Networks: Opportunities and Challenges</dc:title>
 <dc:creator>Onur, Ertan</dc:creator>
 <dc:creator>Mollahasani, Shahram</dc:creator>
 <dc:creator>Ero&#x11f;lu, Alperen</dc:creator>
 <dc:creator>Moftakhar, Nina Razi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We experience a major paradigm change in mobile networks. The infrastructure
of cellular networks becomes mobile as it is densified by using mobile and
nomadic small cells to increase coverage and capacity. Furthermore, the
innovative approaches such as green operation through sleep scheduling,
user-controlled small cells, and end-to-end slicing will make the network
highly dynamic. Mobile cells, while bringing many benefits, introduce many
unconventional challenges that we present in this paper. We have to introduce
novel techniques for adapting network functions, communication protocols and
their parameters to network density. Especially when cells on wheels or wings
are considered, static and man-made configurations will waste valuable
resources such as spectrum or energy if density is not considered as an
optimization parameter. In this paper, we present the existing density
estimators. We analyze the impact of density on coverage, interference,
mobility management, scalability, capacity, caching, routing protocols and
energy consumption. We evaluate nomadic cells in dynamic networks in a
comprehensive way and illustrate the potential objectives we can achieve by
adapting mobile networks to base station density. The main challenges we may
face by employing dynamic networks and how we can tackle these problems are
discussed in detail.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09117</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overcomplete Frame Thresholding for Acoustic Scene Analysis</dc:title>
 <dc:creator>Cosentino, Romain</dc:creator>
 <dc:creator>Balestriero, Randall</dc:creator>
 <dc:creator>Baraniuk, Richard</dc:creator>
 <dc:creator>Patel, Ankit</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work, we derive a generic overcomplete frame thresholding scheme
based on risk minimization. Overcomplete frames being favored for analysis
tasks such as classification, regression or anomaly detection, we provide a way
to leverage those optimal representations in real-world applications through
the use of thresholding. We validate the method on a large scale bird activity
detection task via the scattering network architecture performed by means of
continuous wavelets, known for being an adequate dictionary in audio
environments.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09121</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Distributed Algorithms for Exact Shortest Paths</dc:title>
 <dc:creator>Ghaffari, Mohsen</dc:creator>
 <dc:creator>Li, Jason</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Computing shortest paths is one of the central problems in the theory of
distributed computing. For the last few years, substantial progress has been
made on the approximate single source shortest paths problem, culminating in an
algorithm of Becker et al. [DISC'17] which deterministically computes
$(1+o(1))$-approximate shortest paths in $\tilde O(D+\sqrt n)$ time, where $D$
is the hop-diameter of the graph. Up to logarithmic factors, this time
complexity is optimal, matching the lower bound of Das Sarma et al. [STOC'11].
  The question of exact shortest paths however saw no algorithmic progress for
decades, until the recent breakthrough of Elkin [STOC'17], which established a
sublinear-time algorithm for exact single source shortest paths on undirected
graphs. Shortly after, Huang et al. [FOCS'17] provided improved algorithms for
exact all pairs shortest paths problem on directed graphs.
  In this paper, we present a new single-source shortest path algorithm with
complexity $\tilde O(n^{3/4}D^{1/4})$. For polylogarithmic $D$, this improves
on Elkin's $\tilde{O}(n^{5/6})$ bound and gets closer to the
$\tilde{\Omega}(n^{1/2})$ lower bound of Peleg and Rubinovich [FOCS'99]. For
larger values of $D$, we present an improved variant of our algorithm which
achieves complexity $\tilde{O}\left( n^{3/4+o(1)}+ \min\{
n^{3/4}D^{1/6},n^{6/7}\}+D\right)$, and thus compares favorably with Elkin's
bound of $\tilde{O}(n^{5/6} + n^{2/3}D^{1/3} + D ) $ in essentially the entire
range of parameters. This algorithm provides also a qualitative improvement,
because it works for the more challenging case of directed graphs (i.e., graphs
where the two directions of an edge can have different weights), constituting
the first sublinear-time algorithm for directed graphs. Our algorithm also
extends to the case of exact $\kappa$-source shortest paths...
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09123</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SAGA: A Submodular Greedy Algorithm For Group Recommendation</dc:title>
 <dc:creator>Parambath, Shameem A Puthiya</dc:creator>
 <dc:creator>Vijayakumar, Nishant</dc:creator>
 <dc:creator>Chawla, Sanjay</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose a unified framework and an algorithm for the
problem of group recommendation where a fixed number of items or alternatives
can be recommended to a group of users. The problem of group recommendation
arises naturally in many real world contexts, and is closely related to the
budgeted social choice problem studied in economics. We frame the group
recommendation problem as choosing a subgraph with the largest group consensus
score in a completely connected graph defined over the item affinity matrix. We
propose a fast greedy algorithm with strong theoretical guarantees, and show
that the proposed algorithm compares favorably to the state-of-the-art group
recommendation algorithms according to commonly used relevance and coverage
performance measures on benchmark dataset.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09124</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gender differences in beliefs about algorithmic fairness</dc:title>
 <dc:creator>Pierson, Emma</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The field of algorithmic fairness has highlighted ethical questions which may
not have purely technical answers. For example, different algorithmic fairness
constraints are often impossible to satisfy simultaneously, and choosing
between them requires value judgments about which people may disagree. Here we
investigate whether people's beliefs about algorithmic fairness correlate with
their demographic backgrounds, a question of interest because computer science
is demographically non-representative. If beliefs about algorithmic fairness
correlate with demographics, and algorithm designers are demographically
non-representative, decisions made about algorithmic fairness may not reflect
the will of the population as a whole. We show in two separate surveys that
gender correlates with beliefs about algorithmic fairness. For example, women
are significantly less likely to favor including gender as a feature in an
algorithm which recommends courses to students if doing so would make female
students less likely to be recommended science courses.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09127</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Adversarial Nets for Multiple Text Corpora</dc:title>
 <dc:creator>Wang, Baiyang</dc:creator>
 <dc:creator>Klabjan, Diego</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Generative adversarial nets (GANs) have been successfully applied to the
artificial generation of image data. In terms of text data, much has been done
on the artificial generation of natural language from a single corpus. We
consider multiple text corpora as the input data, for which there can be two
applications of GANs: (1) the creation of consistent cross-corpus word
embeddings given different word embeddings per corpus; (2) the generation of
robust bag-of-words document embeddings for each corpora. We demonstrate our
GAN models on real-world text data sets from different corpora, and show that
embeddings from both models lead to improvements in supervised learning
problems.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09131</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Random Block-Coordinate Douglas-Rachford Splitting Method with Low
  Computational Complexity for Binary Logistic Regression</dc:title>
 <dc:creator>Briceno-Arias, Luis M.</dc:creator>
 <dc:creator>Chierchia, Giovanni</dc:creator>
 <dc:creator>Chouzenoux, Emilie</dc:creator>
 <dc:creator>Pesquet, Jean-Christophe</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we propose a new optimization algorithm for sparse logistic
regression based on a stochastic version of the Douglas-Rachford splitting
method. Our algorithm sweeps the training set by randomly selecting a
mini-batch of data at each iteration, and it allows us to update the variables
in a block coordinate manner. Our approach leverages the proximity operator of
the logistic loss, which is expressed with the generalized Lambert W function.
Experiments carried out on standard datasets demonstrate the efficiency of our
approach w.r.t. stochastic gradient-like methods.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09133</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strongly Hierarchical Factorization Machines and ANOVA Kernel Regression</dc:title>
 <dc:creator>Guo, Ruocheng</dc:creator>
 <dc:creator>Alvari, Hamidreza</dc:creator>
 <dc:creator>Shakarian, Paulo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  High-order parametric models that include terms for feature interactions are
applied to various data mining tasks, where ground truth depends on
interactions of features. However, with sparse data, the high- dimensional
parameters for feature interactions often face three issues: expensive
computation, difficulty in parameter estimation and lack of structure. Previous
work has proposed approaches which can partially re- solve the three issues. In
particular, models with factorized parameters (e.g. Factorization Machines) and
sparse learning algorithms (e.g. FTRL-Proximal) can tackle the first two issues
but fail to address the third. Regarding to unstructured parameters,
constraints or complicated regularization terms are applied such that
hierarchical structures can be imposed. However, these methods make the
optimization problem more challenging. In this work, we propose Strongly
Hierarchical Factorization Machines and ANOVA kernel regression where all the
three issues can be addressed without making the optimization problem more
difficult. Experimental results show the proposed models significantly
outperform the state-of-the-art in two data mining tasks: cold-start user
response time prediction and stock volatility prediction.
</dc:description>
 <dc:description>Comment: 9 pages, to appear in SDM'18</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09136</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Measuring Membership Privacy</dc:title>
 <dc:creator>Long, Yunhui</dc:creator>
 <dc:creator>Bindschaedler, Vincent</dc:creator>
 <dc:creator>Gunter, Carl A.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Machine learning models are increasingly made available to the masses through
public query interfaces. Recent academic work has demonstrated that malicious
users who can query such models are able to infer sensitive information about
records within the training data. Differential privacy can thwart such attacks,
but not all models can be readily trained to achieve this guarantee or to
achieve it with acceptable utility loss. As a result, if a model is trained
without differential privacy guarantee, little is known or can be said about
the privacy risk of releasing it. In this work, we investigate and analyze
membership attacks to understand why and how they succeed. Based on this
understanding, we propose Differential Training Privacy (DTP), an empirical
metric to estimate the privacy risk of publishing a classier when methods such
as differential privacy cannot be applied. DTP is a measure of a classier with
respect to its training dataset, and we show that calculating DTP is efficient
in many practical cases. We empirically validate DTP using state-of-the-art
machine learning models such as neural networks trained on real-world datasets.
Our results show that DTP is highly predictive of the success of membership
attacks and therefore reducing DTP also reduces the privacy risk. We advocate
for DTP to be used as part of the decision-making process when considering
publishing a classifier. To this end, we also suggest adopting the DTP-1
hypothesis: if a classifier has a DTP value above 1, it should not be
published.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09145</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Provably Secure Ring Signature Scheme in Certificateless Cryptography</dc:title>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:creator>Zhang, Futai</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Ring signature is a kind of group-oriented signature. It allows a member of a
group to sign messages on behalf of the group without revealing his/her
identity. Certificateless public key cryptography was first introduced by
Al-Riyami and Paterson in Asiacrypt 2003. In certificateless cryptography, it
does not require the use of certificates to guarantee the authenticity of
users' public keys. Meanwhile, certificateless cryptography does not have the
key escrow problem, which seems to be inherent in the Identity-based
cryptography. In this paper, we propose a concrete certificateless ring
signature scheme. The security models of certificateless ring signature are
also formalized. Our new scheme is provably secure in the random oracle model,
with the assumption that the Computational Diffie-Hellman problem is hard. In
addition, we also show that a generic construction of certificateless ring
signature is insecure against the key replacement attack defined in our
security models.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09152</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Technical Report on Deploying a highly secured OpenStack Cloud
  Infrastructure using BradStack as a Case Study</dc:title>
 <dc:creator>Mohammed, Bashir</dc:creator>
 <dc:creator>Moyo, Sibusiso</dc:creator>
 <dc:creator>Maiyama, K. M</dc:creator>
 <dc:creator>Kinteh, Sulayman</dc:creator>
 <dc:creator>Al-Shaidy, Al Noaman M. K.</dc:creator>
 <dc:creator>Kamala, M. A.</dc:creator>
 <dc:creator>Kiran, M.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Cloud computing has emerged as a popular paradigm and an attractive model for
providing a reliable distributed computing model.it is increasing attracting
huge attention both in academic research and industrial initiatives. Cloud
deployments are paramount for institution and organizations of all scales. The
availability of a flexible, free open source cloud platform designed with no
propriety software and the ability of its integration with legacy systems and
third-party applications are fundamental. Open stack is a free and opensource
software released under the terms of Apache license with a fragmented and
distributed architecture making it highly flexible. This project was initiated
and aimed at designing a secured cloud infrastructure called BradStack, which
is built on OpenStack in the Computing Laboratory at the University of
Bradford. In this report, we present and discuss the steps required in
deploying a secured BradStack Multi-node cloud infrastructure and conducting
Penetration testing on OpenStack Services to validate the effectiveness of the
security controls on the BradStack platform. This report serves as a practical
guideline, focusing on security and practical infrastructure related issues. It
also serves as a reference for institutions looking at the possibilities of
implementing a secured cloud solution.
</dc:description>
 <dc:description>Comment: 38 pages, 19 figures,</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09153</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Meta Learning for Real-Time Visual Tracking based on
  Target-Specific Feature Space</dc:title>
 <dc:creator>Choi, Janghoon</dc:creator>
 <dc:creator>Kwon, Junseok</dc:creator>
 <dc:creator>Lee, Kyoung Mu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel on-line visual tracking framework based on
Siamese matching network and meta-learner network which runs at real-time
speed. Conventional deep convolutional feature based discriminative visual
tracking algorithms require continuous re-training of classifiers or
correlation filters for solving complex optimization tasks to adapt to the new
appearance of a target object. To remove this process, our proposed algorithm
incorporates and utilizes a meta-learner network to provide the matching
network with new appearance information of the target object by adding the
target-aware feature space. The parameters for the target-specific feature
space are provided instantly from a single forward-pass of the meta-learner
network. By eliminating the necessity of continuously solving the complex
optimization tasks in the course of tracking, experimental results demonstrate
that our algorithm performs at a real-time speed of $62$ fps while maintaining
a competitive performance among other state-of-the-art tracking algorithms.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09158</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matching model of flow table for networked big data</dc:title>
 <dc:creator>Su, Yiheng</dc:creator>
 <dc:creator>Peng, Ting</dc:creator>
 <dc:creator>Zhong, Xiaoxun</dc:creator>
 <dc:creator>Zhang, Lianming</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Networking for big data has to be intelligent because it will adjust data
transmission requirements adaptively during data splitting and merging.
Software-defined networking (SDN) provides a workable and practical paradigm
for designing more efficient and flexible networks. Matching strategy in the
flow table of SDN switches is most crucial. In this paper, we use a
classification approach to analyze the structure of packets based on the
tuple-space lookup mechanism, and propose a matching model of the flow table in
SDN switches by classifying packets based on a set of fields, which is called
an F-OpenFlow. The experiment results show that the proposed F-OpenFlow
effectively improves the utilization rate and matching efficiency of the flow
table in SDN switches for networked big data.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09159</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Transmission for Physical Layer Security by Exploring Social
  Awareness</dc:title>
 <dc:creator>Xu, Yiming</dc:creator>
 <dc:creator>Wang, Hui-Ming</dc:creator>
 <dc:creator>Yang, Qian</dc:creator>
 <dc:creator>Huang, Ke-Wen</dc:creator>
 <dc:creator>Zheng, Tong-Xing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Social awareness and social ties are becoming increasingly fashionable with
emerging mobile and handheld devices. Social trust degree describing the
strength of the social ties has drawn lots of research interests in many fields
including secure cooperative communications. Such trust degree reflects the
users' willingness for cooperation, which impacts the selection of the
cooperative users in the practical networks. In this paper, we propose a
cooperative relay and jamming selection scheme to secure communication based on
the social trust degree under a stochastic geometry framework. We aim to
analyze the involved secrecy outage probability (SOP) of the system's
performance. To achieve this target, we propose a double Gamma ratio (DGR)
approach through Gamma approximation. Based on this, the SOP is tractably
obtained in closed form. The simulation results verify our theoretical
findings, and validate that the social trust degree has dramatic influences on
the network's secrecy performance.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, IEEE GLOBECOM 2017 Conference</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09161</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmenting Sky Pixels in Images</dc:title>
 <dc:creator>La Place, Cecilia</dc:creator>
 <dc:creator>Khan, Aisha Urooj</dc:creator>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Outdoor scene parsing models are often trained on ideal datasets and produce
quality results. However, this leads to a discrepancy when applied to the real
world. The quality of scene parsing, particularly sky classification, decreases
in night time images, images involving varying weather conditions, and scene
changes due to seasonal weather. This project focuses on approaching these
challenges by using a state-of-the-art model in conjunction with a non-ideal
dataset: SkyFinder and a subset from SUN database with Sky object. We focus
specifically on sky segmentation, the task of determining sky and not-sky
pixels, and improving upon an existing state-of-the-art model: RefineNet. As a
result of our efforts, we have seen an improvement of 10-15% in the average MCR
compared to the prior methods on SkyFinder dataset. We have also improved from
an off-the shelf-model in terms of average mIOU by nearly 35%. Further, we
analyze our trained models on images w.r.t two aspects: times of day and
weather, and find that, in spite of facing same challenges as prior methods,
our trained models significantly outperform them.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09162</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>REDBEE: A Visual-Inertial Drone System for Real-Time Moving Object
  Detection</dc:title>
 <dc:creator>Huang, Chong</dc:creator>
 <dc:creator>Chen, Peng</dc:creator>
 <dc:creator>Yang, Xin</dc:creator>
 <dc:creator>Kwang-Ting</dc:creator>
 <dc:creator>Cheng</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Aerial surveillance and monitoring demand both real-time and robust motion
detection from a moving camera. Most existing techniques for drones involve
sending a video data streams back to a ground station with a high-end desktop
computer or server. These methods share one major drawback: data transmission
is subjected to considerable delay and possible corruption. Onboard computation
can not only overcome the data corruption problem but also increase the range
of motion. Unfortunately, due to limited weight-bearing capacity, equipping
drones with computing hardware of high processing capability is not feasible.
Therefore, developing a motion detection system with real-time performance and
high accuracy for drones with limited computing power is highly desirable. In
this paper, we propose a visual-inertial drone system for real-time motion
detection, namely REDBEE, that helps overcome challenges in shooting scenes
with strong parallax and dynamic background. REDBEE, which can run on the
state-of-the-art commercial low-power application processor (e.g. Snapdragon
Flight board used for our prototype drone), achieves real-time performance with
high detection accuracy. The REDBEE system overcomes obstacles in shooting
scenes with strong parallax through an inertial-aided dual-plane homography
estimation; it solves the issues in shooting scenes with dynamic background by
distinguishing the moving targets through a probabilistic model based on
spatial, temporal, and entropy consistency. The experiments are presented which
demonstrate that our system obtains greater accuracy when detecting moving
targets in outdoor environments than the state-of-the-art real-time onboard
detection systems.
</dc:description>
 <dc:description>Comment: 8 pages, IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS 2017)</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09163</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer Algebra Methods in Control Systems</dc:title>
 <dc:creator>Abbaszadeh, Masoud</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>15A60, 37M99</dc:subject>
 <dc:subject>B.1.1</dc:subject>
 <dc:subject>B.1.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.1.3</dc:subject>
 <dc:subject>I.1.4</dc:subject>
 <dc:description>  As dynamic and control systems become more complex, relying purely on
numerical computations for systems analysis and design might become extremely
expensive or totally infeasible. Computer algebra can act as an enabler for
analysis and design of such complex systems. It also provides means for
characterization of all solutions and studying them before realizing a
particular solution. This note provides a brief survey on some of the
applications of symbolic computations in control systems analysis and design.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09166</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-linear Time Algorithms for Approximate Minimum Degree Spanning
  Trees</dc:title>
 <dc:creator>Duan, Ran</dc:creator>
 <dc:creator>He, Haoqing</dc:creator>
 <dc:creator>Zhang, Tianyi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Given a graph $G = (V, E)$, $n=|V|, m=|E|$, we wish to compute a spanning
tree whose maximum vertex degree is as small as possible. Computing the exact
optimal solution is known to be NP-hard, since it generalizes the Hamiltonian
path problem. For the approximation version of this problem, a $\tilde{O}(mn)$
time algorithm that computes a spanning tree of degree at most $\Delta^* +1$ is
previously known [F\&quot;urer, Raghavachari 1994]; here $\Delta^*$ denotes the
optimal tree degree. In this paper we give the first near-linear time algorithm
for this problem. Specifically speaking, we first propose a simple
$\tilde{O}(m)$ time algorithm that achieves an $O(\Delta^*\log n)$
approximation; then we further improve this algorithm to obtain a
$(1+\delta)\Delta^* + O(\frac{1}{\delta^2}\log n)$ approximation in
$\tilde{O}(\frac{1}{\delta^6}m)$ time.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09168</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-throughput Binding Affinity Calculations at Extreme Scales</dc:title>
 <dc:creator>Dakka, Jumana</dc:creator>
 <dc:creator>Turilli, Matteo</dc:creator>
 <dc:creator>Wright, David W</dc:creator>
 <dc:creator>Zasada, Stefan J</dc:creator>
 <dc:creator>Balasubramanian, Vivek</dc:creator>
 <dc:creator>Wan, Shunzhou</dc:creator>
 <dc:creator>Coveney, Peter V</dc:creator>
 <dc:creator>Jha, Shantenu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Resistance to chemotherapy and molecularly targeted therapies is a major
factor in limiting the effectiveness of cancer treatment. In many cases,
resistance can be linked to genetic changes in target proteins, either
pre-existing or evolutionarily selected during treatment. Key to overcoming
this challenge is an understanding of the molecular determinants of drug
binding. Using multi-stage pipelines of molecular simulations we can gain
insights into the binding free energy and the residence time of a ligand, which
can inform both stratified and personal treatment regimes and drug development.
To support the scalable, adaptive and automated calculation of the binding free
energy on high-performance computing resources, we introduce the High-
throughput Binding Affinity Calculator (HTBAC). HTBAC uses a building block
approach in order to attain both workflow flexibility and performance. We
demonstrate close to perfect weak scaling to hundreds of concurrent multi-stage
binding affinity calculation pipelines. This permits a rapid time-to-solution
that is essentially invariant of the calculation protocol, size of candidate
ligands and number of ensemble simulations. As such, HTBAC advances the state
of the art of binding affinity calculations and protocols.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09183</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of the Prodromal Phase of Bipolar Disorder from Psychological
  and Phonological Aspects in Social Media</dc:title>
 <dc:creator>Huang, Yen-Hao</dc:creator>
 <dc:creator>Wei, Lin-Hung</dc:creator>
 <dc:creator>Chen, Yi-Shin</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Seven out of ten people with bipolar disorder are initially misdiagnosed and
thirty percent of individuals with bipolar disorder will commit suicide.
Identifying the early phases of the disorder is one of the key components for
reducing the full development of the disorder. In this study, we aim at
leveraging the data from social media to design predictive models, which
utilize the psychological and phonological features, to determine the onset
period of bipolar disorder and provide insights on its prodrome. This study
makes these discoveries possible by employing a novel data collection process,
coined as Time-specific Subconscious Crowdsourcing, which helps collect a
reliable dataset that supplements diagnosis information from people suffering
from bipolar disorder. Our experimental results demonstrate that the proposed
models could greatly contribute to the regular assessments of people with
bipolar disorder, which is important in the primary care setting.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09184</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detect-and-Track: Efficient Pose Estimation in Videos</dc:title>
 <dc:creator>Girdhar, Rohit</dc:creator>
 <dc:creator>Gkioxari, Georgia</dc:creator>
 <dc:creator>Torresani, Lorenzo</dc:creator>
 <dc:creator>Paluri, Manohar</dc:creator>
 <dc:creator>Tran, Du</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the problem of estimating and tracking human body
keypoints in complex, multi-person video. We propose an extremely lightweight
yet highly effective approach that builds upon the latest advancements in human
detection and video understanding. Our method operates in two-stages: keypoint
estimation in frames or short clips, followed by lightweight tracking to
generate keypoint predictions linked over the entire video. For frame-level
pose estimation we experiment with Mask R-CNN, as well as our own proposed 3D
extension of this model, which leverages temporal information over small clips
to generate more robust frame predictions. We conduct extensive ablative
experiments on the newly released multi-person video pose estimation benchmark,
PoseTrack, to validate various design choices of our model. Our approach
achieves an accuracy of 55.2% on the validation and 51.8% on the test set using
the Multi-Object Tracking Accuracy (MOTA) metric, and achieves state of the art
performance on the ICCV 2017 PoseTrack keypoint tracking challenge.
</dc:description>
 <dc:description>Comment: Ranked first in ICCV 2017 PoseTrack challenge (keypoint tracking in
  videos)</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09185</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Actionable Email Intent Modeling with Reparametrized RNNs</dc:title>
 <dc:creator>Lin, Chu-Cheng</dc:creator>
 <dc:creator>Kang, Dongyeop</dc:creator>
 <dc:creator>Gamon, Michael</dc:creator>
 <dc:creator>Khabsa, Madian</dc:creator>
 <dc:creator>Awadallah, Ahmed Hassan</dc:creator>
 <dc:creator>Pantel, Patrick</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Emails in the workplace are often intentional calls to action for its
recipients. We propose to annotate these emails for what action its recipient
will take. We argue that our approach of action-based annotation is more
scalable and theory-agnostic than traditional speech-act-based email intent
annotation, while still carrying important semantic and pragmatic information.
We show that our action-based annotation scheme achieves good inter-annotator
agreement. We also show that we can leverage threaded messages from other
domains, which exhibit comparable intents in their conversation, with domain
adaptive RAINBOW (Recurrently AttentIve Neural Bag-Of-Words). On a collection
of datasets consisting of IRC, Reddit, and email, our reparametrized RNNs
outperform common multitask/multidomain approaches on several speech act
related tasks. We also experiment with a minimally supervised scenario of email
recipient action classification, and find the reparametrized RNNs learn a
useful representation.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09196</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Robust Manifold Defense: Adversarial Training using Generative
  Models</dc:title>
 <dc:creator>Ilyas, Andrew</dc:creator>
 <dc:creator>Jalal, Ajil</dc:creator>
 <dc:creator>Asteri, Eirini</dc:creator>
 <dc:creator>Daskalakis, Constantinos</dc:creator>
 <dc:creator>Dimakis, Alexandros G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks are demonstrating excellent performance on several
classical vision problems. However, these networks are vulnerable to
adversarial examples, minutely modified images that induce arbitrary
attacker-chosen output from the network. We propose a mechanism to protect
against these adversarial inputs based on a generative model of the data. We
introduce a pre-processing step that projects on the range of a generative
model using gradient descent before feeding an input into a classifier. We show
that this step provides the classifier with robustness against first-order,
substitute model, and combined adversarial attacks. Using a min-max
formulation, we show that there may exist adversarial examples even in the
range of the generator, natural-looking images extremely close to the decision
boundary for which the classifier has unjustifiedly high confidence. We show
that adversarial training on the generative manifold can be used to make a
classifier that is robust to these attacks.
  Finally, we show how our method can be applied even without a pre-trained
generative model using a recent method called the deep image prior. We evaluate
our method on MNIST, CelebA and Imagenet and show robustness against the
current state of the art attacks.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09203</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic Regularization in Over-parameterized Matrix Recovery</dc:title>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:creator>Ma, Tengyu</dc:creator>
 <dc:creator>Zhang, Hongyang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of recovering a low-rank matrix $X^\star$ from linear
measurements using an over-parameterized model. We parameterize the rank-$r$
matrix $X^\star$ by $UU^\top$ where $U\in \mathbb{R}^{d\times d}$ is a square
matrix, whereas the number of linear measurements is much less than $d^2$. We
show that with $\tilde{O}(dr^{2})$ random linear measurements, the gradient
descent on the squared loss, starting from a small initialization, recovers
$X^\star$ approximately in $\tilde{O}(\sqrt{r})$ iterations. The results solve
the conjecture of Gunasekar et al. under the restricted isometry property, and
demonstrate that the training algorithm can provide an implicit regularization
for non-linear matrix factorization models.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09206</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chaos-guided Input Structuring for Improved Learning in Recurrent Neural
  Networks</dc:title>
 <dc:creator>Panda, Priyadarshini</dc:creator>
 <dc:creator>Roy, Kaushik</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:description>  Anatomical studies demonstrate that brain reformats input information to
generate reliable responses for performing computations. However, it remains
unclear how neural circuits encode complex spatio-temporal patterns. We show
that neural dynamics are strongly influenced by the phase alignment between the
input and the spontaneous chaotic activity. Input structuring along the
dominant chaotic projections causes the chaotic trajectories to become stable
channels (or attractors), hence, improving the computational capability of a
recurrent network. Using mean field analysis, we derive the impact of input
structuring on the overall stability of attractors formed. Our results indicate
that input alignment determines the extent of intrinsic noise suppression and
hence, alters the attractor state stability, thereby controlling the network's
inference ability.
</dc:description>
 <dc:description>Comment: 11 pages with 6 figures including supplementary material</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09213</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aircraft Fuselage Defect Detection using Deep Neural Networks</dc:title>
 <dc:creator>Malekzadeh, Touba</dc:creator>
 <dc:creator>Abdollahzadeh, Milad</dc:creator>
 <dc:creator>Nejati, Hossein</dc:creator>
 <dc:creator>Cheung, Ngai-Man</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To ensure flight safety of aircraft structures, it is necessary to have
regular maintenance using visual and nondestructive inspection (NDI) methods.
In this paper, we propose an automatic image-based aircraft defect detection
using Deep Neural Networks (DNNs). To the best of our knowledge, this is the
first work for aircraft defect detection using DNNs. We perform a comprehensive
evaluation of state-of-the-art feature descriptors and show that the best
performance is achieved by vgg-f DNN as feature extractor with a linear SVM
classifier. To reduce the processing time, we propose to apply SURF key point
detector to identify defect patch candidates. Our experiment results suggest
that we can achieve over 96% accuracy at around 15s processing time for a
high-resolution (20-megapixel) image on a laptop.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09216</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale 3D Scene Classification With Multi-View Volumetric CNN</dc:title>
 <dc:creator>Aiger, Dror</dc:creator>
 <dc:creator>Allen, Brett</dc:creator>
 <dc:creator>Golovinskiy, Aleksey</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a method to classify imagery using a convo- lutional neural
network (CNN) on multi-view image pro- jections. The power of our method comes
from using pro- jections of multiple images at multiple depth planes near the
reconstructed surface. This enables classification of categories whose salient
aspect is appearance change un- der different viewpoints, such as water, trees,
and other materials with complex reflection/light response proper- ties. Our
method does not require boundary labelling in images and works on pixel-level
classification with a small (few pixels) context, which simplifies the cre-
ation of a training set. We demonstrate this application on large-scale aerial
imagery collections, and extend the per-pixel classification to robustly create
a consistent 2D classification which can be used to fill the gaps in non-
reconstructible water regions. We also apply our method to classify tree
regions. In both cases, the training data can quickly be generated using a
small number of manually- created polygons on a map. We show that even with a
very simple and standard network our CNN outperforms the state-of-the-art image
classification, the Inception-V3 model retrained from a large collection of
aerial images.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09227</identifier>
 <datestamp>2018-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Real-Time Autonomous Highway Accident Detection Model Based on Big
  Data Processing and Computational Intelligence</dc:title>
 <dc:creator>Ozbayoglu, A. Murat</dc:creator>
 <dc:creator>Kucukayan, Gokhan</dc:creator>
 <dc:creator>Dogdu, Erdogan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68TXX</dc:subject>
 <dc:description>  Due to increasing urban population and growing number of motor vehicles,
traffic congestion is becoming a major problem of the 21st century. One of the
main reasons behind traffic congestion is accidents which can not only result
in casualties and losses for the participants, but also in wasted and lost time
for the others that are stuck behind the wheels. Early detection of an accident
can save lives, provides quicker road openings, hence decreases wasted time and
resources, and increases efficiency. In this study, we propose a preliminary
real-time autonomous accident-detection system based on computational
intelligence techniques. Istanbul City traffic-flow data for the year 2015 from
various sensor locations are populated using big data processing methodologies.
The extracted features are then fed into a nearest neighbor model, a regression
tree, and a feed-forward neural network model. For the output, the possibility
of an occurrence of an accident is predicted. The results indicate that even
though the number of false alarms dominates the real accident cases, the system
can still provide useful information that can be used for status verification
and early reaction to possible accidents.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09227</dc:identifier>
 <dc:identifier>IEEE International Conference on Big Data, (2016), pp.1807-1813,
  Washington D.C. 5-8 December, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/BigData.2016.7840798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09230</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Efficient Algorithms for Longest Increasing Subsequence</dc:title>
 <dc:creator>Kiyomi, Masashi</dc:creator>
 <dc:creator>Ono, Hirotaka</dc:creator>
 <dc:creator>Otachi, Yota</dc:creator>
 <dc:creator>Schweitzer, Pascal</dc:creator>
 <dc:creator>Tarui, Jun</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Given a sequence of integers, we want to find a longest increasing
subsequence of the sequence. It is known that this problem can be solved in
$O(n \log n)$ time and space. Our goal in this paper is to reduce the space
consumption while keeping the time complexity small. For $\sqrt{n} \le s \le
n$, we present algorithms that use $O(s \log n)$ bits and $O(\frac{1}{s} \cdot
n^{2} \cdot \log n)$ time for computing the length of a longest increasing
subsequence, and $O(\frac{1}{s} \cdot n^{2} \cdot \log^{2} n)$ time for finding
an actual subsequence. We also show that the time complexity of our algorithms
is optimal up to polylogarithmic factors in the framework of sequential access
algorithms with the prescribed amount of space.
</dc:description>
 <dc:description>Comment: 14 pages, STACS 2018</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09259</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intention Games</dc:title>
 <dc:creator>Ahuja, Aditya</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Strategic interactions between competitive entities are generally considered
from the perspective of complete revelations of benefits achieved from those
interactions, in the form of public payoff functions in the announced games. In
this work, we propose a formal framework for a competitive ecosystem where each
player is permitted to deviate from publicly optimal strategies under certain
private payoffs greater than public payoffs, given that these deviations have
certain acceptable bounds as agreed by all players. We call this game theoretic
construction an Intention Game. We formally define an Intention Game, and
notions of equilibria that exist in such deviant interactions. We give an
example of a Cournot competition in a partially honest setting. We compare
Intention Games with conventional strategic form games. Finally, we give a
cryptographic use of Intention Games and a dual interpretation of this novel
framework.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09282</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fog Computing based SDI Framework for Mineral Resources Information
  Infrastructure Management in India</dc:title>
 <dc:creator>Barik, Rabindra K.</dc:creator>
 <dc:creator>Lenka, Rakesh K.</dc:creator>
 <dc:creator>Simha, N. V. R.</dc:creator>
 <dc:creator>Dubey, Harishchandra</dc:creator>
 <dc:creator>Mankodiya, Kunal</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Spatial Data Infrastructure (SDI) is an important concept for sharing spatial
data across the web. With cumulative techniques with spatial cloud computing
and fog computing, SDI has the greater potential and has been emerged as a tool
for processing, analysis and transmission of spatial data. The Fog computing is
a paradigm where Fog devices help to increase throughput and reduce latency at
the edge of the client with respect to cloud computing environment. This paper
proposed and developed a fog computing based SDI framework for mining analytics
from spatial big data for mineral resources management in India. We built a
prototype using Raspberry Pi, an embedded microprocessor. We validated by
taking suitable case study of mineral resources management in India by doing
preliminary analysis including overlay analysis. Results showed that fog
computing hold a great promise for analysis of spatial data. We used open
source GIS i.e. QGIS and QIS plugin for reducing the transmission to cloud from
the fog node.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09288</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Extensible Ad Hoc Interface between Lean and Mathematica</dc:title>
 <dc:creator>Lewis, Robert Y.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We implement a user-extensible ad hoc connection between the Lean proof
assistant and the computer algebra system Mathematica. By reflecting the syntax
of each system in the other and providing a flexible interface for extending
translation, our connection allows for the exchange of arbitrary information
between the two systems. We show how to make use of the Lean metaprogramming
framework to verify certain Mathematica computations, so that the rigor of the
proof assistant is not compromised.
</dc:description>
 <dc:description>Comment: In Proceedings PxTP 2017, arXiv:1712.00898</dc:description>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09288</dc:identifier>
 <dc:identifier>EPTCS 262, 2017, pp. 23-37</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.262.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09289</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Learning Algorithms and Post-Quantum Cryptography</dc:title>
 <dc:creator>Poremba, Alexander</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Quantum algorithms have demonstrated promising speed-ups over classical
algorithms in the context of computational learning theory - despite the
presence of noise. In this work, we give an overview of recent quantum
speed-ups, revisit the Bernstein-Vazirani algorithm in a new learning problem
extension over an arbitrary cyclic group and discuss recent applications in
cryptography, such as the Learning with Errors problem.
  We turn to post-quantum cryptography and investigate attacks in which an
adversary is given quantum access to a classical encryption scheme. In
particular, we consider new notions of security under non-adaptive quantum
chosen-ciphertext attacks and propose symmetric-key encryption schemes based on
quantum-secure pseudorandom functions that fulfil our definitions. In order to
prove security, we introduce a novel relabeling game and show that, in an
oracle model, no quantum algorithm making superposition queries can reliably
distinguish between the class of functions that are randomly relabeled at a
small subset of the domain.
  Finally, we discuss current progress in quantum computing technology,
particularly with regard to the ion-trap architecture, as well as the
implementation of quantum algorithms. Moreover, we shed light on the relevance
and effectiveness of common noise models adopted in computational learning
theory.
</dc:description>
 <dc:description>Comment: 104 pages. Master's thesis collaboration between QMATH, University of
  Copenhagen, and Heidelberg University</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09299</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A model for interpreting social interactions in local image regions</dc:title>
 <dc:creator>Ben-Yosef, Guy</dc:creator>
 <dc:creator>Yachin, Alon</dc:creator>
 <dc:creator>Ullman, Shimon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Understanding social interactions (such as 'hug' or 'fight') is a basic and
important capacity of the human visual system, but a challenging and still open
problem for modeling. In this work we study visual recognition of social
interactions, based on small but recognizable local regions. The approach is
based on two novel key components: (i) A given social interaction can be
recognized reliably from reduced images (called 'minimal images'). (ii) The
recognition of a social interaction depends on identifying components and
relations within the minimal image (termed 'interpretation'). We show
psychophysics data for minimal images and modeling results for their
interpretation. We discuss the integration of minimal configurations in
recognizing social interactions in a detailed, high-resolution image.
</dc:description>
 <dc:description>Comment: In AAAI spring symposium on Science of Intelligence: Computational
  Principles of Natural and Artificial Intelligence, Palo Alto, 2017</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09300</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Shot Learning via Latent Space Encoding</dc:title>
 <dc:creator>Yu, Yunlong</dc:creator>
 <dc:creator>Ji, Zhong</dc:creator>
 <dc:creator>Guo, Jichang</dc:creator>
 <dc:creator>Zhongfei</dc:creator>
 <dc:creator>Zhang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-Shot Learning (ZSL) is typically achieved by resorting to a class
semantic embedding space to transfer the knowledge from the seen classes to
unseen ones. Capturing the common semantic characteristics between the visual
modality and the class semantic modality (e.g., attributes or word vector) is a
key to the success of ZSL. In this paper, we present a novel approach called
Latent Space Encoding (LSE) for ZSL based on an encoder-decoder framework,
which learns a highly effective latent space to well reconstruct both the
visual space and the semantic embedding space. For each modality, the
encoderdecoder framework jointly maximizes the recoverability of the original
space from the latent space and the predictability of the latent space from the
original space, thus making the latent space feature-aware. To relate the
visual and class semantic modalities together, their features referring to the
same concept are enforced to share the same latent codings. In this way, the
semantic relations of different modalities are generalized with the latent
representations. We also show that the proposed encoder-decoder framework is
easily extended to more modalities. Extensive experimental results on four
benchmark datasets (AwA, CUB, aPY, and ImageNet) clearly demonstrate the
superiority of the proposed approach on several ZSL tasks, including
traditional ZSL, generalized ZSL, and zero-shot retrieval (ZSR).
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09302</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Semantics of Intensionality and Intensional Recursion</dc:title>
 <dc:creator>Kavvos, G. A.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03B70, 03B45, 03F45, 68Q55, 18C50, 18A99</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  Intensionality is a phenomenon that occurs in logic and computation. In the
most general sense, a function is intensional if it operates at a level finer
than (extensional) equality. This is a familiar setting for computer
scientists, who often study different programs or processes that are
interchangeable, i.e. extensionally equal, even though they are not implemented
in the same way, so intensionally distinct. Concomitant with intensionality is
the phenomenon of intensional recursion, which refers to the ability of a
program to have access to its own code. In computability theory, intensional
recursion is enabled by Kleene's Second Recursion Theorem. This thesis is
concerned with the crafting of a logical toolkit through which these phenomena
can be studied. Our main contribution is a framework in which mathematical and
computational constructions can be considered either extensionally, i.e. as
abstract values, or intensionally, i.e. as fine-grained descriptions of their
construction. Once this is achieved, it may be used to analyse intensional
recursion.
</dc:description>
 <dc:description>Comment: DPhil thesis, Department of Computer Science &amp; St John's College,
  University of Oxford</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09308</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A MPC Walking Framework With External Contact Forces</dc:title>
 <dc:creator>Mason, Sean</dc:creator>
 <dc:creator>Rotella, Nicholas</dc:creator>
 <dc:creator>Schaal, Stefan</dc:creator>
 <dc:creator>Righetti, Ludovic</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this work, we present an extension to a linear Model Predictive Control
(MPC) scheme that plans external contact forces for the robot when given
multiple contact locations and their corresponding friction cone. To accomplish
this we set up a two step optimization problem. In the first optimization, we
compute the Center of Mass (CoM) trajectory, foot step locations, and introduce
slack variables to account for violating the imposed constraints on the Center
of Pressure (CoP). We then use the slack variables to trigger the second
optimization, in which we calculate the optimal external force that compensates
for the CoP tracking error. This optimization considers multiple contacts with
the environment by formulating the problem as a Mixed Integer Quadratic Program
(MIQP) that can be solved at the order of 100 Hz. Once contact is created, the
MIQP collapses to a single Quadratic Program (QP) that can be solved in real
time $&lt;$ 1kHz. Simulations show that the presented control scheme can withstand
disturbances 2-5x larger with the additional force provide by a hand contact
when considering delays and 3-6x larger when contact is already made.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09315</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who is Smarter? Intelligence Measure of Learning-based Cognitive Radios</dc:title>
 <dc:creator>Dabaghchian, Monireh</dc:creator>
 <dc:creator>Alipour-Fanid, Amir</dc:creator>
 <dc:creator>Liu, Songsong</dc:creator>
 <dc:creator>Zeng, Kai</dc:creator>
 <dc:creator>Liy, Xiaohua</dc:creator>
 <dc:creator>Chen, Yu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Cognitive radio (CR) is considered as a key enabling technology for dynamic
spectrum access to improve spectrum efficiency. Although the CR concept was
invented with the core idea of realizing cognition, the research on measuring
CR cognitive capabilities and intelligence is largely open. Deriving the
intelligence measure of CR not only can lead to the development of new CR
technologies, but also makes it possible to better configure the networks by
integrating CRs with different cognitive capabilities. In this paper, for the
first time, we propose a data-driven methodology to quantitatively measure the
intelligence factors of the CR with learning capabilities. The basic idea of
our methodology is to run various tests on the CR in different spectrum
environments under different settings and obtain various performance data on
different metrics. Then we apply factor analysis on the performance data to
identify and quantize the intelligence factors and cognitive capabilities of
the CR. More specifically, we present a case study consisting of 144 different
types of CRs. The CRs are different in terms of learning-based dynamic spectrum
access strategies, number of sensors, sensing accuracy, processing speed, and
algorithmic complexity. Five intelligence factors are identified for the CRs
through our data analysis.We show that these factors comply well with the
nature of the tested CRs, which validates the proposed intelligence measure
methodology.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09317</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Folding Polyominoes into (Poly)Cubes</dc:title>
 <dc:creator>Aichholzer, Oswin</dc:creator>
 <dc:creator>Biro, Michael</dc:creator>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Demaine, Martin L.</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:creator>Fekete, S&#xe1;ndor P.</dc:creator>
 <dc:creator>Hesterberg, Adam</dc:creator>
 <dc:creator>Kostitsyna, Irina</dc:creator>
 <dc:creator>Schmidt, Christiane</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We study the problem of folding a polyomino $P$ into a polycube $Q$, allowing
faces of $Q$ to be covered multiple times. First, we define a variety of
folding models according to whether the folds (a) must be along grid lines of
$P$ or can divide squares in half (diagonally and/or orthogonally), (b) must be
mountain or can be both mountain and valley, (c) can remain flat (forming an
angle of $180^\circ$), and (d) must lie on just the polycube surface or can
have interior faces as well. Second, we give all the inclusion relations among
all models that fold on the grid lines of $P$. Third, we characterize all
polyominoes that can fold into a unit cube, in some models. Fourth, we give a
linear-time dynamic programming algorithm to fold a tree-shaped polyomino into
a constant-size polycube, in some models. Finally, we consider the triangular
version of the problem, characterizing which polyiamonds fold into a regular
tetrahedron.
</dc:description>
 <dc:description>Comment: 30 pages, 19 figures, full version of extended abstract that appeared
  in CCCG 2015</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09327</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Robust Deep Neural Networks for Road Sign Detection</dc:title>
 <dc:creator>Aung, Arkar Min</dc:creator>
 <dc:creator>Fadila, Yousef</dc:creator>
 <dc:creator>Gondokaryono, Radian</dc:creator>
 <dc:creator>Gonzalez, Luis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep Neural Networks are built to generalize outside of training set in mind
by using techniques such as regularization, early stopping and dropout. But
considerations to make them more resilient to adversarial examples are rarely
taken. As deep neural networks become more prevalent in mission-critical and
real-time systems, miscreants start to attack them by intentionally making deep
neural networks to misclassify an object of one type to be seen as another
type. This can be catastrophic in some scenarios where the classification of a
deep neural network can lead to a fatal decision by a machine. In this work, we
used GTSRB dataset to craft adversarial samples by Fast Gradient Sign Method
and Jacobian Saliency Method, used those crafted adversarial samples to attack
another Deep Convolutional Neural Network and built the attacked network to be
more resilient against adversarial attacks by making it more robust by
Defensive Distillation and Adversarial Training
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09331</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Based on CC1 and CC4 Neural Networks</dc:title>
 <dc:creator>Kak, Subhash</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose that a general learning system should have three kinds of agents
corresponding to sensory, short-term, and long-term memory that implicitly will
facilitate context-free and context-sensitive aspects of learning. These three
agents perform mututally complementary functions that capture aspects of the
human cognition system. We investigate the use of CC1 and CC4 networks for use
as models of short-term and sensory memory.
</dc:description>
 <dc:description>Comment: 5 pages.arXiv admin note: text overlap with arXiv:0809.5087; text
  overlap with arXiv:cs/0601129 by other authors</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09332</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting protein-protein interactions based on rotation of proteins in
  3D-space</dc:title>
 <dc:creator>Aghajanbaglo, Samaneh</dc:creator>
 <dc:creator>Moosavi, Sobhan</dc:creator>
 <dc:creator>Rahgozar, Maseud</dc:creator>
 <dc:creator>Rahimi, Amir</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Protein-Protein Interactions (PPIs) perform essential roles in biological
functions. Although some experimental techniques have been developed to detect
PPIs, they suffer from high false positive and high false negative rates.
Consequently, efforts have been devoted during recent years to develop
computational approaches to predict the interactions utilizing various sources
of information. Therefore, a unique category of prediction approaches has been
devised which is based on the protein sequence information. However, finding an
appropriate feature encoding to characterize the sequence of proteins is a
major challenge in such methods. In presented work, a sequence based method is
proposed to predict protein-protein interactions using N-Gram encoding
approaches to describe amino acids and a Relaxed Variable Kernel Density
Estimator (RVKDE) as a machine learning tool. Moreover, since proteins can
rotate in 3D-space, amino acid compositions have been considered with
&quot;undirected&quot; property which leads to reduce dimensions of the vector space. The
results show that our proposed method achieves the superiority of prediction
performance with improving an F-measure of 2.5% on Human Protein Reference
Dataset (HPRD).
</dc:description>
 <dc:description>Comment: 6 pages, accepted in The Second International Workshop on Parallelism
  in Bioinformatics (PBio 2014), as part of IEEE Cluster 2014</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09333</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Implementation of a Deep Random Generator</dc:title>
 <dc:creator>de Valroger, Thibault</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We have introduced in former work the concept of Deep Randomness and its
interest to design Unconditionally Secure communication protocols. We have in
particular given an example of such protocol and introduced how to design a
Deep Random Generator associated to that protocol. Deep Randomness is a form of
randomness in which, at each draw of random variable, not only the result is
unpredictable bu also the distribution is unknown to any observer. In this
article, we remind formal definition of Deep Randomness, and we expose two
practical algorithmic methods to implement a Deep Random Generator within a
classical computing resource. We also discuss their performances and their
parameters.
</dc:description>
 <dc:description>Comment: 25 pages. arXiv admin note: text overlap with arXiv:1507.08258</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09344</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger</dc:title>
 <dc:creator>Behzadan, Vahid</dc:creator>
 <dc:creator>Munir, Arslan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Recent developments have established the vulnerability of deep Reinforcement
Learning (RL) to policy manipulation attacks via adversarial perturbations. In
this paper, we investigate the robustness and resilience of deep RL to
training-time and test-time attacks. Through experimental results, we
demonstrate that under noncontiguous training-time attacks, Deep Q-Network
(DQN) agents can recover and adapt to the adversarial conditions by reactively
adjusting the policy. Our results also show that policies learned under
adversarial perturbations are more robust to test-time attacks. Furthermore, we
compare the performance of $\epsilon$-greedy and parameter-space noise
exploration methods in terms of robustness and resilience against adversarial
perturbations.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1701.04143</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09345</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Duplication-Correcting Codes</dc:title>
 <dc:creator>Lenz, Andreas</dc:creator>
 <dc:creator>Wachter-Zeh, Antonia</dc:creator>
 <dc:creator>Yaakobi, Eitan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B20, 94B65, 94B60</dc:subject>
 <dc:description>  In this work, we propose constructions that correct duplications of multiple
consecutive symbols. These errors are known as tandem duplications, where a
sequence of symbols is repeated; respectively as palindromic duplications,
where a sequence is repeated in reversed order. We compare the redundancies of
these constructions with code size upper bounds that are obtained from sphere
packing arguments. Proving that an upper bound on the code cardinality for
tandem deletions is also an upper bound for inserting tandem duplications, we
derive the bounds based on this special tandem deletion error as this results
in tighter bounds. Our upper bounds on the cardinality directly imply lower
bounds on the redundancy which we compare with the redundancy of the best known
construction correcting arbitrary burst insertions. Our results indicate that
the correction of palindromic duplications requires more redundancy than the
correction of tandem duplications and both significantly less than arbitrary
burst insertions.
</dc:description>
 <dc:description>Comment: 24 pages, 1 figure. arXiv admin note: text overlap with
  arXiv:1707.00052</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09347</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smart Fog: Fog Computing Framework for Unsupervised Clustering Analytics
  in Wearable Internet of Things</dc:title>
 <dc:creator>Borthakur, Debanjan</dc:creator>
 <dc:creator>Dubey, Harishchandra</dc:creator>
 <dc:creator>Constant, Nicholas</dc:creator>
 <dc:creator>Mahler, Leslie</dc:creator>
 <dc:creator>Mankodiya, Kunal</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The increasing use of wearables in smart telehealth generates heterogeneous
medical big data. Cloud and fog services process these data for assisting
clinical procedures. IoT based ehealthcare have greatly benefited from
efficient data processing. This paper proposed and evaluated use of low
resource machine learning on Fog devices kept close to the wearables for smart
healthcare. In state of the art telecare systems, the signal processing and
machine learning modules are deployed in the cloud for processing physiological
data. We developed a prototype of Fog-based unsupervised machine learning big
data analysis for discovering patterns in physiological data. We employed Intel
Edison and Raspberry Pi as Fog computer in proposed architecture. We performed
validation studies on real-world pathological speech data from in home
monitoring of patients with Parkinson's disease (PD). Proposed architecture
employed machine learning for analysis of pathological speech data obtained
from smartwatches worn by the patients with PD. Results showed that proposed
architecture is promising for low-resource clinical machine learning. It could
be useful for other applications within wearable IoT for smart telehealth
scenarios by translating machine learning approaches from the cloud backend to
edge computing devices such as Fog.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures. 5th IEEE Global Conference on Signal and
  Information Processing GlobalSIP 2017</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09350</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytic signal in many dimensions</dc:title>
 <dc:creator>Tsitsvero, Mikhail</dc:creator>
 <dc:creator>Borgnat, Pierre</dc:creator>
 <dc:creator>Gon&#xe7;alves, Paulo</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Complex Variables</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:description>  In this paper we extend analytic signal method to the functions in many
dimensions. First it is shown how to obtain separate phase-shifted components
and how combine them to obtain signal's envelope, instantaneous frequencies and
phases in many dimensions. Second, we show that phase-shifted components may be
obtained by positive frequency restriction of the Fourier transform defined in
the algebra of commutative elliptic hypercomplex numbers. Finally we prove that
for $d&gt;2$ there is no corresponding Clifford-Fourier transform that allows to
recover phase-shifted components correctly.
</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09356</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Online Ride-Sharing Path Planning Strategy for Public Vehicle Systems</dc:title>
 <dc:creator>Zhu, Ming</dc:creator>
 <dc:creator>Liu, Xiao-Yang</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  As efficient traffic-management platforms, public vehicle (PV) systems are
envisioned to be a promising approach to solving traffic congestions and
pollutions for future smart cities. PV systems provide online/dynamic
peer-to-peer ride-sharing services with the goal of serving sufficient number
of customers with minimum number of vehicles and lowest possible cost. A key
component of the PV system is the online ride-sharing scheduling strategy. In
this paper, we propose an efficient path planning strategy that focuses on a
limited potential search area for each vehicle by filtering out the requests
that violate passenger service quality level, so that the global search is
reduced to local search. We analyze the performance of the proposed solution
such as reduction ratio of computational complexity. Simulations based on the
Manhattan taxi data set show that, the computing time is reduced by 22%
compared with the exhaustive search method under the same service quality
performance.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09359</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Basic concepts and tools for the Toki Pona minimalist and constructed
  language: Wordnet synsets; analysis of the vocabulary; synthesis and syntax
  highlighting of texts</dc:title>
 <dc:creator>Fabbri, Renato</dc:creator>
 <dc:creator>de Oliveira, Maria Cristina Ferreira</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A minimalist constructed language (conlang) is useful for experiments and
comfortable for making tools. The Toki Pona (TP) conlang is minimalist both in
the vocabulary (with only 14 letters and 124 words) and in the $\approx10$
syntax rules. The language is useful for being a used and somewhat established
minimalist conlang with at least hundreds of fluent speakers. In this article,
we describe current concepts and resources for TP, and make available Python
scripted routines for the analysis of the language, the synthesis of texts, the
specification of syntax highlighting schemes, and the achievement of a
preliminary TP Wordnet \cite{wordnet}. We focus on the analysis of the basic
vocabulary, as corpus analyses were found in \cite{corpus}. The synthesis is
based on sentence templates, relates to context by keeping track of used words,
and renders larger texts by using a fixed number of phonemes (e.g. for poems)
and number of sentences, words and letters (e.g. for paragraphs). Syntax
highlighting reflects morphosyntactic classes given in the official dictionary
and different solutions are described and implemented in the well-established
Vim text editor \cite{vim}. The tentative TP Wordnet is made available in three
forms that reflect the choices of the synsets related to each word. In summary,
this text holds potentially novel conceptualizations about, and tools and
results in analyzing, synthesizing and syntax highlighting the TP language.
</dc:description>
 <dc:description>Comment: Python scripts and Vim configuration files in this repository:
  https://github.com/ttm/tokipona</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09374</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLAC: A Sparsely Labeled Dataset for Action Classification and
  Localization</dc:title>
 <dc:creator>Zhao, Hang</dc:creator>
 <dc:creator>Yan, Zhicheng</dc:creator>
 <dc:creator>Wang, Heng</dc:creator>
 <dc:creator>Torresani, Lorenzo</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper describes a procedure for the creation of large-scale video
datasets for action classification and localization from unconstrained,
realistic web data. The scalability of the proposed procedure is demonstrated
by building a novel video benchmark, named SLAC (Sparsely Labeled ACtions),
consisting of over 520K untrimmed videos and 1.75M clip annotations spanning
200 action categories. Using our proposed framework, annotating a clip takes
merely 8.8 seconds on average. This represents a saving in labeling time of
over 95% compared to the traditional procedure of manual trimming and
localization of actions. Our approach dramatically reduces the amount of human
labeling by automatically identifying hard clips, i.e., clips that contain
coherent actions but lead to prediction disagreement between action
classifiers. A human annotator can disambiguate whether such a clip truly
contains the hypothesized action in a handful of seconds, thus generating
labels for highly informative samples at little cost. We show that our
large-scale dataset can be used to effectively pre-train action recognition
models, significantly improving final metrics on smaller-scale benchmarks after
fine-tuning. On Kinetics, UCF-101 and HMDB-51, models pre-trained on SLAC
outperform baselines trained from scratch, by 2.0%, 20.1% and 35.4% in top-1
accuracy, respectively when RGB input is used. Furthermore, we introduce a
simple procedure that leverages the sparse labels in SLAC to pre-train action
localization models. On THUMOS14 and ActivityNet-v1.3, our localization model
improves the mAP of baseline model by 8.6% and 2.5%, respectively.
</dc:description>
 <dc:description>Comment: CVPR submission</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09376</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy-SGD optimizes the prior of a PAC-Bayes bound: Data-dependent
  PAC-Bayes priors via differential privacy</dc:title>
 <dc:creator>Dziugaite, Gintare Karolina</dc:creator>
 <dc:creator>Roy, Daniel M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We show that Entropy-SGD (Chaudhari et al., 2016), when viewed as a learning
algorithm, optimizes a PAC-Bayes bound on the risk of a Gibbs (posterior)
classifier, i.e., a randomized classifier obtained by a risk-sensitive
perturbation of the weights of a learned classifier. Entropy-SGD works by
optimizing the bound's prior, violating the hypothesis of the PAC-Bayes theorem
that the prior is chosen independently of the data. Indeed, available
implementations of Entropy-SGD rapidly obtain zero training error on random
labels and the same holds of the Gibbs posterior. In order to obtain a valid
generalization bound, we show that an $\epsilon$-differentially private prior
yields a valid PAC-Bayes bound, a straightforward consequence of results
connecting generalization with differential privacy. Using stochastic gradient
Langevin dynamics (SGLD) to approximate the well-known exponential release
mechanism, we observe that generalization error on MNIST (measured on held out
data) falls within the (empirically nonvacuous) bounds computed under the
assumption that SGLD produces perfect samples. In particular, Entropy-SGLD can
be configured to yield relatively tight generalization bounds and still fit
real labels, although these same settings do not obtain state-of-the-art
performance.
</dc:description>
 <dc:description>Comment: 22 pages, 4 figures</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09379</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IHT dies hard: Provable accelerated Iterative Hard Thresholding</dc:title>
 <dc:creator>Khanna, Rajiv</dc:creator>
 <dc:creator>Kyrillidis, Anastasios</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study --both in theory and practice-- the use of momentum motions in
classic iterative hard thresholding (IHT) methods. By simply modifying plain
IHT, we investigate its convergence behavior on convex optimization criteria
with non-convex constraints, under standard assumptions. In diverse scenaria,
we observe that acceleration in IHT leads to significant improvements, compared
to state of the art projected gradient descent and Frank-Wolfe variants. As a
byproduct of our inspection, we study the impact of selecting the momentum
parameter: similar to convex settings, two modes of behavior are observed
--&quot;rippling&quot; and linear-- depending on the level of momentum.
</dc:description>
 <dc:description>Comment: 22 pages, accepted to AISTATS 2018</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09381</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ray RLlib: A Composable and Scalable Reinforcement Learning Library</dc:title>
 <dc:creator>Liang, Eric</dc:creator>
 <dc:creator>Liaw, Richard</dc:creator>
 <dc:creator>Nishihara, Robert</dc:creator>
 <dc:creator>Moritz, Philipp</dc:creator>
 <dc:creator>Fox, Roy</dc:creator>
 <dc:creator>Gonzalez, Joseph</dc:creator>
 <dc:creator>Goldberg, Ken</dc:creator>
 <dc:creator>Stoica, Ion</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Reinforcement learning (RL) algorithms involve the deep nesting of distinct
components, where each component typically exhibits opportunities for
distributed computation. Current RL libraries offer parallelism at the level of
the entire program, coupling all the components together and making existing
implementations difficult to extend, combine, and reuse. We argue for building
composable RL components by encapsulating parallelism and resource requirements
within individual components, which can be achieved by building on top of a
flexible task-based programming model. We demonstrate this principle by
building Ray RLlib on top of Ray and show that we can implement a wide range of
state-of-the-art algorithms by composing and reusing a handful of standard
components. This composability does not come at the cost of performance --- in
our experiments, RLlib matches or exceeds the performance of highly optimized
reference implementations. Ray RLlib is available as part of Ray at
https://github.com/ray-project/ray/.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09382</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audio to Body Dynamics</dc:title>
 <dc:creator>Shlizerman, Eli</dc:creator>
 <dc:creator>Dery, Lucio M.</dc:creator>
 <dc:creator>Schoen, Hayden</dc:creator>
 <dc:creator>Kemelmacher-Shlizerman, Ira</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We present a method that gets as input an audio of violin or piano playing,
and outputs a video of skeleton predictions which are further used to animate
an avatar. The key idea is to create an animation of an avatar that moves their
hands similarly to how a pianist or violinist would do, just from audio. Aiming
for a fully detailed correct arms and fingers motion is a goal, however, it's
not clear if body movement can be predicted from music at all. In this paper,
we present the first result that shows that natural body dynamics can be
predicted at all. We built an LSTM network that is trained on violin and piano
recital videos uploaded to the Internet. The predicted points are applied onto
a rigged avatar to create the animation.
</dc:description>
 <dc:description>Comment: Link with videos https://arviolin.github.io/AudioBodyDynamics/</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09382</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09388</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling GRPC Tensorflow on 512 nodes of Cori Supercomputer</dc:title>
 <dc:creator>Mathuriya, Amrita</dc:creator>
 <dc:creator>Kurth, Thorsten</dc:creator>
 <dc:creator>Rane, Vivek</dc:creator>
 <dc:creator>Mustafa, Mustafa</dc:creator>
 <dc:creator>Shao, Lei</dc:creator>
 <dc:creator>Bard, Debbie</dc:creator>
 <dc:creator>Prabhat</dc:creator>
 <dc:creator>Lee, Victor W</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We explore scaling of the standard distributed Tensorflow with GRPC
primitives on up to 512 Intel Xeon Phi (KNL) nodes of Cori supercomputer with
synchronous stochastic gradient descent (SGD), and identify causes of scaling
inefficiency at higher node counts. To our knowledge, this is the first
exploration of distributed GRPC Tensorflow scalability on a HPC supercomputer
at such large scale with synchronous SGD. We studied scaling of two convolution
neural networks - ResNet-50, a state-of-the-art deep network for classification
with roughly 25.5 million parameters, and HEP-CNN, a shallow topology with less
than 1 million parameters for common scientific usages. For ResNet-50, we
achieve &gt;80% scaling efficiency on up to 128 workers, using 32 parameter
servers (PS tasks) with a steep decline down to 23% for 512 workers using 64 PS
tasks. Our analysis of the efficiency drop points to low network bandwidth
utilization due to combined effect of three factors. (a) Heterogeneous
distributed parallelization algorithm which uses PS tasks as centralized
servers for gradient averaging is suboptimal for utilizing interconnect
bandwidth. (b) Load imbalance among PS tasks hinders their efficient scaling.
(c) Underlying communication primitive GRPC is currently inefficient on Cori
high-speed interconnect. The HEP-CNN demands less interconnect bandwidth, and
shows &gt;80% weak scaling efficiency for up to 256 nodes with only 1 PS task. Our
findings are applicable to other deep learning networks. Big networks with
millions of parameters stumble upon the issues discussed here. Shallower
networks like HEP-CNN with relatively lower number of parameters can
efficiently enjoy weak scaling even with a single parameter server.
</dc:description>
 <dc:description>Comment: Published as a poster in NIPS 2017 Workshop: Deep Learning At
  Supercomputer Scale</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09391</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping to Declarative Knowledge for Word Problem Solving</dc:title>
 <dc:creator>Roy, Subhro</dc:creator>
 <dc:creator>Roth, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Math word problems form a natural abstraction to a range of quantitative
reasoning problems, such as understanding financial news, sports results, and
casualties of war. Solving such problems requires the understanding of several
mathematical concepts such as dimensional analysis, subset relationships, etc.
In this paper, we develop declarative rules which govern the translation of
natural language description of these concepts to math expressions. We then
present a framework for incorporating such declarative knowledge into word
problem solving. Our method learns to map arithmetic word problem text to math
expressions, by learning to select the relevant declarative knowledge for each
operation of the solution expression. This provides a way to handle multiple
concepts in the same problem while, at the same time, support interpretability
of the answer expression. Our method models the mapping to declarative
knowledge as a latent variable, thus removing the need for expensive
annotations. Experimental evaluation suggests that our domain knowledge based
solver outperforms all other systems, and that it generalizes better in the
realistic case where the training data it is exposed to is biased in a
different way than the test data.
</dc:description>
 <dc:description>Comment: Accepted at TACL 2018</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09392</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RaspiReader: Open Source Fingerprint Reader</dc:title>
 <dc:creator>Engelsma, Joshua J.</dc:creator>
 <dc:creator>Cao, Kai</dc:creator>
 <dc:creator>Jain, Anil K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We open source an easy to assemble, spoof resistant, high resolution, optical
fingerprint reader, called RaspiReader, using ubiquitous components. By using
our open source STL files and software, RaspiReader can be built in under one
hour for only US $175. As such, RaspiReader provides the fingerprint research
community a seamless and simple method for quickly prototyping new ideas
involving fingerprint reader hardware. In particular, we posit that this open
source fingerprint reader will facilitate the exploration of novel fingerprint
spoof detection techniques involving both hardware and software. We demonstrate
one such spoof detection technique by specially customizing RaspiReader with
two cameras for fingerprint image acquisition. One camera provides high
contrast, frustrated total internal reflection (FTIR) fingerprint images, and
the other outputs direct images of the finger in contact with the platen. Using
both of these image streams, we extract complementary information which, when
fused together and used for spoof detection, results in marked performance
improvement over previous methods relying only on grayscale FTIR images
provided by COTS optical readers. Finally, fingerprint matching experiments
between images acquired from the FTIR output of RaspiReader and images acquired
from a COTS reader verify the interoperability of the RaspiReader with existing
COTS optical readers.
</dc:description>
 <dc:description>Comment: substantial text overlap with arXiv:1708.07887</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09401</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Minutiae Extractor: Integrating Deep Networks and Fingerprint
  Domain Knowledge</dc:title>
 <dc:creator>Nguyen, Dinh-Luan</dc:creator>
 <dc:creator>Cao, Kai</dc:creator>
 <dc:creator>Jain, Anil K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a fully automatic minutiae extractor, called MinutiaeNet, based on
deep neural networks with compact feature representation for fast comparison of
minutiae sets. Specifically, first a network, called CoarseNet, estimates the
minutiae score map and minutiae orientation based on convolutional neural
network and fingerprint domain knowledge (enhanced image, orientation field,
and segmentation map). Subsequently, another network, called FineNet, refines
the candidate minutiae locations based on score map. We demonstrate the
effectiveness of using the fingerprint domain knowledge together with the deep
networks. Experimental results on both latent (NIST SD27) and plain (FVC 2004)
public domain fingerprint datasets provide comprehensive empirical support for
the merits of our method. Further, our method finds minutiae sets that are
better in terms of precision and recall in comparison with state-of-the-art on
these two datasets. Given the lack of annotated fingerprint datasets with
minutiae ground truth, the proposed approach to robust minutiae detection will
be useful to train network-based fingerprint matching algorithms as well as for
evaluating fingerprint individuality at scale. MinutiaeNet is implemented in
Tensorflow: https://github.com/luannd/MinutiaeNet
</dc:description>
 <dc:description>Comment: Accepted to International Conference on Biometrics (ICB 2018)</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09402</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formalization of Unique Solutions of Equations in Process Algebra</dc:title>
 <dc:creator>Tian, Chun</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In this thesis, a comprehensive formalization of Milner's Calculus of
Communicating Systems (also known as CCS) has been done in HOL theorem prover
(HOL4), based on an old work in HOL88. This includes all classical properties
of strong/weak bisimulation equivalences and observation congruence, a theory
of congruence for CCS, various versions of &quot;bisimulation up to&quot; techniques, and
several deep theorems, namely the &quot;coarsest congruence contained in weak
equivalence&quot;, and three versions of the &quot;unique solution of equations&quot; theorem
in Milner's book.
  This work is further extended to support recent developments in Concurrency
Theory, namely the &quot;contraction&quot; relation and the related &quot;unique solutions of
contractions&quot; theorem found by Prof. Davide Sangiorgi, University of Bologna.
As a result, a rather complete theory of &quot;contraction&quot; (and a similar relation
called &quot;expansion&quot;) for CCS is also formalized in this thesis. Further more, a
new variant of contraction called &quot;observational contraction&quot; was found by the
author during this work, based on existing contraction relation. It's formally
proved that, this new relation is preserved by direct sums of CCS processes,
and has a more elegant form of the &quot;unique solutions of contractions&quot; theorem
without any restriction on the CCS grammar.
</dc:description>
 <dc:description>Comment: 250 pages, Master degree thesis of Computer Science in University of
  Bologna</dc:description>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09404</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Algebraic View of Computation</dc:title>
 <dc:creator>Egri-Nagy, Attila</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We argue that computation is an abstract algebraic concept, and a computer is
a result of a morphism (a structure preserving map) from a finite universal
semigroup.
</dc:description>
 <dc:description>Comment: 13 pages, final version will be published elsewhere</dc:description>
 <dc:date>2017-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09405</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advances in Pre-Training Distributed Word Representations</dc:title>
 <dc:creator>Mikolov, Tomas</dc:creator>
 <dc:creator>Grave, Edouard</dc:creator>
 <dc:creator>Bojanowski, Piotr</dc:creator>
 <dc:creator>Puhrsch, Christian</dc:creator>
 <dc:creator>Joulin, Armand</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Many Natural Language Processing applications nowadays rely on pre-trained
word representations estimated from large text corpora such as news
collections, Wikipedia and Web Crawl. In this paper, we show how to train
high-quality word vector representations by using a combination of known tricks
that are however rarely used together. The main result of our work is the new
set of publicly available pre-trained models that outperform the current state
of the art by a large margin on a number of tasks.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09418</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Horn-ICE Learning for Synthesizing Invariants and Contracts</dc:title>
 <dc:creator>D'Souza, Deepak</dc:creator>
 <dc:creator>Ezudheen, P.</dc:creator>
 <dc:creator>Garg, Pranav</dc:creator>
 <dc:creator>Madhusudan, P.</dc:creator>
 <dc:creator>Neider, Daniel</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>68Q60, 68Q32</dc:subject>
 <dc:description>  We design learning algorithms for synthesizing invariants using Horn
implication counterexamples (Horn-ICE), extending the ICE-learning model. In
particular, we describe a decision-tree learning algorithm that learns from
Horn-ICE samples, works in polynomial time, and uses statistical heuristics to
learn small trees that satisfy the samples. Since most verification proofs can
be modeled using Horn clauses, Horn-ICE learning is a more robust technique to
learn inductive annotations that prove programs correct. Our experiments show
that an implementation of our algorithm is able to learn adequate inductive
invariants and contracts efficiently for a variety of sequential and concurrent
programs.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09420</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Optimization Criteria and Relay Selection Algorithms for
  Physical-Layer Security in Multiple-Antenna Relay Networks</dc:title>
 <dc:creator>Lu, X.</dc:creator>
 <dc:creator>de Lamare, R. C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Physical-layer security for wireless networks has become an effective
approach and recently drawn significant attention in the literature. In
particular, the deployment and allocation of resources such as relays to assist
the transmission have gained significant interest due to their ability to
improve the secrecy rate of wireless networks. In this work, we examine relay
selection criteria with arbitrary knowledge of the channels of the users and
the eavesdroppers. We present alternative optimization criteria based on the
signal-to-interference and the secrecy rate criteria that can be used for
resource allocation and that do not require knowledge of the channels of the
eavesdroppers and the interference. We then develop effective relay selection
algorithms that can achieve a high secrecy rate performance without the need
for the knowledge of the channels of the eavesdroppers and the interference.
Simulation results show that the proposed criteria and algorithms achieve
excellent performance.
</dc:description>
 <dc:description>Comment: 5 figures, 9 pages.arXiv admin note: substantial text overlap with
  arXiv:1707.00953</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09424</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timely Feedback in Unstructured Cybersecurity Exercises</dc:title>
 <dc:creator>Vykopal, Jan</dc:creator>
 <dc:creator>O&#x161;lej&#x161;ek, Radek</dc:creator>
 <dc:creator>Bursk&#xe1;, Karol&#xed;na</dc:creator>
 <dc:creator>Z&#xe1;kop&#x10d;anov&#xe1;, Krist&#xed;na</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Cyber defence exercises are intensive, hands-on learning events for teams of
professionals who gain or develop their skills to successfully prevent and
respond to cyber attacks. The exercises mimic the real-life, routine operation
of an organization which is being attacked by an unknown offender. Teams of
learners receive very limited immediate feedback from the instructors during
the exercise; they can usually see only a scoreboard showing the aggregated
gain or loss of points for particular tasks. An in-depth analysis of learners'
actions requires considerable human effort, which results in days or weeks of
delay. The intensive experience is thus not followed by proper feedback
facilitating actual learning, and this diminishes the effect of the exercise.
  In this initial work, we investigate how to provide valuable feedback to
learners right after the exercise without any unnecessary delay. Based on the
scoring system of a cyber defence exercise, we have developed a new feedback
tool that presents an interactive, personalized timeline of exercise events. We
deployed this tool during an international exercise, where we monitored
participants' interactions and gathered their reflections. The results show
that learners did use the new tool and rated it positively. Since this new
feature is not bound to a particular defence exercise, it can be applied to all
exercises that employ scoring based on the evaluation of individual exercise
objectives. As a result, it enables the learner to immediately reflect on the
experience gained.
</dc:description>
 <dc:description>Comment: 6 pages; SIGCSE '18, Baltimore, MD, USA</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09424</dc:identifier>
 <dc:identifier>doi:10.1145/3159450.3159561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09431</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The L-CSC cluster: greenest supercomputer in the world in Green500 list
  of November 2014</dc:title>
 <dc:creator>Rohr, D.</dc:creator>
 <dc:creator>Neskovic, G.</dc:creator>
 <dc:creator>Radtke, M.</dc:creator>
 <dc:creator>Lindenstruth, V.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The L-CSC (Lattice Computer for Scientific Computing) is a general purpose
compute cluster built of commodity hardware installed at GSI. Its main
operational purpose is Lattice QCD (LQCD) calculations for physics simulations.
Quantum Chromo Dynamics (QCD) is the physical theory describing the strong
force, one of the four known fundamental interactions in the universe. L-CSC
leverages a multi-GPU design accommodating the huge demand of LQCD for memory
bandwidth. In recent years, heterogeneous clusters with accelerators such as
GPUs have become more and more powerful while supercomputers in general have
shown enormous increases in power consumption making electricity costs and
cooling a significant factor in the total cost of ownership. Using mainly GPUs
for processing, L-CSC is very power efficient, and its architecture was
optimized to provide the greatest possible power efficiency. This paper
presents the cluster design as well as optimizations to improve the power
efficiency. It examines the power measurements performed for the Green500 list
of the most power efficient supercomputers in the world which led to the number
1 position as the greenest supercomputer in November 2014.
</dc:description>
 <dc:description>Comment: 4 pages, proceedings to Supercomputing Frontiers conference</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09433</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User-Centric Joint Transmission in Virtual-Cell-Based Ultra-Dense
  Networks</dc:title>
 <dc:creator>Zhang, Yingxiao</dc:creator>
 <dc:creator>Bi, Suzhi</dc:creator>
 <dc:creator>Zhang, Ying-Jun Angela</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In ultra-dense networks (UDNs), distributed radio access points (RAPs) are
configured into small virtual cells around mobile users for fair and
high-throughput services. In this correspondence, we evaluate the performance
of user-centric joint transmission (JT) in a UDN with a number of virtual
cells. In contrast to existing cooperation schemes, which assume constant RAP
transmit power, we consider a total transmit power constraint for each user,
and assume that the total power is optimally allocated to the RAPs in each
virtual cell using maximum ratio transmission (MRT). Based on stochastic
geometry models of the RAP and user locations, we resolve the correlation of
transmit powers introduced by MRT and derive the average user throughput.
Numerical results show that user-centric JT with MRT provides a high
signal-to-noise ratio (SNR) without generating severe interference to other
co-channel users. Moreover, we show that MRT precoding, while requiring
channel-state-information (CSI), is essential for the success of JT.
</dc:description>
 <dc:description>Comment: Submitted to IEEE TVT correspondence</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09435</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Frequency Dependency of Radio Channel's Delay Spread: Analyses
  and Findings From mmMAGIC Multi-frequency Channel Sounding</dc:title>
 <dc:creator>Nguyen, Sinh L. H.</dc:creator>
 <dc:creator>Medbo, Jonas</dc:creator>
 <dc:creator>Peter, Michael</dc:creator>
 <dc:creator>Karttunen, Aki</dc:creator>
 <dc:creator>Haneda, Katsuyuki</dc:creator>
 <dc:creator>Bamba, Aliou</dc:creator>
 <dc:creator>D'Errico, Raffaele</dc:creator>
 <dc:creator>Iqbal, Naveed</dc:creator>
 <dc:creator>Diakhate, Cheikh</dc:creator>
 <dc:creator>Conrat, Jean-Marc</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper analyzes the frequency dependency of the radio propagation
channel's root mean square (rms) delay spread (DS), based on the
multi-frequency measurement campaigns in the mmMAGIC project. The campaigns
cover indoor, outdoor, and outdoor-to-indoor (O2I) scenarios and a wide
frequency range from 2 to 86 GHz. Several requirements have been identified
that define the parameters which need to be aligned in order to make a
reasonable comparison among the different channel sounders employed for this
study. A new modelling approach enabling the evaluation of the statistical
significance of the model parameters from different measurements and the
establishment of a unified model is proposed. After careful analysis, the
conclusion is that any frequency trend of the DS is small considering its
confidence intervals. There is statistically significant difference from the
3GPP New Radio (NR) model TR 38.901, except for the O2I scenario.
</dc:description>
 <dc:description>Comment: This paper has been accepted to the 2018 12th European Conference on
  Antennas and Propagation (EuCAP), London, UK, April 2018</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09436</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On reciprocal systems and controllability</dc:title>
 <dc:creator>Hughes, Timothy H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we extend classical results on (i) signature symmetric
realizations, and (ii) signature symmetric and passive realizations, to systems
which need not be controllable. These results are motivated in part by the
existence of important electrical networks, such as the famous Bott-Duffin
networks, which possess signature symmetric and passive realizations that are
uncontrollable. In this regard, we provide necessary and sufficient algebraic
conditions for a behavior to be realized as the driving-point behavior of an
electrical network comprising resistors, inductors, capacitors and
transformers.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09437</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pattern-Driven Data Cleaning</dc:title>
 <dc:creator>Rezig, El Kindi</dc:creator>
 <dc:creator>Ouzzani, Mourad</dc:creator>
 <dc:creator>Aref, Walid G.</dc:creator>
 <dc:creator>Elmagarmid, Ahmed K.</dc:creator>
 <dc:creator>Mahmood, Ahmed R.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Data is inherently dirty and there has been a sustained effort to come up
with different approaches to clean it. A large class of data repair algorithms
rely on data-quality rules and integrity constraints to detect and repair the
data. A well-studied class of integrity constraints is Functional Dependencies
(FDs, for short) that specify dependencies among attributes in a relation. In
this paper, we address three major challenges in data repairing: (1) Accuracy:
Most existing techniques strive to produce repairs that minimize changes to the
data. However, this process may produce incorrect combinations of attribute
values (or patterns). In this work, we formalize the interaction of FD-induced
patterns and select repairs that result in preserving frequent patterns found
in the original data. This has the potential to yield a better repair quality
both in terms of precision and recall. (2) Interpretability of repairs: Current
data repair algorithms produce repairs in the form of data updates that are not
necessarily understandable. This makes it hard to debug repair decisions and
trace the chain of steps that produced them. To this end, we define a new
formalism to declaratively express repairs that are easy for users to reason
about. (3) Scalability: We propose a linear-time algorithm to compute repairs
that outperforms state-of-the-art FD repairing algorithms by orders of
magnitude in repair time. Our experiments using both real-world and synthetic
data demonstrate that our new repair approach consistently outperforms existing
techniques both in terms of repair quality and scalability.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09438</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing Radio Propagation Channels Between 28 and 140 GHz Bands in a
  Shopping Mall</dc:title>
 <dc:creator>Nguyen, Sinh Le Hong</dc:creator>
 <dc:creator>Jarvelainen, Jan</dc:creator>
 <dc:creator>Karttunen, Aki</dc:creator>
 <dc:creator>Haneda, Katsuyuki</dc:creator>
 <dc:creator>Putkonen, Jyri</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  In this paper, we compare the radio propagation channels characteristics
between 28 and 140 GHz bands based on the wideband (several GHz) and
directional channel sounding in a shopping mall environment. The measurements
and data processing are conducted in such a way to meet requirements for a fair
comparison of large- and small- scale channel parameters between the two bands.
Our results reveal that there is high spatial-temporal correlation between 28
and 140 GHz channels, similar numbers of strong multipath components, and only
small variations in the large-scale parameters between the two bands.
Furthermore, when including the weak paths there are higher total numbers of
clusters and paths in 28 GHz as compared to those in 140 GHz bands. With these
similarities, it would be very interesting to investigate the potentials of
using 140 GHz band in the future mobile radio communications.
</dc:description>
 <dc:description>Comment: This paper has been accepted to the 2018 12th European Conference on
  Antennas and Propagation (EuCAP), London, UK, April 2018</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09444</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Letter-Based Speech Recognition with Gated ConvNets</dc:title>
 <dc:creator>Liptchinsky, Vitaliy</dc:creator>
 <dc:creator>Synnaeve, Gabriel</dc:creator>
 <dc:creator>Collobert, Ronan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper we introduce a new speech recognition system, leveraging a
simple letter-based ConvNet acoustic model. The acoustic model requires -- only
audio transcription for training -- no alignment annotations, nor any forced
alignment step is needed. At inference, our decoder takes only a word list and
a language model, and is fed with letter scores from the -- acoustic model --
no phonetic word lexicon is needed. Key ingredients for the acoustic model are
Gated Linear Units and high dropout. We show near state-of-the-art results in
word error rate on the LibriSpeech corpus using log-mel filterbanks, both on
the &quot;clean&quot; and &quot;other&quot; configurations.
</dc:description>
 <dc:description>Comment: 13 pages.arXiv admin note: text overlap with arXiv:1609.03193</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09448</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Taking Visual Motion Prediction To New Heightfields</dc:title>
 <dc:creator>Ehrhardt, Sebastien</dc:creator>
 <dc:creator>Monszpart, Aron</dc:creator>
 <dc:creator>Mitra, Niloy</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While the basic laws of Newtonian mechanics are well understood, explaining a
physical scenario still requires manually modeling the problem with suitable
equations and estimating the associated parameters. In order to be able to
leverage the approximation capabilities of artificial intelligence techniques
in such physics related contexts, researchers have handcrafted the relevant
states, and then used neural networks to learn the state transitions using
simulation runs as training data. Unfortunately, such approaches are unsuited
for modeling complex real-world scenarios, where manually authoring relevant
state spaces tend to be tedious and challenging. In this work, we investigate
if neural networks can implicitly learn physical states of real-world
mechanical processes only based on visual data while internally modeling
non-homogeneous environment and in the process enable long-term physical
extrapolation. We develop a recurrent neural network architecture for this task
and also characterize resultant uncertainties in the form of evolving variance
estimates. We evaluate our setup to extrapolate motion of rolling ball(s) on
bowls of varying shape and orientation, and on arbitrary heightfields using
only images as input. We report significant improvements over existing
image-based methods both in terms of accuracy of predictions and complexity of
scenarios; and report competitive performance with approaches that, unlike us,
assume access to internal physical states.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1706.02179</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09449</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Field- and time-normalization of zero-inflated data: An empirical
  analysis using citation and Twitter data</dc:title>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Thelwall (2017a, 2017b) proposed a new family of field- and time-normalized
indicators, which is intended for sparse data. These indicators are based on
units of analysis (e.g., institutions) rather than on the paper level. They
compare the proportion of mentioned papers (e.g., on Twitter) of a unit with
the proportion of mentioned papers in the corresponding fields and publication
years (the expected values). We propose a new indicator (Mantel-Haenszel
quotient, MHq) for the indicator family. The MHq goes back to the MH analysis.
This analysis is an established method, which can be used to pool the data from
several 2x2 cross tables based on different subgroups. We investigate (using
citations and assessments by peers, i.e., F1000Prime recommendations) whether
the indicator family (including the MHq) can distinguish between quality levels
defined by the assessments of peers. Thus, we test the convergent validity. We
find that the MHq is able to distinguish between quality levels (in most cases)
while other indicators of the family are not. Since our study approves the MHq
as a convergent valid indicator, we apply the MHq to four different Twitter
groups as defined by the company Altmetric (e.g., science communicators). Our
results show that there is a weak relationship between all four Twitter groups
and scientific quality, much weaker than between citations and scientific
quality. Therefore, our results discourage the use of Twitter counts in
research evaluation.
</dc:description>
 <dc:description>Comment: This is a substantially extended version of a conference paper which
  has been presented at the 16th International Conference on Scientometrics &amp;
  Informetrics (ISSI) 2017. 15 pages, 2 tables, 4 figures, and 20 equations.
  arXiv admin note: substantial text overlap with arXiv:1704.02211,
  arXiv:1712.02228</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09458</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-modal Geolocation Estimation Using Deep Neural Networks</dc:title>
 <dc:creator>Johns, Jesse M.</dc:creator>
 <dc:creator>Rounds, Jeremiah</dc:creator>
 <dc:creator>Henry, Michael J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Estimating the location where an image was taken based solely on the contents
of the image is a challenging task, even for humans, as properly labeling an
image in such a fashion relies heavily on contextual information, and is not as
simple as identifying a single object in the image. Thus any methods which
attempt to do so must somehow account for these complexities, and no single
model to date is completely capable of addressing all challenges. This work
contributes to the state of research in image geolocation inferencing by
introducing a novel global meshing strategy, outlining a variety of training
procedures to overcome the considerable data limitations when training these
models, and demonstrating how incorporating additional information can be used
to improve the overall performance of a geolocation inference model. In this
work, it is shown that Delaunay triangles are an effective type of mesh for
geolocation in relatively low volume scenarios when compared to results from
state of the art models which use quad trees and an order of magnitude more
training data. In addition, the time of posting, learned user albuming, and
other meta data are easily incorporated to improve geolocation by up to 11% for
country-level (750 km) locality accuracy to 3% for city-level (25 km)
localities.
</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09469</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Closed-Form Coverage Probability for Downlink Poisson Network with
  Double Shadowed Fading</dc:title>
 <dc:creator>Chen, Jingrui</dc:creator>
 <dc:creator>Yuan, Chaowei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Performances of cellular networks over {\kappa}-{\mu} shadowed fading with
long-term shadowing has been studied in the existing literature. However, the
impact of {\kappa}-{\mu} shadowed fading with instantaneous shadowing on
performances of cellular networks is unknown. Therefore, this letter analyzes
the downlink coverage probability of a Poisson network with double shadowed
fading which is composed of a large-scale fading of lognormal distribution and
{\kappa}-{\mu} shadowed fading with integer fading parameters. The closest base
station association rule without shadowing is considered. For analytical
tractability, the double shadowed fading is approximated as a weighted sum of
{\kappa}-{\mu} shadowed distributions based on the Gaussian-Hermit quadrature.
As a main theoretical result, a closed-form expression for the downlink
coverage probability of a Poisson network under double shadowed fading for the
desired signal and arbitrary fading for the interfering signals is successfully
derived. Numerical simulations reveal that the double shadowed fading provides
a pessimistic coverage on a Poisson network compared with the long-term
shadowing which is incorporated into cell selection.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09473</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sketching for Kronecker Product Regression and P-splines</dc:title>
 <dc:creator>Diao, Huaian</dc:creator>
 <dc:creator>Song, Zhao</dc:creator>
 <dc:creator>Sun, Wen</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  TensorSketch is an oblivious linear sketch introduced in Pagh'13 and later
used in Pham, Pagh'13 in the context of SVMs for polynomial kernels. It was
shown in Avron, Nguyen, Woodruff'14 that TensorSketch provides a subspace
embedding, and therefore can be used for canonical correlation analysis, low
rank approximation, and principal component regression for the polynomial
kernel. We take TensorSketch outside of the context of polynomials kernels, and
show its utility in applications in which the underlying design matrix is a
Kronecker product of smaller matrices. This allows us to solve Kronecker
product regression and non-negative Kronecker product regression, as well as
regularized spline regression. Our main technical result is then in extending
TensorSketch to other norms. That is, TensorSketch only provides input sparsity
time for Kronecker product regression with respect to the $2$-norm. We show how
to solve Kronecker product regression with respect to the $1$-norm in time
sublinear in the time required for computing the Kronecker product, as well as
for more general $p$-norms.
</dc:description>
 <dc:description>Comment: AISTATS 2018</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09480</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Zero-Watermark Scheme with Similarity-based Retrieval for
  Copyright Protection of 3D Video</dc:title>
 <dc:creator>Liu, Xiyao</dc:creator>
 <dc:creator>Wang, Yifan</dc:creator>
 <dc:creator>Sun, Ziqiang</dc:creator>
 <dc:creator>Zou, Beiji</dc:creator>
 <dc:creator>Zhao, Yuqian</dc:creator>
 <dc:creator>Zhu, Yuesheng</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The copyright protection of 3D videos has become a crucial issue. In this
study, a novel zero-watermark scheme with similarity-based retrieval is
proposed. In our proposed scheme the features of both 2D-video and depth-map
components are first extracted. Next, master shares and ownership shares are
generated from these features and their relevant copyright information based on
(2,2) visual secret sharing scheme. Different with traditional zero-watermark
schemes, both the features and ownership shares are stored in relevant
databases. When a 3D video is queried, a novel similarity-based retrieval phase
is designed to obtain the ownership shares relevant to the particular 3D video.
After that, the queried master shares are generated from this 3D video and
stacked with its relevant ownership shares to identify its copyright ownership.
To satisfy different DRM requirements of 3D videos, flexible mechanisms are
designed for both similarity-based retrieval and copyright identification
functions in our study. The experimental results demonstrate that RZW-SR3D not
only obtains the ownership shares relevant to a particular 3D video precisely
and reliably when processing numerous videos, which outperforms the traditional
zero-watermark schemes, but also identifies the copyrights of 2D-video and
depth-map components of 3D videos reliably, independently and simultaneously
without any content distortion or watermark-embedding limitation, which
outperforms existing 2D-video based and depth-map based watermark schemes for
protecting 3D video.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09482</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Loss Functions under Label Noise for Deep Neural Networks</dc:title>
 <dc:creator>Ghosh, Aritra</dc:creator>
 <dc:creator>Kumar, Himanshu</dc:creator>
 <dc:creator>Sastry, P. S.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In many applications of classifier learning, training data suffers from label
noise. Deep networks are learned using huge training data where the problem of
noisy labels is particularly relevant. The current techniques proposed for
learning deep networks under label noise focus on modifying the network
architecture and on algorithms for estimating true labels from noisy labels. An
alternate approach would be to look for loss functions that are inherently
noise-tolerant. For binary classification there exist theoretical results on
loss functions that are robust to label noise. In this paper, we provide some
sufficient conditions on a loss function so that risk minimization under that
loss function would be inherently tolerant to label noise for multiclass
classification problems. These results generalize the existing results on
noise-tolerant loss functions for binary classification. We study some of the
widely used loss functions in deep networks and show that the loss function
based on mean absolute value of error is inherently robust to label noise. Thus
standard back propagation is enough to learn the true classifier even under
label noise. Through experiments, we illustrate the robustness of risk
minimization with such loss functions for learning neural networks.
</dc:description>
 <dc:description>Comment: Appeared in AAAI 2017</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09491</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the Space of Black-box Attacks on Deep Neural Networks</dc:title>
 <dc:creator>Bhagoji, Arjun Nitin</dc:creator>
 <dc:creator>He, Warren</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Existing black-box attacks on deep neural networks (DNNs) so far have largely
focused on transferability, where an adversarial instance generated for a
locally trained model can &quot;transfer&quot; to attack other learning models. In this
paper, we propose novel Gradient Estimation black-box attacks for adversaries
with query access to the target model's class probabilities, which do not rely
on transferability. We also propose strategies to decouple the number of
queries required to generate each adversarial sample from the dimensionality of
the input. An iterative variant of our attack achieves close to 100%
adversarial success rates for both targeted and untargeted attacks on DNNs. We
carry out extensive experiments for a thorough comparative evaluation of
black-box attacks and show that the proposed Gradient Estimation attacks
outperform all transferability based black-box attacks we tested on both MNIST
and CIFAR-10 datasets, achieving adversarial success rates similar to well
known, state-of-the-art white-box attacks. We also apply the Gradient
Estimation attacks successfully against a real-world Content Moderation
classifier hosted by Clarifai. Furthermore, we evaluate black-box attacks
against state-of-the-art defenses. We show that the Gradient Estimation attacks
are very effective even against these defenses.
</dc:description>
 <dc:description>Comment: 25 pages, 7 figures, 10 tables</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09494</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysing the Performance of GPU Hash Tables for State Space Exploration</dc:title>
 <dc:creator>Cassee, Nathan</dc:creator>
 <dc:creator>Wijs, Anton</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the past few years, General Purpose Graphics Processors (GPUs) have been
used to significantly speed up numerous applications. One of the areas in which
GPUs have recently led to a significant speed-up is model checking. In model
checking, state spaces, i.e., large directed graphs, are explored to verify
whether models satisfy desirable properties. GPUexplore is a GPU-based model
checker that uses a hash table to efficiently keep track of already explored
states. As a large number of states is discovered and stored during such an
exploration, the hash table should be able to quickly handle many inserts and
queries concurrently. In this paper, we experimentally compare two different
hash tables optimised for the GPU, one being the GPUexplore hash table, and the
other using Cuckoo hashing. We compare the performance of both hash tables
using random and non-random data obtained from model checking experiments, to
analyse the applicability of the two hash tables for state space exploration.
We conclude that Cuckoo hashing is three times faster than GPUexplore hashing
for random data, and that Cuckoo hashing is five to nine times faster for
non-random data. This suggests great potential to further speed up GPUexplore
in the near future.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2017, arXiv:1712.08345</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09494</dc:identifier>
 <dc:identifier>EPTCS 263, 2017, pp. 1-15</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.263.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09495</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rewriting in Free Hypergraph Categories</dc:title>
 <dc:creator>Zanasi, Fabio</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We study rewriting for equational theories in the context of symmetric
monoidal categories where there is a separable Frobenius monoid on each object.
These categories, also called hypergraph categories, are increasingly relevant:
Frobenius structures recently appeared in cross-disciplinary applications,
including the study of quantum processes, dynamical systems and natural
language processing. In this work we give a combinatorial characterisation of
arrows of a free hypergraph category as cospans of labelled hypergraphs and
establish a precise correspondence between rewriting modulo Frobenius structure
on the one hand and double-pushout rewriting of hypergraphs on the other. This
interpretation allows to use results on hypergraphs to ensure decidability of
confluence for rewriting in a free hypergraph category. Our results generalise
previous approaches where only categories generated by a single object (props)
were considered.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2017, arXiv:1712.08345</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09495</dc:identifier>
 <dc:identifier>EPTCS 263, 2017, pp. 16-30</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.263.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09496</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Features of Agent-based Models</dc:title>
 <dc:creator>Heckel, Reiko</dc:creator>
 <dc:creator>Kurz, Alexander</dc:creator>
 <dc:creator>Chattoe-Brown, Edmund</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The design of agent-based models (ABMs) is often ad-hoc when it comes to
defining their scope. In order for the inclusion of features such as network
structure, location, or dynamic change to be justified, their role in a model
should be systematically analysed. We propose a mechanism to compare and assess
the impact of such features. In particular we are using techniques from
software engineering and semantics to support the development and assessment of
ABMs, such as graph transformations as semantic representations for agent-based
models, feature diagrams to identify ingredients under consideration, and
extension relations between graph transformation systems to represent model
fragments expressing features.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2017, arXiv:1712.08345</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09496</dc:identifier>
 <dc:identifier>EPTCS 263, 2017, pp. 31-37</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.263.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09497</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable Self-Assembled Atomic-Switch Networks for Neuromorphic
  Applications</dc:title>
 <dc:creator>Bose, Saurabh K.</dc:creator>
 <dc:creator>Mallinson, Joshua B.</dc:creator>
 <dc:creator>Gazoni, Rodrigo M.</dc:creator>
 <dc:creator>Brown, Simon A.</dc:creator>
 <dc:subject>Physics - Applied Physics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Nature inspired neuromorphic architectures are being explored as an
alternative to imminent limitations of conventional complementary metal-oxide
semiconductor (CMOS) architectures. Utilization of such architectures for
practical applications like advanced pattern recognition tasks will require
synaptic connections that are both reconfigurable and stable. Here, we report
realization of stable atomic-switch networks (ASN), with inherent complex
connectivity, self-assembled from percolating metal nanoparticles (NPs). The
device conductance reflects the configuration of synapses which can be
modulated via voltage stimulus. By controlling Relative Humidity (RH) and
oxygen partial-pressure during NP deposition we obtain stochastic conductance
switching that is stable over several months. Detailed characterization reveals
signatures of electric-field induced atomic-wire formation within the
tunnel-gaps of the oxidized percolating network. Finally we show that the
synaptic structure can be reconfigured by stimulating at different repetition
rates, which can be utilized as short-term to long-term memory conversion. This
demonstration of stable stochastic switching in ASNs provides a promising route
to hardware implementation of biological neuronal models and, as an example, we
highlight possible applications in Reservoir Computing (RC).
</dc:description>
 <dc:description>Comment: 12 Pages, 8 Figures</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09497</dc:identifier>
 <dc:identifier>IEEE Transactions on Electron Devices ( Volume: 64, Page: 5194,
  2017)</dc:identifier>
 <dc:identifier>doi:10.1109/TED.2017.2766063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09509</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Gap-Based Framework for Chinese Word Segmentation via Very Deep
  Convolutional Networks</dc:title>
 <dc:creator>Sun, Zhiqing</dc:creator>
 <dc:creator>Shen, Gehui</dc:creator>
 <dc:creator>Deng, Zhihong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Most previous approaches to Chinese word segmentation can be roughly
classified into character-based and word-based methods. The former regards this
task as a sequence-labeling problem, while the latter directly segments
character sequence into words. However, if we consider segmenting a given
sentence, the most intuitive idea is to predict whether to segment for each gap
between two consecutive characters, which in comparison makes previous
approaches seem too complex. Therefore, in this paper, we propose a gap-based
framework to implement this intuitive idea. Moreover, very deep convolutional
neural networks, namely, ResNets and DenseNets, are exploited in our
experiments. Results show that our approach outperforms the best
character-based and word-based methods on 5 benchmarks, without any further
post-processing module (e.g. Conditional Random Fields) nor beam search.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ACL 2018; 10 pages</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09511</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial-noise-aided Secure Multicast Precoding for Directional
  Modulation Systems</dc:title>
 <dc:creator>Shu, Feng</dc:creator>
 <dc:creator>Xu, Ling</dc:creator>
 <dc:creator>Wang, Jiangzhou</dc:creator>
 <dc:creator>Zhu, Wei</dc:creator>
 <dc:creator>Xiaobo, Zhou</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In multi-cast scenario, all desired users are divided into $K$ groups. Each
group receives its own individual confidential message stream. Eavesdropper
group aims to intercept $K$ confidential-message streams. To achieve a secure
transmission, two secure schemes are proposed: maximum group receive power plus
null-space (NS) projection (Max-GRP plus NSP) and leakage. The former obtains
its precoding vector per group by maximizing its own group receive power
subject to the orthogonal constraint, and its AN projection matrix consist of
all bases of NS of all desired steering vectors from all groups. The latter
attains its desired precoding vector per group by driving the current
confidential message power to its group steering space and reducing its power
leakage to eavesdropper group and other $K-1$ desired ones by maximizing signal
to leakage and noise ratio (Max-SLNR). And its AN projection matrix is designed
by forcing AN power into the eavesdropper steering space by viewing AN as a
useful signal for eavesdropper group and maximizing AN to leakage-and-noise
ratio (Max-ANLNR). Simulation results show that the proposed two methods are
better than conventional method in terms of both bit-error-rate (BER) and
secrecy sum-rate per group. Also, the leakage scheme performs better than
Max-GRP-NSP , especially in the presence of direction measurement errors.
However, the latter requires no channel statistical parameters and thus is
simpler compared to the former.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09518</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Text Normalization by Optimizing Nearest Neighbor Matching</dc:title>
 <dc:creator>Ansari, Salman Ahmad</dc:creator>
 <dc:creator>Zafar, Usman</dc:creator>
 <dc:creator>Karim, Asim</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Text normalization is an essential task in the processing and analysis of
social media that is dominated with informal writing. It aims to map informal
words to their intended standard forms. Previously proposed text normalization
approaches typically require manual selection of parameters for improved
performance. In this paper, we present an automatic optimizationbased nearest
neighbor matching approach for text normalization. This approach is motivated
by the observation that text normalization is essentially a matching problem
and nearest neighbor matching with an adaptive similarity function is the most
direct procedure for it. Our similarity function incorporates weighted
contributions of contextual, string, and phonetic similarity, and the nearest
neighbor matching involves a minimum similarity threshold. These four
parameters are tuned efficiently using grid search. We evaluate the performance
of our approach on two benchmark datasets. The results demonstrate that
parameter tuning on small sized labeled datasets produce state-of-the-art text
normalization performances. Thus, this approach allows practically easy
construction of evolving domain-specific normalization lexicons
</dc:description>
 <dc:description>Comment: A short paper which outlines an approach for text normalization ( 4
  pages long with 1 additional page for references )</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09520</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor Regression Networks with various Low-Rank Tensor Approximations</dc:title>
 <dc:creator>Cao, Xingwei</dc:creator>
 <dc:creator>Rabusseau, Guillaume</dc:creator>
 <dc:creator>Pineau, Joelle</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Tensor regression networks achieve high rate of compression of model
parameters in multilayer perceptrons (MLP) while having slight impact on
performances. Tensor regression layer imposes low-rank constraints on the
tensor regression layer which replaces the flattening operation of traditional
MLP. We investigate tensor regression networks using various low-rank tensor
approximations, aiming to leverage the multi-modal structure of high
dimensional data by enforcing efficient low-rank constraints. We provide a
theoretical analysis giving insights on the choice of the rank parameters. We
evaluated performance of proposed model with state-of-the-art deep
convolutional models. For CIFAR-10 dataset, we achieved the compression rate of
0.018 with the sacrifice of accuracy less than 1%.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09527</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-Morbidity Exploration on Wearables Activity Data Using Unsupervised
  Pre-training and Multi-Task Learning</dc:title>
 <dc:creator>Aggarwal, Karan</dc:creator>
 <dc:creator>Joty, Shafiq</dc:creator>
 <dc:creator>Luque, Luis F.</dc:creator>
 <dc:creator>Srivastava, Jaideep</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Physical activity and sleep play a major role in the prevention and
management of many chronic conditions. It is not a trivial task to understand
their impact on chronic conditions. Currently, data from electronic health
records (EHRs), sleep lab studies, and activity/sleep logs are used. The rapid
increase in the popularity of wearable health devices provides a significant
new data source, making it possible to track the user's lifestyle real-time
through web interfaces, both to consumer as well as their healthcare provider,
potentially. However, at present there is a gap between lifestyle data (e.g.,
sleep, physical activity) and clinical outcomes normally captured in EHRs. This
is a critical barrier for the use of this new source of signal for healthcare
decision making. Applying deep learning to wearables data provides a new
opportunity to overcome this barrier.
  To address the problem of the unavailability of clinical data from a major
fraction of subjects and unrepresentative subject populations, we propose a
novel unsupervised (task-agnostic) time-series representation learning
technique called act2vec. act2vec learns useful features by taking into account
the co-occurrence of activity levels along with periodicity of human activity
patterns. The learned representations are then exploited to boost the
performance of disorder-specific supervised learning models. Furthermore, since
many disorders are often related to each other, a phenomenon referred to as
co-morbidity, we use a multi-task learning framework for exploiting the shared
structure of disorder inducing life-style choices partially captured in the
wearables data. Empirical evaluation using actigraphy data from 4,124 subjects
shows that our proposed method performs and generalizes substantially better
than the conventional time-series symbolic representational methods and
task-specific deep learning models.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09528</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the WSDM Cup 2017: Vandalism Detection and Triple Scoring</dc:title>
 <dc:creator>Potthast, Martin</dc:creator>
 <dc:creator>Heindorf, Stefan</dc:creator>
 <dc:creator>Bast, Hannah</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  The WSDM Cup 2017 was a data mining challenge held in conjunction with the
10th International Conference on Web Search and Data Mining (WSDM). It
addressed key challenges of knowledge bases today: quality assurance and entity
search. For quality assurance, we tackle the task of vandalism detection, based
on a dataset of more than 82 million user-contributed revisions of the Wikidata
knowledge base, all of which annotated with regard to whether or not they are
vandalism. For entity search, we tackle the task of triple scoring, using a
dataset that comprises relevance scores for triples from type-like relations
including occupation and country of citizenship, based on about 10,000 human
relevance judgements. For reproducibility sake, participants were asked to
submit their software on TIRA, a cloud-based evaluation platform, and they were
incentivized to share their approaches open source.
</dc:description>
 <dc:description>Comment: Proceedings of the WSDM Cup 2017</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09531</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Target, Multi-Camera Tracking by Hierarchical Clustering: Recent
  Progress on DukeMTMC Project</dc:title>
 <dc:creator>Zhang, Zhimeng</dc:creator>
 <dc:creator>Wu, Jianan</dc:creator>
 <dc:creator>Zhang, Xuan</dc:creator>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Although many methods perform well in single camera tracking, multi-camera
tracking remains a challenging problem with less attention. DukeMTMC is a
large-scale, well-annotated multi-camera tracking benchmark which makes great
progress in this field. This report is dedicated to briefly introduce our
method on DukeMTMC and show that simple hierarchical clustering with
well-trained person re-identification features can get good results on this
dataset.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09532</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus-based Sequence Training for Video Captioning</dc:title>
 <dc:creator>Phan, Sang</dc:creator>
 <dc:creator>Henter, Gustav Eje</dc:creator>
 <dc:creator>Miyao, Yusuke</dc:creator>
 <dc:creator>Satoh, Shin'ichi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Captioning models are typically trained using the cross-entropy loss.
However, their performance is evaluated on other metrics designed to better
correlate with human assessments. Recently, it has been shown that
reinforcement learning (RL) can directly optimize these metrics in tasks such
as captioning. However, this is computationally costly and requires specifying
a baseline reward at each step to make training converge. We propose a fast
approach to optimize one's objective of interest through the REINFORCE
algorithm. First we show that, by replacing model samples with ground-truth
sentences, RL training can be seen as a form of weighted cross-entropy loss,
giving a fast, RL-based pre-training algorithm. Second, we propose to use the
consensus among ground-truth captions of the same video as the baseline reward.
This can be computed very efficiently. We call the complete proposal
Consensus-based Sequence Training (CST). Applied to the MSRVTT video captioning
benchmark, our proposals train significantly faster than comparable methods and
establish a new state-of-the-art on the task, improving the CIDEr score from
47.3 to 54.2.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, 5 tables. Github repo at
  https://github.com/mynlp/cst_captioning</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09550</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Search for High Recall: a Non-Stationary Extension of Thompson
  Sampling</dc:title>
 <dc:creator>Renders, Jean-Michel</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  We consider the problem of Active Search, where a maximum of relevant objects
- ideally all relevant objects - should be retrieved with the minimum effort or
minimum time. Typically, there are two main challenges to face when tackling
this problem: first, the class of relevant objects has often low prevalence
and, secondly, this class can be multi-faceted or multi-modal: objects could be
relevant for completely different reasons. To solve this problem and its
associated issues, we propose an approach based on a non-stationary (aka
restless) extension of Thompson Sampling, a well-known strategy for Multi-Armed
Bandits problems. The collection is first soft-clustered into a finite set of
components and a posterior distribution of getting a relevant object inside
each cluster is updated after receiving the user feedback about the proposed
instances. The &quot;next instance&quot; selection strategy is a mixed, two-level
decision process, where both the soft clusters and their instances are
considered. This method can be considered as an insurance, where the cost of
the insurance is an extra exploration effort in the short run, for achieving a
nearly &quot;total&quot; recall with less efforts in the long run.
</dc:description>
 <dc:description>Comment: 7 pages, 0 figures. Long version (with full details and appendices)
  of the short paper accepted for ECIR 2018</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09552</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Big Data and Fog Computing</dc:title>
 <dc:creator>Simmhan, Yogesh</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Fog computing serves as a computing layer that sits between the edge devices
and the cloud in the network topology. They have more compute capacity than the
edge but much less so than cloud data centers. They typically have high uptime
and always-on Internet connectivity. Applications that make use of the fog can
avoid the network performance limitation of cloud computing while being less
resource constrained than edge computing. As a result, they offer a useful
balance of the current paradigms. This article explores various aspects of fog
computing in the context of big data.
</dc:description>
 <dc:description>Comment: To Appear as a contribution in Encyclopedia of Big Data Technologies,
  Sherif Sakr and Albert Zomaya eds., Springer Nature, 2018</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09553</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepIEP: a Peptide Sequence Model of Isoelectric Point (IEP/pI) using
  Recurrent Neural Networks (RNNs)</dc:title>
 <dc:creator>Bjerrum, Esben Jannik</dc:creator>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  The isoelectric point (IEP or pI) is the pH where the net charge on the
molecular ensemble of peptides and proteins is zero. This physical-chemical
property is dependent on protonable/deprotonable sidechains and their pKa
values. Here an pI prediction model is trained from a database of peptide
sequences and pIs using a recurrent neural network (RNN) with long short-term
memory (LSTM) cells. The trained model obtains an RMSE and R$^2$ of 0.28 and
0.95 for the external test set. The model is not based on pKa values, but
prediction of constructed test sequences show similar rankings as already known
pKa values. The prediction depends mostly on the existence of known acidic and
basic amino acids with fine-adjusted based on the neighboring sequence and
position of the charged amino acids in the peptide chain.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09557</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cache-Aided Non-Orthogonal Multiple Access</dc:title>
 <dc:creator>Xiang, Lin</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Ge, Xiaohu</dc:creator>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:creator>Wong, Vincent W. S.</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a novel joint caching and non-orthogonal multiple
access (NOMA) scheme to facilitate advanced downlink transmission for next
generation cellular networks. In addition to reaping the conventional
advantages of caching and NOMA transmission, the proposed cache-aided NOMA
scheme also exploits cached data for interference cancellation which is not
possible with separate caching and NOMA transmission designs. Furthermore, as
caching can help to reduce the residual interference power, several decoding
orders are feasible at the receivers, and these decoding orders can be flexibly
selected for performance optimization. We characterize the achievable rate
region of cache-aided NOMA and investigate its benefits for minimizing the time
required to complete video file delivery. Our simulation results reveal that,
compared to several baseline schemes, the proposed cache-aided NOMA scheme
significantly expands the achievable rate region for downlink transmission,
which translates into substantially reduced file delivery times.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures; submitted to ICC 2018 for possible publication</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09558</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory-Efficient Deep Salient Object Segmentation Networks on Gridized
  Superpixels</dc:title>
 <dc:creator>Aytekin, Caglar</dc:creator>
 <dc:creator>Ni, Xingyang</dc:creator>
 <dc:creator>Cricri, Francesco</dc:creator>
 <dc:creator>Fan, Lixin</dc:creator>
 <dc:creator>Aksu, Emre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computer vision algorithms with pixel-wise labeling tasks, such as semantic
segmentation and salient object detection, have gone through a significant
accuracy increase with the incorporation of deep learning. Deep segmentation
methods slightly modify and fine-tune pre-trained networks that have hundreds
of millions of parameters. In this work, we question the need to have such
memory demanding networks for the specific task of salient object segmentation.
To this end, we propose a way to learn a memory-efficient network from scratch
by training it only on salient object detection datasets. Our method encodes
images to gridized superpixels that preserve both the object boundaries and the
connectivity rules of regular pixels. This representation allows us to use
convolutional neural networks that operate on regular grids. By using these
encoded images, we train a memory-efficient network using only 0.048\% of the
number of parameters that other deep salient object detection networks have.
Our method shows comparable accuracy with the state-of-the-art deep salient
object detection methods and provides a faster and a much more memory-efficient
alternative to them. Due to its easy deployment, such a network is preferable
for applications in memory limited devices such as mobile phones and IoT
devices.
</dc:description>
 <dc:description>Comment: 6 pages, submitted to ICPR 2018</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09569</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering discussion topics about development of cross-platform mobile
  applications using a cross-compiler development framework</dc:title>
 <dc:creator>Martinez, Matias</dc:creator>
 <dc:creator>Lecomte, Sylvain</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A cross-platform mobile application is an application that runs on multiple
mobile platforms (Android or iOS platforms). One strategy for developing this
kind of mobile applications involves to develop, using platform-related
toolkits, a native application for each chosen platform. Several frameworks
have been proposed to simplify the development of cross-platform mobile
applications and, therefore, to reduce development and maintenance costs.
Between them, the cross-compiler mobile development frameworks transform the
application's code written in intermediate (aka non-native) language to native
code for each platform. However, to our best knowledge, there is no much
research about the advantages and disadvantages of the use of cross-compiler
frameworks during the development and maintenance phases of mobile
applications. This paper aims at contributing with one of the first bricks in
that research direction. We study what mobile developers that use
cross-compiler frameworks ask about when they develop and maintain
cross-platform mobile applications. In particular, we focus on one framework:
Xamarin from Microsoft. For that, we first created two datasets of questions
and answers (QA) related to the development of mobile applications using
Xamarin by mining two QA sites: Xamarin Forum and Stack Overflow. We analyzed
and compared the number of questions, views and accepted. Then, we applied LDA
on Xamarin-related questions to discover the main topics asked by developers
that use Xamarin. Finally, we compared the discovered topics with those topics
about mobile development. Our findings show that Xamarin Forum has a larger
number of questions than Stack Overflow, however, the latter has more answers
per question. Moreover, both sites share most of the main topics, which mainly
discuss about user interface (UI), formatting, design and navigation.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09574</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guarded and Unguarded Iteration for Generalized Processes</dc:title>
 <dc:creator>Goncharov, Sergey</dc:creator>
 <dc:creator>Schr&#xf6;der, Lutz</dc:creator>
 <dc:creator>Rauch, Christoph</dc:creator>
 <dc:creator>Pir&#xf3;g, Maciej</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03D75, 68Q55</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Models of iterated computation, such as (completely) iterative monads, often
depend on a notion of guardedness, which guarantees unique solvability of
recursive equations and requires roughly that recursive calls happen only under
certain guarding operations. On the other hand, many models of iteration do
admit unguarded iteration. Solutions are then no longer unique, and in general
not even determined as least or greatest fixpoints, being instead governed by
quasi-equational axioms. Monads that support unguarded iteration in this sense
are called (complete) Elgot monads. Here, we propose to equip (Kleisli
categories of) monads with an abstract notion of guardedness and then require
solvability of abstractly guarded recursive equations; examples of such
abstractly guarded pre-iterative monads include both iterative monads and Elgot
monads, the latter by deeming any recursive definition to be abstractly
guarded. Our main result is then that Elgot monads are precisely the
iteration-congruent retracts of abstractly guarded iterative monads, the latter
being defined as admitting unique solutions of abstractly guarded recursive
equations; in other words, models of unguarded iteration come about by
quotienting models of guarded iteration.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09592</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Artificial Neural Network-based Stock Trading System Using Technical
  Analysis and Big Data Framework</dc:title>
 <dc:creator>Sezer, O. B.</dc:creator>
 <dc:creator>Ozbayoglu, M.</dc:creator>
 <dc:creator>Dogdu, E.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Finance - Trading and Market Microstructure</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68TXX</dc:subject>
 <dc:description>  In this paper, a neural network-based stock price prediction and trading
system using technical analysis indicators is presented. The model developed
first converts the financial time series data into a series of buy-sell-hold
trigger signals using the most commonly preferred technical analysis
indicators. Then, a Multilayer Perceptron (MLP) artificial neural network (ANN)
model is trained in the learning stage on the daily stock prices between 1997
and 2007 for all of the Dow30 stocks. Apache Spark big data framework is used
in the training stage. The trained model is then tested with data from 2007 to
2017. The results indicate that by choosing the most appropriate technical
indicators, the neural network model can achieve comparable results against the
Buy and Hold strategy in most of the cases. Furthermore, fine tuning the
technical indicators and/or optimization strategy can enhance the overall
trading performance.
</dc:description>
 <dc:description>Comment: ACM Southeast Conference, ACMSE 2017, Kennesaw State University, GA,
  U.S.A., 13-15 April, 2017</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09592</dc:identifier>
 <dc:identifier>ACM Southeast Conference, ACMSE 2017, Kennesaw State University,
  GA, U.S.A., 13-15 April, 2017</dc:identifier>
 <dc:identifier>doi:10.1145/3077286.3077294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09601</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building the Brazilian Academic Genealogy Tree</dc:title>
 <dc:creator>Dores, Wellington</dc:creator>
 <dc:creator>Soares, Elias</dc:creator>
 <dc:creator>Benevenuto, Fabr&#xed;cio</dc:creator>
 <dc:creator>Laender, Alberto H. F.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Along the history, many researchers provided remarkable contributions to
science, not only advancing knowledge but also in terms of mentoring new
scientists. Currently, identifying and studying the formation of researchers
over the years is a challenging task as current repositories of theses and
dissertations are cataloged in a decentralized way through many local digital
libraries. Following our previous work in which we created and analyzed a large
collection of genealogy trees extracted from NDLTD, in this paper we focus our
attention on building such trees for the Brazilian research community. For
this, we use data from the Lattes Platform, an internationally renowned
initiative from CNPq, the Brazilian National Council for Scientific and
Technological Development, for managing information about individual
researchers and research groups in Brazil.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09603</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classical System of Martin-Lof's Inductive Definitions is not Equivalent
  to Cyclic Proofs</dc:title>
 <dc:creator>Berardi, Stefano</dc:creator>
 <dc:creator>Tatsuta, Makoto</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A cyclic proof system, called CLKID-omega, gives us another way of
representing inductive definitions and effcient proof search. The 2011 paper by
Brotherston and Simpson showed that the provability of CLKID-omega includes the
provability of Martin-Lof's system of inductive definitions, called LKID, and
conjectured the equivalence. Since then, the equivalence has been left an open
question. This paper shows that CLKID-omega and LKID are indeed not equivalent.
This paper considers a statement called 2-Hydra in these two systems with the
first-order language formed by 0, the successor, the natural number predicate,
and a binary predicate symbol used to express 2-Hydra. This paper shows that
the 2-Hydra statement is provable in CLKID-omega, but the statement is not
provable in LKID, by constructing some Henkin model where the statement is
false.
</dc:description>
 <dc:description>Comment: Full version of the fossacs 2017 paper by the same authors. About 50%
  new text added, mostly mathematical proofs</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09612</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Spatial Filtering on Distortion from Low-Noise Amplifiers in
  Massive MIMO Base Stations</dc:title>
 <dc:creator>Moll&#xe9;n, Christopher</dc:creator>
 <dc:creator>Gustavsson, Ulf</dc:creator>
 <dc:creator>Eriksson, Thomas</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Because of the large number of antennas at the base station, the power
consumption and cost of the low-noise amplifiers (LNAs) can be substantial.
Therefore, we investigate the feasibility of inexpensive, power efficient LNAs,
which inherently are less linear. To characterize the nonlinear distortion, the
LNAs are described using a polynomial model, which allows for the derivation of
the second-order statistics of the distortion. We show that some terms of the
distortion from the LNAs combine coherently, and that the SINR of the symbol
estimates therefore is limited by the linearity of the LNAs. Furthermore, the
impact of a strong transmitter in the adjacent frequency band is investigated.
The second-order statistics show how the power from that transmission leaks
into the main band and interferes with the symbol estimates. The term that
scales with the cube of the power received from the blocker can be filtered out
by spatial processing. Only the coherent term that scales with the square of
the power remains. Nonlinear distortion from the LNAs can be reduced by spatial
processing in massive MIMO. However, it does not vanish as the number of
antennas is increased.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09612</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09617</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On efficiently solvable cases of Quantum k-SAT</dc:title>
 <dc:creator>Aldi, Marco</dc:creator>
 <dc:creator>de Beaudrap, Niel</dc:creator>
 <dc:creator>Gharibian, Sevag</dc:creator>
 <dc:creator>Saeedi, Seyran</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The constraint satisfaction problems k-SAT and Quantum k-SAT (k-QSAT) are
canonical NP-complete and QMA_1-complete problems (for k &gt;= 3), respectively,
where QMA_1 is a quantum generalization of NP with one-sided error. Whereas
k-SAT has been well-studied for special tractable cases, as well as from a
parameterized complexity perspective, much less is known in similar settings
for k-QSAT. Here, we study the open problem of computing satisfying assignments
to k-QSAT instances which have a &quot;matching&quot; or &quot;dimer covering&quot;; this is an NP
problem whose decision variant is trivial, but whose search complexity remains
open.
  Our results fall into three directions, all of which relate to the &quot;matching&quot;
setting: (1) We give a polynomial-time classical algorithm for k-QSAT when all
qubits occur in at most two clauses. (2) We show a &quot;parameterized complexity&quot;
type result by showing that for k-QSAT instances from a certain non-trivial
class, computing explicit solutions reduces to solving for a single root of a
single univariate polynomial, where the degree of the polynomial depends on the
&quot;parameters&quot;. (3) We conduct a structural graph theoretic study of 3-QSAT
interaction graphs which have a &quot;matching&quot;. We remark that the results of (2),
in particular, introduce a number of new tools to the study of Quantum SAT,
including graph theoretic concepts such as transfer filtrations and blow-ups
from algebraic geometry; we hope these prove useful elsewhere.
</dc:description>
 <dc:description>Comment: 39 pages, 15 figures, comments welcome</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09618</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Plexus: A network based analysis</dc:title>
 <dc:creator>Singh, Malvika</dc:creator>
 <dc:creator>Mandan, Sneha</dc:creator>
 <dc:creator>Sharma, Smriti</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Power generation and distribution remains an important topic of discussion
since the industrial revolution. As the system continues to grow, it needs to
evolve both in infrastructure, robustness and its resilience to deal with
failures. One such potential failure that we target in this work is the
cascading failure. This avalanche effect propagates through the network and we
study this propagation by Percolation Theory and implement some solutions for
mitigation. We have extended the percolation theory as given in Mark Newman.
Networks: an introduction,for random nodes to targeted nodes having high load
bearing which is eliminated from the network to study the cascade effect. We
also implement mitigation strategy to improve the network performance.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09619</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Two Disjoint Simple Paths on Two Sets of Points is NP-Complete</dc:title>
 <dc:creator>Razzazi, Mohammadreza</dc:creator>
 <dc:creator>Sepahvand, Abdolah</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Finding two disjoint simple paths on two given sets of points is a geometric
problem introduced by Jeff Erickson. This problem has various applications in
computational geometry, like robot motion planning, generating polygon etc. We
will present a reduction from planar Hamiltonian path to this problem, and
prove that it is NP-Complete. To the best of our knowledge, no study has
considered its complexity up until now. We also present a reduction from planar
Hamiltonian path problem to the problem of finding a path on given points in
the presence of arbitrary obstacles and prove that it is NP-Complete too. Also,
we present a heuristic algorithm with time complexity of O(n4) to solve this
problem. The proposed algorithm first calculates the convex hull for each of
the entry points and then produces two simple paths on the two entry point sets
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09619</dc:identifier>
 <dc:identifier>scientiairanica.sharif.edu/article_4116.html 2017</dc:identifier>
 <dc:identifier>doi:10.24200/SCI.2017.4116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09623</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An empirical evaluation for the intrusion detection features based on
  machine learning and feature selection methods</dc:title>
 <dc:creator>Alkasassbeh, Mouhammd</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Despite the great developments in information technology, particularly the
Internet, computer networks, global information exchange, and its positive
impact in all areas of daily life, it has also contributed to the development
of penetration and intrusion which forms a high risk to the security of
information organizations, government agencies, and causes large economic
losses. There are many techniques designed for protection such as firewall and
intrusion detection systems (IDS). IDS is a set of software and/or hardware
techniques used to detect hacker's activities in computer systems. Two types of
anomalies are used in IDS to detect intrusive activities different from normal
user behavior. Misuse relies on the knowledge base that contains all known
attack techniques and intrusion is discovered through research in this
knowledge base. Artificial intelligence techniques have been introduced to
improve the performance of these systems. The importance of IDS is to identify
unauthorized access attempting to compromise confidentiality, integrity or
availability of the computer network. This paper investigates the Intrusion
Detection (ID) problem using three machine learning algorithms namely, BayesNet
algorithm, Multi-Layer Perceptron (MLP), and Support Vector Machine (SVM). The
algorithms are applied on a real, Management Information Based (MIB) dataset
that is collected from real life environment. To enhance the detection process
accuracy, a set of feature selection approaches is used; Infogain (IG), ReleifF
(RF), and Genetic Search (GS). Our experiments show that the three feature
selection methods have enhanced the classification performance. GS with
bayesNet, MLP and SVM give high accuracy rates, more specifically the BayesNet
with the GS accuracy rate is 99.9%.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09623</dc:identifier>
 <dc:identifier>Journal of Theoretical and Applied Information Technology 30th
  November 2017 -- Vol. 95. No. 22 -- 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09624</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cuckoo++ Hash Tables: High-Performance Hash Tables for Networking
  Applications</dc:title>
 <dc:creator>Scouarnec, Nicolas Le</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Hash tables are an essential data-structure for numerous networking
applications (e.g., connection tracking, firewalls, network address
translators). Among these, cuckoo hash tables provide excellent performance by
allowing lookups to be processed with very few memory accesses (2 to 3 per
lookup). Yet, for large tables, cuckoo hash tables remain memory bound and each
memory access impacts performance. In this paper, we propose algorithmic
improvements to cuckoo hash tables allowing to eliminate some unnecessary
memory accesses; these changes are conducted without altering the properties of
the original cuckoo hash table so that all existing theoretical analysis remain
applicable. On a single core, our hash table achieves 37M lookups per second
for positive lookups (i.e., when the key looked up is present in the table),
and 60M lookups per second for negative lookups, a 50% improvement over the
implementation included into the DPDK. On a 18-core, with mostly positive
lookups, our implementation achieves 496M lookups per second, a 45% improvement
over DPDK.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09630</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor network complexity of multilinear maps</dc:title>
 <dc:creator>Austrin, Per</dc:creator>
 <dc:creator>Kaski, Petteri</dc:creator>
 <dc:creator>Kubjas, Kaie</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study \emph{tensor networks} as a model of arithmetic computation for
evaluating multilinear maps. This model turns out to be strong enough to
capture the current best algorithms for a variety of problems, e.g.,
$O(n^{\omega + \epsilon})$ time matrix multiplication, $O(n \log n)$ time
discrete Fourier transform, $O(n^{(\omega+\epsilon)t + j})$ time
$(3t+j)$-clique counting and $O^*(2^n)$ time for computing the permanent of a
matrix.
  While powerful, the model still has limitations, and we are able to show a
number of unconditional lower bounds for various linear maps, including:
  (a) an $\Omega(n^{\lceil 2v/3 \rceil})$ time lower bound for $v$-clique,
matching the upper bound if $\omega = 2$.
  (b) an $\Omega(2^{0.918n})$ time lower bound for the permanent of an $n
\times n$ matrix.
  (c) an $\Omega(n^4)$ time lower bound for the trilinear map $D_{ijk} =
\sum_{l} A_{ijl}B_{ikl} C_{jkl}$ generalizing matrix multiplication, taking
three $n \times n \times n$ tensors $A, B, C$ and producing an $n \times n
\times n$ tensor $D$, ruling out tensor networks as an approach to obtaining
non-trivial algorithms for hyperclique counting and the Max-$3$-CSP problem.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09636</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Concurrent Lock-Free Hash Tries with Constant-Time
  Operations</dc:title>
 <dc:creator>Prokopec, Aleksandar</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Ctrie is a scalable concurrent non-blocking dictionary data structure, with
good cache locality, and non-blocking linearizable iterators. However,
operations on most existing concurrent hash tries run in O(log n) time. In this
technical report, we extend the standard concurrent hash-tries with an
auxiliary data structure called a cache. The cache is essentially an array that
stores pointers to a specific level of the hash trie. We analyze the
performance implications of adding a cache, and prove that the running time of
the basic operations becomes O(1).
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09644</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PyPhi: A toolbox for integrated information theory</dc:title>
 <dc:creator>Mayner, William G. P.</dc:creator>
 <dc:creator>Marshall, William</dc:creator>
 <dc:creator>Albantakis, Larissa</dc:creator>
 <dc:creator>Findlay, Graham</dc:creator>
 <dc:creator>Marchman, Robert</dc:creator>
 <dc:creator>Tononi, Giulio</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Integrated information theory provides a mathematical framework to fully
characterize the cause-effect structure of a physical system. Here, we
introduce PyPhi, a Python software package that implements this framework for
causal analysis and unfolds the full cause-effect structure of discrete
dynamical systems of binary elements. The software allows users to easily study
these structures, serves as an up-to-date reference implementation of the
formalisms of integrated information theory, and has been applied in research
on complexity, emergence, and certain biological questions. We first provide an
overview of the main algorithm and demonstrate PyPhi's functionality in the
course of analyzing an example system, and then describe details of the
algorithm's design and implementation.
  PyPhi can be installed with Python's package manager via the command 'pip
install pyphi' on Linux and macOS systems equipped with Python 3.4 or higher.
PyPhi is open-source and licensed under the GPLv3; the source code is hosted on
GitHub at https://github.com/wmayner/pyphi . Comprehensive and
continually-updated documentation is available at https://pyphi.readthedocs.io/
. The pyphi-users mailing list can be joined at
https://groups.google.com/forum/#!forum/pyphi-users . A web-based graphical
interface to the software is available at
http://integratedinformationtheory.org/calculate.html .
</dc:description>
 <dc:description>Comment: 22 pages, 4 figures, 6 pages of appendices. Supporting information
  &quot;S1 Calculating Phi&quot; can be found in the ancillary files</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09645</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FogGrid: Leveraging Fog Computing for Enhanced Smart Grid Network</dc:title>
 <dc:creator>Barik, Rabindra K.</dc:creator>
 <dc:creator>Gudey, Satish Kumar</dc:creator>
 <dc:creator>Reddy, Gujji Giridhar</dc:creator>
 <dc:creator>Pant, Meenakshi</dc:creator>
 <dc:creator>Dubey, Harishchandra</dc:creator>
 <dc:creator>Mankodiya, Kunal</dc:creator>
 <dc:creator>Kumar, Vinay</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The present manuscript concentrates on the application of Fog computing to a
Smart Grid Network that comprises of a Distribution Generation System known as
a Microgrid. It addresses features and advantages of a smart grid. Two
computational methods for on-demand processing based on shared information
resources is discussed. Fog Computing acts as an additional layer of
computational and/or communication nodes that offload the Cloud backend from
multi-tasking while dealing with large amounts of data. Both Fog computing and
Cloud computing hierarchical architecture is compared with respect to efficient
utilization of resources. To alleviate the advantages of Fog computing, a Fog
computing framework based on Intel Edison is proposed. The proposed
architecture has been hardware implemented for a microgrid system. The results
obtained show the efficacy of Fog Computing for smart grid network in terms of
low power consumption, reduced storage requirement and overlay analysis
capabilities.
</dc:description>
 <dc:description>Comment: 6 pages, 10 figures, INDICON-2017 14TH IEEE India Council
  International Conference 2017, Dec 15-17, IIT Roorkee, India</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09648</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing Big Data as Networks: New Methods and Insights</dc:title>
 <dc:creator>Xu, Jian</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Our world produces massive data every day; they exist in diverse forms, from
pairwise data and matrix to time series and trajectories. Meanwhile, we have
access to the versatile toolkit of network analysis. Networks also have
different forms; from simple networks to higher-order network, each
representation has different capabilities in carrying information. For
researchers who want to leverage the power of the network toolkit, and apply it
beyond networks data to sequential data, diffusion data, and many more, the
question is: how to represent big data and networks? This dissertation makes a
first step to answering the question. It proposes the higher-order network,
which is a critical piece for representing higher-order interaction data; it
introduces a scalable algorithm for building the network, and visualization
tools for interactive exploration. Finally, it presents broad applications of
the higher-order network in the real-world.
</dc:description>
 <dc:description>Comment: PhD thesis, Univ Indiana (Jul 2017). Committee: Nitesh Chawla
  (chair), David Lodge, Tijana Milenkovec, Zoltan Toroczkai. Initial deposit at
  CurateND: https://curate.nd.edu/show/q524jm2466t</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09652</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Convergence of some Gradient-based Temporal-Differences Algorithms
  for Off-Policy Learning</dc:title>
 <dc:creator>Yu, Huizhen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C40, 62L20, 68W40</dc:subject>
 <dc:description>  We consider off-policy temporal-difference (TD) learning methods for policy
evaluation in Markov decision processes with finite spaces and discounted
reward criteria, and we present a collection of convergence results for several
gradient-based TD algorithms with linear function approximation. The algorithms
we analyze include: (i) two basic forms of two-time-scale gradient-based TD
algorithms, which we call GTD and which minimize the mean squared projected
Bellman error using stochastic gradient-descent; (ii) their &quot;robustified&quot;
biased variants; (iii) their mirror-descent versions which combine the
mirror-descent idea with TD learning; and (iv) a single-time-scale version of
GTD that solves minimax problems formulated for approximate policy evaluation.
  We derive convergence results for three types of stepsizes: constant
stepsize, slowly diminishing stepsize, as well as the standard type of
diminishing stepsize with a square-summable condition. For the first two types
of stepsizes, we apply the weak convergence method from stochastic
approximation theory to characterize the asymptotic behavior of the algorithms,
and for the standard type of stepsize, we analyze the algorithmic behavior with
respect to a stronger mode of convergence, almost sure convergence. Our
convergence results are for the aforementioned TD algorithms with three general
ways of setting their $\lambda$-parameters: (i) state-dependent $\lambda$; (ii)
a recently proposed scheme of using history-dependent $\lambda$ to keep the
eligibility traces of the algorithms bounded while allowing for relatively
large values of $\lambda$; and (iii) a composite scheme of setting the
$\lambda$-parameters that combines the preceding two schemes and allows a
broader class of generalized Bellman operators to be used for approximate
policy evaluation with TD methods.
</dc:description>
 <dc:description>Comment: Technical report; 80 pages</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09657</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The information bottleneck and geometric clustering</dc:title>
 <dc:creator>Strouse, D J</dc:creator>
 <dc:creator>Schwab, David J</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The information bottleneck (IB) approach to clustering takes a joint
distribution $P\!\left(X,Y\right)$ and maps the data $X$ to cluster labels $T$
which retain maximal information about $Y$ (Tishby et al., 1999). This
objective results in an algorithm that clusters data points based upon the
similarity of their conditional distributions $P\!\left(Y\mid X\right)$. This
is in contrast to classic &quot;geometric clustering&quot; algorithms such as $k$-means
and gaussian mixture models (GMMs) which take a set of observed data points
$\left\{ \mathbf{x}_{i}\right\}_{i=1:N}$ and cluster them based upon their
geometric (typically Euclidean) distance from one another. Here, we show how to
use the deterministic information bottleneck (DIB) (Strouse and Schwab, 2017),
a variant of IB, to perform geometric clustering, by choosing cluster labels
that preserve information about data point location on a smoothed dataset. We
also introduce a novel intuitive method to choose the number of clusters, via
kinks in the information curve. We apply this approach to a variety of simple
clustering problems, showing that DIB with our model selection procedure
recovers the generative cluster labels. We also show that, for one simple case,
DIB interpolates between the cluster boundaries of GMMs and $k$-means in the
large data limit. Thus, our IB approach to clustering also provides an
information-theoretic perspective on these classic algorithms.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09658</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Anomalies in Sequential Data with Higher-order Networks</dc:title>
 <dc:creator>Xu, Jian</dc:creator>
 <dc:creator>Saebi, Mandana</dc:creator>
 <dc:creator>Ribeiro, Bruno</dc:creator>
 <dc:creator>Kaplan, Lance M.</dc:creator>
 <dc:creator>Chawla, Nitesh V.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A major branch of anomaly detection methods rely on dynamic networks: raw
sequential data is first converted to a series of networks, then critical
change points are identified in the evolving network structure. However,
existing approaches use the first-order network (FON) to represent the
underlying raw data, which may lose important higher-order sequence patterns,
making higher-order anomalies undetectable in subsequent analysis. By replacing
FON with higher-order network (HONs), we show that existing anomaly detection
algorithms can better capture higher-order anomalies that may otherwise be
ignored. We show that the existing HON construction algorithm cannot be used
for the anomaly detection task due to the extra parameters and poor
scalability; we introduce a parameter-free algorithm that constructs HON in big
data sets. Using a large-scale synthetic data set with 11 billion web
clickstreams, we demonstrate how the proposed method can capture variable
orders of anomalies. Using a real-world taxi trajectory data, we show how the
proposed method amplifies higher-order anomaly signals. Finally, we provide
complexity analysis and benchmarking to show how one can incorporating
higher-order dependencies with a small overhead.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09662</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN Is All You Need</dc:title>
 <dc:creator>Chen, Qiming</dc:creator>
 <dc:creator>Wu, Ren</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The Convolution Neural Network (CNN) has demonstrated the unique advantage in
audio, image and text learning; recently it has also challenged Recurrent
Neural Networks (RNNs) with long short-term memory cells (LSTM) in
sequence-to-sequence learning, since the computations involved in CNN are
easily parallelizable whereas those involved in RNN are mostly sequential,
leading to a performance bottleneck. However, unlike RNN, the native CNN lacks
the history sensitivity required for sequence transformation; therefore
enhancing the sequential order awareness, or position-sensitivity, becomes the
key to make CNN the general deep learning model. In this work we introduce an
extended CNN model with strengthen position-sensitivity, called PoseNet. A
notable feature of PoseNet is the asymmetric treatment of position information
in the encoder and the decoder. Experiments shows that PoseNet allows us to
improve the accuracy of CNN based sequence-to-sequence learning significantly,
achieving around 33-36 BLEU scores on the WMT 2014 English-to-German
translation task, and around 44-46 BLEU scores on the English-to-French
translation task.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09665</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Patch</dc:title>
 <dc:creator>Brown, Tom B.</dc:creator>
 <dc:creator>Man&#xe9;, Dandelion</dc:creator>
 <dc:creator>Roy, Aurko</dc:creator>
 <dc:creator>Abadi, Mart&#xed;n</dc:creator>
 <dc:creator>Gilmer, Justin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a method to create universal, robust, targeted adversarial image
patches in the real world. The patches are universal because they can be used
to attack any scene, robust because they work under a wide variety of
transformations, and targeted because they can cause a classifier to output any
target class. These adversarial patches can be printed, added to any scene,
photographed, and presented to image classifiers; even when the patches are
small, they cause the classifiers to ignore the other items in the scene and
report a chosen target class.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09666</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast and Accurate Failure Frequency Approximation for $k$-Terminal
  Reliability Systems</dc:title>
 <dc:creator>Heidarzadeh, Anoosheh</dc:creator>
 <dc:creator>Sprintson, Alex</dc:creator>
 <dc:creator>Singh, Chanan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper considers the problem of approximating the failure frequency of
large-scale composite $k$-terminal reliability systems. In such systems, the
nodes ($k$ of which are terminals) are connected through components which are
subject to random failure and repair processes. At any time, a system failure
occurs if the surviving system fails to connect all the k terminals together.
We assume that each component's up-times and down-times follow statistically
independent stationary random processes, and these processes are statistically
independent across the components. In this setting, the exact computation of
failure frequency is known to be computationally intractable (NP-hard). In this
work, we present an algorithm to approximate the failure frequency for any
given multiplicative error factor that runs in polynomial time in the number of
(minimal) cutsets. Moreover, for the special case of all-terminal reliability
systems, i.e., where all nodes are terminals, we propose an algorithm for
approximating the failure frequency within an arbitrary multiplicative error
that runs in polynomial time in the number of nodes (which can be much smaller
than the number of cutsets). In addition, our simulation results confirm that
the proposed method is much faster and more accurate than the Monte Carlo
simulation technique for approximating the failure frequency.
</dc:description>
 <dc:description>Comment: 17 pages, 3 figures, 5 tables</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09668</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eventness: Object Detection on Spectrograms for Temporal Localization of
  Audio Events</dc:title>
 <dc:creator>Pham, Phuong</dc:creator>
 <dc:creator>Li, Juncheng</dc:creator>
 <dc:creator>Szurley, Joseph</dc:creator>
 <dc:creator>Das, Samarjit</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In this paper, we introduce the concept of Eventness for audio event
detection, which can, in part, be thought of as an analogue to Objectness from
computer vision. The key observation behind the eventness concept is that audio
events reveal themselves as 2-dimensional time-frequency patterns with specific
textures and geometric structures in spectrograms. These time-frequency
patterns can then be viewed analogously to objects occurring in natural images
(with the exception that scaling and rotation invariance properties do not
apply). With this key observation in mind, we pose the problem of detecting
monophonic or polyphonic audio events as an equivalent visual object(s)
detection problem under partial occlusion and clutter in spectrograms. We adapt
a state-of-the-art visual object detection model to evaluate the audio event
detection task on publicly available datasets. The proposed network has
comparable results with a state-of-the-art baseline and is more robust on
minority events. Provided large-scale datasets, we hope that our proposed
conceptual model of eventness will be beneficial to the audio signal processing
community towards improving performance of audio event detection.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, submitted to ICASSP 2018</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09673</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Instance Deep Learning for Weakly Supervised Audio Event
  Detection</dc:title>
 <dc:creator>Tseng, Shao-Yen</dc:creator>
 <dc:creator>Li, Juncheng</dc:creator>
 <dc:creator>Wang, Yun</dc:creator>
 <dc:creator>Szurley, Joseph</dc:creator>
 <dc:creator>Metze, Florian</dc:creator>
 <dc:creator>Das, Samarjit</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  State-of-the-art audio event detection (AED) systems rely on supervised
learning using strongly labeled data. However, this dependence severely limits
scalability to large-scale datasets where fine resolution annotations are too
expensive to obtain. In this paper, we propose a multiple instance learning
(MIL) framework for multi-class AED using weakly annotated labels. The proposed
MIL framework uses audio embeddings extracted from a pre-trained convolutional
neural network as input features. We show that by using audio embeddings the
MIL framework can be implemented using a simple DNN with performance comparable
to recurrent neural networks.
  We evaluate our approach by training an audio tagging system using a subset
of AudioSet, which is a large collection of weakly labeled YouTube video
excerpts. Combined with a late-fusion approach, we improve the F1 score of a
baseline audio tagging system by 17\%. We show that audio embeddings extracted
by the convolutional neural networks significantly boost the performance of all
MIL models. This framework reduces the model complexity of the AED system and
is suitable for applications where computational resources are limited.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, submitted to ICASSP 2018</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09677</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Momentum and Stochastic Momentum for Stochastic Gradient, Newton,
  Proximal Point and Subspace Descent Methods</dc:title>
 <dc:creator>Loizou, Nicolas</dc:creator>
 <dc:creator>Richt&#xe1;rik, Peter</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we study several classes of stochastic optimization algorithms
enriched with heavy ball momentum. Among the methods studied are: stochastic
gradient descent, stochastic Newton, stochastic proximal point and stochastic
dual subspace ascent. This is the first time momentum variants of several of
these methods are studied. We choose to perform our analysis in a setting in
which all of the above methods are equivalent. We prove global nonassymptotic
linear convergence rates for all methods and various measures of success,
including primal function values, primal iterates (in L2 sense), and dual
function values. We also show that the primal iterates converge at an
accelerated linear rate in the L1 sense. This is the first time a linear rate
is shown for the stochastic heavy ball method (i.e., stochastic gradient
descent method with momentum). Under somewhat weaker conditions, we establish a
sublinear convergence rate for Cesaro averages of primal iterates. Moreover, we
propose a novel concept, which we call stochastic momentum, aimed at decreasing
the cost of performing the momentum step. We prove linear convergence of
several stochastic methods with stochastic momentum, and show that in some
sparse data regimes and for sufficiently small momentum parameters, these
methods enjoy better overall complexity than methods with deterministic
momentum. Finally, we perform extensive numerical testing on artificial and
real datasets, including data coming from average consensus problems.
</dc:description>
 <dc:description>Comment: 47 pages, 7 figures, 7 tables</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09679</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enumerating consistent subgraphs of directed acyclic graphs: an insight
  into biomedical ontologies</dc:title>
 <dc:creator>Peng, Yisu</dc:creator>
 <dc:creator>Jiang, Yuxiang</dc:creator>
 <dc:creator>Radivojac, Predrag</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:description>  Modern problems of concept annotation associate an object of interest (gene,
individual, text document) with a set of interrelated textual descriptors
(functions, diseases, topics), often organized in concept hierarchies or
ontologies. Most ontologies can be seen as directed acyclic graphs, where nodes
represent concepts and edges represent relational ties between these concepts.
Given an ontology graph, each object can only be annotated by a consistent
subgraph; that is, a subgraph such that if an object is annotated by a
particular concept, it must also be annotated by all other concepts that
generalize it. Ontologies therefore provide a compact representation of a large
space of possible consistent subgraphs; however, until now we have not been
aware of a practical algorithm that can enumerate such annotation spaces for a
given ontology. In this work we propose an algorithm for enumerating consistent
subgraphs of directed acyclic graphs. The algorithm recursively partitions the
graph into strictly smaller graphs until the resulting graph becomes a rooted
tree (forest), for which a linear-time solution is computed. It then combines
the tallies from graphs created in the recursion to obtain the final count. We
prove the correctness of this algorithm and then apply it to characterize four
major biomedical ontologies. We believe this work provides valuable insights
into concept annotation spaces and predictability of ontological annotation.
</dc:description>
 <dc:description>Comment: 18 pages, 6 figures</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09680</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Light-Weight Multimodal Framework for Improved Environmental Audio
  Tagging</dc:title>
 <dc:creator>Li, Juncheng</dc:creator>
 <dc:creator>Wang, Yun</dc:creator>
 <dc:creator>Szurley, Joseph</dc:creator>
 <dc:creator>Metze, Florian</dc:creator>
 <dc:creator>Das, Samarjit</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  The lack of strong labels has severely limited the state-of-the-art fully
supervised audio tagging systems to be scaled to larger dataset. Meanwhile,
audio-visual learning models based on unlabeled videos have been successfully
applied to audio tagging, but they are inevitably resource hungry and require a
long time to train. In this work, we propose a light-weight, multimodal
framework for environmental audio tagging. The audio branch of the framework is
a convolutional and recurrent neural network (CRNN) based on multiple instance
learning (MIL). It is trained with the audio tracks of a large collection of
weakly labeled YouTube video excerpts; the video branch uses pretrained
state-of-the-art image recognition networks and word embeddings to extract
information from the video track and to map visual objects to sound events.
Experiments on the audio tagging task of the DCASE 2017 challenge show that the
incorporation of video information improves a strong baseline audio tagging
system by 5.3\% absolute in terms of $F_1$ score. The entire system can be
trained within 6~hours on a single GPU, and can be easily carried over to other
audio tasks such as speech sentimental analysis.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, submitted to ICASSP 2018</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09684</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometry Processing of Conventionally Produced Mouse Brain Slice Images</dc:title>
 <dc:creator>Agarwal, Nitin</dc:creator>
 <dc:creator>Xu, Xiangmin</dc:creator>
 <dc:creator>Meenakshisundaram, Gopi</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Brain mapping research in most neuroanatomical laboratories relies on
conventional processing techniques, which often introduce histological
artifacts such as tissue tears and tissue loss. In this paper we present
techniques and algorithms for automatic registration and 3D reconstruction of
conventionally produced mouse brain slices in a standardized atlas space. This
is achieved first by constructing a virtual 3D mouse brain model from annotated
slices of Allen Reference Atlas (ARA). Virtual re-slicing of the reconstructed
model generates ARA-based slice images corresponding to the microscopic images
of histological brain sections. These image pairs are aligned using a geometric
approach through contour images. Histological artifacts in the microscopic
images are detected and removed using Constrained Delaunay Triangulation before
performing global alignment. Finally, non-linear registration is performed by
solving Laplace's equation with Dirichlet boundary conditions. Our methods
provide significant improvements over previously reported registration
techniques for the tested slices in 3D space, especially on slices with
significant histological artifacts. Further, as an application we count the
number of neurons in various anatomical regions using a dataset of 51
microscopic slices from a single mouse brain. This work represents a
significant contribution to this subfield of neuroscience as it provides tools
to neuroanatomist for analyzing and processing histological data.
</dc:description>
 <dc:description>Comment: 14 pages, 11 figures</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09686</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deviator Detection under Imperfect Monitoring</dc:title>
 <dc:creator>Berwanger, Dietmar</dc:creator>
 <dc:creator>Ramanujam, R.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>91A20, 91A28, 68W15, 68T37</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Grim-trigger strategies are a fundamental mechanism for sustaining equilibria
in iterated games: the players cooperate along an agreed path, and as soon as
one player deviates, the others form a coalition to play him down to his minmax
level. A precondition to triggering such a strategy is that the identity of the
deviating player becomes common knowledge among the other players. This can be
difficult or impossible to attain in games where the information structure
allows only imperfect monitoring of the played actions or of the global state.
  We study the problem of synthesising finite-state strategies for detecting
the deviator from an agreed strategy profile in games played on finite graphs
with different information structures. We show that the problem is undecidable
in the general case where the global state cannot be monitored. On the other
hand, we prove that under perfect monitoring of the global state and imperfect
monitoring of actions, the problem becomes decidable, and we present an
effective synthesis procedure that covers infinitely repeated games with
private monitoring.
</dc:description>
 <dc:description>Comment: Extended abstract, presented at the 5th Workshop on Strategic
  Reasoning 2017</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09687</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Representation Learning with Logic for Language Processing</dc:title>
 <dc:creator>Rockt&#xe4;schel, Tim</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The current state-of-the-art in many natural language processing and
automated knowledge base completion tasks is held by representation learning
methods which learn distributed vector representations of symbols via
gradient-based optimization. They require little or no hand-crafted features,
thus avoiding the need for most preprocessing steps and task-specific
assumptions. However, in many cases representation learning requires a large
amount of annotated training data to generalize well to unseen data. Such
labeled training data is provided by human annotators who often use formal
logic as the language for specifying annotations. This thesis investigates
different combinations of representation learning methods with logic for
reducing the need for annotated training data, and for improving
generalization.
</dc:description>
 <dc:description>Comment: PhD Thesis, University College London, Submitted and accepted in 2017</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09691</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Entity Resolution Using Probabilistic Signatures on Parallel
  Databases</dc:title>
 <dc:creator>Zhang, Yuhang</dc:creator>
 <dc:creator>Ng, Kee Siong</dc:creator>
 <dc:creator>Walker, Michael</dc:creator>
 <dc:creator>Chou, Pauline</dc:creator>
 <dc:creator>Churchill, Tania</dc:creator>
 <dc:creator>Christen, Peter</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Accurate and efficient entity resolution is an open challenge of particular
relevance to intelligence organisations that collect large datasets from
disparate sources with differing levels of quality and standard. Starting from
a first-principles formulation of entity resolution, this paper presents a
novel Entity Resolution algorithm that introduces a data-driven blocking and
record-linkage technique based on the probabilistic identification of entity
signatures in data. The scalability and accuracy of the proposed algorithm are
evaluated using benchmark datasets and shown to achieve state-of-the-art
results. The proposed algorithm can be implemented simply on modern parallel
databases, which allows it to be deployed with relative ease in large
industrial applications.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09692</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Short Note on Parameterized Computation of Network Reliability with
  respect to Treewidth</dc:title>
 <dc:creator>Goharshady, Amir Kafshdar</dc:creator>
 <dc:creator>Mohammadi, Fatemeh</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider the classic problem of network reliability. A network is given
together with a source vertex, one or more target vertices and probabilities
assigned to each of the edges. Each edge appears in the network with its
associated probability and the problem is to determine the probability of
having at least one source-to-target path. This problem is known to be NP-hard
for general networks and has been solved for several special families.
  In this work we present a fixed-parameter algorithm based on treewidth, which
is a measure of tree-likeness of graphs. The problem was already known to be
solvable in linear time for bounded treewidth, however the known methods used
complicated structures and were not easy to implement. We provide a
significantly simpler and more intuitive algorithm that while remaining linear,
is much easier to implement.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:date>2017-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09702</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Control Computation via Evolution Partial Differential Equation
  with Arbitrary Definite Conditions</dc:title>
 <dc:creator>Zhang, Sheng</dc:creator>
 <dc:creator>Yong, En-Mi</dc:creator>
 <dc:creator>Qian, Wei-Qi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The compact Variation Evolving Method (VEM) that originates from the
continuous-time dynamics stability theory seeks the optimal solutions with
variation evolution principle. It is further developed to be more flexible in
solving the Optimal Control Problems (OCPs), by relaxing the definite
conditions from a feasible solution to an arbitrary one for the derived
Evolution Partial Differential Equation (EPDE). To guarantee the validity, an
unconstrained Lyapunov functional that has the same minimum as the original OCP
is constructed, and it ensures the evolution towards the optimal solution from
infeasible solutions. With the semi-discrete method, the EPDE is transformed to
the finite-dimensional Initial-value Problem (IVP), and then solved with common
Ordinary Differential Equation (ODE) numerical integration methods.
Illustrative examples are presented to show the effectiveness of the proposed
method.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1709.02242,
  arXiv:1711.02998</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09707</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep learning for universal linear embeddings of nonlinear dynamics</dc:title>
 <dc:creator>Lusch, Bethany</dc:creator>
 <dc:creator>Kutz, J. Nathan</dc:creator>
 <dc:creator>Brunton, Steven L.</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Identifying coordinate transformations that make strongly nonlinear dynamics
approximately linear is a central challenge in modern dynamical systems. These
transformations have the potential to enable prediction, estimation, and
control of nonlinear systems using standard linear theory. The Koopman operator
has emerged as a leading data-driven embedding, as eigenfunctions of this
operator provide intrinsic coordinates that globally linearize the dynamics.
However, identifying and representing these eigenfunctions has proven to be
mathematically and computationally challenging. This work leverages the power
of deep learning to discover representations of Koopman eigenfunctions from
trajectory data of dynamical systems. Our network is parsimonious and
interpretable by construction, embedding the dynamics on a low-dimensional
manifold that is of the intrinsic rank of the dynamics and parameterized by the
Koopman eigenfunctions. In particular, we identify nonlinear coordinates on
which the dynamics are globally linear using a modified auto-encoder. We also
generalize Koopman representations to include a ubiquitous class of systems
that exhibit continuous spectra, ranging from the simple pendulum to nonlinear
optics and broadband turbulence. Our framework parametrizes the continuous
frequency using an auxiliary network, enabling a compact and efficient
embedding at the intrinsic rank, while connecting our models to half a century
of asymptotics. In this way, we benefit from the power and generality of deep
learning, while retaining the physical interpretability of Koopman embeddings.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09708</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning More Universal Representations for Transfer-Learning</dc:title>
 <dc:creator>Tamaazousti, Youssef</dc:creator>
 <dc:creator>Borgne, Herv&#xe9; Le</dc:creator>
 <dc:creator>Hudelot, C&#xe9;line</dc:creator>
 <dc:creator>Seddik, Mohamed El Amine</dc:creator>
 <dc:creator>Tamaazousti, Mohamed</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Transfer learning is commonly used to address the problem of the prohibitive
need in annotated data when one want to classify visual content with a
Convolutional Neural Network (CNN). We address the problem of the universality
of the CNN-based representation of images in such a context. The
state-of-the-art consists in diversifying the source problem on which the CNN
is learned. It reduces the cost for the target problem but still requires a
large amount of efforts to satisfy the source problem needs in annotated data.
We propose an unified framework of the methods that improve the universality by
diversifying the source problem. We also propose two methods that improve the
universality but pay special attention to limit the need of annotated data.
Finally, we propose a new evaluation protocol to compare the ability of
CNN-based representation to tackle the problem of universality. It demonstrates
the interest of our work on 10 publicly available benchmarks, relating to a
variety of visual classification problems.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI)</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09709</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Report: Dynamic Eye Movement Matching and Visualization Tool in Neuro
  Gesture</dc:title>
 <dc:creator>Xu, Qiangeng</dc:creator>
 <dc:creator>Kender, John</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the research of the impact of gestures using by a lecturer, one
challenging task is to infer the attention of a group of audiences. Two
important measurements that can help infer the level of attention are eye
movement data and Electroencephalography (EEG) data. Under the fundamental
assumption that a group of people would look at the same place if they all pay
attention at the same time, we apply a method, &quot;Time Warp Edit Distance&quot;, to
calculate the similarity of their eye movement trajectories. Moreover, we also
cluster eye movement pattern of audiences based on these pair-wised similarity
metrics. Besides, since we don't have a direct metric for the &quot;attention&quot;
ground truth, a visual assessment would be beneficial to evaluate the
gesture-attention relationship. Thus we also implement a visualization tool.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09710</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On low for speed oracles</dc:title>
 <dc:creator>Bienvenu, Laurent</dc:creator>
 <dc:creator>Downey, Rod</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03D15, 03D25, 03D32, 03D30, 03D80</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Relativizing computations of Turing machines to an oracle is a central
concept in the theory of computation, both in complexity theory and in
computability theory(!). Inspired by lowness notions from computability theory,
Allender introduced the concept of &quot;low for speed&quot; oracles. An oracle A is low
for speed if relativizing to A has essentially no effect on computational
complexity, meaning that if a decidable language can be decided in time $f(n)$
with access to oracle A, then it can be decided in time poly(f(n)) without any
oracle. The existence of non-computable such A's was later proven by Bayer and
Slaman, who even constructed a computably enumerable one, and exhibited a
number of properties of these oracles as well as interesting connections with
computability theory. In this paper, we pursue this line of research, answering
the questions left by Bayer and Slaman and give further evidence that the
structure of the class of low for speed oracles is a very rich one.
</dc:description>
 <dc:description>Comment: A preliminary version of this paper was published in the proceedings
  of the STACS 2018 conference</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09713</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extrapolating Expected Accuracies for Large Multi-Class Problems</dc:title>
 <dc:creator>Zheng, Charles</dc:creator>
 <dc:creator>Achanta, Rakesh</dc:creator>
 <dc:creator>Benjamini, Yuval</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The difficulty of multi-class classification generally increases with the
number of classes. Using data from a subset of the classes, can we predict how
well a classifier will scale with an increased number of classes? Under the
assumptions that the classes are sampled identically and independently from a
population, and that the classifier is based on independently learned scoring
functions, we show that the expected accuracy when the classifier is trained on
k classes is the (k-1)st moment of a certain distribution that can be estimated
from data. We present an unbiased estimation method based on the theory, and
demonstrate its application on a facial recognition example.
</dc:description>
 <dc:description>Comment: Submitted to JMLR</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09716</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Modal Active Perception for Information Gathering in Science
  Missions</dc:title>
 <dc:creator>Arora, Akash</dc:creator>
 <dc:creator>Furlong, P. Michael</dc:creator>
 <dc:creator>Fitch, Robert</dc:creator>
 <dc:creator>Sukkarieh, Salah</dc:creator>
 <dc:creator>Fong, Terrence</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robotic science missions in remote environments, such as deep ocean and outer
space, can involve studying phenomena that cannot directly be observed using
on-board sensors but must be deduced by combining measurements of correlated
variables with domain knowledge. Traditionally, in such missions, robots
passively gather data along prescribed paths, while inference, path planning,
and other high level decision making is largely performed by a supervisory
science team. However, communication constraints hinder these processes, and
hence the rate of scientific progress. This paper presents an active perception
approach that aims to reduce robots' reliance on human supervision and improve
science productivity by encoding scientists' domain knowledge and decision
making process on-board. We use Bayesian networks to compactly model critical
aspects of scientific knowledge while remaining robust to observation and
modeling uncertainty. We then formulate path planning and sensor scheduling as
an information gain maximization problem, and propose a sampling-based solution
based on Monte Carlo tree search to plan informative sensing actions which
exploit the knowledge encoded in the network. The computational complexity of
our framework does not grow with the number of observations taken and allows
long horizon planning in an anytime manner, making it highly applicable to
field robotics. Simulation results show statistically significant performance
improvements over baseline methods, and we validate the practicality of our
approach through both hardware experiments and simulated experiments with field
data gathered during the NASA Mojave Volatiles Prospector science expedition.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09718</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Directional Statistics and Filtering Using libDirectional</dc:title>
 <dc:creator>Kurz, Gerhard</dc:creator>
 <dc:creator>Gilitschenski, Igor</dc:creator>
 <dc:creator>Pfaff, Florian</dc:creator>
 <dc:creator>Drude, Lukas</dc:creator>
 <dc:creator>Hanebeck, Uwe D.</dc:creator>
 <dc:creator>Haeb-Umbach, Reinhold</dc:creator>
 <dc:creator>Siegwart, Roland Y.</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we present libDirectional, a MATLAB library for directional
statistics and directional estimation. It supports a variety of commonly used
distributions on the unit circle, such as the von Mises, wrapped normal, and
wrapped Cauchy distributions. Furthermore, various distributions on
higher-dimensional manifolds such as the unit hypersphere and the hypertorus
are available. Based on these distributions, several recursive filtering
algorithms in libDirectional allow estimation on these manifolds. The
functionality is implemented in a clear, well-documented, and object-oriented
structure that is both easy to use and easy to extend.
</dc:description>
 <dc:description>Comment: Version accepted for Publication in the Journal of Statistical
  Software</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09721</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of the Game-Theoretic Modeling of Backscatter Wireless Sensor
  Networks under Smart Interference</dc:title>
 <dc:creator>Hong, Seung Gwan</dc:creator>
 <dc:creator>Hwang, Yu Min</dc:creator>
 <dc:creator>Lee, Sun Yui</dc:creator>
 <dc:creator>Shin, Yoan</dc:creator>
 <dc:creator>Kim, Dong In</dc:creator>
 <dc:creator>Kim, Jin Young</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  In this paper, we study an interference avoidance scenario in the presence of
a smart interferer which can rapidly observe the transmit power of a
backscatter wireless sensor network (WSN) and effectively interrupt backscatter
signals. We consider a power control with a sub-channel allocation to avoid
interference attacks and a time-switching ratio for backscattering and RF
energy harvesting in backscatter WSNs. We formulate the problem based on a
Stackelberg game theory and compute the optimal transmit power, time-switching
ratio, and sub-channel allocation parameter to maximize a utility function
against the smart interference. We propose two algorithms for the utility
maximization using Lagrangian dual decomposition for the backscatter WSN and
the smart interference to prove the existence of the Stackelberg equilibrium.
Numerical results show that the proposed algorithms effectively maximize the
utility, compared to that of the algorithm based on the Nash game, so as to
overcome smart interference in backscatter communications.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09722</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Satellite-Based Continuous-Variable Quantum Communications:
  State-of-the-Art and a Predictive Outlook</dc:title>
 <dc:creator>Hosseinidehaj, Nedasadat</dc:creator>
 <dc:creator>Malaney, Robert</dc:creator>
 <dc:creator>Ng, Soon Xin</dc:creator>
 <dc:creator>Hanzo, Lajos</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The recent launch of the Micius quantum-enabled satellite heralds a major
step forward for long-range quantum communication. Using single-photon
discrete-variable quantum states, this exciting new development proves beyond
any doubt that all of the quantum protocols previously deployed over limited
ranges in terrestrial experiments can, in fact, be translated to global
distances via the use of low-orbit satellites. In this work, we survey the
imminent extension of space-based quantum communication to the
continuous-variable regime - the quantum regime perhaps most closely related to
classical wireless communications. The CV regime offers the potential for
increased communication performance and represents the next major step forward
for quantum communications and the development of the global quantum internet.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Communications Surveys and Tutorials. Contains
  updated references</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09724</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NR Wide Bandwidth Operations</dc:title>
 <dc:creator>Jeon, Jeongho</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The 3rd Generation Partnership Project (3GPP) is in the process of developing
the next generation radio access technology, named New Radio (NR), which will
be proposed as a candidate technology for IMT-2020. This article outlines the
wide bandwidth operation of NR, among other new features being considered,
based on the up-to-date discussions and decisions made in 3GPP standardization
meetings. The much wider channel bandwidth of NR, compared to LTE, enables more
efficient use of resources than the existing carrier aggregation framework at
lower control overhead. The support of multiple sub-carrier spacing options
allows NR to operate in a wide range of carrier frequency from sub-6 GHz band
to mmWave band with appropriate handling of multi-path delay spread and phase
noise depending on the carrier frequency. In addition, the introduction of the
new bandwidth part concept allows to flexibly and dynamically configure User
Equipment's (UE's) operating bandwidth, which will make NR an energy efficient
solution despite the support of wide bandwidth. Other NR wideband operation
related issues, such as the support of UEs with limited radio frequency (RF)
capability and frequency domain resource indexing, are also explained in this
article.
</dc:description>
 <dc:description>Comment: Final manuscript to IEEE Communications Magazine on Key Technologies
  for 5G New Radio (initial submission on August 1, 2017, Revised on December
  14, 2017, and accepted on December 18, 2017)</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09726</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CHOKeD: A Fair Active Queue Management System</dc:title>
 <dc:creator>Manzoor, Sanaullah</dc:creator>
 <dc:creator>Abbas, Ghulam</dc:creator>
 <dc:creator>Hussain, Masroor</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Fairness is the significant factor to sustain best effort delivery of network
services. Now-a-days, real-time multimedia applications have evolved largely
over the Internet. Most of multimedia services are unresponsive during network
congestion. Unresponsive traffic streams steal most network bandwidth and
starve out some other flows which are responsive during network congestion. In
the presence of these unresponsive traffic flows, protection of responsive
flows has become a major issue. Many Active Queue Management (AQM) based
solutions have been recommended to protect responsive traffic flows from
unresponsive ones and to ensure fairness among all traffic flows. The thesis
proposes a novel AQM scheme CHOKeD, to deliver fairness among all flows of a
congested link. It is a completely stateless approach. CHOKeD is based on
dynamic drawing factor to penalize unresponsive traffic. It successfully
protects responsive flows in the presence of unresponsive flows. CHOKeD
features such as fairness, high throughput of responsive traffic and stateless
design, are encouraging factors for its deployment over the edge as well as the
network core routers. Extensive simulations have been carried out to evaluate
its performance under real-time network scenarios
</dc:description>
 <dc:description>Comment: MS thesis</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09731</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ASYMP: Fault-tolerant Mining of Massive Graphs</dc:title>
 <dc:creator>Fleury, Eduardo</dc:creator>
 <dc:creator>Lattanzi, Silvio</dc:creator>
 <dc:creator>Mirrokni, Vahab</dc:creator>
 <dc:creator>Perozzi, Bryan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present ASYMP, a distributed graph processing system developed for the
timely analysis of graphs with trillions of edges. ASYMP has several
distinguishing features including a robust fault tolerance mechanism, a
lockless architecture which scales seamlessly to thousands of machines, and
efficient data access patterns to reduce per-machine overhead. ASYMP is used to
analyze the largest graphs at Google, and the graphs we consider in our
empirical evaluation here are, to the best of our knowledge, the largest
considered in the literature.
  Our experimental results show that compared to previous graph processing
frameworks at Google, ASYMP can scale to larger graphs, operate on more crowded
clusters, and complete real-world graph mining analytic tasks faster. First, we
evaluate the speed of ASYMP, where we show that across a diverse selection of
graphs, it runs Connected Component 3-50x faster than state of the art
implementations in MapReduce and Pregel. Then we demonstrate the scalability
and parallelism of this framework: first by showing that the running time
increases linearly by increasing the size of the graphs (without changing the
number of machines), and then by showing the gains in running time while
increasing the number of machines. Finally, we demonstrate the fault-tolerance
properties for the framework, showing that inducing 50% of our machines to fail
increases the running time by only 41%.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09738</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Decision Tree Complexity of String Matching</dc:title>
 <dc:creator>He, Xiaoyu</dc:creator>
 <dc:creator>Huang, Neng</dc:creator>
 <dc:creator>Sun, Xiaoming</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  String matching is one of the most fundamental problems in computer science.
A natural problem is to find the number of characters that need to be queried
(i.e. the decision tree complexity) in a string in order to determine whether
this string contains a certain pattern. Rivest showed that for every pattern
$p$, in the worst case any deterministic algorithm needs to query at least
$n-|p|+1$ characters, where $n$ is the length of the string and $|p|$ is the
length of the pattern. He further conjectured that these bounds are tight. By
using adversary methods, Tuza disproved this conjecture and showed that more
than half of binary patterns are evasive, i.e. any algorithm needs to query all
the characters. In this paper, we give a query algorithm which settles the
decision tree complexity for almost all patterns. Using the algebraic approach
of Rivest and Vuillemin we give a new sufficient condition for the evasiveness
of patterns, which reveals an interesting connection to Skolem's Problem.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09741</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topological and Algebraic Properties of Chernoff Information between
  Gaussian Graphs</dc:title>
 <dc:creator>Li, Binglin</dc:creator>
 <dc:creator>Wei, Shuangqing</dc:creator>
 <dc:creator>Wang, Yue</dc:creator>
 <dc:creator>Yuan, Jian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we want to find out the determining factors of Chernoff
information in distinguishing a set of Gaussian graphs. We find that Chernoff
information of two Gaussian graphs can be determined by the generalized
eigenvalues of their covariance matrices. We find that the unit generalized
eigenvalue doesn't affect Chernoff information and its corresponding dimension
doesn't provide information for classification purpose. In addition, we can
provide a partial ordering using Chernoff information between a series of
Gaussian trees connected by independent grafting operations. With the
relationship between generalized eigenvalues and Chernoff information, we can
do optimal linear dimension reduction with least loss of information for
classification.
</dc:description>
 <dc:description>Comment: Submitted to ISIT2018, and this version contains proofs of the
  propositions in the paper</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09742</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chernoff Information between Gaussian Trees</dc:title>
 <dc:creator>Li, Binglin</dc:creator>
 <dc:creator>Wei, Shuangqing</dc:creator>
 <dc:creator>Wang, Yue</dc:creator>
 <dc:creator>Yuan, Jian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we aim to provide a systematic study of the relationship
between Chernoff information and topological, as well as algebraic properties
of the corresponding Gaussian tree graphs for the underlying graphical testing
problems. We first show the relationship between Chernoff information and
generalized eigenvalues of the associated covariance matrices. It is then
proved that Chernoff information between two Gaussian trees sharing certain
local subtree structures can be transformed into that of two smaller trees.
Under our proposed grafting operations, bottleneck Gaussian trees, namely,
Gaussian trees connected by one such operation, can thus be simplified into two
3-node Gaussian trees, whose topologies and edge weights are subject to the
specifics of the operation. Thereafter, we provide a thorough study about how
Chernoff information changes when small differences are accumulated into bigger
ones via concatenated grafting operations. It is shown that the two Gaussian
trees connected by more than one grafting operation may not have bigger
Chernoff information than that of one grafting operation unless these grafting
operations are separate and independent. At the end, we propose an optimal
linear dimensional reduction method related to generalized eigenvalues.
</dc:description>
 <dc:description>Comment: Submitted to Information Sciences, and this version contains proofs
  of the propositions in the paper</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09749</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New bounds for range closest-pair problems</dc:title>
 <dc:creator>Xue, Jie</dc:creator>
 <dc:creator>Li, Yuan</dc:creator>
 <dc:creator>Rahul, Saladi</dc:creator>
 <dc:creator>Janardan, Ravi</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Given a dataset $S$ of points in $\mathbb{R}^2$, the range closest-pair (RCP)
problem aims to preprocess $S$ into a data structure such that when a query
range $X$ is specified, the closest-pair in $S \cap X$ can be reported
efficiently. The RCP problem can be viewed as a range-search version of the
classical closest-pair problem, and finds applications in many areas. Due to
its non-decomposability, the RCP problem is much more challenging than many
traditional range-search problems. This paper revisits the RCP problem, and
proposes new data structures for various query types including quadrants,
strips, rectangles, and halfplanes. Both worst-case and average-case analyses
(in the sense that the data points are drawn uniformly and independently from
the unit square) are applied to these new data structures, which result in new
bounds for the RCP problem. Some of the new bounds significantly improve the
previous results, while the others are entirely new.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09752</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing Fair Ranking Schemes</dc:title>
 <dc:creator>Asudeh, Abolfazl</dc:creator>
 <dc:creator>Jagadish, H. V.</dc:creator>
 <dc:creator>Stoyanovich, Julia</dc:creator>
 <dc:creator>Das, Gautam</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Items from a database are often ranked based on a combination of multiple
criteria. A user may have the flexibility to accept combinations that weigh
these criteria differently, within limits. On the other hand, this choice of
weights can greatly affect the fairness of the produced ranking. In this paper,
we develop a system that helps users choose criterion weights that lead to
greater fairness.
  We consider ranking functions that compute the score of each item as a
weighted sum of (numeric) attribute values, and then sort items on their score.
Each ranking function can be expressed as a vector of weights, or as a point in
a multi-dimensional space. For a broad range of fairness criteria, we show how
to efficiently identify regions in this space that satisfy these criteria.
Using this identification method, our system is able to tell users whether
their proposed ranking function satisfies the desired fairness criteria and, if
it does not, to suggest the smallest modification that does. We develop
user-controllable approximation that and indexing techniques that are applied
during preprocessing, and support sub-second response times during the online
phase. Our extensive experiments on real datasets demonstrate that our methods
are able to find solutions that satisfy fairness criteria effectively and
efficiently.
</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09757</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Celebrities Endorse Politicians: Analyzing the Behavior of
  Celebrity Followers in the 2016 U.S. Presidential Election</dc:title>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Thanks to their name recognition and popularity, celebrities play an
important role in American politics. Celebrity endorsements could add to the
momentum of a politician's campaign and win the candidate extensive media
coverage. There is one caveat though: the political preference of celebrity
followers might differ from that of the celebrity. In this paper we explore
that possibility. By carefully studying six prominent endorsements to the
leading presidential candidates in the 2016 U.S. presidential election and
statistically modeling Twitter &quot;follow&quot; behavior, we show (1) followers of all
the celebrities with the exception of Lady Gaga are more likely to follow a
large number of candidates and (2) the opinion of celebrity followers could
systematically differ from that of the celebrity. Our methodology can be
generalized to the study of such events as NBA players' refusing to visit the
White House and pop singers' meeting with Dalai Lama.
</dc:description>
 <dc:description>Comment: 10 pages. arXiv admin note: substantial text overlap with
  arXiv:1702.00048</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09763</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PixelSNAIL: An Improved Autoregressive Generative Model</dc:title>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Mishra, Nikhil</dc:creator>
 <dc:creator>Rohaninejad, Mostafa</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Autoregressive generative models consistently achieve the best results in
density estimation tasks involving high dimensional data, such as images or
audio. They pose density estimation as a sequence modeling task, where a
recurrent neural network (RNN) models the conditional distribution over the
next element conditioned on all previous elements. In this paradigm, the
bottleneck is the extent to which the RNN can model long-range dependencies,
and the most successful approaches rely on causal convolutions, which offer
better access to earlier parts of the sequence than conventional RNNs. Taking
inspiration from recent work in meta reinforcement learning, where dealing with
long-range dependencies is also essential, we introduce a new generative model
architecture that combines causal convolutions with self attention. In this
note, we describe the resulting model and present state-of-the-art
log-likelihood results on CIFAR-10 (2.85 bits per dim) and $32 \times 32$
ImageNet (3.80 bits per dim). Our implementation is available at
https://github.com/neocxi/pixelsnail-public
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09765</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private Matrix Completion, Revisited</dc:title>
 <dc:creator>Jain, Prateek</dc:creator>
 <dc:creator>Thakkar, Om</dc:creator>
 <dc:creator>Thakurta, Abhradeep</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of privacy-preserving collaborative filtering where the
objective is to reconstruct the entire users-items preference matrix using a
few observed preferences of users for some of the items. Furthermore, the
collaborative filtering algorithm should reconstruct the preference matrix
while preserving the privacy of each user. We study this problem in the setting
of joint differential privacy where each user computes her own preferences for
all the items, without violating privacy of other users' preferences.
  We provide the first provably differentially private algorithm with formal
utility guarantees for this problem. Our algorithm is based on the Frank-Wolfe
(FW) method, and consistently estimates the underlying preference matrix as
long as the number of users $m$ is $\omega(n^{5/4})$, where $n$ is the number
of items, and each user provides her preference for at least $\sqrt{n}$
randomly selected items. We also empirically evaluate our FW-based algorithm on
a suite of datasets, and show that our method provides nearly same accuracy as
the state-of-the-art non-private algorithm, and outperforms the
state-of-the-art private algorithm by as much as 30%.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09771</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Analysis of EEGs Using Big Data and Hybrid Deep Learning
  Architectures</dc:title>
 <dc:creator>Golmohammadi, Meysam</dc:creator>
 <dc:creator>Torbati, Amir Hossein Harati Nejad</dc:creator>
 <dc:creator>de Diego, Silvia Lopez</dc:creator>
 <dc:creator>Obeid, Iyad</dc:creator>
 <dc:creator>Picone, Joseph</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Objective: A clinical decision support tool that automatically interprets
EEGs can reduce time to diagnosis and enhance real-time applications such as
ICU monitoring. Clinicians have indicated that a sensitivity of 95% with a
specificity below 5% was the minimum requirement for clinical acceptance. We
propose a highperformance classification system based on principles of big data
and machine learning. Methods: A hybrid machine learning system that uses
hidden Markov models (HMM) for sequential decoding and deep learning networks
for postprocessing is proposed. These algorithms were trained and evaluated
using the TUH EEG Corpus, which is the world's largest publicly available
database of clinical EEG data. Results: Our approach delivers a sensitivity
above 90% while maintaining a specificity below 5%. This system detects three
events of clinical interest: (1) spike and/or sharp waves, (2) periodic
lateralized epileptiform discharges, (3) generalized periodic epileptiform
discharges. It also detects three events used to model background noise: (1)
artifacts, (2) eye movement (3) background. Conclusions: A hybrid HMM/deep
learning system can deliver a low false alarm rate on EEG event detection,
making automated analysis a viable option for clinicians. Significance: The TUH
EEG Corpus enables application of highly data consumptive machine learning
algorithms to EEG analysis. Performance is approaching clinical acceptance for
real-time applications.
</dc:description>
 <dc:description>Comment: Under review in Journal of Clinical Neurophysiology</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09775</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sky detection and log illumination refinement for PDE-based hazy image
  contrast enhancement</dc:title>
 <dc:creator>Nnolim, Uche A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This report presents the results of a sky detection technique used to improve
the performance of a previously developed partial differential equation
(PDE)-based hazy image enhancement algorithm. Additionally, a proposed
alternative method utilizes a function for log illumination refinement to
improve de-hazing results while avoiding over-enhancement of sky or homogeneous
regions. The algorithms were tested with several benchmark and calibration
images and compared with several standard algorithms from the literature.
Results indicate that the algorithms yield mostly consistent results and
surpasses several of the other algorithms in terms of colour and contrast
enhancement in addition to improved edge visibility.
</dc:description>
 <dc:description>Comment: 22 pages, 13 figures, 5 tables</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09776</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Architectures for Automated Seizure Detection in Scalp EEGs</dc:title>
 <dc:creator>Golmohammadi, Meysam</dc:creator>
 <dc:creator>Ziyabari, Saeedeh</dc:creator>
 <dc:creator>Shah, Vinit</dc:creator>
 <dc:creator>de Diego, Silvia Lopez</dc:creator>
 <dc:creator>Obeid, Iyad</dc:creator>
 <dc:creator>Picone, Joseph</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Automated seizure detection using clinical electroencephalograms is a
challenging machine learning problem because the multichannel signal often has
an extremely low signal to noise ratio. Events of interest such as seizures are
easily confused with signal artifacts (e.g, eye movements) or benign variants
(e.g., slowing). Commercially available systems suffer from unacceptably high
false alarm rates. Deep learning algorithms that employ high dimensional models
have not previously been effective due to the lack of big data resources. In
this paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid
deep structures including Convolutional Neural Networks and Long Short-Term
Memory Networks. We introduce a novel recurrent convolutional architecture that
delivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated
our system on a held-out evaluation set based on the Duke University Seizure
Corpus and demonstrate that performance trends are similar to the TUH EEG
Seizure Corpus. This is a significant finding because the Duke corpus was
collected with different instrumentation and at different hospitals. Our work
shows that deep learning architectures that integrate spatial and temporal
contexts are critical to achieving state of the art performance and will enable
a new generation of clinically-acceptable technology.
</dc:description>
 <dc:description>Comment: nder review in International Conference on Machine Learning,
  Stockholm, Sweden</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09783</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Compositional Neural Language Model</dc:title>
 <dc:creator>Wang, Wenlin</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Wang, Wenqi</dc:creator>
 <dc:creator>Shen, Dinghan</dc:creator>
 <dc:creator>Huang, Jiaji</dc:creator>
 <dc:creator>Ping, Wei</dc:creator>
 <dc:creator>Satheesh, Sanjeev</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a Topic Compositional Neural Language Model (TCNLM), a novel
method designed to simultaneously capture both the global semantic meaning and
the local word ordering structure in a document. The TCNLM learns the global
semantic coherence of a document via a neural topic model, and the probability
of each learned latent topic is further used to build a Mixture-of-Experts
(MoE) language model, where each expert (corresponding to one topic) is a
recurrent neural network (RNN) that accounts for learning the local structure
of a word sequence. In order to train the MoE model efficiently, a matrix
factorization method is applied, by extending each weight matrix of the RNN to
be an ensemble of topic-dependent weight matrices. The degree to which each
member of the ensemble is used is tied to the document-dependent probability of
the corresponding topics. Experimental results on several corpora show that the
proposed approach outperforms both a pure RNN-based model and other
topic-guided language models. Further, our model yields sensible topics, and
also has the capacity to generate meaningful sentences conditioned on given
topics.
</dc:description>
 <dc:description>Comment: To appear in AISTATS 2018</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09786</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A linear programming approach for designing multilevel PWM waveforms</dc:title>
 <dc:creator>Mohan, Shravan</dc:creator>
 <dc:creator>Bhikkaji, Bharath</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers the problem of designing a multilevel pulse width
modulated waveform (PWM) with a prescribed harmonic content. Multilevel PWM
design plays a major role in many diverse engineering disciplines. In power
electronics, multilevel PWM design corresponds to determining the inverter
switching times and levels for selective harmonic elimination and harmonic
compensation. In mechatronics, the same design corresponds to shaping input
signals to damp residual vibrations in flexible structures. More generally, in
most applications, the aim of PWM design is to minimize the total harmonic
distortion while adhering to a prescribed harmonic content. The solution
approach presented in this paper is based on linear programming with the
objective of minimizing the total harmonic distortion. This objective is
achieved within an arbitrarily small bound of the optimal solution. In
addition, the linear programming formulation makes the design of such switching
waveforms computationally tractable and efficient. Simulations are provided for
corroboration.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09789</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Parallel Connected Components Labeling with a Coarse-to-fine
  Strategy</dc:title>
 <dc:creator>Chen, Jun</dc:creator>
 <dc:creator>Nonaka, Keisuke</dc:creator>
 <dc:creator>Watanabe, Ryosuke</dc:creator>
 <dc:creator>Sankoh, Hiroshi</dc:creator>
 <dc:creator>Sabirin, Houari</dc:creator>
 <dc:creator>Naito, Sei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a new parallel approach to solve connected components on
a 2D binary image implemented with CUDA. We employ the following strategies to
accelerate neighborhood exploration after dividing an input image into
independent blocks. In the local labeling stage, a coarse-labeling algorithm,
including row-column connection and label-equivalence list unification, is
applied first to sort out the mess of an initialized local label map; a
refinement algorithm is then introduced to merge separated sub-regions from a
single component. In the block merge stage, we scan the pixels located on the
boundary of each block instead of solving the connectivity of all the pixels.
With the proposed method, the length of label-equivalence lists is compressed,
and the number of memory accesses is reduced. Thus, the efficiency of connected
components labeling is improved. Experimental results show that our method
outperforms the other approaches between $29\%$ and $80\%$ on average.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09791</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Label Languages of 8-directional Array P System</dc:title>
 <dc:creator>Kumar, William Suresh</dc:creator>
 <dc:creator>Mahalingam, Kalpana</dc:creator>
 <dc:creator>Rama, Raghavan</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  An 8-directional array P system is one where the rewriting of an array can
happen in any 8-directions. The array rules of such a system are labelled thus
resulting in a labelled 8-directional array P system. The labelling is not
unique and the label language is obtained by recording the strings over the
labels used in any terminating derivation of the P system. The system is shown
to generate interesting pictures. The label language is compared with Chomsky
hierarchy.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09792</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Siamese LSTM based Fiber Structural Similarity Network (FS2Net) for
  Rotation Invariant Brain Tractography Segmentation</dc:title>
 <dc:creator>Patil, Shreyas Malakarjun</dc:creator>
 <dc:creator>Nigam, Aditya</dc:creator>
 <dc:creator>Bhavsar, Arnav</dc:creator>
 <dc:creator>Chattopadhyay, Chiranjoy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel deep learning architecture combining
stacked Bi-directional LSTM and LSTMs with the Siamese network architecture for
segmentation of brain fibers, obtained from tractography data, into
anatomically meaningful clusters. The proposed network learns the structural
difference between fibers of different classes, which enables it to classify
fibers with high accuracy. Importantly, capturing such deep inter and intra
class structural relationship also ensures that the segmentation is robust to
relative rotation among test and training data, hence can be used with
unregistered data. Our extensive experimentation over order of
hundred-thousands of fibers show that the proposed model achieves
state-of-the-art results, even in cases of large relative rotations between
test and training data.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09795</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Customize Network Security Rules</dc:title>
 <dc:creator>Bargury, Michael</dc:creator>
 <dc:creator>Levin, Roy</dc:creator>
 <dc:creator>Ronen, Royi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Security is a major concern for organizations who wish to leverage cloud
computing. In order to reduce security vulnerabilities, public cloud providers
offer firewall functionalities. When properly configured, a firewall protects
cloud networks from cyber-attacks. However, proper firewall configuration
requires intimate knowledge of the protected system, high expertise and
on-going maintenance.
  As a result, many organizations do not use firewalls effectively, leaving
their cloud resources vulnerable. In this paper, we present a novel supervised
learning method, and prototype, which compute recommendations for firewall
rules. Recommendations are based on sampled network traffic meta-data (NetFlow)
collected from a public cloud provider. Labels are extracted from firewall
configurations deemed to be authored by experts. NetFlow is collected from
network routers, avoiding expensive collection from cloud VMs, as well as
relieving privacy concerns.
  The proposed method captures network routines and dependencies between
resources and firewall configuration. The method predicts IPs to be allowed by
the firewall. A grouping algorithm is subsequently used to generate a
manageable number of IP ranges. Each range is a parameter for a firewall rule.
  We present results of experiments on real data, showing ROC AUC of 0.92,
compared to 0.58 for an unsupervised baseline. The results prove the hypothesis
that firewall rules can be automatically generated based on router data, and
that an automated method can be effective in blocking a high percentage of
malicious traffic.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, one table</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09797</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Refactoring of Nested-IF Formulae in Spreadsheets</dc:title>
 <dc:creator>Zhang, Jie</dc:creator>
 <dc:creator>Han, Shi</dc:creator>
 <dc:creator>Hao, Dan</dc:creator>
 <dc:creator>Zhang, Lu</dc:creator>
 <dc:creator>Zhang, Dongmei</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Spreadsheets are the most popular end-user programming software, where
formulae act like programs and also have smells. One well recognized common
smell of spreadsheet formulae is nest-IF expressions, which have low
readability and high cognitive cost for users, and are error-prone during reuse
or maintenance. However, end users usually lack essential programming language
knowledge and skills to tackle or even realize the problem. The previous
research work has made very initial attempts in this aspect, while no effective
and automated approach is currently available.
  This paper firstly proposes an AST-based automated approach to systematically
refactoring nest-IF formulae. The general idea is two-fold. First, we detect
and remove logic redundancy on the AST. Second, we identify higher-level
semantics that have been fragmented and scattered, and reassemble the syntax
using concise built-in functions. A comprehensive evaluation has been conducted
against a real-world spreadsheet corpus, which is collected in a leading IT
company for research purpose. The results with over 68,000 spreadsheets with 27
million nest-IF formulae reveal that our approach is able to relieve the smell
of over 99\% of nest-IF formulae. Over 50% of the refactorings have reduced
nesting levels of the nest-IFs by more than a half. In addition, a survey
involving 49 participants indicates that for most cases the participants prefer
the refactored formulae, and agree on that such automated refactoring approach
is necessary and helpful.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09803</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Innovative Approach for Achieving Composability in Concurrent Systems
  using Multi-Version Object Based STMs</dc:title>
 <dc:creator>Kulkarni, Sandeep</dc:creator>
 <dc:creator>Kumari, Sweta</dc:creator>
 <dc:creator>Peri, Sathya</dc:creator>
 <dc:creator>Somani, Archit</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In the modern era of multicore processors, utilizing multiple cores properly
is a tedious job. Synchronization and communication among processors involve
high cost. Software transaction memory systems (STMs) addresses this issues and
provide better concurrency in which programmer need not have to worry about
consistency issues. Several big-data applications which deal large amounts of
data can benefit from Transactional Memory Systems.
  In this paper, we introduce a new STM system as multi-version object based
STM (MV-OSTM) which is the fusion of object based STM with multiple versions.
As the name suggests MV-OSTM, works on a higher level and keeping the multiple
versions corresponding to each key. Presently, we have developed MV-OSTM with
the unlimited number of versions corresponding to each key. To overcome
traversal overhead, it performs the garbage collection method to delete the
unwanted versions corresponding to the key. It provides greater concurrency
while reducing the number of aborts. It ensures composability by making the
transaction as atomic. In the proposed algorithm, $k$ is the input parameter
and the value of it will be decided by the programmer and depends on the
application. Programmer can tune the value of $k$ from 1 to $\infty$. If k
equal to 1 then it will boil down to single version object based STM (OSTM) and
if k equal to $\infty$ then it will be equivalent to multi-version OSTM with
$\infty$ versions.
  MV-OSTM satisfies correctness-criteria as opacity. For a given version order
of keys, if any history H generated by MV-OSTM produces acyclic graph then $H$
is opaque.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09809</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Scale and Multi-Depth Convolutional Neural Network for Remote
  Sensing Imagery Pan-Sharpening</dc:title>
 <dc:creator>Yuan, Qiangqiang</dc:creator>
 <dc:creator>Wei, Yancong</dc:creator>
 <dc:creator>Meng, Xiangchao</dc:creator>
 <dc:creator>Shen, Huanfeng</dc:creator>
 <dc:creator>Zhang, Liangpei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pan-sharpening is a fundamental and significant task in the field of remote
sensing imagery processing, in which high-resolution spatial details from
panchromatic images are employed to enhance the spatial resolution of
multi-spectral (MS) images. As the transformation from low spatial resolution
MS image to high-resolution MS image is complex and highly non-linear, inspired
by the powerful representation for non-linear relationships of deep neural
networks, we introduce multi-scale feature extraction and residual learning
into the basic convolutional neural network (CNN) architecture and propose the
multi-scale and multi-depth convolutional neural network (MSDCNN) for the
pan-sharpening of remote sensing imagery. Both the quantitative assessment
results and the visual assessment confirm that the proposed network yields
high-resolution MS images that are superior to the images produced by the
compared state-of-the-art methods.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09813</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate Bayesian Data Classification without Hyperparameter
  Cross-validation</dc:title>
 <dc:creator>Sheikh, M</dc:creator>
 <dc:creator>Coolen, A C C</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We extend the standard Bayesian multivariate Gaussian generative data
classifier by considering a generalization of the conjugate, normal-Wishart
prior distribution and by deriving the hyperparameters analytically via
evidence maximization. The behaviour of the optimal hyperparameters is explored
in the high-dimensional data regime. The classification accuracy of the
resulting generalized model is competitive with state-of-the art Bayesian
discriminant analysis methods, but without the usual computational burden of
cross-validation.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09818</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Formal Equivalence Verification of Pipelined Nested Loops in
  Datapath Designs</dc:title>
 <dc:creator>Behnam, Payman</dc:creator>
 <dc:creator>Alizadeh, Bijan</dc:creator>
 <dc:creator>Taheri, Sajjad</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  In this paper, we present an efficient formal approach to check the
equivalence of synthesized RTL against the high-level specification in the
presence of pipelining transformations. To increase the scalability of our
proposed method, we dynamically divide the designs into several smaller parts
called segments by introducing cut-points. Then we employ Modular Horner
Expansion Diagram (M-HED) to check whether the specification and implementation
are equivalent or not. In an iterative manner, the equivalence checking for
each segment is performed. At each step, the equivalent nodes and those nodes
which have an impact on them are removed until the whole design is covered. Our
proposed method enables us to deal with the equivalence checking problem for
behaviorally synthesized designs even in the presence of pipelines for nested
loops. The empirical results demonstrate the efficiency and scalability of our
proposed method in terms of run-time and memory usage for several large designs
synthesized by a commercial behavioral synthesis tool. Average improvements in
terms of the memory usage and run time in comparison with SMT- and SAT-based
equivalence checking are 16.7x and 111.9x, respectively.
</dc:description>
 <dc:description>Comment: 14 pages, 20 figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09827</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Syntactic Approach to Domain-Specific Automatic Question Generation</dc:title>
 <dc:creator>Danon, Guy</dc:creator>
 <dc:creator>Last, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Factoid questions are questions that require short fact-based answers.
Automatic generation (AQG) of factoid questions from a given text can
contribute to educational activities, interactive question answering systems,
search engines, and other applications. The goal of our research is to generate
factoid source-question-answer triplets based on a specific domain. We propose
a four-component pipeline, which obtains as input a training corpus of
domain-specific documents, along with a set of declarative sentences from the
same domain, and generates as output a set of factoid questions that refer to
the source sentences but are slightly different from them, so that a
question-answering system or a person can be asked a question that requires a
deeper understanding and knowledge than a simple word-matching. Contrary to
existing domain-specific AQG systems that utilize the template-based approach
to question generation, we propose to transform each source sentence into a set
of questions by applying a series of domain-independent rules (a
syntactic-based approach). Our pipeline was evaluated in the domain of cyber
security using a series of experiments on each component of the pipeline
separately and on the end-to-end system. The proposed approach generated a
higher percentage of acceptable questions than a prior state-of-the-art AQG
system.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09829</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Probabilistic Analysis on a Lattice Attack against DSA</dc:title>
 <dc:creator>Gomez-Perez, Domingo</dc:creator>
 <dc:creator>Renault, Gu&#xe9;na&#xeb;l</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  Analyzing the security of cryptosystems under attacks based on the malicious
modification of memory registers is a research topic of high importance. This
type of attacks may affect the randomness of the secret parameters by forcing a
limited number of bits to a certain value which can be unknown to the attacker.
In this context, we revisit the attack on DSA presented by Faug\`ere, Goyet and
Renault during the conference SAC 2012: we simplify their method and we provide
a probabilistic approach in opposition to the heuristic proposed in the former
to measure the limits of the attack. More precisely, the main problem is
formulated as the search for a closest vector to a lattice, then we study the
distribution of the vectors with bounded norms in a this family of lattices and
we apply the result to predict the behavior of the attack. We validated this
approach by computational experiments.
</dc:description>
 <dc:description>Comment: 18 pages, 2 figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09831</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum-secured data transmission in urban fibre-optic communication
  lines</dc:title>
 <dc:creator>Duplinskiy, A. V.</dc:creator>
 <dc:creator>Kiktenko, E. O.</dc:creator>
 <dc:creator>Pozhar, N. O.</dc:creator>
 <dc:creator>Anufriev, M. N.</dc:creator>
 <dc:creator>Ermakov, R. P.</dc:creator>
 <dc:creator>Kotov, A. I.</dc:creator>
 <dc:creator>Brodsky, A. V.</dc:creator>
 <dc:creator>Yunusov, R. R.</dc:creator>
 <dc:creator>Kurochkin, V. L.</dc:creator>
 <dc:creator>Fedorov, A. K.</dc:creator>
 <dc:creator>Kurochkin, Y. V.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Quantum key distribution (QKD) provides information-theoretic security in
communication based on the laws of quantum physics. In this work, we report an
implementation of quantum-secured data transmission in standard communication
lines in Moscow. The experiment is realized on the basis of the already
deployed urban fibre-optic communication channels with significant losses. We
realize the decoy-state BB84 QKD protocol using the one-way scheme with
polarization encoding for generating keys. Quantum-generated keys are then used
for continuous key renewal in the hardware devices for establishing a
quantum-secured VPN Tunnel. Such a hybrid approach offers possibilities for
long-term protection of the transmitted data, and it is promising for
integrating into the already existing information security infrastructure.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09835</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connecting Software Metrics across Versions to Predict Defects</dc:title>
 <dc:creator>Liu, Yibin</dc:creator>
 <dc:creator>Li, Yanhui</dc:creator>
 <dc:creator>Guo, Jianbo</dc:creator>
 <dc:creator>Zhou, Yuming</dc:creator>
 <dc:creator>Xu, Baowen</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Accurate software defect prediction could help software practitioners
allocate test resources to defect-prone modules effectively and efficiently. In
the last decades, much effort has been devoted to build accurate defect
prediction models, including developing quality defect predictors and modeling
techniques. However, current widely used defect predictors such as code metrics
and process metrics could not well describe how software modules change over
the project evolution, which we believe is important for defect prediction. In
order to deal with this problem, in this paper, we propose to use the
Historical Version Sequence of Metrics (HVSM) in continuous software versions
as defect predictors. Furthermore, we leverage Recurrent Neural Network (RNN),
a popular modeling technique, to take HVSM as the input to build software
prediction models. The experimental results show that, in most cases, the
proposed HVSM-based RNN model has a significantly better effort-aware ranking
effectiveness than the commonly used baseline models.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09846</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rating Protocol Design for Extortion and Cooperation in the
  Crowdsourcing Contest Dilemma</dc:title>
 <dc:creator>Lu, Jianfeng</dc:creator>
 <dc:creator>Xin, Yun</dc:creator>
 <dc:creator>Zhang, Zhao</dc:creator>
 <dc:creator>Tang, Shaojie</dc:creator>
 <dc:creator>Yan, Songyuan</dc:creator>
 <dc:creator>Tang, Changbing</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Crowdsourcing has emerged as a paradigm for leveraging human intelligence and
activity to solve a wide range of tasks. However, strategic workers will find
enticement in their self-interest to free-ride and attack in a crowdsourcing
contest dilemma game. Hence, incentive mechanisms are of great importance to
overcome the inefficiency of the socially undesirable equilibrium. Existing
incentive mechanisms are not effective in providing incentives for cooperation
in crowdsourcing competitions due to the following features: heterogeneous
workers compete against each other in a crowdsourcing platform with imperfect
monitoring. In this paper, we take these features into consideration, and
develop a novel game-theoretic design of rating protocols, which integrates
binary rating labels with differential pricing to maximize the requester's
utility, by extorting selfish workers and enforcing cooperation among them. By
quantifying necessary and sufficient conditions for the sustainable social
norm, we formulate the problem of maximizing the revenue of the requester among
all sustainable rating protocols, provide design guidelines for optimal rating
protocols, and design a low-complexity algorithm to select optimal design
parameters which are related to differential punishments and pricing schemes.
Simulation results demonstrate how intrinsic parameters impact on design
parameters, as well as the performance gain of the proposed rating protocol.
</dc:description>
 <dc:description>Comment: 13 pages, 21 figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09848</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game-Theoretic Design of Optimal Two-Sided Rating Protocols for Service
  Exchange Dilemma in Crowdsourcing</dc:title>
 <dc:creator>Lu, Jianfeng</dc:creator>
 <dc:creator>Xin, Yun</dc:creator>
 <dc:creator>Zhang, Zhao</dc:creator>
 <dc:creator>Liu, Xinwang</dc:creator>
 <dc:creator>Li, Kenli</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Despite the increasing popularity and successful examples of crowdsourcing,
its openness overshadows important episodes when elaborate sabotage derailed or
severely hindered collective efforts. A service exchange dilemma arises when
non-cooperation among self-interested users, and zero social welfare is
obtained at myopic equilibrium. Traditional rating protocols are not effective
to overcome the inefficiency of the socially undesirable equilibrium due to
specific features of crowdsourcing: a large number of anonymous users having
asymmetric service requirements, different service capabilities, and
dynamically joining/leaving a crowdsourcing platform with imperfect monitoring.
In this paper, we develop the first game-theoretic design of the two-sided
rating protocol to stimulate cooperation among self-interested users, which
consists of a recommended strategy and a rating update rule. The recommended
strategy recommends a desirable behavior from three predefined plans according
to intrinsic parameters, while the rating update rule involves the update of
ratings of both users, and uses differential punishments that punish users with
different ratings differently. By quantifying necessary and sufficient
conditions for a sustainable social norm, we formulate the problem of designing
an optimal two-sided rating protocol that maximizes the social welfare among
all sustainable protocols, provide design guidelines for optimal two-sided
rating protocols and a low-complexity algorithm to select optimal design
parameters in an alternate manner. Finally, illustrative results show the
validity and effectiveness of our proposed protocol designed for service
exchange dilemma in crowdsourcing.
</dc:description>
 <dc:description>Comment: 13 pages, 12 figures. arXiv admin note: text overlap with
  arXiv:1101.0272 by other authors</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09855</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond-Planarity: Density Results for Bipartite Graphs</dc:title>
 <dc:creator>Angelini, Patrizio</dc:creator>
 <dc:creator>Bekos, Michael A.</dc:creator>
 <dc:creator>Kaufmann, Michael</dc:creator>
 <dc:creator>Pfister, Maximilian</dc:creator>
 <dc:creator>Ueckerdt, Torsten</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Beyond-planarity focuses on the study of geometric and topological graphs
that are in some sense nearly-planar. Here, planarity is relaxed by allowing
edge crossings, but only with respect to some local forbidden crossing
configurations. Early research dates back to the 1960s (e.g., Avital and Hanani
1966) for extremal problems on geometric graphs, but is also related to graph
drawing problems where visual clutter by edge crossings should be minimized
(e.g., Huang et al. 2008) that could negatively affect the readability of the
drawing. Different types of forbidden crossing configurations give rise to
different families of nearly-planar graphs.
  Most of the literature focuses on Tur\'an-type problems, which ask for the
maximum number of edges a nearly-planar graph can have. Here, we study this
problem for bipartite topological graphs, considering several types of
nearly-planar graphs, i.e., 1-planar, 2-planar, fan-planar, and RAC graphs. We
prove bounds on the number of edges that are tight up to small additive
constants; some of them are surprising and not along the lines of the known
results for non-bipartite graphs. Our findings lead to an improvement of the
leading constant of the well-known Crossing Lemma for bipartite graphs, as well
as to a number of interesting research questions on topological graphs.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09856</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Bounds for Maximal Identifiability of Failure Nodes in Boolean
  Network Tomography</dc:title>
 <dc:creator>Galesi, Nicola</dc:creator>
 <dc:creator>Ranjbar, Fariba</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We study maximal identifiability, a measure recently introduced in Boolean
Network Tomography to characterize networks' capability to localize failure
nodes in end-to-end path measurements. Under standard assumptions on topologies
and on monitors placement, we prove tight upper and lower bounds on the maximal
identifiability of failure nodes for specific classes of network topologies,
such as trees, bounded-degree graphs, $d$-dimensional grids, in both directed
and undirected cases. Among other results we prove that directed
$d$-dimensional grids with support $n$ have maximal identifiability $d$ using
$nd$ monitors; and in the undirected case we show that $2d$ monitors suffice to
get identifiability of $d-1$. We then study identifiability under embeddings:
we establish relations between maximal identifiability, embeddability and
dimension when network topologies are modelled as DAGs. Through our analysis we
also refine and generalize results on limits of maximal identifiability
recently obtained in [11] and [1]. Our results suggest the design of networks
over $N$ nodes with maximal identifiability $\Omega(\sqrt{\log N})$ using
$2\sqrt{\log N}$ monitors and heuristics to place monitors and edges in a
network to boost maximal identifiability.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09859</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Secure and Authenticated Key Management Protocol (SA-KMP) for
  Vehicular Networks</dc:title>
 <dc:creator>Tan, Hengchuan</dc:creator>
 <dc:creator>Ma, Maode</dc:creator>
 <dc:creator>Labiod, Houda</dc:creator>
 <dc:creator>Boudguiga, Aymen</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Chong, Peter Han Joo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Public key infrastructure (PKI) is the most widely used security mechanism
for securing communications over the network. However, there are known
performance issues, making it unsuitable for use in vehicular networks. In this
paper, we propose a secure and authenticated key management protocol (SA-KMP)
to overcome the shortcomings of the PKI. The SA-KMP scheme distributes
repository containing the bindings of the en-tity's identity and its
corresponding public key to each vehicle and road side unit. By doing so,
certificate exchanges and certificate revocation lists are eliminated.
Furthermore, the SA-KMP scheme uses symmetric keys derived based on a
3-D-matrix-based key agreement scheme to reduce the high computational costs of
using asymmetric cryptography. We demonstrate the efficiency of the SA-KMP
through performance evaluations in terms of transmission and storage overhead,
network latency, and key generation time. Analytical results show that the
SA-KMP is more scalable and outperforms the certificate-based PKI. Simulation
results indicate that the key generation time of the SA-KMP scheme is less than
that of the existing Elliptic Curve Diffie--Hellman and Diffie--Hellman
protocols. In addition, we use Proverif to prove that the SA-KMP scheme is
secure against an active attacker under the Dolev and Yao model and further
show that the SA-KMP scheme is secure against denial of service, collusion
attacks, and a wide range of other malicious attacks.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09859</dc:identifier>
 <dc:identifier>IEEE Transactions on Vehicular Technology, Institute of Electrical
  and Electronics Engineers, 2016, 65 (12), pp.9570 - 9584.
  \&amp;\#x3008;10.1109/TVT.2016.2621354\&amp;\#x3009</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2016.2621354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09862</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A non-biased trust model for wireless mesh networks</dc:title>
 <dc:creator>Tan, Heng Chuan</dc:creator>
 <dc:creator>Ma, Maode</dc:creator>
 <dc:creator>Labiod, Houda</dc:creator>
 <dc:creator>Chong, Peter Han Joo</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Trust models that rely on recommendation trusts are vulnerable to badmouthing
and ballot-stuffing attacks. To cope with these attacks, existing trust models
use different trust aggregation techniques to process the recommendation trusts
and combine them with the direct trust values to form a combined trust value.
However, these trust models are biased as recommendation trusts that deviate
too much from one's own opinion are discarded. In this paper, we propose a
non-biased trust model that considers every recommendation trusts available
regardless they are good or bad. Our trust model is based on a combination of 2
techniques: the dissimilarity test and the Dempster-Shafer Theory. The
dissimilarity test determines the amount of conflict between 2 trust records,
whereas the Dempster-Shafer Theory assigns belief functions based on the
results of the dissimilarity test. Numerical results show that our trust model
is robust against reputation-based attacks when compared to trust aggregation
techniques such as the linear opinion pooling, subjective logic model,
entropy-based probability model, and regression analysis. In addition, our
model has been extensively tested using network simulator NS-3 in an
Infrastructure-based wireless mesh networks and a Hybrid-based wireless mesh
networks to demonstrate that it can mitigate blackhole and grayhole attacks.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09862</dc:identifier>
 <dc:identifier>International Journal of Communication Systems, Wiley, 2016, 30
  (9)</dc:identifier>
 <dc:identifier>doi:10.1002/dac.3200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09864</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TEDS: A Trusted Entropy and Dempster Shafer Mechanism for Routing in
  Wireless Mesh Networks</dc:title>
 <dc:creator>Tan, Hengchuan</dc:creator>
 <dc:creator>Ma, Maode</dc:creator>
 <dc:creator>Labiod, Houda</dc:creator>
 <dc:creator>Chong, Peter Han Joo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Wireless Mesh Networks (WMNs) have emerged as a key technology for the next
generation of wireless networking due to its self-forming, self-organizing and
self-healing properties. However, due to the multi-hop nature of communications
in WMN, we cannot assume that all nodes in the network are cooperative. Nodes
may drop all of the data packets they received to mount a Denial of Service
(DoS) attack. In this paper, we proposed a lightweight trust detection
mechanism called Trusted Entropy and Dempster Shafer (TEDS) to mitigate the
effects of blackhole attacks. This novel idea combines entropy function and
Dempster Shafer belief theory to derive a trust rating for a node. If the trust
rating of a node is less than a threshold, it will be blacklisted and isolated
from the network. In this way, the network can be assured of a secure end to
end path free of malicious nodes for data forwarding. Our proposed idea has
been extensively tested in simulation using network simulator NS-3 and
simulation results show that we are able to improve the packet delivery ratio
with slight increase in normalized routing overhead.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09864</dc:identifier>
 <dc:identifier>MOBILITY 2014 The Fourth International Conference on Mobile
  Services, Resources, and Users, Jul 2014, Paris, France</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09867</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Future Frame Prediction for Anomaly Detection -- A New Baseline</dc:title>
 <dc:creator>Liu, Wen</dc:creator>
 <dc:creator>Luo, Weixin</dc:creator>
 <dc:creator>Lian, Dongze</dc:creator>
 <dc:creator>Gao, Shenghua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Anomaly detection in videos refers to the identification of events that do
not conform to expected behavior. However, almost all existing methods tackle
the problem by minimizing the reconstruction errors of training data, which
cannot guarantee a larger reconstruction error for an abnormal event. In this
paper, we propose to tackle the anomaly detection problem within a video
prediction framework. To the best of our knowledge, this is the first work that
leverages the difference between a predicted future frame and its ground truth
to detect an abnormal event. To predict a future frame with higher quality for
normal events, other than the commonly used appearance (spatial) constraints on
intensity and gradient, we also introduce a motion (temporal) constraint in
video prediction by enforcing the optical flow between predicted frames and
ground truth frames to be consistent, and this is the first work that
introduces a temporal constraint into the video prediction task. Such spatial
and motion constraints facilitate the future frame prediction for normal
events, and consequently facilitate to identify those abnormal events that do
not conform the expectation. Extensive experiments on both a toy dataset and
some publicly available datasets validate the effectiveness of our method in
terms of robustness to the uncertainty in normal events and the sensitivity to
abnormal events.
</dc:description>
 <dc:description>Comment: Submitted to Conference on Computer Vision and Pattern Recognition
  2018</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09872</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handwritten Bangla Character Recognition Using The State-of-Art Deep
  Convolutional Neural Networks</dc:title>
 <dc:creator>Alom, Md Zahangir</dc:creator>
 <dc:creator>Sidike, Peherding</dc:creator>
 <dc:creator>Hasan, Mahmudul</dc:creator>
 <dc:creator>Taha, Tark M.</dc:creator>
 <dc:creator>Asari, Vijayan K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In spite of advances in object recognition technology, Handwritten Bangla
Characters Recognition (HBCR) (such as alpha-numeric and special) remains
largely unsolved due to the presence of many ambiguous handwritten characters
and excessive cursive in Bangla handwritings. Even the best existing
recognizers do not lead to satisfactory performance for practical applications,
and have much lower performance than those developed for English alpha-numeric
characters. To improve the performance of HBCR, we herein present Bangla
handwritten characters recognition methods by employing the state-of-the-art
Deep Convolutional Neural Networks (DCNN) including VGG Network, All
Convolution Network (All-Conv Net), Network in Network (NiN), Residual Network,
FractalNet, and DenseNet. The deep learning approaches have the advantage of
extracting and using feature information, improving the recognition of 2D
shapes with a high degree of invariance to translation, scaling and other
distortions. We systematically evaluated the performance of DCNN models on
publicly available Bangla handwritten character dataset called CMATERdb, and
achieved the state-of-the-art recognition accuracy when using DCNN models. Such
improvement fills a significant gap between practical requirements and the
actual performance of Bangla handwritten characters recognizers.
</dc:description>
 <dc:description>Comment: 12 pages,22 figures, 5 tables</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09876</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliable Messaging to Millions of Users with MigratoryData</dc:title>
 <dc:creator>Rotaru, Mihai</dc:creator>
 <dc:creator>Olariu, Florentin</dc:creator>
 <dc:creator>Onica, Emanuel</dc:creator>
 <dc:creator>Rivi&#xe8;re, Etienne</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Web-based notification services are used by a large range of businesses to
selectively distribute live updates to customers, following the
publish/subscribe (pub/sub) model. Typical deployments can involve millions of
subscribers expecting ordering and delivery guarantees together with low
latencies. Notification services must be vertically and horizontally scalable,
and adopt replication to provide a reliable service. We report our experience
building and operating MigratoryData, a highly-scalable notification service.
We discuss the typical requirements of MigratoryData customers, and describe
the architecture and design of the service, focusing on scalability and fault
tolerance. Our evaluation demonstrates the ability of MigratoryData to handle
millions of concurrent connections and support a reliable notification service
despite server failures and network disconnections.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09876</dc:identifier>
 <dc:identifier>Middleware 2017 - Proceedings of the 18th ACM/IFIP/USENIX
  Middleware Conference: Industrial Track, Pages 1-7</dc:identifier>
 <dc:identifier>doi:10.1145/3154448.3154449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09888</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Inception-Residual Convolutional Neural Network for Object
  Recognition</dc:title>
 <dc:creator>Alom, Md Zahangir</dc:creator>
 <dc:creator>Hasan, Mahmudul</dc:creator>
 <dc:creator>Yakopcic, Chris</dc:creator>
 <dc:creator>Taha, Tarek M.</dc:creator>
 <dc:creator>Asari, Vijayan K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Machine learning and computer vision have driven many of the greatest
advances in the modeling of Deep Convolutional Neural Networks (DCNNs).
Nowadays, most of the research has been focused on improving recognition
accuracy with better DCNN models and learning approaches. The recurrent
convolutional approach is not applied very much, other than in a few DCNN
architectures. On the other hand, Inception-v4 and Residual networks have
promptly become popular among computer the vision community. In this paper, we
introduce a new DCNN model called the Inception Recurrent Residual
Convolutional Neural Network (IRRCNN), which utilizes the power of the
Recurrent Convolutional Neural Network (RCNN), the Inception network, and the
Residual network. This approach improves the recognition accuracy of the
Inception-residual network with same number of network parameters. In addition,
this proposed architecture generalizes the Inception network, the RCNN, and the
Residual network with significantly improved training accuracy. We have
empirically evaluated the performance of the IRRCNN model on different
benchmarks including CIFAR-10, CIFAR-100, TinyImageNet-200, and CU3D-100. The
experimental results show higher recognition accuracy against most of the
popular DCNN models including the RCNN. We have also investigated the
performance of the IRRCNN approach against the Equivalent Inception Network
(EIN) and the Equivalent Inception Residual Network (EIRN) counterpart on the
CIFAR-100 dataset. We report around 4.53%, 4.49% and 3.56% improvement in
classification accuracy compared with the RCNN, EIN, and EIRN on the CIFAR-100
dataset respectively. Furthermore, the experiment has been conducted on the
TinyImageNet-200 and CU3D-100 datasets where the IRRCNN provides better testing
accuracy compared to the Inception Recurrent CNN (IRCNN), the EIN, and the
EIRN.
</dc:description>
 <dc:description>Comment: 17 pages, 15 figures, 4 tables</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09913</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing the Loss Landscape of Neural Nets</dc:title>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Xu, Zheng</dc:creator>
 <dc:creator>Taylor, Gavin</dc:creator>
 <dc:creator>Goldstein, Tom</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural network training relies on our ability to find &quot;good&quot; minimizers of
highly non-convex loss functions. It is well known that certain network
architecture designs (e.g., skip connections) produce loss functions that train
easier, and well-chosen training parameters (batch size, learning rate,
optimizer) produce minimizers that generalize better. However, the reasons for
these differences, and their effect on the underlying loss landscape, is not
well understood. In this paper, we explore the structure of neural loss
functions, and the effect of loss landscapes on generalization, using a range
of visualization methods. First, we introduce a simple &quot;filter normalization&quot;
method that helps us visualize loss function curvature, and make meaningful
side-by-side comparisons between loss functions. Then, using a variety of
visualizations, we explore how network architecture affects the loss landscape,
and how training parameters affect the shape of minimizers.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09915</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Field Studies with Multimedia Big Data: Opportunities and Challenges
  (Extended Version)</dc:title>
 <dc:creator>Krell, Mario Michael</dc:creator>
 <dc:creator>Bernd, Julia</dc:creator>
 <dc:creator>Li, Yifan</dc:creator>
 <dc:creator>Ma, Daniel</dc:creator>
 <dc:creator>Choi, Jaeyoung</dc:creator>
 <dc:creator>Ellsworth, Michael</dc:creator>
 <dc:creator>Borth, Damian</dc:creator>
 <dc:creator>Friedland, Gerald</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Social multimedia users are increasingly sharing all kinds of data about the
world. They do this for their own reasons, not to provide data for field
studies-but the trend presents a great opportunity for scientists. The Yahoo
Flickr Creative Commons 100 Million (YFCC100M) dataset comprises 99 million
images and nearly 800 thousand videos from Flickr, all shared under Creative
Commons licenses. To enable scientists to leverage these media records for
field studies, we propose a new framework that extracts targeted subcorpora
from the YFCC100M, in a format usable by researchers who are not experts in big
data retrieval and processing.
  This paper discusses a number of examples from the literature-as well as some
entirely new ideas-of natural and social science field studies that could be
piloted, supplemented, replicated, or conducted using YFCC100M data. These
examples illustrate the need for a general new open-source framework for
Multimedia Big Data Field Studies. There is currently a gap between the
separate aspects of what multimedia researchers have shown to be possible with
consumer-produced big data and the follow-through of creating a comprehensive
field study framework that supports scientists across other disciplines.
  To bridge this gap, we must meet several challenges. For example, the
framework must handle unlabeled and noisily labeled data to produce a filtered
dataset for a scientist-who naturally wants it to be both as large and as clean
as possible. This requires an iterative approach that provides access to
statistical summaries and refines the search by constructing new classifiers.
The first phase of our framework is available as Multimedia Commons Search, an
intuitive interface that enables complex search queries at a large scale...
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09916</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A ReRAM Physically Unclonable Function (ReRAM PUF)-based Approach to
  Enhance Authentication Security in Software Defined Wireless Networks</dc:title>
 <dc:creator>Afghah, Fatemeh</dc:creator>
 <dc:creator>Cambou, Bertrand</dc:creator>
 <dc:creator>Abedini, Masih</dc:creator>
 <dc:creator>Zeadally, Sherali</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The exponentially increasing number of ubiquitous wireless devices connected
to the Internet in Internet of Things (IoT) networks highlights the need for a
new paradigm of data flow management in such large-scale networks under
software defined wireless networking (SDWN). The limited power and computation
capability available at IoT devices as well as the centralized management and
decision-making approach in SDWN introduce a whole new set of security threats
to the networks. In particular, the authentication mechanism between the
controllers and the forwarding devices in SDWNs is a key challenge from both
secrecy and integrity aspects. Conventional authentication protocols based on
public key infrastructure (PKI) are no longer sufficient for these networks
considering the large-scale and heterogeneity nature of the networks as well as
their deployment cost, and security vulnerabilities due to key distribution and
storage. We propose a novel security protocol based on physical unclonable
functions (PUFs) known as hardware security primitives to enhance the
authentication security in SDWNs. In this approach, digital PUFs are developed
using the inherent randomness of the nanomaterials of Resistive Random Access
Memory (ReRAM) that are embedded in most IoT devices to enable a secure
authentication and access control in these networks. These PUFs are developed
based on a novel approach of multi-states, in which the natural drifts due to
the physical variations in the environment are predicted to reduce the
potential errors in challenge-response pairs of PUFs being tested in different
situations. We also proposed a PUF-based PKI protocol to secure the controller
in SDWNs. The performance of the developed ReRAM-based PUFs are evaluated in
the experimental results.
</dc:description>
 <dc:description>Comment: 16 pages, 10 figures, submitted to Springer International Journal of
  Wireless Information Networks</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09923</identifier>
 <datestamp>2018-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What do we need to build explainable AI systems for the medical domain?</dc:title>
 <dc:creator>Holzinger, Andreas</dc:creator>
 <dc:creator>Biemann, Chris</dc:creator>
 <dc:creator>Pattichis, Constantinos S.</dc:creator>
 <dc:creator>Kell, Douglas B.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Artificial intelligence (AI) generally and machine learning (ML) specifically
demonstrate impressive practical success in many different application domains,
e.g. in autonomous driving, speech recognition, or recommender systems. Deep
learning approaches, trained on extremely large data sets or using
reinforcement learning methods have even exceeded human performance in visual
tasks, particularly on playing games such as Atari, or mastering the game of
Go. Even in the medical domain there are remarkable results. The central
problem of such models is that they are regarded as black-box models and even
if we understand the underlying mathematical principles, they lack an explicit
declarative knowledge representation, hence have difficulty in generating the
underlying explanatory structures. This calls for systems enabling to make
decisions transparent, understandable and explainable. A huge motivation for
our approach are rising legal and privacy aspects. The new European General
Data Protection Regulation entering into force on May 25th 2018, will make
black-box approaches difficult to use in business. This does not imply a ban on
automatic learning approaches or an obligation to explain everything all the
time, however, there must be a possibility to make the results re-traceable on
demand. In this paper we outline some of our research topics in the context of
the relatively new area of explainable-AI with a focus on the application in
medicine, which is a very special domain. This is due to the fact that medical
professionals are working mostly with distributed heterogeneous and complex
sources of data. In this paper we concentrate on three sources: images, *omics
data and text. We argue that research in explainable-AI would generally help to
facilitate the implementation of AI/ML in the medical domain, and specifically
help to facilitate transparency and trust.
</dc:description>
 <dc:description>Comment: This is a survey article and section 3.1. draws heavily from
  arXiv:1706.07979</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09926</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Rapid-Temporal Adaptations</dc:title>
 <dc:creator>Munkhdalai, Tsendsuren</dc:creator>
 <dc:creator>Yuan, Xingdi</dc:creator>
 <dc:creator>Mehri, Soroush</dc:creator>
 <dc:creator>Wang, Tong</dc:creator>
 <dc:creator>Trischler, Adam</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A hallmark of human intelligence and cognition is its flexibility. One of the
long-standing goals in AI research is to replicate this flexibility in a
learning machine. In this work we describe a mechanism by which artificial
neural networks can learn rapid-temporal adaptation - the ability to adapt
quickly to new environments or tasks - that we call adaptive neurons. Adaptive
neurons modify their activations with task-specific values retrieved from a
working memory. On standard metalearning and few-shot learning benchmarks in
both vision and language domains, models augmented with adaptive neurons
achieve state-of-the-art results.
</dc:description>
 <dc:description>Comment: initial submission, 10 pages</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09929</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Challenges of Detecting Rude Conversational Behaviour</dc:title>
 <dc:creator>Grewal, Karan</dc:creator>
 <dc:creator>Truong, Khai N.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this study, we aim to identify moments of rudeness between two
individuals. In particular, we segment all occurrences of rudeness in
conversations into three broad, distinct categories and try to identify each.
We show how machine learning algorithms can be used to identify rudeness based
on acoustic and semantic signals extracted from conversations. Furthermore, we
make note of our shortcomings in this task and highlight what makes this
problem inherently difficult. Finally, we provide next steps which are needed
to ensure further success in identifying rudeness in conversations.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09936</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Regularization Improves Accuracy of Discriminative Models</dc:title>
 <dc:creator>Varga, D&#xe1;niel</dc:creator>
 <dc:creator>Csisz&#xe1;rik, Adri&#xe1;n</dc:creator>
 <dc:creator>Zombori, Zsolt</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Regularizing the gradient norm of the output of a neural network with respect
to its inputs is a powerful technique, first proposed by Drucker &amp; LeCun (1991)
who named it Double Backpropagation. The idea has been independently
rediscovered several times since then, most often with the goal of making
models robust against adversarial sampling. This paper presents evidence that
gradient regularization can consistently and significantly improve
classification accuracy on vision tasks, especially when the amount of training
data is small. We introduce our regularizers as members of a broader class of
Jacobian-based regularizers, and compare them theoretically and empirically.
  A straightforward objection against minimizing the gradient norm at the
training points is that a locally optimal solution, where the model has small
gradients at the training points, may possibly contain large changes at other
regions. We demonstrate through experiments on real and synthetic tasks that
stochastic gradient descent is unable to find these locally optimal but
globally unproductive solutions. Instead, it is forced to find solutions that
generalize well.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09943</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Continual Learning for Conversational Agents</dc:title>
 <dc:creator>Lee, Sungjin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  While end-to-end neural conversation models have led to promising advances in
reducing hand-crafted features and errors induced by the traditional complex
system architecture, they typically require an enormous amount of data due to
the lack of modularity. Previous studies adopted a hybrid approach with
knowledge-based components either to abstract out domain-specific information
or to augment data to cover more diverse patterns. On the contrary, we propose
to directly address the problem using recent developments in the space of
continual learning for neural models. Specifically, we adopt a
domain-independent neural conversational model and introduce a novel neural
continual learning algorithm that allows a conversational agent to accumulate
skills across different tasks in a data-efficient way. To the best of our
knowledge, this is the first work that applies continual learning to
conversation systems. We verified the efficacy of our method through a
conversational skill transfer from either synthetic dialogs or human-human
dialogs to human-computer conversations in a customer support domain.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09948</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing Polarization and Disagreement in Social Networks</dc:title>
 <dc:creator>Musco, Cameron</dc:creator>
 <dc:creator>Musco, Christopher</dc:creator>
 <dc:creator>Tsourakakis, Charalampos E.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The rise of social media and online social networks has been a disruptive
force in society. Opinions are increasingly shaped by interactions on online
social media, and social phenomena including disagreement and polarization are
now tightly woven into everyday life. In this work we initiate the study of the
following question: given $n$ agents, each with its own initial opinion that
reflects its core value on a topic, and an opinion dynamics model, what is the
structure of a social network that minimizes {\em polarization} and {\em
disagreement} simultaneously?
  This question is central to recommender systems: should a recommender system
prefer a link suggestion between two online users with similar mindsets in
order to keep disagreement low, or between two users with different opinions in
order to expose each to the other's viewpoint of the world, and decrease
overall levels of polarization? Our contributions include a mathematical
formalization of this question as an optimization problem and an exact,
time-efficient algorithm. We also prove that there always exists a network with
$O(n/\epsilon^2)$ edges that is a $(1+\epsilon)$ approximation to the optimum.
For a fixed graph, we additionally show how to optimize our objective function
over the agents' innate opinions in polynomial time.
  We perform an empirical study of our proposed methods on synthetic and
real-world data that verify their value as mining tools to better understand
the trade-off between of disagreement and polarization. We find that there is a
lot of space to reduce both polarization and disagreement in real-world
networks; for instance, on a Reddit network where users exchange comments on
politics, our methods achieve a $\sim 60\,000$-fold reduction in polarization
and disagreement.
</dc:description>
 <dc:description>Comment: 19 pages (accepted, WWW 2018)</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09952</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Methods in the Presence of Discontinuities</dc:title>
 <dc:creator>Piotrowska, Joanna</dc:creator>
 <dc:creator>Miller, Jonah M.</dc:creator>
 <dc:creator>Schnetter, Erik</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>General Relativity and Quantum Cosmology</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Spectral methods provide an elegant and efficient way of numerically solving
differential equations of all kinds. For smooth problems, truncation error for
spectral methods vanishes exponentially in the infinity norm and $L_2$-norm.
However, for non-smooth problems, convergence is significantly worse---the
$L_2$-norm of the error for a discontinuous problem will converge at a
sub-linear rate and the infinity norm will not converge at all. We explore and
improve upon a post-processing technique---optimally convergent mollifiers---to
recover exponential convergence from a poorly-converging spectral
reconstruction of non-smooth data. This is an important first step towards
using these techniques for simulations of realistic systems.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09958</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object-Oriented Theorem Proving (OOTP): First Thoughts</dc:title>
 <dc:creator>AbdelGawad, Moez A.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Automatic (i.e., computer-assisted) theorem proving (ATP) can come in many
flavors. This document presents early steps in our effort towards defining
object-oriented theorem proving (OOTP) as a new style of ATP.
  Traditional theorem proving (TTP) is the only well-known flavor of ATP so
far. OOTP is a generalization of TTP. While TTP is strongly based on functional
programming (FP), OOTP is strongly based on object-oriented programming (OOP)
instead. We believe OOTP is a style of theorem proving that is no less powerful
and no less natural than TTP and thus likely will be no less practically useful
than TTP.
  In the document we also discuss, very briefly, a related notion of OO
software verification (OOSV) based on OOTP. To clarify the relation between
OOTP and TTP, we also touch on the relation between OOP and FP.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09960</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Bayesian Learning in the Wisdom of the Crowd</dc:title>
 <dc:creator>Adjodah, Dhaval</dc:creator>
 <dc:creator>Leng, Yan</dc:creator>
 <dc:creator>Chong, Shi Kai</dc:creator>
 <dc:creator>Krafft, Peter</dc:creator>
 <dc:creator>Pentland, Alex</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Being able to correctly aggregate the beliefs of many people into a single
belief is a problem fundamental to many important social, economic and
political processes such as policy making, market pricing and voting. Although
there exist many models and mechanisms for aggregation, there is a lack of
methods and literature regarding the aggregation of opinions when influence and
learning between individuals exist. This is in part because there are not many
models of how people update their belief when exposed to the beliefs of others,
and so it is hard to quantify the dependencies between people's mental models
which is essential to minimizing redundancies in the aggregation. In this
paper, we explore many models of how users influence and learn from each other,
and we benchmark our models against the well-known DeGroot model. Our main
contributions are: 1) we collect a new dataset of unprecedented size and detail
to be posted online; 2) we develop a new Social Bayesian model of how people
update their mental models, 3) we compare of our model to other well-known
social learning models. Specifically, we show that our new Social Bayesian
model is superior to the other models tested.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09967</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A PSPACE Construction of a Hitting Set for the Closure of Small
  Algebraic Circuits</dc:title>
 <dc:creator>Forbes, Michael A.</dc:creator>
 <dc:creator>Shpilka, Amir</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  In this paper we study the complexity of constructing a hitting set for the
closure of VP, the class of polynomials that can be infinitesimally
approximated by polynomials that are computed by polynomial sized algebraic
circuits, over the real or complex numbers. Specifically, we show that there is
a PSPACE algorithm that given n,s,r in unary outputs a set of n-tuples over the
rationals of size poly(n,s,r), with poly(n,s,r) bit complexity, that hits all
n-variate polynomials of degree-r that are the limit of size-s algebraic
circuits. Previously it was known that a random set of this size is a hitting
set, but a construction that is certified to work was only known in EXPSPACE
(or EXPH assuming the generalized Riemann hypothesis). As a corollary we get
that a host of other algebraic problems such as Noether Normalization Lemma,
can also be solved in PSPACE deterministically, where earlier only randomized
algorithms and EXPSPACE algorithms (or EXPH assuming the generalized Riemann
hypothesis) were known.
  The proof relies on the new notion of a robust hitting set which is a set of
inputs such that any nonzero polynomial that can be computed by a polynomial
size algebraic circuit, evaluates to a not too small value on at least one
element of the set. Proving the existence of such a robust hitting set is the
main technical difficulty in the proof.
  Our proof uses anti-concentration results for polynomials, basic tools from
algebraic geometry and the existential theory of the reals.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09983</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Feature-based Online Multi-kernel Learning in Environments with
  Unknown Dynamics</dc:title>
 <dc:creator>Shen, Yanning</dc:creator>
 <dc:creator>Chen, Tianyi</dc:creator>
 <dc:creator>Giannakis, Georgios B.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Kernel-based methods exhibit well-documented performance in various nonlinear
learning tasks. Most of them rely on a preselected kernel, whose prudent choice
presumes task-specific prior information. Especially when the latter is not
available, multi-kernel learning has gained popularity thanks to its
flexibility in choosing kernels from a prescribed kernel dictionary. Leveraging
the random feature approximation and its recent orthogonality-promoting
variant, the present contribution develops a scalable multi-kernel learning
scheme (termed Raker) to obtain the sought nonlinear learning function `on the
fly,' first for static environments. To further boost performance in dynamic
environments, an adaptive multi-kernel learning scheme (termed AdaRaker) is
developed using weighted combinations of advices from hierarchical ensembles of
experts. The weights account not only for each kernel's contribution to the
learning, but also for the unknown dynamics. Performance is analyzed in terms
of both static and dynamic regrets. AdaRaker is uniquely capable of tracking
nonlinear learning functions in environments with unknown dynamics, with
analytic performance guarantees. Tests with synthetic and real datasets are
carried out to showcase the effectiveness of the novel algorithms, and their
performance.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09999</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Active Subspace Decomposition for Scalable and Efficient Tensor
  Robust Principal Component Analysis</dc:title>
 <dc:creator>Jiang, Jonathan Q.</dc:creator>
 <dc:creator>Ng, Michael K.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Tensor robust principal component analysis (TRPCA) has received a substantial
amount of attention in various fields. Most existing methods, normally relying
on tensor nuclear norm minimization, need to pay an expensive computational
cost due to multiple singular value decompositions (SVDs) at each iteration. To
overcome the drawback, we propose a scalable and efficient method, named
Parallel Active Subspace Decomposition (PASD), which divides the unfolding
along each mode of the tensor into a columnwise orthonormal matrix (active
subspace) and another small-size matrix in parallel. Such a transformation
leads to a nonconvex optimization problem in which the scale of nulcear norm
minimization is generally much smaller than that in the original problem.
Furthermore, we introduce an alternating direction method of multipliers (ADMM)
method to solve the reformulated problem and provide rigorous analyses for its
convergence and suboptimality. Experimental results on synthetic and real-world
data show that our algorithm is more accurate than the state-of-the-art
approaches, and is orders of magnitude faster.
</dc:description>
 <dc:description>Comment: 19 pages, 2 figures, 2 tables</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.09999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10008</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of Security Detection Model for the Security of Social Blogs
  and Chatting from Hostile Users</dc:title>
 <dc:creator>Gupta, Shubhankar</dc:creator>
 <dc:creator>Nitin</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Worldwide, a large number of people interact with each other by means of
online chatting. There has been a significant rise in the number of platforms,
both social and professional, such as WhatsApp, Facebook,and Twitter, which
allow people to share their experiences, views and knowledge with others. Sadly
enough, with online communication getting embedded into our daily
communication, incivility and misbehaviour has taken on many nuances from
professional misbehaviour to professional decay. Generally flaming starts with
the exchange of rude messages and comments, which in turn triggers to higher
scale of flaming. To prevent online communication from getting downgraded, it
is essential to keep away the hostile users from communication platforms. This
paper presents a Security Detection Model and a tool which checks and prevents
online flaming. It detects the presence of flaming while chatting or posting
blogs, and censors swear words as well as blocks the users from flaming.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10008</dc:identifier>
 <dc:identifier>International Journal of Computer Science &amp; Information Technology
  (IJCSIT) Vol 9, No 5, October 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10009</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VB and R codes using Households databases available in the NSI's : A
  prelude to statistical applied studies</dc:title>
 <dc:creator>Lo, Gane Samb</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>68P01, 68P05, 68N01</dc:subject>
 <dc:description>  We describe the main features of the households databases we can find in most
of our National Statistics Institute. We provide algorithms aimed at extracting
a diversity of variables on which different statistical procedures may be
applied. Here, we particularly focus on the scaled income, as a beginning.
Associated codes (MS Visual Basic and R codes) have been successfully tested
and delivered in the text and in a separate file
</dc:description>
 <dc:description>Comment: 42 pages, 3 figures</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10009</dc:identifier>
 <dc:identifier>doi:10.16929/ajas/206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10010</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conflict-free connection of trees</dc:title>
 <dc:creator>Chang, Hong</dc:creator>
 <dc:creator>Ji, Meng</dc:creator>
 <dc:creator>Li, Xueliang</dc:creator>
 <dc:creator>Zhang, Jingshu</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C15, 05C40, 05C75, 05C85</dc:subject>
 <dc:description>  An edge-colored graph $G$ is \emph{conflict-free connected} if, between each
pair of distinct vertices, there exists a path containing a color used on
exactly one of its edges. The \emph{conflict-free connection number} of a
connected graph $G$, denoted by $cfc(G)$, is defined as the smallest number of
colors that are required in order to make $G$ conflict-free connected. A
coloring of vertices of a hypergraph $H=(\mathcal{V},\mathcal{E})$ is called
\emph{conflict-free} if each hyperedge $e$ of $H$ has a vertex of unique color
that does not get repeated in $e$. The smallest number of colors required for
such a coloring is called the \emph{conflict-free chromatic number} of $H$, and
is denoted by \emph{$\chi_{cf}(H)$}. In this paper, we study the conflict-free
connection coloring of trees, which is also the conflict-free coloring of
edge-path hypergraphs of trees. We first prove that for a tree $T$ of order
$n$, $cfc(T)\geq cfc(P_n)=\lceil \log_{2} n\rceil$, and this completely
confirms the conjecture of Li and Wu. We then present a sharp upper bound for
the conflict-free connection number of trees by a simple algorithm.
Furthermore, we show that the conflict-free connection number of the binomial
tree with $2^{k-1}$ vertices is $k-1$. At last, we construct some tree classes
which are $k$-$cfc$-critical for every positive integer $k$.
</dc:description>
 <dc:description>Comment: 14 pages. arXiv admin note: text overlap with arXiv:1002.4210,
  arXiv:0912.3004 by other authors</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10011</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Merits of Sharing a Ride</dc:title>
 <dc:creator>Ehsani, Pooyan</dc:creator>
 <dc:creator>Yu, Jia Yuan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The culture of sharing instead of ownership is sharply increasing in
individuals behaviors. Particularly in transportation, concepts of sharing a
ride in either carpooling or ridesharing have been recently adopted. An
efficient optimization approach to match passengers in real-time is the core of
any ridesharing system. In this paper, we model ridesharing as an online
matching problem on general graphs such that passengers do not drive private
cars and use shared taxis. We propose an optimization algorithm to solve it.
The outlined algorithm calculates the optimal waiting time when a passenger
arrives. This leads to a matching with minimal overall overheads while
maximizing the number of partnerships. To evaluate the behavior of our
algorithm, we used NYC taxi real-life data set. Results represent a substantial
reduction in overall overheads.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10011</dc:identifier>
 <dc:identifier>doi:10.1109/ALLERTON.2017.8262818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10024</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning for Partial Identification: Example of Bracketed Data</dc:title>
 <dc:creator>Semenova, Vira</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Economics - Econometrics</dc:subject>
 <dc:description>  Partially identified models occur commonly in economic applications. A common
problem in this literature is a regression problem with bracketed
(interval-censored) outcome variable Y, which creates a set-identified
parameter of interest. The recent studies have only considered
finite-dimensional linear regression in such context. To incorporate more
complex controls into the problem, we consider a partially linear projection of
Y on the set functions that are linear in treatment/policy variables and
nonlinear in the controls. We characterize the identified set for the linear
component of this projection and propose an estimator of its support function.
Our estimator converges at parametric rate and has asymptotic normality
properties. It may be useful for labor economics applications that involve
bracketed salaries and rich, high-dimensional demographic data about the
subjects of the study.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10041</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Caching under Content Freshness Constraints</dc:title>
 <dc:creator>Poojary, Pawan</dc:creator>
 <dc:creator>Moharir, Sharayu</dc:creator>
 <dc:creator>Jagannathan, Krishna</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Several real-time delay-sensitive applications pose varying degrees of
freshness demands on the requested content. The performance of cache
replacement policies that are agnostic to these demands is likely to be
sub-optimal. Motivated by this concern, in this paper, we study caching
policies under a request arrival process which incorporates user freshness
demands. We consider the performance metric to be the steady-state cache hit
probability. We first provide a universal upper bound on the performance of any
caching policy. We then analytically obtain the content-wise hit-rates for the
Least Popular (LP) policy and provide sufficient conditions for the asymptotic
optimality of cache performance under this policy. Next, we obtain an accurate
approximation for the LRU hit-rates in the regime of large content population.
To this end, we map the characteristic time of a content in the LRU policy to
the classical Coupon Collector's Problem and show that it sharply concentrates
around its mean. Further, we develop modified versions of these policies which
eject cache redundancies present in the form of stale contents. Finally, we
propose a new policy which outperforms the above policies by explicitly using
freshness specifications of user requests to prioritize among the cached
contents. We corroborate our analytical insights with extensive simulations.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10042</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative and Geometry Aware Unsupervised Domain Adaptation</dc:title>
 <dc:creator>Luo, Lingkun</dc:creator>
 <dc:creator>Chen, Liming</dc:creator>
 <dc:creator>Hu, Shiqiang</dc:creator>
 <dc:creator>Lu, Ying</dc:creator>
 <dc:creator>Wang, Xiaofang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Domain adaptation (DA) aims to generalize a learning model across training
and testing data despite the mismatch of their data distributions. In light of
a theoretical estimation of upper error bound, we argue in this paper that an
effective DA method should 1) search a shared feature subspace where source and
target data are not only aligned in terms of distributions as most state of the
art DA methods do, but also discriminative in that instances of different
classes are well separated; 2) account for the geometric structure of the
underlying data manifold when inferring data labels on the target domain. In
comparison with a baseline DA method which only cares about data distribution
alignment between source and target, we derive three different DA models,
namely CDDA, GA-DA, and DGA-DA, to highlight the contribution of Close yet
Discriminative DA(CDDA) based on 1), Geometry Aware DA (GA-DA) based on 2), and
finally Discriminative and Geometry Aware DA (DGA-DA) implementing jointly 1)
and 2). Using both synthetic and real data, we show the effectiveness of the
proposed approach which consistently outperforms state of the art DA methods
over 36 image classification DA tasks through 6 popular benchmarks. We further
carry out in-depth analysis of the proposed DA method in quantifying the
contribution of each term of our DA model and provide insights into the
proposed DA methods in visualizing both real and synthetic data.
</dc:description>
 <dc:description>Comment: 18pages, 12figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10043</identifier>
 <datestamp>2018-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Covariate Shift Prediction with General Losses and Feature Views</dc:title>
 <dc:creator>Liu, Anqi</dc:creator>
 <dc:creator>Ziebart, Brian D.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Covariate shift relaxes the widely-employed independent and identically
distributed (IID) assumption by allowing different training and testing input
distributions. Unfortunately, common methods for addressing covariate shift by
trying to remove the bias between training and testing distributions using
importance weighting often provide poor performance guarantees in theory and
unreliable predictions with high variance in practice. Recently developed
methods that construct a predictor that is inherently robust to the
difficulties of learning under covariate shift are restricted to minimizing
logloss and can be too conservative when faced with high-dimensional learning
tasks. We address these limitations in two ways: by robustly minimizing various
loss functions, including non-convex ones, under the testing distribution; and
by separately shaping the influence of covariate shift according to different
feature-based views of the relationship between input variables and example
labels. These generalizations make robust covariate shift prediction applicable
to more task scenarios. We demonstrate the benefits on classification under
covariate shift tasks.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10050</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernel Robust Bias-Aware Prediction under Covariate Shift</dc:title>
 <dc:creator>Liu, Anqi</dc:creator>
 <dc:creator>Fathony, Rizal</dc:creator>
 <dc:creator>Ziebart, Brian D.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Under covariate shift, training (source) data and testing (target) data
differ in input space distribution, but share the same conditional label
distribution. This poses a challenging machine learning task. Robust Bias-Aware
(RBA) prediction provides the conditional label distribution that is robust to
the worstcase logarithmic loss for the target distribution while matching
feature expectation constraints from the source distribution. However,
employing RBA with insufficient feature constraints may result in high
certainty predictions for much of the source data, while leaving too much
uncertainty for target data predictions. To overcome this issue, we extend the
representer theorem to the RBA setting, enabling minimization of regularized
expected target risk by a reweighted kernel expectation under the source
distribution. By applying kernel methods, we establish consistency guarantees
and demonstrate better performance of the RBA classifier than competing methods
on synthetically biased UCI datasets as well as datasets that have natural
covariate shift.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10052</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearly linear time encodable codes beating the Gilbert-Varshamov bound</dc:title>
 <dc:creator>Narayanan, Anand Kumar</dc:creator>
 <dc:creator>Weidner, Matthew</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  We construct explicit nearly linear time encodable error-correcting codes
beating the Gilbert-Varshamov bound. Our codes are algebraic geometry codes
built from the Garcia-Stichtenoth function field tower and beat the
Gilbert-Varshamov bound for alphabet sizes at least $19^2$. Messages are
identified with functions in certain Riemann-Roch spaces associated with
divisors supported on multiple places. Encoding amounts to evaluating these
functions at degree one places. By exploiting algebraic structures particular
to the Garcia-Stichtenoth tower, we devise an intricate deterministic nearly
linear time encoding algorithm and nearly quadratic expected time randomized
(unique and list) decoding algorithms.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10054</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Corpus specificity in LSA and Word2vec: the role of out-of-domain
  documents</dc:title>
 <dc:creator>Altszyler, Edgar</dc:creator>
 <dc:creator>Sigman, Mariano</dc:creator>
 <dc:creator>Slezak, Diego Fernandez</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Latent Semantic Analysis (LSA) and Word2vec are some of the most widely used
word embeddings. Despite the popularity of these techniques, the precise
mechanisms by which they acquire new semantic relations between words remain
unclear. In the present article we investigate whether LSA and Word2vec
capacity to identify relevant semantic dimensions increases with size of
corpus. One intuitive hypothesis is that the capacity to identify relevant
dimensions should increase as the amount of data increases. However, if corpus
size grow in topics which are not specific to the domain of interest, signal to
noise ratio may weaken. Here we set to examine and distinguish these
alternative hypothesis. To investigate the effect of corpus specificity and
size in word-embeddings we study two ways for progressive elimination of
documents: the elimination of random documents vs. the elimination of documents
unrelated to a specific task. We show that Word2vec can take advantage of all
the documents, obtaining its best performance when it is trained with the whole
corpus. On the contrary, the specialization (removal of out-of-domain
documents) of the training corpus, accompanied by a decrease of dimensionality,
can increase LSA word-representation quality while speeding up the processing
time. Furthermore, we show that the specialization without the decrease in LSA
dimensionality can produce a strong performance reduction in specific tasks.
From a cognitive-modeling point of view, we point out that LSA's word-knowledge
acquisitions may not be efficiently exploiting higher-order co-occurrences and
global relations, whereas Word2vec does.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10056</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring Formal Properties of Production Key-Value Stores</dc:title>
 <dc:creator>Pek, Edgar</dc:creator>
 <dc:creator>Garg, Pranav</dc:creator>
 <dc:creator>Rahman, Muntasir Raihan</dc:creator>
 <dc:creator>Palmskog, Karl</dc:creator>
 <dc:creator>Gupta, Indranil</dc:creator>
 <dc:creator>Madhusudan, P.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Production distributed systems are challenging to formally verify, in
particular when they are based on distributed protocols that are not rigorously
described or fully understood. In this paper, we derive models and properties
for two core distributed protocols used in eventually consistent production
key-value stores such as Riak and Cassandra. We propose a novel modeling called
certified program models, where complete distributed systems are captured as
programs written in traditional systems languages such as concurrent C.
Specifically, we model the read-repair and hinted-handoff recovery protocols as
concurrent C programs, test them for conformance with real systems, and then
verify that they guarantee eventual consistency, modeling precisely the
specification as well as the failure assumptions under which the results hold.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10057</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arrow of time and its reversal on IBM quantum computer</dc:title>
 <dc:creator>Lesovik, G. B.</dc:creator>
 <dc:creator>Sadovskyy, I. A.</dc:creator>
 <dc:creator>Suslov, M. V.</dc:creator>
 <dc:creator>Lebedev, A. V.</dc:creator>
 <dc:creator>Vinokur, V. M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Condensed Matter - Superconductivity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Uncovering the origin of the arrow of time remains a fundamental scientific
challenge. Within the framework of statistical physics, this problem was
inextricably associated with the Second Law of Thermodynamics, which declares
that entropy growth proceeds from the system's entanglement with the
environment. It remains to be seen, however, whether the irreversibility of
time is a fundamental law of nature or whether, on the contrary, it might be
circumvented. Here we show that, while in nature the complex conjugation needed
for time reversal is exponentially improbable, one can design a quantum
algorithm that includes complex conjugation and thus reverses a given quantum
state. Using this algorithm on an IBM quantum computer enables us to
experimentally demonstrate a backward time dynamics for an electron scattered
on a two-level impurity.
</dc:description>
 <dc:description>Comment: 14 pages, 3 figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10058</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abstract Interpretation using a Language of Symbolic Approximation</dc:title>
 <dc:creator>Lemerre, Matthieu</dc:creator>
 <dc:creator>Bardin, S&#xe9;bastien</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The traditional abstract domain framework for imperative programs suffers
from several shortcomings; in particular it does not allow precise symbolic
abstractions. To solve these problems, we propose a new abstract interpretation
framework, based on symbolic expressions used both as an abstraction of the
program, and as the input analyzed by abstract domains. We demonstrate new
applications of the frame- work: an abstract domain that efficiently propagates
constraints across the whole program; a new formalization of functor domains as
approximate translation, which allows the production of approximate programs,
on which we can perform classical symbolic techniques. We used these to build a
complete analyzer for embedded C programs, that demonstrates the practical
applicability of the framework.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10061</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Age of Information in Multihop Networks</dc:title>
 <dc:creator>Bedewy, Ahmed M.</dc:creator>
 <dc:creator>Sun, Yin</dc:creator>
 <dc:creator>Shroff, Ness B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The problem of minimizing the age-of-information has been extensively studied
in single-hop networks. In this paper, we minimize the age of a single
information flow in multihop networks. If the packet transmission times over
the network links are exponentially distributed, we prove that a preemptive
Last-Generated, First-Serve (LGFS) policy results in smaller age processes at
all nodes of the network (in a stochastic ordering sense) than any other causal
policy. In addition, for arbitrary distributions of packet transmission times,
the non-preemptive LGFS policy is shown to minimize the age processes at all
nodes among all non-preemptive work-conserving policies (again in a stochastic
ordering sense). Interestingly, these simple policies can achieve optimality of
the joint distribution of the age processes at all nodes even under arbitrary
network topologies, as well as arbitrary packet generation and arrival times.
These optimality results not only hold for the age processes, but also for any
non-decreasing functional of the age processes. Finally, we investigate the
class of New-Better-than-Used (NBU) packet transmission time distributions and
show that the non-preemptive LGFS policy is within a constant age gap from the
optimum average age, and that the gap is independent of system parameters.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1701.05711</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10062</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-timescale memory dynamics in a reinforcement learning network with
  attention-gated memory</dc:title>
 <dc:creator>Martinolli, Marco</dc:creator>
 <dc:creator>Gerstner, Wulfram</dc:creator>
 <dc:creator>Gilra, Aditya</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning and memory are intertwined in our brain and their relationship is at
the core of several recent neural network models. In particular, the
Attention-Gated MEmory Tagging model (AuGMEnT) is a reinforcement learning
network with an emphasis on biological plausibility of memory dynamics and
learning. We find that the AuGMEnT network does not solve some hierarchical
tasks, where higher-level stimuli have to be maintained over a long time, while
lower-level stimuli need to be remembered and forgotten over a shorter
timescale. To overcome this limitation, we introduce hybrid AuGMEnT, with leaky
or short-timescale and non-leaky or long-timescale units in memory, that allow
to exchange lower-level information while maintaining higher-level one, thus
solving both hierarchical and distractor tasks.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10063</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Topology Mapping from Partial Virtual Coordinates and Graph
  Geodesics</dc:title>
 <dc:creator>Jayasumana, Anura P.</dc:creator>
 <dc:creator>Paffenroth, Randy</dc:creator>
 <dc:creator>Ramasamy, Sridhar</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>15A83</dc:subject>
 <dc:description>  For many important network types (e.g., sensor networks in complex harsh
environments and social networks) physical coordinate systems (e.g.,
Cartesian), and physical distances (e.g., Euclidean), are either difficult to
discern or inappropriate. Accordingly, Topology Preserving Maps (TPMs) derived
from a Virtual-Coordinate (VC) system representing the distance to a small set
of anchors is an attractive alternative to physical coordinates for many
network algorithms. Herein, we present an approach, based on the theory of
low-rank matrix completion, to recover geometric properties of a network with
only partial information about the VCs of nodes. In particular, our approach is
a combination of geodesic recovery concepts and low-rank matrix completion,
generalized to the case of hop-distances in graphs. Distortion evaluated using
the change of distance among node pairs shows that even with up to 40% to 60%
of random coordinates missing, accurate TPMs can be obtained. TPM generation
can now also be based on different context appropriate VC systems or
measurements as long as they characterize each node with distances to a small
set of random nodes (instead of a global set of anchors). The proposed method
is a significant generalization that allows the topology to be extracted from a
random set of graph geodesics, making it applicable in contexts such as social
networks where VC generation may not be possible.
</dc:description>
 <dc:description>Comment: 11 pages and 7 figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10066</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disentangled Representations for Manipulation of Sentiment in Text</dc:title>
 <dc:creator>Larsson, Maria</dc:creator>
 <dc:creator>Nilsson, Amanda</dc:creator>
 <dc:creator>K&#xe5;geb&#xe4;ck, Mikael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The ability to change arbitrary aspects of a text while leaving the core
message intact could have a strong impact in fields like marketing and politics
by enabling e.g. automatic optimization of message impact and personalized
language adapted to the receiver's profile. In this paper we take a first step
towards such a system by presenting an algorithm that can manipulate the
sentiment of a text while preserving its semantics using disentangled
representations. Validation is performed by examining trajectories in embedding
space and analyzing transformed sentences for semantic preservation while
expression of desired sentiment shift.
</dc:description>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10068</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Platform Criminalism: The 'Last-Mile' Geography of the Darknet Market
  Supply Chain</dc:title>
 <dc:creator>Dittus, Martin</dc:creator>
 <dc:creator>Wright, Joss</dc:creator>
 <dc:creator>Graham, Mark</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:subject>K.4.4</dc:subject>
 <dc:description>  Does recent growth of darknet markets signify a slow reorganisation of the
illicit drug trade? Where are darknet markets situated in the global drug
supply chain? In principle, these platforms allow producers to sell directly to
end users, bypassing traditional trafficking routes. And yet, there is evidence
that many offerings originate from a small number of highly active consumer
countries, rather than from countries that are primarily known for drug
production. In a large-scale empirical study, we determine the darknet trading
geography of three plant-based drugs across four of the largest darknet
markets, and compare it to the global footprint of production and consumption
for these drugs. We present strong evidence that cannabis and cocaine vendors
are primarily located in a small number of consumer countries, rather than
producer countries, suggesting that darknet trading happens at the 'last mile',
possibly leaving old trafficking routes intact. A model to explain trading
volumes of opiates is inconclusive. We cannot find evidence for significant
production-side offerings across any of the drug types or marketplaces. Our
evidence further suggests that the geography of darknet market trades is
primarily driven by existing consumer demand, rather than new demand fostered
by individual markets.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10069</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Robotic Mapping through Deep Reinforcement Learning</dc:title>
 <dc:creator>Barratt, Shane</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose an approach to learning agents for active robotic mapping, where
the goal is to map the environment as quickly as possible. The agent learns to
map efficiently in simulated environments by receiving rewards corresponding to
how fast it constructs an accurate map. In contrast to prior work, this
approach learns an exploration policy based on a user-specified prior over
environment configurations and sensor model, allowing it to specialize to the
specifications. We evaluate the approach through a simulated Disaster Mapping
scenario and find that it achieves performance slightly better than a
near-optimal myopic exploration scheme, suggesting that it could be useful in
more complicated problem scenarios.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10070</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning with Analogical Similarity to Guide Schema
  Induction and Attention</dc:title>
 <dc:creator>Foster, James M.</dc:creator>
 <dc:creator>Jones, Matt</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Research in analogical reasoning suggests that higher-order cognitive
functions such as abstract reasoning, far transfer, and creativity are founded
on recognizing structural similarities among relational systems. Here we
integrate theories of analogy with the computational framework of reinforcement
learning (RL). We propose a psychology theory that is a computational synergy
between analogy and RL, in which analogical comparison provides the RL learning
algorithm with a measure of relational similarity, and RL provides feedback
signals that can drive analogical learning. Simulation results support the
power of this approach.
</dc:description>
 <dc:description>Comment: 20 pages, 7 figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10073</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling Noise-Resilient Single-Switch Scanning Systems</dc:title>
 <dc:creator>Nel, Emli-Mari</dc:creator>
 <dc:creator>Kristensson, Per Ola</dc:creator>
 <dc:creator>MacKay, David J. C.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Single-switch scanning systems allow nonspeaking individuals with motor
disabilities to communicate by triggering a single switch (e.g., raising an eye
brow). A problem with current single-switch scanning systems is that while they
result in reasonable performance in noiseless conditions, for instance via
simulation or tests with able-bodied users, they fail to accurately model the
noise sources that are introduced when a non-speaking individual with motor
disabilities is triggering the switch in a realistic use context. To help
assist the development of more noise-resilient single-switch scanning systems
we have developed a mathematical model of scanning systems which incorporates
extensive noise modelling. Our model includes an improvement to the standard
scanning method, which we call fast-scan, which we show via simulation can be
more suitable for certain users of scanning systems.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10077</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aircraft trajectory control with feedback linearization for general
  nonlinear system</dc:title>
 <dc:creator>Zhang, Sheng</dc:creator>
 <dc:creator>Liao, Fei</dc:creator>
 <dc:creator>Chen, Yanqing</dc:creator>
 <dc:creator>He, Kaifeng</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The feedback linearization method is further developed for the controller
design on general nonlinear systems. Through the Lyapunov stability theory, the
intractable nonlinear implicit algebraic control equations are effectively
solved, and the asymptotically tracking performance is guaranteed. Moreover, it
is proved that the controller may be used in an inverse-free version to the
set-point control. With this method, a nonlinear aircraft outer-loop trajectory
controller is developed. For the concern regarding the controller's robustness,
the integral control technique is combined to counteract the adverse effect
from modeling errors. Simulation results verify the well performance of the
proposed controller.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10081</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Level Augmented Bayesian Optimization for Finding the Best Cloud VM</dc:title>
 <dc:creator>Hsu, Chin-Jung</dc:creator>
 <dc:creator>Nair, Vivek</dc:creator>
 <dc:creator>Freeh, Vincent W.</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  With the advent of big data applications, which tends to have longer
execution time, choosing the right cloud VM to run these applications has
significant performance as well as economic implications. For example, in our
large-scale empirical study of 107 different workloads on three popular big
data systems, we found that a wrong choice can lead to a 20 times slowdown or
an increase in cost by 10 times.
  Bayesian optimization is a technique for optimizing expensive (black-box)
functions. Previous attempts have only used instance-level information (such as
# of cores, memory size) which is not sufficient to represent the search space.
In this work, we discover that this may lead to the fragility problem---either
incurs high search cost or finds only the sub-optimal solution. The central
insight of this paper is to use low-level performance information to augment
the process of Bayesian Optimization. Our novel low-level augmented Bayesian
Optimization is rarely worse than current practices and often performs much
better (in 46 of 107 cases). Further, it significantly reduces the search cost
in nearly half of our case studies.
  Based on this work, we conclude that it is often insufficient to use
general-purpose off-the-shelf methods for configuring cloud instances without
augmenting those methods with essential systems knowledge such as CPU
utilization, working memory size and I/O wait time.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10082</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Convolutional Neural Network to Predict Airfoil Lift
  Coefficient</dc:title>
 <dc:creator>Zhang, Yao</dc:creator>
 <dc:creator>Sung, Woong-Je</dc:creator>
 <dc:creator>Mavris, Dimitri</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The adaptability of the convolutional neural network (CNN) technique for
aerodynamic meta-modeling tasks is probed in this work. The primary objective
is to develop suitable CNN architecture for variable flow conditions and object
geometry, in addition to identifying a sufficient data preparation process.
Multiple CNN structures were trained to learn the lift coefficients of the
airfoils with a variety of shapes in multiple flow Mach numbers, Reynolds
numbers, and diverse angles of attack. This is conducted to illustrate the
concept of the technique. A multi-layered perceptron (MLP) is also used for the
training sets. The MLP results are compared with that of the CNN results. The
newly proposed meta-modeling concept has been found to be comparable with the
MLP in learning capability; and more importantly, our CNN model exhibits a
competitive prediction accuracy with minimal constraints in a geometric
representation.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10085</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Limited Feedback Channel Estimation in Massive MIMO with Non-uniform
  Directional Dictionaries</dc:title>
 <dc:creator>Alevizos, Panos N.</dc:creator>
 <dc:creator>Fu, Xiao</dc:creator>
 <dc:creator>Sidiropoulos, Nicholas</dc:creator>
 <dc:creator>Ye, Yang</dc:creator>
 <dc:creator>Bletsas, Aggelos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Channel state information (CSI) at the base station (BS) is crucial to
achieve beamforming and multiplexing gains in multiple-input multiple-output
(MIMO) systems. State-of-the-art limited feedback schemes require feedback
overhead that scales linearly with the number of BS antennas, which is
prohibitive for $5$G massive MIMO. This work proposes novel limited feedback
algorithms that lift this burden by exploiting the inherent sparsity in double
directional (DD) MIMO channel representation using overcomplete dictionaries.
These dictionaries are associated with angle of arrival (AoA) and angle of
departure (AoD) that specifically account for antenna directivity patterns at
both ends of the link. The proposed algorithms achieve satisfactory channel
estimation accuracy using a small number of feedback bits, even when the number
of transmit antennas at the BS is large -- making them ideal for $5$G massive
MIMO. Judicious simulations reveal that they outperform a number of popular
feedback schemes, and underscore the importance of using angle dictionaries
matching the given antenna directivity patterns, as opposed to uniform
dictionaries. The proposed algorithms are lightweight in terms of computation,
especially on the user equipment side, making them ideal for actual deployment
in $5$G systems.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10095</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind Identification of Fully Observed Discrete-Time Linear Time-Varying
  Systems via Sparse Recovery</dc:title>
 <dc:creator>Dobbe, Roel</dc:creator>
 <dc:creator>Liu, Stephan</dc:creator>
 <dc:creator>Yuan, Ye</dc:creator>
 <dc:creator>Tomlin, Claire</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Discrete-time linear time-varying (LTV) systems form a powerful class of
models to approximate complex dynamical systems or networks with nonlinear
dynamics for the purpose of analysis, design and control. Motivated by
inference of spatio-temporal dynamics in breast cancer research, we propose a
method to efficiently solve an identification problem for a specific class of
discrete-time LTV systems, in which the states are fully observed and there is
no access to system inputs. In addition, it is assumed that we do not know on
which states the inputs act, which can change between time steps, and that the
total number of inputs is sparse over all states and over time. The problem is
formulated as a compressive sensing problem, which incorporates the effect of
measurement and process noise and which has a solution with a partially sparse
support. We derive sufficient conditions for the unique recovery of the system
model and input values, which lead to practical conditions on the number of
experiments and rank conditions on system outputs. Synthetic experiments
validate the sensitivity to noise.
</dc:description>
 <dc:description>Comment: Under review with Automatica</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10097</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Wirelessly Powered Crowd Sensing: Trading energy for data</dc:title>
 <dc:creator>Li, Xiaoyang</dc:creator>
 <dc:creator>You, Changsheng</dc:creator>
 <dc:creator>Andreev, Sergey</dc:creator>
 <dc:creator>Gong, Yi</dc:creator>
 <dc:creator>Huang, Kaibin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To overcome the limited coverage in traditional wireless sensor networks,
\emph{mobile crowd sensing} (MCS) has emerged as a new sensing paradigm. To
achieve longer battery lives of user devices and incentive human involvement,
this paper presents a novel approach that seamlessly integrates MCS with
wireless power transfer, called \emph{wirelessly powered crowd sensing} (WPCS),
for supporting crowd sensing with energy consumption and offering rewards as
incentives. The optimization problem is formulated to simultaneously maximize
the data utility and minimize the energy consumption for service operator, by
jointly controlling wireless-power allocation at the \emph{access point} (AP)
as well as sensing-data size, compression ratio, and sensor-transmission
duration at \emph{mobile sensor} (MS). Given the fixed compression ratios, the
optimal power allocation policy is shown to have a \emph{threshold}-based
structure with respect to a defined \emph{crowd-sensing priority} function for
each MS. Given fixed sensing-data utilities, the compression policy achieves
the optimal compression ratio. Extensive simulations are also presented to
verify the efficiency of the contributed mechanisms.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1711.02066</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10107</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Objective evaluation metrics for automatic classification of EEG events</dc:title>
 <dc:creator>Ziyabari, Saeedeh</dc:creator>
 <dc:creator>Shah, Vinit</dc:creator>
 <dc:creator>Golmohammadi, Meysam</dc:creator>
 <dc:creator>Obeid, Iyad</dc:creator>
 <dc:creator>Picone, Joseph</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The evaluation of machine learning algorithms in biomedical fields for
applications involving sequential data lacks standardization. Common
quantitative scalar evaluation metrics such as sensitivity and specificity can
often be misleading depending on the requirements of the application.
Evaluation metrics must ultimately reflect the needs of users yet be
sufficiently sensitive to guide algorithm development. Feedback from critical
care clinicians who use automated event detection software in clinical
applications has been overwhelmingly emphatic that a low false alarm rate,
typically measured in units of the number of errors per 24 hours, is the single
most important criterion for user acceptance. Though using a single metric is
not often as insightful as examining performance over a range of operating
conditions, there is a need for a single scalar figure of merit. In this paper,
we discuss the deficiencies of existing metrics for a seizure detection task
and propose several new metrics that offer a more balanced view of performance.
We demonstrate these metrics on a seizure detection task based on the TUH EEG
Corpus. We show that two promising metrics are a measure based on a concept
borrowed from the spoken term detection literature, Actual Term-Weighted Value,
and a new metric, Time-Aligned Event Scoring (TAES), that accounts for the
temporal alignment of the hypothesis to the reference annotation. We also
demonstrate that state of the art technology based on deep learning, though
impressive in its performance, still needs significant improvement before it
will meet very strict user acceptance guidelines.
</dc:description>
 <dc:description>Comment: Under review on Journal of Neural Engineering</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10110</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Keywords and Relevance: A Personalized Ad Retrieval Framework in
  E-Commerce Sponsored Search</dc:title>
 <dc:creator>Yan, Su</dc:creator>
 <dc:creator>Lin, Wei</dc:creator>
 <dc:creator>Wu, Tianshu</dc:creator>
 <dc:creator>Xiao, Daorui</dc:creator>
 <dc:creator>Wu, Bo</dc:creator>
 <dc:creator>Liu, Kaipeng</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  On most sponsored search platforms, advertisers bid on some keywords for
their advertisements (ads). Given a search request, ad retrieval module
rewrites the query into bidding keywords, and uses these keywords as keys to
select Top N ads through inverted indexes. In this way, an ad will not be
retrieved even if queries are related when the advertiser does not bid on
corresponding keywords. Moreover, most ad retrieval approaches regard rewriting
and ad-selecting as two separated tasks, and focus on boosting relevance
between search queries and ads. Recently, in e-commerce sponsored search more
and more personalized information has been introduced, such as user profiles,
long-time and real-time clicks. Personalized information makes ad retrieval
able to employ more elements (e.g. real-time clicks) as search signals and
retrieval keys, however it makes ad retrieval more difficult to measure ads
retrieved through different signals. To address these problems, we propose a
novel ad retrieval framework beyond keywords and relevance in e-commerce
sponsored search. Firstly, we employ historical ad click data to initialize a
hierarchical network representing signals, keys and ads, in which personalized
information is introduced. Then we train a model on top of the hierarchical
network by learning the weights of edges. Finally we select the best edges
according to the model, boosting RPM/CTR. Experimental results on our
e-commerce platform demonstrate that our ad retrieval framework achieves good
performance.
</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10114</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient and Fair Multi-Resource Allocation Mechanism for
  Heterogeneous Servers</dc:title>
 <dc:creator>Khamse-Ashari, Jalal</dc:creator>
 <dc:creator>Lambadaris, Ioannis</dc:creator>
 <dc:creator>Kesidis, George</dc:creator>
 <dc:creator>Urgaonkar, Bhuvan</dc:creator>
 <dc:creator>Zhao, Yiqiang</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Efficient and fair allocation of multiple types of resources is a crucial
objective in a cloud/distributed computing cluster. Users may have diverse
resource needs. Furthermore, diversity in server properties/ capabilities may
mean that only a subset of servers may be usable by a given user. In platforms
with such heterogeneity, we identify important limitations in existing
multi-resource fair allocation mechanisms, notably Dominant Resource Fairness
(DRF) and its follow-up work. To overcome such limitations, we propose a new
server-based approach; each server allocates resources by maximizing a
per-server utility function. We propose a specific class of utility functions
which, when appropriately parameterized, adjusts the trade-off between
efficiency and fairness, and captures a variety of fairness measures (such as
our recently proposed Per-Server Dominant Share Fairness). We establish
conditions for the proposed mechanism to satisfy certain properties that are
generally deemed desirable, e.g., envy-freeness, sharing incentive, bottleneck
fairness, and Pareto optimality. To implement our resource allocation
mechanism, we develop an iterative algorithm which is shown to be globally
convergent. Finally, we show how the proposed mechanism could be implemented in
a distributed fashion. We carry out extensive trace-driven simulations to show
the enhanced performance of our proposed mechanism over the existing ones.
</dc:description>
 <dc:description>Comment: Technical Report, 20 pages, 14 figures</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10128</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured decentralized control of positive systems with applications
  to combination drug therapy and leader selection in directed networks</dc:title>
 <dc:creator>Dhingra, Neil K.</dc:creator>
 <dc:creator>Colombino, Marcello</dc:creator>
 <dc:creator>Jovanovi&#x107;, Mihailo R.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We study a class of structured optimal control problems in which the main
diagonal of the dynamic matrix is a linear function of the design variable.
While such problems are in general challenging and nonconvex, for positive
systems we prove convexity of the $H_2$ and $H_\infty$ optimal control
formulations which allow for arbitrary convex constraints and regularization of
the control input. Moreover, we establish differentiability of the $H_\infty$
norm when the graph associated with the dynamical generator is weakly connected
and develop a customized algorithm for computing the optimal solution even in
the absence of differentiability. We apply our results to the problems of
leader selection in directed consensus networks and combination drug therapy
for HIV treatment. In the context of leader selection, we address the
combinatorial challenge by deriving upper and lower bounds on optimal
performance. For combination drug therapy, we develop a customized subgradient
method for efficient treatment of diseases whose mutation patterns are not
connected.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10132</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Multilinear Structure of ReLU Networks</dc:title>
 <dc:creator>Laurent, Thomas</dc:creator>
 <dc:creator>von Brecht, James</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the loss surface of neural networks equipped with a hinge loss
criterion and ReLU or leaky ReLU nonlinearities. Any such network defines a
piecewise multilinear form in parameter space, and as a consequence, optima of
such networks generically occur in non-differentiable regions of parameter
space. Any understanding of such networks must therefore carefully take into
account their non-smooth nature. We show how to use techniques from nonsmooth
analysis to study these non-differentiable loss surfaces. Our analysis focuses
on three different scenarios: (1) a deep linear network with hinge loss and
arbitrary data, (2) a one-hidden layer network with leaky ReLUs and linearly
separable data, and (3) a one-hidden layer network with ReLU nonlinearities and
linearly separable data. We show that all local minima are global minima in the
first two scenarios. A bifurcation occurs when passing from the second to the
the third scenario, in that ReLU networks do have non-optimal local minima. We
provide a complete description of such sub-optimal solutions. We conclude by
investigating the extent to which these phenomena do, or do not, persist when
passing to the multiclass context.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10136</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep and Compact Models for Gesture Recognition</dc:title>
 <dc:creator>Mullick, Koustav</dc:creator>
 <dc:creator>Namboodiri, Anoop M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We look at the problem of developing a compact and accurate model for gesture
recognition from videos in a deep-learning framework. Towards this we propose a
joint 3DCNN-LSTM model that is end-to-end trainable and is shown to be better
suited to capture the dynamic information in actions. The solution achieves
close to state-of-the-art accuracy on the ChaLearn dataset, with only half the
model size. We also explore ways to derive a much more compact representation
in a knowledge distillation framework followed by model compression. The final
model is less than $1~MB$ in size, which is less than one hundredth of our
initial model, with a drop of $7\%$ in accuracy, and is suitable for real-time
gesture recognition on mobile devices.
</dc:description>
 <dc:description>Comment: Accepted at 2017 IEEE International Conference on Image Processing
  (ICIP 2017)</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10145</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Transmission and Self-Energy Recycling for Wireless-Powered Relay
  Systems with Partial Eavesdropper Channel State Information</dc:title>
 <dc:creator>Qiao, Jingping</dc:creator>
 <dc:creator>Zhang, Haixia</dc:creator>
 <dc:creator>Zhao, Feng</dc:creator>
 <dc:creator>Yuan, Dongfeng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper focuses on the secure transmission of wireless-powered relay
systems with imperfect eavesdropper channel state information (ECSI). For
efficient energy transfer and information relaying, a novel two-phase protocol
is proposed, in which the relay operates in full-duplex (FD) mode to achieve
simultaneous wireless power and information transmission. Compared with those
existing protocols, the proposed design possesses two main advantages: 1) it
fully exploits the available hardware resource (antenna element) of relay and
can offer higher secrecy rate; 2) it enables self-energy recycling (S-ER) at
relay, in which the loopback interference (LI) generated by FD operation is
harvested and reused for information relaying. To maximize the worst-case
secrecy rate (WCSR) through jointly designing the source and relay beamformers
coupled with the power allocation ratio, an optimization problem is formulated.
This formulated problem is proved to be non-convex and the challenge to solve
it is how to concurrently solve out the beamformers and the power allocation
ratio. To cope with this difficulty, an alternative approach is proposed by
converting the original problem into three subproblems. By solving these
subproblems iteratively, the closed form solutions of robust beamformers and
power allocation ratio for the original problem are achieved. Simulations are
done and results reveal that the proposed S-ER based secure transmission scheme
outperforms the traditional time-switching based relaying (TSR) scheme at a
maximum WCSR gain of 80%.Results also demonstrate that the WCSR performance of
the scheme reusing idle antennas for information reception is much better than
that of schemes exploiting only one receive antenna.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10151</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Significance of Softmax-based Features in Comparison to Distance Metric
  Learning-based Features</dc:title>
 <dc:creator>Horiguchi, Shota</dc:creator>
 <dc:creator>Ikami, Daiki</dc:creator>
 <dc:creator>Aizawa, Kiyoharu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The extraction of useful deep features is important for many computer vision
tasks. Deep features extracted from classification networks have proved to
perform well in those tasks. To obtain features of greater usefulness,
end-to-end distance metric learning (DML) has been applied to train the feature
extractor directly. However, in these DML studies, there were no equitable
comparisons between features extracted from a DML-based network and those from
a softmax-based network. In this paper, by presenting objective comparisons
between these two approaches under the same network architecture, we show that
the softmax-based features perform competitive, or even better, to the
state-of-the-art DML features when the size of the dataset, that is, the number
of training samples per class, is large. The results suggest that softmax-based
features should be properly taken into account when evaluating the performance
of deep features.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10152</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the significance of using perceptually relevant image
  decolorization method for scene classification</dc:title>
 <dc:creator>Sowmya, V.</dc:creator>
 <dc:creator>Govind, D.</dc:creator>
 <dc:creator>Soman, K. P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A color image contains luminance and chrominance components representing the
intensity and color information respectively. The objective of the work
presented in this paper is to show the significance of incorporating the
chrominance information for the task of scene classification. An improved
color-to-grayscale image conversion algorithm by effectively incorporating the
chrominance information is proposed using color-to-gay structure similarity
index (C2G-SSIM) and singular value decomposition (SVD) to improve the
perceptual quality of the converted grayscale images. The experimental result
analysis based on the image quality assessment for image decolorization called
C2G-SSIM and success rate (Cadik and COLOR250 datasets) shows that the proposed
image decolorization technique performs better than 8 existing benchmark
algorithms for image decolorization. In the second part of the paper, the
effectiveness of incorporating the chrominance component in scene
classification task is demonstrated using the deep belief network (DBN) based
image classification system developed using dense scale invariant feature
transform (SIFT) as features. The levels of chrominance information
incorporated by the proposed image decolorization technique is confirmed by the
improvement in the overall scene classification accuracy . Also, the overall
scene classification performance is improved by the combination of models
obtained using the proposed and the conventional decolorization methods.
</dc:description>
 <dc:description>Comment: This article is accepted in SPIE J.of Electronic Imaging with title:
  Significance of perceptually relevant image decolorization for scene
  classification</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10152</dc:identifier>
 <dc:identifier>Sowmya Viswanathan, Govind Divakaran, Kutti Padanyl Soman,
  Significance of perceptually relevant image decolorization for scene
  classification, J. Electron. Imaging 26(6), 063019 (2017)</dc:identifier>
 <dc:identifier>doi:10.1117/1.JEI.26.6.063019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10155</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secret Sharing for Cloud Data Security</dc:title>
 <dc:creator>Attasena, Varunya</dc:creator>
 <dc:creator>Darmont, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Harbi, Nouria</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cloud computing helps reduce costs, increase business agility and deploy
solutions with a high return on investment for many types of applications.
However, data security is of premium importance to many users and often
restrains their adoption of cloud technologies. Various approaches, i.e., data
encryption, anonymization, replication and verification, help enforce different
facets of data security. Secret sharing is a particularly interesting
cryptographic technique. Its most advanced variants indeed simultaneously
enforce data privacy, availability and integrity, while allowing computation on
encrypted data. The aim of this paper is thus to wholly survey secret sharing
schemes with respect to data security, data access and costs in the
pay-as-you-go paradigm.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10155</dc:identifier>
 <dc:identifier>The International Journal on Very Large Databases,
  Springer-Verlag, 2017, 26 (5), pp.657-681</dc:identifier>
 <dc:identifier>doi:10.1007/s00778-017-0470-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10157</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signed Graph Analysis for the Interpretation of Voting Behavior</dc:title>
 <dc:creator>Arinik, Nejat</dc:creator>
 <dc:creator>Figueiredo, Rosa</dc:creator>
 <dc:creator>Labatut, Vincent</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In a signed graph, each link is labeled with either a positive or a negative
sign. This is particularly appropriate to model polarized systems. Such a graph
can be characterized through the notion of structural balance, which relies on
the partitioning of the graph into internally solidary but mutually hostile
subgroups. In this work, we show that signed graphs can be used to model and
understand voting behavior. We take advantage of data from the European
Parliament to confront two variants of structural balance, and illustrate how
their use can help better understanding the studied system.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10157</dc:identifier>
 <dc:identifier>International Conference on Knowledge Technologies and Data-driven
  Business (i-KNOW), Oct 2017, Graz, Austria. 2017, International Workshop on
  Social Network Analysis and Digital Humanities (SnanDig).
  \&amp;\#x3008;http://ceur-ws.org/Vol-2025/paper\_rssna\_1.pdf\&amp;\#x3009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10158</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-linear motor control by local learning in spiking neural networks</dc:title>
 <dc:creator>Gilra, Aditya</dc:creator>
 <dc:creator>Gerstner, Wulfram</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning weights in a spiking neural network with hidden neurons, using
local, stable and online rules, to control non-linear body dynamics is an open
problem. Here, we employ a supervised scheme, Feedback-based Online Local
Learning Of Weights (FOLLOW), to train a network of heterogeneous spiking
neurons with hidden layers, to control a two-link arm so as to reproduce a
desired state trajectory. The network first learns an inverse model of the
non-linear dynamics, i.e. from state trajectory as input to the network, it
learns to infer the continuous-time command that produced the trajectory.
Connection weights are adjusted via a local plasticity rule that involves
pre-synaptic firing and post-synaptic feedback of the error in the inferred
command. We choose a network architecture, termed differential feedforward,
that gives the lowest test error from different feedforward and recurrent
architectures. The learned inverse model is then used to generate a
continuous-time motor command to control the arm, given a desired trajectory.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10163</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation under group actions: recovering orbits from invariants</dc:title>
 <dc:creator>Bandeira, Afonso S.</dc:creator>
 <dc:creator>Blum-Smith, Ben</dc:creator>
 <dc:creator>Perry, Amelia</dc:creator>
 <dc:creator>Weed, Jonathan</dc:creator>
 <dc:creator>Wein, Alexander S.</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>62F10, 92C55, 16W22</dc:subject>
 <dc:description>  Motivated by geometric problems in signal processing, computer vision, and
structural biology, we study a class of orbit recovery problems where we
observe noisy copies of an unknown signal, each acted upon by a random element
of some group (such as $\mathbb{Z}/p$ or $\mathrm{SO}(3)$). The goal is to
recover the orbit of the signal under the group action. This generalizes
problems of interest such as multi-reference alignment (MRA) and the
reconstruction problem in cryo-electron microscopy (cryo-EM). We obtain
matching lower and upper bounds on the sample complexity of these problems in
high generality, showing that the statistical difficulty is intricately
determined by the invariant theory of the underlying symmetry group.
  In particular, we determine that for cryo-EM with noise variance $\sigma^2$
and uniform viewing directions, the number of samples required scales as
$\sigma^6$. We match this bound with a novel algorithm for ab initio
reconstruction in cryo-EM, based on invariant features of degree at most $3$.
We further discuss how to recover multiple molecular structures from
heterogeneous cryo-EM samples.
</dc:description>
 <dc:description>Comment: 42 pages</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10164</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polyp detection inside the capsule endoscopy: an approach for power
  consumption reduction</dc:title>
 <dc:creator>Khorsandi, Mohammad Amin</dc:creator>
 <dc:creator>Karimi, Nader</dc:creator>
 <dc:creator>Samavi, Shadrokh</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Capsule endoscopy is a novel and non-invasive method for diagnosis, which
assists gastroenterologists to monitor the digestive track. Although this new
technology has many advantages over the conventional endoscopy, there are
weaknesses that limits the usage of this technology. Some weaknesses are due to
using small-size batteries. Radio transmitter consumes the largest portion of
energy; consequently, a simple way to reduce the power consumption is to reduce
the data to be transmitted. Many works are proposed to reduce the amount of
data to be transmitted consist of specific compression methods and reduction in
video resolution and frame rate. We proposed a system inside the capsule for
detecting informative frames and sending these frames instead of several
non-informative frames. In this work, we specifically focused on hardware
friendly algorithm (with capability of parallelism and pipeline) for
implementation of polyp detection. Two features of positive contrast and
customized edges of polyps are exploited to define whether the frame consists
of polyp or not. The proposed method is devoid of complex and iterative
structure to save power and reduce the response time. Experimental results
indicate acceptable rate of detection of our work.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10167</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple cubic graphs with no short traveling salesman tour</dc:title>
 <dc:creator>Luko&#x165;ka, Robert</dc:creator>
 <dc:creator>Maz&#xe1;k, J&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let $tsp(G)$ denote the length of a shortest travelling salesman tour in a
graph $G$. We prove that for any $\varepsilon&gt;0$, there exists a simple
$2$-connected planar cubic graph $G_1$ such that $tsp(G_1)\ge
(1.25-\varepsilon)\cdot|V(G_1)|$, a simple $2$-connected bipartite cubic graph
$G_2$ such that $tsp(G_2)\ge (1.2-\varepsilon)\cdot|V(G_2)|$, and a simple
$3$-connected cubic graph $G_3$ such that $tsp(G_3)\ge
(1.125-\varepsilon)\cdot|V(G_3)|$.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10179</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RedDwarfData: a simplified dataset of StarCraft matches</dc:title>
 <dc:creator>Merelo-Guerv&#xf3;s, Juan J.</dc:creator>
 <dc:creator>Fern&#xe1;ndez-Ares, Antonio</dc:creator>
 <dc:creator>Caballero, Antonio &#xc1;lvarez</dc:creator>
 <dc:creator>Garc&#xed;a-S&#xe1;nchez, Pablo</dc:creator>
 <dc:creator>Rivas, Victor</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The game Starcraft is one of the most interesting arenas to test new machine
learning and computational intelligence techniques; however, StarCraft matches
take a long time and creating a good dataset for training can be hard. Besides,
analyzing match logs to extract the main characteristics can also be done in
many different ways to the point that extracting and processing data itself can
take an inordinate amount of time and of course, depending on what you choose,
can bias learning algorithms. In this paper we present a simplified dataset
extracted from the set of matches published by Robinson and Watson, which we
have called RedDwarfData, containing several thousand matches processed to
frames, so that temporal studies can also be undertaken. This dataset is
available from GitHub under a free license. An initial analysis and appraisal
of these matches is also made.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10190</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Cross-Lingual Plagiarism Using Simulated Word Embeddings</dc:title>
 <dc:creator>Thompson, Victor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Cross-lingual plagiarism (CLP) occurs when texts written in one language are
translated into a different language and used without acknowledging the
original sources. One of the most common methods for detecting CLP requires
online machine translators (such as Google or Microsoft translate) which are
not always available, and given that plagiarism detection typically involves
large document comparison, the amount of translations required would overwhelm
an online machine translator, especially when detecting plagiarism over the
web. In addition, when translated texts are replaced with their synonyms, using
online machine translators to detect CLP would result in poor performance. This
paper addresses the problem of cross-lingual plagiarism detection (CLPD) by
proposing a model that uses simulated word embeddings to reproduce the
predictions of an online machine translator (Google translate) when detecting
CLP. The simulated embeddings comprise of translated words in different
languages mapped in a common space, and replicated to increase the prediction
probability of retrieving the translations of a word (and their synonyms) from
the model. Unlike most existing models, the proposed model does not require
parallel corpora, and accommodates multiple languages (multi-lingual). We
demonstrated the effectiveness of the proposed model in detecting CLP in
standard datasets that contain CLP cases, and evaluated its performance against
a state-of-the-art baseline that relies on online machine translator (T+MA
model). Evaluation results revealed that the proposed model is not only
effective in detecting CLP, it outperformed the baseline. The results indicate
that CLP could be detected with state-of-the-art performances by leveraging the
prediction accuracy of an internet translator with word embeddings, without
relying on internet translators.
</dc:description>
 <dc:description>Comment: This is a mildly edited version that is currently undergoing review</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10191</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coupling of Magneto-Thermal and Mechanical Superconducting Magnet Models
  by Means of Mesh-Based Interpolation</dc:title>
 <dc:creator>Maciejewski, Micha&#x142;</dc:creator>
 <dc:creator>Bayrasy, Pascal</dc:creator>
 <dc:creator>Wolf, Klaus</dc:creator>
 <dc:creator>Wilczek, Micha&#x142;</dc:creator>
 <dc:creator>Auchmann, Bernhard</dc:creator>
 <dc:creator>Griesemer, Tina</dc:creator>
 <dc:creator>Bortot, Lorenzo</dc:creator>
 <dc:creator>Prioli, Marco</dc:creator>
 <dc:creator>Navarro, Alejandro Manuel Fernandez</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:creator>Garcia, Idoia Cortes</dc:creator>
 <dc:creator>Verweij, Arjan</dc:creator>
 <dc:subject>Physics - Accelerator Physics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>78M10, 94C99, 74F15</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>I.6.3</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  In this paper we present an algorithm for the coupling of magneto-thermal and
mechanical finite element models representing superconducting accelerator
magnets. The mechanical models are used during the design of the mechanical
structure as well as the optimization of the magnetic field quality under
nominal conditions. The magneto-thermal models allow for the analysis of
transient phenomena occurring during quench initiation, propagation, and
protection. Mechanical analysis of quenching magnets is of high importance
considering the design of new protection systems and the study of new
superconductor types. We use field/circuit coupling to determine temperature
and electromagnetic force evolution during the magnet discharge. These
quantities are provided as a load to existing mechanical models. The models are
discretized with different meshes and, therefore, we employ a mesh-based
interpolation method to exchange coupled quantities. The coupling algorithm is
illustrated with a simulation of a mechanical response of a standalone
high-field dipole magnet protected with CLIQ (Coupling-Loss Induced Quench)
technology.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10191</dc:identifier>
 <dc:identifier>IEEE Transactions on Applied Superconductivity 28.3 (Apr. 2018).
  issn: 1051-8223</dc:identifier>
 <dc:identifier>doi:10.1109/TASC.2017.2786721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10193</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multi-candidate electronic voting scheme with unlimited participants</dc:title>
 <dc:creator>Zhao, Xi</dc:creator>
 <dc:creator>Ding, Yong</dc:creator>
 <dc:creator>Zhao, Quanyu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper a new multi-candidate electronic voting scheme is constructed
with unlimited participants. The main idea is to express a ballot to allow
voting for up to k out of the m candidates and unlimited participants. The
purpose of vote is to select more than one winner among $m$ candidates. Our
result is complementary to the result by Sun peiyong$'$ s scheme, in the sense,
their scheme is not amenable for large-scale electronic voting due to flaw of
ballot structure. In our scheme the vote is split and hidden, and tallying is
made for $G\ddot{o}del$ encoding in decimal base without any trusted third
party, and the result does not rely on any traditional cryptography or
computational intractable assumption. Thus the proposed scheme not only solves
the problem of ballot structure, but also achieves the security including
perfect ballot secrecy, receipt-free, robustness, fairness and
dispute-freeness.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10194</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Lower Bound for a Tripartite Version of the Hidden Shift Problem</dc:title>
 <dc:creator>Belovs, Aleksandrs</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper, we prove a polynomial lower bound of $\Omega(n^{1/3})$ on the
quantum query complexity of the following rather natural generalisation of both
the hidden shift and the 3-sum problem. Given an array of $3\times n$ elements,
is it possible to circularly shift its rows so that the sum of the elements in
each column becomes zero? It is promised that if this is not the case, then no
3 elements in the table sum up to zero.
  The lower bound is proven by a novel application of the dual learning graph
framework. Additionally, we state a property testing version of the problem,
for which we prove a similar lower bound.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10195</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Network Growth under Resource Constraints</dc:title>
 <dc:creator>Shah, Harshay</dc:creator>
 <dc:creator>Kumar, Suhansanu</dc:creator>
 <dc:creator>Sundaram, Hari</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We propose a resource-constrained network growth model that explains the
emergence of key structural properties of real-world directed networks:
heavy-tailed indegree distribution, high local clustering and degree-clustering
relationship. In real-world networks, individuals form edges under constraints
of limited network access and partial information. However, well-known growth
models that preserve multiple structural properties do not incorporate these
resource constraints. Conversely, existing resource-constrained models do not
jointly preserve multiple structural properties of real-world networks. We
propose a random walk growth model that explains how real-world network
properties can jointly arise from edge formation under resource constraints. In
our model, each node that joins the network selects a seed node from which it
initiates a random walk. At each step of the walk, the new node either jumps
back to the seed node or chooses an outgoing or incoming edge to visit another
node. It links to each visited node with some probability and stops after
forming a few edges. Our experimental results against four well-known growth
models indicate improvement in accurately preserving structural properties of
five citation networks. Our model also preserves two structural properties that
most growth models cannot: skewed local clustering distribution and bivariate
indegree-clustering relationship.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10197</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interesting Paths in the Mapper</dc:title>
 <dc:creator>Kalyanaraman, Ananth</dc:creator>
 <dc:creator>Kamruzzaman, Methun</dc:creator>
 <dc:creator>Krishnamoorthy, Bala</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>05C85, 68Q25, 62H30, 55U99</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  The Mapper produces a compact summary of high dimensional data as a
simplicial complex. We study the problem of quantifying the interestingness of
subpopulations in a Mapper, which appear as long paths, flares, or loops.
First, we create a weighted directed graph G using the 1-skeleton of the
Mapper. We use the average values at the vertices of a target function to
direct edges (from low to high). The difference between the average values at
vertices (high-low) is set as its weight. Covariation of the remaining h
functions (independent variables) is captured by a h-bit binary signature
assigned to the edge. An interesting path in G is a directed path whose edges
all have the same signature. We define the interestingness score of such a path
as a sum of its edge weights multiplied by a nonlinear function of their ranks
in the path.
  Second, we study three optimization problems on this graph G. In the problem
Max-IP, we seek an interesting path in G with the maximum interestingness
score. We show that Max-IP is NP-complete. For the special case when G is a
directed acyclic graph (DAG), we show that Max-IP can be solved in polynomial
time - in O(mnd_i) where d_i is the maximum indegree of a vertex in G.
  In the more general problem IP, the goal is to find a collection of
interesting paths such that these paths form an exact cover of E (hence they
are edge-disjoint) and the overall sum of interestingness scores of all paths
is maximized. We also study a variant of IP termed k-IP, where the goal is to
identify a collection of edge-disjoint interesting paths each with k edges, and
the total interestingness score of all paths is maximized. While k-IP can be
solved in polynomial time for k &lt;= 2, we show k-IP is NP-complete for k &gt;= 3.
Further, we show that k-IP remains NP-complete for k &gt;= 3 even for the case
when G is a DAG. We develop polynomial time heuristics for IP and k-IP on DAGs.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10201</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metascheduling of HPC Jobs in Day-Ahead Electricity Markets</dc:title>
 <dc:creator>Murali, Prakash</dc:creator>
 <dc:creator>Vadhiyar, Sathish</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  High performance grid computing is a key enabler of large scale collaborative
computational science. With the promise of exascale computing, high performance
grid systems are expected to incur electricity bills that grow super-linearly
over time. In order to achieve cost effectiveness in these systems, it is
essential for the scheduling algorithms to exploit electricity price
variations, both in space and time, that are prevalent in the dynamic
electricity price markets. In this paper, we present a metascheduling algorithm
to optimize the placement of jobs in a compute grid which consumes electricity
from the day-ahead wholesale market. We formulate the scheduling problem as a
Minimum Cost Maximum Flow problem and leverage queue waiting time and
electricity price predictions to accurately estimate the cost of job execution
at a system. Using trace based simulation with real and synthetic workload
traces, and real electricity price data sets, we demonstrate our approach on
two currently operational grids, XSEDE and NorduGrid. Our experimental setup
collectively constitute more than 433K processors spread across 58 compute
systems in 17 geographically distributed locations. Experiments show that our
approach simultaneously optimizes the total electricity cost and the average
response time of the grid, without being unfair to users of the local batch
systems.
</dc:description>
 <dc:description>Comment: Appears in IEEE Transactions on Parallel and Distributed Systems</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10201</dc:identifier>
 <dc:identifier>doi:10.1109/TPDS.2017.2769082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10207</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dense Fully Convolutional Network for Skin Lesion Segmentation</dc:title>
 <dc:creator>Nasr-Esfahani, Ebrahim</dc:creator>
 <dc:creator>Rafiei, Shima</dc:creator>
 <dc:creator>Jafari, Mohammad H.</dc:creator>
 <dc:creator>Karimi, Nader</dc:creator>
 <dc:creator>Wrobel, James S.</dc:creator>
 <dc:creator>Soroushmehr, S. M. Reza</dc:creator>
 <dc:creator>Samavi, Shadrokh</dc:creator>
 <dc:creator>Najarian, Kayvan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Skin cancer is a deadly disease and is on the rise in the world. Computerized
diagnosis of skin cancer can accelerate the detection of this type of cancer
that is a key point in increasing the survival rate of patients. Lesion
segmentation in skin images is an important step in computerized detection of
the skin cancer. Existing methods for this aim usually lack accuracy especially
in fuzzy borders of lesions. In this paper, we propose a new class of fully
convolutional networks with novel dense pooling layers for segmentation of
lesion regions in non-dermoscopic images. Unlike other existing convolutional
networks, the proposed dense pooling layers are designed to preserve all of the
input features. This has led to highly accurate segmentation of lesions. Our
proposed method produces dice score of 91.6% which outperforms all
state-of-the-art algorithms in segmentation of skin lesions based on the
Dermquest dataset.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10210</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Load-Balancing Vertical Control for Large-Scale Software-Defined
  Internet of Things</dc:title>
 <dc:creator>Zhang, Lianming</dc:creator>
 <dc:creator>Zhong, Xiaoxun</dc:creator>
 <dc:creator>Wei, Yehua</dc:creator>
 <dc:creator>Yang, Kun</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  As the global Internet of things increasingly is popular with consumers and
business environment, network flow management has become an important topic to
optimize the performance on Internet of Things. The rigid existing Internet of
things (IoT) architecture blocks current traffic management technology to
provide a real differentiated service for large-scale IoT. Software-defined
Internet of Things (SD-IoT) is a new computing paradigm that separates control
plane and data plane, and enables centralized logic control. In this paper, we
first present a general framework for SD-IoT, which consists of two main
components: SD-IoT controllers and SD-IoT switches. The controllers of SD-IoT
uses resource pooling technology, and the pool is responsible for the
centralized control of the entire network. The switches of SD-IoT integrate
with the gateway functions, which is responsible for data access and
forwarding. The SD-IoT controller pool is designed as a vertical control
architecture, which includes the main control layer and the base control layer.
The controller (main controller) of the main control layer interacts upward
with the application layer, interacts with the base control layer downwards,
and the controller (base controller) of the basic control layer interacts with
the data forwarding layer. We propose a dynamic balancing algorithm of the main
controller based on election mechanism and a dynamic load balancing algorithm
of the basic controller based on the balanced delay, respectively. The
experimental results show that the dynamic balancing algorithm based on the
election mechanism can ensure the consistency of the messages between the main
controllers, and the dynamic load balancing algorithm based on the balanced
delay can balance between these different workloads in the basic controllers.
</dc:description>
 <dc:description>Comment: 25 pages, 10 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10211</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Similarity Models with Focus Ranking for Fabric Image
  Retrieval</dc:title>
 <dc:creator>Deng, Daiguo</dc:creator>
 <dc:creator>Wang, Ruomei</dc:creator>
 <dc:creator>Wu, Hefeng</dc:creator>
 <dc:creator>He, Huayong</dc:creator>
 <dc:creator>Li, Qi</dc:creator>
 <dc:creator>Luo, Xiaonan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fabric image retrieval is beneficial to many applications including clothing
searching, online shopping and cloth modeling. Learning pairwise image
similarity is of great importance to an image retrieval task. With the
resurgence of Convolutional Neural Networks (CNNs), recent works have achieved
significant progresses via deep representation learning with metric embedding,
which drives similar examples close to each other in a feature space, and
dissimilar ones apart from each other. In this paper, we propose a novel
embedding method termed focus ranking that can be easily unified into a CNN for
jointly learning image representations and metrics in the context of
fine-grained fabric image retrieval. Focus ranking aims to rank similar
examples higher than all dissimilar ones by penalizing ranking disorders via
the minimization of the overall cost attributed to similar samples being ranked
below dissimilar ones. At the training stage, training samples are organized
into focus ranking units for efficient optimization. We build a large-scale
fabric image retrieval dataset (FIRD) with about 25,000 images of 4,300
fabrics, and test the proposed model on the FIRD dataset. Experimental results
show the superiority of the proposed model over existing metric embedding
models.
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures, accepted by Image and Vision Computing</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10211</dc:identifier>
 <dc:identifier>doi:10.1016/j.imavis.2017.12.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10213</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying Theories of Timed with Generalised Reactive Processes</dc:title>
 <dc:creator>Foster, Simon</dc:creator>
 <dc:creator>Cavalcanti, Ana</dc:creator>
 <dc:creator>Woodcock, Jim</dc:creator>
 <dc:creator>Zeyda, Frank</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Hoare and He's theory of reactive processes provides a unifying foundation
for the formal semantics of concurrent and reactive languages. Though highly
applicable, their theory is limited to models that can express event histories
as discrete sequences. In this paper, we show how their theory can be
generalised by using an abstract trace algebra. We show how the algebra,
notably, allows us to also consider continuous-time traces and thereby
facilitate models of hybrid systems. We then use this algebra to reconstruct
the theory of reactive processes in our generic setting, and prove
characteristic laws for sequential and parallel processes, all of which have
been mechanically verified in the Isabelle/HOL proof assistant.
</dc:description>
 <dc:description>Comment: 7 pages, submitted to Information Processing Letters, May 2017</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10215</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for
  3D Scans</dc:title>
 <dc:creator>Dai, Angela</dc:creator>
 <dc:creator>Ritchie, Daniel</dc:creator>
 <dc:creator>Bokeloh, Martin</dc:creator>
 <dc:creator>Reed, Scott</dc:creator>
 <dc:creator>Sturm, J&#xfc;rgen</dc:creator>
 <dc:creator>Nie&#xdf;ner, Matthias</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce ScanComplete, a novel data-driven approach for taking an
incomplete 3D scan of a scene as input and predicting a complete 3D model along
with per-voxel semantic labels. The key contribution of our method is its
ability to handle large scenes with varying spatial extent, managing the cubic
growth in data size as scene size increases. To this end, we devise a
fully-convolutional generative 3D CNN model whose filter kernels are invariant
to the overall scene size. The model can be trained on scene subvolumes but
deployed on arbitrarily large scenes at test time. In addition, we propose a
coarse-to-fine inference strategy in order to produce high-resolution output
while also leveraging large input context sizes. In an extensive series of
experiments, we carefully evaluate different model design choices, considering
both deterministic and probabilistic models for completion and semantic
inference. Our results show that we outperform other methods not only in the
size of the environments handled and processing efficiency, but also with
regard to completion quality and semantic segmentation performance by a
significant margin.
</dc:description>
 <dc:description>Comment: Video: https://youtu.be/5s5s8iH0NF8</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10218</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Asymptotic Analysis of Zero-Delay Energy-Distortion Tradeoff Under
  Additive White Gaussian Noise</dc:title>
 <dc:creator>Sevin&#xe7;, Ceren</dc:creator>
 <dc:creator>Tuncel, Ertem</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Asymptotic energy-distortion performance of zero-delay communication
scenarios under additive white Gaussian noise is investigated. Using
high-resolution analysis for quantizer design, the higher-order term in the
logarithm of the distortion (termed the {\em energy-distortion dispersion}) is
optimized while keeping the leading term (i.e., {\em energy-distortion
exponent}) at its optimal value. For uniform and Gaussian sources, significant
gains are observed compared to na\&quot;{i}vely performed quantization, i.e., aimed
at optimizing the source coding performance instead of the end-to-end
distortion in joint source-channel coding.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Communications (ICC) 2018</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10219</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum secret sharing for a multipartite system under energy
  dissipation</dc:title>
 <dc:creator>Singh, Siddhant</dc:creator>
 <dc:creator>Srivastava, Shivang</dc:creator>
 <dc:creator>Panigrahi, Prasanta K.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a protocol for multipartite secret sharing of quantum information
through an \textit{amplitude damping} quantum channel. This network is, for
example, of two organizations communicating with their own employees connected
via classical channels locally. We consider a GHZ state distributed among four
members in an asymmetric fashion where the members of a sub-party collaborate
to decode the received information at their end. The target is to send two bits
of information in \textit{one execution} of the protocol. Firstly, we consider
an ideal channel and observe that our protocol enables decoding of a secret
2-bit information with unit probability. This is accomplished by one of the
senders by the use of a globally operated \textit{quantum teleportation
operator}. Secondly, we implement the same protocol in a realistic scenario
under energy dissipation by the use of a parameterized \textit{amplitude
damping channel} with variable noise. This noise is associated with energy
dissipation and hence, loss of probability to distinguish and decode the
information at the receiving end. Finally, we make this task possible through
an optimization algorithm. Various channel \textit{quality measures} are also
quantitatively ascertained.
</dc:description>
 <dc:description>Comment: First two authors have contributed equally to this work (shared first
  authorship)</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10222</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Charge Lightning</dc:title>
 <dc:creator>Br&#xe2;nzei, Simina</dc:creator>
 <dc:creator>Segal-Halevi, Erel</dc:creator>
 <dc:creator>Zohar, Aviv</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Off-chain transaction channels represent one of the leading techniques to
scale the transaction throughput in cryptocurrencies. However, the economic
effect of transaction channels on the system has not been explored much until
now. We study the economics of Bitcoin transaction channels, and present a
framework for an economic analysis of the lightning network and its effect on
transaction fees on the blockchain. Our framework allows us to reason about
different patterns of demand for transactions and different topologies of the
lightning network, and to derive the resulting fees for transacting both on and
off the blockchain.
  Our initial results indicate that while the lightning network does allow for
a substantially higher number of transactions to pass through the system, it
does not necessarily provide higher fees to miners, and as a result may in fact
lead to lower participation in mining within the system.
</dc:description>
 <dc:description>Comment: Presented at Scaling Bitcoin 2017</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10224</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Multi-Domain Dialogue State Tracking</dc:title>
 <dc:creator>Rastogi, Abhinav</dc:creator>
 <dc:creator>Hakkani-Tur, Dilek</dc:creator>
 <dc:creator>Heck, Larry</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Dialogue state tracking (DST) is a key component of task-oriented dialogue
systems. DST estimates the user's goal at each user turn given the interaction
until then. State of the art approaches for state tracking rely on deep
learning methods, and represent dialogue state as a distribution over all
possible slot values for each slot present in the ontology. Such a
representation is not scalable when the set of possible values are unbounded
(e.g., date, time or location) or dynamic (e.g., movies or usernames).
Furthermore, training of such models requires labeled data, where each user
turn is annotated with the dialogue state, which makes building models for new
domains challenging. In this paper, we present a scalable multi-domain deep
learning based approach for DST. We introduce a novel framework for state
tracking which is independent of the slot value set, and represent the dialogue
state as a distribution over a set of values of interest (candidate set)
derived from the dialogue history or knowledge. Restricting these candidate
sets to be bounded in size addresses the problem of slot-scalability.
Furthermore, by leveraging the slot-independent architecture and transfer
learning, we show that our proposed approach facilitates quick adaptation to
new domains.
</dc:description>
 <dc:description>Comment: Published at ASRU-17. New version has updated results in Tables 1, 2
  and 3 corresponding to the datasets released on
  github.com/google-research-datasets/simulated-dialogue</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10230</identifier>
 <datestamp>2018-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On quality of implementation of Fortran 2008 complex intrinsic functions
  on branch cuts</dc:title>
 <dc:creator>Shterenlikht, Anton</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>30-04</dc:subject>
 <dc:description>  Branch cuts in complex functions in combination with signed zero and signed
infinity have important uses in fracture mechanics, jet flow and aerofoil
analysis. We present benchmarks for validating Fortran 2008 complex functions -
LOG, SQRT, ASIN, ACOS, ATAN, ASINH, ACOSH and ATANH - on branch cuts with
arguments of all 3 IEEE floating point binary formats: binary32, binary64 and
binary128. Results are reported with 8 Fortran 2008 compilers: GCC, Flang,
Cray, Oracle, PGI, Intel, NAG and IBM. Multiple test failures were revealed,
e.g. wrong signs of results or unexpected overflow, underflow, or NaN. We
conclude that the quality of implementation of these Fortran 2008 intrinsics in
many compilers is not yet sufficient to remove the need for special code for
branch cuts. The test results are complemented by conformal maps of the branch
cuts and detailed derivations of the values of these functions on branch cuts,
to be used as a reference. The benchmarks are freely available from
cmplx.sf.net. This work will be of interest to engineers who use complex
functions, as well as to compiler and maths library developers.
</dc:description>
 <dc:description>Comment: 28 pages, 10 figures, 13 tables, original work</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10232</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependence Structure Analysis Of Meta-level Metrics in YouTube Videos: A
  Vine Copula Approach</dc:title>
 <dc:creator>Krishnamurthy, Vikram</dc:creator>
 <dc:creator>Duan, Yan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper uses vine copula to analyze the multivariate statistical
dependence in a massive YouTube dataset consisting of 6 million videos over 25
thousand channels. Specifically we study the statistical dependency of 7
YouTube meta-level metrics: view count, number of likes, number of comments,
length of video title, number of subscribers, click rates, and average
percentage watching. Dependency parameters such as the Kendall's tau and tail
dependence coefficients are computed to evaluate the pair-wise dependence of
these meta-level metrics. The vine copula model yields several interesting
dependency structures. We show that view count and number of likes' are in the
central position of the dependence structure. Conditioned on these two metrics,
the other five meta-level metrics are virtually independent of each other.
Also, Sports, Gaming, Fashion, Comedy videos have similar dependence structure
to each other, while the News category exhibits a strong tail dependence. We
also study Granger causality effects and upload dynamics and their impact on
view count. Our findings provide a useful understanding of user engagement in
YouTube.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10233</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying Theories of Reactive Design Contracts</dc:title>
 <dc:creator>Foster, Simon</dc:creator>
 <dc:creator>Cavalcanti, Ana</dc:creator>
 <dc:creator>Canham, Samuel</dc:creator>
 <dc:creator>Woodcock, Jim</dc:creator>
 <dc:creator>Zeyda, Frank</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Design-by-contract is an important technique for model-based design in which
a composite system is specified by a collection of contracts that specify the
behavioural assumptions and guarantees of each component. In this paper, we
describe a unifying theory for reactive design contracts that provides the
basis for modelling and verification of reactive systems. We provide a language
for expression and composition of contracts that is supported by a rich
calculational theory. In contrast with other semantic models in the literature,
our theory of contracts allow us to specify both the evolution of state
variables and the permissible interactions with the environment. Moreover, our
model of interaction is abstract, and supports, for instance, discrete time,
continuous time, and hybrid computational models. Being based in Unifying
Theories of Programming (UTP), our theory can be composed with further
computational theories to support semantics for multi-paradigm languages.
Practical reasoning support is provided via our proof framework, Isabelle/UTP,
including a proof tactic that reduces a conjecture about a reactive program to
three predicates, characterising its assumptions and guarantees about
intermediate and final observations. Our work advances the state-of-the-art in
semantics for reactive languages, description of their contractual
specifications, and compositional verification.
</dc:description>
 <dc:description>Comment: 53 pages, submitted to Journal of Theoretical Computer Science
  December 2017</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10243</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Threat Modeling Data Analysis in Socio-technical Systems</dc:title>
 <dc:creator>Ostwald, Tomasz</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Our decision-making processes are becoming more data driven, based on data
from multiple sources, of different types, processed by a variety of
technologies. As technology becomes more relevant for decision processes, the
more likely they are to be subjects of attacks aimed at disrupting their
execution or changing their outcome. With the increasing complexity and
dependencies on technical components, such attempts grow more sophisticated and
their impact will be more severe. This is especially important in scenarios
with shared goals, which had to be previously agreed to, or decisions with
broad social impact. We need to think about our decisions-making and underlying
data analysis processes in a systemic way to correctly evaluate benefits and
risks of specific solutions and to design them to be resistant to attacks. To
reach these goals, we can apply experiences from threat modeling analysis used
in software security. We will need to adapt these practices to new types of
threats, protecting different assets and operating in socio-technical systems.
With these changes, threat modeling can become a foundation for implementing
detailed technical, organizational or legal mitigations and making our
decisions more reliable and trustworthy.
</dc:description>
 <dc:description>Comment: Presented at the Data For Good Exchange 2017</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10248</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Interior Tomography for Region-of-Interest Reconstruction</dc:title>
 <dc:creator>Han, Yoseob</dc:creator>
 <dc:creator>Gu, Jawook</dc:creator>
 <dc:creator>Ye, Jong Chul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Interior tomography for the region-of-interest (ROI) imaging has advantages
of using a small detector and reducing X-ray radiation dose. However, standard
analytic reconstruction suffers from severe cupping artifacts due to existence
of null space in the truncated Radon transform. Existing penalized
reconstruction methods may address this problem but they require extensive
computations due to the iterative reconstruction. Inspired by the recent deep
learning approaches to low-dose and sparse view CT, here we propose a deep
learning architecture that removes null space signals from the FBP
reconstruction. Experimental results have shown that the proposed method
provides near-perfect reconstruction with about 7-10 dB improvement in PSNR
over existing methods in spite of significantly reduced run-time complexity.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10252</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral analysis for non-stationary audio</dc:title>
 <dc:creator>Meynard, Adrien</dc:creator>
 <dc:creator>Torresani, Bruno</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  A new approach for the analysis of non-stationary signals is proposed, with a
focus on audio applications. Following earlier contributions, non-stationarity
is modeled via stationarity-breaking operators acting on Gaussian stationary
random signals. The focus is here on time warping and amplitude modulation, and
an approximate maximum-likelihood approach based on suitable approximations in
the wavelet transform domain is developed. This papers provides theoretical
analysis of the approximations, and describes and analyses a
correspondingestimation algorithm. The latter is tested and validated on
synthetic as well as real audio signal.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10259</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Class of Automatic Sequences</dc:title>
 <dc:creator>Underwood, Robert G.</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68Q45, 68Q70</dc:subject>
 <dc:description>  We show that the characteristic sequence of a regular language over the
alphabet $\{a,b\}$ is $2$-automatic.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10261</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Lower Bounds for Sketching Graph Cuts</dc:title>
 <dc:creator>Carlson, Charles</dc:creator>
 <dc:creator>Kolla, Alexandra</dc:creator>
 <dc:creator>Srivastava, Nikhil</dc:creator>
 <dc:creator>Trevisan, Luca</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We study the space complexity of sketching cuts and Laplacian quadratic forms
of graphs. We show that any data structure which approximately stores the sizes
of all cuts in an undirected graph on $n$ vertices up to a $1+\epsilon$ error
must use $\Omega(n\log n/\epsilon^2)$ bits of space in the worst case,
improving the $\Omega(n/\epsilon^2)$ bound of Andoni et al. and matching the
best known upper bound achieved by spectral sparsifiers. Our proof is based on
a rigidity phenomenon for cut (and spectral) approximation which may be of
independent interest: any two $d-$regular graphs which approximate each other's
cuts significantly better than a random graph approximates the complete graph
must overlap in a constant fraction of their edges.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10266</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Exploration Primitives for Data Cleaning</dc:title>
 <dc:creator>Ge, Chang</dc:creator>
 <dc:creator>Ilyas, Ihab F.</dc:creator>
 <dc:creator>He, Xi</dc:creator>
 <dc:creator>Machanavajjhala, Ashwin</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Data cleaning, or the process of detecting and repairing inaccurate or
corrupt records in the data, is inherently human-driven. State of the art
systems assume cleaning experts can access the data (or a sample of it) to tune
the cleaning process. However, in many cases, privacy constraints disallow
unfettered access to the data. To address this challenge, we observe and
provide empirical evidence that data cleaning can be achieved without access to
the sensitive data, but with access to a (noisy) query interface that supports
a small set of linear counting query primitives. Motivated by this, we present
DPClean, a first of a kind system that allows engineers tune data cleaning
workflows while ensuring differential privacy. In DPClean, a cleaning engineer
can pose sequences of aggregate counting queries with error tolerances. A
privacy engine translates each query into a differentially private mechanism
that returns an answer with error matching the specified tolerance, and allows
the data owner track the overall privacy loss. With extensive experiments using
human and simulated cleaning engineers on blocking and matching tasks, we
demonstrate that our approach is able to achieve high cleaning quality while
ensuring a reasonable privacy loss.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10273</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Online Algorithm for Weighted Flow Time</dc:title>
 <dc:creator>Azar, Yossi</dc:creator>
 <dc:creator>Touitou, Noam</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We discuss one of the most fundamental scheduling problem of processing jobs
on a single machine to minimize the weighted flow time (weighted response
time). Our main result is a $O(\log P)$-competitive algorithm, where $P$ is the
maximum-to-minimum processing time ratio, improving upon the
$O(\log^{2}P)$-competitive algorithm of Chekuri, Khanna and Zhu (STOC 2001). We
also design a $O(\log D)$-competitive algorithm, where $D$ is the
maximum-to-minimum density ratio of jobs. Finally, we show how to combine these
results with the result of Bansal and Dhamdhere (SODA 2003) to achieve a
$O(\log(\min(P,D,W)))$-competitive algorithm (where $W$ is the
maximum-to-minimum weight ratio), without knowing $P,D,W$ in advance. As shown
by Bansal and Chan (SODA 2009), no constant-competitive algorithm is achievable
for this problem.
</dc:description>
 <dc:description>Comment: 22 pages, 2 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10279</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vector and Matrix Optimal Mass Transport: Theory, Algorithm, and
  Applications</dc:title>
 <dc:creator>Ryu, Ernest K.</dc:creator>
 <dc:creator>Chen, Yongxin</dc:creator>
 <dc:creator>Li, Wuchen</dc:creator>
 <dc:creator>Osher, Stanley</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>65K10, 65K05, 90C25</dc:subject>
 <dc:description>  In many applications such as color image processing, data has more than one
piece of information associated with each spatial coordinate, and in such cases
the classical optimal mass transport (OMT) must be generalized to handle
vector-valued or matrix-valued densities. In this paper, we discuss the vector
and matrix optimal mass transport and present three contributions. We first
present a rigorous mathematical formulation for these setups and provide
analytical results including existence of solutions and strong duality. Next,
we present a simple, scalable, and parallelizable methods to solve the vector
and matrix-OMT problems. Finally, we implement the proposed methods on a CUDA
GPU and present experiments and applications.
</dc:description>
 <dc:description>Comment: 22 pages, 5 figures, 3 tables</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10280</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>First Draft on the xInf Model for Universal Physical Computation and
  Reverse Engineering of Natural Intelligence</dc:title>
 <dc:creator>Jia, Hongbo</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Turing Machines are universal computing machines in theory. It has been a
long debate whether Turing Machines can simulate the consciousness mind
behaviors in the materialistic universe. Three different hypotheses come out of
such debate, in short:(A) Can; (B) Cannot; (C) Super-Turing machines can.
Because Turing Machines or other kinds of theoretical computing models are
abstract objects while behaviors are real observables, this debate involves at
least three distinct fields of science and technology: physics, computer
engineering, and experimental neuroscience. However, the languages used in
these different fields are highly heterogeneous and not easily interpretable
for each other, making it very difficult to reach partial agreements regarding
this debate, Therefore, the main goal of this manuscript is to establish a
proper language that can translate among those different fields. First, I
propose a theoretical model for analyzing how theoretical computing machines
would physically run in physical time. This model, termed as the xInf, is at
first place Turing-complete in theory, and depending on the properties of
physical time, it can be either Turing-equivalent or Super-Turing in the
physical universe. The xInf Model is demonstrated to be a suitable universal
language to translate among physics, computer engineering, and neuroscience.
Finally, I propose a conjecture that there exists a Minimal Complete Set of
rules in the xInf Model that enables the construction of a physical machine
using inorganic materials that can pass the Turing Test in physical time. I
cannot demonstrate whether such a conjecture to be testified or falsified on
paper using finite-order logic, my only solution is physical time itself, i.e.
an evolutionary competition will eventually tell the conclusion.
</dc:description>
 <dc:description>Comment: 32 pages, 4 figures</dc:description>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10281</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General-Purpose Visual Language and Information System with Case-Studies
  in Developing Business Applications</dc:title>
 <dc:creator>Fayed, Mahmoud Samir</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Learning computer programming has been always challenging. Since the sixties
of the last century, many researchers developed Visual Programming Languages
(VPLs) to help in this regard. In this thesis, ten VPLs were specifically
selected, studied, experimented with, and evaluated. A total of fifteen metrics
were used to evaluate the tools. Comparisons, classification, and gap analysis
were then presented. A list of requirements for a general-purpose VPL and a
guide to help the novice programmer choose the right tool were generated and
finally the PWCT (Programming Without Coding Technology, a novel
general-purpose visual programming language) is developed and presented. PWCT
has been launched as a Sourceforge project, which currently has more than
230,000 downloads for the language and more than 19,500,000 downloads for
samples, tutorials and movies. Many business applications and projects are
developed using PWCT, Also we developed the Supernova programming language and
the Ring programming language using PWCT to prove that it can be used for
advanced and large projects. Feedback from developers and results from the
studies indicate that PWCT is a very appealing, competitive, and powerful
language.
</dc:description>
 <dc:description>Comment: Master of Science Thesis</dc:description>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10282</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting the Actor with Dual Critic</dc:title>
 <dc:creator>Dai, Bo</dc:creator>
 <dc:creator>Shaw, Albert</dc:creator>
 <dc:creator>He, Niao</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a new actor-critic-style algorithm called Dual
Actor-Critic or Dual-AC. It is derived in a principled way from the Lagrangian
dual form of the Bellman optimality equation, which can be viewed as a
two-player game between the actor and a critic-like function, which is named as
dual critic. Compared to its actor-critic relatives, Dual-AC has the desired
property that the actor and dual critic are updated cooperatively to optimize
the same objective function, providing a more transparent way for learning the
critic that is directly related to the objective function of the actor. We then
provide a concrete algorithm that can effectively solve the minimax
optimization problem, using techniques of multi-step bootstrapping, path
regularization, and stochastic dual ascent algorithm. We demonstrate that the
proposed algorithm achieves the state-of-the-art performances across several
benchmarks.
</dc:description>
 <dc:description>Comment: 21 pages, 9 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10284</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Experiment on the Importance of Social Learning and
  Unimodality in the Wisdom of the Crowd</dc:title>
 <dc:creator>Adjodah, Dhaval</dc:creator>
 <dc:creator>Chong, Shi Kai</dc:creator>
 <dc:creator>Leng, Yan</dc:creator>
 <dc:creator>Krafft, Peter</dc:creator>
 <dc:creator>Pentland, Alex</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  In this study, we build on previous research to understand the conditions
within which the Wisdom of the Crowd (WoC) improves or worsens as a result of
showing individuals the predictions of their peers. Our main novel
contributions are: 1) a dataset of unprecedented size and detail; 2) we observe
the novel effect of the importance of the unimodality of the social information
shown to individuals: if one does not see only one clear peak in the
distribution of the crowd's predictions, the WoC is worsened after social
exposure; and 3) we estimate social learning weights that we use to show that
there exists individuals who are much better at learning from the crowd and can
be filtered to improve collective accuracy.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10285</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smoothed Dual Embedding Control</dc:title>
 <dc:creator>Dai, Bo</dc:creator>
 <dc:creator>Shaw, Albert</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Xiao, Lin</dc:creator>
 <dc:creator>He, Niao</dc:creator>
 <dc:creator>Chen, Jianshu</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We revisit the Bellman optimality equation with Nesterov's smoothing
technique and provide a unique saddle-point optimization perspective of the
policy optimization problem in reinforcement learning based on Fenchel duality.
A new reinforcement learning algorithm, called Smoothed Dual Embedding Control
or SDEC, is derived to solve the saddle-point reformulation with arbitrary
learnable function approximator. The algorithm bypasses the policy evaluation
step in the policy optimization from a principled scheme and is extensible to
integrate with multi-step bootstrapping and eligibility traces. We provide a
PAC-learning bound on the number of samples needed from one single off-policy
sample path, and also characterize the convergence of the algorithm. Finally,
we show the algorithm compares favorably to the state-of-the-art baselines on
several benchmark control problems.
</dc:description>
 <dc:description>Comment: 25 pages, 4 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10288</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Bayesian Inference Framework for Generalized Linear Models</dc:title>
 <dc:creator>Meng, Xiangming</dc:creator>
 <dc:creator>Wu, Sheng</dc:creator>
 <dc:creator>Zhu, Jiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this letter, we present a unified Bayesian inference framework for
generalized linear models (GLM) which iteratively reduces the GLM problem to a
sequence of standard linear model (SLM) problems. This framework provides new
perspectives on some established GLM algorithms derived from SLM ones and also
suggests novel extensions for some other SLM algorithms. Specific instances
elucidated under such framework are the GLM versions of approximate message
passing (AMP), vector AMP (VAMP), and sparse Bayesian learning (SBL). It is
proved that the resultant GLM version of AMP is equivalent to the well-known
generalized approximate message passing (GAMP). Numerical results for 1-bit
quantized compressed sensing (CS) demonstrate the effectiveness of this unified
framework.
</dc:description>
 <dc:description>Comment: 6 pages,4 figures. To appear in IEEE Signal Processing Letters. This
  version contains an appendix</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10291</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communications and Control for Wireless Drone-Based Antenna Array</dc:title>
 <dc:creator>Mozaffari, Mohammad</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Debbah, Merouane</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the effective use of multiple quadrotor drones as an aerial
antenna array that provides wireless service to ground users is investigated.
In particular, under the goal of minimizing the airborne service time needed
for communicating with ground users, a novel framework for deploying and
operating a drone-based antenna array system whose elements are single-antenna
drones is proposed. In the considered model, the service time is minimized by
jointly optimizing the wireless transmission time as well as the control time
that is needed for movement and stabilization of the drones. To minimize the
transmission time, first, the antenna array gain is maximized by optimizing the
drone spacing within the array. In this case, using perturbation techniques,
the drone spacing optimization problem is addressed by solving successive,
perturbed convex optimization problems. Then, the optimal locations of the
drones around the array's center are derived such that the transmission time
for the user is minimized. Given the determined optimal locations of drones,
the drones must spend a control time to adjust their positions dynamically so
as to serve multiple users. To minimize this control time of the quadrotor
drones, the speed of rotors is optimally adjusted based on both the
destinations of the drones and external forces (e.g., wind and gravity). In
particular, using bang-bang control theory, the optimal rotors' speeds as well
as the minimum control time are derived in closed-form. Simulation results show
that the proposed approach can significantly reduce the service time to ground
users compared to a multi-drone scenario in which the same number of drones are
deployed separately to serve ground users. The results also show that, in
comparison with the multi-drones case, the network's spectral efficiency can be
significantly improved.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10293</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compute--Forward Multiple Access (CFMA): Practical Code Design</dc:title>
 <dc:creator>Sula, Erixhen</dc:creator>
 <dc:creator>Zhu, Jingge</dc:creator>
 <dc:creator>Pastore, Adriano</dc:creator>
 <dc:creator>Lim, Sung Hoon</dc:creator>
 <dc:creator>Gastpar, Michael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present a practical strategy that aims to attain rate points on the
dominant face of the multiple access channel capacity using a standard low
complexity decoder. This technique is built upon recent theoretical
developments of Zhu and Gastpar on compute-forward multiple access (CFMA) which
achieves the capacity of the multiple access channel using a sequential
decoder. We illustrate this strategy with off-the-shelf LDPC codes. In the
first stage of decoding, the receiver first recovers a linear combination of
the transmitted codewords using the sum-product algorithm (SPA). In the second
stage, by using the recovered sum-of-codewords as side information, the
receiver recovers one of the two codewords using a modified SPA, ultimately
recovering both codewords. The main benefit of recovering the sum-of-codewords
instead of the codeword itself is that it allows to attain points on the
dominant face of the multiple access channel capacity without the need of
rate-splitting or time sharing while maintaining a low complexity in the order
of a standard point-to-point decoder. This property is also shown to be crucial
for some applications, e.g., interference channels. For all the simulations
with single-layer binary codes, our proposed practical strategy is shown to be
within \SI{1.7}{\decibel} of the theoretical limits, without explicit
optimization on the off-the-self LDPC codes.
</dc:description>
 <dc:description>Comment: 30 pages, 14 figures, submitted to the IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10299</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wiretap and Gelfand-Pinsker Channels Analogy and its Applications</dc:title>
 <dc:creator>Goldfeld, Ziv</dc:creator>
 <dc:creator>Permuter, Haim. H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A framework of analogy between wiretap channels (WTCs) and state-dependent
point-to-point channels with non-causal encoder channel state information
(referred to as Gelfand-Pinker channels (GPCs)) is proposed. A good (reliable
and secure) sequence of wiretap codes is shown to induce a good (reliable)
sequence of codes for a corresponding GPC. Consequently, the framework enables
exploiting existing results for GPCs to produce converse proofs for their
wiretap analogs. The fundamental limits of communication of analogous wiretap
and GP models are characterized by the same rate bounds; the optimization
domains may differ. The analogy readily extends to multiuser broadcasting
scenarios, encompassing broadcast channels (BCs) with deterministic components,
degradation ordering between users, and BCs with cooperative receivers. Given a
wiretap BC (WTBC) with two receivers and one eavesdropper, an analogous
Gelfand-Pinsker BC (GPBC) is constructed by converting the eavesdropper's
observations to a state sequence with an appropriate product distribution, and
non-causally revealing the states to the encoder. The transition matrix of the
(state-dependent) GPBC is the appropriate conditional marginal of the WTBC's
transition law, with the eavesdropper's output playing the role of the channel
state. Past capacity results for the semi-deterministic (SD) GPBC and the
physically-degraded (PD) GPBC with an informed receiver are leveraged to
furnish analogy-based converse proofs for the analogous WTBC setups. This
characterizes the secrecy-capacity regions of the SD-WTBC, which was an open
problem until this work, as well as the PD-WTBC where the stronger receiver
also observes the eavesdropper's channel output. These new derivations
exemplify the strength of the wiretap-GP analogy as a research tool through
which results on one problem directly translate into advances in the study of
the other.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10309</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Methods for Detecting Paraphrase Plagiarism</dc:title>
 <dc:creator>Thompson, Victor</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Paraphrase plagiarism is one of the difficult challenges facing plagiarism
detection systems. Paraphrasing occur when texts are lexically or syntactically
altered to look different, but retain their original meaning. Most plagiarism
detection systems (many of which are commercial based) are designed to detect
word co-occurrences and light modifications, but are unable to detect severe
semantic and structural alterations such as what is seen in many academic
documents. Hence many paraphrase plagiarism cases go undetected. In this paper,
we approached the problem of paraphrase plagiarism by proposing methods for
detecting the most common techniques (phenomena) used in paraphrasing texts
(namely; lexical substitution, insertion/deletion and word and phrase
reordering), and combined the methods into a paraphrase detection model. We
evaluated our proposed methods and model on collections containing paraphrase
texts. Experimental results show significant improvement in performance when
the methods were combined (the proposed model) as opposed to running them
individually. The results also show that the proposed paraphrase detection
model outperformed a standard baseline (based on greedy string tilling), and
previous studies.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10321</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer
  Electromagnetic Calorimeters with Generative Adversarial Networks</dc:title>
 <dc:creator>Paganini, Michela</dc:creator>
 <dc:creator>de Oliveira, Luke</dc:creator>
 <dc:creator>Nachman, Benjamin</dc:creator>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The precise modeling of subatomic particle interactions and propagation
through matter is paramount for the advancement of nuclear and particle physics
searches and precision measurements. The most computationally expensive step in
the simulation pipeline of a typical experiment at the Large Hadron Collider
(LHC) is the detailed modeling of the full complexity of physics processes that
govern the motion and evolution of particle showers inside calorimeters. We
introduce \textsc{CaloGAN}, a new fast simulation technique based on generative
adversarial networks (GANs). We apply these neural networks to the modeling of
electromagnetic showers in a longitudinally segmented calorimeter, and achieve
speedup factors comparable to or better than existing full simulation
techniques on CPU ($100\times$-$1000\times$) and even faster on GPU (up to
$\sim10^5\times$). There are still challenges for achieving precision across
the entire phase space, but our solution can reproduce a variety of geometric
shower shape properties of photons, positrons and charged pions. This
represents a significant stepping stone toward a full neural network-based
detector simulation that could save significant computing time and enable many
analyses now and in the future.
</dc:description>
 <dc:description>Comment: 14 pages, 4 tables, 13 figures; version accepted by Physical Review D
  (PRD)</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.10321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00004</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Model for Data Citation in Astronomical Research using Digital Object
  Identifiers (DOIs)</dc:title>
 <dc:creator>Novacescu, Jenny</dc:creator>
 <dc:creator>Peek, Joshua E. G.</dc:creator>
 <dc:creator>Weissman, Sarah</dc:creator>
 <dc:creator>Fleming, Scott W.</dc:creator>
 <dc:creator>Levay, Karen</dc:creator>
 <dc:creator>Fraser, Elizabeth</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:description>  Standardizing and incentivizing the use of digital object identifiers (DOIs)
to aggregate and identify both data analyzed and data generated by a research
project will advance the field of astronomy to match best practices in other
research fields like geosciences and medicine. Increase in the use of DOIs will
prepare the discipline for changing expectations among funding agencies and
publishers, who increasingly expect accurate and thorough data citation to
accompany scientific outputs. The use of DOIs ensures a robust, sustainable,
and interoperable approach to data citation in which due credit is given to
researchers and institutions who produce and maintain the primary data. We
describe in this work the advantages of DOIs for data citation and best
practices for integrating a DOI service in an astronomical archive. We report
on a pilot project carried out in collaboration with AAS Journals. During the
course of the 1.5 year pilot, over 75% of submitting authors opted to use the
integrated DOI service to clearly identify data analyzed during their research
project when prompted at the time of paper submission.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures. Accepted on Dec 19, 2017 for publication in
  Astrophysical Journal Supplement Series</dc:description>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00005</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytical Inverter Delay Modeling Using Matlab's Curve Fitting Toolbox</dc:title>
 <dc:creator>Schneider, Walter</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  This paper presents a new analytical propagation delay model for deep
submicron CMOS inverters. The model is inspired by the key observation that the
inverter delay is a complicated function of several process parameters as well
as load capacitance. These relationships are considered by fitting functions
for each parameter derived from the Curve Fitting Toolbox in Matlab. Compared
to SPICE simulations based on the BSIM4 transistor model, the analytical delay
model shows very good accuracy with an average error less than 2% over a wide
range of process parameters and output loads. Hence, the proposed model can be
efficiently used for different technology nodes as well as statistical gate
delay characterisation.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00016</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Principles of Neuromorphic Photonics</dc:title>
 <dc:creator>Shastri, Bhavin J.</dc:creator>
 <dc:creator>Tait, Alexander N.</dc:creator>
 <dc:creator>de Lima, Thomas Ferreira</dc:creator>
 <dc:creator>Nahmias, Mitchell A.</dc:creator>
 <dc:creator>Peng, Hsuan-Tung</dc:creator>
 <dc:creator>Prucnal, Paul R.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  In an age overrun with information, the ability to process reams of data has
become crucial. The demand for data will continue to grow as smart gadgets
multiply and become increasingly integrated into our daily lives.
Next-generation industries in artificial intelligence services and
high-performance computing are so far supported by microelectronic platforms.
These data-intensive enterprises rely on continual improvements in hardware.
Their prospects are running up against a stark reality: conventional
one-size-fits-all solutions offered by digital electronics can no longer
satisfy this need, as Moore's law (exponential hardware scaling),
interconnection density, and the von Neumann architecture reach their limits.
  With its superior speed and reconfigurability, analog photonics can provide
some relief to these problems; however, complex applications of analog
photonics have remained largely unexplored due to the absence of a robust
photonic integration industry. Recently, the landscape for
commercially-manufacturable photonic chips has been changing rapidly and now
promises to achieve economies of scale previously enjoyed solely by
microelectronics.
  The scientific community has set out to build bridges between the domains of
photonic device physics and neural networks, giving rise to the field of
\emph{neuromorphic photonics}. This article reviews the recent progress in
integrated neuromorphic photonics. We provide an overview of neuromorphic
computing, discuss the associated technology (microelectronic and photonic)
platforms and compare their metric performance. We discuss photonic neural
network approaches and challenges for integrated neuromorphic photonic
processors while providing an in-depth description of photonic neurons and a
candidate interconnection architecture. We conclude with a future outlook of
neuro-inspired photonic processing.
</dc:description>
 <dc:description>Comment: 28 pages, 19 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00025</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Belief Network Based Machine Learning System for Risky Host
  Detection</dc:title>
 <dc:creator>Feng, Wangyan</dc:creator>
 <dc:creator>Wu, Shuning</dc:creator>
 <dc:creator>Li, Xiaodan</dc:creator>
 <dc:creator>Kunkle, Kevin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  To assure cyber security of an enterprise, typically SIEM (Security
Information and Event Management) system is in place to normalize security
event from different preventive technologies and flag alerts. Analysts in the
security operation center (SOC) investigate the alerts to decide if it is truly
malicious or not. However, generally the number of alerts is overwhelming with
majority of them being false positive and exceeding the SOC's capacity to
handle all alerts. There is a great need to reduce the false positive rate as
much as possible. While most previous research focused on network intrusion
detection, we focus on risk detection and propose an intelligent Deep Belief
Network machine learning system. The system leverages alert information,
various security logs and analysts' investigation results in a real enterprise
environment to flag hosts that have high likelihood of being compromised. Text
mining and graph based method are used to generate targets and create features
for machine learning. In the experiment, Deep Belief Network is compared with
other machine learning algorithms, including multi-layer neural network, random
forest, support vector machine and logistic regression. Results on real
enterprise data indicate that the deep belief network machine learning system
performs better than other algorithms for our problem and is six times more
effective than current rule-based system. We also implement the whole system
from data collection, label creation, feature engineering to host score
generation in a real enterprise production environment.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures. The paper is accepted by IEEE Conference on
  Communications and Network Security 2017. However, it is not published
  because either of the authors showed up in the conference</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00035</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LaMMos - Latching Mechanism based on Motorized-screw for Reconfigurable
  Robots and Exoskeleton Suits</dc:title>
 <dc:creator>Mateos, Luis A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Reconfigurable robots refer to a category of robots that their components
(individual joints and links) can be assembled in multiple configurations and
geometries. Most of existing latching mechanisms are based on physical tools
such as hooks, cages or magnets, which limit the payload capacity. Therefore,
robots re- quire a latching mechanism which can help to reconfigure itself
without sacrificing the payload capability. This paper presents a latching
mechanism based on the flexible screw attaching principle. In which, actuators
are used to move the robot links and joints while connecting them with a
motorized-screw and dis- connecting them by unfastening the screw. The brackets
used in our mechanism configuration helps to hold maximum force up to 5000N.
The LaMMos - Latching Mechanism based on Motorized- screw has been applied to
the DeWaLoP - Developing Water Loss Prevention in-pipe robot. It helps the
robot to shrink its body to crawl into the pipe with minimum diameter, by
recon- figuring the leg positions. And it helps to recover the legs positions
to original status once the robot is inside the pipe. Also, LaMMos add
stiffness to the robot legs by dynamically integrate them to the structure.
Additionally, we present an application of the LaMMos mechanism to exoskeleton
suits, for easing the mo- tors from the joints when carrying heavy weights for
long periods of time. This mechanism offers many interesting opportunities for
robotics research in terms of functionality, pay- load and size.
</dc:description>
 <dc:description>Comment: 14 pages, 15 figures</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00036</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An introduction to Graph Data Management</dc:title>
 <dc:creator>Angles, Renzo</dc:creator>
 <dc:creator>Gutierrez, Claudio</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  A graph database is a database where the data structures for the schema
and/or instances are modeled as a (labeled)(directed) graph or generalizations
of it, and where querying is expressed by graph-oriented operations and type
constructors. In this article we present the basic notions of graph databases,
give an historical overview of its main development, and study the main current
systems that implement them.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00043</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Deployment for Maximal Energy Efficiency in Uplink with
  Multislope Path Loss</dc:title>
 <dc:creator>Pizzo, Andrea</dc:creator>
 <dc:creator>Verenzuela, Daniel</dc:creator>
 <dc:creator>Sanguinetti, Luca</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work aims to design the uplink (UL) of a cellular network for maximal
energy efficiency (EE). Each base station (BS) is randomly deployed within a
given area and is equipped with $M$ antennas to serve $K$ user equipments
(UEs). A multislope (distance-dependent) path loss model is considered and
linear processing is used, under the assumption that channel state information
(CSI) is acquired by using pilot sequences (reused across the network). Within
this setting, a lower bound on the UL spectral efficiency and a realistic
circuit power consumption model are used to evaluate the network EE. Numerical
results are first used to compute the optimal BS density and pilot reuse factor
for a Massive multiple-input-multiple-output (MIMO) network (such that $M\gg
K\gg 1$) with three different detection schemes, namely, maximum ratio
combining (MRC), zero-forcing (ZF) and multicell minimum mean-squared error
(M-MMSE). The numerical analysis shows that the EE is a unimodal function of BS
density and achieves its maximum for a relatively small BS densification,
irrespective of the employed detection scheme. Therefore, we concentrate on ZF
and use stochastic geometry to compute a new lower bound on the spectral
efficiency, which is then used to optimize, for a given BS density, the pilot
reuse factor, number of BS antennas and UEs. Closed-form expressions are
computed from which valuable insights into the interplay between the
optimization variables, hardware characteristics, and propagation environment
can be obtained.
</dc:description>
 <dc:description>Comment: 30 pages, 5 figures, submitted to IEEE Transactions on Green
  Communications and Networking</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00048</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing optimal hierarchical policy inference on graphs via
  non-equilibrium thermodynamics</dc:title>
 <dc:creator>McNamee, Daniel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Hierarchies are of fundamental interest in both stochastic optimal control
and biological control due to their facilitation of a range of desirable
computational traits in a control algorithm and the possibility that they may
form a core principle of sensorimotor and cognitive control systems. However, a
theoretically justified construction of state-space hierarchies over all
spatial resolutions and their evolution through a policy inference process
remains elusive. Here, a formalism for deriving such normative representations
of discrete Markov decision processes is introduced in the context of graphs.
The resulting hierarchies correspond to a hierarchical policy inference
algorithm approximating a discrete gradient flow between state-space trajectory
densities generated by the prior and optimal policies.
</dc:description>
 <dc:description>Comment: NIPS 2017 Workshop on Hierarchical Reinforcement Learning. 8 pages, 1
  figure</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00049</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personal Names in Modern Turkey</dc:title>
 <dc:creator>Herda&#x11f;delen, Ama&#xe7;</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We analyzed the most common 5000 male and 5000 female Turkish names based on
their etymological, morphological, and semantic attributes. The name statistics
are based on all Turkish citizens who were alive in 2014 and they cover 90% of
all population. To the best of our knowledge, this study is the most
comprehensive data-driven analysis of Turkish personal names. Female names have
a greater diversity than male names (e.g., top 15 male names cover 25% of the
male population, whereas top 28 female names cover 25% of the female
population). Despite their diversity, female names exhibit predictable
patterns. For example, certain roots such as g\&quot;ul and nar (rose and
pomegranate/red, respectively) are used to generate hundreds of unique female
names. Turkish personal names have their origins mainly in Arabic, followed by
Turkish and Persian. We computed overall frequencies of names according to
broad semantic themes that were identified in previous studies. We found that
foreign-origin names such as olga and khaled, pastoral names such as ya\u{g}mur
and deniz (rain and sea, respectively), and names based on fruits and plants
such as filiz and menek\c{s}e (sprout and violet, respectively) are more
frequently observed among females. Among males, names based on animals such as
arslan and yunus (lion and dolphin, respectively) and names based on famous
and/or historical figures such as mustafa kemal and o\u{g}uz ka\u{g}an (founder
of the Turkish Republic and the founder of the Turks in Turkish mythology,
respectively) are observed more frequently.
</dc:description>
 <dc:description>Comment: in Turkish</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00054</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning for Unsupervised Video Summarization with
  Diversity-Representativeness Reward</dc:title>
 <dc:creator>Zhou, Kaiyang</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video summarization aims to facilitate large-scale video browsing by
producing short, concise summaries that are diverse and representative of
original videos. In this paper, we formulate video summarization as a
sequential decision-making process and develop a deep summarization network
(DSN) to summarize videos. DSN predicts for each video frame a probability,
which indicates how likely a frame is selected, and then takes actions based on
the probability distributions to select frames, forming video summaries. To
train our DSN, we propose an end-to-end, reinforcement learning-based
framework, where we design a novel reward function that jointly accounts for
diversity and representativeness of generated summaries and does not rely on
labels or user interactions at all. During training, the reward function judges
how diverse and representative the generated summaries are, while DSN strives
for earning higher rewards by learning to produce more diverse and more
representative summaries. Since labels are not required, our method can be
fully unsupervised. Extensive experiments on two benchmark datasets show that
our unsupervised method not only outperforms other state-of-the-art
unsupervised methods, but also is comparable to or even superior than most of
published supervised approaches.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00055</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deformable GANs for Pose-based Human Image Generation</dc:title>
 <dc:creator>Siarohin, Aliaksandr</dc:creator>
 <dc:creator>Sangineto, Enver</dc:creator>
 <dc:creator>Lathuiliere, Stephane</dc:creator>
 <dc:creator>Sebe, Nicu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we address the problem of generating person images conditioned
on a given pose. Specifically, given an image of a person and a target pose, we
synthesize a new image of that person in the novel pose. In order to deal with
pixel-to-pixel misalignments caused by the pose differences, we introduce
deformable skip connections in the generator of our Generative Adversarial
Network. Moreover, a nearest-neighbour loss is proposed instead of the common
$L_1$ and $L_2$ losses in order to match the details of the generated image
with the target image. We test out approach using photos of persons in
different poses and we compare our method with previous work in this area
showing state-of-the-art results in two benchmarks. Our method can be applied
to the wider field of deformable object generation, provided that the pose of
the articulated object can be extracted using a keypoint detector.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00056</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>f-Divergence constrained policy improvement</dc:title>
 <dc:creator>Belousov, Boris</dc:creator>
 <dc:creator>Peters, Jan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  To ensure stability of learning, state-of-the-art generalized policy
iteration algorithms augment the policy improvement step with a trust region
constraint bounding the information loss. The size of the trust region is
commonly determined by the Kullback-Leibler (KL) divergence, which not only
captures the notion of distance well but also yields closed-form solutions. In
this paper, we consider a more general class of f-divergences and derive the
corresponding policy update rules. The generic solution is expressed through
the derivative of the convex conjugate function to f and includes the KL
solution as a special case. Within the class of f-divergences, we further focus
on a one-parameter family of {\alpha}-divergences to study effects of the
choice of divergence on policy improvement. Previously known as well as new
policy updates emerge for different values of {\alpha}. We show that every type
of policy update comes with a compatible policy evaluation resulting from the
chosen f-divergence. Interestingly, the mean-squared Bellman error minimization
is closely related to policy evaluation with the Pearson $\chi^2$-divergence
penalty, while the KL divergence results in the soft-max policy update and a
log-sum-exp critic. We carry out asymptotic analysis of the solutions for
different values of {\alpha} and demonstrate the effects of using different
divergence functions on a multi-armed bandit problem and on common standard
reinforcement learning problems.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00059</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The CAPIO 2017 Conversational Speech Recognition System</dc:title>
 <dc:creator>Han, Kyu J.</dc:creator>
 <dc:creator>Chandrashekaran, Akshay</dc:creator>
 <dc:creator>Kim, Jungsuk</dc:creator>
 <dc:creator>Lane, Ian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we show how we have achieved the state-of-the-art performance
on the industry-standard NIST 2000 Hub5 English evaluation set. We explore
densely connected LSTMs, inspired by the densely connected convolutional
networks recently introduced for image classification tasks. We also propose an
acoustic model adaptation scheme that simply averages the parameters of a seed
neural network acoustic model and its adapted version. This method was applied
with the CallHome training corpus and improved individual system performances
by on average 6.1% (relative) against the CallHome portion of the evaluation
set with no performance loss on the Switchboard portion. With RNN-LM rescoring
and lattice combination on the 5 systems trained across three different phone
sets, our 2017 speech recognition system has obtained 5.0% and 9.1% on
Switchboard and CallHome, respectively, both of which are the best word error
rates reported thus far. According to IBM in their latest work to compare human
and machine transcriptions, our reported Switchboard word error rate can be
considered to surpass the human parity (5.1%) of transcribing conversational
telephone speech.
</dc:description>
 <dc:description>Comment: 6 page, 3 figures, 5 tables</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00061</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multichannel Robot Speech Recognition Database: MChRSR</dc:title>
 <dc:creator>Novoa, Jos&#xe9;</dc:creator>
 <dc:creator>Escudero, Juan Pablo</dc:creator>
 <dc:creator>Fredes, Josu&#xe9;</dc:creator>
 <dc:creator>Wuth, Jorge</dc:creator>
 <dc:creator>Mahu, Rodrigo</dc:creator>
 <dc:creator>Yoma, N&#xe9;stor Becerra</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In real human robot interaction (HRI) scenarios, speech recognition
represents a major challenge due to robot noise, background noise and
time-varying acoustic channel. This document describes the procedure used to
obtain the Multichannel Robot Speech Recognition Database (MChRSR). It is
composed of 12 hours of multichannel evaluation data recorded in a real mobile
HRI scenario. This database was recorded with a PR2 robot performing different
translational and azimuthal movements. Accordingly, 16 evaluation sets were
obtained re-recording the clean set of the Aurora 4 database in different
movement conditions.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00062</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dendritic error backpropagation in deep cortical microcircuits</dc:title>
 <dc:creator>Sacramento, Jo&#xe3;o</dc:creator>
 <dc:creator>Costa, Rui Ponte</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:creator>Senn, Walter</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Animal behaviour depends on learning to associate sensory stimuli with the
desired motor command. Understanding how the brain orchestrates the necessary
synaptic modifications across different brain areas has remained a longstanding
puzzle. Here, we introduce a multi-area neuronal network model in which
synaptic plasticity continuously adapts the network towards a global desired
output. In this model synaptic learning is driven by a local dendritic
prediction error that arises from a failure to predict the top-down input given
the bottom-up activities. Such errors occur at apical dendrites of pyramidal
neurons where both long-range excitatory feedback and local inhibitory
predictions are integrated. When local inhibition fails to match excitatory
feedback an error occurs which triggers plasticity at bottom-up synapses at
basal dendrites of the same pyramidal neurons. We demonstrate the learning
capabilities of the model in a number of tasks and show that it approximates
the classical error backpropagation algorithm. Finally, complementing this
cortical circuit with a disinhibitory mechanism enables attention-like stimulus
denoising and generation. Our framework makes several experimental predictions
on the function of dendritic integration and cortical microcircuits, is
consistent with recent observations of cross-area learning, and suggests a
biological implementation of deep learning.
</dc:description>
 <dc:description>Comment: 27 pages, 5 figures, 10 pages supplementary information</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00070</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sum of squares certificates for stability of planar, homogeneous, and
  switched systems</dc:title>
 <dc:creator>Ahmadi, Amir Ali</dc:creator>
 <dc:creator>Parrilo, Pablo A.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  We show that existence of a global polynomial Lyapunov function for a
homogeneous polynomial vector field or a planar polynomial vector field (under
a mild condition) implies existence of a polynomial Lyapunov function that is a
sum of squares (sos) and that the negative of its derivative is also a sum of
squares. This result is extended to show that such sos-based certificates of
stability are guaranteed to exist for all stable switched linear systems. For
this class of systems, we further show that if the derivative inequality of the
Lyapunov function has an sos certificate, then the Lyapunov function itself is
automatically a sum of squares. These converse results establish cases where
semidefinite programming is guaranteed to succeed in finding proofs of Lyapunov
inequalities. Finally, we demonstrate some merits of replacing the sos
requirement on a polynomial Lyapunov function with an sos requirement on its
top homogeneous component. In particular, we show that this is a weaker
algebraic requirement in addition to being cheaper to impose computationally.
</dc:description>
 <dc:description>Comment: 12 pages. The arxiv version includes some more details than the
  published version</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00070</dc:identifier>
 <dc:identifier>IEEE Transactions On Automatic Control, Vol. 62, No. 10, October
  2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00074</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Communication in Radio Networks</dc:title>
 <dc:creator>Chlebus, Bogdan S.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A communication network is called a radio network if its nodes exchange
messages in the following restricted way. First, a send operation performed by
a node delivers copies of the same message to all directly reachable nodes.
Secondly, a node can successfully receive an incoming message only if exactly
one of its neighbors sent a message in that step. It is this semantics of how
ports at nodes send and receive messages that defines the networks rather than
the fact that only radio waves are used as a medium of communication; but if
that is the case then just a single frequency is used. We discuss algorithmic
aspects of exchanging information in such networks, concentrating on
distributed randomized protocols. Specific problems and solutions depend a lot
on the topology of the underlying reachability graph and how much the nodes
know about it. In single-hop networks each pair of nodes can communicate
directly. This kind of networks is also known as the multiple access channel.
Popular broadcasting protocols used on such channels are Aloha and the
exponential backoff. Multi-hop networks may have arbitrary topology and packets
need to be routed hopping through a sequence of adjacent nodes. Distributed
protocols run by such networks are usually robust enough not to expect the
nodes to know their neighbors. These ad-hoc networks and protocols model the
situation when nodes are mobile and do not rely on a fixed infrastructure.
</dc:description>
 <dc:description>Comment: Published in Panos M. Pardalos, Sanguthevar Rajasekaran, John H.
  Reif, and Jose D. P. Rolim, editors, Handbook of Randomized Computing, volume
  I, pages 401-456. Kluwer Academic Publishers, 2001</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00075</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logarithmic Frequency Scaling and Consistent Frequency Coverage for the
  Selection of Auditory Filterbank Center Frequencies</dc:title>
 <dc:creator>Lin, Shoufeng</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper provides new insights into the problem of selecting filter center
frequencies for the auditory filterbanks. We propose to use a constant
frequency distance and a consistent frequency coverage as the two metrics that
motivate the logarithmic frequency scaling and a regularized selection of
center frequencies. The frequency scaling and the consistent frequency coverage
have been derived based on a common harmonic speaker signal model. Furthermore,
we have found that the existing linear equivalent rectangular bandwidth (ERB)
function as well as any possible linear ERB approximation can also lead to a
consistent frequency coverage. The results are verified and demonstrated using
the gammatone filterbank.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00076</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Attention for SQL Generation</dc:title>
 <dc:creator>Guo, Tong</dc:creator>
 <dc:creator>Gao, Huilin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Generating structural query language (SQL) queries from natural language is a
long-standing open problem and has been attracting considerable interest
recently, driven by the explosive development of deep learning techniques.
Toward solving the problem, we leverage the structure of SQL queries and
present a sketch-based approach or synthesizing way to solve this problem,
which turns the solving method to a sequence-to-set problem and word order
generation problem. We employ the bidirectional attention mechanisms and
character level embedding to further improve the result. Experimental
evaluations show that our model achieves the state-of-the-art results in
WikiSQL dataset.
</dc:description>
 <dc:description>Comment: 7 pages 3 figures</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00077</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Synthesis from Visual Attributes via Sketch using Conditional VAEs
  and GANs</dc:title>
 <dc:creator>Di, Xing</dc:creator>
 <dc:creator>Patel, Vishal M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic synthesis of faces from visual attributes is an important problem
in computer vision and has wide applications in law enforcement and
entertainment. With the advent of deep generative convolutional neural networks
(CNNs), attempts have been made to synthesize face images from attributes and
text descriptions. In this paper, we take a different approach, where we
formulate the original problem as a stage-wise learning problem. We first
synthesize the facial sketch corresponding to the visual attributes and then we
reconstruct the face image based on the synthesized sketch. The proposed
Attribute2Sketch2Face framework, which is based on a combination of deep
Conditional Variational Autoencoder (CVAE) and Generative Adversarial Networks
(GANs), consists of three stages: (1) Synthesis of facial sketch from
attributes using a CVAE architecture, (2) Enhancement of coarse sketches to
produce sharper sketches using a GAN-based framework, and (3) Synthesis of face
from sketch using another GAN-based network. Extensive experiments and
comparison with recent methods are performed to verify the effectiveness of the
proposed attribute-based three stage face synthesis method.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00085</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Structural Weight Uncertainty for Sequential Decision-Making</dc:title>
 <dc:creator>Zhang, Ruiyi</dc:creator>
 <dc:creator>Li, Chunyuan</dc:creator>
 <dc:creator>Chen, Changyou</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning probability distributions on the weights of neural networks (NNs)
has recently proven beneficial in many applications. Bayesian methods, such as
Stein variational gradient descent (SVGD), offer an elegant framework to reason
about NN model uncertainty. However, by assuming independent Gaussian priors
for the individual NN weights (as often applied), SVGD does not impose prior
knowledge that there is often structural information (dependence) among
weights. We propose efficient posterior learning of structural weight
uncertainty, within an SVGD framework, by employing matrix variate Gaussian
priors on NN parameters. We further investigate the learned structural
uncertainty in sequential decision-making problems, including contextual
bandits and reinforcement learning. Experiments on several synthetic and real
datasets indicate the superiority of our model, compared with state-of-the-art
methods.
</dc:description>
 <dc:description>Comment: To appear in AISTATS 2018 (keep updating before camera-ready)</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.00085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="143000" completeListSize="155308">2369777|144001</resumptionToken>
</ListRecords>
</OAI-PMH>
