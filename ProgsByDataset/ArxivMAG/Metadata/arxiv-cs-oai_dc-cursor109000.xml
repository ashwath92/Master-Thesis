<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:14:09Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|109001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00350</identifier>
 <datestamp>2016-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computationally Efficient Influence Maximization in Stochastic and
  Adversarial Models: Algorithms and Analysis</dc:title>
 <dc:creator>Khim, Justin</dc:creator>
 <dc:creator>Jog, Varun</dc:creator>
 <dc:creator>Loh, Po-Ling</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of influence maximization in fixed networks, for both
stochastic and adversarial contagion models. The common goal is to select a
subset of nodes of a specified size to infect so that the number of infected
nodes at the conclusion of the epidemic is as large as possible. In the
stochastic setting, the epidemic spreads according to a general triggering
model, which includes the popular linear threshold and independent cascade
models. We establish upper and lower bounds for the influence of an initial
subset of nodes in the network, where the influence is defined as the expected
number of infected nodes. Although the problem of exact influence computation
is NP-hard in general, our bounds may be evaluated efficiently, leading to
scalable algorithms for influence maximization with rigorous theoretical
guarantees. In the adversarial spreading setting, an adversary is allowed to
specify the edges through which contagion may spread, and the player chooses
sets of nodes to infect in successive rounds. Both the adversary and player may
behave stochastically, but we limit the adversary to strategies that are
oblivious of the player's actions. We establish upper and lower bounds on the
minimax pseudo-regret in both undirected and directed networks.
</dc:description>
 <dc:description>Comment: 56 pages, 2 figures, 1 table</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00354</identifier>
 <datestamp>2016-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster decoding for subword level Phrase-based SMT between related
  languages</dc:title>
 <dc:creator>Kunchukuttan, Anoop</dc:creator>
 <dc:creator>Bhattacharyya, Pushpak</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A common and effective way to train translation systems between related
languages is to consider sub-word level basic units. However, this increases
the length of the sentences resulting in increased decoding time. The increase
in length is also impacted by the specific choice of data format for
representing the sentences as subwords. In a phrase-based SMT framework, we
investigate different choices of decoder parameters as well as data format and
their impact on decoding time and translation accuracy. We suggest best options
for these settings that significantly improve decoding time with little impact
on the translation accuracy.
</dc:description>
 <dc:description>Comment: Accepted at VarDial3 (Third Workshop on NLP for Similar Languages,
  Varieties and Dialects) collocated with COLING 2016; 7 pages</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00356</identifier>
 <datestamp>2016-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Artificial Intelligence to Identify State Secrets</dc:title>
 <dc:creator>Souza, Renato Rocha</dc:creator>
 <dc:creator>Coelho, Flavio Codeco</dc:creator>
 <dc:creator>Shah, Rohan</dc:creator>
 <dc:creator>Connelly, Matthew</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Whether officials can be trusted to protect national security information has
become a matter of great public controversy, reigniting a long-standing debate
about the scope and nature of official secrecy. The declassification of
millions of electronic records has made it possible to analyze these issues
with greater rigor and precision. Using machine-learning methods, we examined
nearly a million State Department cables from the 1970s to identify features of
records that are more likely to be classified, such as international
negotiations, military operations, and high-level communications. Even with
incomplete data, algorithms can use such features to identify 90% of classified
cables with &lt;11% false positives. But our results also show that there are
longstanding problems in the identification of sensitive information. Error
analysis reveals many examples of both overclassification and
underclassification. This indicates both the need for research on inter-coder
reliability among officials as to what constitutes classified material and the
opportunity to develop recommender systems to better manage both classification
and declassification.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00370</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical success factors for m-commerce in Saudi Arabia's private sector
  -- a multiple case study analysis</dc:title>
 <dc:creator>Alturaigi, Norah Suliman</dc:creator>
 <dc:creator>Altameem, Abdullah Abdulaziz</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Many developing country firms are investing huge money in the sector of
mobile commerce m commerce Simplifying and understanding the factors which can
impact on m commerce success enables the organisations managers to focus their
efforts on the key areas of their m commerce businesses thereby contributing to
the successful implementation of m commerce This study provides a clear
understanding of m commerce in the private sector in the Kingdom of Saudi
Arabia and identifies the critical success factors of implementing m commerce
within the local business environment A case study approach will be used for
five Saudi companies which use mcommerce represented by Alrajhi Bank Souqcom
Saudi Electricity Company Saudi telecom company STC and Saudi Airlines This
study represents a research in progress and interviews based on the literature
to identify the key success factors for these companies in particular and in
Saudi Arabia s private sector in general
</dc:description>
 <dc:description>Comment: 10 pages, 2015. International Journal of Information Technology
  Convergence and Services IJITCS</dc:description>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00370</dc:identifier>
 <dc:identifier>doi:10.5121/ijitcs.2015.5601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00374</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A secure service provisioning framework for cyber physical cloud
  computing systems</dc:title>
 <dc:creator>Ara, Anees</dc:creator>
 <dc:creator>Al-Rodhaan, Mznah</dc:creator>
 <dc:creator>Tian, Yuan</dc:creator>
 <dc:creator>Al-Dhelaan, Abdullah</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cyber physical systems (CPS) are mission critical systems engineered by
combination of cyber and physical systems respectively. These systems are
tightly coupled, resource constrained systems and have dynamic real time
applications. Due to the limitation of resources, and in order to improve the
efficiency of the CPS systems, they are combined with cloud computing
architecture, and are called as Cyber Physical Cloud Computing Systems (CPCCS).
These CPCCS have critical care applications where security of the systems is a
major concern. Therefore, we propose a Secure Service provisioning architecture
for Cyber Physical Cloud Computing Systems (CPCCS), which includes the
combination of technologies such as CPS, Cloud Computing and Wireless Sensor
Networks. In addition to this, we also highlight various threats/attacks;
security requirements and mechanisms that are applicable to CPCCS at different
layers and propose two security models that can be adapted in a layered
architectural format.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, 1 table.
  http://airccse.org/journal/ijdps/current2015.html</dc:description>
 <dc:date>2015-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00377</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaboration Networks in the Music Industry</dc:title>
 <dc:creator>Budner, Pascal</dc:creator>
 <dc:creator>Grahl, Joern</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Recording an album brings singers, producers, musicians, audio engineers, and
many other professions together. We know from the press that a few
&quot;super&quot;-producers work with many artists. But how does the large-scale social
structure of the music industry look like? What is the social network behind
the finest albums of all time? In this paper we studied the large-scale
structure of music collaborations using the tools of network science. We
considered all albums in Rolling Stone Magazine's list of '500 Greatest Albums
of All Time' and the '1001 Albums You Must Hear Before You Die' by Robert
Dimery. We found that the existing research on collaboration networks is
corroborated by the particular collaboration network in the music industry.
Furthermore, it has been found that the most important professions of the music
industry in terms of connectivity were main artists and engineers.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, 6 tables</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00379</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Machine Learning Algorithm as Creative Musical Tool</dc:title>
 <dc:creator>Fiebrink, Rebecca</dc:creator>
 <dc:creator>Caramiaux, Baptiste</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning is the capacity of a computational system to learn
structures from datasets in order to make predictions on newly seen data. Such
an approach offers a significant advantage in music scenarios in which
musicians can teach the system to learn an idiosyncratic style, or can break
the rules to explore the system's capacity in unexpected ways. In this chapter
we draw on music, machine learning, and human-computer interaction to elucidate
an understanding of machine learning algorithms as creative tools for music and
the sonic arts. We motivate a new understanding of learning algorithms as
human-computer interfaces. We show that, like other interfaces, learning
algorithms can be characterised by the ways their affordances intersect with
goals of human users. We also argue that the nature of interaction between
users and algorithms impacts the usability and usefulness of those algorithms
in profound ways. This human-centred view of machine learning motivates our
concluding discussion of what it means to employ machine learning as a creative
tool.
</dc:description>
 <dc:description>Comment: Pre-print to appear in the Oxford Handbook on Algorithmic Music.
  Oxford University Press</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00381</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comments on an image encryption scheme based on a chaotic Tent map</dc:title>
 <dc:creator>Jolfaei, Alireza</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Recently an image encryption scheme based on a chaotic Tent map has been
proposed by Li et al. This comment shows that this scheme is broken and no
secure application can be found for it.
</dc:description>
 <dc:date>2016-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00384</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Deep Journey from Content to Collaborative Filtering</dc:title>
 <dc:creator>Barkan, Oren</dc:creator>
 <dc:creator>Koenigstein, Noam</dc:creator>
 <dc:creator>Yogev, Eylon</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In Recommender Systems research, algorithms are often characterized as either
Collaborative Filtering (CF) or Content Based (CB). CF algorithms are trained
using a dataset of user explicit or implicit preferences while CB algorithms
are typically based on item profiles. These approaches harness very different
data sources hence the resulting recommended items are generally also very
different. This paper presents a novel model that serves as a bridge from items
content into their CF representations. We introduce a multiple input deep
regression model to predict the CF latent embedding vectors of items based on
their textual description and metadata. We showcase the effectiveness of the
proposed model by predicting the CF vectors of movies and apps based on their
textual descriptions. Finally, we show that the model can be further improved
by incorporating metadata such as the movie release year and tags which
contribute to a higher accuracy.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00393</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving Visual Madlibs with Multiple Cues</dc:title>
 <dc:creator>Tommasi, Tatiana</dc:creator>
 <dc:creator>Mallya, Arun</dc:creator>
 <dc:creator>Plummer, Bryan</dc:creator>
 <dc:creator>Lazebnik, Svetlana</dc:creator>
 <dc:creator>Berg, Alexander C.</dc:creator>
 <dc:creator>Berg, Tamara L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an approach for answering fill-in-the-blank multiple
choice questions from the Visual Madlibs dataset. Instead of generic and
commonly used representations trained on the ImageNet classification task, our
approach employs a combination of networks trained for specialized tasks such
as scene recognition, person activity classification, and attribute prediction.
We also present a method for localizing phrases from candidate answers in order
to provide spatial support for feature extraction. We map each of these
features, together with candidate answers, to a joint embedding space through
normalized canonical correlation analysis (nCCA). Finally, we solve an
optimization problem to learn to combine scores from nCCA models trained on
multiple cues to select the best answer. Extensive experimental results show a
significant improvement over the previous state of the art and confirm that
answering questions from a wide range of types benefits from examining a
variety of image cues and carefully choosing the spatial support for feature
extraction.
</dc:description>
 <dc:description>Comment: submitted to IJCV -- under review</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2017-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00401</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Games for Bisimulations and Abstraction</dc:title>
 <dc:creator>Escrig, David De Frutos</dc:creator>
 <dc:creator>Keiren, Jeroen J. A.</dc:creator>
 <dc:creator>Willemse, Tim A. C.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Weak bisimulations are typically used in process algebras where silent steps
are used to abstract from internal behaviours. They facilitate relating
implementations to specifications. When an implementation fails to conform to
its specification, pinpointing the root cause can be challenging. In this paper
we provide a generic characterisation of branching-, delayed-, $\eta$- and
weak-bisimulation as a game between Spoiler and Duplicator, offering an
operational understanding of the relations. We show how such games can be used
to assist in diagnosing non-conformance between implementation and
specification. Moreover, we show how these games can be extended to distinguish
divergences.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00401</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 4 (November
  28, 2017) lmcs:4099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00403</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Experimental Investigation of Hyperbolic Routing with a Smart
  Forwarding Plane in NDN</dc:title>
 <dc:creator>Lehman, Vince</dc:creator>
 <dc:creator>Gawande, Ashlesh</dc:creator>
 <dc:creator>Zhang, Beichuan</dc:creator>
 <dc:creator>Zhang, Lixia</dc:creator>
 <dc:creator>Aldecoa, Rodrigo</dc:creator>
 <dc:creator>Krioukov, Dmitri</dc:creator>
 <dc:creator>Wang, Lan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Routing in NDN networks must scale in terms of forwarding table size and
routing protocol overhead. Hyperbolic routing (HR) presents a potential
solution to address the routing scalability problem, because it does not use
traditional forwarding tables or exchange routing updates upon changes in
network topologies. Although HR has the drawbacks of producing sub-optimal
routes or local minima for some destinations, these issues can be mitigated by
NDN's intelligent data forwarding plane. However, HR's viability still depends
on both the quality of the routes HR provides and the overhead incurred at the
forwarding plane due to HR's sub-optimal behavior. We designed a new forwarding
strategy called Adaptive Smoothed RTT-based Forwarding (ASF) to mitigate HR's
sub-optimal path selection. This paper describes our experimental investigation
into the packet delivery delay and overhead under HR as compared with
Named-Data Link State Routing (NLSR), which calculates shortest paths. We run
emulation experiments using various topologies with different failure
scenarios, probing intervals, and maximum number of next hops for a name
prefix. Our results show that HR's delay stretch has a median close to 1 and a
95th-percentile around or below 2, which does not grow with the network size.
HR's message overhead in dynamic topologies is nearly independent of the
network size, while NLSR's overhead grows polynomially at least. These results
suggest that HR offers a more scalable routing solution with little impact on
the optimality of routing paths.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00403</dc:identifier>
 <dc:identifier>2016 IEEE/ACM 24th International Symposium on Quality of Service
  (IWQoS)</dc:identifier>
 <dc:identifier>doi:10.1109/IWQoS.2016.7590394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00404</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Per-Server Dominant-Share Fairness (PS-DSF): A Multi-Resource Fair
  Allocation Mechanism for Heterogeneous Servers</dc:title>
 <dc:creator>Khamse-Ashari, Jalal</dc:creator>
 <dc:creator>Lambadaris, Ioannis</dc:creator>
 <dc:creator>Kesidis, George</dc:creator>
 <dc:creator>Urgaonkar, Bhuvan</dc:creator>
 <dc:creator>Zhao, Yiqiang</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Users of cloud computing platforms pose different types of demands for
multiple resources on servers (physical or virtual machines). Besides
differences in their resource capacities, servers may be additionally
heterogeneous in their ability to service users - certain users' tasks may only
be serviced by a subset of the servers. We identify important shortcomings in
existing multi-resource fair allocation mechanisms - Dominant Resource Fairness
(DRF) and its follow up work - when used in such environments. We develop a new
fair allocation mechanism called Per-Server Dominant-Share Fairness (PS-DSF)
which we show offers all desirable sharing properties that DRF is able to offer
in the case of a single &quot;resource pool&quot; (i.e., if the resources of all servers
were pooled together into one hypothetical server). We evaluate the performance
of PS-DSF through simulations. Our evaluation shows the enhanced efficiency of
PS-DSF compared to the existing allocation mechanisms. We argue how our
proposed allocation mechanism is applicable in cloud computing networks and
especially large scale data-centers.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures, technical report</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00421</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flood-Filling Networks</dc:title>
 <dc:creator>Januszewski, Micha&#x142;</dc:creator>
 <dc:creator>Maitin-Shepard, Jeremy</dc:creator>
 <dc:creator>Li, Peter</dc:creator>
 <dc:creator>Kornfeld, J&#xf6;rgen</dc:creator>
 <dc:creator>Denk, Winfried</dc:creator>
 <dc:creator>Jain, Viren</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art image segmentation algorithms generally consist of at least
two successive and distinct computations: a boundary detection process that
uses local image information to classify image locations as boundaries between
objects, followed by a pixel grouping step such as watershed or connected
components that clusters pixels into segments. Prior work has varied the
complexity and approach employed in these two steps, including the
incorporation of multi-layer neural networks to perform boundary prediction,
and the use of global optimizations during pixel clustering. We propose a
unified and end-to-end trainable machine learning approach, flood-filling
networks, in which a recurrent 3d convolutional network directly produces
individual segments from a raw image. The proposed approach robustly segments
images with an unknown and variable number of objects as well as highly
variable object sizes. We demonstrate the approach on a challenging 3d image
segmentation task, connectomic reconstruction from volume electron microscopy
data, on which flood-filling neural networks substantially improve accuracy
over other state-of-the-art methods. The proposed approach can replace complex
multi-step segmentation pipelines with a single neural network that is learned
end-to-end.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00423</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Skylines on Distributed Data</dc:title>
 <dc:creator>Zhang, Haoyu</dc:creator>
 <dc:creator>Zhang, Qin</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we study skyline queries in the distributed computational
model, where we have $s$ remote sites and a central coordinator (the query
node); each site holds a piece of data, and the coordinator wants to compute
the skyline of the union of the $s$ datasets. The computation is in terms of
rounds, and the goal is to minimize both the total communication cost and the
round cost.
  Viewing data objects as points in the Euclidean space, we consider both the
horizontal data partition case where each site holds a subset of points, and
the vertical data partition case where each site holds one coordinate of all
the points. We give a set of algorithms that have provable theoretical
guarantees, and complement them with information theoretical lower bounds. We
also demonstrate the superiority of our algorithms over existing heuristics by
an extensive set of experiments on both synthetic and real world datasets.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00429</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Mean Estimation with Limited Communication</dc:title>
 <dc:creator>Suresh, Ananda Theertha</dc:creator>
 <dc:creator>Yu, Felix X.</dc:creator>
 <dc:creator>Kumar, Sanjiv</dc:creator>
 <dc:creator>McMahan, H. Brendan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Motivated by the need for distributed learning and optimization algorithms
with low communication cost, we study communication efficient algorithms for
distributed mean estimation. Unlike previous works, we make no probabilistic
assumptions on the data. We first show that for $d$ dimensional data with $n$
clients, a naive stochastic binary rounding approach yields a mean squared
error (MSE) of $\Theta(d/n)$ and uses a constant number of bits per dimension
per client. We then extend this naive algorithm in two ways: we show that
applying a structured random rotation before quantization reduces the error to
$\mathcal{O}((\log d)/n)$ and a better coding strategy further reduces the
error to $\mathcal{O}(1/n)$ and uses a constant number of bits per dimension
per client. We also show that the latter coding strategy is optimal up to a
constant in the minimax sense i.e., it achieves the best MSE for a given
communication cost. We finally demonstrate the practicality of our algorithms
by applying them to distributed Lloyd's algorithm for k-means and power
iteration for PCA.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2017-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00435</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds for the $l_1$-distance of $q$-ary lattices obtained via
  Constructions D, D$^{'}$ and $\overline{D}$</dc:title>
 <dc:creator>Strey, Eleonesio</dc:creator>
 <dc:creator>Costa, Sueli I. R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Lattices have been used in several problems in coding theory and
cryptography. In this paper we approach $q$-ary lattices obtained via
Constructions D, $\D'$ and $\overline{D}$. It is shown connections between
Constructions D and $\D'$. Bounds for the minimum $l_1$-distance of lattices
$\Lambda_{D}$, $\Lambda_{D'}$ and $\Lambda_{\overline{D}}$ and, under certain
conditions, a generator matrix for $\Lambda_{D'}$ are presented. In addition,
when the chain of codes used is closed under the zero-one addition, we derive
explicit expressions for the minimum $l_1$-distances of the lattices
$\Lambda_{D}$ and $\Lambda_{\overline{D}}$ attached to the distances of the
codes used in these constructions.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00440</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>And the Winner is ...: Bayesian Twitter-based Prediction on 2016 U.S.
  Presidential Election</dc:title>
 <dc:creator>Tunggawan, Elvyna</dc:creator>
 <dc:creator>Soelistio, Yustinus Eko</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper describes a Naive-Bayesian predictive model for 2016 U.S.
Presidential Election based on Twitter data. We use 33,708 tweets gathered
since December 16, 2015 until February 29, 2016. We introduce a simpler data
preprocessing method to label the data and train the model. The model achieves
95.8% accuracy on 10-fold cross validation and predicts Ted Cruz and Bernie
Sanders as Republican and Democratic nominee respectively. It achieves a
comparable result to those in its competitor methods.
</dc:description>
 <dc:description>Comment: This is the non-final version of the paper. The final version is
  published in the IC3INA 2016 Conference (3-5 Oct. 2016,
  http://situs.opi.lipi.go.id/ic3ina2016/). All citation should be directed to
  the final version</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00447</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bots as Virtual Confederates: Design and Ethics</dc:title>
 <dc:creator>Krafft, Peter M</dc:creator>
 <dc:creator>Macy, Michael</dc:creator>
 <dc:creator>Pentland, Alex</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  The use of bots as virtual confederates in online field experiments holds
extreme promise as a new methodological tool in computational social science.
However, this potential tool comes with inherent ethical challenges. Informed
consent can be difficult to obtain in many cases, and the use of confederates
necessarily implies the use of deception. In this work we outline a design
space for bots as virtual confederates, and we propose a set of guidelines for
meeting the status quo for ethical experimentation. We draw upon examples from
prior work in the CSCW community and the broader social science literature for
illustration. While a handful of prior researchers have used bots in online
experimentation, our work is meant to inspire future work in this area and
raise awareness of the associated ethical issues.
</dc:description>
 <dc:description>Comment: Forthcoming in CSCW 2017</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00447</dc:identifier>
 <dc:identifier>The 20th ACM Conference on Computer-Supported Cooperative Work and
  Social Computing (CSCW) (2016)</dc:identifier>
 <dc:identifier>doi:10.1145/2998181.2998354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00448</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural-Parameter Networks: A Class of Probabilistic Neural Networks</dc:title>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Shi, Xingjian</dc:creator>
 <dc:creator>Yeung, Dit-Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural networks (NN) have achieved state-of-the-art performance in various
applications. Unfortunately in applications where training data is
insufficient, they are often prone to overfitting. One effective way to
alleviate this problem is to exploit the Bayesian approach by using Bayesian
neural networks (BNN). Another shortcoming of NN is the lack of flexibility to
customize different distributions for the weights and neurons according to the
data, as is often done in probabilistic graphical models. To address these
problems, we propose a class of probabilistic neural networks, dubbed
natural-parameter networks (NPN), as a novel and lightweight Bayesian treatment
of NN. NPN allows the usage of arbitrary exponential-family distributions to
model the weights and neurons. Different from traditional NN and BNN, NPN takes
distributions as input and goes through layers of transformation before
producing distributions to match the target output distributions. As a Bayesian
treatment, efficient backpropagation (BP) is performed to learn the natural
parameters for the distributions over both the weights and neurons. The output
distributions of each layer, as byproducts, may be used as second-order
representations for the associated tasks such as link prediction. Experiments
on real-world datasets show that NPN can achieve state-of-the-art performance.
</dc:description>
 <dc:description>Comment: To appear at NIPS 2016</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00453</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Directional Training and Fast Sector-based Processing Schemes for mmWave
  Channels</dc:title>
 <dc:creator>Li, Zheda</dc:creator>
 <dc:creator>Rupasinghe, Nadisanka</dc:creator>
 <dc:creator>Bursalioglu, Ozgun Y.</dc:creator>
 <dc:creator>Wang, Chenwei</dc:creator>
 <dc:creator>Papadopoulos, Haralabos</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a single-cell scenario involving a single base station (BS) with
a massive array serving multi-antenna terminals in the downlink of a mmWave
channel. We present a class of multiuser user MIMO schemes, which rely on
uplink training from the user terminals, and on uplink/downlink channel
reciprocity. The BS employs virtual sector-based processing according to which,
user-channel estimation and data transmission are performed in parallel over
non-overlapping angular sectors. The uplink training schemes we consider are
non-orthogonal, that is, we allow multiple users to transmit pilots on the same
pilot dimension (thereby potentially interfering with one another). Elementary
processing allows each sector to determine the subset of user channels that can
be resolved on the sector (effectively pilot contamination free) and, thus, the
subset of users that can be served by the sector. This allows resolving
multiple users on the same pilot dimension at different sectors, thereby
increasing the overall multiplexing gains of the system. Our analysis and
simulations reveal that, by using appropriately designed directional training
beams at the user terminals, the sector-based transmission schemes we present
can yield substantial spatial multiplexing and ergodic user-rates improvements
with respect to their orthogonal-training counterparts.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00454</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in
  the Blanks</dc:title>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Shi, Xingjian</dc:creator>
 <dc:creator>Yeung, Dit-Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Hybrid methods that utilize both content and rating information are commonly
used in many recommender systems. However, most of them use either handcrafted
features or the bag-of-words representation as a surrogate for the content
information but they are neither effective nor natural enough. To address this
problem, we develop a collaborative recurrent autoencoder (CRAE) which is a
denoising recurrent autoencoder (DRAE) that models the generation of content
sequences in the collaborative filtering (CF) setting. The model generalizes
recent advances in recurrent deep learning from i.i.d. input to non-i.i.d.
(CF-based) input and provides a new denoising scheme along with a novel
learnable pooling scheme for the recurrent autoencoder. To do this, we first
develop a hierarchical Bayesian model for the DRAE and then generalize it to
the CF setting. The synergy between denoising and CF enables CRAE to make
accurate recommendations while learning to fill in the blanks in sequences.
Experiments on real-world datasets from different domains (CiteULike and
Netflix) show that, by jointly modeling the order-aware generation of sequences
for the content information and performing CF for the ratings, CRAE is able to
significantly outperform the state of the art on both the recommendation task
based on ratings and the sequence generation task based on content information.
</dc:description>
 <dc:description>Comment: To appear at NIPS 2016</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00455</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Compositionality of Quantitative Information Flow</dc:title>
 <dc:creator>Kawamoto, Yusuke</dc:creator>
 <dc:creator>Chatzikokolakis, Konstantinos</dc:creator>
 <dc:creator>Palamidessi, Catuscia</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Information flow is the branch of security that studies the leakage of
information due to correlation between secrets and observables. Since in
general such correlation cannot be avoided completely, it is important to
quantify the leakage. The most followed approaches to defining appropriate
measures are those based on information theory. In particular, one of the most
successful approaches is the recently proposed $g$-leakage framework, which
encompasses most of the information-theoretic ones. A problem with $g$-leakage,
however, is that it is defined in terms of a minimization problem, which, in
the case of large systems, can be computationally rather heavy. In this paper
we study the case in which the channel associated to the system can be
decomposed into simpler channels, which typically happens when the observables
consist of multiple components. Our main contribution is the derivation of
bounds on the (multiplicative version of) $g$-leakage of the whole system in
terms of the $g$-leakages of its components. We also consider the particular
cases of min-entropy leakage and of parallel channels, generalizing and
systematizing results from the literature. We demonstrate the effectiveness of
our method and evaluate the precision of our bounds using examples.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00455</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 3 (August
  15, 2017) lmcs:3860</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(3:11)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00456</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Asymmetric Opinions on Online Social Interrelationship with
  Language and Network Features</dc:title>
 <dc:creator>Wang, Bo</dc:creator>
 <dc:creator>Yu, Yanshu</dc:creator>
 <dc:creator>Wang, Yuan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Instead of studying the properties of social relationship from an objective
view, in this paper, we focus on individuals' subjective and asymmetric
opinions on their interrelationships. Inspired by the theories from
sociolinguistics, we investigate two individuals' opinions on their
interrelationship with their interactive language features. Eliminating the
difference of personal language style, we clarify that the asymmetry of
interactive language feature values can indicate individuals' asymmetric
opinions on their interrelationship. We also discuss how the degree of
opinions' asymmetry is related to the individuals' personality traits.
Furthermore, to measure the individuals' asymmetric opinions on
interrelationship concretely, we develop a novel model synthetizing interactive
language and social network features. The experimental results with Enron email
dataset provide multiple evidences of the asymmetric opinions on
interrelationship, and also verify the effectiveness of the proposed model in
measuring the degree of opinions' asymmetry.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00457</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure vs. Language: Investigating the Multi-factors of Asymmetric
  Opinions on Online Social Interrelationship with a Case Study</dc:title>
 <dc:creator>Wang, Bo</dc:creator>
 <dc:creator>Sun, Yingjun</dc:creator>
 <dc:creator>Wang, Yuan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Though current researches often study the properties of online social
relationship from an objective view, we also need to understand individuals'
subjective opinions on their interrelationships in social computing studies.
Inspired by the theories from sociolinguistics, the latest work indicates that
interactive language can reveal individuals' asymmetric opinions on their
interrelationship. In this work, in order to explain the opinions' asymmetry on
interrelationship with more latent factors, we extend the investigation from
single relationship to the structural context in online social network. We
analyze the correlation between interactive language features and the
structural context of interrelationships. The structural context of vertex,
edges and triangles in social network are considered. With statistical analysis
on Enron email dataset, we find that individuals' opinions (measured by
interactive language features) on their interrelationship are related to some
of their important structural context in social network. This result can help
us to understand and measure the individuals' opinions on their
interrelationship with more intrinsic information.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00459</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Peak Detection for Demodulation in Molecular Communication</dc:title>
 <dc:creator>Noel, Adam</dc:creator>
 <dc:creator>Eckford, Andrew W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Molecular communication requires low-complexity symbol detection algorithms
to deal with the many sources of uncertainty that are inherent in these
channels. This paper proposes two variants of a high-performance asynchronous
peak detection algorithm for a receiver that makes independent observations.
The first variant has low complexity and measures the largest observation
within a sampling interval. The second variant adds decision feedback to
mitigate inter-symbol interference. Although the algorithm does not require
synchronization between the transmitter and receiver, results demonstrate that
the bit error performance of symbol-by-symbol detection using the first variant
is better than using a single sample whose sampling time is chosen a priori.
The second variant is shown to have performance comparable to that of an energy
detector. Both variants of the algorithm demonstrate better resilience to
timing offsets than that of existing detectors.
</dc:description>
 <dc:description>Comment: 6 pages, 1 table, 5 figures. To be presented at the IEEE
  International Conference on Communications (IEEE ICC 2017) in May 2017</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00463</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Load-Balanced Parallel and Distributed Sorting Algorithm Implemented
  with PGX.D</dc:title>
 <dc:creator>Khatami, Zahra</dc:creator>
 <dc:creator>Hong, Sungpack</dc:creator>
 <dc:creator>Lee, Jinsoo</dc:creator>
 <dc:creator>Depner, Siegfried</dc:creator>
 <dc:creator>Chafi, Hassan</dc:creator>
 <dc:creator>Ramanujam, J.</dc:creator>
 <dc:creator>Kaiser, Hartmut</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Sorting has been one of the most challenging studied problems in different
scientific researches. Although many techniques and algorithms have been
proposed on the theory of having efficient parallel sorting implementation,
however achieving desired performance on different types of the architectures
with large number of processors is still a challenging issue. Maximizing
parallelism level in applications can be achieved by minimizing overheads due
to load imbalance and waiting time due to memory latencies. In this paper, we
present a distributed sorting algorithm implemented in PGX.D, a fast
distributed graph processing system, which outperforms the Spark's distributed
sorting implementation by around 2x-3x by hiding communication latencies and
minimizing unnecessary overheads. Furthermore, it shows that the proposed PGX.D
sorting method handles dataset containing many duplicated data entries
efficiently and always results in keeping balanced workloads for different
input data distribution types.
</dc:description>
 <dc:description>Comment: 8 pages, 12 figures</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2017-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00467</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Performance Survey on Stack-based and Register-based Virtual Machines</dc:title>
 <dc:creator>Fang, Ruijie</dc:creator>
 <dc:creator>Liu, Siqi</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Virtual machines have been widely adapted for high-level programming language
implementations and for providing a degree of platform neutrality. As the
overall use and adaptation of virtual machines grow, the overall performance of
virtual machines has become a widely-discussed topic. In this paper, we present
a survey on the performance differences of the two most widely adapted types of
virtual machines - the stack-based virtual machine and the register-based
virtual machine - using various benchmark programs. Additionally, we adopted a
new approach of measuring performance by measuring the overall dispatch time,
amount of dispatches, fetch time, and execution time while running benchmarks
on custom-implemented, lightweight virtual machines. Finally, we present two
lightweight, custom-designed, Turing-equivalent virtual machines that are
specifically designed in benchmarking virtual machine performance - the
&quot;Conceptum&quot; stack-based virtual machine, and the &quot;Inertia&quot; register-based
virtual machine. Our result showed that while on average the register machine
spends 20.39% less time in executing benchmarks than the stack machine, the
stack-based virtual machine is still faster than the virtual machine regarding
the instruction fetch time.
</dc:description>
 <dc:description>Comment: Short paper for evaluating performance differences between a
  stack-based and a register-based virtual machine</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00468</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CRF-CNN: Modeling Structured Information in Human Pose Estimation</dc:title>
 <dc:creator>Chu, Xiao</dc:creator>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:creator>Li, Hongsheng</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional neural networks (CNN) have achieved great success. On the
other hand, modeling structural information has been proved critical in many
vision problems. It is of great interest to integrate them effectively. In a
classical neural network, there is no message passing between neurons in the
same layer. In this paper, we propose a CRF-CNN framework which can
simultaneously model structural information in both output and hidden feature
layers in a probabilistic way, and it is applied to human pose estimation. A
message passing scheme is proposed, so that in various layers each body joint
receives messages from all the others in an efficient way. Such message passing
can be implemented with convolution between features maps in the same layer,
and it is also integrated with feedforward propagation in neural networks.
Finally, a neural network implementation of end-to-end learning CRF-CNN is
provided. Its effectiveness is demonstrated through experiments on two
benchmark datasets.
</dc:description>
 <dc:description>Comment: NIPS</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00469</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shedding Light on the Adoption of Let's Encrypt</dc:title>
 <dc:creator>Manousis, Antonis</dc:creator>
 <dc:creator>Ragsdale, Roy</dc:creator>
 <dc:creator>Draffin, Ben</dc:creator>
 <dc:creator>Agrawal, Adwiteeya</dc:creator>
 <dc:creator>Sekar, Vyas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Let's Encrypt is a new entrant in the Certificate Authority ecosystem that
offers free and automated certificate signing. It is visionary in its
commitment to Certificate Transparency. In this paper, we shed light on the
adoption patterns of Let's Encrypt &quot;in the wild&quot; and inform the future design
and deployment of this exciting development in the security landscape. We
analyze acquisition patterns of certificates as well as their usage and
deployment trends in the real world. To this end, we analyze data from
Certificate Transparency Logs containing records of more then 18 million
certificates. We also leverage other sources like Censys, Alexa's historic
records, Geolocation databases, and VirusTotal. We also perform active HTTPS
measurements on the domains owning Let's Encrypt certificates. Our analysis of
certificate acquisition shows that (1) the impact of Let's Encrypt is
particularly visible in Western Europe; (2) Let's Encrypt has the potential to
democratize HTTPS adoption in countries that are recent entrants to Internet
adoption; (3) there is anecdotal evidence of popular domains quitting their
previously untrustworthy or expensive CAs in order to transition to Let's
Encrypt; and (4) there is a &quot;heavy tailed&quot; behavior where a small number of
domains acquire a large number of certificates. With respect to usage, we find
that: (1) only 54% of domains actually use the Let's Encrypt certificates they
have procured; (2) there are many non-trivial incidents of server
misconfigurations; and (3) there is early evidence of use of Let's Encrypt
certificates for typosquatting and for malware-laden sites.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00471</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Attention Networks for Multimodal Reasoning and Matching</dc:title>
 <dc:creator>Nam, Hyeonseob</dc:creator>
 <dc:creator>Ha, Jung-Woo</dc:creator>
 <dc:creator>Kim, Jeonghee</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose Dual Attention Networks (DANs) which jointly leverage visual and
textual attention mechanisms to capture fine-grained interplay between vision
and language. DANs attend to specific regions in images and words in text
through multiple steps and gather essential information from both modalities.
Based on this framework, we introduce two types of DANs for multimodal
reasoning and matching, respectively. The reasoning model allows visual and
textual attentions to steer each other during collaborative inference, which is
useful for tasks such as Visual Question Answering (VQA). In addition, the
matching model exploits the two attention mechanisms to estimate the similarity
between images and sentences by focusing on their shared semantics. Our
extensive experiments validate the effectiveness of DANs in combining vision
and language, achieving the state-of-the-art performance on public benchmarks
for VQA and image-text matching.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00472</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Sub-Word Level Compositions for Sentiment Analysis of
  Hindi-English Code Mixed Text</dc:title>
 <dc:creator>Prabhu, Ameya</dc:creator>
 <dc:creator>Joshi, Aditya</dc:creator>
 <dc:creator>Shrivastava, Manish</dc:creator>
 <dc:creator>Varma, Vasudeva</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Sentiment analysis (SA) using code-mixed data from social media has several
applications in opinion mining ranging from customer satisfaction to social
campaign analysis in multilingual societies. Advances in this area are impeded
by the lack of a suitable annotated dataset. We introduce a Hindi-English
(Hi-En) code-mixed dataset for sentiment analysis and perform empirical
analysis comparing the suitability and performance of various state-of-the-art
SA methods in social media.
  In this paper, we introduce learning sub-word level representations in LSTM
(Subword-LSTM) architecture instead of character-level or word-level
representations. This linguistic prior in our architecture enables us to learn
the information about sentiment value of important morphemes. This also seems
to work well in highly noisy text containing misspellings as shown in our
experiments which is demonstrated in morpheme-level feature maps learned by our
model. Also, we hypothesize that encoding this linguistic prior in the
Subword-LSTM architecture leads to the superior performance. Our system attains
accuracy 4-5% greater than traditional approaches on our dataset, and also
outperforms the available system for sentiment analysis in Hi-En code-mixed
text by 18%.
</dc:description>
 <dc:description>Comment: Accepted paper at COLING 2016</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00481</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Multi-view Clustering with Incomplete Views</dc:title>
 <dc:creator>Shao, Weixiang</dc:creator>
 <dc:creator>He, Lifang</dc:creator>
 <dc:creator>Lu, Chun-Ta</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In the era of big data, it is common to have data with multiple modalities or
coming from multiple sources, known as &quot;multi-view data&quot;. Multi-view clustering
provides a natural way to generate clusters from such data. Since different
views share some consistency and complementary information, previous works on
multi-view clustering mainly focus on how to combine various numbers of views
to improve clustering performance. However, in reality, each view may be
incomplete, i.e., instances missing in the view. Furthermore, the size of data
could be extremely huge. It is unrealistic to apply multi-view clustering in
large real-world applications without considering the incompleteness of views
and the memory requirement. None of previous works have addressed all these
challenges simultaneously. In this paper, we propose an online multi-view
clustering algorithm, OMVC, which deals with large-scale incomplete views. We
model the multi-view clustering problem as a joint weighted nonnegative matrix
factorization problem and process the multi-view data chunk by chunk to reduce
the memory requirement. OMVC learns the latent feature matrices for all the
views and pushes them towards a consensus. We further increase the robustness
of the learned latent feature matrices in OMVC via lasso regularization. To
minimize the influence of incompleteness, dynamic weight setting is introduced
to give lower weights to the incoming missing instances in different views.
More importantly, to reduce the computational time, we incorporate a faster
projected gradient descent by utilizing the Hessian matrices in OMVC. Extensive
experiments conducted on four real data demonstrate the effectiveness of the
proposed OMVC method.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00483</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Context Dependent Messages in a Conversational Environment</dc:title>
 <dc:creator>Li, Chaozhuo</dc:creator>
 <dc:creator>Wu, Yu</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:creator>Xing, Chen</dc:creator>
 <dc:creator>Li, Zhoujun</dc:creator>
 <dc:creator>Zhou, Ming</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  While automatic response generation for building chatbot systems has drawn a
lot of attention recently, there is limited understanding on when we need to
consider the linguistic context of an input text in the generation process. The
task is challenging, as messages in a conversational environment are short and
informal, and evidence that can indicate a message is context dependent is
scarce. After a study of social conversation data crawled from the web, we
observed that some characteristics estimated from the responses of messages are
discriminative for identifying context dependent messages. With the
characteristics as weak supervision, we propose using a Long Short Term Memory
(LSTM) network to learn a classifier. Our method carries out text
representation and classifier learning in a unified framework. Experimental
results show that the proposed method can significantly outperform baseline
methods on accuracy of classification.
</dc:description>
 <dc:description>Comment: Accepted paper at COLING 2016</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00484</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RECOME: a New Density-Based Clustering Algorithm Using Relative KNN
  Kernel Density</dc:title>
 <dc:creator>Geng, Yangli-ao</dc:creator>
 <dc:creator>Li, Qingyong</dc:creator>
 <dc:creator>Zheng, Rong</dc:creator>
 <dc:creator>Zhuangz, Fuzhen</dc:creator>
 <dc:creator>He, Ruisi</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Discovering clusters from a dataset with different shapes, density, and
scales is a known challenging problem in data clustering. In this paper, we
propose the RElative COre MErge (RECOME) clustering algorithm. The core of
RECOME is a novel density measure, i.e., Relative $K$ nearest Neighbor Kernel
Density (RNKD). RECOME identifies core objects with unit RNKD, and partitions
non-core objects into atom clusters by successively following higher-density
neighbor relations toward core objects. Core objects and their corresponding
atom clusters are then merged through $\alpha$-reachable paths on a KNN graph.
Furthermore, we discover that the number of clusters computed by RECOME is a
step function of the $\alpha$ parameter with jump discontinuity on a small
collection of values. A jump discontinuity discovery (JDD) method is proposed
using a variant of the Dijkstra's algorithm. RECOME is evaluated on three
synthetic datasets and six real datasets. Experimental results indicate that
RECOME is able to discover clusters with different shapes, density and scales.
It achieves better clustering results than established density-based clustering
methods on real datasets. Moreover, JDD is shown to be effective to extract the
jump discontinuity set of parameter $\alpha$ for all tested dataset, which can
ease the task of data exploration and parameter tuning.
</dc:description>
 <dc:description>Comment: This version has updated Section 3 and Section 4</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00491</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A High Throughput Pilot Allocation for M2M Communication in Crowded
  Massive MIMO Systems</dc:title>
 <dc:creator>Han, Huimei</dc:creator>
 <dc:creator>Guo, Xudong</dc:creator>
 <dc:creator>Li, Ying</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A new scheme to resolve the intra-cell pilot collision for M2M communication
in crowded massive multiple-input multiple-output (MIMO) systems is proposed.
The proposed scheme permits those failed user equipments (UEs), judged by a
strongest-user collision resolution (SUCR) protocol, to contend for the idle
pilots, i.e., the pilots that are not selected by any UE in the initial step.
This scheme is called as SUCR combined idle pilots access (SUCR-IPA). To
analyze the performance of the SUCR-IPA scheme, we develop a simple method to
compute the access success probability of the UEs in each random access slot
(RAST). The simulation results coincide well with the analysis. It is also
shown that, compared to the SUCR protocol, the proposed SUCR-IPA scheme
increases the throughput of the system significantly, and thus decreases the
number of access attempts dramatically.
</dc:description>
 <dc:description>Comment: 5 pages,6 figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00502</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Algorithmic Proof of the Symmetric Lopsided Lov\'{a}sz Local
  Lemma</dc:title>
 <dc:creator>Kirousis, Lefteris</dc:creator>
 <dc:creator>Livieratos, John</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We provide a simple algorithmic proof for the symmetric Lopsided Lov\'{a}sz
Local Lemma, a variant of the classic Lov\'{a}sz Local Lemma, where, roughly,
only the degree of the negatively correlated undesirable events counts. Our
analysis refers to the algorithm by Moser (2009), however it is based on a
simple application of the probabilistic method, rather than a counting
argument, as are most of the analyses of algorithms for variants of the
Lov\'{a}sz Local Lemma.
</dc:description>
 <dc:description>Comment: Added examples and figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00507</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Worst Case Competitive Analysis of Online Algorithms for Conic
  Optimization</dc:title>
 <dc:creator>Eghbali, Reza</dc:creator>
 <dc:creator>Fazel, Maryam</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Online optimization covers problems such as online resource allocation,
online bipartite matching, adwords (a central problem in e-commerce and
advertising), and adwords with separable concave returns. We analyze the worst
case competitive ratio of two primal-dual algorithms for a class of online
convex (conic) optimization problems that contains the previous examples as
special cases defined on the positive orthant. We derive a sufficient condition
on the objective function that guarantees a constant worst case competitive
ratio (greater than or equal to $\frac{1}{2}$) for monotone objective
functions. We provide new examples of online problems on the positive orthant
and the positive semidefinite cone that satisfy the sufficient condition. We
show how smoothing can improve the competitive ratio of these algorithms, and
in particular for separable functions, we show that the optimal smoothing can
be derived by solving a convex optimization problem. This result allows us to
directly optimize the competitive ratio bound over a class of smoothing
functions, and hence design effective smoothing customized for a given cost
function.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00510</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ancilla-driven instantaneous quantum polynomial time circuit for quantum
  supremacy</dc:title>
 <dc:creator>Takeuchi, Yuki</dc:creator>
 <dc:creator>Takahashi, Yasuhiro</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Instantaneous quantum polynomial time (IQP) is a model of (probably)
non-universal quantum computation. Since it has been proven that IQP circuits
are unlikely to be simulated classically up to a multiplicative error and an
error in the $l_1$ norm, IQP is considered as one of the promising classes that
demonstrates quantum supremacy. Although IQP circuits can be realized more
easily than a universal quantum computer, demonstrating quantum supremacy is
still difficult. It is therefore desired to find subclasses of IQP that are
easy to implement. In this paper, by imposing some restrictions on IQP, we
propose ancilla-driven IQP (ADIQP) as the subclass of commuting quantum
computation suitable for many experimental settings. We show that even though
ADIQP circuits are strictly weaker than IQP circuits in a sense, they are also
hard to simulate classically up to a multiplicative error and an error in the
$l_1$ norm. Moreover, the properties of ADIQP make it easy to investigate the
verifiability of ADIQP circuits and the difficulties in realizing ADIQP
circuits.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00510</dc:identifier>
 <dc:identifier>Phys. Rev. A 94, 062336 (2016)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.94.062336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00514</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Intelligent Voice 2016 Speaker Recognition System</dc:title>
 <dc:creator>Khosravani, Abbas</dc:creator>
 <dc:creator>Glackin, Cornelius</dc:creator>
 <dc:creator>Dugan, Nazim</dc:creator>
 <dc:creator>Chollet, G&#xe9;rard</dc:creator>
 <dc:creator>Cannings, Nigel</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents the Intelligent Voice (IV) system submitted to the NIST
2016 Speaker Recognition Evaluation (SRE). The primary emphasis of SRE this
year was on developing speaker recognition technology which is robust for novel
languages that are much more heterogeneous than those used in the current
state-of-the-art, using significantly less training data, that does not contain
meta-data from those languages. The system is based on the state-of-the-art
i-vector/PLDA which is developed on the fixed training condition, and the
results are reported on the protocol defined on the development set of the
challenge.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, NIST SRE 2016 Workshop</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00518</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dynamic Multi Agent based scheduling for flexible flow line
  manufacturing system accompanied by dynamic customer demand</dc:title>
 <dc:creator>Roudi, Daniral</dc:creator>
 <dc:creator>Barenji, Ali Vatankhah</dc:creator>
 <dc:creator>Barenji, Reza Vatankhah</dc:creator>
 <dc:creator>Hashemipour, Majid</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Dynamic rescheduling decision-making problem is an important issue in modern
manufacturing system with the feature of combinational computation complexity.
This paper introduces a multi-agent based approach using the detailed process,
provided by Prometheus methodology, which used for the design of a simultaneous
dynamic rescheduling decision making for flexible flow line manufacturing
system that working under dynamic customer demand. The application has been
completely modeled with the Prometheus Design Tool (PDT), which offers full
support to Prometheus Methodology. The proposed dynamic scheduling decision
making system is developed for Automated UPVC door and Windows Company and can
be support both static and dynamic scheduling.
</dc:description>
 <dc:description>Comment: Conference</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00522</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized Thermal-Aware Job Scheduling and Control of Data Centers</dc:title>
 <dc:creator>Van Damme, Tobias</dc:creator>
 <dc:creator>De Persis, Claudio</dc:creator>
 <dc:creator>Tesi, Pietro</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Analyzing data centers with thermal-aware optimization techniques is a viable
approach to reduce energy consumption of data centers. By taking into account
thermal consequences of job placements among the servers of a data center, it
is possible to reduce the amount of cooling necessary to keep the servers below
a given safe temperature threshold. We set up an optimization problem to
analyze and characterize the optimal setpoints for the workload distribution
and the supply temperature of the cooling equipment. Furthermore under mild
assumptions we design and analyze controllers that drive the data center to the
optimal state without knowledge of the current total workload to be handled by
the data center. The response of our controller is validated by simulations and
convergence to the optimal setpoints is achieved under varying workload
conditions.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00531</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modal Analysis of Masonry Structures</dc:title>
 <dc:creator>Girardi, Maria</dc:creator>
 <dc:creator>Padovani, Cristina</dc:creator>
 <dc:creator>Pellegrini, Daniele</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  This paper presents a new numerical procedure for evaluating the vibration
frequencies and mode shapes of masonry buildings in the presence of cracks. The
algorithm has been implemented within the NOSA-ITACA code, which models masonry
as a nonlinear elastic material with zero tensile strength. Some case studies
are reported, and the differences between linear and nonlinear behavior
highlighted.
</dc:description>
 <dc:description>Comment: 50 pages, 23 figures, 7 tables</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00532</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An asymptotically optimal, online algorithm for weighted random sampling
  with replacement</dc:title>
 <dc:creator>Startek, Micha&#x142;</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  This paper presents a novel algorithm solving the classic problem of
generating a random sample of size s from population of size n with non-uniform
probabilities. The sampling is done with replacement. The algorithm requires
constant additional memory, and works in O(n) time (even when s &gt;&gt; n, in which
case the algorithm produces a list containing, for every population member, the
number of times it has been selected for sample). The algorithm works online,
and as such is well-suited to processing streams. In addition, a novel method
of mass-sampling from any discrete distribution using the algorithm is
presented.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00538</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An application of incomplete pairwise comparison matrices for ranking
  top tennis players</dc:title>
 <dc:creator>Boz&#xf3;ki, S&#xe1;ndor</dc:creator>
 <dc:creator>Csat&#xf3;, L&#xe1;szl&#xf3;</dc:creator>
 <dc:creator>Temesi, J&#xf3;zsef</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Pairwise comparison is an important tool in multi-attribute decision making.
Pairwise comparison matrices (PCM) have been applied for ranking criteria and
for scoring alternatives according to a given criterion. Our paper presents a
special application of incomplete PCMs: ranking of professional tennis players
based on their results against each other. The selected 25 players have been on
the top of the ATP rankings for a shorter or longer period in the last 40
years. Some of them have never met on the court. One of the aims of the paper
is to provide ranking of the selected players, however, the analysis of
incomplete pairwise comparison matrices is also in the focus. The eigenvector
method and the logarithmic least squares method were used to calculate weights
from incomplete PCMs. In our results the top three players of four decades were
Nadal, Federer and Sampras. Some questions have been raised on the properties
of incomplete PCMs and remains open for further investigation.
</dc:description>
 <dc:description>Comment: 14 pages, 2 figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00538</dc:identifier>
 <dc:identifier>European Journal of Operational Research (2016). 248(1): 211-218</dc:identifier>
 <dc:identifier>doi:10.1016/j.ejor.2015.06.069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00547</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Limitations and Alternatives for the Evaluation of Large-scale Link
  Prediction</dc:title>
 <dc:creator>Garcia-Gasulla, Dario</dc:creator>
 <dc:creator>Ayguad&#xe9;, Eduard</dc:creator>
 <dc:creator>Labarta, Jes&#xfa;s</dc:creator>
 <dc:creator>Cort&#xe9;s, Ulises</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Link prediction, the problem of identifying missing links among a set of
inter-related data entities, is a popular field of research due to its
application to graph-like domains. Producing consistent evaluations of the
performance of the many link prediction algorithms being proposed can be
challenging due to variable graph properties, such as size and density. In this
paper we first discuss traditional data mining solutions which are applicable
to link prediction evaluation, arguing about their capacity for producing
faithful and useful evaluations. We also introduce an innovative modification
to a traditional evaluation methodology with the goal of adapting it to the
problem of evaluating link prediction algorithms when applied to large graphs,
by tackling the problem of class imbalance. We empirically evaluate the
proposed methodology and, building on these findings, make a case for its
importance on the evaluation of large-scale graph processing.
</dc:description>
 <dc:description>Comment: Submitted to New Generation Computing, 15 pages, 4 tables, 4 figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00549</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring Coupling of Distributed Dynamical Systems via Transfer Entropy</dc:title>
 <dc:creator>Cliff, Oliver M.</dc:creator>
 <dc:creator>Prokopenko, Mikhail</dc:creator>
 <dc:creator>Fitch, Robert</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work, we are interested in structure learning for a set of spatially
distributed dynamical systems, where individual subsystems are coupled via
latent variables and observed through a filter. We represent this model as a
directed acyclic graph (DAG) that characterises the unidirectional coupling
between subsystems. Standard approaches to structure learning are not
applicable in this framework due to the hidden variables, however we can
exploit the properties of certain dynamical systems to formulate exact methods
based on state space reconstruction. We approach the problem by using
reconstruction theorems to analytically derive a tractable expression for the
KL-divergence of a candidate DAG from the observed dataset. We show this
measure can be decomposed as a function of two information-theoretic measures,
transfer entropy and stochastic interaction. We then present two mathematically
robust scoring functions based on transfer entropy and statistical independence
tests. These results support the previously held conjecture that transfer
entropy can be used to infer effective connectivity in complex networks.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00558</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online bagging for recommendation with incremental matrix factorization</dc:title>
 <dc:creator>Vinagre, Jo&#xe3;o</dc:creator>
 <dc:creator>Jorge, Al&#xed;pio M&#xe1;rio</dc:creator>
 <dc:creator>Gama, Jo&#xe3;o</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Online recommender systems often deal with continuous, potentially fast and
unbounded flows of data. Ensemble methods for recommender systems have been
used in the past in batch algorithms, however they have never been studied with
incremental algorithms, that are capable of processing those data streams on
the fly. We propose online bagging, using an incremental matrix factorization
algorithm for positive-only data streams. Using prequential evaluation, we show
that bagging is able to improve accuracy more than 35% over the baseline with
small computational overhead.
</dc:description>
 <dc:description>Comment: Presented at STREAMEVOLV 2016, held in conjunction with ECML/PKDD
  2016, Riva del Garda, Italy, September 23rd, 2016</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00559</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Algorithm for Demand Response with Inelastic Demands and Apparent
  Power Constraint</dc:title>
 <dc:creator>Karapetyan, Areg</dc:creator>
 <dc:creator>Khonji, Majid</dc:creator>
 <dc:creator>Chau, Chi-Kin</dc:creator>
 <dc:creator>Elbassioni, Khaled</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  A classical problem in power systems is to allocate in-coming (elastic or
inelastic) demands without violating the operating constraints of electric
networks in an online fashion. Although online decision problems have been
well-studied in the literature, a unique challenge arising in power systems is
the presence of non-linear constraints, a departure from the traditional
settings. A particular example is the capacity constraint of apparent power,
which gives rise to a quadratic constraint, rather than typical linear
constraints. In this paper, we present a competitive randomized online
algorithm for deciding whether a sequence of inelastic demands can be allocated
for the requested intervals, subject to the total satisfiable apparent power
within a time-varying capacity constraint. We also consider an alternative
setting with nodal voltage constraint, using a variant of the online algorithm.
Finally, simulation studies are provided to evaluate the algorithms
empirically.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00566</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Architecture Modularisation and Slicing for Next Generation
  Networks</dc:title>
 <dc:creator>An, Xueli</dc:creator>
 <dc:creator>Trivisonno, Riccardo</dc:creator>
 <dc:creator>Einsiedler, Hans</dc:creator>
 <dc:creator>von Hugo, Dirk</dc:creator>
 <dc:creator>Haensge, Kay</dc:creator>
 <dc:creator>Huang, Xiaofeng</dc:creator>
 <dc:creator>Shen, Qing</dc:creator>
 <dc:creator>Corujo, Daniel</dc:creator>
 <dc:creator>Mahmood, Kashif</dc:creator>
 <dc:creator>Trossen, Dirk</dc:creator>
 <dc:creator>Liebsch, Marco</dc:creator>
 <dc:creator>Leitao, Filipe</dc:creator>
 <dc:creator>Phan, Cao-Thanh</dc:creator>
 <dc:creator>Klamm, Frederic</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>68M10</dc:subject>
 <dc:description>  The journey towards the deployment of next generation networks has recently
accelerated, driven by the joint effort of research and standards
organisations. Despite this fact, the overall picture is still unclear as
prioritization and understanding on several key concepts are not yet agreed by
major vendors and network providers. Network Slicing is one of the central
topics of the debate, and it is expected to become the key feature of next
generation networks, providing the flexibility required to support the variety
of 5G use cases and business. Network slices are seen as network operator
business, offering the possibility to provide flexible services and even
infrastructures to vertical industries and classical Telco customers alike.
Another key ingredient is the Architecture Modularisation concept, discussed in
this paper and regarded by the authors as the essential design principle to
build a flexible network architecture natively supporting Network Slicing.
According to this concept, conventional monolithic network functions, often
corresponding to physical network elements in the existing systems, are to
split into basic building blocks defined with the proper granularity, allowing
the definition of different logical architectures (i.e. different Network
Slices). In this paper, we further discuss a modularisation methodology as a
criteria to define the right set of basic building blocks. Defined through this
proposed methodology, the set of basic building blocks and the relating
interfacing model are discussed. The paper concludes by proposing a modular 5G
network architecture as candidate for next generation network standards.
</dc:description>
 <dc:description>Comment: 13 pages, 5 Figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00568</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Link Formation, Persistence and Dissolution in NetSense Data</dc:title>
 <dc:creator>Bahulkar, Ashwin</dc:creator>
 <dc:creator>Szymanski, Boleslaw K.</dc:creator>
 <dc:creator>Lizardo, Omar</dc:creator>
 <dc:creator>Dong, Yuxiao</dc:creator>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Chawla, Nitesh V.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We study a unique behavioral network data set (based on periodic surveys and
on electronic logs of dyadic contact via smartphones) collected at the
University of Notre Dame.The participants are a sample of members of the
entering class of freshmen in the fall of 2011 whose opinions on a wide variety
of political and social issues and activities on campus were regularly recorded
- at the beginning and end of each semester - for the first three years of
their residence on campus. We create a communication activity network implied
by call and text data, and a friendship network based on surveys. Both networks
are limited to students participating in the NetSense surveys. We aim at
finding student traits and activities on which agreements correlate well with
formation and persistence of links while disagreements are highly correlated
with non-existence or dissolution of links in the two social networks that we
created. Using statistical analysis and machine learning, we observe several
traits and activities displaying such correlations, thus being of potential use
to predict social network evolution.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00568</dc:identifier>
 <dc:identifier>Proc. 2016 IEEE/ACM International Conference on Advances in Social
  Networks Analysis and Mining (ASONAM), San Francisco, CA, August 18-21, 2016,
  pp. 1197-1204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00574</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compositional Reasoning for Shared-variable Concurrent Programs</dc:title>
 <dc:creator>Zhang, Fuyuan</dc:creator>
 <dc:creator>Zhao, Yongwang</dc:creator>
 <dc:creator>Sanan, David</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Tiu, Alwen</dc:creator>
 <dc:creator>Lin, Shang-Wei</dc:creator>
 <dc:creator>Wu, Zhimin</dc:creator>
 <dc:creator>Sun, Jun</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Scalable and automatic formal verification for concurrent systems is always
demanding, but yet to be developed. In this paper, we propose a verification
framework to support automated compositional reasoning for concurrent programs
with shared variables. Our framework models concurrent programs as succinct
automata and supports the verification of multiple important properties. Safety
verification and simulations of succinct automata are parallel compositional,
and safety properties of succinct automata are preserved under refinements.
Formal verification of finite state succinct automata can be automated.
Furthermore, we propose the first automated approach to checking rely-guarantee
based simulations between infinite state concurrent programs. We have
prototyped our algorithm and applied our tool to the verification of multiple
refinements.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00576</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strong Neutrosophic Graphs and Subgraph Topological Subspaces</dc:title>
 <dc:creator>Kandasamy, W. B. Vasantha</dc:creator>
 <dc:creator>K, Ilanthenral</dc:creator>
 <dc:creator>Smarandache, Florentin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  In this book authors for the first time introduce the notion of strong
neutrosophic graphs. They are very different from the usual graphs and
neutrosophic graphs. Using these new structures special subgraph topological
spaces are defined. Further special lattice graph of subgraphs of these graphs
are defined and described. Several interesting properties using subgraphs of a
strong neutrosophic graph are obtained. Several open conjectures are proposed.
These new class of strong neutrosophic graphs will certainly find applications
in Neutrosophic Cognitive Maps (NCM), Neutrosophic Relational Maps (NRM) and
Neutrosophic Relational Equations (NRE) with appropriate modifications.
</dc:description>
 <dc:description>Comment: 226 pages, many graphs, Europa Belgique, 2016</dc:description>
 <dc:date>2016-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00577</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The new hybrid COAW method for solving multi-objective problems</dc:title>
 <dc:creator>Borhanifar, Zeinab</dc:creator>
 <dc:creator>Shadkam, Elham</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this article using Cuckoo Optimization Algorithm and simple additive
weighting method the hybrid COAW algorithm is presented to solve
multi-objective problems. Cuckoo algorithm is an efficient and structured
method for solving nonlinear continuous problems. The created Pareto frontiers
of the COAW proposed algorithm are exact and have good dispersion. This method
has a high speed in finding the Pareto frontiers and identifies the beginning
and end points of Pareto frontiers properly. In order to validation the
proposed algorithm, several experimental problems were analyzed. The results of
which indicate the proper effectiveness of COAW algorithm for solving
multi-objective problems.
</dc:description>
 <dc:date>2016-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00577</dc:identifier>
 <dc:identifier>doi:10.5121/ijfcst.2015.5602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00578</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking Web-testing - Selenium versus Watir and the Choice of
  Programming Language and Browser</dc:title>
 <dc:creator>Kuutila, Miikka</dc:creator>
 <dc:creator>M&#xe4;ntyl&#xe4;, Mika</dc:creator>
 <dc:creator>Raulamo-Jurvanen, P&#xe4;ivi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Context: Selenium is claimed to be the most popular software test automation
tool. Past academic works have mainly neglected testing tools in favor of more
methodological topics. Objective: We investigated the performance of
web-testing tools, to provide empirical evidence supporting choices in software
test tool selection and configuration. Method: We used 4*5 factorial design to
study 20 different configurations for testing a web-store. We studied 5
programming language bindings (C#, Java, Python, and Ruby for Selenium, while
Watir supports Ruby only) and 4 browsers (Google Chrome, Internet Explorer,
Mozilla Firefox and Opera). Performance was measured with execution time,
memory usage, length of the test scripts and stability of the tests. Results:
Considering all measures the best configuration was Selenium with Python
language binding for Chrome. Selenium with Python bindings was the best option
for all browsers. The effect size of the difference between the slowest and
fastest configuration was very high (Cohens d=41.5, 91% increase in execution
time). Overall Internet Explorer was the fastest browser while having the worst
results in the stability. Conclusions: We recommend benchmarking tools before
adopting them. Weighting of factors, e.g. how much test stability is one
willing to sacrifice for faster performance, affects the decision.
</dc:description>
 <dc:description>Comment: 40 pages, 3 figures, 26 tables</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00580</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Verifying Causal Consistency</dc:title>
 <dc:creator>Bouajjani, Ahmed</dc:creator>
 <dc:creator>Enea, Constantin</dc:creator>
 <dc:creator>Guerraoui, Rachid</dc:creator>
 <dc:creator>Hamza, Jad</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Causal consistency is one of the most adopted consistency criteria for
distributed implementations of data structures. It ensures that operations are
executed at all sites according to their causal precedence. We address the
issue of verifying automatically whether the executions of an implementation of
a data structure are causally consistent. We consider two problems: (1)
checking whether one single execution is causally consistent, which is relevant
for developing testing and bug finding algorithms, and (2) verifying whether
all the executions of an implementation are causally consistent.
  We show that the first problem is NP-complete. This holds even for the
read-write memory abstraction, which is a building block of many modern
distributed systems. Indeed, such systems often store data in key-value stores,
which are instances of the read-write memory abstraction. Moreover, we prove
that, surprisingly, the second problem is undecidable, and again this holds
even for the read-write memory abstraction. However, we show that for the
read-write memory abstraction, these negative results can be circumvented if
the implementations are data independent, i.e., their behaviors do not depend
on the data values that are written or read at each moment, which is a
realistic assumption.
</dc:description>
 <dc:description>Comment: extended version of POPL 2017</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00582</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards High-Efficiency Cascading Outage Simulation and Analysis in
  Power Systems: A Sequential Importance Sampling Approach</dc:title>
 <dc:creator>Guo, Jinpeng</dc:creator>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Wang, Jianhui</dc:creator>
 <dc:creator>Lin, Junhao</dc:creator>
 <dc:creator>Mei, Shengwei</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  This paper addresses how to improve the computational efficiency and
estimation reliability in cascading outage analysis. We first formulate a
cascading outage as a Markov chain with specific state space and transition
probability by leveraging the Markov property of cascading outages. It provides
a rigorous formulation that allows analytic investigation on cascading outages
in the framework of standard mathematical statistics. Then we derive a
sequential importance sampling (SIS) based simulation strategy for cascading
outage simulation and blackout risk analysis with theoretical justification.
Numerical experiments manifest that the proposed SIS strategy can significantly
bring down the number of simulations and reduce the estimation variance of
cascading outage analysis compared with the traditional Monte Carlo simulation
strategy.
</dc:description>
 <dc:date>2016-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00586</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed MPC: Guaranteeing Global Stabilizability from Locally
  Designed Tubes</dc:title>
 <dc:creator>Hernandez, Bernardo</dc:creator>
 <dc:creator>Baldivieso, Pablo</dc:creator>
 <dc:creator>Trodden, Paul</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies a fundamental relation that exists between stabilizability
assumptions usually employed in distributed model predictive control
implementations, and the corresponding notions of invariance implicit in such
controllers. The relation is made explicit in the form of a theorem that
presents sufficient conditions for global stabilizability. It is shown that
constraint admissibility of local robust controllers is sufficient for the
global closed-loop system to be stable, and how these controllers are related
to more complex forms of control such as tube-based distributed model
predictive control implementations.
</dc:description>
 <dc:description>Comment: Submitted to the IFAC World Congress 2017 (Toulouse)</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00591</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Networks for HDR imaging</dc:title>
 <dc:creator>Sheth, Kshiteej</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose novel methods of solving two tasks using Convolutional Neural
Networks, firstly the task of generating HDR map of a static scene using
differently exposed LDR images of the scene captured using conventional cameras
and secondly the task of finding an optimal tone mapping operator that would
give a better score on the TMQI metric compared to the existing methods. We
quantitatively show the performance of our networks and illustrate the cases
where our networks performs good as well as bad.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00598</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A bioinformatics system for searching Co-Occurrence based on
  Co-Operational Formation with Advanced Method (COCOFAM)</dc:title>
 <dc:creator>Park, Junseok</dc:creator>
 <dc:creator>Kim, Gwangmin</dc:creator>
 <dc:creator>Jang, Dongjin</dc:creator>
 <dc:creator>Choo, Sungji</dc:creator>
 <dc:creator>Bae, Sunghwa</dc:creator>
 <dc:creator>Lee, Doheon</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.1.2</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:description>  Literature analysis is a key step in obtaining background information in
biomedical research. However, it is difficult for researchers to obtain
knowledge of their interests in an efficient manner because of the massive
amount of the published biomedical literature. Therefore, efficient and
systematic search strategies are required, which allow ready access to the
substantial amount of literature. In this paper, we propose a novel search
system, named Co-Occurrence based on Co-Operational Formation with Advanced
Method(COCOFAM) which is suitable for the large-scale literature analysis.
COCOFAM is based on integrating both Spark for local clusters and a global job
scheduler to gather crowdsourced co-occurrence data on global clusters. It will
allow users to obtain information of their interests from the substantial
amount of literature.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00601</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ordinal Common-sense Inference</dc:title>
 <dc:creator>Zhang, Sheng</dc:creator>
 <dc:creator>Rudinger, Rachel</dc:creator>
 <dc:creator>Duh, Kevin</dc:creator>
 <dc:creator>Van Durme, Benjamin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Humans have the capacity to draw common-sense inferences from natural
language: various things that are likely but not certain to hold based on
established discourse, and are rarely stated explicitly. We propose an
evaluation of automated common-sense inference based on an extension of
recognizing textual entailment: predicting ordinal human responses on the
subjective likelihood of an inference holding in a given context. We describe a
framework for extracting common-sense knowledge from corpora, which is then
used to construct a dataset for this ordinal entailment task. We train a neural
sequence-to-sequence model on this dataset, which we use to score and generate
possible inferences. Further, we annotate subsets of previously established
datasets via our ordinal annotation protocol in order to then analyze the
distinctions between these and what we have constructed.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00602</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scala-gopher: CSP-style programming techniques with idiomatic Scala</dc:title>
 <dc:creator>Shevchenko, Ruslan</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Cala-gopher is a library-level Scala implementation of communication sequence
process constructs: channels, selectors (similar to analogical constructs in
Limbo or Go) transputers (similar to Occam proc) and a set of high-level
operations on top of akka and SIP-22 async. The framework integrates CSP-style
programming into standard Scala concurrency environment via idiomatic API. This
allows usage of communication patterns, well known in Go world, but not easy
expressable in mainstream scala concurrency frameworks, along with algebraic
approach for composing computation builders. Besides, we want to discuss
current implementation issues and future directions in the context of evolving
of compiler and libraries ecosystem.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00606</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid CPU-GPU generation of the Hamiltonian and Overlap matrices in
  FLAPW methods</dc:title>
 <dc:creator>Fabregat-Traver, Diego</dc:creator>
 <dc:creator>Davidovi&#x107;, Davor</dc:creator>
 <dc:creator>H&#xf6;hnerbach, Markus</dc:creator>
 <dc:creator>Di Napoli, Edoardo</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  In this paper we focus on the integration of high-performance numerical
libraries in ab initio codes and the portability of performance and
scalability. The target of our work is FLEUR, a software for electronic
structure calculations developed in the Forschungszentrum J\&quot;ulich over the
course of two decades. The presented work follows up on a previous effort to
modernize legacy code by re-engineering and rewriting it in terms of highly
optimized libraries. We illustrate how this initial effort to get efficient and
portable shared-memory code enables fast porting of the code to emerging
heterogeneous architectures. More specifically, we port the code to nodes
equipped with multiple GPUs. We divide our study in two parts. First, we show
considerable speedups attained by minor and relatively straightforward code
changes to off-load parts of the computation to the GPUs. Then, we identify
further possible improvements to achieve even higher performance and
scalability. On a system consisting of 16-cores and 2 GPUs, we observe speedups
of up to 5x with respect to our optimized shared-memory code, which in turn
means between 7.5x and 12.5x speedup with respect to the original FLEUR code.
</dc:description>
 <dc:date>2016-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00616</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Quaternion Variational Integrator for Rigid Body Dynamic Simulation</dc:title>
 <dc:creator>Xu, Jiafeng</dc:creator>
 <dc:creator>Halse, Karl Henning</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  We introduce a symplectic dual quaternion variational integrator(DQVI) for
simulating single rigid body motion in all six degrees of freedom. Dual
quaternion is used to represent rigid body kinematics and one-step Lie group
variational integrator is used to conserve the geometric structure, energy and
momentum of the system during the simulation. The combination of these two
becomes the first Lie group variational integrator for rigid body simulation
without decoupling translations and rotations. Newton-Raphson method is used to
solve the recursive dynamic equation. This method is suitable for real-time
rigid body simulations with high precision under large time step. DQVI respects
the symplectic structure of the system with excellent long-term conservation of
geometry structure, momentum and energy. It also allows the reference point and
6-by-6 inertia matrix to be arbitrarily defined, which is very convenient for a
variety of engineering problems.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00617</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel 2D non-stationary wideband massive MIMO channel model</dc:title>
 <dc:creator>Lopez, C. F.</dc:creator>
 <dc:creator>Wang, C. -X.</dc:creator>
 <dc:creator>Feng, R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a novel two-dimensional (2D) non-stationary wideband
geometry-based stochastic model (GBSM) for massive multiple-input
multiple-output (MIMO) communication systems is proposed. Key characteristics
of massive MIMO channels such as near field effects and cluster evolution along
the array are addressed in this model. Near field effects are modelled by a
second-order approximation to spherical wavefronts, i.e., parabolic wavefronts,
leading to linear drifts of the angles of multipath components (MPCs) and
non-stationarity along the array. Cluster evolution along the array involving
cluster (dis)appearance and smooth average power variations is considered.
Cluster (dis)appearance is modeled by a two-state Markov process and smooth
average power variations are modelled by a spatial lognormal process.
Statistical properties of the channel model such as time autocorrelation
function (ACF), spatial cross-correlation function (CCF), and cluster average
power and Rician factor variations over the array are derived. Finally,
simulation results are presented and analyzed, demonstrating that parabolic
wavefronts and cluster soft evolution are good candidates to model important
massive MIMO channel characteristics.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, conference</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00617</dc:identifier>
 <dc:identifier>IEEE International Workshop on Computer Aided Modelling and Design
  of Communication Links and Networks (CAMAD), Toronto, Canada, Oct. 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00625</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TorchCraft: a Library for Machine Learning Research on Real-Time
  Strategy Games</dc:title>
 <dc:creator>Synnaeve, Gabriel</dc:creator>
 <dc:creator>Nardelli, Nantas</dc:creator>
 <dc:creator>Auvolat, Alex</dc:creator>
 <dc:creator>Chintala, Soumith</dc:creator>
 <dc:creator>Lacroix, Timoth&#xe9;e</dc:creator>
 <dc:creator>Lin, Zeming</dc:creator>
 <dc:creator>Richoux, Florian</dc:creator>
 <dc:creator>Usunier, Nicolas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:description>  We present TorchCraft, a library that enables deep learning research on
Real-Time Strategy (RTS) games such as StarCraft: Brood War, by making it
easier to control these games from a machine learning framework, here Torch.
This white paper argues for using RTS games as a benchmark for AI research, and
describes the design and components of TorchCraft.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00665</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial Prophet Inequalities</dc:title>
 <dc:creator>Rubinstein, Aviad</dc:creator>
 <dc:creator>Singla, Sahil</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We introduce a novel framework of Prophet Inequalities for combinatorial
valuation functions. For a (non-monotone) submodular objective function over an
arbitrary matroid feasibility constraint, we give an $O(1)$-competitive
algorithm. For a monotone subadditive objective function over an arbitrary
downward-closed feasibility constraint, we give an $O(\log n \log^2
r)$-competitive algorithm (where $r$ is the cardinality of the largest feasible
subset).
  Inspired by the proof of our subadditive prophet inequality, we also obtain
an $O(\log n \cdot \log^2 r)$-competitive algorithm for the Secretary Problem
with a monotone subadditive objective function subject to an arbitrary
downward-closed feasibility constraint. Even for the special case of a
cardinality feasibility constraint, our algorithm circumvents an
$\Omega(\sqrt{n})$ lower bound by Bateni, Hajiaghayi, and Zadimoghaddam
\cite{BHZ13-submodular-secretary_original} in a restricted query model.
  En route to our submodular prophet inequality, we prove a technical result of
independent interest: we show a variant of the Correlation Gap Lemma for
non-monotone submodular functions.
</dc:description>
 <dc:description>Comment: 28 Pages, SODA 2017</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00674</identifier>
 <datestamp>2017-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy paraphrases in learning word representations with a lexicon</dc:title>
 <dc:creator>Ke, Yuanzhi</dc:creator>
 <dc:creator>Hagiwara, Masafumi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A synonym of a polysemous word is usually only the paraphrase of one sense
among many. When lexicons are used to improve vector-space word
representations, such paraphrases are unreliable and bring noise to the
vector-space. The prior works use a coefficient to adjust the overall learning
of the lexicons. They regard the paraphrases equally. In this paper, we propose
a novel approach that regards the paraphrases diversely to alleviate the
adverse effects of polysemy. We annotate each paraphrase with a degree of
reliability. The paraphrases are randomly eliminated according to the degrees
when our model learns word representations. In this way, our approach drops the
unreliable paraphrases, keeping more reliable paraphrases at the same time. The
experimental results show that the proposed method improves the word vectors.
Our approach is an attempt to address the polysemy problem keeping one vector
per word. It makes the approach easier to use than the conventional methods
that estimate multiple vectors for a word. Our approach also outperforms the
prior works in the experiments.
</dc:description>
 <dc:description>Comment: Withdrawn. Our recent study shows that there is no significant
  difference when we remove some part of the lexicon with the method in the
  paper. We decided to withdraw this paper</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00675</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>emgr - The Empirical Gramian Framework</dc:title>
 <dc:creator>Himpe, Christian</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>93B99</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  Gramian matrices are a well-known encoding for properties of input-output
systems such as controllability, observability or minimality. These so called
system Gramian matrices were developed in linear system theory for applications
such as model order reduction of control systems. Empirical Gramian matrices
are an extension to the system Gramians for parametric and nonlinear systems as
well as a data-driven method of computation. The empirical Gramian framework
\emgr implements the empirical Gramians in a uniform and configurable manner,
with applications such as Gramian-based (nonlinear) model reduction,
decentralized control, sensitivity analysis, parameter identification and
combined state and parameter reduction.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00676</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge-infused and Consistent Complex Event Processing over Real-time
  and Persistent Streams</dc:title>
 <dc:creator>Zhou, Qunzhi</dc:creator>
 <dc:creator>Simmhan, Yogesh</dc:creator>
 <dc:creator>Prasanna, Viktor</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>68U35</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  Emerging applications in Internet of Things (IoT) and Cyber-Physical Systems
(CPS) present novel challenges to Big Data platforms for performing online
analytics. Ubiquitous sensors from IoT deployments are able to generate data
streams at high velocity, that include information from a variety of domains,
and accumulate to large volumes on disk. Complex Event Processing (CEP) is
recognized as an important real-time computing paradigm for analyzing
continuous data streams. However, existing work on CEP is largely limited to
relational query processing, exposing two distinctive gaps for query
specification and execution: (1) infusing the relational query model with
higher level knowledge semantics, and (2) seamless query evaluation across
temporal spaces that span past, present and future events. These allow
accessible analytics over data streams having properties from different
disciplines, and help span the velocity (real-time) and volume (persistent)
dimensions. In this article, we introduce a Knowledge-infused CEP (X-CEP)
framework that provides domain-aware knowledge query constructs along with
temporal operators that allow end-to-end queries to span across real-time and
persistent streams. We translate this query model to efficient query execution
over online and offline data streams, proposing several optimizations to
mitigate the overheads introduced by evaluating semantic predicates and in
accessing high-volume historic data streams. The proposed X-CEP query model and
execution approaches are implemented in our prototype semantic CEP engine,
SCEPter. We validate our query model using domain-aware CEP queries from a
real-world Smart Power Grid application, and experimentally analyze the
benefits of our optimizations for executing these queries, using event streams
from a campus-microgrid IoT deployment.
</dc:description>
 <dc:description>Comment: 34 pages, 16 figures, accepted in Future Generation Computer Systems,
  October 27, 2016</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00676</dc:identifier>
 <dc:identifier>doi:10.1016/j.future.2016.10.030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00679</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Scheme for Interference Mitigation of WBANs Using
  Predictable Channel Hopping</dc:title>
 <dc:creator>Ali, Mohamad</dc:creator>
 <dc:creator>Moungla, Hassine</dc:creator>
 <dc:creator>Younis, Mohamed</dc:creator>
 <dc:creator>Mehaoua, Ahmed</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  When sensors of different coexisting wireless body area networks (WBANs)
transmit at the same time using the same channel, a co-channel interference is
experienced and hence the performance of the involved WBANs may be degraded. In
this paper, we exploit the 16 channels available in the 2.4 GHz international
band of ZIGBEE, and propose a distributed scheme that avoids interference
through predictable channel hopping based on Latin rectangles, namely, CHIM. In
the proposed CHIM scheme, each WBAN's coordinator picks a Latin rectangle whose
rows are ZIGBEE channels and columns are sensor IDs. Based on the Latin
rectangle of the individual WBAN, each sensor is allocated a backup time-slot
and a channel to use if it experiences interference such that collisions among
different transmissions of coexisting WBANs are minimized. We further present a
mathematical analysis that derives the collision probability of each sensor's
transmission in the network. In addition, the efficiency of CHIM in terms of
transmission delay and energy consumption minimization are validated by
simulations.
</dc:description>
 <dc:description>Comment: 18th IEEE International Conference on E-health Networking,
  Application &amp; Services, Munich, Germany, 2016</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00684</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wearable Vision Detection of Environmental Fall Risks using
  Convolutional Neural Networks</dc:title>
 <dc:creator>Nouredanesh, Mina</dc:creator>
 <dc:creator>McCormick, Andrew</dc:creator>
 <dc:creator>Kukreja, Sunil L.</dc:creator>
 <dc:creator>Tung, James</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a method to detect environmental hazards related to a fall
risk using a mobile vision system is proposed. First-person perspective videos
are proposed to provide objective evidence on cause and circumstances of
perturbed balance during activities of daily living, targeted to seniors. A
classification problem was defined with 12 total classes of potential fall
risks, including slope changes (e.g., stairs, curbs, ramps) and surfaces (e.g.,
gravel, grass, concrete). Data was collected using a chest-mounted GoPro
camera. We developed a convolutional neural network for automatic feature
extraction, reduction, and classification of frames. Initial results, with a
mean square error of 8%, are promising.
</dc:description>
 <dc:description>Comment: Accepted paper-The 38th Annual International Conference of the IEEE
  Engineering in Medicine and Biology Society (EMBC 2016)</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00685</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Searching for General Artificial Intelligence</dc:title>
 <dc:creator>Rosa, Marek</dc:creator>
 <dc:creator>Feyereisl, Jan</dc:creator>
 <dc:creator>Collective, The GoodAI</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  There is a significant lack of unified approaches to building generally
intelligent machines. The majority of current artificial intelligence research
operates within a very narrow field of focus, frequently without considering
the importance of the 'big picture'. In this document, we seek to describe and
unify principles that guide the basis of our development of general artificial
intelligence. These principles revolve around the idea that intelligence is a
tool for searching for general solutions to problems. We define intelligence as
the ability to acquire skills that narrow this search, diversify it and help
steer it to more promising areas. We also provide suggestions for studying,
measuring, and testing the various skills and abilities that a human-level
intelligent machine needs to acquire. The document aims to be both
implementation agnostic, and to provide an analytic, systematic, and scalable
way to generate hypotheses that we believe are needed to meet the necessary
conditions in the search for general artificial intelligence. We believe that
such a framework is an important stepping stone for bringing together
definitions, highlighting open problems, connecting researchers willing to
collaborate, and for unifying the arguably most significant search of this
century.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00687</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Engagement dynamics and sensitivity analysis of YouTube videos</dc:title>
 <dc:creator>Hoiles, Wiliam</dc:creator>
 <dc:creator>Aprem, Anup</dc:creator>
 <dc:creator>Krishnamurthy, Vikram</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  YouTube, with millions of content creators, has become the preferred
destination for watching videos online. Through the Partner program, YouTube
allows content creators to monetize their popular videos. Of significant
importance for content creators is which meta-level features (e.g. title, tag,
thumbnail) are most sensitive for promoting video popularity. The popularity of
videos also depends on the social dynamics, i.e. the interaction of the content
creators (or channels) with YouTube users. Using real-world data consisting of
about 6 million videos spread over 25 thousand channels, we empirically examine
the sensitivity of YouTube meta-level features and social dynamics. The key
meta-level features that impact the view counts of a video include: first day
view count , number of subscribers, contrast of the video thumbnail, Google
hits, number of keywords, video category, title length, and number of
upper-case letters in the title respectively and illustrate that these
meta-level features can be used to estimate the popularity of a video. In
addition, optimizing the meta-level features after a video is posted increases
the popularity of videos. In the context of social dynamics, we discover that
there is a causal relationship between views to a channel and the associated
number of subscribers. Additionally, insights into the effects of scheduling
and video playthrough in a channel are also provided. Our findings provide a
useful understanding of user engagement in YouTube.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00688</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mitigating Inter-network Interference in LoRa Networks</dc:title>
 <dc:creator>Voigt, Thiemo</dc:creator>
 <dc:creator>Bor, Martin</dc:creator>
 <dc:creator>Roedig, Utz</dc:creator>
 <dc:creator>Alonso, Juan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Long Range (LoRa) is a popular technology used to construct Low-Power
Wide-Area Network (LPWAN) networks. Given the popularity of LoRa it is likely
that multiple independent LoRa networks are deployed in close proximity. In
this situation, neighbouring networks interfere and methods have to be found to
combat this interference. In this paper we investigate the use of directional
antennae and the use of multiple base stations as methods of dealing with
inter-network interference. Directional antennae increase signal strength at
receivers without increasing transmission energy cost. Thus, the probability of
successfully decoding the message in an interference situation is improved.
Multiple base stations can alternatively be used to improve the probability of
receiving a message in a noisy environment. We compare the effectiveness of
these two approaches via simulation. Our findings show that both methods are
able to improve LoRa network performance in interference settings. However, the
results show that the use of multiple base stations clearly outperforms the use
of directional antennae. For example, in a setting where data is collected from
600 nodes which are interfered by four networks with 600 nodes each, using
three base stations improves the Data Extraction Rate (DER) from 0.24 to 0.56
while the use of directional antennae provides an increase to only 0.32.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00692</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Automatic Resource Bound Analysis for OCaml</dc:title>
 <dc:creator>Hoffmann, Jan</dc:creator>
 <dc:creator>Das, Ankush</dc:creator>
 <dc:creator>Weng, Shu-Chun</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This article presents a resource analysis system for OCaml programs. This
system automatically derives worst-case resource bounds for higher-order
polymorphic programs with user-defined inductive types. The technique is
parametric in the resource and can derive bounds for time, memory allocations
and energy usage. The derived bounds are multivariate resource polynomials
which are functions of different size parameters that depend on the standard
OCaml types. Bound inference is fully automatic and reduced to a linear
optimization problem that is passed to an off-the-shelf LP solver. Technically,
the analysis system is based on a novel multivariate automatic amortized
resource analysis (AARA). It builds on existing work on linear AARA for
higher-order programs with user-defined inductive types and on multivariate
AARA for first-order programs with built-in lists and binary trees. For the
first time, it is possible to automatically derive polynomial bounds for
higher-order functions and polynomial bounds that depend on user-defined
inductive types. Moreover, the analysis handles programs with side effects and
even outperforms the linear bound inference of previous systems. At the same
time, it preserves the expressivity and efficiency of existing AARA techniques.
The practicality of the analysis system is demonstrated with an implementation
and integration with Inria's OCaml compiler. The implementation is used to
automatically derive resource bounds for 411 functions and 6018 lines of code
derived from OCaml libraries, the CompCert compiler, and implementations of
textbook algorithms. In a case study, the system infers bounds on the number of
queries that are sent by OCaml programs to DynamoDB, a commercial NoSQL cloud
database service.
</dc:description>
 <dc:description>Comment: 74 pages, technical report, short version accepted at POPL 2017</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00704</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Scheme for Interference Mitigation of Coexisting WBANs Using
  Latin Rectangles</dc:title>
 <dc:creator>Ali, Mohamad</dc:creator>
 <dc:creator>Moungla, Hassine</dc:creator>
 <dc:creator>Younis, Mohamed</dc:creator>
 <dc:creator>Mehaoua, Ahmed</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The performance of wireless body area networks (WBANs) may be degraded due to
co-channel interference, i.e., when sensors of different coexisting WBANs
transmit at the same time-slots using the same channel. In this paper, we
exploit the 16 channels available in the 2.4 GHz unlicensed international band
of ZIGBEE, and propose a distributed scheme that opts to avoid interference
through channel to time-slot hopping based on Latin rectangles, DAIL. In DAIL,
each WBAN's coordinator picks a Latin rectangle whose rows are ZIGBEE channels
and columns are time-slots of its superframe. Subsequently, it assigns a unique
symbol to each sensor; this latter forms a transmission pattern according to
distinct positions of its symbol in the rectangle, such that collisions among
different transmissions of coexisting WBANs are minimized. We further present
an analytical model that derives bounds on the collision probability of each
sensor's transmission in the network. In addition, the efficiency of DAIL in
interference mitigation has been validated by simulations.
</dc:description>
 <dc:description>Comment: The 14th Annual IEEE Consumer Communications &amp; Networking Conference,
  Las Vegas, USA, January 2017. arXiv admin note: text overlap with
  arXiv:1611.00679</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00708</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inter-WBANs Interference Mitigation Using Orthogonal Walsh Hadamard
  Codes</dc:title>
 <dc:creator>Ali, Mohamad</dc:creator>
 <dc:creator>Moungla, Hassine</dc:creator>
 <dc:creator>Younis, Mohamed</dc:creator>
 <dc:creator>Mehaoua, Ahmed</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A Wireless Body Area Network (WBAN) provides health care services. The
performance and utility of WBANs can be degraded due to interference. In this
paper, our contribution for co-channel interference mitigation among coexisting
WBANs is threefold. First, we propose a distributed orthogonal code allocation
scheme, namely, OCAIM, where, each WBAN generates sensor interference lists
(SILs), and then all sensors belonging to these lists are allocated orthogonal
codes. Secondly, we propose a distributed time reference correlation scheme,
namely, DTRC, that is used as a building block of OCAIM. DTRC enables eachWBAN
to generate a virtual time-based pattern to relate the different superframes.
Accordingly, DTRC provides each WBAN with the knowledge about, 1) which
superframes and, 2) which time-slots of those superframes interfere with the
time-slots within its superframe. Thirdly, we further analyze the success and
collision probabilities of frames transmissions when the number of coexisting
WBANs grows. The simulation results demonstrate that OCAIM outperforms other
competing schemes in terms of interference mitigation and power savings.
</dc:description>
 <dc:description>Comment: 2016 27th IEEE International Symposium on Personal, Indoor and Mobile
  Radio Communications (PIMRC), Valencia, Spain</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00709</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Hybrid Beamforming Algorithm with Unified Analog Beamforming by
  Subspace Construction Based on Partial CSI for Massive MIMO-OFDM Systems</dc:title>
 <dc:creator>Zhu, Dengkui</dc:creator>
 <dc:creator>Li, Boyu</dc:creator>
 <dc:creator>Liang, Ping</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Hybrid beamforming (HB) has been widely studied for reducing the number of
costly radio frequency (RF) chains in massive multiple-input multiple-output
(MIMO) systems. However, previous works on HB are limited to a single user
equipment (UE) or a single group of UEs, employing the frequency-flat
first-level analog beamforming (AB) that cannot be applied to multiple groups
of UEs served in different frequency resources in an orthogonal
frequency-division multiplexing (OFDM) system. In this paper, a novel HB
algorithm with unified AB based on the spatial covariance matrix (SCM)
knowledge of all UEs is proposed for a massive MIMO-OFDM system in order to
support multiple groups of UEs. The proposed HB method with a much smaller
number of RF chains can achieve more than 95% performance of full digital
beamforming. In addition, a novel practical subspace construction (SC)
algorithm based on partial channel state information is proposed to estimate
the required SCM. The proposed SC method can offer more than 97% performance of
the perfect SCM case. With the proposed methods, significant cost and power
savings can be achieved without large loss in performance. Furthermore, the
proposed methods can be applied to massive MIMO-OFDM systems in both
time-division duplex and frequency-division duplex.
</dc:description>
 <dc:description>Comment: accepted to journal</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00710</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep counter networks for asynchronous event-based processing</dc:title>
 <dc:creator>Binas, Jonathan</dc:creator>
 <dc:creator>Indiveri, Giacomo</dc:creator>
 <dc:creator>Pfeiffer, Michael</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Despite their advantages in terms of computational resources, latency, and
power consumption, event-based implementations of neural networks have not been
able to achieve the same performance figures as their equivalent
state-of-the-art deep network models. We propose counter neurons as minimal
spiking neuron models which only require addition and comparison operations,
thus avoiding costly multiplications. We show how inference carried out in deep
counter networks converges to the same accuracy levels as are achieved with
state-of-the-art conventional networks. As their event-based style of
computation leads to reduced latency and sparse updates, counter networks are
ideally suited for efficient compact and low-power hardware implementation. We
present theory and training methods for counter networks, and demonstrate on
the MNIST benchmark that counter networks converge quickly, both in terms of
time and number of operations required, to state-of-the-art classification
accuracy.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00711</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Programming Heuristics for the Graph Isomorphism Problem</dc:title>
 <dc:creator>Takapoui, Reza</dc:creator>
 <dc:creator>Boyd, Stephen</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  An isomorphism between two graphs is a bijection between their vertices that
preserves the edges. We consider the problem of determining whether two finite
undirected weighted graphs are isomorphic, and finding an isomorphism relating
them if the answer is positive. In this paper we introduce effective
probabilistic linear programming (LP) heuristics to solve the graph isomorphism
problem. We motivate our heuristics by showing guarantees under some
conditions, and present numerical experiments that show effectiveness of these
heuristics in the general case.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00712</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Concrete Distribution: A Continuous Relaxation of Discrete Random
  Variables</dc:title>
 <dc:creator>Maddison, Chris J.</dc:creator>
 <dc:creator>Mnih, Andriy</dc:creator>
 <dc:creator>Teh, Yee Whye</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The reparameterization trick enables optimizing large scale stochastic
computation graphs via gradient descent. The essence of the trick is to
refactor each stochastic node into a differentiable function of its parameters
and a random variable with fixed distribution. After refactoring, the gradients
of the loss propagated by the chain rule through the graph are low variance
unbiased estimators of the gradients of the expected loss. While many
continuous random variables have such reparameterizations, discrete random
variables lack useful reparameterizations due to the discontinuous nature of
discrete states. In this work we introduce Concrete random
variables---continuous relaxations of discrete random variables. The Concrete
distribution is a new family of distributions with closed form densities and a
simple reparameterization. Whenever a discrete stochastic node of a computation
graph can be refactored into a one-hot bit representation that is treated
continuously, Concrete stochastic nodes can be used with automatic
differentiation to produce low-variance biased gradients of objectives
(including objectives that depend on the log-probability of latent stochastic
nodes) on the corresponding discrete graph. We demonstrate the effectiveness of
Concrete relaxations on density estimation and structured prediction tasks
using neural networks.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00714</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Semi-Supervised Learning over Networks using Nonsmooth Convex
  Optimization</dc:title>
 <dc:creator>Jung, Alexander</dc:creator>
 <dc:creator>Hero III, Alfred O.</dc:creator>
 <dc:creator>Mara, Alexandru</dc:creator>
 <dc:creator>Aridhi, Sabeur</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We propose a scalable method for semi-supervised (transductive) learning from
massive network-structured datasets. Our approach to semi-supervised learning
is based on representing the underlying hypothesis as a graph signal with small
total variation. Requiring a small total variation of the graph signal
representing the underlying hypothesis corresponds to the central smoothness
assumption that forms the basis for semi-supervised learning, i.e., input
points forming clusters have similar output values or labels. We formulate the
learning problem as a nonsmooth convex optimization problem which we solve by
appealing to Nesterovs optimal first-order method for nonsmooth optimization.
We also provide a message passing formulation of the learning method which
allows for a highly scalable implementation in big data frameworks.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00721</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating Cycles in Directed Graphs: Fast Algorithms for Girth and
  Roundtrip Spanners</dc:title>
 <dc:creator>Pachocki, Jakub</dc:creator>
 <dc:creator>Roditty, Liam</dc:creator>
 <dc:creator>Sidford, Aaron</dc:creator>
 <dc:creator>Tov, Roei</dc:creator>
 <dc:creator>Williams, Virginia Vassilevska</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The girth of a graph, i.e. the length of its shortest cycle, is a fundamental
graph parameter. Unfortunately all known algorithms for computing, even
approximately, the girth and girth-related structures in directed weighted
$m$-edge and $n$-node graphs require $\Omega(\min\{n^{\omega}, mn\})$ time (for
$2\leq\omega&lt;2.373$). In this paper, we drastically improve these runtimes as
follows:
  * Multiplicative Approximations in Nearly Linear Time: We give an algorithm
that in $\widetilde{O}(m)$ time computes an $\widetilde{O}(1)$-multiplicative
approximation of the girth as well as an $\widetilde{O}(1)$-multiplicative
roundtrip spanner with $\widetilde{O}(n)$ edges with high probability (w.h.p).
  * Nearly Tight Additive Approximations: For unweighted graphs and any $\alpha
\in (0,1)$ we give an algorithm that in $\widetilde{O}(mn^{1 - \alpha})$ time
computes an $O(n^\alpha)$-additive approximation of the girth as well as an
$O(n^\alpha)$-additive roundtrip spanner with $\widetilde{O}(n^{2-\alpha})$
edges w.h.p. We show that the runtime of our algorithm cannot be significantly
improved without a breakthrough in combinatorial Boolean matrix multiplication,
and that unconditionally the size of our spanner is essentially optimal.
  Our main technical contribution to achieve these results is the first nearly
linear time algorithm for computing roundtrip covers, a directed graph
decomposition concept key to previous roundtrip spanner constructions.
Previously it was not known how to compute these significantly faster than
$\Omega(\min\{n^\omega, mn\})$ time. Given the traditional difficulty in
efficiently processing directed graphs, we hope our techniques may find further
applications.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00726</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pure Gaussian states from quantum harmonic oscillator chains with a
  single local dissipative process</dc:title>
 <dc:creator>Ma, Shan</dc:creator>
 <dc:creator>Woolley, Matthew J.</dc:creator>
 <dc:creator>Petersen, Ian R.</dc:creator>
 <dc:creator>Yamamoto, Naoki</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study the preparation of entangled pure Gaussian states via reservoir
engineering. In particular, we consider a chain consisting of $(2\aleph+1)$
quantum harmonic oscillators where the central oscillator of the chain is
coupled to a single reservoir. We then completely parametrize the class of
$(2\aleph+1)$-mode pure Gaussian states that can be prepared by this type of
quantum harmonic oscillator chain. This parametrization allows us to determine
the steady-state entanglement properties of such quantum harmonic oscillator
chains.
</dc:description>
 <dc:description>Comment: 27 pages, 4 figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00726</dc:identifier>
 <dc:identifier>J. Phys. A: Math. Theor. 50 (2017) 135301 (28pp)</dc:identifier>
 <dc:identifier>doi:10.1088/1751-8121/aa5fbe</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00736</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extensions and Limitations of the Neural GPU</dc:title>
 <dc:creator>Price, Eric</dc:creator>
 <dc:creator>Zaremba, Wojciech</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The Neural GPU is a recent model that can learn algorithms such as
multi-digit binary addition and binary multiplication in a way that generalizes
to inputs of arbitrary length. We show that there are two simple ways of
improving the performance of the Neural GPU: by carefully designing a
curriculum, and by increasing model size. The latter requires a memory
efficient implementation, as a naive implementation of the Neural GPU is memory
intensive. We find that these techniques increase the set of algorithmic
problems that can be solved by the Neural GPU: we have been able to learn to
perform all the arithmetic operations (and generalize to arbitrarily long
numbers) when the arguments are given in the decimal representation (which,
surprisingly, has not been possible before). We have also been able to train
the Neural GPU to evaluate long arithmetic expressions with multiple operands
that require respecting the precedence order of the operands, although these
have succeeded only in their binary representation, and not with perfect
accuracy.
  In addition, we gain insight into the Neural GPU by investigating its failure
modes. We find that Neural GPUs that correctly generalize to arbitrarily long
numbers still fail to compute the correct answer on highly-symmetric, atypical
inputs: for example, a Neural GPU that achieves near-perfect generalization on
decimal multiplication of up to 100-digit long numbers can fail on
$000000\dots002 \times 000000\dots002$ while succeeding at $2 \times 2$. These
failure modes are reminiscent of adversarial examples.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00739</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enerji \.Izleme Yaz{\i}l{\i}mlar{\i} i\c{c}in Merkezi ve Genel bir
  Mimari (A Centralized and Generic Architecture for Energy Monitoring
  Software)</dc:title>
 <dc:creator>K&#xfc;&#xe7;&#xfc;k, Dilek</dc:creator>
 <dc:creator>Demirci, Turan</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  There is need for several software systems within the energy domain and
corresponding systems are being developed to satisfy these needs. These systems
include energy monitoring, information, wide area monitoring and control
systems, and SCADA systems. Energy monitoring systems are one of the most
important and common systems among them. In this study, after briefly reviewing
several of the software systems within the energy domain, a centralized and
generic software architecture for energy monitoring systems is presented. Next,
sample projects are described in which energy monitoring systems based on this
architecture have been implemented. We envisage that this study will be an
important resource for software projects in the energy domain.
</dc:description>
 <dc:description>Comment: in Turkish. 10. Ulusal Yaz{\i}l{\i}m M\&quot;uhendisli\u{g}i Sempozyumu'na
  (UYMS 2016) kabul edildi</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00740</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why and When Can Deep -- but Not Shallow -- Networks Avoid the Curse of
  Dimensionality: a Review</dc:title>
 <dc:creator>Poggio, Tomaso</dc:creator>
 <dc:creator>Mhaskar, Hrushikesh</dc:creator>
 <dc:creator>Rosasco, Lorenzo</dc:creator>
 <dc:creator>Miranda, Brando</dc:creator>
 <dc:creator>Liao, Qianli</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The paper characterizes classes of functions for which deep learning can be
exponentially better than shallow learning. Deep convolutional networks are a
special case of these conditions, though weight sharing is not the main reason
for their exponential advantage.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00742</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chaotic Memory Randomization for Securing Embedded Systems</dc:title>
 <dc:creator>Henderson, Peter</dc:creator>
 <dc:creator>Maheswaran, Muthucumaru</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  Embedded systems permeate through nearly all aspects of modern society. From
cars to refrigerators to nuclear refineries, securing these systems has never
been more important. Intrusions, such as the Stuxnet malware which broke the
centrifuges in Iran's Natanz refinery, can be catastrophic to not only the
infected systems, but even to the wellbeing of the surrounding population.
Modern day protection mechanisms for these embedded systems generally look only
at protecting the network layer, and those that try to discover malware already
existing on a system typically aren't efficient enough to run on a standalone
embedded system. As such, we present a novel way to ensure that no malware has
been inserted into an embedded system. We chaotically randomize the entire
memory space of the application, interspersing watchdog-monitor programs
throughout, to monitor that the core application hasn't been infiltrated. By
validating the original program through conventional methods and creating a
clean reset, we can ensure that any inserted malware is purged from the system
with minimal effect on the given system. We also present a software prototype
to validate the possibility of this approach, but given the limitations and
vulnerabilities of the prototype, we also suggest a hardware alternative to the
system.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00745</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Heavy-Traffic Queue Length Scaling in an Incompletely Saturated
  Switch</dc:title>
 <dc:creator>Maguluri, Siva Theja</dc:creator>
 <dc:creator>Burle, Sai Kiran</dc:creator>
 <dc:creator>Srikant, R.</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>60K25, 90B15</dc:subject>
 <dc:description>  We consider an input queued switch operating under the MaxWeight scheduling
algorithm. This system is interesting to study because it is a model for
Internet routers and data center networks. Recently, it was shown that the
MaxWeight algorithm has optimal heavy-traffic queue length scaling when all
ports are uniformly saturated. Here we consider the case when an arbitrary
number of ports are saturated (which we call the incompletely saturated case),
and each port is allowed to saturate at a different rate. We use a recently
developed drift technique to show that the heavy-traffic queue length under the
MaxWeight scheduling algorithm has optimal scaling with respect to the switch
size even in these cases.
</dc:description>
 <dc:description>Comment: 32 pages</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00751</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Porting the LSST Data Management Pipeline Software to Python 3</dc:title>
 <dc:creator>Jenness, Tim</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The LSST data management science pipelines software consists of more than
100,000 lines of Python 2 code. LSST operations will begin after support for
Python 2 has been dropped by the Python community in 2020, and we must
therefore plan to migrate the codebase to Python 3. During the transition
period we must also support our community of active Python 2 users and this
complicates the porting significantly. We have decided to use the Python future
package as the basis for our port to enable support for Python 2 and Python 3
simultaneously, whilst developing with a mindset more suited to Python 3. In
this paper we report on the current status of the port and the difficulties
that have been encountered.
</dc:description>
 <dc:description>Comment: 4 pages, presented at Astronomical Data Analysis Software and Systems
  XXVI conference, Trieste, Italy, October 2016</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00755</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost-Linear-Time Algorithms for Markov Chains and New Spectral
  Primitives for Directed Graphs</dc:title>
 <dc:creator>Cohen, Michael B.</dc:creator>
 <dc:creator>Kelner, Jonathan</dc:creator>
 <dc:creator>Peebles, John</dc:creator>
 <dc:creator>Peng, Richard</dc:creator>
 <dc:creator>Rao, Anup</dc:creator>
 <dc:creator>Sidford, Aaron</dc:creator>
 <dc:creator>Vladu, Adrian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we introduce a notion of spectral approximation for directed
graphs. While there are many potential ways one might define approximation for
directed graphs, most of them are too strong to allow sparse approximations in
general. In contrast, we prove that for our notion of approximation, such
sparsifiers do exist, and we show how to compute them in almost linear time.
  Using this notion of approximation, we provide a general framework for
solving asymmetric linear systems that is broadly inspired by the work of
[Peng-Spielman, STOC`14]. Applying this framework in conjunction with our
sparsification algorithm, we obtain an almost linear time algorithm for solving
directed Laplacian systems associated with Eulerian Graphs. Using this solver
in the recent framework of [Cohen-Kelner-Peebles-Peng-Sidford-Vladu, FOCS`16],
we obtain almost linear time algorithms for solving a directed Laplacian linear
system, computing the stationary distribution of a Markov chain, computing
expected commute times in a directed graph, and more.
  For each of these problems, our algorithms improves the previous best running
times of $O((nm^{3/4} + n^{2/3} m) \log^{O(1)} (n \kappa \epsilon^{-1}))$ to
$O((m + n2^{O(\sqrt{\log{n}\log\log{n}})}) \log^{O(1)} (n \kappa
\epsilon^{-1}))$ where $n$ is the number of vertices in the graph, $m$ is the
number of edges, $\kappa$ is a natural condition number associated with the
problem, and $\epsilon$ is the desired accuracy. We hope these results open the
door for further studies into directed spectral graph theory, and will serve as
a stepping stone for designing a new generation of fast algorithms for directed
graphs.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00756</identifier>
 <datestamp>2017-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Methods for Non-Convex Optimization</dc:title>
 <dc:creator>Carmon, Yair</dc:creator>
 <dc:creator>Duchi, John C.</dc:creator>
 <dc:creator>Hinder, Oliver</dc:creator>
 <dc:creator>Sidford, Aaron</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present an accelerated gradient method for non-convex optimization
problems with Lipschitz continuous first and second derivatives. The method
requires time $O(\epsilon^{-7/4} \log(1/ \epsilon) )$ to find an
$\epsilon$-stationary point, meaning a point $x$ such that $\|\nabla f(x)\| \le
\epsilon$. The method improves upon the $O(\epsilon^{-2} )$ complexity of
gradient descent and provides the additional second-order guarantee that
$\nabla^2 f(x) \succeq -O(\epsilon^{1/2})I$ for the computed $x$. Furthermore,
our method is Hessian free, i.e. it only requires gradient computations, and is
therefore suitable for large scale applications.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00760</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Laplacian Eigenmap</dc:title>
 <dc:creator>Huang, Yiming</dc:creator>
 <dc:creator>Li, Xiaoyu</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Laplacian eigenmap algorithm is a typical nonlinear model for dimensionality
reduction in classical machine learning. We propose an efficient quantum
Laplacian eigenmap algorithm to exponentially speed up the original
counterparts. In our work, we demonstrate that the Hermitian chain product
proposed in quantum linear discriminant analysis (arXiv:1510.00113,2015) can be
applied to implement quantum Laplacian eigenmap algorithm. While classical
Laplacian eigenmap algorithm requires polynomial time to solve the eigenvector
problem, our algorithm is able to exponentially speed up nonlinear
dimensionality reduction.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00783</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preserving Randomness for Adaptive Algorithms</dc:title>
 <dc:creator>Hoza, William M.</dc:creator>
 <dc:creator>Klivans, Adam R.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Suppose $\mathsf{Est}$ is a randomized estimation algorithm that uses $n$
random bits and outputs values in $\mathbb{R}^d$. We show how to execute
$\mathsf{Est}$ on $k$ adaptively chosen inputs using only $n + O(k \log(d +
1))$ random bits instead of the trivial $nk$ (at the cost of mild increases in
the error and failure probability). Our algorithm combines a variant of the INW
pseudorandom generator (STOC '94) with a new scheme for shifting and rounding
the outputs of $\mathsf{Est}$. We prove that modifying the outputs of
$\mathsf{Est}$ is necessary in this setting, and furthermore, our algorithm's
randomness complexity is near-optimal in the case $d \leq O(1)$. As an
application, we give a randomness-efficient version of the Goldreich-Levin
algorithm; our algorithm finds all Fourier coefficients with absolute value at
least $\theta$ of a function $F: \{0, 1\}^n \to \{-1, 1\}$ using $O(n \log n)
\cdot \text{poly}(1/\theta)$ queries to $F$ and $O(n)$ random bits (independent
of $\theta$), improving previous work by Bshouty et al. (JCSS '04).
</dc:description>
 <dc:description>Comment: 33 pages, 2 figures. Added sections 1.5.3 and 7.1, changed
  terminology, fixed typos, improved presentation, added appendix C, simplified
  abstract</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00791</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Domain Generation Algorithms with Long Short-Term Memory
  Networks</dc:title>
 <dc:creator>Woodbridge, Jonathan</dc:creator>
 <dc:creator>Anderson, Hyrum S.</dc:creator>
 <dc:creator>Ahuja, Anjum</dc:creator>
 <dc:creator>Grant, Daniel</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Various families of malware use domain generation algorithms (DGAs) to
generate a large number of pseudo-random domain names to connect to a command
and control (C&amp;C) server. In order to block DGA C&amp;C traffic, security
organizations must first discover the algorithm by reverse engineering malware
samples, then generating a list of domains for a given seed. The domains are
then either preregistered or published in a DNS blacklist. This process is not
only tedious, but can be readily circumvented by malware authors using a large
number of seeds in algorithms with multivariate recurrence properties (e.g.,
banjori) or by using a dynamic list of seeds (e.g., bedep). Another technique
to stop malware from using DGAs is to intercept DNS queries on a network and
predict whether domains are DGA generated. Such a technique will alert network
administrators to the presence of malware on their networks. In addition, if
the predictor can also accurately predict the family of DGAs, then network
administrators can also be alerted to the type of malware that is on their
networks. This paper presents a DGA classifier that leverages long short-term
memory (LSTM) networks to predict DGAs and their respective families without
the need for a priori feature extraction. Results are significantly better than
state-of-the-art techniques, providing 0.9993 area under the receiver operating
characteristic curve for binary classification and a micro-averaged F1 score of
0.9906. In other terms, the LSTM technique can provide a 90% detection rate
with a 1:10000 false positive (FP) rate---a twenty times FP improvement over
comparable methods. Experiments in this paper are run on open datasets and code
snippets are provided to reproduce the results.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00800</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Matrix Completion with Locally Linear Latent Factors for
  Medical Applications</dc:title>
 <dc:creator>Chan, Frodo Kin Sun</dc:creator>
 <dc:creator>Ma, Andy J</dc:creator>
 <dc:creator>Yuen, Pong C</dc:creator>
 <dc:creator>Yip, Terry Cheuk-Fung</dc:creator>
 <dc:creator>Tse, Yee-Kit</dc:creator>
 <dc:creator>Wong, Vincent Wai-Sun</dc:creator>
 <dc:creator>Wong, Grace Lai-Hung</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Regular medical records are useful for medical practitioners to analyze and
monitor patient health status especially for those with chronic disease, but
such records are usually incomplete due to unpunctuality and absence of
patients. In order to resolve the missing data problem over time, tensor-based
model is suggested for missing data imputation in recent papers because this
approach makes use of low rank tensor assumption for highly correlated data.
However, when the time intervals between records are long, the data correlation
is not high along temporal direction and such assumption is not valid. To
address this problem, we propose to decompose a matrix with missing data into
its latent factors. Then, the locally linear constraint is imposed on these
factors for matrix completion in this paper. By using a publicly available
dataset and two medical datasets collected from hospital, experimental results
show that the proposed algorithm achieves the best performance by comparing
with the existing methods.
</dc:description>
 <dc:date>2016-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00801</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A FOFE-based Local Detection Approach for Named Entity Recognition and
  Mention Detection</dc:title>
 <dc:creator>Xu, Mingbin</dc:creator>
 <dc:creator>Jiang, Hui</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we study a novel approach for named entity recognition (NER)
and mention detection in natural language processing. Instead of treating NER
as a sequence labelling problem, we propose a new local detection approach,
which rely on the recent fixed-size ordinally forgetting encoding (FOFE) method
to fully encode each sentence fragment and its left/right contexts into a
fixed-size representation. Afterwards, a simple feedforward neural network is
used to reject or predict entity label for each individual fragment. The
proposed method has been evaluated in several popular NER and mention detection
tasks, including the CoNLL 2003 NER task and TAC-KBP2015 and TAC-KBP2016
Tri-lingual Entity Discovery and Linking (EDL) tasks. Our methods have yielded
pretty strong performance in all of these examined tasks. This local detection
approach has shown many advantages over the traditional sequence labelling
methods.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00812</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging tagging and rating for recommendation: RMF meets weighted
  diffusion on tripartite graphs</dc:title>
 <dc:creator>Li, Jianguo</dc:creator>
 <dc:creator>Tang, Yong</dc:creator>
 <dc:creator>Chen, Jiemin</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Recommender systems (RSs) have been a widely exploited approach to solving
the information overload problem. However, the performance is still limited due
to the extreme sparsity of the rating data. With the popularity of Web 2.0, the
social tagging system provides more external information to improve
recommendation accuracy. Although some existing approaches combine the matrix
factorization models with co-occurrence properties and context of tags, they
neglect the issue of tag sparsity without the commonly associated tags problem
that would also result in inaccurate recommendations. Consequently, in this
paper, we propose a novel hybrid collaborative filtering model named
WUDiff_RMF, which improves Regularized Matrix Factorization (RMF) model by
integrating Weighted User-Diffusion-based CF algorithm(WUDiff) that obtains the
information of similar users from the weighted tripartite user-item-tag graph.
This model aims to capture the degree correlation of the user-item-tag
tripartite network to enhance the performance of recommendation. Experiments
conducted on four real-world datasets demonstrate that our approach
significantly performs better than already widely used methods in the accuracy
of recommendation. Moreover, results show that WUDiff_RMF can alleviate the
data sparsity, especially in the circumstance that users have made few ratings
and few tags.
</dc:description>
 <dc:date>2016-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00812</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2017.04.121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00814</identifier>
 <datestamp>2017-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-theoretic thresholds from the cavity method</dc:title>
 <dc:creator>Coja-Oghlan, Amin</dc:creator>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:creator>Perkins, Will</dc:creator>
 <dc:creator>Zdeborova, Lenka</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>68Q87</dc:subject>
 <dc:description>  Vindicating a sophisticated but non-rigorous physics approach called the
cavity method, we establish a formula for the mutual information in statistical
inference problems induced by random graphs and we show that the mutual
information holds the key to understanding certain important phase transitions
in random graph models. We work out several concrete applications of these
general results. For instance, we pinpoint the exact condensation phase
transition in the Potts antiferromagnet on the random graph, thereby improving
prior approximate results [Contucci et al.: Communications in Mathematical
Physics 2013]. Further, we prove the conjecture from [Krzakala et al.: PNAS
2007] about the condensation phase transition in the random graph coloring
problem for any number $q\geq3$ of colors. Moreover, we prove the conjecture on
the information-theoretic threshold in the disassortative stochastic block
model [Decelle et al.: Phys. Rev. E 2011]. Additionally, our general result
implies the conjectured formula for the mutual information in Low-Density
Generator Matrix codes [Montanari: IEEE Transactions on Information Theory
2005].
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2016-12-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00822</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Embeddings with Histogram Loss</dc:title>
 <dc:creator>Ustinova, Evgeniya</dc:creator>
 <dc:creator>Lempitsky, Victor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We suggest a loss for learning deep embeddings. The new loss does not
introduce parameters that need to be tuned and results in very good embeddings
across a range of datasets and problems. The loss is computed by estimating two
distribution of similarities for positive (matching) and negative
(non-matching) sample pairs, and then computing the probability of a positive
pair to have a lower similarity score than a negative pair based on the
estimated similarity distributions. We show that such operations can be
performed in a simple and piecewise-differentiable manner using 1D histograms
with soft assignment operations. This makes the proposed loss suitable for
learning deep embeddings using stochastic optimization. In the experiments, the
new loss performs favourably compared to recently proposed alternatives.
</dc:description>
 <dc:description>Comment: NIPS 2016</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00827</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric complexity theory and matrix powering</dc:title>
 <dc:creator>Gesmundo, Fulvio</dc:creator>
 <dc:creator>Ikenmeyer, Christian</dc:creator>
 <dc:creator>Panova, Greta</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:subject>68Q17, 05E10, 20C30, 15A86</dc:subject>
 <dc:description>  Valiant's famous determinant versus permanent problem is the flagship problem
in algebraic complexity theory. Mulmuley and Sohoni (Siam J Comput 2001, 2008)
introduced geometric complexity theory, an approach to study this and related
problems via algebraic geometry and representation theory. Their approach works
by multiplying the permanent polynomial with a high power of a linear form (a
process called padding) and then comparing the orbit closures of the
determinant and the padded permanent. This padding was recently used heavily to
show no-go results for the method of shifted partial derivatives (Efremenko,
Landsberg, Schenck, Weyman, 2016) and for geometric complexity theory
(Ikenmeyer Panova, FOCS 2016 and B\&quot;urgisser, Ikenmeyer Panova, FOCS 2016).
Following a classical homogenization result of Nisan (STOC 1991) we replace the
determinant in geometric complexity theory with the trace of a variable matrix
power. This gives an equivalent but much cleaner homogeneous formulation of
geometric complexity theory in which the padding is removed. This radically
changes the representation theoretic questions involved to prove complexity
lower bounds. We prove that in this homogeneous formulation there are no orbit
occurrence obstructions that prove even superlinear lower bounds on the
complexity of the permanent. This is the first no-go result in geometric
complexity theory that rules out superlinear lower bounds in some model.
Interestingly---in contrast to the determinant---the trace of a variable matrix
power is not uniquely determined by its stabilizer.
</dc:description>
 <dc:description>Comment: 21 pages. Final version to appear: Differential Geometry and its
  Applications - Special issue in Geometry and Complexity Theory</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00829</identifier>
 <datestamp>2017-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multidimensional Binary Search for Contextual Decision-Making</dc:title>
 <dc:creator>Lobel, Ilan</dc:creator>
 <dc:creator>Leme, Renato Paes</dc:creator>
 <dc:creator>Vladu, Adrian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a multidimensional search problem that is motivated by questions
in contextual decision-making, such as dynamic pricing and personalized
medicine. Nature selects a state from a $d$-dimensional unit ball and then
generates a sequence of $d$-dimensional directions. We are given access to the
directions, but not access to the state. After receiving a direction, we have
to guess the value of the dot product between the state and the direction. Our
goal is to minimize the number of times when our guess is more than $\epsilon$
away from the true answer. We construct a polynomial time algorithm that we
call Projected Volume achieving regret $O(d\log(d/\epsilon))$, which is optimal
up to a $\log d$ factor. The algorithm combines a volume cutting strategy with
a new geometric technique that we call cylindrification.
</dc:description>
 <dc:description>Comment: Appears in EC 2017</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00837</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-aware System Service Call-oriented Symbolic Execution of Android
  Framework with Application to Exploit Generation</dc:title>
 <dc:creator>Luo, Lannan</dc:creator>
 <dc:creator>Zeng, Qiang</dc:creator>
 <dc:creator>Cao, Chen</dc:creator>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:creator>Liu, Jian</dc:creator>
 <dc:creator>Liu, Limin</dc:creator>
 <dc:creator>Gao, Neng</dc:creator>
 <dc:creator>Yang, Min</dc:creator>
 <dc:creator>Xing, Xinyu</dc:creator>
 <dc:creator>Liu, Peng</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Android Framework is a layer of software that exists in every Android system
managing resources of all Android apps. A vulnerability in Android Framework
can lead to severe hacks, such as destroying user data and leaking private
information. With tens of millions of Android devices unpatched due to Android
fragmentation, vulnerabilities in Android Framework certainly attract attackers
to exploit them. So far, enormous manual effort is needed to craft such
exploits. To our knowledge, no research has been done on automatic generation
of exploits that take advantage of Android Framework vulnerabilities. We make a
first step towards this goal by applying symbolic execution of Android
Framework to finding bugs and generating exploits. Several challenges have been
raised by the task. (1) The information of an app flows to Android Framework in
multiple intricate steps, making it difficult to identify symbolic inputs. (2)
Android Framework has a complex initialization phase, which exacerbates the
state space explosion problem. (3) A straightforward design that builds the
symbolic executor as a layer inside the Android system will not work well: not
only does the implementation have to ensure the compatibility with the Android
system, but it needs to be maintained whenever Android gets updated. We present
novel ideas and techniques to resolve the challenges, and have built the first
system for symbolic execution of Android Framework. It fundamentally changes
the state of the art in exploit generation on the Android system, and has been
applied to constructing new techniques for finding vulnerabilities.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00838</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Initialization and Coordinate Optimization for Multi-way Matching</dc:title>
 <dc:creator>Tang, Da</dc:creator>
 <dc:creator>Jebara, Tony</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of consistently matching multiple sets of elements to
each other, which is a common task in fields such as computer vision. To solve
the underlying NP-hard objective, existing methods often relax or approximate
it, but end up with unsatisfying empirical performance due to a misaligned
objective. We propose a coordinate update algorithm that directly optimizes the
target objective. By using pairwise alignment information to build an
undirected graph and initializing the permutation matrices along the edges of
its Maximum Spanning Tree, our algorithm successfully avoids bad local optima.
Theoretically, with high probability our algorithm guarantees an optimal
solution under reasonable noise assumptions. Empirically, our algorithm
consistently and significantly outperforms existing methods on several
benchmark tasks on real datasets.
</dc:description>
 <dc:description>Comment: Artificial Intelligence and Statistics (AISTATS), 2017</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00840</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Below all subsets for Minimal Connected Dominating Set</dc:title>
 <dc:creator>Lokshtanov, Daniel</dc:creator>
 <dc:creator>Pilipczuk, Micha&#x142;</dc:creator>
 <dc:creator>Saurabh, Saket</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A vertex subset $S$ in a graph $G$ is a dominating set if every vertex not
contained in $S$ has a neighbor in $S$. A dominating set $S$ is a connected
dominating set if the subgraph $G[S]$ induced by $S$ is connected. A connected
dominating set $S$ is a minimal connected dominating set if no proper subset of
$S$ is also a connected dominating set. We prove that there exists a constant
$\varepsilon &gt; 10^{-50}$ such that every graph $G$ on $n$ vertices has at most
$O(2^{(1-\varepsilon)n})$ minimal connected dominating sets. For the same
$\varepsilon$ we also give an algorithm with running time
$2^{(1-\varepsilon)n}\cdot n^{O(1)}$ to enumerate all minimal connected
dominating sets in an input graph $G$.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00843</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling and Estimation for (Sparse) Exchangeable Graphs</dc:title>
 <dc:creator>Veitch, Victor</dc:creator>
 <dc:creator>Roy, Daniel M.</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Sparse exchangeable graphs on $\mathbb{R}_+$, and the associated graphex
framework for sparse graphs, generalize exchangeable graphs on $\mathbb{N}$,
and the associated graphon framework for dense graphs. We develop the graphex
framework as a tool for statistical network analysis by identifying the
sampling scheme that is naturally associated with the models of the framework,
and by introducing a general consistent estimator for the parameter (the
graphex) underlying these models. The sampling scheme is a modification of
independent vertex sampling that throws away vertices that are isolated in the
sampled subgraph. The estimator is a dilation of the empirical graphon
estimator, which is known to be a consistent estimator for dense exchangeable
graphs; both can be understood as graph analogues to the empirical distribution
in the i.i.d. sequence setting. Our results may be viewed as a generalization
of consistent estimation via the empirical graphon from the dense graph regime
to also include sparse graphs.
</dc:description>
 <dc:description>Comment: 26 pages, 3 figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00847</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Convolutional Neural Network Design Patterns</dc:title>
 <dc:creator>Smith, Leslie N.</dc:creator>
 <dc:creator>Topin, Nicholay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recent research in the deep learning field has produced a plethora of new
architectures. At the same time, a growing number of groups are applying deep
learning to new applications. Some of these groups are likely to be composed of
inexperienced deep learning practitioners who are baffled by the dizzying array
of architecture choices and therefore opt to use an older architecture (i.e.,
Alexnet). Here we attempt to bridge this gap by mining the collective knowledge
contained in recent deep learning research to discover underlying principles
for designing neural network architectures. In addition, we describe several
architectural innovations, including Fractal of FractalNet network, Stagewise
Boosting Networks, and Taylor Series Networks (our Caffe code and prototxt
files is available at https://github.com/iPhysicist/CNNDesignPatterns). We hope
others are inspired to build on our preliminary work.
</dc:description>
 <dc:description>Comment: Submitted as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00850</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optical Flow Estimation using a Spatial Pyramid Network</dc:title>
 <dc:creator>Ranjan, Anurag</dc:creator>
 <dc:creator>Black, Michael J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We learn to compute optical flow by combining a classical spatial-pyramid
formulation with deep learning. This estimates large motions in a
coarse-to-fine approach by warping one image of a pair at each pyramid level by
the current flow estimate and computing an update to the flow. Instead of the
standard minimization of an objective function at each pyramid level, we train
one deep network per level to compute the flow update. Unlike the recent
FlowNet approach, the networks do not need to deal with large motions; these
are dealt with by the pyramid. This has several advantages. First, our Spatial
Pyramid Network (SPyNet) is much simpler and 96% smaller than FlowNet in terms
of model parameters. This makes it more efficient and appropriate for embedded
applications. Second, since the flow at each pyramid level is small (&lt; 1
pixel), a convolutional approach applied to pairs of warped images is
appropriate. Third, unlike FlowNet, the learned convolution filters appear
similar to classical spatio-temporal filters, giving insight into the method
and how to improve it. Our results are more accurate than FlowNet on most
standard benchmarks, suggesting a new direction of combining classical flow
methods with deep learning.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00851</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An All-In-One Convolutional Neural Network for Face Analysis</dc:title>
 <dc:creator>Ranjan, Rajeev</dc:creator>
 <dc:creator>Sankaranarayanan, Swami</dc:creator>
 <dc:creator>Castillo, Carlos D.</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a multi-purpose algorithm for simultaneous face detection, face
alignment, pose estimation, gender recognition, smile detection, age estimation
and face recognition using a single deep convolutional neural network (CNN).
The proposed method employs a multi-task learning framework that regularizes
the shared parameters of CNN and builds a synergy among different domains and
tasks. Extensive experiments show that the network has a better understanding
of face and achieves state-of-the-art result for most of these tasks.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00860</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HPVM: A Portable Virtual Instruction Set for Heterogeneous Parallel
  Systems</dc:title>
 <dc:creator>Srivastava, Prakalp</dc:creator>
 <dc:creator>Kotsifakou, Maria</dc:creator>
 <dc:creator>Adve, Vikram</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We describe a programming abstraction for heterogeneous parallel hardware,
designed to capture a wide range of popular parallel hardware, including GPUs,
vector instruction sets and multicore CPUs. Our abstraction, which we call
HPVM, is a hierarchical dataflow graph with shared memory and vector
instructions. We use HPVM to define both a virtual instruction set (ISA) and
also a compiler intermediate representation (IR). The virtual ISA aims to
achieve both functional portability and performance portability across
heterogeneous systems, while the compiler IR aims to enable effective code
generation and optimization for such systems.
  HPVM effectively supports all forms of parallelism used to achieve
computational speedups (as opposed to concurrency), including task parallelism,
coarse-grain data parallelism, fine-grain data parallelism, and pipelined
parallelism. HPVM also enables flexible scheduling and tiling: different nodes
in the dataflow graph can be mapped flexibly to different combinations of
compute units, and the graph hierarchy expresses memory tiling, essential for
achieving high performance on GPU and CPU targets.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00861</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emerging Wireless Technologies in the Internet of Things: a Comparative
  Study</dc:title>
 <dc:creator>Elkhodr, Mahmoud</dc:creator>
 <dc:creator>Shahrestani, Seyed</dc:creator>
 <dc:creator>Cheung, Hon</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Internet of Things (IoT) incorporates multiple long-range, short-range,
and personal area wireless networks and technologies into the designs of IoT
applications. This enables numerous business opportunities in fields as diverse
as e-health, smart cities, smart homes, among many others. This research
analyses some of the major evolving and enabling wireless technologies in the
IoT. Particularly, it focuses on ZigBee, 6LoWPAN, Bluetooth Low Energy, LoRa,
and the different versions of Wi-Fi including the recent IEEE 802.11ah
protocol. The studies evaluate the capabilities and behaviours of these
technologies regarding various metrics including the data range and rate,
network size, RF Channels and Bandwidth, and power consumption. It is concluded
that there is a need to develop a multifaceted technology approach to enable
interoperable and secure communications in the IoT.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00861</dc:identifier>
 <dc:identifier>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  8, No. 5, October 2016</dc:identifier>
 <dc:identifier>doi:10.5121/ijwmn.2016.8505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00862</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantile Reinforcement Learning</dc:title>
 <dc:creator>Gilbert, Hugo</dc:creator>
 <dc:creator>Weng, Paul</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In reinforcement learning, the standard criterion to evaluate policies in a
state is the expectation of (discounted) sum of rewards. However, this
criterion may not always be suitable, we consider an alternative criterion
based on the notion of quantiles. In the case of episodic reinforcement
learning problems, we propose an algorithm based on stochastic approximation
with two timescales. We evaluate our proposition on a simple model of the TV
show, Who wants to be a millionaire.
</dc:description>
 <dc:description>Comment: AWRL 2016</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00864</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Neural Networks for Spatiotemporal Dynamics of Intrinsic
  Networks from fMRI Data</dc:title>
 <dc:creator>Hjelm, R Devon</dc:creator>
 <dc:creator>Plis, Sergey M.</dc:creator>
 <dc:creator>Calhoun, Vince</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Functional magnetic resonance imaging (fMRI) of temporally-coherent blood
oxygenization level-dependent (BOLD) signal provides an effective means of
analyzing functionally coherent patterns in the brain. Intrinsic networks and
functional connectivity are important outcomes of fMRI studies and are central
to understanding brain function and making diagnoses. The most popular method
for separating INs, independent component analysis, begins with the assumption
that the data is a mixture of maximally independent sources. ICA is trainable
through one of many relatively simple optimization routines that maximize
non-Gaussianity or minimize mutual information. Although fMRI data is a time
series, ICA, as with other popular linear methods for separating INs, is
order-agnostic in time: each multivariate signal at each time step is treated
as i.i.d.. ICA in its common use in the field employs the same parameterization
across subjects, which allows for either temporal or spatial variability, but
not both. In order to overcome shortcomings of temporal ICA in lack of dynamics
and subject-wise/temporal variability of spatial maps, but without abandoning
the fundamental strengths of ICA, we combine recurrent neural networks (RNNs)
with an ICA objective. The resulting model naturally represents temporal and
spatial dynamics---having subject-wise and temporally variable spatial
maps---and is easily trainable using gradient descent and back-propagation.
</dc:description>
 <dc:description>Comment: Accepted to &quot;Brain and Bits&quot; workshop for NIPS 2016</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00869</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QoE-based MAC Layer Optimization for Video Teleconferencing over WiFi</dc:title>
 <dc:creator>Xu, Tianyi</dc:creator>
 <dc:creator>Ma, Liangping</dc:creator>
 <dc:creator>Sternberg, Gregory</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In IEEE 802.11, the retry limit is set the same value for all packets. In
this paper, we dynamically classify video teleconferencing packets based on the
type of the video frame that a packet carries and the packet loss events that
have happened in the network, and assign them different retry limits. We
consider the IPPP video encoding structure with instantaneous decoder refresh
(IDR) frame insertion based on packet loss feedback. The loss of a single frame
causes error propagation for a period of time equal to the packet loss feedback
delay. To optimize the video quality, we propose a method to concentrate the
packet losses to small segments of the entire video sequence, and study the
performance by an analytic model. Our proposed method is implemented only on
the stations interested in enhanced video quality, and is compatible with
unmodified IEEE 802.11 stations and access points in terms of performance.
Simulation results show that the performance gain can be significant compared
to the IEEE 802.11 standard without negatively affecting cross traffic.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00872</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decision Support System for Inbound Marketers: An Empirical Use of
  Latent Dirichlet Allocation Topic Model to Guide Infographic Designers</dc:title>
 <dc:creator>Nia, Meisam Hejazi</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Infographic is a type of information presentation that inbound marketers use.
I suggest a method that can allow the infographic designers to benchmark their
design against the previous viral infographics to measure whether a given
design decision can help or hurt the probability of the design becoming viral.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00873</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting Actionability from Machine Learning Models by Sub-optimal
  Deterministic Planning</dc:title>
 <dc:creator>Lyu, Qiang</dc:creator>
 <dc:creator>Chen, Yixin</dc:creator>
 <dc:creator>Li, Zhaorong</dc:creator>
 <dc:creator>Cui, Zhicheng</dc:creator>
 <dc:creator>Chen, Ling</dc:creator>
 <dc:creator>Zhang, Xing</dc:creator>
 <dc:creator>Shen, Haihua</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A main focus of machine learning research has been improving the
generalization accuracy and efficiency of prediction models. Many models such
as SVM, random forest, and deep neural nets have been proposed and achieved
great success. However, what emerges as missing in many applications is
actionability, i.e., the ability to turn prediction results into actions. For
example, in applications such as customer relationship management, clinical
prediction, and advertisement, the users need not only accurate prediction, but
also actionable instructions which can transfer an input to a desirable goal
(e.g., higher profit repays, lower morbidity rates, higher ads hit rates).
Existing effort in deriving such actionable knowledge is few and limited to
simple action models which restricted to only change one attribute for each
action. The dilemma is that in many real applications those action models are
often more complex and harder to extract an optimal solution.
  In this paper, we propose a novel approach that achieves actionability by
combining learning with planning, two core areas of AI. In particular, we
propose a framework to extract actionable knowledge from random forest, one of
the most widely used and best off-the-shelf classifiers. We formulate the
actionability problem to a sub-optimal action planning (SOAP) problem, which is
to find a plan to alter certain features of a given input so that the random
forest would yield a desirable output, while minimizing the total costs of
actions. Technically, the SOAP problem is formulated in the SAS+ planning
formalism, and solved using a Max-SAT based approach. Our experimental results
demonstrate the effectiveness and efficiency of the proposed approach on a
personal credit dataset and other benchmarks. Our work represents a new
application of automated planning on an emerging and challenging machine
learning paradigm.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00880</identifier>
 <datestamp>2017-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensitivity analysis on chaotic dynamical system by Non-Intrusive Least
  Square Shadowing (NILSS)</dc:title>
 <dc:creator>Ni, Angxiu</dc:creator>
 <dc:creator>Wang, Qiqi</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This paper develops the Non-Intrusive Least Squares Shadowing (NILSS) method,
which computes the sensitivity for long-time averaged objectives in chaotic
dynamical systems. In NILSS, we represent a tangent solution by a linear
combination of one inhomogeneous tangent solution and several homogeneous
tangent solutions. Next, we solve a least squares problem using this
representation; thus, the resulting solution can be used for computing
sensitivities. NILSS is easy to implement with existing solvers. In addition,
for chaotic systems with many degrees of freedom but few unstable modes, NILSS
has a low computational cost. NILSS is applied to two chaotic PDE systems: the
Lorenz 63 system and a CFD simulation of flow over a backward-facing step. In
both cases, the sensitivities computed by NILSS reflect the trends in the
long-time averaged objectives of dynamical systems.
</dc:description>
 <dc:description>Comment: 35 pages, 11 figures</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00880</dc:identifier>
 <dc:identifier>Journal of Computational Physics 347C (2017) pp. 56-77</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2017.06.033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00886</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>All or nothing: toward a promise problem dichotomy for constraint
  problems</dc:title>
 <dc:creator>Ham, Lucy</dc:creator>
 <dc:creator>Jackson, Marcel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>68R10, 68Q15, 05C20, 05C60, 08A35</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  A finite constraint language $\mathscr{R}$ is a finite set of relations over
some finite domain $A$. We show that intractability of the constraint
satisfaction problem $\operatorname{CSP}(\mathscr{R})$ can, in all known cases,
be replaced by an infinite hierarchy of intractable promise problems of
increasingly disparate promise conditions: where instances are guaranteed to
either have no solutions at all, or to be $k$-robustly satisfiable (for any
fixed $k$), meaning that every &quot;reasonable&quot; partial instantiation on~$k$
variables extends to a solution. For example, subject to the assumption
$\texttt{P}\neq \texttt{NP}$, then for any~$k$, we show that there is no
polynomial time algorithm that can distinguish non-$3$-colourable graphs, from
those for which any reasonable $3$-colouring of any $k$ of the vertices can
extend to a full $3$-colouring. Our main result shows that an analogous
statement holds for all known intractable constraint problems over fixed finite
constraint languages.
</dc:description>
 <dc:description>Comment: Updated from version 1 to include new results. Updated from version 2
  by some amendments and streamlined arguments</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00889</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing Sparse Reliable Pose-Graph SLAM: A Graph-Theoretic Approach</dc:title>
 <dc:creator>Khosoussi, Kasra</dc:creator>
 <dc:creator>Sukhatme, Gaurav S.</dc:creator>
 <dc:creator>Huang, Shoudong</dc:creator>
 <dc:creator>Dissanayake, Gamini</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we aim to design sparse D-optimal (determinantoptimal)
pose-graph SLAM problems through the synthesis of sparse graphs with the
maximum weighted number of spanning trees. Characterizing graphs with the
maximum number of spanning trees is an open problem in general. To tackle this
problem, several new theoretical results are established in this paper,
including the monotone log-submodularity of the weighted number of spanning
trees. By exploiting these structures, we design a complementary pair of
near-optimal efficient approximation algorithms with provable guarantees. Our
theoretical results are validated using random graphs and a publicly available
pose-graph SLAM dataset.
</dc:description>
 <dc:description>Comment: WAFR 2016</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00890</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing Investment Value of Small-Scale PV in a Smart Grid
  Environment</dc:title>
 <dc:creator>Every, Jeremy</dc:creator>
 <dc:creator>Li, Li</dc:creator>
 <dc:creator>Guo, Youguang G.</dc:creator>
 <dc:creator>Dorrell, David G.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Determining the optimal size and orientation of small-scale residential based
PV arrays will become increasingly complex in the future smart grid environment
with the introduction of smart meters and dynamic tariffs. However consumers
can leverage the availability of smart meter data to conduct a more detailed
exploration of PV investment options for their particular circumstances. In
this paper, an optimization method for PV orientation and sizing is proposed
whereby maximizing the PV investment value is set as the defining objective.
Solar insolation and PV array models are described to form the basis of the PV
array optimization strategy. A constrained particle swarm optimization
algorithm is selected due to its strong performance in non-linear applications.
The optimization algorithm is applied to real-world metered data to quantify
the possible investment value of a PV installation under different energy
retailers and tariff structures. The arrangement with the highest value is
determined to enable prospective small-scale PV investors to select the most
cost-effective system.
</dc:description>
 <dc:description>Comment: To appear the proceedings of the 5th International Conference for
  Renewable Energy Research and Applications (ICRERA2016), Birmingham, United
  Kingdom. 6 pages. 3 figures</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00890</dc:identifier>
 <dc:identifier>2016 IEEE International Conference on Renewable Energy Research
  and Applications (ICRERA), 2016, pp. 385-390</dc:identifier>
 <dc:identifier>doi:10.1109/ICRERA.2016.7884366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00898</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Rank Approximation with Entrywise $\ell_1$-Norm Error</dc:title>
 <dc:creator>Song, Zhao</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:creator>Zhong, Peilin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the $\ell_1$-low rank approximation problem, where for a given $n
\times d$ matrix $A$ and approximation factor $\alpha \geq 1$, the goal is to
output a rank-$k$ matrix $\widehat{A}$ for which
  $$\|A-\widehat{A}\|_1 \leq \alpha \cdot \min_{\textrm{rank-}k\textrm{
matrices}~A'}\|A-A'\|_1,$$ where for an $n \times d$ matrix $C$, we let
$\|C\|_1 = \sum_{i=1}^n \sum_{j=1}^d |C_{i,j}|$. This error measure is known to
be more robust than the Frobenius norm in the presence of outliers and is
indicated in models where Gaussian assumptions on the noise may not apply. The
problem was shown to be NP-hard by Gillis and Vavasis and a number of
heuristics have been proposed. It was asked in multiple places if there are any
approximation algorithms.
  We give the first provable approximation algorithms for $\ell_1$-low rank
approximation, showing that it is possible to achieve approximation factor
$\alpha = (\log d) \cdot \mathrm{poly}(k)$ in $\mathrm{nnz}(A) + (n+d)
\mathrm{poly}(k)$ time, where $\mathrm{nnz}(A)$ denotes the number of non-zero
entries of $A$. If $k$ is constant, we further improve the approximation ratio
to $O(1)$ with a $\mathrm{poly}(nd)$-time algorithm. Under the Exponential Time
Hypothesis, we show there is no $\mathrm{poly}(nd)$-time algorithm achieving a
$(1+\frac{1}{\log^{1+\gamma}(nd)})$-approximation, for $\gamma &gt; 0$ an
arbitrarily small constant, even when $k = 1$.
  We give a number of additional results for $\ell_1$-low rank approximation:
nearly tight upper and lower bounds for column subset selection, CUR
decompositions, extensions to low rank approximation with respect to
$\ell_p$-norms for $1 \leq p &lt; 2$ and earthmover distance, low-communication
distributed protocols and low-memory streaming algorithms, algorithms with
limited randomness, and bicriteria algorithms. We also give a preliminary
empirical evaluation.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00910</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Task-driven sampling of attributed networks</dc:title>
 <dc:creator>Kumar, Suhansanu</dc:creator>
 <dc:creator>Sundaram, Hari</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  This paper introduces new techniques for sampling attributed networks to
support standard Data Mining tasks. The problem is important for two reasons.
First, it is commonplace to perform data mining tasks such as clustering and
classification of network attributes (attributes of the nodes, including social
media posts). Furthermore, the extraordinarily large size of real-world
networks necessitates that we work with a smaller graph sample. Second, while
random sampling will provide an unbiased estimate of content, random access is
often unavailable for many networks. Hence, network samplers such as Snowball
sampling, Forest Fire, Random Walk, Metropolis-Hastings Random Walk are widely
used; however, these attribute-agnostic samplers were designed to capture
salient properties of network structure, not node content. The latter is
critical for clustering and classification tasks. There are three contributions
of this paper. First, we introduce several attribute-aware samplers based on
Information Theoretic principles. Second, we prove that these samplers have a
bias towards capturing new content, and are equivalent to uniform sampling in
the limit. Finally, our experimental results over large real-world datasets and
synthetic benchmarks are insightful: attribute-aware samplers outperform both
random sampling and baseline attribute-agnostic samplers by a wide margin in
clustering and classification tasks.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00911</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DecreaseKeys are Expensive for External Memory Priority Queues</dc:title>
 <dc:creator>Eenberg, Kasper</dc:creator>
 <dc:creator>Larsen, Kasper Green</dc:creator>
 <dc:creator>Yu, Huacheng</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  One of the biggest open problems in external memory data structures is the
priority queue problem with DecreaseKey operations. If only Insert and
ExtractMin operations need to be supported, one can design a comparison-based
priority queue performing $O((N/B)\lg_{M/B} N)$ I/Os over a sequence of $N$
operations, where $B$ is the disk block size in number of words and $M$ is the
main memory size in number of words. This matches the lower bound for
comparison-based sorting and is hence optimal for comparison-based priority
queues. However, if we also need to support DecreaseKeys, the performance of
the best known priority queue is only $O((N/B) \lg_2 N)$ I/Os. The big open
question is whether a degradation in performance really is necessary. We answer
this question affirmatively by proving a lower bound of $\Omega((N/B) \lg_{\lg
N} B)$ I/Os for processing a sequence of $N$ intermixed Insert, ExtraxtMin and
DecreaseKey operations. Our lower bound is proved in the cell probe model and
thus holds also for non-comparison-based priority queues.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00918</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dichotomy for Regular Expression Membership Testing</dc:title>
 <dc:creator>Bringmann, Karl</dc:creator>
 <dc:creator>Gr&#xf8;nlund, Allan</dc:creator>
 <dc:creator>Larsen, Kasper Green</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study regular expression membership testing: Given a regular expression of
size $m$ and a string of size $n$, decide whether the string is in the language
described by the regular expression. Its classic $O(nm)$ algorithm is one of
the big success stories of the 70s, which allowed pattern matching to develop
into the standard tool that it is today.
  Many special cases of pattern matching have been studied that can be solved
faster than in quadratic time. However, a systematic study of tractable cases
was made possible only recently, with the first conditional lower bounds
reported by Backurs and Indyk [FOCS'16]. Restricted to any &quot;type&quot; of
homogeneous regular expressions of depth 2 or 3, they either presented a
near-linear time algorithm or a quadratic conditional lower bound, with one
exception known as the Word Break problem.
  In this paper we complete their work as follows:
  1) We present two almost-linear time algorithms that generalize all known
almost-linear time algorithms for special cases of regular expression
membership testing.
  2) We classify all types, except for the Word Break problem, into
almost-linear time or quadratic time assuming the Strong Exponential Time
Hypothesis. This extends the classification from depth 2 and 3 to any constant
depth.
  3) For the Word Break problem we give an improved $\tilde{O}(n m^{1/3} + m)$
algorithm. Surprisingly, we also prove a matching conditional lower bound for
combinatorial algorithms. This establishes Word Break as the only intermediate
problem.
  In total, we prove matching upper and lower bounds for any type of
bounded-depth homogeneous regular expressions, which yields a full dichotomy
for regular expression membership testing.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00922</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial algorithm for exact calculation of partition function for
  binary spin model on planar graphs</dc:title>
 <dc:creator>Karandashev, Yakov M.</dc:creator>
 <dc:creator>Malsagov, Magomed Yu.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  In this paper we propose and realize (the code is publicly available at
https://github.com/Thrawn1985/2D-Partition-Function) an algorithm for exact
calculation of partition function for planar graph models with binary spins.
The complexity of the algorithm is O(N^2). Test experiments shows good
agreement with Onsager's analytical solution for two-dimensional Ising model of
infinite size.
</dc:description>
 <dc:description>Comment: 9 pages, 10 figure</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00931</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rough Set Based Color Channel Selection</dc:title>
 <dc:creator>Dev, Soumyabrata</dc:creator>
 <dc:creator>Savoy, Florian M.</dc:creator>
 <dc:creator>Lee, Yee Hui</dc:creator>
 <dc:creator>Winkler, Stefan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Color channel selection is essential for accurate segmentation of sky and
clouds in images obtained from ground-based sky cameras. Most prior works in
cloud segmentation use threshold based methods on color channels selected in an
ad-hoc manner. In this letter, we propose the use of rough sets for color
channel selection in visible-light images. Our proposed approach assesses color
channels with respect to their contribution for segmentation, and identifies
the most effective ones.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Geoscience and Remote Sensing Letters, 2016</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00931</dc:identifier>
 <dc:identifier>doi:10.1109/LGRS.2016.2625303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00934</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Exploration of Rectangular Grids</dc:title>
 <dc:creator>B&#xf6;ckenhauer, Hans-Joachim</dc:creator>
 <dc:creator>Fuchs, Janosch</dc:creator>
 <dc:creator>Karhum&#xe4;ki, Ulla</dc:creator>
 <dc:creator>Unger, Walter</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this paper, we consider the problem of exploring unknown environments with
autonomous agents. We model the environment as a graph with edge weights and
analyze the task of visiting all vertices of the graph at least once. The
hardness of this task heavily depends on the knowledge and the capabilities of
the agent. In our model, the agent sees the whole graph in advance, but does
not know the weights of the edges. As soon as it arrives in a vertex, it can
see the weights of all the outgoing edges. We consider the special case of two
different edge weights $1$ and $k$ and prove that the problem remains hard even
in this case. We prove a lower bound of $11/9$ on the competitive ratio of any
deterministic strategy for exploring a ladder graph and complement this result
by a $4$-competitive algorithm. All of these results hold for undirected
graphs. Exploring directed graphs, where the direction of the edges is not
known beforehand, seems to be much harder. Here, we prove that a natural greedy
strategy has a linear lower bound on the competitive ratio both in ladders and
square grids.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00938</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Eigenspace Approximation using Random Signals</dc:title>
 <dc:creator>Paratte, Johan</dc:creator>
 <dc:creator>Martin, Lionel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We focus in this work on the estimation of the first $k$ eigenvectors of any
graph Laplacian using filtering of Gaussian random signals. We prove that we
only need $k$ such signals to be able to exactly recover as many of the
smallest eigenvectors, regardless of the number of nodes in the graph. In
addition, we address key issues in implementing the theoretical concepts in
practice using accurate approximated methods. We also propose fast algorithms
both for eigenspace approximation and for the determination of the $k$th
smallest eigenvalue $\lambda_k$. The latter proves to be extremely efficient
under the assumption of locally uniform distribution of the eigenvalue over the
spectrum. Finally, we present experiments which show the validity of our method
in practice and compare it to state-of-the-art methods for clustering and
visualization both on synthetic small-scale datasets and larger real-world
problems of millions of nodes. We show that our method allows a better scaling
with the number of nodes than all previous methods while achieving an almost
perfect reconstruction of the eigenspace formed by the first $k$ eigenvectors.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00939</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recent Advances in Transient Imaging: A Computer Graphics and Vision
  Perspective</dc:title>
 <dc:creator>Jarabo, Adrian</dc:creator>
 <dc:creator>Masia, Belen</dc:creator>
 <dc:creator>Marco, Julio</dc:creator>
 <dc:creator>Gutierrez, Diego</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Transient imaging has recently made a huge impact in the computer graphics
and computer vision fields. By capturing, reconstructing, or simulating light
transport at extreme temporal resolutions, researchers have proposed novel
techniques to show movies of light in motion, see around corners, detect
objects in highly-scattering media, or infer material properties from a
distance, to name a few. The key idea is to leverage the wealth of information
in the temporal domain at the pico or nanosecond resolution, information
usually lost during the capture-time temporal integration. This paper presents
recent advances in this field of transient imaging from a graphics and vision
perspective, including capture techniques, analysis, applications and
simulation.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00946</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Architecting Time-Critical Big-Data Systems</dc:title>
 <dc:creator>Basanta-Val, Pablo</dc:creator>
 <dc:creator>Audsley, Neil</dc:creator>
 <dc:creator>Wellings, Andy</dc:creator>
 <dc:creator>Gray, Ian</dc:creator>
 <dc:creator>Fernandez, Norberto</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  - Current infrastructures for developing big-data applications are able to
process --via big-data analytics-huge amounts of data, using clusters of
machines that collaborate to perform parallel computations. However, current
infrastructures were not designed to work with the requirements of
time-critical applications; they are more focused on general-purpose
applications rather than time-critical ones. Addressing this issue from the
perspective of the real-time systems community, this paper considers
time-critical big-data. It deals with the definition of a time-critical
big-data system from the point of view of requirements, analyzing the specific
characteristics of some popular big-data applications. This analysis is
complemented by the challenges stemmed from the infrastructures that support
the applications, proposing an architecture and offering initial performance
patterns that connect application costs with infrastructure performance.
</dc:description>
 <dc:description>Comment: in IEEE Transactions on Big Data, 2016</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00946</dc:identifier>
 <dc:identifier>doi:10.1109/TBDATA.2016.2622719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00947</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Runtime Template Instantiation for C++</dc:title>
 <dc:creator>Demaille, Akim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Performance, genericity and flexibility are three valuable qualities for
scientific environments that tend to be antagonistic. C++ provides excellent
support for both performances and genericity thanks to its support for (class
and function) templates. However, a C++ templated library can hardly be
qualified as flexible: data of unexpected types cannot enter the system, which
hinders user interactions. This paper describes the approach that was taken in
the Vcsn platform to add flexibility on top of C++ templates, including runtime
template instantiation.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00954</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reply &amp; Supply: Efficient crowdsourcing when workers do more than answer
  questions</dc:title>
 <dc:creator>McAndrew, Thomas C.</dc:creator>
 <dc:creator>Guseva, Elizaveta A.</dc:creator>
 <dc:creator>Bagrow, James P.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Crowdsourcing works by distributing many small tasks to large numbers of
workers, yet the true potential of crowdsourcing lies in workers doing more
than performing simple tasks---they can apply their experience and creativity
to provide new and unexpected information to the crowdsourcer. One such case is
when workers not only answer a crowdsourcer's questions but also contribute new
questions for subsequent crowd analysis, leading to a growing set of questions.
This growth creates an inherent bias for early questions since a question
introduced earlier by a worker can be answered by more subsequent workers than
a question introduced later. Here we study how to perform efficient
crowdsourcing with such growing question sets. By modeling question sets as
networks of interrelated questions, we introduce algorithms to help curtail the
growth bias by efficiently distributing workers between exploring new questions
and addressing current questions. Experiments and simulations demonstrate that
these algorithms can efficiently explore an unbounded set of questions without
losing confidence in crowd answers.
</dc:description>
 <dc:description>Comment: 20 pages, 6 figures, 1 table</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00954</dc:identifier>
 <dc:identifier>PLoS ONE, 12(8): e0182662, 2017</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0182662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00960</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive mixed norm optical flow estimation</dc:title>
 <dc:creator>Estrela, Vania V.</dc:creator>
 <dc:creator>Franz, Matthias O.</dc:creator>
 <dc:creator>Lopes, Ricardo T.</dc:creator>
 <dc:creator>De Araujo, G. P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The pel-recursive computation of 2-D optical flow has been extensively
studied in computer vision to estimate motion from image sequences, but it
still raises a wealth of issues, such as the treatment of outliers, motion
discontinuities and occlusion. It relies on spatio-temporal brightness
variations due to motion. Our proposed adaptive regularized approach deals with
these issues within a common framework. It relies on the use of a data-driven
technique called Mixed Norm (MN) to estimate the best motion vector for a given
pixel. In our model, various types of noise can be handled, representing
different sources of error. The motion vector estimation takes into
consideration local image properties and it results from the minimization of a
mixed norm functional with a regularization parameter depending on the
kurtosis. This parameter determines the relative importance of the fourth norm
and makes the functional convex. The main advantage of the developed procedure
is that no knowledge of the noise distribution is necessary. Experiments
indicate that this approach provides robust estimates of the optical flow.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:1403.7365</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00960</dc:identifier>
 <dc:identifier>Proc. SPIE 5960, Visual Communications and Image Processing 2005,
  59603W, July 31, 2006, Beijing, China</dc:identifier>
 <dc:identifier>doi:10.1117/12.632674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00962</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multitask Protein Function Prediction Through Task Dissimilarity</dc:title>
 <dc:creator>Frasca, Marco</dc:creator>
 <dc:creator>Bianchi, Nicol&#xf2; Cesa</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>68Q01</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  Automated protein function prediction is a challenging problem with
distinctive features, such as the hierarchical organization of protein
functions and the scarcity of annotated proteins for most biological functions.
We propose a multitask learning algorithm addressing both issues. Unlike
standard multitask algorithms, which use task (protein functions) similarity
information as a bias to speed up learning, we show that dissimilarity
information enforces separation of rare class labels from frequent class
labels, and for this reason is better suited for solving unbalanced protein
function prediction problems. We support our claim by showing that a multitask
extension of the label propagation algorithm empirically works best when the
task relatedness information is represented using a dissimilarity matrix as
opposed to a similarity matrix. Moreover, the experimental comparison carried
out on three model organism shows that our method has a more stable performance
in both &quot;protein-centric&quot; and &quot;function-centric&quot; evaluation settings.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00966</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frame Theory for Signal Processing in Psychoacoustics</dc:title>
 <dc:creator>Balazs, Peter</dc:creator>
 <dc:creator>Holighaus, Nicki</dc:creator>
 <dc:creator>Necciari, Thibaud</dc:creator>
 <dc:creator>Stoeva, Diana</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  This review chapter aims to strengthen the link between frame theory and
signal processing tasks in psychoacoustics. On the one side, the basic concepts
of frame theory are presented and some proofs are provided to explain those
concepts in some detail. The goal is to reveal to hearing scientists how this
mathematical theory could be relevant for their research. In particular, we
focus on frame theory in a filter bank approach, which is probably the most
relevant view-point for audio signal processing. On the other side, basic
psychoacoustic concepts are presented to stimulate mathematicians to apply
their knowledge in this field.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00975</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Holant Problems over Boolean Domain with Non-negative
  Weights</dc:title>
 <dc:creator>Lin, Jiabao</dc:creator>
 <dc:creator>Wang, Hanpin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Holant problem is a general framework to study the computational complexity
of counting problems. We prove a complexity dichotomy theorem for Holant
problems over Boolean domain with non-negative weights. It is the first
complete Holant dichotomy where constraint functions are not necessarily
symmetric.
  Holant problems are indeed read-twice $\#$CSPs. Intuitively, some $\#$CSPs
that are $\#$P-hard become tractable when restricting to read-twice instances.
To capture them, we introduce the Block-rank-one condition. It turns out that
the condition leads to a clear separation. If a function set $\mathcal{F}$
satisfies the condition, then $\mathcal{F}$ is of affine type or product type.
Otherwise (a) $\mathrm{Holant}(\mathcal{F})$ is $\#$P-hard; or (b) every
function in $\mathcal{F}$ is a tensor product of functions of arity at most 2;
or (c) $\mathcal{F}$ is transformable to a product type by some real orthogonal
matrix. Holographic transformations play an important role in both the hardness
proof and the characterization of tractability.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00992</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully polynomial time approximation schemes (FPTAS) for some counting
  problems</dc:title>
 <dc:creator>Alon, Tzvi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this thesis we develop FPTASs for the counting problems of m-tuples,
contingency tables with two rows, and 0/1 knapsack. For the problem of counting
m-tuples, we design two algorithms, one is strongly polynomial. As far as we
know, these are the first FPTASs for this problem. For the problem of counting
contingency tables we improve significantly over the running time of existing
algorithms. For the problem of counting 0/1 knapsack solutions, we design a
simple strongly polynomial algorithm, with similar running times to the
existing algorithms. Our results are derived by using, as well as expanding,
the method of K-approximation sets and functions.
</dc:description>
 <dc:description>Comment: MA thesis</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.00995</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An empirical study for Vietnamese dependency parsing</dc:title>
 <dc:creator>Nguyen, Dat Quoc</dc:creator>
 <dc:creator>Dras, Mark</dc:creator>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents an empirical comparison of different dependency parsers
for Vietnamese, which has some unusual characteristics such as copula drop and
verb serialization. Experimental results show that the neural network-based
parsers perform significantly better than the traditional parsers. We report
the highest parsing scores published to date for Vietnamese with the labeled
attachment score (LAS) at 73.53% and the unlabeled attachment score (UAS) at
80.66%.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of the 14th Annual Workshop of the
  Australasian Language Technology Association</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.00995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01004</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Half-integral linkages in highly connected directed graphs</dc:title>
 <dc:creator>Edwards, Katherine</dc:creator>
 <dc:creator>Muzi, Irene</dc:creator>
 <dc:creator>Wollan, Paul</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the half-integral $k$-Directed Disjoint Paths Problem
($\tfrac12$kDDPP) in highly strongly connected digraphs. The integral kDDPP is
NP-complete even when restricted to instances where $k=2$, and the input graph
is $L$-strongly connected, for any $L\geq 1$. We show that when the integrality
condition is relaxed to allow each vertex to be used in two paths, the problem
becomes efficiently solvable in highly connected digraphs (even with $k$ as
part of the input). Specifically, we show that there is an absolute constant
$c$ such that for each $k\geq 2$ there exists $L(k)$ such that $\tfrac12$kDDPP
is solvable in time $O(|V(G)|^c)$ for a $L(k)$-strongly connected directed
graph $G$. As the function $L(k)$ grows rather quickly, we also show that
$\tfrac12$kDDPP is solvable in time $O(|V(G)|^{f(k)})$ in $(36k^3+2k)$-strongly
connected directed graphs. We also show that for each $\epsilon&lt;1$ deciding
half-integral feasibility of kDDPP instances is NP-complete when $k$ is given
as part of the input, even when restricted to graphs with strong connectivity
$\epsilon k$.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01006</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Heuristics for Group Decisions</dc:title>
 <dc:creator>Rahimian, M. Amin</dc:creator>
 <dc:creator>Jadbabaie, Ali</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>91B06, 91A35, 62C10</dc:subject>
 <dc:description>  We propose a model of inference and heuristic decision-making in groups that
is rooted in the Bayes rule but avoids the complexities of rational inference
in partially observed environments with incomplete information, which are
characteristic of group interactions. Our model is also consistent with a
dual-process psychological theory of thinking: the group members behave
rationally at the initiation of their interactions with each other (the slow
and deliberative mode); however, in the ensuing decision epochs, they rely on a
heuristic that replicates their experiences from the first stage (the fast
automatic mode). We specialize this model to a group decision scenario where
private observations are received at the beginning, and agents aim to take the
best action given the aggregate observations of all group members. We study the
implications of the information structure together with the properties of the
probability distributions which determine the structure of the so-called
&quot;Bayesian heuristics&quot; that the agents follow in our model. We also analyze the
group decision outcomes in two classes of linear action updates and log-linear
belief updates and show that many inefficiencies arise in group decisions as a
result of repeated interactions between individuals, leading to overconfident
beliefs as well as choice-shifts toward extremes. Nevertheless, balanced
regular structures demonstrate a measure of efficiency in terms of aggregating
the initial information of individuals. These results not only verify some
well-known insights about group decision-making but also complement these
insights by revealing additional mechanistic interpretations for the group
declension-process, as well as psychological and cognitive intuitions about the
group interaction model.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01009</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Shift Keying on the Hypersphere: Peak Power-Efficient MIMO
  Communications</dc:title>
 <dc:creator>Rachinger, Christoph</dc:creator>
 <dc:creator>M&#xfc;ller, Ralf R.</dc:creator>
 <dc:creator>Huber, Johannes B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Phase Shift Keying on the Hypersphere (PSKH), a generalization of
conventional Phase Shift Keying (PSK) for Multiple-Input Multiple-Output (MIMO)
systems, is introduced. In PSKH, constellation points are distributed on a
multidimensional hypersphere. The use of such constellations with a
Peak-To-Average-Sum-Power-Ratio (PASPR) of 1 allows to use load-modulated
transmitters which can cope with a small backoff, which in turn results in a
high power efficiency. In this paper, we discuss several methods how to
generate PSKH constellations and compare their performance. After applying
conventional Pulse-Amplitude Modulation (PAM), the PASPR of the continuous time
PSKH signal depends on the choice of the pulse shaping method. This choice also
influences bandwidth and power efficiency of a PSKH system. In order to reduce
the PASPR of the continuous transmission signal, we use spherical interpolation
to generate a smooth signal over the hypersphere and present corresponding
receiver techniques. Additionally, complexity reduction techniques are proposed
and compared. Finally, we discuss the methods presented in this paper regarding
their trade-offs with respect to PASPR, bandwidth, power efficiency and
receiver complexity.
</dc:description>
 <dc:description>Comment: This paper has been submitted to IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2016-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01017</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving the Persistent Phylogeny Problem in polynomial time</dc:title>
 <dc:creator>Bonizzoni, Paola</dc:creator>
 <dc:creator>Della Vedova, Gianluca</dc:creator>
 <dc:creator>Trucco, Gabriella</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The notion of a Persistent Phylogeny generalizes the well-known Perfect
phylogeny model that has been thoroughly investigated and is used to explain a
wide range of evolutionary phenomena. More precisely, while the Perfect
Phylogeny model allows each character to be acquired once in the entire
evolutionary history while character losses are not allowed, the Persistent
Phylogeny model allows each character to be both acquired and lost exactly once
in the evolutionary history. The Persistent Phylogeny Problem (PPP) is the
problem of reconstructing a Persistent phylogeny tree, if it exists, from a
binary matrix where the rows represent the species (or the individuals) studied
and the columns represent the characters that each species can have.
  While the Perfect Phylogeny has a linear-time algorithm, the computational
complexity of PPP has been posed, albeit in an equivalent formulation, 20 years
ago. We settle the question by providing a polynomial time algorithm for the
Persistent Phylogeny problem.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01029</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Sum of Linear Coefficients of a Boolean Valued Function</dc:title>
 <dc:creator>Jha, Sumit Kumar</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Let $f:\{-1,1\}^{n}\rightarrow \{-1,1\}$ be a Boolean valued function having
total degree $d$. Then a conjecture due to Servedio and Gopalan asserts that
$\sum_{i=1}^{n}\widehat{f}(i)\leq \sum_{j=1}^{d}\widehat{\text{Maj}}_{d}(j)$
where $\text{Maj}_{d}$ is the majority function on $d$ bits. Here we give some
alternative formalisms of this conjecture involving the discrete derivative
operators on $f$.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01030</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Support Recovery with Non-smooth Loss Functions</dc:title>
 <dc:creator>Degraux, K&#xe9;vin</dc:creator>
 <dc:creator>Peyr&#xe9;, Gabriel</dc:creator>
 <dc:creator>Fadili, Jalal M.</dc:creator>
 <dc:creator>Jacques, Laurent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the support recovery guarantees of underdetermined
sparse regression using the $\ell_1$-norm as a regularizer and a non-smooth
loss function for data fidelity. More precisely, we focus in detail on the
cases of $\ell_1$ and $\ell_\infty$ losses, and contrast them with the usual
$\ell_2$ loss. While these losses are routinely used to account for either
sparse ($\ell_1$ loss) or uniform ($\ell_\infty$ loss) noise models, a
theoretical analysis of their performance is still lacking. In this article, we
extend the existing theory from the smooth $\ell_2$ case to these non-smooth
cases. We derive a sharp condition which ensures that the support of the vector
to recover is stable to small additive noise in the observations, as long as
the loss constraint size is tuned proportionally to the noise level. A
distinctive feature of our theory is that it also explains what happens when
the support is unstable. While the support is not stable anymore, we identify
an &quot;extended support&quot; and show that this extended support is stable to small
additive noise. To exemplify the usefulness of our theory, we give a detailed
numerical analysis of the support stability/instability of compressed sensing
recovery with these different losses. This highlights different parameter
regimes, ranging from total support stability to progressively increasing
support instability.
</dc:description>
 <dc:description>Comment: in Proc. NIPS 2016</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01032</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Drive Mode Optimization and Path Planning for Plug-in Hybrid Electric
  Vehicles</dc:title>
 <dc:creator>Chau, Chi-Kin</dc:creator>
 <dc:creator>Elbassioni, Khaled</dc:creator>
 <dc:creator>Tseng, Chien-Ming</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Drive modes are driver-selectable pre-set configurations of powertrain and
certain vehicle parameters. Plug-in hybrid electric vehicles (PHEVs) typically
feature special options of drive modes that can affect the hybrid energy source
management system, for example, electric vehicle (EV) mode (that draws fully on
battery) and charge sustaining (CS) mode (that utilizes internal combustion
engine to charge battery while propelling the vehicle). This paper studies an
optimization problem to enable the driver to select the appropriate drive modes
for fuel minimization. We develop optimization algorithms that optimize the
decisions of drive modes based on trip information, and integrated with path
planning to find an optimal path, considering intermediate filling and charging
stations. We further provide an online algorithm that is based on the revealed
trip information. We evaluate our algorithms empirically on a Chevrolet Volt,
which shows significant fuel savings.
</dc:description>
 <dc:description>Comment: To appear in IEEE Transactions on Intelligent Transportation Systems</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01032</dc:identifier>
 <dc:identifier>IEEE Transactions on Intelligent Transportation Systems ( Volume:
  18, Issue: 12, Dec. 2017 ), pp 3421 - 3432</dc:identifier>
 <dc:identifier>doi:10.1109/TITS.2017.2691606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01042</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Way Massive MIMO with Maximum-Ratio Processing and Imperfect CSI</dc:title>
 <dc:creator>Ho, Chung Duc</dc:creator>
 <dc:creator>Ngo, Hien Quoc</dc:creator>
 <dc:creator>Matthaiou, Michail</dc:creator>
 <dc:creator>Duong, Trung Q.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers a multi-way massive multiple-input multiple-output
relaying system, where single-antenna users exchange their information-bearing
signals with the help of one relay station equipped with unconventionally many
antennas. The relay first estimates the channels to all users through the pilot
signals transmitted from them. Then, the relay uses maximum-ratio processing
(i.e. maximum-ratio combining in the multiple-access phase and maximum-ratio
transmission in the broadcast phase) to process the signals. A rigorous
closed-form expression for the spectral efficiency is derived. The effects of
the channel estimation error, the channel estimation overhead, the length of
the training duration, and the randomness of the user locations are analyzed.
We show that by deploying massive antenna arrays at the relay and simple
maximum-ratio processing, we can serve many users in the same time-frequency
resource, while maintaining a given quality-of-service for each user.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01046</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Pivot with Adversarial Networks</dc:title>
 <dc:creator>Louppe, Gilles</dc:creator>
 <dc:creator>Kagan, Michael</dc:creator>
 <dc:creator>Cranmer, Kyle</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Several techniques for domain adaptation have been proposed to account for
differences in the distribution of the data used for training and testing. The
majority of this work focuses on a binary domain label. Similar problems occur
in a scientific context where there may be a continuous family of plausible
data generation processes associated to the presence of systematic
uncertainties. Robust inference is possible if it is based on a pivot -- a
quantity whose distribution does not depend on the unknown values of the
nuisance parameters that parametrize this family of data generation processes.
In this work, we introduce and derive theoretical results for a training
procedure based on adversarial networks for enforcing the pivotal property (or,
equivalently, fairness with respect to continuous attributes) on a predictive
model. The method includes a hyperparameter to control the trade-off between
accuracy and robustness. We demonstrate the effectiveness of this approach with
a toy example and examples from particle physics.
</dc:description>
 <dc:description>Comment: v1: Original submission. v2: Fixed references. v3: version submitted
  to NIPS'2017. Code available at
  https://github.com/glouppe/paper-learning-to-pivot</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01055</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space
  Matter?</dc:title>
 <dc:creator>Peng, Xue Bin</dc:creator>
 <dc:creator>van de Panne, Michiel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The use of deep reinforcement learning allows for high-dimensional state
descriptors, but little is known about how the choice of action representation
impacts the learning difficulty and the resulting performance. We compare the
impact of four different action parameterizations (torques, muscle-activations,
target joint angles, and target joint-angle velocities) in terms of learning
time, policy robustness, motion quality, and policy query rates. Our results
are evaluated on a gait-cycle imitation task for multiple planar articulated
figures and multiple gaits. We demonstrate that the local feedback provided by
higher-level action parameterizations can significantly impact the learning,
robustness, and quality of the resulting policies.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01055</dc:identifier>
 <dc:identifier>doi:10.1145/3099564.3099567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01056</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Immigrant community integration in world cities</dc:title>
 <dc:creator>Lamanna, Fabio</dc:creator>
 <dc:creator>Lenormand, Maxime</dc:creator>
 <dc:creator>Salas-Olmedo, Mar&#xed;a Henar</dc:creator>
 <dc:creator>Romanillos, Gustavo</dc:creator>
 <dc:creator>Gon&#xe7;alves, Bruno</dc:creator>
 <dc:creator>Ramasco, Jos&#xe9; J.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Migrant and hosting communities face long-term challenges in the integration
process. Immigrants must adapt to new laws and ways of life, while hosts need
to adjust to multicultural societies. Integration impacts many facets of life
such as access to jobs, real state and public services and can be well
approximated by the extent of spatial segregation of minority group residence.
Here we conduct an extensive study of immigrant integration in 53 world cities
by using Twitter language detection and by introducing metrics of spatial
segregation. In this way, we quantify the Power of Integration of cities (their
capacity to integrate diverse cultures), and characterize the relations between
cultures when they act in the role of hosts and immigrants.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures + Appendix</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01060</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A-Ward_p\b{eta}: Effective hierarchical clustering using the Minkowski
  metric and a fast k -means initialisation</dc:title>
 <dc:creator>de Amorim, Renato Cordeiro</dc:creator>
 <dc:creator>Makarenkov, Vladimir</dc:creator>
 <dc:creator>Mirkin, Boris</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we make two novel contributions to hierarchical clustering.
First, we introduce an anomalous pattern initialisation method for hierarchical
clustering algorithms, called A-Ward, capable of substantially reducing the
time they take to converge. This method generates an initial partition with a
sufficiently large number of clusters. This allows the cluster merging process
to start from this partition rather than from a trivial partition composed
solely of singletons. Our second contribution is an extension of the Ward and
Ward p algorithms to the situation where the feature weight exponent can differ
from the exponent of the Minkowski distance. This new method, called A-Ward
p\b{eta} , is able to generate a much wider variety of clustering solutions. We
also demonstrate that its parameters can be estimated reasonably well by using
a cluster validity index. We perform numerous experiments using data sets with
two types of noise, insertion of noise features and blurring within-cluster
values of some features. These experiments allow us to conclude: (i) our
anomalous pattern initialisation method does indeed reduce the time a
hierarchical clustering algorithm takes to complete, without negatively
impacting its cluster recovery ability; (ii) A-Ward p\b{eta} provides better
cluster recovery than both Ward and Ward p.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01060</dc:identifier>
 <dc:identifier>Information Sciences, 370, 343-354 (2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.ins.2016.07.076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01063</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Invariants for Probabilistic Termination</dc:title>
 <dc:creator>Chatterjee, Krishnendu</dc:creator>
 <dc:creator>Novotn&#xfd;, Petr</dc:creator>
 <dc:creator>&#x17d;ikeli&#x107;, &#x110;or&#x111;e</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Termination is one of the basic liveness properties, and we study the
termination problem for probabilistic programs with real-valued variables.
Previous works focused on the qualitative problem that asks whether an input
program terminates with probability~1 (almost-sure termination). A powerful
approach for this qualitative problem is the notion of ranking supermartingales
with respect to a given set of invariants. The quantitative problem
(probabilistic termination) asks for bounds on the termination probability. A
fundamental and conceptual drawback of the existing approaches to address
probabilistic termination is that even though the supermartingales consider the
probabilistic behavior of the programs, the invariants are obtained completely
ignoring the probabilistic aspect.
  In this work we address the probabilistic termination problem for
linear-arithmetic probabilistic programs with nondeterminism. We define the
notion of {\em stochastic invariants}, which are constraints along with a
probability bound that the constraints hold. We introduce a concept of {\em
repulsing supermartingales}. First, we show that repulsing supermartingales can
be used to obtain bounds on the probability of the stochastic invariants.
Second, we show the effectiveness of repulsing supermartingales in the
following three ways: (1)~With a combination of ranking and repulsing
supermartingales we can compute lower bounds on the probability of termination;
(2)~repulsing supermartingales provide witnesses for refutation of almost-sure
termination; and (3)~with a combination of ranking and repulsing
supermartingales we can establish persistence properties of probabilistic
programs.
  We also present results on related computational problems and an experimental
evaluation of our approach on academic examples.
</dc:description>
 <dc:description>Comment: Full version of a paper published at POPL 2017. 20 pages</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01078</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classifying unavoidable Tverberg partitions</dc:title>
 <dc:creator>Bukh, Boris</dc:creator>
 <dc:creator>Loh, Po-Shen</dc:creator>
 <dc:creator>Nivasch, Gabriel</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>52C99, 68U05</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  Let $T(d,r) = (r-1)(d+1)+1$ be the parameter in Tverberg's theorem, and call
a partition $\mathcal I$ of $\{1,2,\ldots,T(d,r)\}$ into $r$ parts a &quot;Tverberg
type&quot;. We say that $\mathcal I$ &quot;occurs&quot; in an ordered point sequence $P$ if
$P$ contains a subsequence $P'$ of $T(d,r)$ points such that the partition of
$P'$ that is order-isomorphic to $\mathcal I$ is a Tverberg partition. We say
that $\mathcal I$ is &quot;unavoidable&quot; if it occurs in every sufficiently long
point sequence.
  In this paper we study the problem of determining which Tverberg types are
unavoidable. We conjecture a complete characterization of the unavoidable
Tverberg types, and we prove some cases of our conjecture for $d\le 4$. Along
the way, we study the avoidability of many other geometric predicates.
  Our techniques also yield a large family of $T(d,r)$-point sets for which the
number of Tverberg partitions is exactly $(r-1)!^d$. This lends further support
for Sierksma's conjecture on the number of Tverberg partitions.
</dc:description>
 <dc:description>Comment: Revision following referee comments. 32 pages, 8 figures</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01078</dc:identifier>
 <dc:identifier>Journal of Computational Geometry 8(1):174-205, 2017</dc:identifier>
 <dc:identifier>doi:10.20382/jocg.v8i1a9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01080</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Modeling of Progressive Filtering</dc:title>
 <dc:creator>Armano, Giuliano</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Progressive filtering is a simple way to perform hierarchical classification,
inspired by the behavior that most humans put into practice while attempting to
categorize an item according to an underlying taxonomy. Each node of the
taxonomy being associated with a different category, one may visualize the
categorization process by looking at the item going downwards through all the
nodes that accept it as belonging to the corresponding category. This paper is
aimed at modeling the progressive filtering technique from a probabilistic
perspective, in a hierarchical text categorization setting. As a result, the
designer of a system based on progressive filtering should be facilitated in
the task of devising, training, and testing it.
</dc:description>
 <dc:description>Comment: The article entitled Modeling Progressive Filtering, published on
  Fundamenta Informaticae (Vol. 138, Issue 3, pp. 285-320, July 2015), has been
  derived from this extended report</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01083</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hybrid Approach to Word Sense Disambiguation Combining Supervised and
  Unsupervised Learning</dc:title>
 <dc:creator>Pal, Alok Ranjan</dc:creator>
 <dc:creator>Kundu, Anirban</dc:creator>
 <dc:creator>Singh, Abhay</dc:creator>
 <dc:creator>Shekhar, Raj</dc:creator>
 <dc:creator>Sinha, Kunal</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we are going to find meaning of words based on distinct
situations. Word Sense Disambiguation is used to find meaning of words based on
live contexts using supervised and unsupervised approaches. Unsupervised
approaches use online dictionary for learning, and supervised approaches use
manual learning sets. Hand tagged data are populated which might not be
effective and sufficient for learning procedure. This limitation of information
is main flaw of the supervised approach. Our proposed approach focuses to
overcome the limitation using learning set which is enriched in dynamic way
maintaining new data. Trivial filtering method is utilized to achieve
appropriate training data. We introduce a mixed methodology having Modified
Lesk approach and Bag-of-Words having enriched bags using learning methods. Our
approach establishes the superiority over individual Modified Lesk and
Bag-of-Words approaches based on experimentation.
</dc:description>
 <dc:description>Comment: 13 pages in International Journal of Artificial Intelligence &amp;
  Applications (IJAIA), Vol. 4, No. 4, July 2013</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01083</dc:identifier>
 <dc:identifier>doi:10.5121/ijaia.2013.4409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01086</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Bayesian Inference of Diffusion Networks</dc:title>
 <dc:creator>Shaghaghian, Shohreh</dc:creator>
 <dc:creator>Coates, Mark</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Understanding the process by which a contagion disseminates throughout a
network is of great importance in many real world applications. The required
sophistication of the inference approach depends on the type of information we
want to extract as well as the number of observations that are available to us.
We analyze scenarios in which not only the underlying network structure
(parental relationships and link strengths) needs to be detected, but also the
infection times must be estimated. We assume that our only observation of the
diffusion process is a set of time series, one for each node of the network,
which exhibit changepoints when an infection occurs. After formulating a model
to describe the contagion, and selecting appropriate prior distributions, we
seek to find the set of model parameters that best explains our observations.
Modeling the problem in a Bayesian framework, we exploit Monte Carlo Markov
Chain,
  Sequential Monte Carlo, and time series analysis techniques to develop batch
and online inference algorithms. We evaluate the performance of our proposed
algorithms via numerical simulations of synthetic network contagions and
analysis of real-world datasets.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01090</identifier>
 <datestamp>2017-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General and Fractional Hypertree Decompositions: Hard and Easy Cases</dc:title>
 <dc:creator>Fischl, Wolfgang</dc:creator>
 <dc:creator>Gottlob, Georg</dc:creator>
 <dc:creator>Pichler, Reinhard</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Hypertree decompositions, as well as the more powerful generalized hypertree
decompositions (GHDs), and the yet more general fractional hypertree
decompositions (FHD) are hypergraph decomposition methods successfully used for
answering conjunctive queries and for the solution of constraint satisfaction
problems. Every hypergraph H has a width relative to each of these
decomposition methods: its hypertree width hw(H), its generalized hypertree
width ghw(H), and its fractional hypertree width fhw(H), respectively.
  It is known that hw(H) &lt;= k can be checked in polynomial time for fixed k,
while checking ghw(H) &lt;= k is NP-complete for any k greater than or equal to 3.
The complexity of checking fhw(H) &lt;= k for a fixed k has been open for more
than a decade.
  We settle this open problem by showing that checking fhw(H) &lt;= k is
NP-complete, even for k=2. The same construction allows us to prove also the
NP-completeness of checking ghw(H) &lt;= k for k=2. After proving these hardness
results, we identify meaningful restrictions, for which checking for bounded
ghw or fhw becomes tractable.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01093</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance of Interoperator Fixed-Mobile Network Sharing</dc:title>
 <dc:creator>Szcze&#x15b;niak, Ireneusz</dc:creator>
 <dc:creator>Pach, Andrzej R.</dc:creator>
 <dc:creator>Wo&#x17a;na-Szcze&#x15b;niak, Bo&#x17c;ena</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We evaluate the downstream performance of our novel interoperator
fixed-mobile network sharing, in which operators exchange data in their access
networks. We propose a performance evaluation algorithm, and report credible
performance evaluation results obtained for 204600 randomly-generated passive
optical networks. We show that with the proposed sharing, operators can
increase their access network performance even twofold with software-defined
upgrades, and with no or minimal new hardware required.
</dc:description>
 <dc:description>Comment: submitted to a conference</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01099</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Informational and Causal Architecture of Continuous-time Renewal and
  Hidden Semi-Markov Processes</dc:title>
 <dc:creator>Marzen, Sarah E.</dc:creator>
 <dc:creator>Crutchfield, James P.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  We introduce the minimal maximally predictive models ({\epsilon}-machines) of
processes generated by certain hidden semi-Markov models. Their causal states
are either hybrid discrete-continuous or continuous random variables and
causal-state transitions are described by partial differential equations.
Closed-form expressions are given for statistical complexities, excess
entropies, and differential information anatomy rates. We present a complete
analysis of the {\epsilon}-machines of continuous-time renewal processes and,
then, extend this to processes generated by unifilar hidden semi-Markov models
and semi-Markov models. Our information-theoretic analysis leads to new
expressions for the entropy rate and the rates of related information measures
for these very general continuous-time process classes.
</dc:description>
 <dc:description>Comment: 16 pages, 7 figures;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/ctrp.htm</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01099</dc:identifier>
 <dc:identifier>doi:10.1007/s10955-017-1793-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01101</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CogALex-V Shared Task: ROOT18</dc:title>
 <dc:creator>Chersoni, Emmanuele</dc:creator>
 <dc:creator>Rambelli, Giulia</dc:creator>
 <dc:creator>Santus, Enrico</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we describe ROOT 18, a classifier using the scores of several
unsupervised distributional measures as features to discriminate between
semantically related and unrelated words, and then to classify the related
pairs according to their semantic relation (i.e. synonymy, antonymy, hypernymy,
part-whole meronymy). Our classifier participated in the CogALex-V Shared Task,
showing a solid performance on the first subtask, but a poor performance on the
second subtask. The low scores reported on the second subtask suggest that
distributional measures are not sufficient to discriminate between multiple
semantic relations at once.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01109</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From degree-correlated to payoff-correlated activity for an optimal
  resolution of social dilemmas</dc:title>
 <dc:creator>Aleta, Alberto</dc:creator>
 <dc:creator>Meloni, Sandro</dc:creator>
 <dc:creator>Perc, Matjaz</dc:creator>
 <dc:creator>Moreno, Yamir</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  An active participation of players in evolutionary games depends on several
factors, ranging from personal stakes to the properties of the interaction
network. Diverse activity patterns thus have to be taken into account when
studying the evolution of cooperation in social dilemmas. Here we study the
weak prisoner's dilemma game, where the activity of each player is determined
in a probabilistic manner either by its degree or by its payoff. While
degree-correlated activity introduces cascading failures of cooperation that
are particularly severe on scale-free networks with frequently inactive hubs,
payoff-correlated activity provides a more nuanced activity profile, which
ultimately hinders systemic breakdowns of cooperation. To determine optimal
conditions for the evolution of cooperation, we introduce an exponential decay
to payoff-correlated activity that determines how fast the activity of a player
returns to its default state. We show that there exists an intermediate decay
rate, at which the resolution of the social dilemma is optimal. This can be
explained by the emerging activity patterns of players, where the inactivity of
hubs is compensated effectively by the increased activity of average-degree
players, who through their collective influence in the network sustain a higher
level of cooperation. The sudden drops in the fraction of cooperators observed
with degree-correlated activity therefore vanish, and so does the need for the
lengthy spatiotemporal reorganization of compact cooperative clusters. The
absence of such asymmetric dynamic instabilities thus leads to an optimal
resolution of social dilemmas, especially when the conditions for the evolution
of cooperation are strongly adverse.
</dc:description>
 <dc:description>Comment: 8 two-column pages, 6 figures; accepted for publication in Physical
  Review E</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2016-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01109</dc:identifier>
 <dc:identifier>Phys. Rev. E 94, 062315 (2016)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.94.062315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01115</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Coexistence for the Hard-Core Model on ${\mathbb Z}^2$</dc:title>
 <dc:creator>Blanca, Antonio</dc:creator>
 <dc:creator>Chen, Yuxuan</dc:creator>
 <dc:creator>Galvin, David</dc:creator>
 <dc:creator>Randall, Dana</dc:creator>
 <dc:creator>Tetali, Prasad</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>82B20, 82B26, 05A16, 05C70</dc:subject>
 <dc:description>  The hard-core model has attracted much attention across several disciplines,
representing lattice gases in statistical physics and independent sets in
discrete mathematics and computer science. On finite graphs, we are given a
parameter $\lambda$, and an independent set $I$ arises with probability
proportional to $\lambda^{|I|}$. On infinite graphs a Gibbs measure is defined
as a suitable limit with the correct conditional probabilities, and we are
interested in determining when this limit is unique and when there is phase
coexistence, i.e., existence of multiple Gibbs measures.
  It has long been conjectured that on ${\mathbb Z}^2$ this model has a
critical value $\lambda_c \approx 3.796$ with the property that if $\lambda &lt;
\lambda_c$ then it exhibits uniqueness of phase, while if $\lambda &gt; \lambda_c$
then there is phase coexistence. Much of the work to date on this problem has
focused on the regime of uniqueness, with the state of the art being recent
work of Sinclair, Srivastava, \v{S}tefankovi\v{c} and Yin showing that there is
a unique Gibbs measure for all $\lambda &lt; 2.538$. Here we give the first
non-trivial result in the other direction, showing that there are multiple
Gibbs measures for all $\lambda &gt; 5.3506$. There is some potential for lowering
this bound, but with the methods we are using we cannot hope to replace
$5.3506$ with anything below about $4.8771$.
  Our proof begins along the lines of the standard Peierls argument, but we add
two innovations. First, following ideas of Koteck\'y and Randall, we construct
an event that distinguishes two boundary conditions and always has long
contours associated with it, obviating the need to accurately enumerate short
contours. Second, we obtain improved bounds on the number of contours by
relating them to a new class of self-avoiding walks on an oriented version of
${\mathbb Z}^2$.
</dc:description>
 <dc:description>Comment: A weaker version of this result, with a proof outline, was announced
  in A. Blanca, D. Galvin, D. Randall and P. Tetali, Phase Coexistence and Slow
  Mixing for the Hard-Core Model on Z^2, Lecture Notes in Comput. Sci. 8096
  (Proc. APPROX/RANDOM 2013) (2013), 379-394, arXiv:1211.6182. Here we give the
  full proof</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01116</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Paragraph Vectors</dc:title>
 <dc:creator>Grzegorczyk, Karol</dc:creator>
 <dc:creator>Kurdziel, Marcin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently Le &amp; Mikolov described two log-linear models, called Paragraph
Vector, that can be used to learn state-of-the-art distributed representations
of documents. Inspired by this work, we present Binary Paragraph Vector models:
simple neural networks that learn short binary codes for fast information
retrieval. We show that binary paragraph vectors outperform autoencoder-based
binary codes, despite using fewer bits. We also evaluate their precision in
transfer learning settings, where binary codes are inferred for documents
unrelated to the training corpus. Results from these experiments indicate that
binary paragraph vectors can capture semantics relevant for various
domain-specific documents. Finally, we present a model that simultaneously
learns short binary codes and longer, real-valued representations. This model
can be used to rapidly retrieve a short list of highly relevant documents from
a large document collection.
</dc:description>
 <dc:description>Comment: Accepted to appear as a regular paper at the 2nd Workshop on
  Representation Learning for NLP at ACL 2017</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01120</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Families of Practical Fast Matrix Multiplication Algorithms</dc:title>
 <dc:creator>Huang, Jianyu</dc:creator>
 <dc:creator>Rice, Leslie</dc:creator>
 <dc:creator>Matthews, Devin A.</dc:creator>
 <dc:creator>van de Geijn, Robert A.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Matrix multiplication (GEMM) is a core operation to numerous scientific
applications. Traditional implementations of Strassen-like fast matrix
multiplication (FMM) algorithms often do not perform well except for very large
matrix sizes, due to the increased cost of memory movement, which is
particularly noticeable for non-square matrices. Such implementations also
require considerable workspace and modifications to the standard BLAS
interface. We propose a code generator framework to automatically implement a
large family of FMM algorithms suitable for multiplications of arbitrary matrix
sizes and shapes. By representing FMM with a triple of matrices [U,V,W] that
capture the linear combinations of submatrices that are formed, we can use the
Kronecker product to define a multi-level representation of Strassen-like
algorithms. Incorporating the matrix additions that must be performed for
Strassen-like algorithms into the inherent packing and micro-kernel operations
inside GEMM avoids extra workspace and reduces the cost of memory movement.
Adopting the same loop structures as high-performance GEMM implementations
allows parallelization of all FMM algorithms with simple but efficient data
parallelism without the overhead of task parallelism. We present a simple
performance model for general FMM algorithms and compare actual performance of
20+ FMM algorithms to modeled predictions. Our implementations demonstrate a
performance benefit over conventional GEMM on single core and multi-core
systems. This study shows that Strassen-like fast matrix multiplication can be
incorporated into libraries for practical use.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01129</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross: Efficient Low-rank Tensor Completion</dc:title>
 <dc:creator>Zhang, Anru</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The completion of tensors, or high-order arrays, attracts significant
attention in recent research. Current literature on tensor completion primarily
focuses on recovery from a set of uniformly randomly measured entries, and the
required number of measurements to achieve recovery is not guaranteed to be
optimal. In addition, the implementation of some previous methods are NP-hard.
In this article, we propose a framework for low-rank tensor completion via a
novel tensor measurement scheme we name Cross. The proposed procedure is
efficient and easy to implement. In particular, we show that a third order
tensor of Tucker rank-$(r_1, r_2, r_3)$ in $p_1$-by-$p_2$-by-$p_3$ dimensional
space can be recovered from as few as $r_1r_2r_3 + r_1(p_1-r_1) + r_2(p_2-r_2)
+ r_3(p_3-r_3)$ noiseless measurements, which matches the sample complexity
lower-bound. In the case of noisy measurements, we also develop a theoretical
upper bound and the matching minimax lower bound for recovery error over
certain classes of low-rank tensors for the proposed procedure. The results can
be further extended to fourth or higher-order tensors. Simulation studies show
that the method performs well under a variety of settings. Finally, the
procedure is illustrated through a real dataset in neuroimaging.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01130</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pilot Distribution Optimization and Power Control in Multi-Cellular
  Large Scale MIMO Systems</dc:title>
 <dc:creator>Marinello, Jose Carlos</dc:creator>
 <dc:creator>Abrao, Taufik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Massive MIMO communication systems have been identified as one of the most
prominent technologies of the next generation wireless standards, such as 5G,
due to the large gains in energy and spectral efficiency that can be achieved.
In the asymptotic condition of infinite number of antennas at the base station
(BS), the performance bottleneck of these systems is due to the pilot
contamination effect, i.e., the directional interference arising from users in
adjacent cells that reuse the same set of orthogonal training sequences, and
thus the interference seen by each user is determined by the pilot sequence
assigned to him. We show in this paper that the system performance can be
improved by appropriately assigning the pilot sequences to the users, in the
so-called pilot allocation scheme. Depending on the optimization metric
adopted, it is more advantageous to a user with certain long- term fading
coefficient be assigned to a specific pilot sequence, whose interference can be
completely estimated in advance by the BS by only knowing the long term fading
coefficients of users in adjacent cells. Besides, if the objective is to
maximize the number of users with a target quality of service, we have shown
that the pilot allocation schemes can be combined with power control
algorithms, resulting in much more improvements for the system. For unitary
frequency reuse factor, we have found that the data throughput provided for 95%
of the users increases when applying power control algorithm from 134kbps to
1.461Mbps with no pilot allocation, while this performance gain provided by
power control changes from 793kbps to 6.743Mbps when pilot allocation is
employed. If the reuse factor increases to 3, a 95%-likely data throughput of
17.310Mbps can be assured when pilot allocation and power control are suitably
combined.
</dc:description>
 <dc:description>Comment: 21 pages, 5 figures; submitted paper for a journal</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01137</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Memory Bandwidth-Efficient Hybrid Radix Sort on GPUs</dc:title>
 <dc:creator>Stehle, Elias</dc:creator>
 <dc:creator>Jacobsen, Hans-Arno</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Sorting is at the core of many database operations, such as index creation,
sort-merge joins, and user-requested output sorting. As GPUs are emerging as a
promising platform to accelerate various operations, sorting on GPUs becomes a
viable endeavour. Over the past few years, several improvements have been
proposed for sorting on GPUs, leading to the first radix sort implementations
that achieve a sorting rate of over one billion 32-bit keys per second. Yet,
state-of-the-art approaches are heavily memory bandwidth-bound, as they require
substantially more memory transfers than their CPU-based counterparts.
  Our work proposes a novel approach that almost halves the amount of memory
transfers and, therefore, considerably lifts the memory bandwidth limitation.
Being able to sort two gigabytes of eight-byte records in as little as 50
milliseconds, our approach achieves a 2.32-fold improvement over the
state-of-the-art GPU-based radix sort for uniform distributions, sustaining a
minimum speed-up of no less than a factor of 1.66 for skewed distributions.
  To address inputs that either do not reside on the GPU or exceed the
available device memory, we build on our efficient GPU sorting approach with a
pipelined heterogeneous sorting algorithm that mitigates the overhead
associated with PCIe data transfers. Comparing the end-to-end sorting
performance to the state-of-the-art CPU-based radix sort running 16 threads,
our heterogeneous approach achieves a 2.06-fold and a 1.53-fold improvement for
sorting 64 GB key-value pairs with a skewed and a uniform distribution,
respectively.
</dc:description>
 <dc:description>Comment: 16 pages, accepted at SIGMOD 2017</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01137</dc:identifier>
 <dc:identifier>SIGMOD (2017) 417-432</dc:identifier>
 <dc:identifier>doi:10.1145/3035918.3064043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01141</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extension Theorems for Various Weight Functions over Frobenius Bimodules</dc:title>
 <dc:creator>Gluesing-Luerssen, Heide</dc:creator>
 <dc:creator>Pllaha, Tefjol</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>94B05, 16L60, 16P10</dc:subject>
 <dc:description>  In this paper we study codes where the alphabet is a finite Frobenius
bimodule over a finite ring. We discuss the extension property for various
weight functions. Employing an entirely character-theoretic approach and a
duality theory for partitions on Frobenius bimodules we derive alternative
proofs for the facts that the Hamming weight and the homogeneous weight satisfy
the extension property. We also use the same techniques to derive the extension
property for other weights, such as the Rosenbloom-Tsfasman weight.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01142</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using a Deep Reinforcement Learning Agent for Traffic Signal Control</dc:title>
 <dc:creator>Genders, Wade</dc:creator>
 <dc:creator>Razavi, Saiedeh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Ensuring transportation systems are efficient is a priority for modern
society. Technological advances have made it possible for transportation
systems to collect large volumes of varied data on an unprecedented scale. We
propose a traffic signal control system which takes advantage of this new, high
quality data, with minimal abstraction compared to other proposed systems. We
apply modern deep reinforcement learning methods to build a truly adaptive
traffic signal control agent in the traffic microsimulator SUMO. We propose a
new state space, the discrete traffic state encoding, which is information
dense. The discrete traffic state encoding is used as input to a deep
convolutional neural network, trained using Q-learning with experience replay.
Our agent was compared against a one hidden layer neural network traffic signal
control agent and reduces average cumulative delay by 82%, average queue length
by 66% and average travel time by 20%.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01144</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Categorical Reparameterization with Gumbel-Softmax</dc:title>
 <dc:creator>Jang, Eric</dc:creator>
 <dc:creator>Gu, Shixiang</dc:creator>
 <dc:creator>Poole, Ben</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Categorical variables are a natural choice for representing discrete
structure in the world. However, stochastic neural networks rarely use
categorical latent variables due to the inability to backpropagate through
samples. In this work, we present an efficient gradient estimator that replaces
the non-differentiable sample from a categorical distribution with a
differentiable sample from a novel Gumbel-Softmax distribution. This
distribution has the essential property that it can be smoothly annealed into a
categorical distribution. We show that our Gumbel-Softmax estimator outperforms
state-of-the-art gradient estimators on structured output prediction and
unsupervised generative modeling tasks with categorical latent variables, and
enables large speedups on semi-supervised classification.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01146</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Approximate Local Minima Faster than Gradient Descent</dc:title>
 <dc:creator>Agarwal, Naman</dc:creator>
 <dc:creator>Allen-Zhu, Zeyuan</dc:creator>
 <dc:creator>Bullins, Brian</dc:creator>
 <dc:creator>Hazan, Elad</dc:creator>
 <dc:creator>Ma, Tengyu</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We design a non-convex second-order optimization algorithm that is guaranteed
to return an approximate local minimum in time which scales linearly in the
underlying dimension and the number of training examples. The time complexity
of our algorithm to find an approximate local minimum is even faster than that
of gradient descent to find a critical point. Our algorithm applies to a
general class of optimization problems including training a neural network and
other non-convex objectives arising in machine learning.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01148</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Big Media Data Revolutionarize Gun Violence Prevention?</dc:title>
 <dc:creator>Ayers, John W.</dc:creator>
 <dc:creator>Althouse, Benjamin M.</dc:creator>
 <dc:creator>Leas, Eric C.</dc:creator>
 <dc:creator>Alcorn, Ted</dc:creator>
 <dc:creator>Dredze, Mark</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The scientific method drives improvements in public health, but a strategy of
obstructionism has impeded scientists from gathering even a minimal amount of
information to address America's gun violence epidemic. We argue that in spite
of a lack of federal investment, large amounts of publicly available data offer
scientists an opportunity to measure a range of firearm-related behaviors.
Given the diversity of available data - including news coverage, social media,
web forums, online advertisements, and Internet searches (to name a few) -
there are ample opportunities for scientists to study everything from trends in
particular types of gun violence to gun-related behaviors (such as purchases
and safety practices) to public understanding of and sentiment towards various
gun violence reduction measures. Science has been sidelined in the gun violence
debate for too long. Scientists must tap the big media data stream and help
resolve this crisis.
</dc:description>
 <dc:description>Comment: Presented at the Data For Good Exchange 2016</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01152</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualisation of massive data from scholarly Article and Journal
  Database A Novel Scheme</dc:title>
 <dc:creator>Ginde, Gouri</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Scholarly articles publishing and getting cited has become a way of life for
academicians. These scholarly publications shape up the career growth of not
only the authors but also of the country, continent and the technological
domains. Author affiliations, country and other information of an author
coupled with data analytics can provide useful and insightful results. However,
massive and complete data is required to perform this research. Google scholar
which is a comprehensive and free repository of scholarly articles has been
used as a data source for this purpose. Data scraped from Google scholar when
stored as a graph and visualized in the form of nodes and relationships, can
offer discerning and concealed information. Such as, evident domain shift of an
author, various research domains spread for an author, prediction of emerging
domain and sub domains, detection of journal and author level citation cartel
behaviors etc. The data from graph database is also used in computation of
scholastic indicators for the journals. Eventually, econometric model, named
Cobb Douglas model is used to compute the journals Modeling &quot;Internationality&quot;
Index based on these scholastic indicators.
</dc:description>
 <dc:description>Comment: 5 pages, conference</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01170</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PrivLogit: Efficient Privacy-preserving Logistic Regression by Tailoring
  Numerical Optimizers</dc:title>
 <dc:creator>Xie, Wei</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Boker, Steven M.</dc:creator>
 <dc:creator>Brown, Donald E.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Safeguarding privacy in machine learning is highly desirable, especially in
collaborative studies across many organizations. Privacy-preserving distributed
machine learning (based on cryptography) is popular to solve the problem.
However, existing cryptographic protocols still incur excess computational
overhead. Here, we make a novel observation that this is partially due to naive
adoption of mainstream numerical optimization (e.g., Newton method) and failing
to tailor for secure computing. This work presents a contrasting perspective:
customizing numerical optimization specifically for secure settings. We propose
a seemingly less-favorable optimization method that can in fact significantly
accelerate privacy-preserving logistic regression. Leveraging this new method,
we propose two new secure protocols for conducting logistic regression in a
privacy-preserving and distributed manner. Extensive theoretical and empirical
evaluations prove the competitive performance of our two secure proposals while
without compromising accuracy or privacy: with speedup up to 2.3x and 8.1x,
respectively, over state-of-the-art; and even faster as data scales up. Such
drastic speedup is on top of and in addition to performance improvements from
existing (and future) state-of-the-art cryptography. Our work provides a new
way towards efficient and practical privacy-preserving logistic regression for
large-scale studies which are common for modern science.
</dc:description>
 <dc:description>Comment: 24 pages, 4 figures. Work done and circulated since 2015</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01172</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple-Speaker Localization Based on Direct-Path Features and
  Likelihood Maximization with Spatial Sparsity Regularization</dc:title>
 <dc:creator>Li, Xiaofei</dc:creator>
 <dc:creator>Girin, Laurent</dc:creator>
 <dc:creator>Gannot, Sharon</dc:creator>
 <dc:creator>Horaud, Radu</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper addresses the problem of multiple-speaker localization in noisy
and reverberant environments, using binaural recordings of an acoustic scene. A
Gaussian mixture model (GMM) is adopted, whose components correspond to all the
possible candidate source locations defined on a grid. After optimizing the
GMM-based objective function, given an observed set of binaural features, both
the number of sources and their locations are estimated by selecting the GMM
components with the largest priors. This is achieved by enforcing a sparse
solution, thus favoring a small number of speakers with respect to the large
number of initial candidate source locations. An entropy-based penalty term is
added to the likelihood, thus imposing sparsity over the set of GMM priors. In
addition, the direct-path relative transfer function (DP-RTF) is used to build
robust binaural features. The DP-RTF, recently proposed for single-source
localization, was shown to be robust to reverberations, since it encodes
inter-channel information corresponding to the direct-path of sound
propagation. In this paper, we extend the DP-RTF estimation to the case of
multiple sources. In the short-time Fourier transform domain, a consistency
test is proposed to check whether a set of consecutive frames is associated to
the same source or not. Reliable DP-RTF features are selected from the frames
that pass the consistency test to be used for source localization. Experiments
carried out using both simulation data and real data gathered with a robotic
head confirm the efficiency of the proposed multi-source localization method.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures, 4 tables</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01172</dc:identifier>
 <dc:identifier>IEEE/ACM Transactions on Audio, Speech and Language Processing,
  25(10), pp 1997 - 2012, October 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TASLP.2017.2740001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01179</identifier>
 <datestamp>2017-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Geometric Multiscale Approximations for Intrinsically
  Low-dimensional Data</dc:title>
 <dc:creator>Liao, Wenjing</dc:creator>
 <dc:creator>Maggioni, Mauro</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider the problem of efficiently approximating and encoding
high-dimensional data sampled from a probability distribution $\rho$ in
$\mathbb{R}^D$, that is nearly supported on a $d$-dimensional set $\mathcal{M}$
- for example supported on a $d$-dimensional Riemannian manifold. Geometric
Multi-Resolution Analysis (GMRA) provides a robust and computationally
efficient procedure to construct low-dimensional geometric approximations of
$\mathcal{M}$ at varying resolutions. We introduce a thresholding algorithm on
the geometric wavelet coefficients, leading to what we call adaptive GMRA
approximations. We show that these data-driven, empirical approximations
perform well, when the threshold is chosen as a suitable universal function of
the number of samples $n$, on a wide variety of measures $\rho$, that are
allowed to exhibit different regularity at different scales and locations,
thereby efficiently encoding data from more complex measures than those
supported on manifolds. These approximations yield a data-driven dictionary,
together with a fast transform mapping data to coefficients, and an inverse of
such a map. The algorithms for both the dictionary construction and the
transforms have complexity $C n \log n$ with the constant linear in $D$ and
exponential in $d$. Our work therefore establishes adaptive GMRA as a fast
dictionary learning algorithm with approximation guarantees. We include several
numerical experiments on both synthetic and real data, confirming our
theoretical results and demonstrating the effectiveness of adaptive GMRA.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01186</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demystifying ResNet</dc:title>
 <dc:creator>Li, Sihan</dc:creator>
 <dc:creator>Jiao, Jiantao</dc:creator>
 <dc:creator>Han, Yanjun</dc:creator>
 <dc:creator>Weissman, Tsachy</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The Residual Network (ResNet), proposed in He et al. (2015), utilized
shortcut connections to significantly reduce the difficulty of training, which
resulted in great performance boosts in terms of both training and
generalization error.
  It was empirically observed in He et al. (2015) that stacking more layers of
residual blocks with shortcut 2 results in smaller training error, while it is
not true for shortcut of length 1 or 3. We provide a theoretical explanation
for the uniqueness of shortcut 2.
  We show that with or without nonlinearities, by adding shortcuts that have
depth two, the condition number of the Hessian of the loss function at the zero
initial point is depth-invariant, which makes training very deep models no more
difficult than shallow ones. Shortcuts of higher depth result in an extremely
flat (high-order) stationary point initially, from which the optimization
algorithm is hard to escape. The shortcut 1, however, is essentially equivalent
to no shortcuts, which has a condition number exploding to infinity as the
number of layers grows. We further argue that as the number of layers tends to
infinity, it suffices to only look at the loss function at the zero initial
point.
  Extensive experiments are provided accompanying our theoretical results. We
show that initializing the network to small weights with shortcut 2 achieves
significantly better results than random Gaussian (Xavier) initialization,
orthogonal initialization, and shortcuts of deeper depth, from various
perspectives ranging from final loss, learning dynamics and stability, to the
behavior of the Hessian along the learning process.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01190</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conspiracies between Learning Algorithms, Circuit Lower Bounds and
  Pseudorandomness</dc:title>
 <dc:creator>Oliveira, Igor C.</dc:creator>
 <dc:creator>Santhanam, Rahul</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We prove several results giving new and stronger connections between
learning, circuit lower bounds and pseudorandomness. Among other results, we
show a generic learning speedup lemma, equivalences between various learning
models in the exponential time and subexponential time regimes, a dichotomy
between learning and pseudorandomness, consequences of non-trivial learning for
circuit lower bounds, Karp-Lipton theorems for probabilistic exponential time,
and NC$^1$-hardness for the Minimum Circuit Size Problem.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01195</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Atlas and Graph Cut Methods for LV Segmentation from Cardiac
  Cine MRI</dc:title>
 <dc:creator>Dangi, Shusil</dc:creator>
 <dc:creator>Cahill, Nathan</dc:creator>
 <dc:creator>Linte, Cristian A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Magnetic Resonance Imaging (MRI) has evolved as a clinical standard-of-care
imaging modality for cardiac morphology, function assessment, and guidance of
cardiac interventions. All these applications rely on accurate extraction of
the myocardial tissue and blood pool from the imaging data. Here we propose a
framework for left ventricle (LV) segmentation from cardiac cine-MRI. First, we
segment the LV blood pool using iterative graph cuts, and subsequently use this
information to segment the myocardium. We formulate the segmentation procedure
as an energy minimization problem in a graph subject to the shape prior
obtained by label propagation from an average atlas using affine registration.
The proposed framework has been validated on 30 patient cardiac cine-MRI
datasets available through the STACOM LV segmentation challenge and yielded
fast, robust, and accurate segmentation results.
</dc:description>
 <dc:description>Comment: Statistical Atlases and Computational Modelling of Heart workshop
  2016</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01199</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity-Achieving Rate-Compatible Polar Codes for General Channels</dc:title>
 <dc:creator>Mondelli, Marco</dc:creator>
 <dc:creator>Hassani, S. Hamed</dc:creator>
 <dc:creator>Mari&#x107;, Ivana</dc:creator>
 <dc:creator>Hui, Dennis</dc:creator>
 <dc:creator>Hong, Song-Nam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present a rate-compatible polar coding scheme that achieves the capacity
of any family of channels. Our solution generalizes the previous results [1],
[2] that provide capacity-achieving rate-compatible polar codes for a degraded
family of channels. The motivation for our extension comes from the fact that
in many practical scenarios, e.g., MIMO systems and non-Gaussian interference,
the channels cannot be ordered by degradation. The main technical contribution
of this paper consists in removing the degradation condition. To do so, we
exploit the ideas coming from the construction of universal polar codes.
  Our scheme possesses the usual attractive features of polar codes: low
complexity code construction, encoding, and decoding; super-polynomial scaling
of the error probability with the block length; and absence of error floors. On
the negative side, the scaling of the gap to capacity with the block length is
slower than in standard polar codes, and we prove an upper bound on the scaling
exponent.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures, accepted at WCNC'17 workshop on polar coding</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01210</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal Disjoint-Path Facility Location Through Set Cover by Pairs</dc:title>
 <dc:creator>Johnson, David S.</dc:creator>
 <dc:creator>Breslau, Lee</dc:creator>
 <dc:creator>Diakonikolas, Ilias</dc:creator>
 <dc:creator>Duffield, Nick</dc:creator>
 <dc:creator>Gu, Yu</dc:creator>
 <dc:creator>Hajiaghayi, MohammadTaghi</dc:creator>
 <dc:creator>Karloff, Howard</dc:creator>
 <dc:creator>Resende, Mauricio G. C.</dc:creator>
 <dc:creator>Sen, Subhabrata</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>90C59, 68M10, 94C15</dc:subject>
 <dc:description>  In this paper we consider two special cases of the &quot;cover-by-pairs&quot;
optimization problem that arise when we need to place facilities so that each
customer is served by two facilities that reach it by disjoint shortest paths.
These problems arise in a network traffic monitoring scheme proposed by Breslau
et al. and have potential applications to content distribution. The
&quot;set-disjoint&quot; variant applies to networks that use the OSPF routing protocol,
and the &quot;path-disjoint&quot; variant applies when MPLS routing is enabled, making
better solutions possible at the cost of greater operational expense. Although
we can prove that no polynomial-time algorithm can guarantee good solutions for
either version, we are able to provide heuristics that do very well in practice
on instances with real-world network structure. Fast implementations of the
heuristics, made possible by exploiting mathematical observations about the
relationship between the network instances and the corresponding instances of
the cover-by-pairs problem, allow us to perform an extensive experimental
evaluation of the heuristics and what the solutions they produce tell us about
the effectiveness of the proposed monitoring scheme. For the set-disjoint
variant, we validate our claim of near-optimality via a new lower-bounding
integer programming formulation. Although computing this lower bound requires
solving the NP-hard Hitting Set problem and can underestimate the optimal value
by a linear factor in the worst case, it can be computed quickly by CPLEX, and
it equals the optimal solution value for all the instances in our extensive
testbed.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01211</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combating Reinforcement Learning's Sisyphean Curse with Intrinsic Fear</dc:title>
 <dc:creator>Lipton, Zachary C.</dc:creator>
 <dc:creator>Kumar, Abhishek</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  To use deep reinforcement learning in the wild, we might hope for an agent
that can avoid catastrophic mistakes. Unfortunately, even in simple
environments, the popular deep Q-network (DQN) algorithm is doomed by a
Sisyphean curse. Owing to the use of function approximation, these agents may
eventually forget experiences as they become exceedingly unlikely under a new
policy. Consequently, for as long as they continue to train, DQNs may
periodically repeat avoidable catastrophic mistakes. In this paper, we learn a
\emph{reward shaping} that accelerates learning and guards oscillating policies
against repeated catastrophes. First, we demonstrate unacceptable performance
of DQNs on two toy problems. We then introduce \emph{intrinsic fear}, a new
method that mitigates these problems by avoiding dangerous states. Our approach
incorporates a second model trained via supervised learning to predict the
probability of catastrophe within a short number of steps. This score then acts
to penalize the Q-learning objective. Equipped with intrinsic fear, our DQNs
solve the toy environments and improve on the Atari games Seaquest, Asteroids,
and Freeway.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-10-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01224</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sample Efficient Actor-Critic with Experience Replay</dc:title>
 <dc:creator>Wang, Ziyu</dc:creator>
 <dc:creator>Bapst, Victor</dc:creator>
 <dc:creator>Heess, Nicolas</dc:creator>
 <dc:creator>Mnih, Volodymyr</dc:creator>
 <dc:creator>Munos, Remi</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents an actor-critic deep reinforcement learning agent with
experience replay that is stable, sample efficient, and performs remarkably
well on challenging environments, including the discrete 57-game Atari domain
and several continuous control problems. To achieve this, the paper introduces
several innovations, including truncated importance sampling with bias
correction, stochastic dueling network architectures, and a new trust region
policy optimization method.
</dc:description>
 <dc:description>Comment: 20 pages. Prepared for ICLR 2017</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01228</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>URL ordering policies for distributed crawlers: a review</dc:title>
 <dc:creator>Deepika</dc:creator>
 <dc:creator>Dixit, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  With the increase in size of web, the information is also spreading at large
scale. Search Engines are the medium to access this information. Crawler is the
module of search engine which is responsible for download the web pages. In
order to download the fresh information and get the database rich, crawler
should crawl the web in some order. This is called as ordering of URLs. URL
ordering should be done in efficient and effective manner in order to crawl the
web in proficient manner. In this paper, a survey is done on some existing
methods of URL ordering and at the end of this paper comparison is also carried
out among them.
</dc:description>
 <dc:description>Comment: 6 Pages, 5 figures, 1 Table, International Conference on Recent
  Trends in Computer and Information Technology Research September 2015</dc:description>
 <dc:date>2015-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01230</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Inverse Formulation of Optical Flow with Uncertainty
  Quantification</dc:title>
 <dc:creator>Sun, Jie</dc:creator>
 <dc:creator>Bollt, Erik</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Optical flow refers to the visual motion observed between two consecutive
images. Since the degree of freedom is typically much larger than the
constraints imposed by the image observations, the straightforward formulation
of optical flow inference is an ill-posed problem. By setting some type of
additional &quot;regularity&quot; constraints, classical approaches formulate a
well-posed optical flow inference problem in the form of a parameterized set of
variational equations. In this work we build a mathematical connection, focused
on optical flow methods, between classical variational optical flow approaches
and Bayesian statistical inversion. A classical optical flow solution is in
fact identical to a maximum a posteriori estimator under the assumptions of
linear model with additive independent Gaussian noise and a Gaussian prior
distribution. Unlike classical approaches, the statistical inversion approach
to optical flow estimation not only allows for &quot;point&quot; estimates, but also
provides a distribution of solutions which can be used for ensemble estimation
and in particular uncertainty quantification.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01232</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Information Propagation</dc:title>
 <dc:creator>Schoenholz, Samuel S.</dc:creator>
 <dc:creator>Gilmer, Justin</dc:creator>
 <dc:creator>Ganguli, Surya</dc:creator>
 <dc:creator>Sohl-Dickstein, Jascha</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the behavior of untrained neural networks whose weights and biases
are randomly distributed using mean field theory. We show the existence of
depth scales that naturally limit the maximum depth of signal propagation
through these random networks. Our main practical result is to show that random
networks may be trained precisely when information can travel through them.
Thus, the depth scales that we identify provide bounds on how deep a network
may be trained for a specific choice of hyperparameters. As a corollary to
this, we argue that in networks at the edge of chaos, one of these depth scales
diverges. Thus arbitrarily deep networks may be trained only sufficiently close
to criticality. We show that the presence of dropout destroys the
order-to-chaos critical point and therefore strongly limits the maximum
trainable depth for random networks. Finally, we develop a mean field theory
for backpropagation and we show that the ordered and chaotic phases correspond
to regions of vanishing and exploding gradient respectively.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01235</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Self-Driving Robot Using Deep Convolutional Neural Networks on
  Neuromorphic Hardware</dc:title>
 <dc:creator>Hwu, Tiffany</dc:creator>
 <dc:creator>Isbell, Jacob</dc:creator>
 <dc:creator>Oros, Nicolas</dc:creator>
 <dc:creator>Krichmar, Jeffrey</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Neuromorphic computing is a promising solution for reducing the size, weight
and power of mobile embedded systems. In this paper, we introduce a realization
of such a system by creating the first closed-loop battery-powered
communication system between an IBM TrueNorth NS1e and an autonomous
Android-Based Robotics platform. Using this system, we constructed a dataset of
path following behavior by manually driving the Android-Based robot along steep
mountain trails and recording video frames from the camera mounted on the robot
along with the corresponding motor commands. We used this dataset to train a
deep convolutional neural network implemented on the TrueNorth NS1e. The NS1e,
which was mounted on the robot and powered by the robot's battery, resulted in
a self-driving robot that could successfully traverse a steep mountain path in
real time. To our knowledge, this represents the first time the TrueNorth NS1e
neuromorphic chip has been embedded on a mobile platform under closed-loop
control.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01236</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Machine Learning at Scale</dc:title>
 <dc:creator>Kurakin, Alexey</dc:creator>
 <dc:creator>Goodfellow, Ian</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Adversarial examples are malicious inputs designed to fool machine learning
models. They often transfer from one model to another, allowing attackers to
mount black box attacks without knowledge of the target model's parameters.
Adversarial training is the process of explicitly training a model on
adversarial examples, in order to make it more robust to attack or to reduce
its test error on clean inputs. So far, adversarial training has primarily been
applied to small problems. In this research, we apply adversarial training to
ImageNet. Our contributions include: (1) recommendations for how to succesfully
scale adversarial training to large models and datasets, (2) the observation
that adversarial training confers robustness to single-step attack methods, (3)
the finding that multi-step attack methods are somewhat less transferable than
single-step attack methods, so single-step attacks are the best for mounting
black-box attacks, and (4) resolution of a &quot;label leaking&quot; effect that causes
adversarially trained models to perform better on adversarial examples than on
clean examples, because the adversarial example construction process uses the
true label and the model can learn to exploit regularities in the construction
process.
</dc:description>
 <dc:description>Comment: 17 pages, 5 figures</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2017-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01239</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reparameterization trick for discrete variables</dc:title>
 <dc:creator>Tokui, Seiya</dc:creator>
 <dc:creator>sato, Issei</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Low-variance gradient estimation is crucial for learning directed graphical
models parameterized by neural networks, where the reparameterization trick is
widely used for those with continuous variables. While this technique gives
low-variance gradient estimates, it has not been directly applicable to
discrete variables, the sampling of which inherently requires discontinuous
operations. We argue that the discontinuity can be bypassed by marginalizing
out the variable of interest, which results in a new reparameterization trick
for discrete variables. This reparameterization greatly reduces the variance,
which is understood by regarding the method as an application of common random
numbers to the estimation. The resulting estimator is theoretically guaranteed
to have a variance not larger than that of the likelihood-ratio method with the
optimal input-dependent baseline. We give empirical results for variational
learning of sigmoid belief networks.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01242</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Answering Complicated Question Intents Expressed in Decomposed Question
  Sequences</dc:title>
 <dc:creator>Iyyer, Mohit</dc:creator>
 <dc:creator>Yih, Wen-tau</dc:creator>
 <dc:creator>Chang, Ming-Wei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent work in semantic parsing for question answering has focused on long
and complicated questions, many of which would seem unnatural if asked in a
normal conversation between two humans. In an effort to explore a
conversational QA setting, we present a more realistic task: answering
sequences of simple but inter-related questions. We collect a dataset of 6,066
question sequences that inquire about semi-structured tables from Wikipedia,
with 17,553 question-answer pairs in total. Existing QA systems face two major
problems when evaluated on our dataset: (1) handling questions that contain
coreferences to previous questions or answers, and (2) matching words or
phrases in a question to corresponding entries in the associated table. We
conclude by proposing strategies to handle both of these issues.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01257</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Black Lives Matter in Wikipedia: Collaboration and Collective Memory
  around Online Social Movements</dc:title>
 <dc:creator>Twyman, Marlon</dc:creator>
 <dc:creator>Keegan, Brian C.</dc:creator>
 <dc:creator>Shaw, Aaron</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:subject>K.4.2</dc:subject>
 <dc:description>  Social movements use social computing systems to complement offline
mobilizations, but prior literature has focused almost exclusively on movement
actors' use of social media. In this paper, we analyze participation and
attention to topics connected with the Black Lives Matter movement in the
English language version of Wikipedia between 2014 and 2016. Our results point
to the use of Wikipedia to (1) intensively document and connect historical and
contemporary events, (2) collaboratively migrate activity to support coverage
of new events, and (3) dynamically re-appraise pre-existing knowledge in the
aftermath of new events. These findings reveal patterns of behavior that
complement theories of collective memory and collective action and help explain
how social computing systems can encode and retrieve knowledge about social
movements as they unfold.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01257</dc:identifier>
 <dc:identifier>doi:10.1145/2998181.2998232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01259</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Topic Modeling</dc:title>
 <dc:creator>Blum, Avrim</dc:creator>
 <dc:creator>Haghtalab, Nika</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recently there has been significant activity in developing algorithms with
provable guarantees for topic modeling. In standard topic models, a topic (such
as sports, business, or politics) is viewed as a probability distribution $\vec
a_i$ over words, and a document is generated by first selecting a mixture $\vec
w$ over topics, and then generating words i.i.d. from the associated mixture
$A{\vec w}$. Given a large collection of such documents, the goal is to recover
the topic vectors and then to correctly classify new documents according to
their topic mixture.
  In this work we consider a broad generalization of this framework in which
words are no longer assumed to be drawn i.i.d. and instead a topic is a complex
distribution over sequences of paragraphs. Since one could not hope to even
represent such a distribution in general (even if paragraphs are given using
some natural feature representation), we aim instead to directly learn a
document classifier. That is, we aim to learn a predictor that given a new
document, accurately predicts its topic mixture, without learning the
distributions explicitly. We present several natural conditions under which one
can do this efficiently and discuss issues such as noise tolerance and sample
complexity in this model. More generally, our model can be viewed as a
generalization of the multi-view or co-training setting in machine learning.
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01260</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Identity Mappings with Residual Gates</dc:title>
 <dc:creator>Savarese, Pedro H. P.</dc:creator>
 <dc:creator>Mazza, Leonardo O.</dc:creator>
 <dc:creator>Figueiredo, Daniel R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a new layer design by adding a linear gating mechanism to shortcut
connections. By using a scalar parameter to control each gate, we provide a way
to learn identity mappings by optimizing only one parameter. We build upon the
motivation behind Residual Networks, where a layer is reformulated in order to
make learning identity mappings less problematic to the optimizer. The
augmentation introduces only one extra parameter per layer, and provides easier
optimization by making degeneration into identity mappings simpler. We propose
a new model, the Gated Residual Network, which is the result when augmenting
Residual Networks. Experimental results show that augmenting layers provides
better optimization, increased performance, and more layer independence. We
evaluate our method on MNIST using fully-connected networks, showing empirical
indications that our augmentation facilitates the optimization of deep models,
and that it provides high tolerance to full layer removal: the model retains
over 90% of its performance even after half of its layers have been randomly
removed. We also evaluate our model on CIFAR-10 and CIFAR-100 using Wide Gated
ResNets, achieving 3.65% and 18.27% error, respectively.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2016-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01268</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Noise Modeling for Better Representation Learning</dc:title>
 <dc:creator>Kim, Hyo-Eun</dc:creator>
 <dc:creator>Hwang, Sangheum</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Latent representation learned from multi-layered neural networks via
hierarchical feature abstraction enables recent success of deep learning. Under
the deep learning framework, generalization performance highly depends on the
learned latent representation which is obtained from an appropriate training
scenario with a task-specific objective on a designed network model. In this
work, we propose a novel latent space modeling method to learn better latent
representation. We designed a neural network model based on the assumption that
good base representation can be attained by maximizing the total correlation
between the input, latent, and output variables. From the base model, we
introduce a semantic noise modeling method which enables class-conditional
perturbation on latent space to enhance the representational power of learned
latent feature. During training, latent vector representation can be
stochastically perturbed by a modeled class-conditional additive noise while
maintaining its original semantic feature. It implicitly brings the effect of
semantic augmentation on the latent space. The proposed model can be easily
learned by back-propagation with common gradient-based optimization algorithms.
Experimental results show that the proposed method helps to achieve performance
benefits against various previous approaches. We also provide the empirical
analyses for the proposed class-conditional perturbation process including
t-SNE visualization.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01270</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast property testing and metrics for permutations</dc:title>
 <dc:creator>Fox, Jacob</dc:creator>
 <dc:creator>Wei, Fan</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>05, 60, 68</dc:subject>
 <dc:description>  The goal of property testing is to quickly distinguish between objects which
satisfy a property and objects that are $\epsilon$-far from satisfying the
property. There are now several general results in this area which show that
natural properties of combinatorial objects can be tested with &quot;constant&quot; query
complexity, depending only on $\epsilon$ and the property, and not on the size
of the object being tested. The upper bound on the query complexity coming from
the proof techniques are often enormous and impractical. It remains a major
open problem if better bounds hold.
  Maybe surprisingly, for testing with respect to the rectangular distance, we
prove there is a universal (not depending on the property), polynomial in
$1/\epsilon$ query complexity bound for two-sided testing hereditary properties
of sufficiently large permutations. We further give a nearly linear bound with
respect to a closely related metric which also depends on the smallest
forbidden subpermutation for the property. Finally, we show that several
different permutation metrics of interest are related to the rectangular
distance, yielding similar results for testing with respect to these metrics.
</dc:description>
 <dc:description>Comment: 32 pages, 12 figures</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01272</identifier>
 <datestamp>2016-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Could freely available articles reduce faculty reliance on library for
  access? An analysis of items cited by faculty from Singapore Management
  University</dc:title>
 <dc:creator>Yahaya, Nursyeha Binte</dc:creator>
 <dc:creator>Tay, Aaron</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Various studies have attempted to assess the amount of free full text
available on the web and recent work have suggested that we are close to the
50% mark for freely available articles (Archambault et al. 2013; Bjork et al.
2010; Jamali and Nabavi 2015). It is natural to wonder if this might reduce
researchers' reliance on library subscriptions for access. To do so, we need to
determine not just what papers researchers are citing to that are free today,
but to estimate if the papers they were citing were freely available at the
time they were citing it. We attempt to do so for a sample of citations made by
researchers in the Singapore Management University in the field of Economics.
</dc:description>
 <dc:description>Comment: 15 pages, 3 Figures</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2016-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01276</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Communication-Efficient Parallel Algorithm for Decision Tree</dc:title>
 <dc:creator>Meng, Qi</dc:creator>
 <dc:creator>Ke, Guolin</dc:creator>
 <dc:creator>Wang, Taifeng</dc:creator>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:creator>Ye, Qiwei</dc:creator>
 <dc:creator>Ma, Zhi-Ming</dc:creator>
 <dc:creator>Liu, Tie-Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Decision tree (and its extensions such as Gradient Boosting Decision Trees
and Random Forest) is a widely used machine learning algorithm, due to its
practical effectiveness and model interpretability. With the emergence of big
data, there is an increasing need to parallelize the training process of
decision tree. However, most existing attempts along this line suffer from high
communication costs. In this paper, we propose a new algorithm, called
\emph{Parallel Voting Decision Tree (PV-Tree)}, to tackle this challenge. After
partitioning the training data onto a number of (e.g., $M$) machines, this
algorithm performs both local voting and global voting in each iteration. For
local voting, the top-$k$ attributes are selected from each machine according
to its local data. Then, globally top-$2k$ attributes are determined by a
majority voting among these local candidates. Finally, the full-grained
histograms of the globally top-$2k$ attributes are collected from local
machines in order to identify the best (most informative) attribute and its
split point. PV-Tree can achieve a very low communication cost (independent of
the total number of attributes) and thus can scale out very well. Furthermore,
theoretical analysis shows that this algorithm can learn a near optimal
decision tree, since it can find the best attribute with a large probability.
Our experiments on real-world datasets show that PV-Tree significantly
outperforms the existing parallel decision tree algorithms in the trade-off
between accuracy and efficiency.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01278</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topological Interference Management: Linear Cooperation is not useful
  for Wyner's Networks</dc:title>
 <dc:creator>Gamal, Aly El</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we study the value of cooperative transmission in wireless
networks if no channel state information is available at the transmitters (no
CSIT). Our focus is on large locally connected networks, where each transmitter
is connected to the receiver that has the same index as well as L succeeding
receivers. The cases of L=1 and L=2 represent Wyner's asymmetric and symmetric
network models, respectively. The considered rate criterion is the per user
Degrees of Freedom (puDoF) as the number of transmitter-receiver pairs goes to
infinity. For the case when L=1, it was shown in previous work that linear
cooperation schemes do not increases the puDoF value, and that the optimal
scheme relies on assigning each message to a single transmitter and using
orthogonal access (TDMA). Here, we extend this conclusion to the case where
L=2, by proving optimality of TDMA in this case as well. We conclude by
discussing whether increasing the value of L can create a value for linear
cooperation schemes from a DoF perspective.
</dc:description>
 <dc:description>Comment: submitted to IEEE International Symposium on Information Theory (ISIT
  2017)</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01286</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating a Model of Analytical Quality Assurance into the V-Modell XT</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Meisinger, Michael</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.9</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Economic models of quality assurance can be an important tool for decision
makers in software development projects. They enable to base quality assurance
planning on economical factors of the product and the used defect-detection
techniques. A variety of such models has been proposed but many are too
abstract to be used in practice. Furthermore, even the more concrete models
lack an integration with existing software development process models to
increase their applicability. This paper describes an integration of a thorough
stochastic model of the economics of analytical quality assurance with the
systems development process model V-Modell XT. The integration is done in a
modular way by providing a new process module - a concept directly available in
the V-Modell XT for extension purposes - related to analytical quality
assurance. In particular, we describe the work products, roles, and activities
defined in our new process module and their effects on existing V-Modell XT
elements.
</dc:description>
 <dc:description>Comment: 9 pages in Proceedings of the 3rd international workshop on Software
  quality assurance (SOQUA'06), ACM, 2006</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01286</dc:identifier>
 <dc:identifier>doi:10.1145/1188895.1188906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01287</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Managing Quality Requirements Using Activity-Based Quality Models</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Deissenboeck, Florian</dc:creator>
 <dc:creator>Winter, Sebastian</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.1</dc:subject>
 <dc:subject>D.2.9</dc:subject>
 <dc:description>  Managing requirements on quality aspects is an important issue in the
development of software systems. Difficulties arise from expressing them
appropriately what in turn results from the difficulty of the concept of
quality itself. Building and using quality models is an approach to handle the
complexity of software quality. A novel kind of quality models uses the
activities performed on and with the software as an explicit dimension. These
quality models are a well-suited basis for managing quality requirements from
elicitation over refinement to assurance. The paper proposes such an approach
and shows its applicability in an automotive case study.
</dc:description>
 <dc:description>Comment: 6 pages in Proceedings of the 6th international workshop on Software
  quality (WoSQ '08). ACM, 2008</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01287</dc:identifier>
 <dc:identifier>doi:10.1145/1370099.1370107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01291</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tighter Hard Instances for PPSZ</dc:title>
 <dc:creator>Pudl&#xe1;k, Pavel</dc:creator>
 <dc:creator>Scheder, Dominik</dc:creator>
 <dc:creator>Talebanfard, Navid</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We construct uniquely satisfiable $k$-CNF formulas that are hard for the
algorithm PPSZ. Firstly, we construct graph-instances on which &quot;weak PPSZ&quot; has
savings of at most $(2 + \epsilon) / k$; the saving of an algorithm on an input
formula with $n$ variables is the largest $\gamma$ such that the algorithm
succeeds (i.e. finds a satisfying assignment) with probability at least $2^{ -
(1 - \gamma) n}$. Since PPSZ (both weak and strong) is known to have savings of
at least $\frac{\pi^2 + o(1)}{6k}$, this is optimal up to the constant factor.
In particular, for $k=3$, our upper bound is $2^{0.333\dots n}$, which is
fairly close to the lower bound $2^{0.386\dots n}$ of Hertli [SIAM J.
Comput.'14]. We also construct instances based on linear systems over
$\mathbb{F}_2$ for which strong PPSZ has savings of at most
$O\left(\frac{\log(k)}{k}\right)$. This is only a $\log(k)$ factor away from
the optimal bound. Our constructions improve previous savings upper bound of
$O\left(\frac{\log^2(k)}{k}\right)$ due to Chen et al. [SODA'13].
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01291</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.ICALP.2017.85</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01294</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Mappings for Planning and Optimization of Cellular Networks</dc:title>
 <dc:creator>G., David Gonz&#xe1;lez</dc:creator>
 <dc:creator>Hakula, Harri</dc:creator>
 <dc:creator>Rasila, Antti</dc:creator>
 <dc:creator>H&#xe4;m&#xe4;l&#xe4;inen, Jyri</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In cellular networks, users are grouped into different cells and served by
different access points (base stations) that provide wireless access to
services and applications. In general, the service demand is very
heterogeneous, non-uniformly distributed, and dynamic. Consequently, radio
access networks create very irregular topologies with more access points where
service demand is concentrated. While this dynamism requires networks with the
ability to adapt to time-varying conditions, the non-uniformity of the service
demand makes the planning, analysis, and optimization difficult. In order to
help with these tasks, a framework based on canonical domains and spatial
mappings (e.g., conformal mapping) have recently been proposed. The idea is to
carry out part of the planning in a canonical (perfectly symmetric) domain that
is connected to the physical one (real-scenario) by means of a spatial
transformation designed to map the access points consistently with the service
demand. This paper continues the research in that direction by introducing
additional tools and possibilities to that framework, namely the use of
centroidal Voronoi algorithms and non-conformal composite mappings. Moreover,
power optimization is also introduced to the framework. The results show the
usability and effectiveness of the proposed method and its promising research
perspectives.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01296</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Goal-Driven Unfolding of Petri Nets</dc:title>
 <dc:creator>Chatain, Thomas</dc:creator>
 <dc:creator>Paulev&#xe9;, Lo&#xef;c</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Unfoldings provide an efficient way to avoid the state-space explosion due to
interleavings of concurrent transitions when exploring the runs of a Petri net.
The theory of adequate orders allows one to define finite prefixes of
unfoldings which contain all the reachable markings. In this paper we are
interested in reachability of a single given marking, called the goal. We
propose an algorithm for computing a finite prefix of the unfolding of a 1-safe
Petri net that preserves all minimal configurations reaching this goal. Our
algorithm combines the unfolding technique with on-the-fly model reduction by
static analysis aiming at avoiding the exploration of branches which are not
needed for reaching the goal. We present some experimental results.
</dc:description>
 <dc:description>Comment: research report</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01298</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularized Pel-Recursive Motion Estimation Using Generalized
  Cross-Validation and Spatial Adaptation</dc:title>
 <dc:creator>Estrela, Vania V.</dc:creator>
 <dc:creator>Rivera, Luis A.</dc:creator>
 <dc:creator>Beggio, Paulo C.</dc:creator>
 <dc:creator>Lopes, Ricardo T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The computation of 2-D optical flow by means of regularized pel-recursive
algorithms raises a host of issues, which include the treatment of outliers,
motion discontinuities and occlusion among other problems. We propose a new
approach which allows us to deal with these issues within a common framework.
Our approach is based on the use of a technique called Generalized
Cross-Validation to estimate the best regularization scheme for a given pixel.
In our model, the regularization parameter is a matrix whose entries can
account for diverse sources of error. The estimation of the motion vectors
takes into consideration local properties of the image following a spatially
adaptive approach where each moving pixel is supposed to have its own
regularization matrix. Preliminary experiments indicate that this approach
provides robust estimates of the optical flow.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures in Proceedings of the XVI Brazilian Symposium on
  Computer Graphics and Image Processing, 2003. SIBGRAPI 2003. IEEE. arXiv
  admin note: text overlap with arXiv:1403.7365, arXiv:1611.00960</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01298</dc:identifier>
 <dc:identifier>doi:10.1109/SIBGRA.2003.1241027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01318</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interval Enclosures of Upper Bounds of Roundoff Errors using
  Semidefinite Programming</dc:title>
 <dc:creator>Magron, Victor</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  A longstanding problem related to floating-point implementation of numerical
programs is to provide efficient yet precise analysis of output errors.
  We present a framework to compute lower bounds of absolute roundoff errors,
for a particular rounding model. This method applies for numerical programs
implementing polynomial functions with box constrained input variables. Our
study relies on semidefinite programming (SDP) relaxations and is complementary
of over-approximation frameworks, consisting of obtaining upper bounds for the
absolute roundoff error. Combining the results of both frameworks allows to get
interval enclosures for upper bounds of roundoff errors.
  The under-approximation framework is based on a new hierarchy of convergent
robust SDP approximations for certain classes of polynomial optimization
problems. Each problem in this hierarchy can be exactly solved via SDP. By
using this hierarchy, one can provide a monotone non-decreasing sequence of
lower bounds converging to the absolute roundoff error of a program
implementing a polynomial function, applying for a particular rounding model.
  We investigate the efficiency and precision of our method on non-trivial
polynomial programs coming from space control, optimization and computational
biology.
</dc:description>
 <dc:description>Comment: 15 pages, 2 tables, 1 figure</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01325</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-level Simulation of Internet of Things on Smart Territories</dc:title>
 <dc:creator>D'Angelo, Gabriele</dc:creator>
 <dc:creator>Ferretti, Stefano</dc:creator>
 <dc:creator>Ghini, Vittorio</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, a methodology is presented and employed for simulating the
Internet of Things (IoT). The requirement for scalability, due to the possibly
huge amount of involved sensors and devices, and the heterogeneous scenarios
that might occur, impose resorting to sophisticated modeling and simulation
techniques. In particular, multi-level simulation is regarded as a main
framework that allows simulating large-scale IoT environments while keeping
high levels of detail, when it is needed. We consider a use case based on the
deployment of smart services in decentralized territories. A two level
simulator is employed, which is based on a coarse agent-based, adaptive
parallel and distributed simulation approach to model the general life of
simulated entities. However, when needed a finer grained simulator (based on
OMNeT++) is triggered on a restricted portion of the simulated area, which
allows considering all issues concerned with wireless communications. Based on
this use case, it is confirmed that the ad-hoc wireless networking technologies
do represent a principle tool to deploy smart services over decentralized
countrysides. Moreover, the performance evaluation confirms the viability of
utilizing multi-level simulation for simulating large scale IoT environments.
</dc:description>
 <dc:description>Comment: Simulation Modelling Practice and Theory, Elsevier, vol. 73 (April
  2017)</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01325</dc:identifier>
 <dc:identifier>doi:10.1016/j.simpat.2016.10.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01328</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feasible Interpolation for QBF Resolution Calculi</dc:title>
 <dc:creator>Beyersdorff, Olaf</dc:creator>
 <dc:creator>Chew, Leroy</dc:creator>
 <dc:creator>Mahajan, Meena</dc:creator>
 <dc:creator>Shukla, Anil</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In sharp contrast to classical proof complexity we are currently short of
lower bound techniques for QBF proof systems. In this paper we establish the
feasible interpolation technique for all resolution-based QBF systems, whether
modelling CDCL or expansion-based solving. This both provides the first general
lower bound method for QBF proof systems as well as largely extends the scope
of classical feasible interpolation. We apply our technique to obtain new
exponential lower bounds to all resolution-based QBF systems for a new class of
QBF formulas based on the clique problem. Finally, we show how feasible
interpolation relates to the recently established lower bound method based on
strategy extraction.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01328</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 2 (June 8,
  2017) lmcs:3702</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(2:7)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01331</identifier>
 <datestamp>2017-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RenderGAN: Generating Realistic Labeled Data</dc:title>
 <dc:creator>Sixt, Leon</dc:creator>
 <dc:creator>Wild, Benjamin</dc:creator>
 <dc:creator>Landgraf, Tim</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Convolutional Neuronal Networks (DCNNs) are showing remarkable
performance on many computer vision tasks. Due to their large parameter space,
they require many labeled samples when trained in a supervised setting. The
costs of annotating data manually can render the use of DCNNs infeasible. We
present a novel framework called RenderGAN that can generate large amounts of
realistic, labeled images by combining a 3D model and the Generative
Adversarial Network framework. In our approach, image augmentations (e.g.
lighting, background, and detail) are learned from unlabeled data such that the
generated images are strikingly realistic while preserving the labels known
from the 3D model. We apply the RenderGAN framework to generate images of
barcode-like markers that are attached to honeybees. Training a DCNN on data
generated by the RenderGAN yields considerably better performance than training
it on various baselines.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01335</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phi-Entropic Measures of Correlation</dc:title>
 <dc:creator>Beigi, Salman</dc:creator>
 <dc:creator>Gohari, Amin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A measure of correlation is said to have the tensorization property if it is
unchanged when computed for i.i.d.\ copies. More precisely, a measure of
correlation between two random variables $(X, Y)$ denoted by $\rho(X, Y)$, has
the tensorization property if $\rho(X^n, Y^n)=\rho(X, Y)$ where $(X^n, Y^n)$ is
$n$ i.i.d.\ copies of $(X, Y)$.Two well-known examples of such measures are the
maximal correlation and the hypercontractivity ribbon (HC~ribbon). We show that
the maximal correlation and HC ribbons are special cases of $\Phi$-ribbon,
defined in this paper for any function $\Phi$ from a class of convex functions
($\Phi$-ribbon reduces to HC~ribbon and the maximal correlation for special
choices of $\Phi$). Any $\Phi$-ribbon is shown to be a measures of correlation
with the tensorization property. We show that the $\Phi$-ribbon also
characterizes the $\Phi$-strong data processing inequality constant introduced
by Raginsky. We further study the $\Phi$-ribbon for the choice of $\Phi(t)=t^2$
and introduce an equivalent characterization of this ribbon.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01337</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Nondeterministic and Abstract Algorithm for Translating Hierarchical
  Block Diagrams</dc:title>
 <dc:creator>Preoteasa, Viorel</dc:creator>
 <dc:creator>Dragomir, Iulia</dc:creator>
 <dc:creator>Tripakis, Stavros</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this paper we introduce a nondeterministic algorithm for translating
hierarchical block diagrams (HBDs) into an abstract algebra of components with
three basic composition operations (serial, parallel, and feedback) and with
three constants (split, switch, and sink). We prove that despite its internal
nondeterminism, the result of the algorithm is deterministic, meaning that all
possible algebra expressions that can be generated from a given HBD are
equivalent. Then, different determinizations of the algorithm result in
different translation strategies which are all semantically equivalent,
although each having its pros and cons with respect to various criteria
(compositionality, readability, simplifiability, etc.). As an application of
our framework, we show how two translation strategies for Simulink introduced
in previous work can be formalized as determinizations of the abstract
algorithm. We also prove these strategies equivalent, thus answering an open
question raised in the earlier work. All results are formalized and proved in
Isabelle.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01344</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Polytope-Collision Problem</dc:title>
 <dc:creator>Almagor, Shaull</dc:creator>
 <dc:creator>Ouaknine, Jo&#xeb;l</dc:creator>
 <dc:creator>Worrell, James</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The Orbit Problem consists of determining, given a matrix $A\in
\mathbb{R}^{d\times d}$ and vectors $x,y\in \mathbb{R}^d$, whether there exists
$n\in \mathbb{N}$ such that $A^n=y$. This problem was shown to be decidable in
a seminal work of Kannan and Lipton in the 1980s. Subsequently, Kannan and
Lipton noted that the Orbit Problem becomes considerably harder when the target
$y$ is replaced with a subspace of $\mathbb{R}^d$. Recently, it was shown that
the problem is decidable for vector-space targets of dimension at most three,
followed by another development showing that the problem is in PSPACE for
polytope targets of dimension at most three. In this work, we take a dual look
at the problem, and consider the case where the initial vector $x$ is replaced
with a polytope $P_1$, and the target is a polytope $P_2$. Then, the question
is whether there exists $n\in \mathbb{N}$ such that $A^n P_1\cap P_2\neq
\emptyset$. We show that the problem can be decided in PSPACE for dimension at
most three. As in previous works, decidability in the case of higher dimensions
is left open, as the problem is known to be hard for long-standing
number-theoretic open problems.
  Our proof begins by formulating the problem as the satisfiability of a
parametrized family of sentences in the existential first-order theory of
real-closed fields. Then, after removing quantifiers, we are left with
instances of simultaneous positivity of sums of exponentials. Using techniques
from transcendental number theory, and separation bounds on algebraic numbers,
we are able to solve such instances in PSPACE.
</dc:description>
 <dc:description>Comment: 20 pages, 1 figure. Submitted to STOC 2017</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01346</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the primitivity of PRESENT and other lightweight ciphers</dc:title>
 <dc:creator>Aragona, Riccardo</dc:creator>
 <dc:creator>Calderini, Marco</dc:creator>
 <dc:creator>Tortora, Antonio</dc:creator>
 <dc:creator>Tota, Maria</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>20B15, 20B35, 94A60</dc:subject>
 <dc:description>  We provide two sufficient conditions to guarantee that the round functions of
a translation based cipher generate a primitive group. Furthermore, under the
same hypotheses, and assuming that a round of the cipher is strongly proper and
consists of m-bit S-Boxes, with m = 3; 4 or 5, we prove that such a group is
the alternating group. As an immediate consequence, we deduce that the round
functions of some lightweight translation based ciphers, such as the PRESENT
cipher, generate the alternating group.
</dc:description>
 <dc:description>Comment: to appear on Journal of Algebra and its Applications</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01353</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Dropout: Learning Optimal Representations Through Noisy
  Computation</dc:title>
 <dc:creator>Achille, Alessandro</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  The cross-entropy loss commonly used in deep learning is closely related to
the defining properties of optimal representations, but does not enforce some
of the key properties. We show that this can be solved by adding a
regularization term, which is in turn related to injecting multiplicative noise
in the activations of a Deep Neural Network, a special case of which is the
common practice of dropout. We show that our regularized loss function can be
efficiently minimized using Information Dropout, a generalization of dropout
rooted in information theoretic principles that automatically adapts to the
data and can better exploit architectures of limited capacity. When the task is
the reconstruction of the input, we show that our loss function yields a
Variational Autoencoder as a special case, thus providing a link between
representation learning, information theory and variational inference. Finally,
we prove that we can promote the creation of disentangled representations
simply by enforcing a factorized prior, a fact that has been observed
empirically in recent work. Our experiments validate the theoretical intuitions
behind our method, and we find that information dropout achieves a comparable
or better generalization performance than binary dropout, especially on smaller
models, since it can automatically adapt the noise to the structure of the
network, as well as to the test sample.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01359</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Out-of-Band Radiation from Large Antenna Arrays</dc:title>
 <dc:creator>Moll&#xe9;n, Christopher</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:creator>Gustavsson, Ulf</dc:creator>
 <dc:creator>Eriksson, Thomas</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Co-existing wireless systems, which share a common spectrum, need to mitigate
out-of-band (OOB) radiation to avoid excessive interference. For legacy
systems, OOB radiation is well understood and is commonly handled by digital
precompensation techniques. When using large arrays, however, new phenomena and
hardware limitations have to be considered. First, signals can be radiated
directionally, which might focus the OOB radiation. Second, low-complexity
hardware is used for cost reasons, which increases the relative amount of OOB
radiation. Given that massive MIMO and millimeter wave communication rely on
base stations with a large number of antennas, the spatial behavior of OOB
radiation from large arrays will have significant implications for the hardware
requirements of future base stations. We show that, if the OOB radiation is
beamformed, its array gain is never larger than that of the in-band signal. In
many cases, the OOB radiation is close to isotropic even when the in-band
signal is highly directive. With the same total radiated power, the OOB
radiation from large arrays is therefore never more severe than from a legacy
system with the same adjacent-channel-leakage ratio. Further, the OOB radiation
is less detrimental than from a legacy system since the high array gain of the
in-band signal allows large arrays to radiate less total power than legacy
systems. We also show how OOB radiation from large arrays varies with location
in static propagation environments and how these effects vanish when averaged
over the small-scale fading. Since a higher relative amount of OOB radiation
can be tolerated for large arrays, the linearity requirement can be relaxed as
compared to legacy systems. Specifically, less stringent linearity requirements
on each transmitter makes it possible to build large arrays from low-complexity
hardware.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01361</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research on Life Characteristics of Internet Based on Network Motifs</dc:title>
 <dc:creator>Wang, Jinfa</dc:creator>
 <dc:creator>Zhao, Hai</dc:creator>
 <dc:creator>Liu, Xiao</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  From biosystem to complex system,the study of life is always an important
area. Inspired by hyper-cycle theory about the evolution of non-life system, we
study the metabolism, self-replication and mutation behavior in the Internet
based on node entity, connection relationship and function subgraph--motif--of
network topology. Firstly a framework of complex network evolution is proposed
to analyze the birth and death phenomena of Internet topology from January 1998
to August 2013. Then we find the Internet metabolism behavior from angle of
node, motif to global topology, i.e. one born node is only added into Internet,
subsequently takes part in the local reconstruction activities. Meanwhile there
are nodes' and motifs' death. In process of the local reconstruction, although
the Internet system replicates motifs repeatedly by adding or removing actions,
the system characteristics and global structure are not destroyed. Statistics
about the motif M3 which is a full connectivity subgraph shows that the process
of its metabolism is fluctuation that causes mutation of Internet. Furthermore
we find that mutation is instinctive reaction of Internet when it's influenced
from inside or outside environment, such as Internet bubble, social network
rising and finance crisis. The behaviors of metabolism, self-replication and
mutation of Internet indicate its life characteristic as a complex artificial
life. And our work will inspire people to study the life-like phenomena of
other complex systems from angle of topology structure.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures, 1 table</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01364</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalization of the Minisum and Minimax Voting Methods</dc:title>
 <dc:creator>Sivarajan, Shankar N.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we propose a family of approval voting-schemes for electing
committees based on the preferences of voters. In our schemes, we calculate the
vector of distances of the possible committees from each of the ballots and,
for a given $ p $-norm, choose the one that minimizes the magnitude of the
distance vector under that norm. The minisum and minimax methods suggested by
previous authors and analyzed extensively in the literature naturally appear as
special cases corresponding to $ p = 1 $ and $ p = \infty, $ respectively.
Supported by examples, we suggest that using a small value of $ p, $ such as 2
or 3, provides a good compromise between the minisum and minimax voting methods
with regard to the weightage given to approvals and disapprovals. For large but
finite $ p, $ our method reduces to finding the committee that covers the
maximum number of voters, and this is far superior to the minimax method which
is prone to ties. We also discuss extensions of our methods to ternary voting.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01364</dc:identifier>
 <dc:identifier>SIAM Undergraduate Research Online (SIURO), Volume 11 (2018)</dc:identifier>
 <dc:identifier>doi:10.1137/16S014870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01368</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies</dc:title>
 <dc:creator>Linzen, Tal</dc:creator>
 <dc:creator>Dupoux, Emmanuel</dc:creator>
 <dc:creator>Goldberg, Yoav</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The success of long short-term memory (LSTM) neural networks in language
processing is typically attributed to their ability to capture long-distance
statistical regularities. Linguistic regularities are often sensitive to
syntactic structure; can such dependencies be captured by LSTMs, which do not
have explicit structural representations? We begin addressing this question
using number agreement in English subject-verb dependencies. We probe the
architecture's grammatical competence both using training objectives with an
explicit grammatical target (number prediction, grammaticality judgments) and
using language models. In the strongly supervised settings, the LSTM achieved
very high overall accuracy (less than 1% errors), but errors increased when
sequential and structural information conflicted. The frequency of such errors
rose sharply in the language-modeling setting. We conclude that LSTMs can
capture a non-trivial amount of grammatical structure given targeted
supervision, but stronger architectures may be required to further reduce
errors; furthermore, the language modeling signal is insufficient for capturing
syntax-sensitive dependencies, and should be supplemented with more direct
supervision if such dependencies need to be captured.
</dc:description>
 <dc:description>Comment: 15 pages; to appear in Transactions of the Association for
  Computational Linguistics</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01376</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denoising based Vector Approximate Message Passing</dc:title>
 <dc:creator>Schniter, Philip</dc:creator>
 <dc:creator>Rangan, Sundeep</dc:creator>
 <dc:creator>Fletcher, Alyson</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The denoising-based approximate message passing (D-AMP) methodology, recently
proposed by Metzler, Maleki, and Baraniuk, allows one to plug in sophisticated
denoisers like BM3D into the AMP algorithm to achieve state-of-the-art
compressive image recovery. But AMP diverges with small deviations from the
i.i.d.-Gaussian assumption on the measurement matrix. Recently, the vector AMP
(VAMP) algorithm has been proposed to fix this problem. In this work, we show
that the benefits of VAMP extend to D-VAMP.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01377</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formal Approach to Cyber-Physical Attacks</dc:title>
 <dc:creator>Lanotte, Ruggero</dc:creator>
 <dc:creator>Merro, Massimo</dc:creator>
 <dc:creator>Muradore, Riccardo</dc:creator>
 <dc:creator>Vigan&#xf2;, Luca</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We apply formal methods to lay and streamline theoretical foundations to
reason about Cyber-Physical Systems (CPSs) and cyber-physical attacks. We focus
on %a formal treatment of both integrity and DoS attacks to sensors and
actuators of CPSs, and on the timing aspects of these attacks. Our
contributions are threefold: (1) we define a hybrid process calculus to model
both CPSs and cyber-physical attacks; (2) we define a threat model of
cyber-physical attacks and provide the means to assess attack
tolerance/vulnerability with respect to a given attack; (3) we formalise how to
estimate the impact of a successful attack on a CPS and investigate possible
quantifications of the success chances of an attack. We illustrate definitions
and results by means of a non-trivial engineering application.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01381</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revealing the Anatomy of Vote Trading</dc:title>
 <dc:creator>Guerrero, Omar A.</dc:creator>
 <dc:creator>Matter, Ulrich</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:description>  Cooperation in the form of vote trading, also known as logrolling, is central
for law-making processes, shaping the development of democratic societies.
Empirical evidence of logrolling is scarce and limited to highly specific
situations because existing methods are not easily applicable to broader
contexts. We have developed a general and scalable methodology for revealing a
network of vote traders, allowing us to measure logrolling on a large scale.
Analysis on more than 9 million votes spanning 40 years in the U.S. Congress
reveals a higher logrolling prevalence in the Senate and an overall decreasing
trend over recent congresses, coincidental with high levels of political
polarization. Our method is applicable in multiple contexts, shedding light on
many aspects of logrolling and opening new doors in the study of hidden
cooperation.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01390</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Modeling of Motion Perception using Dynamical Stochastic
  Textures</dc:title>
 <dc:creator>Vacher, Jonathan</dc:creator>
 <dc:creator>Meso, Andrew Isaac</dc:creator>
 <dc:creator>Perrinet, Laurent U.</dc:creator>
 <dc:creator>Peyr&#xe9;, Gabriel</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A common practice to account for psychophysical biases in vision is to frame
them as consequences of a dynamic process relying on optimal inference with
respect to a generative model. The present study details the complete
formulation of such a generative model intended to probe visual motion
perception. It is first derived in a set of axiomatic steps constrained by
biological plausibility. We then extend previous contributions by detailing
three equivalent formulations of the Gaussian dynamic texture model. First, the
composite dynamic textures are constructed by the random aggregation of warped
patterns, which can be viewed as 3D Gaussian fields. Second, these textures are
cast as solutions to a stochastic partial differential equation (sPDE). This
essential step enables real time, on-the-fly, texture synthesis using
time-discretized auto- regressive processes. It also allows for the derivation
of a local motion-energy model, which corresponds to the log-likelihood of the
probability density. The log-likelihoods are finally essential for the
construction of a Bayesian inference framework. We use the model to probe speed
perception in humans psychophysically using zoom-like changes in stimulus
spatial frequency content. The likelihood is contained within the genera- tive
model and we chose a slow speed prior consistent with previous literature. We
then validated the fitting process of the model using synthesized data. The
human data replicates previous findings that relative perceived speed is
positively biased by spatial frequency increments. The effect cannot be fully
accounted for by previous models, but the current prior acting on the
spatio-temporal likelihoods has proved necessary in accounting for the
perceptual bias.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01393</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Overlapping Clustering of Network Data Using Cut Metrics</dc:title>
 <dc:creator>Gama, Fernando</dc:creator>
 <dc:creator>Segarra, Santiago</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A novel method to obtain hierarchical and overlapping clusters from network
data -i.e., a set of nodes endowed with pairwise dissimilarities- is presented.
The introduced method is hierarchical in the sense that it outputs a nested
collection of groupings of the node set depending on the resolution or degree
of similarity desired, and it is overlapping since it allows nodes to belong to
more than one group. Our construction is rooted on the facts that a
hierarchical (non-overlapping) clustering of a network can be equivalently
represented by a finite ultrametric space and that a convex combination of
ultrametrics results in a cut metric. By applying a hierarchical
(non-overlapping) clustering method to multiple dithered versions of a given
network and then convexly combining the resulting ultrametrics, we obtain a cut
metric associated to the network of interest. We then show how to extract a
hierarchical overlapping clustering structure from the aforementioned cut
metric. Furthermore, the so-called overlapping function is presented as a tool
for gaining insights about the data by identifying meaningful resolutions of
the obtained hierarchical structure. Additionally, we explore hierarchical
overlapping quasi-clustering methods that preserve the asymmetry of the data
contained in directed networks. Finally, the presented method is illustrated
via synthetic and real-world classification problems including handwritten
digit classification and authorship attribution of famous plays.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Signal and
  Information Processing Over Networks</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01400</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Rank Scientific Documents from the Crowd</dc:title>
 <dc:creator>Lingeman, Jesse M</dc:creator>
 <dc:creator>Yu, Hong</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Finding related published articles is an important task in any science, but
with the explosion of new work in the biomedical domain it has become
especially challenging. Most existing methodologies use text similarity metrics
to identify whether two articles are related or not. However biomedical
knowledge discovery is hypothesis-driven. The most related articles may not be
ones with the highest text similarities. In this study, we first develop an
innovative crowd-sourcing approach to build an expert-annotated
document-ranking corpus. Using this corpus as the gold standard, we then
evaluate the approaches of using text similarity to rank the relatedness of
articles. Finally, we develop and evaluate a new supervised model to
automatically rank related scientific articles. Our results show that authors'
ranking differ significantly from rankings by text-similarity-based models. By
training a learning-to-rank model on a subset of the annotated corpus, we found
the best supervised learning-to-rank model (SVM-Rank) significantly surpassed
state-of-the-art baseline systems.
</dc:description>
 <dc:description>Comment: 12 pages, 1 figure</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01403</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Searching a Tree with Permanently Noisy Advice</dc:title>
 <dc:creator>Boczkowski, Lucas</dc:creator>
 <dc:creator>Korman, Amos</dc:creator>
 <dc:creator>Rodeh, Yoav</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider a search problem on trees using unreliable guiding instructions.
Specifically, an agent starts a search at the root of a tree aiming to find a
treasure hidden at one of the nodes by an adversary. Each visited node holds
information, called advice, regarding the most promising neighbor to continue
the search. However, the memory holding this information may be unreliable.
Modeling this scenario, we focus on a probabilistic setting. That is, the
advice at a node is a pointer to one of its neighbors. With probability $q$
each node is faulty, independently of other nodes, in which case its advice
points at an arbitrary neighbor, chosen u.a.r. Otherwise, the node is sound and
points at the correct neighbor. Crucially, the advice is permanent, in the
sense that querying a node several times would yield the same answer.
  Let $\Delta$ denote the maximal degree. Roughly speaking, the main message of
this paper is that in order to obtain efficient search, $1/\sqrt{\Delta}$ is a
threshold for the noise parameter $q$. Essentially, we prove that above the
threshold, every search algorithm has query complexity (and move complexity)
which is both exponential in the depth $d$ of the treasure and polynomial in
the number of nodes $n$. Conversely, below the threshold, there exists an
algorithm with move complexity $O(d\sqrt{\Delta})$, and an algorithm with query
complexity $O(\sqrt{\Delta}\log \Delta \log^2 n)$. Moreover, for the case of
regular trees, we obtain an algorithm with query complexity
$O(\sqrt{\Delta}\log n\log\log n)$. The move complexity bound is tight below
the threshold and the query complexity bounds are not far from the lower bound
of $\Omega(\sqrt{\Delta}\log_\Delta n)$. We also consider an adversarial
variant which can find applications in making search trees robust to memory
faults
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01408</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonnegative Matrix Underapproximation for Robust Multiple Model Fitting</dc:title>
 <dc:creator>Tepper, Mariano</dc:creator>
 <dc:creator>Sapiro, Guillermo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we introduce a highly efficient algorithm to address the
nonnegative matrix underapproximation (NMU) problem, i.e., nonnegative matrix
factorization (NMF) with an additional underapproximation constraint. NMU
results are interesting as, compared to traditional NMF, they present
additional sparsity and part-based behavior, explaining unique data features.
To show these features in practice, we first present an application to the
analysis of climate data. We then present an NMU-based algorithm to robustly
fit multiple parametric models to a dataset. The proposed approach delivers
state-of-the-art results for the estimation of multiple fundamental matrices
and homographies, outperforming other alternatives in the literature and
exemplifying the use of efficient NMU computations.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01414</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-Theoretic Bounds and Approximations in Neural Population
  Coding</dc:title>
 <dc:creator>Huang, Wentao</dc:creator>
 <dc:creator>Zhang, Kechen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  While Shannon's mutual information has widespread applications in many
disciplines, for practical applications it is often difficult to calculate its
value accurately for high-dimensional variables because of the curse of
dimensionality. This paper is focused on effective approximation methods for
evaluating mutual information in the context of neural population coding. For
large but finite neural populations, we derive several information-theoretic
asymptotic bounds and approximation formulas that remain valid in
high-dimensional spaces. We prove that optimizing the population density
distribution based on these approximation formulas is a convex optimization
problem which allows efficient numerical solutions. Numerical simulation
results confirmed that our asymptotic formulas were highly accurate for
approximating mutual information for large neural populations. In special
cases, the approximation formulas are exactly equal to the true mutual
information. We also discuss techniques of variable transformation and
dimensionality reduction to facilitate computation of the approximations.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01419</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stratifying High Dimensional Data Based on Proximity to the Convex Hull
  Boundary</dc:title>
 <dc:creator>Ziegelmeier, Lori</dc:creator>
 <dc:creator>Kirby, Michael</dc:creator>
 <dc:creator>Peterson, Chris</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>52A20, 52A41, 90C20, 90C25</dc:subject>
 <dc:description>  The convex hull of a set of points, $C$, serves to expose extremal properties
of $C$ and can help identify elements in $C$ of high interest. For many
problems, particularly in the presence of noise, the true vertex set (and
facets) may be difficult to determine. One solution is to expand the list of
high interest candidates to points lying near the boundary of the convex hull.
We propose a quadratic program for the purpose of stratifying points in a data
cloud based on proximity to the boundary of the convex hull. For each data
point, a quadratic program is solved to determine an associated weight vector.
We show that the weight vector encodes geometric information concerning the
point's relationship to the boundary of the convex hull. The computation of the
weight vectors can be carried out in parallel, and for a fixed number of points
and fixed neighborhood size, the overall computational complexity of the
algorithm grows linearly with dimension. As a consequence, meaningful
computations can be completed on reasonably large, high dimensional data sets.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01421</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>STDP-based spiking deep convolutional neural networks for object
  recognition</dc:title>
 <dc:creator>Kheradpisheh, Saeed Reza</dc:creator>
 <dc:creator>Ganjtabesh, Mohammad</dc:creator>
 <dc:creator>Thorpe, Simon J</dc:creator>
 <dc:creator>Masquelier, Timoth&#xe9;e</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Previous studies have shown that spike-timing-dependent plasticity (STDP) can
be used in spiking neural networks (SNN) to extract visual features of low or
intermediate complexity in an unsupervised manner. These studies, however, used
relatively shallow architectures, and only one layer was trainable. Another
line of research has demonstrated - using rate-based neural networks trained
with back-propagation - that having many layers increases the recognition
robustness, an approach known as deep learning. We thus designed a deep SNN,
comprising several convolutional (trainable with STDP) and pooling layers. We
used a temporal coding scheme where the most strongly activated neurons fire
first, and less activated neurons fire later or not at all. The network was
exposed to natural images. Thanks to STDP, neurons progressively learned
features corresponding to prototypical patterns that were both salient and
frequent. Only a few tens of examples per category were required and no label
was needed. After learning, the complexity of the extracted features increased
along the hierarchy, from edge detectors in the first layer to object
prototypes in the last layer. Coding was very sparse, with only a few thousands
spikes per image, and in some cases the object category could be reasonably
well inferred from the activity of a single higher-order neuron. More
generally, the activity of a few hundreds of such neurons contained robust
category information, as demonstrated using a classifier on Caltech 101,
ETH-80, and MNIST databases. We also demonstrate the superiority of STDP over
other unsupervised techniques such as random crops (HMAX) or auto-encoders.
Taken together, our results suggest that the combination of STDP with latency
coding may be a key to understanding the way that the primate visual system
learns, its remarkable processing speed and its low energy consumption.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01423</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Continuous Semantic Representations of Symbolic Expressions</dc:title>
 <dc:creator>Allamanis, Miltiadis</dc:creator>
 <dc:creator>Chanthirasegaran, Pankajan</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:creator>Sutton, Charles</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Combining abstract, symbolic reasoning with continuous neural reasoning is a
grand challenge of representation learning. As a step in this direction, we
propose a new architecture, called neural equivalence networks, for the problem
of learning continuous semantic representations of algebraic and logical
expressions. These networks are trained to represent semantic equivalence, even
of expressions that are syntactically very different. The challenge is that
semantic representations must be computed in a syntax-directed manner, because
semantics is compositional, but at the same time, small changes in syntax can
lead to very large changes in semantics, which can be difficult for continuous
neural architectures. We perform an exhaustive evaluation on the task of
checking equivalence on a highly diverse class of symbolic algebraic and
boolean expression types, showing that our model significantly outperforms
existing architectures.
</dc:description>
 <dc:description>Comment: Accepted to ICML 2017</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01427</identifier>
 <datestamp>2017-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparsely-Connected Neural Networks: Towards Efficient VLSI
  Implementation of Deep Neural Networks</dc:title>
 <dc:creator>Ardakani, Arash</dc:creator>
 <dc:creator>Condo, Carlo</dc:creator>
 <dc:creator>Gross, Warren J.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recently deep neural networks have received considerable attention due to
their ability to extract and represent high-level abstractions in data sets.
Deep neural networks such as fully-connected and convolutional neural networks
have shown excellent performance on a wide range of recognition and
classification tasks. However, their hardware implementations currently suffer
from large silicon area and high power consumption due to the their high degree
of complexity. The power/energy consumption of neural networks is dominated by
memory accesses, the majority of which occur in fully-connected networks. In
fact, they contain most of the deep neural network parameters. In this paper,
we propose sparsely-connected networks, by showing that the number of
connections in fully-connected networks can be reduced by up to 90% while
improving the accuracy performance on three popular datasets (MNIST, CIFAR10
and SVHN). We then propose an efficient hardware architecture based on
linear-feedback shift registers to reduce the memory requirements of the
proposed sparsely-connected networks. The proposed architecture can save up to
90% of memory compared to the conventional implementations of fully-connected
neural networks. Moreover, implementation results show up to 84% reduction in
the energy consumption of a single neuron of the proposed sparsely-connected
networks compared to a single neuron of fully-connected neural networks.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01428</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost universal codes for MIMO wiretap channels</dc:title>
 <dc:creator>Luzzi, Laura</dc:creator>
 <dc:creator>Vehkalahti, Roope</dc:creator>
 <dc:creator>Ling, Cong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  Despite several works on secrecy coding for fading and MIMO wiretap channels
from an error probability perspective, the construction of information
theoretically secure codes over such channels remains as an open problem. In
this paper, we consider a fading wiretap channel model where the transmitter
has only partial statistical channel state information. We extend the flatness
factor criterion from the Gaussian wiretap channel to fading and MIMO wiretap
channels, and propose concrete lattice codes with a vanishing flatness factor
to achieve information theoretic security. These codes are built from algebraic
number fields with constant root discriminant for the single-antenna fading
wiretap channel, and from division algebras centered at such number fields for
the MIMO wiretap channel, respectively. The proposed lattice codes achieve
strong secrecy and semantic security over any ergodic stationary fading/MIMO
wiretap channel with sufficiently fast decay of time correlations, for all
secrecy rates $R &lt; C_b-C_e -\kappa$, where $C_b$ and $C_e$ are Bob and Eve's
channel capacities respectively, and $\kappa$ is an explicit constant gap.
Moreover, these codes are almost universal in the sense that a fixed code is
good for secrecy for a wide range of fading models.
</dc:description>
 <dc:description>Comment: 31 pages, 1 figure</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01429</identifier>
 <datestamp>2017-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Epistemic extensions of combined classical and intuitionistic
  propositional logic</dc:title>
 <dc:creator>Lewitzka, Steffen</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Logic $L$ was introduced by Lewitzka [7] as a modal system that combines
intuitionistic and classical logic: $L$ is a conservative extension of CPC and
it contains a copy of IPC via the embedding $\varphi\mapsto\square\varphi$. In
this article, we consider $L3$, i.e. $L$ augmented with S3 modal axioms, define
basic epistemic extensions and prove completeness w.r.t. algebraic semantics.
The resulting logics combine classical knowledge and belief with intuitionistic
truth. Some epistemic laws of Intuitionistic Epistemic Logic studied by Artemov
and Protopopescu [1] are reflected by classical modal principles. In
particular, the implications &quot;intuitionistic truth $\Rightarrow$ knowledge
$\Rightarrow$ classical truth&quot; are represented by the theorems
$\square\varphi\rightarrow K\varphi$ and $K\varphi\rightarrow\varphi$ of our
logic $EL3$, where we are dealing with classical instead of intuitionistic
knowledge. Finally, we show that a modification of our semantics yields
algebraic models for the systems of Intuitionistic Epistemic Logic introduced
in [1].
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01429</dc:identifier>
 <dc:identifier>doi:10.1093/jigpal/jzx004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01436</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Recurrent Span Representations for Extractive Question
  Answering</dc:title>
 <dc:creator>Lee, Kenton</dc:creator>
 <dc:creator>Salant, Shimi</dc:creator>
 <dc:creator>Kwiatkowski, Tom</dc:creator>
 <dc:creator>Parikh, Ankur</dc:creator>
 <dc:creator>Das, Dipanjan</dc:creator>
 <dc:creator>Berant, Jonathan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The reading comprehension task, that asks questions about a given evidence
document, is a central problem in natural language understanding. Recent
formulations of this task have typically focused on answer selection from a set
of candidates pre-defined manually or through the use of an external NLP
pipeline. However, Rajpurkar et al. (2016) recently released the SQuAD dataset
in which the answers can be arbitrary strings from the supplied text. In this
paper, we focus on this answer extraction task, presenting a novel model
architecture that efficiently builds fixed length representations of all spans
in the evidence document with a recurrent network. We show that scoring
explicit span representations significantly improves performance over other
approaches that factor the prediction into separate predictions about words or
start and end markers. Our approach improves upon the best published results of
Wang &amp; Jiang (2016) by 5% and decreases the error of Rajpurkar et al.'s
baseline by &gt; 50%.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01449</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised deep learning by metric embedding</dc:title>
 <dc:creator>Hoffer, Elad</dc:creator>
 <dc:creator>Ailon, Nir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep networks are successfully used as classification models yielding
state-of-the-art results when trained on a large number of labeled samples.
These models, however, are usually much less suited for semi-supervised
problems because of their tendency to overfit easily when trained on small
amounts of data. In this work we will explore a new training objective that is
targeting a semi-supervised regime with only a small subset of labeled data.
This criterion is based on a deep metric embedding over distance relations
within the set of labeled samples, together with constraints over the
embeddings of the unlabeled set. The final learned representations are
discriminative in euclidean space, and hence can be used with subsequent
nearest-neighbor classification using the labeled samples.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01455</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ways of Conditioning Generative Adversarial Networks</dc:title>
 <dc:creator>Kwak, Hanock</dc:creator>
 <dc:creator>Zhang, Byoung-Tak</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The GANs are generative models whose random samples realistically reflect
natural images. It also can generate samples with specific attributes by
concatenating a condition vector into the input, yet research on this field is
not well studied. We propose novel methods of conditioning generative
adversarial networks (GANs) that achieve state-of-the-art results on MNIST and
CIFAR-10. We mainly introduce two models: an information retrieving model that
extracts conditional information from the samples, and a spatial bilinear
pooling model that forms bilinear features derived from the spatial cross
product of an image and a condition vector. These methods significantly enhance
log-likelihood of test data under the conditional distributions compared to the
methods of concatenation.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01456</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning heat diffusion graphs</dc:title>
 <dc:creator>Thanou, Dorina</dc:creator>
 <dc:creator>Dong, Xiaowen</dc:creator>
 <dc:creator>Kressner, Daniel</dc:creator>
 <dc:creator>Frossard, Pascal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Effective information analysis generally boils down to properly identifying
the structure or geometry of the data, which is often represented by a graph.
In some applications, this structure may be partly determined by design
constraints or pre-determined sensing arrangements, like in road transportation
networks for example. In general though, the data structure is not readily
available and becomes pretty difficult to define. In particular, the global
smoothness assumptions, that most of the existing works adopt, are often too
general and unable to properly capture localized properties of data. In this
paper, we go beyond this classical data model and rather propose to represent
information as a sparse combination of localized functions that live on a data
structure represented by a graph. Based on this model, we focus on the problem
of inferring the connectivity that best explains the data samples at different
vertices of a graph that is a priori unknown. We concentrate on the case where
the observed data is actually the sum of heat diffusion processes, which is a
quite common model for data on networks or other irregular structures. We cast
a new graph learning problem and solve it with an efficient nonconvex
optimization algorithm. Experiments on both synthetic and real world data
finally illustrate the benefits of the proposed graph learning framework and
confirm that the data structure can be efficiently learned from data
observations only. We believe that our algorithm will help solving key
questions in diverse application domains such as social and biological network
analysis where it is crucial to unveil proper geometry for data understanding
and inference.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01457</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-task learning with deep model based reinforcement learning</dc:title>
 <dc:creator>Mujika, Asier</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In recent years, model-free methods that use deep learning have achieved
great success in many different reinforcement learning environments. Most
successful approaches focus on solving a single task, while multi-task
reinforcement learning remains an open problem. In this paper, we present a
model based approach to deep reinforcement learning which we use to solve
different tasks simultaneously. We show that our approach not only does not
degrade but actually benefits from learning multiple tasks. For our model, we
also present a new kind of recurrent neural network inspired by residual
networks that decouples memory from computation allowing to model complex
environments that do not require lots of memory.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01462</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tying Word Vectors and Word Classifiers: A Loss Framework for Language
  Modeling</dc:title>
 <dc:creator>Inan, Hakan</dc:creator>
 <dc:creator>Khosravi, Khashayar</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recurrent neural networks have been very successful at predicting sequences
of words in tasks such as language modeling. However, all such models are based
on the conventional classification framework, where the model is trained
against one-hot targets, and each word is represented both as an input and as
an output in isolation. This causes inefficiencies in learning both in terms of
utilizing all of the information and in terms of the number of parameters
needed to train. We introduce a novel theoretical framework that facilitates
better learning in language modeling, and show that our framework leads to
tying together the input embedding and the output projection matrices, greatly
reducing the number of trainable variables. Our framework leads to state of the
art performance on the Penn Treebank with a variety of network models.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01463</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>International Portfolio Optimisation with Integrated Currency Overlay
  Costs and Constraints</dc:title>
 <dc:creator>Chatsanga, Nonthachote</dc:creator>
 <dc:creator>Parkes, Andrew J.</dc:creator>
 <dc:subject>Quantitative Finance - Portfolio Management</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Portfolio optimisation typically aims to provide an optimal allocation that
minimises risk, at a given return target, by diversifying over different
investments. However, the potential scope of such risk diversification can be
limited if investments are concentrated in only one country, or more
specifically one currency. Multi-currency portfolio is an alternative to
achieve higher returns and more diversified portfolios but it requires a
careful management of the entailed risks from changes in exchange rates.
  The deviation between asset and currency exposures in a portfolio is defined
as the &quot;currency overlay&quot;. This paper addresses risk mitigation by allowing
currency overlay and asset allocation be optimised together. We propose a model
of the international portfolio optimisation problem in which the currency
overlay is constructed by holding foreign exchange rate forward contracts.
Crucially, the cost of carry, transaction costs, and margin requirement of
forward contracts are also taken into account in portfolio return calculation.
This novel extension of previous overlay models improves the accuracy of risk
and return calculation of portfolios; furthermore, our experimental results
show that inclusion of such costs significantly changes the optimal decisions.
Effects of constraints imposed to reduce transaction costs associated are
examined and the empirical results show that risk-return compensation of
portfolios varies significantly with different return targets.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01463</dc:identifier>
 <dc:identifier>doi:10.1016/j.eswa.2017.04.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01477</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Hover to Compromise the Confidentiality of User Input on Android</dc:title>
 <dc:creator>Ulqinaku, Enis</dc:creator>
 <dc:creator>Malisa, Luka</dc:creator>
 <dc:creator>Stefa, Julinda</dc:creator>
 <dc:creator>Mei, Alessandro</dc:creator>
 <dc:creator>Capkun, Srdjan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We show that the new hover (floating touch) technology, available in a number
of today's smartphone models, can be abused by any Android application running
with a common SYSTEM_ALERT_WINDOW permission to record all touchscreen input
into other applications. Leveraging this attack, a malicious application
running on the system is therefore able to profile user's behavior, capture
sensitive input such as passwords and PINs as well as record all user's social
interactions. To evaluate our attack we implemented Hoover, a proof-of-concept
malicious application that runs in the system background and records all input
to foreground applications. We evaluated Hoover with 40 users, across two
different Android devices and two input methods, stylus and finger. In the case
of touchscreen input by finger, Hoover estimated the positions of users' clicks
within an error of 100 pixels and keyboard input with an accuracy of 79%.
Hoover captured users' input by stylus even more accurately, estimating users'
clicks within 2 pixels and keyboard input with an accuracy of 98%. We discuss
ways of mitigating this attack and show that this cannot be done by simply
restricting access to permissions or imposing additional cognitive load on the
users since this would significantly constrain the intended use of the hover
technology.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01479</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Efficient Re-Pair Compression</dc:title>
 <dc:creator>Bille, Philip</dc:creator>
 <dc:creator>G&#xf8;rtz, Inge Li</dc:creator>
 <dc:creator>Prezza, Nicola</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Re-Pair is an effective grammar-based compression scheme achieving strong
compression rates in practice. Let $n$, $\sigma$, and $d$ be the text length,
alphabet size, and dictionary size of the final grammar, respectively. In their
original paper, the authors show how to compute the Re-Pair grammar in expected
linear time and $5n + 4\sigma^2 + 4d + \sqrt{n}$ words of working space on top
of the text. In this work, we propose two algorithms improving on the space of
their original solution. Our model assumes a memory word of $\lceil\log_2
n\rceil$ bits and a re-writable input text composed by $n$ such words. Our
first algorithm runs in expected $\mathcal O(n/\epsilon)$ time and uses
$(1+\epsilon)n +\sqrt n$ words of space on top of the text for any parameter
$0&lt;\epsilon \leq 1$ chosen in advance. Our second algorithm runs in expected
$\mathcal O(n\log n)$ time and improves the space to $n +\sqrt n$ words.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01484</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UMDFaces: An Annotated Face Dataset for Training Deep Networks</dc:title>
 <dc:creator>Bansal, Ankan</dc:creator>
 <dc:creator>Nanduri, Anirudh</dc:creator>
 <dc:creator>Castillo, Carlos</dc:creator>
 <dc:creator>Ranjan, Rajeev</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent progress in face detection (including keypoint detection), and
recognition is mainly being driven by (i) deeper convolutional neural network
architectures, and (ii) larger datasets. However, most of the large datasets
are maintained by private companies and are not publicly available. The
academic computer vision community needs larger and more varied datasets to
make further progress.
  In this paper we introduce a new face dataset, called UMDFaces, which has
367,888 annotated faces of 8,277 subjects. We also introduce a new face
recognition evaluation protocol which will help advance the state-of-the-art in
this area. We discuss how a large dataset can be collected and annotated using
human annotators and deep networks. We provide human curated bounding boxes for
faces. We also provide estimated pose (roll, pitch and yaw), locations of
twenty-one key-points and gender information generated by a pre-trained neural
network. In addition, the quality of keypoint annotations has been verified by
humans for about 115,000 images. Finally, we compare the quality of the dataset
with other publicly available face datasets at similar scales.
</dc:description>
 <dc:description>Comment: Updates: Verified keypoints, removed duplicate subjects, released
  test protocol</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01487</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Morphological Inflection Generation with Hard Monotonic Attention</dc:title>
 <dc:creator>Aharoni, Roee</dc:creator>
 <dc:creator>Goldberg, Yoav</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a neural model for morphological inflection generation which
employs a hard attention mechanism, inspired by the nearly-monotonic alignment
commonly found between the characters in a word and the characters in its
inflection. We evaluate the model on three previously studied morphological
inflection generation datasets and show that it provides state of the art
results in various setups compared to previous neural and non-neural
approaches. Finally we present an analysis of the continuous representations
learned by both the hard and soft attention \cite{bahdanauCB14} models for the
task, shedding some light on the features such models extract.
</dc:description>
 <dc:description>Comment: Accepted as a long paper in ACL 2017</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01491</identifier>
 <datestamp>2017-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Deep Neural Networks with Rectified Linear Units</dc:title>
 <dc:creator>Arora, Raman</dc:creator>
 <dc:creator>Basu, Amitabh</dc:creator>
 <dc:creator>Mianjy, Poorya</dc:creator>
 <dc:creator>Mukherjee, Anirbit</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we investigate the family of functions representable by deep
neural networks (DNN) with rectified linear units (ReLU). We give the
first-ever polynomial time (in the size of data) algorithm to train to global
optimality a ReLU DNN with one hidden layer, assuming the input dimension and
number of nodes of the network as fixed constants.
  We also improve on the known lower bounds on size (from exponential to super
exponential) for approximating a ReLU deep net function by a shallower ReLU
net. Our gap theorems hold for smoothly parametrized families of &quot;hard&quot;
functions, contrary to countable, discrete families known in the literature. An
example consequence of our gap theorems is the following: for every natural
number $k$ there exists a function representable by a ReLU DNN with $k^2$
hidden layers and total size $k^3$, such that any ReLU DNN with at most $k$
hidden layers will require at least $\frac{1}{2}k^{k+1}-1$ total nodes.
  Finally, we construct a family of $\mathbb{R}^n\to \mathbb{R}$ piecewise
linear functions for $n\geq 2$ (also smoothly parameterized), whose number of
affine pieces scales exponentially with the dimension $n$ at any fixed size and
depth. To the best of our knowledge, such a construction with exponential
dependence on $n$ has not been achieved by previous families of &quot;hard&quot;
functions in the neural nets literature. This construction utilizes the theory
of zonotopes from polyhedral theory.
</dc:description>
 <dc:description>Comment: The poly(data) training algorithm has been improved to now be
  applicable to any single hidden layer R^n-&gt; R ReLU DNN</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01501</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Poisoning: Lightweight Soft Fault Injection for Python</dc:title>
 <dc:creator>Alipour, Mohammad Amin</dc:creator>
 <dc:creator>Groce, Alex</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.4.5</dc:subject>
 <dc:description>  This paper introduces and explores the idea of data poisoning, a light-weight
peer-architecture technique to inject faults into Python programs. This method
requires very small modification to the original program, which facilitates
evaluation of sensitivity of systems that are prototyped or modeled in Python.
We propose different fault scenarios that can be injected to programs using
data poisoning. We use Dijkstra's Self Stabilizing Ring Algorithm to illustrate
the approach.
</dc:description>
 <dc:description>Comment: Draft- 6 pages</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01503</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Protein Secondary Structure Prediction Using Deep Multi-scale
  Convolutional Neural Networks and Next-Step Conditioning</dc:title>
 <dc:creator>Busia, Akosua</dc:creator>
 <dc:creator>Collins, Jasmine</dc:creator>
 <dc:creator>Jaitly, Navdeep</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:description>  Recently developed deep learning techniques have significantly improved the
accuracy of various speech and image recognition systems. In this paper we
adapt some of these techniques for protein secondary structure prediction. We
first train a series of deep neural networks to predict eight-class secondary
structure labels given a protein's amino acid sequence information and find
that using recent methods for regularization, such as dropout and weight-norm
constraining, leads to measurable gains in accuracy. We then adapt recent
convolutional neural network architectures--Inception, ReSNet, and DenseNet
with Batch Normalization--to the problem of protein structure prediction. These
convolutional architectures make heavy use of multi-scale filter layers that
simultaneously compute features on several scales, and use residual connections
to prevent underfitting. Using a carefully modified version of these
architectures, we achieve state-of-the-art performance of 70.0% per amino acid
accuracy on the public CB513 benchmark dataset. Finally, we explore additions
from sequence-to-sequence learning, altering the model to make its predictions
conditioned on both the protein's amino acid sequence and its past secondary
structure labels. We introduce a new method of ensembling such a conditional
model with our convolutional model, an approach which reaches 70.6% Q8 accuracy
on CB513. We argue that these results can be further refined for larger boosts
in prediction accuracy through more sophisticated attempts to control
overfitting of conditional models. We aim to release the code for these
experiments as part of the TensorFlow repository.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures, submitted to RECOMB 2017</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01504</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Causal Direction and Confounding of Two Discrete Variables</dc:title>
 <dc:creator>Chalupka, Krzysztof</dc:creator>
 <dc:creator>Eberhardt, Frederick</dc:creator>
 <dc:creator>Perona, Pietro</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a method to classify the causal relationship between two discrete
variables given only the joint distribution of the variables, acknowledging
that the method is subject to an inherent baseline error. We assume that the
causal system is acyclicity, but we do allow for hidden common causes. Our
algorithm presupposes that the probability distributions $P(C)$ of a cause $C$
is independent from the probability distribution $P(E\mid C)$ of the
cause-effect mechanism. While our classifier is trained with a Bayesian
assumption of flat hyperpriors, we do not make this assumption about our test
data. This work connects to recent developments on the identifiability of
causal models over continuous variables under the assumption of &quot;independent
mechanisms&quot;. Carefully-commented Python notebooks that reproduce all our
experiments are available online at
http://vision.caltech.edu/~kchalupk/code.html.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01505</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Stochastic Gradient Descent with Feedback</dc:title>
 <dc:creator>Koushik, Jayanth</dc:creator>
 <dc:creator>Hayashi, Hiroaki</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we propose a simple and efficient method for improving
stochastic gradient descent methods by using feedback from the objective
function. The method tracks the relative changes in the objective function with
a running average, and uses it to adaptively tune the learning rate in
stochastic gradient descent. We specifically apply this idea to modify Adam, a
popular algorithm for training deep neural networks. We conduct experiments to
compare the resulting algorithm, which we call Eve, with state of the art
methods used for training deep learning models. We train CNNs for image
classification, and RNNs for language modeling and question answering. Our
experiments show that Eve outperforms all other algorithms on these benchmark
tasks. We also analyze the behavior of the feedback mechanism during the
training process.
</dc:description>
 <dc:description>Comment: Added section 3.1 discussing an assumption of our method. Fixed a
  typo regarding the lower/upper bound in algorithm section</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01507</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counterexamples and Proof Loophole for the C/C++ to POWER and ARMv7
  Trailing-Sync Compiler Mappings</dc:title>
 <dc:creator>Manerkar, Yatin A.</dc:creator>
 <dc:creator>Trippel, Caroline</dc:creator>
 <dc:creator>Lustig, Daniel</dc:creator>
 <dc:creator>Pellauer, Michael</dc:creator>
 <dc:creator>Martonosi, Margaret</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  The C and C++ high-level languages provide programmers with atomic operations
for writing high-performance concurrent code. At the assembly language level, C
and C++ atomics get mapped down to individual instructions or combinations of
instructions by compilers, depending on the ordering guarantees and
synchronization instructions provided by the underlying architecture. These
compiler mappings must uphold the ordering guarantees provided by C/C++ atomics
or the compiled program will not behave according to the C/C++ memory model. In
this paper we discuss two counterexamples to the well-known trailing-sync
compiler mappings for the Power and ARMv7 architectures that were previously
thought to be proven correct. In addition to the counterexamples, we discuss
the loophole in the proof of the mappings that allowed the incorrect mappings
to be proven correct. We also discuss the current state of compilers and
architectures in relation to the bug.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01523</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite generating sets for reversible gate sets under general
  conservation laws</dc:title>
 <dc:creator>Boykett, Tim</dc:creator>
 <dc:creator>Kari, Jarkko</dc:creator>
 <dc:creator>Salo, Ville</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  It is well-known that the Toffoli gate and the negation gate together yield a
universal gate set, in the sense that every permutation of $\{0,1\}^n$ can be
implemented as a composition of these gates. Since every bit operation that
does not use all of the bits performs an even permutation, we need to use at
least one auxiliary bit to perform every permutation, and it is known that one
bit is indeed enough. Without auxiliary bits, all even permutations can be
implemented. We generalize these results to non-binary logic: For any finite
set $A$, a finite gate set can generate all even permutations of $A^n$ for all
$n$, without any auxiliary symbols. This directly implies the previously
published result that a finite gate set can generate all permutations of $A^n$
when the cardinality of $A$ is odd, and that one auxiliary symbol is necessary
and sufficient to obtain all permutations when the cardinality of $A$ is even.
We also consider the conservative case, that is, those permutations of $A^n$
that preserve the weight of the input word. The weight is the vector that
records how many times each symbol occurs in the word or, more generally, the
image of the word under a fixed monoid homomorphism from $A^*$ to a commutative
monoid. It turns out that no finite conservative gate set can, for all $n$,
implement all conservative even permutations of $A^n$ without auxiliary bits.
But we provide a finite gate set that can implement all those conservative
permutations that are even within each weight class of $A^n$.
</dc:description>
 <dc:description>Comment: Extended journal version of our previous paper [arXiv:1602.04967] for
  the RC2016 conference</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01525</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diversity Pulse Shaped Transmission in Ultra-Dense Small Cell Networks</dc:title>
 <dc:creator>Jafari, Amir H.</dc:creator>
 <dc:creator>Venkateswaran, Vijay</dc:creator>
 <dc:creator>Lopez-Perez, David</dc:creator>
 <dc:creator>Zhang, Jie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In ultra-dense small cell networks, spatial multiplexing gain is a challenge
because of the different propagation conditions. The channels associated with
different transmitreceive pairs can be highly correlated due to the i) high
probability of line-of-sight (LOS) communication between user equipment (UE)
and base station (BS), and ii) insufficient spacing between antenna elements at
both UE and BS. In this paper, we propose a novel transmission technique titled
Diversity Pulse Shaped Transmission (DPST) to enhance the throughput over the
correlated MIMO channels in an ultra-dense small cell network. The fundamental
of DPST is to shape transmit signals at adjacent antennas with distinct
interpolating filters, introducing pulse shaping diversity. In DPST, each
antenna transmits its own data stream with a relative deterministic time
offset-which must be a fraction of the symbol period-with respect to the
adjacent antenna. The delay is interpolated with the pulse shaped signal
generating a virtual MIMO channel that benefits from increased diversity from
the receiver perspective. To extract the diversity, the receiver must operate
in an over-sampled domain and hence a fractionally spaced equaliser (FSE) is
proposed. The joint impact of DPST and FSE helps the receiver to sense a less
correlated channel, eventually enhancing the UE's throughput. Moreover, in
order to minimise the spatial correlation, we aim to optimise the deterministic
fractional delay. Simulation results show that applying DPST to a correlated
channel can approximately enhance the UE throughput by 1.93x and 3.76x in 2x2
and 4x4 MIMO systems, respectively.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures. Submitted to IEEE Transactions on Vehicular
  Technology</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01529</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dapper: Data Plane Performance Diagnosis of TCP</dc:title>
 <dc:creator>Ghasemi, Mojgan</dc:creator>
 <dc:creator>Benson, Theophilus</dc:creator>
 <dc:creator>Rexford, Jennifer</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With more applications moving to the cloud, cloud providers need to diagnose
performance problems in a timely manner. Offline processing of logs is slow and
inefficient, and instrumenting the end-host network stack would violate the
tenants' rights to manage their own virtual machines (VMs). Instead, our Dapper
system analyzes TCP performance in real time near the end-hosts (e.g., at the
hypervisor, NIC, or top-of-rack switch). Dapper determines whether a connection
is limited by the sender (e.g., a slow server competing for shared resources),
the network (e.g., congestion), or the receiver (e.g., small receive buffer).
Emerging edge devices now offer flexible packet processing at high speed on
commodity hardware, making it possible to monitor TCP performance in the data
plane, at line rate. We use P4 to prototype Dapper and evaluate our design on
real and synthetic traffic. To reduce the data-plane state requirements, we
perform lightweight detection for all connections, followed by heavier-weight
diagnosis just for the troubled connections.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01534</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GFA: Exploratory Analysis of Multiple Data Sources with Group Factor
  Analysis</dc:title>
 <dc:creator>Lepp&#xe4;aho, Eemeli</dc:creator>
 <dc:creator>Ammad-ud-din, Muhammad</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  The R package GFA provides a full pipeline for factor analysis of multiple
data sources that are represented as matrices with co-occurring samples. It
allows learning dependencies between subsets of the data sources, decomposed
into latent factors. The package also implements sparse priors for the
factorization, providing interpretable biclusters of the multi-source data
</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01540</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topology and Geometry of Half-Rectified Network Optimization</dc:title>
 <dc:creator>Freeman, C. Daniel</dc:creator>
 <dc:creator>Bruna, Joan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The loss surface of deep neural networks has recently attracted interest in
the optimization and machine learning communities as a prime example of
high-dimensional non-convex problem. Some insights were recently gained using
spin glass models and mean-field approximations, but at the expense of strongly
simplifying the nonlinear nature of the model.
  In this work, we do not make any such assumption and study conditions on the
data distribution and model architecture that prevent the existence of bad
local minima. Our theoretical work quantifies and formalizes two important
\emph{folklore} facts: (i) the landscape of deep linear networks has a
radically different topology from that of deep half-rectified ones, and (ii)
that the energy landscape in the non-linear case is fundamentally controlled by
the interplay between the smoothness of the data distribution and model
over-parametrization. Our main theoretical contribution is to prove that
half-rectified single layer networks are asymptotically connected, and we
provide explicit bounds that reveal the aforementioned interplay.
  The conditioning of gradient descent is the next challenge we address. We
study this question through the geometry of the level sets, and we introduce an
algorithm to efficiently estimate the regularity of such sets on large-scale
networks. Our empirical results show that these level sets remain connected
throughout all the learning phase, suggesting a near convex behavior, but they
become exponentially more curvy as the energy level decays, in accordance to
what is observed in practice with very low curvature attractors.
</dc:description>
 <dc:description>Comment: 22 Pages (10 main + Appendices), 4 Figures, 1 Table, Published as a
  conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01541</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification with Ultrahigh-Dimensional Features</dc:title>
 <dc:creator>Li, Yanming</dc:creator>
 <dc:creator>Hong, Hyokyoung</dc:creator>
 <dc:creator>Kang, Jian</dc:creator>
 <dc:creator>He, Kevin</dc:creator>
 <dc:creator>Zhu, Ji</dc:creator>
 <dc:creator>Li, Yi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although much progress has been made in classification with high-dimensional
features \citep{Fan_Fan:2008, JGuo:2010, CaiSun:2014, PRXu:2014},
classification with ultrahigh-dimensional features, wherein the features much
outnumber the sample size, defies most existing work. This paper introduces a
novel and computationally feasible multivariate screening and classification
method for ultrahigh-dimensional data. Leveraging inter-feature correlations,
the proposed method enables detection of marginally weak and sparse signals and
recovery of the true informative feature set, and achieves asymptotic optimal
misclassification rates. We also show that the proposed procedure provides more
powerful discovery boundaries compared to those in \citet{CaiSun:2014} and
\citet{JJin:2009}. The performance of the proposed procedure is evaluated using
simulation studies and demonstrated via classification of patients with
different post-transplantation renal functional types.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01546</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Holistic Analysis of Multi-Source, Data-Intensive Problems
  Using Multilayered Networks</dc:title>
 <dc:creator>Santra, Abhishek</dc:creator>
 <dc:creator>Bhowmick, Sanjukta</dc:creator>
 <dc:creator>Chakravarthy, Sharma</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Holistic analysis of many real-world problems are based on data collected
from multiple sources contributing to some aspect of that problem. The word
fusion has also been used in the literature for such problems involving
disparate data types. Holistically understanding traffic patterns, causes of
accidents, bombings, terrorist planning and many natural phenomenon such as
storms, earthquakes fall into this category. Some may have real-time
requirements and some may need to be analyzed after the fact (post-mortem or
forensic analysis.) What is common for all these problems is that the amount
and types of data associated with the event. Data may also be incomplete and
trustworthiness of sources may also vary. Currently, manual and ad-hoc
approaches are used in aggregating data in different ways for analyzing and
understanding these problems.
  In this paper, we approach this problem in a novel way using multilayered
networks. We identify features of a central event and propose a network layer
for each feature. This approach allows us to study the effect of each feature
independently and its impact on the event. We also establish that the proposed
approach allows us to compose these features in arbitrary ways (without loss of
information) to analyze their combined effect. Additionally, formulation of
relationships (e.g., distance measure for a single feature instead of several
at the same time) is simpler. Further, computations can be done once on each
layer in this approach and reused for mixing and matching the features for
aggregate impacts and &quot;what if&quot; scenarios to understand the problem
holistically. This has been demonstrated by recreating the communities for the
AND-Composed network by using the communities of the individual layers.
  We believe that techniques proposed here make an important contribution to
the nascent yet fast growing area of data fusion.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01547</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Generation of Multilingual Clusters for the Evaluation of
  Distributed Representations</dc:title>
 <dc:creator>Blair, Philip</dc:creator>
 <dc:creator>Merhav, Yuval</dc:creator>
 <dc:creator>Barry, Joel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a language-agnostic way of automatically generating sets of
semantically similar clusters of entities along with sets of &quot;outlier&quot;
elements, which may then be used to perform an intrinsic evaluation of word
embeddings in the outlier detection task. We used our methodology to create a
gold-standard dataset, which we call WikiSem500, and evaluated multiple
state-of-the-art embeddings. The results show a correlation between performance
on this dataset and performance on sentiment analysis.
</dc:description>
 <dc:description>Comment: Published as a workshop paper at ICLR 2017</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01548</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Web of Science: showing a bug today that can mislead scientific research
  output's prediction</dc:title>
 <dc:creator>Batista, Pablo Diniz</dc:creator>
 <dc:creator>Marques-Carneiro, Igor</dc:creator>
 <dc:creator>Fauth, Leduc Hermeto de Almeida</dc:creator>
 <dc:creator>Brand&#xe3;o, Marcia de Oliveira Reis</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  As it happened in all domains of human activities, economic issues and the
increase of people working in scientific research have altered the way
scientific production is evaluated so as the objectives of performing the
evaluation. Introduced in 2005 by J. E. Hirsch as an indicator able to measure
individual scientific output not only in terms of quantity, but also in terms
of quality, h index has spread throughout the world. In 2007, Hirsch proposed
its adoption also as the best to predict future scientific achievement and,
consequently, a useful guide for investments in research and for institutions
when hiring members for their scientific staff. Since then, several authors
have also been using the Thomson ISI Web of Science database to develop their
proposals for evaluating research output. Here, using a software we have
developed, we analyse more than 100 thousand articles and show that a subtle
flaw in Web of Science can inflate the results of info collected, therefore
compromising the exactness and, consequently, the effectiveness of Hirsch's
proposal and its variations.
</dc:description>
 <dc:description>Comment: Submitted to Scientometrics on December 3, 2016</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01549</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>More Than Peer Production: Fanfiction Communities as Sites of
  Distributed Mentoring</dc:title>
 <dc:creator>Evans, Sarah</dc:creator>
 <dc:creator>Davis, Katie</dc:creator>
 <dc:creator>Evans, Abigail</dc:creator>
 <dc:creator>Campbell, Julie Ann</dc:creator>
 <dc:creator>Randall, David P.</dc:creator>
 <dc:creator>Yin, Kodlee</dc:creator>
 <dc:creator>Aragon, Cecilia</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  From Harry Potter to American Horror Story, fanfiction is extremely popular
among young people. Sites such as Fanfiction.net host millions of stories, with
thousands more posted each day. Enthusiasts are sharing their writing and
reading stories written by others. Exactly how does a generation known more for
videogame expertise than long-form writing become so engaged in reading and
writing in these communities? Via a nine-month ethnographic investigation of
fanfiction communities that included participant observation, interviews, a
thematic analysis of 4,500 reader reviews and an in-depth case study of a
discussion group, we found that members of fanfiction communities spontaneously
mentor each other in open forums, and that this mentoring builds upon previous
interactions in a way that is distinct from traditional forms of mentoring and
made possible by the affordances of networked publics. This work extends and
develops the theory of distributed mentoring. Our findings illustrate how
distributed mentoring supports fanfiction authors as they work to develop their
writing skills. We believe distributed mentoring holds potential for supporting
learning in a variety of formal and informal learning environments.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01549</dc:identifier>
 <dc:identifier>doi:10.1145/2998181.2998342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01553</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QBF Solving by Counterexample-guided Expansion</dc:title>
 <dc:creator>Bloem, Roderick</dc:creator>
 <dc:creator>Braud-Santoni, Nicolas</dc:creator>
 <dc:creator>Hadzic, Vedad</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce a novel generalization of Counterexample-Guided Inductive
Synthesis (CEGIS) and instantiate it to yield a novel, competitive algorithm
for solving Quantified Boolean Formulas (QBF). Current QBF solvers based on
counterexample-guided expansion use a recursive approach which scales poorly
with the number of quantifier alternations. Our generalization of CEGIS removes
the need for this recursive approach, and we instantiate it to yield a simple
and efficient algorithm for QBF solving. Lastly, this research is supported by
a competitive, though straightforward, implementation of the algorithm, making
it possible to study the practical impact of our algorithm design decisions,
along with various optimizations.
</dc:description>
 <dc:description>Comment: pre-print, submitted at TACAS 2017, source code available at
  https://extgit.iaik.tugraz.at/scos/ijtihad</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01558</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social influence makes self-interested crowds smarter: an optimal
  control perspective</dc:title>
 <dc:creator>Luo, Yu</dc:creator>
 <dc:creator>Iyengar, Garud</dc:creator>
 <dc:creator>Venkatasubramanian, Venkat</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>93C95 (Primary), 93B52, 93C05, 93C55, 15A18, 65N22, 65F10, 65F15,
  65F35 (Secondary)</dc:subject>
 <dc:description>  It is very common to observe crowds of individuals solving similar problems
with similar information in a largely independent manner. We argue here that
crowds can become &quot;smarter,&quot; i.e., more efficient and robust, by partially
following the average opinion. This observation runs counter to the widely
accepted claim that the wisdom of crowds deteriorates with social influence.
The key difference is that individuals are self-interested and hence will
reject feedbacks that do not improve their performance. We propose a
control-theoretic methodology to compute the degree of social influence, i.e.,
the level to which one accepts the population feedback, that optimizes
performance. We conducted an experiment with human subjects ($N = 194$), where
the participants were first asked to solve an optimization problem
independently, i.e., under no social influence. Our theoretical methodology
estimates a $30\%$ degree of social influence to be optimal, resulting in a
$29\%$ improvement in the crowd's performance. We then let the same cohort
solve a new problem and have access to the average opinion. Surprisingly, we
find the average degree of social influence in the cohort to be $32\%$ with a
$29\%$ improvement in performance: In other words, the crowd self-organized
into a near-optimal setting. We believe this new paradigm for making crowds
&quot;smarter&quot; has the potential for making a significant impact on a diverse set of
fields including population health to government planning. We include a case
study to show how a crowd of states can collectively learn the level of
taxation and expenditure that optimizes economic growth.
</dc:description>
 <dc:description>Comment: Venkat Venkatasubramanian is the corresponding author. Email:
  venkat@columbia.edu</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01560</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Photo-z-SQL: integrated, flexible photometric redshift computation in a
  database</dc:title>
 <dc:creator>Beck, R&#xf3;bert</dc:creator>
 <dc:creator>Dobos, L&#xe1;szl&#xf3;</dc:creator>
 <dc:creator>Budav&#xe1;ri, Tam&#xe1;s</dc:creator>
 <dc:creator>Szalay, Alexander S.</dc:creator>
 <dc:creator>Csabai, Istv&#xe1;n</dc:creator>
 <dc:subject>Astrophysics - Astrophysics of Galaxies</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We present a flexible template-based photometric redshift estimation
framework, implemented in C#, that can be seamlessly integrated into a SQL
database (or DB) server and executed on-demand in SQL. The DB integration
eliminates the need to move large photometric datasets outside a database for
redshift estimation, and utilizes the computational capabilities of DB
hardware. The code is able to perform both maximum likelihood and Bayesian
estimation, and can handle inputs of variable photometric filter sets and
corresponding broad-band magnitudes. It is possible to take into account the
full covariance matrix between filters, and filter zero points can be
empirically calibrated using measurements with given redshifts. The list of
spectral templates and the prior can be specified flexibly, and the expensive
synthetic magnitude computations are done via lazy evaluation, coupled with a
caching of results. Parallel execution is fully supported. For large upcoming
photometric surveys such as the LSST, the ability to perform in-place photo-z
calculation would be a significant advantage. Also, the efficient handling of
variable filter sets is a necessity for heterogeneous databases, for example
the Hubble Source Catalog, and for cross-match services such as SkyQuery. We
illustrate the performance of our code on two reference photo-z estimation
testing datasets, and provide an analysis of execution time and scalability
with respect to different configurations. The code is available for download at
https://github.com/beckrob/Photo-z-SQL.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures. Minor revision accepted by Astronomy &amp; Computing
  on 2017 March 11</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01560</dc:identifier>
 <dc:identifier>doi:10.1016/j.ascom.2017.03.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01569</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Two Pronged Progress in Structured Dense Matrix Multiplication</dc:title>
 <dc:creator>De Sa, Christopher</dc:creator>
 <dc:creator>Gu, Albert</dc:creator>
 <dc:creator>Puttagunta, Rohan</dc:creator>
 <dc:creator>R&#xe9;, Christopher</dc:creator>
 <dc:creator>Rudra, Atri</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Matrix-vector multiplication is one of the most fundamental computing
primitives. Given a matrix $A\in\mathbb{F}^{N\times N}$ and a vector $b$, it is
known that in the worst case $\Theta(N^2)$ operations over $\mathbb{F}$ are
needed to compute $Ab$. A broad question is to identify classes of structured
dense matrices that can be represented with $O(N)$ parameters, and for which
matrix-vector multiplication can be performed sub-quadratically. One such class
of structured matrices is the orthogonal polynomial transforms, whose rows
correspond to a family of orthogonal polynomials. Other well known classes
include the Toeplitz, Hankel, Vandermonde, Cauchy matrices and their extensions
that are all special cases of a ldisplacement rank property. In this paper, we
make progress on two fronts:
  1. We introduce the notion of recurrence width of matrices. For matrices with
constant recurrence width, we design algorithms to compute $Ab$ and $A^Tb$ with
a near-linear number of operations. This notion of width is finer than all the
above classes of structured matrices and thus we can compute multiplication for
all of them using the same core algorithm.
  2. We additionally adapt this algorithm to an algorithm for a much more
general class of matrices with displacement structure: those with low
displacement rank with respect to quasiseparable matrices. This class includes
Toeplitz-plus-Hankel-like matrices, Discrete Cosine/Sine Transforms, and more,
and captures all previously known matrices with displacement structure that we
are aware of under a unified parametrization and algorithm.
  Our work unifies, generalizes, and simplifies existing state-of-the-art
results in structured matrix-vector multiplication. Finally, we show how
applications in areas such as multipoint evaluations of multivariate
polynomials can be reduced to problems involving low recurrence width matrices.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01571</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flat ORAM: A Simplified Write-Only Oblivious RAM Construction for Secure
  Processors</dc:title>
 <dc:creator>Haider, Syed Kamran</dc:creator>
 <dc:creator>van Dijk, Marten</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Oblivious RAM (ORAM) is a cryptographic primitive which obfuscates the access
patterns to a storage thereby preventing privacy leakage. So far in the current
literature, only `fully functional' ORAMs are widely studied which can protect,
at a cost of considerable performance penalty, against the strong adversaries
who can monitor all read and write operations. However, recent research has
shown that information can still be leaked even if only the write access
pattern (not reads) is visible to the adversary. For such weaker adversaries, a
fully functional ORAM turns out to be an overkill causing unnecessary
overheads. Instead, a simple `write-only' ORAM is sufficient, and, more
interestingly, is preferred as it can offer far more performance and energy
efficiency than a fully functional ORAM.
  In this work, we present Flat ORAM: an efficient write-only ORAM scheme which
outperforms the closest existing write-only ORAM called HIVE. HIVE suffers from
performance bottlenecks while managing the memory occupancy information vital
for correctness of the protocol. Flat ORAM resolves these bottlenecks by
introducing a simple idea of Occupancy Map (OccMap) which efficiently manages
the memory occupancy information resulting in far better performance. Our
simulation results show that, on average, Flat ORAM only incurs a moderate
slowdown of $3\times$ over the insecure DRAM for memory intensive benchmarks
among Splash2 and $1.6\times$ for SPEC06. Compared to HIVE, Flat ORAM offers
$50\%$ performance gain on average and up to $80\%$ energy savings.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01572</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowd Guilds: Worker-led Reputation and Feedback on Crowdsourcing
  Platforms</dc:title>
 <dc:creator>Whiting, Mark E.</dc:creator>
 <dc:creator>Gamage, Dilrukshi</dc:creator>
 <dc:creator>Gaikwad, Snehalkumar S.</dc:creator>
 <dc:creator>Gilbee, Aaron</dc:creator>
 <dc:creator>Goyal, Shirish</dc:creator>
 <dc:creator>Ballav, Alipta</dc:creator>
 <dc:creator>Majeti, Dinesh</dc:creator>
 <dc:creator>Chhibber, Nalin</dc:creator>
 <dc:creator>Richmond-Fuller, Angela</dc:creator>
 <dc:creator>Vargus, Freddie</dc:creator>
 <dc:creator>Sarma, Tejas Seshadri</dc:creator>
 <dc:creator>Chandrakanthan, Varshine</dc:creator>
 <dc:creator>Moura, Teogenes</dc:creator>
 <dc:creator>Salih, Mohamed Hashim</dc:creator>
 <dc:creator>Kalejaiye, Gabriel Bayomi Tinoco</dc:creator>
 <dc:creator>Ginzberg, Adam</dc:creator>
 <dc:creator>Mullings, Catherine A.</dc:creator>
 <dc:creator>Dayan, Yoni</dc:creator>
 <dc:creator>Milland, Kristy</dc:creator>
 <dc:creator>Orefice, Henrique</dc:creator>
 <dc:creator>Regino, Jeff</dc:creator>
 <dc:creator>Parsi, Sayna</dc:creator>
 <dc:creator>Mainali, Kunz</dc:creator>
 <dc:creator>Sehgal, Vibhor</dc:creator>
 <dc:creator>Matin, Sekandar</dc:creator>
 <dc:creator>Sinha, Akshansh</dc:creator>
 <dc:creator>Vaish, Rajan</dc:creator>
 <dc:creator>Bernstein, Michael S.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  Crowd workers are distributed and decentralized. While decentralization is
designed to utilize independent judgment to promote high-quality results, it
paradoxically undercuts behaviors and institutions that are critical to
high-quality work. Reputation is one central example: crowdsourcing systems
depend on reputation scores from decentralized workers and requesters, but
these scores are notoriously inflated and uninformative. In this paper, we draw
inspiration from historical worker guilds (e.g., in the silk trade) to design
and implement crowd guilds: centralized groups of crowd workers who
collectively certify each other's quality through double-blind peer assessment.
A two-week field experiment compared crowd guilds to a traditional
decentralized crowd work model. Crowd guilds produced reputation signals more
strongly correlated with ground-truth worker quality than signals available on
current crowd working platforms, and more accurate than in the traditional
model.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, 1 table. To be presented at CSCW2017</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01572</dc:identifier>
 <dc:identifier>doi:10.1145/2998181.2998234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01576</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasi-Recurrent Neural Networks</dc:title>
 <dc:creator>Bradbury, James</dc:creator>
 <dc:creator>Merity, Stephen</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural networks are a powerful tool for modeling sequential data,
but the dependence of each timestep's computation on the previous timestep's
output limits parallelism and makes RNNs unwieldy for very long sequences. We
introduce quasi-recurrent neural networks (QRNNs), an approach to neural
sequence modeling that alternates convolutional layers, which apply in parallel
across timesteps, and a minimalist recurrent pooling function that applies in
parallel across channels. Despite lacking trainable recurrent layers, stacked
QRNNs have better predictive accuracy than stacked LSTMs of the same hidden
size. Due to their increased parallelism, they are up to 16 times faster at
train and test time. Experiments on language modeling, sentiment
classification, and character-level neural machine translation demonstrate
these advantages and underline the viability of QRNNs as a basic building block
for a variety of sequence tasks.
</dc:description>
 <dc:description>Comment: Submitted to conference track at ICLR 2017</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01578</identifier>
 <datestamp>2017-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Architecture Search with Reinforcement Learning</dc:title>
 <dc:creator>Zoph, Barret</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Neural networks are powerful and flexible models that work well for many
difficult learning tasks in image, speech and natural language understanding.
Despite their success, neural networks are still hard to design. In this paper,
we use a recurrent network to generate the model descriptions of neural
networks and train this RNN with reinforcement learning to maximize the
expected accuracy of the generated architectures on a validation set. On the
CIFAR-10 dataset, our method, starting from scratch, can design a novel network
architecture that rivals the best human-invented architecture in terms of test
set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is
0.09 percent better and 1.05x faster than the previous state-of-the-art model
that used a similar architectural scheme. On the Penn Treebank dataset, our
model can compose a novel recurrent cell that outperforms the widely-used LSTM
cell, and other state-of-the-art baselines. Our cell achieves a test set
perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than
the previous state-of-the-art model. The cell can also be transferred to the
character language modeling task on PTB and achieves a state-of-the-art
perplexity of 1.214.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01579</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized Caching and Coded Delivery with Distinct Cache Capacities</dc:title>
 <dc:creator>Amiri, Mohammad Mohammadi</dc:creator>
 <dc:creator>Yang, Qianqian</dc:creator>
 <dc:creator>Gunduz, Deniz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Decentralized proactive caching and coded delivery is studied in a content
delivery network, where each user is equipped with a cache memory, not
necessarily of equal capacity. Cache memories are filled in advance during the
off-peak traffic period in a decentralized manner, i.e., without the knowledge
of the number of active users, their identities, or their particular demands.
User demands are revealed during the peak traffic period, and are served
simultaneously through an error-free shared link. The goal is to find the
minimum delivery rate during the peak traffic period that is sufficient to
satisfy all possible demand combinations. A group-based decentralized caching
and coded delivery scheme is proposed, and it is shown to improve upon the
state-of-the-art in terms of the minimum required delivery rate when there are
more users in the system than files. Numerical results indicate that the
improvement is more significant as the cache capacities of the users become
more skewed. A new lower bound on the delivery rate is also presented, which
provides a tighter bound than the classical cut-set bound.
</dc:description>
 <dc:description>Comment: to appear, IEEE Transactions on Communications</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01582</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Social Communities for Optimizing Cellular Device-to-Device
  Communications</dc:title>
 <dc:creator>Alim, Md Abdul</dc:creator>
 <dc:creator>Pan, Tianyi</dc:creator>
 <dc:creator>Thai, My Tra</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Device-to-device (D2D) communications over licensed wireless spectrum has
been recently proposed as a promising technology to meet the capacity crunch of
next generation cellular networks. However, due to the high mobility of
cellular devices, establishing and ensuring the success of D2D transmission
becomes a major challenge. To this end, in this paper, a novel framework is
proposed to enable devices to form multi-hop D2D connections in an effort to
maintain sustainable communication in the presence of device mobility. To solve
the problem posed by device mobility, in contrast to existing works, which
mostly focus on physical domain information, a durable community based approach
is introduced taking social encounters into context. It is shown that the
proposed scheme can derive an optimal solution for time sensitive content
transmission while also minimizing the cost that the base station pays in order
to incentivize users to participate in D2D. Simulation results show that the
proposed social community aware approach yields significant performance gain,
in terms of the amount of traffic offloaded from the cellular network to the
D2D tier, compared to the classical social-unaware methods.
</dc:description>
 <dc:description>Comment: 34 pages</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01582</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2626280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01584</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Branching Cascaded Regression for Face Alignment under
  Significant Head Rotation</dc:title>
 <dc:creator>Smith, Brandon M.</dc:creator>
 <dc:creator>Dyer, Charles R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite much interest in face alignment in recent years, the large majority
of work has focused on near-frontal faces. Algorithms typically break down on
profile faces, or are too slow for real-time applications. In this work we
propose an efficient approach to face alignment that can handle 180 degrees of
head rotation in a unified way (e.g., without resorting to view-based models)
using 2D training data. The foundation of our approach is cascaded shape
regression (CSR), which has emerged recently as the leading strategy. We
propose a generalization of conventional CSRs that we call branching cascaded
regression (BCR). Conventional CSRs are single-track; that is, they progress
from one cascade level to the next in a straight line, with each regressor
attempting to fit the entire dataset. We instead split the regression problem
into two or more simpler ones after each cascade level. Intuitively, each
regressor can then operate on a simpler objective function (i.e., with fewer
conflicting gradient directions). Within the BCR framework, we model and infer
pose-related landmark visibility and face shape simultaneously using Structured
Point Distribution Models (SPDMs). We propose to learn task-specific feature
mapping functions that are adaptive to landmark visibility, and that use SPDM
parameters as regression targets instead of 2D landmark coordinates.
Additionally, we introduce a new in-the-wild dataset of profile faces to
validate our approach.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01585</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Amplifiers and Suppressors of Selection for the Moran Process on
  Undirected Graphs</dc:title>
 <dc:creator>Giakkoupis, George</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  We consider the classic Moran process modeling the spread of genetic
mutations, as extended to structured populations by Lieberman et al.\ (Nature,
2005). In this process, individuals are the vertices of a connected graph $G$.
Initially, there is a single mutant vertex, chosen uniformly at random. In each
step, a random vertex is selected for reproduction with a probability
proportional to its fitness: mutants have fitness $r&gt;1$, while non-mutants have
fitness 1. The vertex chosen to reproduce places a copy of itself to a
uniformly random neighbor in $G$, replacing the individual that was there. The
process ends when the mutation either reaches fixation (i.e., all vertices are
mutants), or gets extinct. The principal quantity of interest is the
probability with which each of the two outcomes occurs.
  A problem that has received significant attention recently concerns the
existence of families of graphs, called strong amplifiers of selection, for
which the fixation probability tends to 1 as the order $n$ of the graph
increases, and the existence of strong suppressors of selection, for which this
probability tends to 0. For the case of directed graphs, it is known that both
strong amplifiers and suppressors exist. For the case of undirected graphs,
however, the problem has remained open, and the general belief has been that
neither strong amplifiers nor suppressors exist. In this paper we disprove this
belief, by providing the first examples of such graphs. The strong amplifier we
present has fixation probability $1-\tilde O(n^{-1/3})$, and the strong
suppressor has fixation probability $\tilde O(n^{-1/4})$. Both graph
constructions are surprisingly simple. We also prove a general upper bound of
$1-\tilde \Omega(n^{-1/3})$ on the fixation probability of any undirected
graph. Hence, our strong amplifier is existentially optimal.
</dc:description>
 <dc:description>Comment: 27 pages, 2 figures</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01586</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Class-prior Estimation for Learning from Positive and Unlabeled Data</dc:title>
 <dc:creator>Plessis, Marthinus C. du</dc:creator>
 <dc:creator>Niu, Gang</dc:creator>
 <dc:creator>Sugiyama, Masashi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of estimating the class prior in an unlabeled
dataset. Under the assumption that an additional labeled dataset is available,
the class prior can be estimated by fitting a mixture of class-wise data
distributions to the unlabeled data distribution. However, in practice, such an
additional labeled dataset is often not available. In this paper, we show that,
with additional samples coming only from the positive class, the class prior of
the unlabeled dataset can be estimated correctly. Our key idea is to use
properly penalized divergences for model fitting to cancel the error caused by
the absence of negative samples. We further show that the use of the penalized
$L_1$-distance gives a computationally efficient algorithm with an analytic
solution. The consistency, stability, and estimation error are theoretically
analyzed. Finally, we experimentally demonstrate the usefulness of the proposed
method.
</dc:description>
 <dc:description>Comment: To appear in Machine Learning</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01586</dc:identifier>
 <dc:identifier>doi:10.1007/s10994-016-5604-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01587</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks</dc:title>
 <dc:creator>Hashimoto, Kazuma</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Tsuruoka, Yoshimasa</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Transfer and multi-task learning have traditionally focused on either a
single source-target pair or very few, similar tasks. Ideally, the linguistic
levels of morphology, syntax and semantics would benefit each other by being
trained in a single model. We introduce a joint many-task model together with a
strategy for successively growing its depth to solve increasingly complex
tasks. Higher layers include shortcut connections to lower-level task
predictions to reflect linguistic hierarchies. We use a simple regularization
term to allow for optimizing all model weights to improve one task's loss
without exhibiting catastrophic interference of the other tasks. Our single
end-to-end model obtains state-of-the-art or competitive results on five
different tasks from tagging, parsing, relatedness, and entailment tasks.
</dc:description>
 <dc:description>Comment: Accepted as a full paper at the 2017 Conference on Empirical Methods
  in Natural Language Processing (EMNLP 2017)</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01590</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alternating Direction Method of Multipliers for Sparse Convolutional
  Neural Networks</dc:title>
 <dc:creator>Kiaee, Farkhondeh</dc:creator>
 <dc:creator>Gagn&#xe9;, Christian</dc:creator>
 <dc:creator>Abbasi, Mahdieh</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The storage and computation requirements of Convolutional Neural Networks
(CNNs) can be prohibitive for exploiting these models over low-power or
embedded devices. This paper reduces the computational complexity of the CNNs
by minimizing an objective function, including the recognition loss that is
augmented with a sparsity-promoting penalty term. The sparsity structure of the
network is identified using the Alternating Direction Method of Multipliers
(ADMM), which is widely used in large optimization problems. This method
alternates between promoting the sparsity of the network and optimizing the
recognition performance, which allows us to exploit the two-part structure of
the corresponding objective functions. In particular, we take advantage of the
separability of the sparsity-inducing penalty functions to decompose the
minimization problem into sub-problems that can be solved sequentially.
Applying our method to a variety of state-of-the-art CNN models, our proposed
method is able to simplify the original model, generating models with less
computation and fewer parameters, while maintaining and often improving
generalization performance. Accomplishments on a variety of models strongly
verify that our proposed ADMM-based method can be a very useful tool for
simplifying and improving deep CNNs.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2017. arXiv admin note:
  text overlap with arXiv:1111.6188 by other authors</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01594</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MetaFlow: a Scalable Metadata Lookup Service for Distributed File
  Systems in Data Centers</dc:title>
 <dc:creator>Sun, Peng</dc:creator>
 <dc:creator>Wen, Yonggang</dc:creator>
 <dc:creator>Duong, Ta Nguyen Binh</dc:creator>
 <dc:creator>Xie, Haiyong</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In large-scale distributed file systems, efficient meta- data operations are
critical since most file operations have to interact with metadata servers
first. In existing distributed hash table (DHT) based metadata management
systems, the lookup service could be a performance bottleneck due to its
significant CPU overhead. Our investigations showed that the lookup service
could reduce system throughput by up to 70%, and increase system latency by a
factor of up to 8 compared to ideal scenarios. In this paper, we present
MetaFlow, a scalable metadata lookup service utilizing software-defined
networking (SDN) techniques to distribute lookup workload over network
components. MetaFlow tackles the lookup bottleneck problem by leveraging
B-tree, which is constructed over the physical topology, to manage flow tables
for SDN-enabled switches. Therefore, metadata requests can be forwarded to
appropriate servers using only switches. Extensive performance evaluations in
both simulations and testbed showed that MetaFlow increases system throughput
by a factor of up to 3.2, and reduce system latency by a factor of up to 5
compared to DHT-based systems. We also deployed MetaFlow in a distributed file
system, and demonstrated significant performance improvement.
</dc:description>
 <dc:description>Comment: in IEEE Transactions on Big Data 2016</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01594</dc:identifier>
 <dc:identifier>doi:10.1109/TBDATA.2016.2612241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01598</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical scalability assesment for parallel scientific numerical
  applications</dc:title>
 <dc:creator>Perlin, Natalie</dc:creator>
 <dc:creator>Zysman, Joel P.</dc:creator>
 <dc:creator>Kirtman, Ben P.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Atmospheric and Oceanic Physics</dc:subject>
 <dc:subject>B.8.2</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  The concept of scalability analysis of numerical parallel applications has
been revisited, with the specific goals defined for the performance estimation
of research applications. A series of Community Climate Model System (CCSM)
numerical simulations were used to test the several MPI implementations,
determine optimal use of the system resources, and their scalability. The
scaling capacity and model throughput performance metrics for $N$ cores showed
a log-linear behavior approximated by a power fit in the form of $C(N)=bN^a$,
where $a$ and $b$ are two empirical constants. Different metrics yielded
identical power coefficients ($a$), but different dimensionality coefficients
($b$). This model was consistent except for the large numbers of N. The power
fit approach appears to be very useful for scalability estimates, especially
when no serial testing is possible. Scalability analysis of additional
scientific application has been conducted in the similar way to validate the
robustness of the power fit approach.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures, 1 table</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01599</identifier>
 <datestamp>2016-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LipNet: End-to-End Sentence-level Lipreading</dc:title>
 <dc:creator>Assael, Yannis M.</dc:creator>
 <dc:creator>Shillingford, Brendan</dc:creator>
 <dc:creator>Whiteson, Shimon</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Lipreading is the task of decoding text from the movement of a speaker's
mouth. Traditional approaches separated the problem into two stages: designing
or learning visual features, and prediction. More recent deep lipreading
approaches are end-to-end trainable (Wand et al., 2016; Chung &amp; Zisserman,
2016a). However, existing work on models trained end-to-end perform only word
classification, rather than sentence-level sequence prediction. Studies have
shown that human lipreading performance increases for longer words (Easton &amp;
Basala, 1982), indicating the importance of features capturing temporal context
in an ambiguous communication channel. Motivated by this observation, we
present LipNet, a model that maps a variable-length sequence of video frames to
text, making use of spatiotemporal convolutions, a recurrent network, and the
connectionist temporal classification loss, trained entirely end-to-end. To the
best of our knowledge, LipNet is the first end-to-end sentence-level lipreading
model that simultaneously learns spatiotemporal visual features and a sequence
model. On the GRID corpus, LipNet achieves 95.2% accuracy in sentence-level,
overlapped speaker split task, outperforming experienced human lipreaders and
the previous 86.4% word-level state-of-the-art accuracy (Gergen et al., 2016).
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2016-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01600</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loss-aware Binarization of Deep Networks</dc:title>
 <dc:creator>Hou, Lu</dc:creator>
 <dc:creator>Yao, Quanming</dc:creator>
 <dc:creator>Kwok, James T.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural network models, though very powerful and highly successful, are
computationally expensive in terms of space and time. Recently, there have been
a number of attempts on binarizing the network weights and activations. This
greatly reduces the network size, and replaces the underlying multiplications
to additions or even XNOR bit operations. However, existing binarization
schemes are based on simple matrix approximation and ignore the effect of
binarization on the loss. In this paper, we propose a proximal Newton algorithm
with diagonal Hessian approximation that directly minimizes the loss w.r.t. the
binarized weights. The underlying proximal step has an efficient closed-form
solution, and the second-order information can be efficiently obtained from the
second moments already computed by the Adam optimizer. Experiments on both
feedforward and recurrent networks show that the proposed loss-aware
binarization algorithm outperforms existing binarization schemes, and is also
more robust for wide and deep networks.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01603</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Attention Flow for Machine Comprehension</dc:title>
 <dc:creator>Seo, Minjoon</dc:creator>
 <dc:creator>Kembhavi, Aniruddha</dc:creator>
 <dc:creator>Farhadi, Ali</dc:creator>
 <dc:creator>Hajishirzi, Hannaneh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Machine comprehension (MC), answering a query about a given context
paragraph, requires modeling complex interactions between the context and the
query. Recently, attention mechanisms have been successfully extended to MC.
Typically these methods use attention to focus on a small portion of the
context and summarize it with a fixed-size vector, couple attentions
temporally, and/or often form a uni-directional attention. In this paper we
introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage
hierarchical process that represents the context at different levels of
granularity and uses bi-directional attention flow mechanism to obtain a
query-aware context representation without early summarization. Our
experimental evaluations show that our model achieves the state-of-the-art
results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze
test.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01604</identifier>
 <datestamp>2017-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Coattention Networks For Question Answering</dc:title>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Zhong, Victor</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Several deep learning models have been proposed for question answering.
However, due to their single-pass nature, they have no way to recover from
local maxima corresponding to incorrect answers. To address this problem, we
introduce the Dynamic Coattention Network (DCN) for question answering. The DCN
first fuses co-dependent representations of the question and the document in
order to focus on relevant parts of both. Then a dynamic pointing decoder
iterates over potential answer spans. This iterative procedure enables the
model to recover from initial local maxima corresponding to incorrect answers.
On the Stanford question answering dataset, a single DCN model improves the
previous state of the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains
80.4% F1.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures, International Conference on Learning
  Representations 2017</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-02-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01606</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Play in a Day: Faster Deep Reinforcement Learning by
  Optimality Tightening</dc:title>
 <dc:creator>He, Frank S.</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Schwing, Alexander G.</dc:creator>
 <dc:creator>Peng, Jian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a novel training algorithm for reinforcement learning which
combines the strength of deep Q-learning with a constrained optimization
approach to tighten optimality and encourage faster reward propagation. Our
novel technique makes deep reinforcement learning more practical by drastically
reducing the training time. We evaluate the performance of our approach on the
49 games of the challenging Arcade Learning Environment, and report significant
improvements in both training time and accuracy.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01607</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Orthogonal Multiple Access in Multi-Cell Networks: Theory,
  Performance, and Practical Challenges</dc:title>
 <dc:creator>Shin, Wonjae</dc:creator>
 <dc:creator>Vaezi, Mojtaba</dc:creator>
 <dc:creator>Lee, Byungju</dc:creator>
 <dc:creator>Love, David J.</dc:creator>
 <dc:creator>Lee, Jungwoo</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Non-orthogonal multiple access (NOMA) is a potential enabler for the
development of 5G and beyond wireless networks. By allowing multiple users to
share the same time and frequency, NOMA can scale up the number of served
users, increase the spectral efficiency, and improve user-fairness compared to
existing orthogonal multiple access (OMA) techniques. While single-cell NOMA
has drawn significant attention recently, much less attention has been given to
multi-cell NOMA. This article discusses the opportunities and challenges of
NOMA in a multi-cell environment. As the density of base stations and devices
increases, inter-cell interference becomes a major obstacle in multi-cell
networks. As such, identifying techniques that combine interference management
approaches with NOMA is of great significance. After discussing the theory
behind NOMA, this paper provides an overview of the current literature and
discusses key implementation and research challenges, with an emphasis on
multi-cell NOMA.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, Accepted for publication on IEEE Communications
  Magazine</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01626</identifier>
 <datestamp>2017-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining policy gradient and Q-learning</dc:title>
 <dc:creator>O'Donoghue, Brendan</dc:creator>
 <dc:creator>Munos, Remi</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:creator>Mnih, Volodymyr</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Policy gradient is an efficient technique for improving a policy in a
reinforcement learning setting. However, vanilla online variants are on-policy
only and not able to take advantage of off-policy data. In this paper we
describe a new technique that combines policy gradient with off-policy
Q-learning, drawing experience from a replay buffer. This is motivated by
making a connection between the fixed points of the regularized policy gradient
algorithm and the Q-values. This connection allows us to estimate the Q-values
from the action preferences of the policy, to which we apply Q-learning
updates. We refer to the new technique as 'PGQL', for policy gradient and
Q-learning. We also establish an equivalency between action-value fitting
techniques and actor-critic algorithms, showing that regularized policy
gradient techniques can be interpreted as advantage function learning
algorithms. We conclude with some numerical examples that demonstrate improved
data efficiency and stability of PGQL. In particular, we tested PGQL on the
full suite of Atari games and achieved performance exceeding that of both
asynchronous advantage actor-critic (A3C) and Q-learning.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01628</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reference-Aware Language Models</dc:title>
 <dc:creator>Yang, Zichao</dc:creator>
 <dc:creator>Blunsom, Phil</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Ling, Wang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a general class of language models that treat reference as an
explicit stochastic latent variable. This architecture allows models to create
mentions of entities and their attributes by accessing external databases
(required by, e.g., dialogue generation and recipe generation) and internal
state (required by, e.g. language models which are aware of coreference). This
facilitates the incorporation of information that can be accessed in
predictable locations in databases or discourse context, even when the targets
of the reference may be rare words. Experiments on three tasks shows our model
variants based on deterministic attention.
</dc:description>
 <dc:description>Comment: emnlp camera ready</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01629</identifier>
 <datestamp>2017-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the optimal feedforward torque control problem of anisotropic
  synchronous machines: Quadrics, quartics and analytical solutions</dc:title>
 <dc:creator>Eldeeb, Hisham</dc:creator>
 <dc:creator>Hackl, Christoph M.</dc:creator>
 <dc:creator>Horlbeck, Lorenz</dc:creator>
 <dc:creator>Kullick, Julian</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The optimal feedforward torque control problem is tackled and solved
analytically for synchronous machines while stator resistance and
cross-coupling inductance are explicitly considered. Analytical solutions for
the direct and quadrature optimal reference currents are found for all major
operation strategies such as Maximum Torque per Current (MTPC) (or often called
as Maximum Torque per Ampere (MTPA)), Maximum Current (MC), Field Weakening
(FW), Maximum Torque per Voltage (MTPV) and Maximum Torque per Flux (MTPF).
Numerical methods (approximating the optimal solutions only) or simplifying
assumptions (neglecting stator resistance and/or cross-coupling inductance) are
no longer necessary. The presented results are based on one simple idea: all
optimization problems (e.g. MTPC, MTPV or MTPF) with their respective
constraints (e.g. current or voltage limit) and the computation of the
intersection point(s) of voltage ellipse, current circle, or torque, MTPC, MTPV
and MTPF hyperbolas are reformulated implicitly as quadrics (quadratic
surfaces) which allow to solve the feedforward torque control problem by
invoking the Lagrangian formalism and by finding the roots of a fourth-order
polynomial analytically. The proposed solutions are applicable to any
anisotropic (or isotropic) synchronous machine independent of the underlying
current control strategy.
</dc:description>
 <dc:description>Comment: 20 pages, 4 figures</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01639</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robustly representing uncertainty in deep neural networks through
  sampling</dc:title>
 <dc:creator>McClure, Patrick</dc:creator>
 <dc:creator>Kriegeskorte, Nikolaus</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  As deep neural networks (DNNs) are applied to increasingly challenging
problems, they will need to be able to represent their own uncertainty.
Modeling uncertainty is one of the key features of Bayesian methods. Using
Bernoulli dropout with sampling at prediction time has recently been proposed
as an efficient and well performing variational inference method for DNNs.
However, sampling from other multiplicative noise based variational
distributions has not been investigated in depth. We evaluated Bayesian DNNs
trained with Bernoulli or Gaussian multiplicative masking of either the units
(dropout) or the weights (dropconnect). We tested the calibration of the
probabilistic predictions of Bayesian convolutional neural networks (CNNs) on
MNIST and CIFAR-10. Sampling at prediction time increased the calibration of
the DNNs' probabalistic predictions. Sampling weights, whether Gaussian or
Bernoulli, led to more robust representation of uncertainty compared to
sampling of units. However, using either Gaussian or Bernoulli dropout led to
increased test set classification accuracy. Based on these findings we used
both Bernoulli dropout and Gaussian dropconnect concurrently, which we show
approximates the use of a spike-and-slab variational distribution without
increasing the number of learned parameters. We found that spike-and-slab
sampling had higher test set performance than Gaussian dropconnect and more
robustly represented its uncertainty compared to Bernoulli dropout.
</dc:description>
 <dc:description>Comment: Bayesian Deep Learning Workshop (NIPS 2017)</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01640</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Is the Best Practice for CNNs Applied to Visual Instance Retrieval?</dc:title>
 <dc:creator>Hao, Jiedong</dc:creator>
 <dc:creator>Dong, Jing</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Tan, Tieniu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Previous work has shown that feature maps of deep convolutional neural
networks (CNNs) can be interpreted as feature representation of a particular
image region. Features aggregated from these feature maps have been exploited
for image retrieval tasks and achieved state-of-the-art performances in recent
years. The key to the success of such methods is the feature representation.
However, the different factors that impact the effectiveness of features are
still not explored thoroughly. There are much less discussion about the best
combination of them.
  The main contribution of our paper is the thorough evaluations of the various
factors that affect the discriminative ability of the features extracted from
CNNs. Based on the evaluation results, we also identify the best choices for
different factors and propose a new multi-scale image feature representation
method to encode the image effectively. Finally, we show that the proposed
method generalises well and outperforms the state-of-the-art methods on four
typical datasets used for visual instance retrieval.
</dc:description>
 <dc:description>Comment: The verison submitted to ICLR</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01642</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GPU-based Pedestrian Detection for Autonomous Driving</dc:title>
 <dc:creator>Campmany, Victor</dc:creator>
 <dc:creator>Silva, Sergio</dc:creator>
 <dc:creator>Espinosa, Antonio</dc:creator>
 <dc:creator>Moure, Juan Carlos</dc:creator>
 <dc:creator>V&#xe1;zquez, David</dc:creator>
 <dc:creator>L&#xf3;pez, Antonio M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a real-time pedestrian detection system for the embedded Nvidia
Tegra X1 GPU-CPU hybrid platform. The pipeline is composed by the following
state-of-the-art algorithms: Histogram of Local Binary Patterns (LBP) and
Histograms of Oriented Gradients (HOG) features extracted from the input image;
Pyramidal Sliding Window technique for candidate generation; and Support Vector
Machine (SVM) for classification. Results show a 8x speedup in the target Tegra
X1 platform and a better performance/watt ratio than desktop CUDA platforms in
study.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01642</dc:identifier>
 <dc:identifier>International Conference on Computational Science 2016 Volume 80
  Pages 2377 to 2381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01644</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Surviving in Directed Graphs: A Polylogarithmic Approximation for
  Two-Connected Directed Steiner Tree</dc:title>
 <dc:creator>Grandoni, Fabrizio</dc:creator>
 <dc:creator>Laekhanukit, Bundit</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In this paper, we study a survivable network design problem on directed
graphs, 2-Connected Directed Steiner Tree (2-DST): given an $n$-vertex weighted
directed graph, a root $r$, and a set of $h$ terminals $S$, find a min-cost
subgraph $H$ that has two edge/vertex disjoint paths from $r$ to any $t\in S$.
2-DST is a natural generalization of the classical Directed Steiner Tree
problem (DST), where we have an additional requirement that the network must
tolerate one failure. No non-trivial approximation is known for 2-DST. This was
left as an open problem by Feldman et al., [SODA'09; JCSS] and has then been
studied by Cheriyan et al. [SODA'12; TALG] and Laekhanukit SODA'14]. However,
no positive result was known except for the special case of a $D$-shallow
instance [Laekhanukit, ICALP'16].
  We present an $O(D^3\log D\cdot h^{2/D}\cdot \log n)$ approximation algorithm
for 2-DST that runs in time $O(n^{O(D)})$, for any $D\in[\log_2h]$. This
implies a polynomial-time $O(h^\epsilon \log n)$ approximation for any constant
$\epsilon&gt;0$, and a poly-logarithmic approximation running in quasi-polynomial
time. We remark that this is essentially the best-known even for the classical
DST, and the latter problem is $O(\log^{2-\epsilon}n)$-hard to approximate
[Halperin and Krauthgamer, STOC'03]. As a by product, we obtain an algorithm
with the same approximation guarantee for the $2$-Connected Directed Steiner
Subgraph problem, where the goal is to find a min-cost subgraph such that every
pair of terminals are $2$-edge/vertex connected.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01646</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Image Captioning with Attributes</dc:title>
 <dc:creator>Yao, Ting</dc:creator>
 <dc:creator>Pan, Yingwei</dc:creator>
 <dc:creator>Li, Yehao</dc:creator>
 <dc:creator>Qiu, Zhaofan</dc:creator>
 <dc:creator>Mei, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatically describing an image with a natural language has been an
emerging challenge in both fields of computer vision and natural language
processing. In this paper, we present Long Short-Term Memory with Attributes
(LSTM-A) - a novel architecture that integrates attributes into the successful
Convolutional Neural Networks (CNNs) plus Recurrent Neural Networks (RNNs)
image captioning framework, by training them in an end-to-end manner. To
incorporate attributes, we construct variants of architectures by feeding image
representations and attributes into RNNs in different ways to explore the
mutual but also fuzzy relationship between them. Extensive experiments are
conducted on COCO image captioning dataset and our framework achieves superior
results when compared to state-of-the-art deep models. Most remarkably, we
obtain METEOR/CIDEr-D of 25.2%/98.6% on testing data of widely used and
publicly available splits in (Karpathy &amp; Fei-Fei, 2015) when extracting image
representations by GoogleNet and achieve to date top-1 performance on COCO
captioning Leaderboard.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01647</identifier>
 <datestamp>2017-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform Sampling through the Lov\'asz Local Lemma</dc:title>
 <dc:creator>Guo, Heng</dc:creator>
 <dc:creator>Jerrum, Mark</dc:creator>
 <dc:creator>Liu, Jingcheng</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We propose a new algorithmic framework, called &quot;partial rejection sampling&quot;,
to draw samples exactly from a product distribution, conditioned on none of a
number of bad events occurring. Our framework builds (perhaps surprising) new
connections between the variable framework of the Lov\'asz Local Lemma and some
classical sampling algorithms such as the &quot;cycle-popping&quot; algorithm for rooted
spanning trees by Wilson. Among other applications, we discover new algorithms
to sample satisfying assignments of k-CNF formulas with bounded variable
occurrences.
</dc:description>
 <dc:description>Comment: 29 pages. Accepted to STOC 17</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01648</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Remarks on Propositional Logics and the categorial relationship between
  Institutions and {\Pi}-Institutions</dc:title>
 <dc:creator>Pinto, Darllan Concei&#xe7;&#xe3;o</dc:creator>
 <dc:creator>Mariano, Hugo Luiz</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B22, 18C99, 03G99</dc:subject>
 <dc:description>  In this work we explore some applications of the notions of Institution and
{\Pi}-Institution in the setting of propositional logics and establish a
precise categorial relation between these notions, i.e., we provide a pair of
functors that establishes an adjunction between the categories Inst and
{\Pi}-Inst.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01652</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Differentiable Physics Engine for Deep Learning in Robotics</dc:title>
 <dc:creator>Degrave, Jonas</dc:creator>
 <dc:creator>Hermans, Michiel</dc:creator>
 <dc:creator>Dambre, Joni</dc:creator>
 <dc:creator>wyffels, Francis</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  One of the most important fields in robotics is the optimization of
controllers. Currently, robots are treated as a black box in this optimization
process, which is the reason why derivative-free optimization methods such as
evolutionary algorithms or reinforcement learning are omnipresent. We propose
an implementation of a modern physics engine, which has the ability to
differentiate control parameters. This has been implemented on both CPU and
GPU. We show how this speeds up the optimization process, even for small
problems, and why it will scale to bigger problems. We explain why this is an
alternative approach to deep Q-learning, for using deep learning in robotics.
Lastly, we argue that this is a big step for deep learning in robotics, as it
opens up new possibilities to optimize robots, both in hardware and software.
</dc:description>
 <dc:description>Comment: International Conference on Learning Representations 2017</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01655</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Twenty (simple) questions</dc:title>
 <dc:creator>Dagan, Yuval</dc:creator>
 <dc:creator>Filmus, Yuval</dc:creator>
 <dc:creator>Gabizon, Ariel</dc:creator>
 <dc:creator>Moran, Shay</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A basic combinatorial interpretation of Shannon's entropy function is via the
&quot;20 questions&quot; game. This cooperative game is played by two players, Alice and
Bob: Alice picks a distribution $\pi$ over the numbers $\{1,\ldots,n\}$, and
announces it to Bob. She then chooses a number $x$ according to $\pi$, and Bob
attempts to identify $x$ using as few Yes/No queries as possible, on average.
  An optimal strategy for the &quot;20 questions&quot; game is given by a Huffman code
for $\pi$: Bob's questions reveal the codeword for $x$ bit by bit. This
strategy finds $x$ using fewer than $H(\pi)+1$ questions on average. However,
the questions asked by Bob could be arbitrary. In this paper, we investigate
the following question: Are there restricted sets of questions that match the
performance of Huffman codes, either exactly or approximately?
  Our first main result shows that for every distribution $\pi$, Bob has a
strategy that uses only questions of the form &quot;$x &lt; c$?&quot; and &quot;$x = c$?&quot;, and
uncovers $x$ using at most $H(\pi)+1$ questions on average, matching the
performance of Huffman codes in this sense. We also give a natural set of
$O(rn^{1/r})$ questions that achieve a performance of at most $H(\pi)+r$, and
show that $\Omega(rn^{1/r})$ questions are required to achieve such a
guarantee.
  Our second main result gives a set $\mathcal{Q}$ of $1.25^{n+o(n)}$ questions
such that for every distribution $\pi$, Bob can implement an optimal strategy
for $\pi$ using only questions from $\mathcal{Q}$. We also show that
$1.25^{n-o(n)}$ questions are needed, for infinitely many $n$. If we allow a
small slack of $r$ over the optimal strategy, then roughly $(rn)^{\Theta(1/r)}$
questions are necessary and sufficient.
</dc:description>
 <dc:description>Comment: 33 pages; to appear in STOC 2017</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01658</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Citation algorithms for identifying research milestones driving
  biomedical innovation</dc:title>
 <dc:creator>Comins, Jordan A.</dc:creator>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Scientific activity plays a major role in innovation for biomedicine and
healthcare. For instance, fundamental research on disease pathologies and
mechanisms can generate potential targets for drug therapy. This co-evolution
is punctuated by papers which provide new perspectives and open new domains.
Despite the relationship between scientific discovery and biomedical
advancement, identifying these research milestones that truly impact biomedical
innovation can be difficult and is largely based solely on the opinions of
subject matter experts. Here, we consider whether a new class of citation
algorithms that identify seminal scientific works in a field, Reference
Publication Year Spectroscopy (RPYS) and multi-RPYS, can identify the
connections between innovation (e.g. therapeutic treatments) and the
foundational research underlying them. Specifically, we assess whether the
results of these analytic techniques converge with expert opinions on research
milestones driving biomedical innovation in the treatment of Basal Cell
Carcinoma. Our results show that these algorithms successfully identify the
majority of milestone papers detailed by experts (Wong and Dlugosz 2014)
thereby validating the power of these algorithms to converge on independent
opinions of seminal scientific works derived by subject matter experts. These
advances offer an opportunity to identify scientific activities enabling
innovation in biomedicine.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01661</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spanning Trees in Multipartite Geometric Graphs</dc:title>
 <dc:creator>Biniaz, Ahmad</dc:creator>
 <dc:creator>Bose, Prosenjit</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:creator>Maheshwari, Anil</dc:creator>
 <dc:creator>Morin, Pat</dc:creator>
 <dc:creator>Smid, Michiel</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $R$ and $B$ be two disjoint sets of points in the plane where the points
of $R$ are colored red and the points of $B$ are colored blue, and let
$n=|R\cup B|$. A bichromatic spanning tree is a spanning tree in the complete
bipartite geometric graph with bipartition $(R,B)$. The minimum (respectively
maximum) bichromatic spanning tree problem is the problem of computing a
bichromatic spanning tree of minimum (respectively maximum) total edge length.
  1. We present a simple algorithm that solves the minimum bichromatic spanning
tree problem in $O(n\log^3 n)$ time. This algorithm can easily be extended to
solve the maximum bichromatic spanning tree problem within the same time bound.
It also can easily be generalized to multicolored point sets.
  2. We present $\Theta(n\log n)$-time algorithms that solve the minimum and
the maximum bichromatic spanning tree problems.
  3. We extend the bichromatic spanning tree algorithms and solve the
multicolored version of these problems in $O(n\log n\log k)$ time, where $k$ is
the number of different colors (or the size of the multipartition in a complete
multipartite geometric graph).
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01667</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Traversable Fixed Size Small Object Allocator in C++</dc:title>
 <dc:creator>Schuessler, Christian</dc:creator>
 <dc:creator>Gruber, Roland</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  At the allocation and deallocation of small objects with fixed size, the
standard allocator of the runtime system has commonly a worse time performance
compared to allocators adapted for a special application field. We propose a
memory allocator, originally developed for mesh primitives but also usable for
any other small equally sized objects. For a large amount of objects it leads
to better results than allocating data with the C ++new instruction and behaves
nowhere worse. The proposed synchronization approach for this allocator behaves
lock-free in practical scenarios without using machine instructions, such as
compare-and-swap. A traversal structure is integrated requiring less memory
than using containers such as STL-vectors or lists, but with comparable time
performance.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01673</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Multi-Adversarial Networks</dc:title>
 <dc:creator>Durugkar, Ishan</dc:creator>
 <dc:creator>Gemp, Ian</dc:creator>
 <dc:creator>Mahadevan, Sridhar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Generative adversarial networks (GANs) are a framework for producing a
generative model by way of a two-player minimax game. In this paper, we propose
the \emph{Generative Multi-Adversarial Network} (GMAN), a framework that
extends GANs to multiple discriminators. In previous work, the successful
training of GANs requires modifying the minimax objective to accelerate
training early on. In contrast, GMAN can be reliably trained with the original,
untampered objective. We explore a number of design perspectives with the
discriminator role ranging from formidable adversary to forgiving teacher.
Image generation tasks comparing the proposed framework to standard GANs
demonstrate GMAN produces higher quality samples in a fraction of the
iterations when measured by a pairwise GAM-type metric.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper (poster) at ICLR 2017</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01678</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing learning algorithms in neural network for diagnosing
  cardiovascular disease</dc:title>
 <dc:creator>Madani, Mirmorsal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Today data mining techniques are exploited in medical science for diagnosing,
overcoming and treating diseases. Neural network is one of the techniques which
are widely used for diagnosis in medical field. In this article efficiency of
nine algorithms, which are basis of neural network learning in diagnosing
cardiovascular diseases, will be assessed. Algorithms are assessed in terms of
accuracy, sensitivity, transparency, AROC and convergence rate by means of 10
fold cross validation. The results suggest that in training phase, Lonberg-M
algorithm has the best efficiency in terms of all metrics, algorithm OSS has
maximum accuracy in testing phase, algorithm SCG has the maximum transparency
and algorithm CGB has the maximum sensitivity.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01683</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulations for Deep Random Secrecy Protocol</dc:title>
 <dc:creator>de Valroger, Thibault</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present numerical simulations measuring secrecy and efficiency rate of
Perfect Secrecy protocol presented in former article named Perfect Secrecy
under Deep Random assumption. Those simulations specifically measure the
respective error rates of both legitimate partner and eavesdropper experimented
during the exchange of a data flow through the protocol. Those measured error
rates also enable us to estimate a lower bound of the Crytpologic Limit
introduced in article named Perfect Secrecy under Deep Random assumption. We
discuss the variation of the protocol parameters and their impact on the
measured performance.
  V2: simulations corresponding to an updated protocol has been performed and
complemented. Simulated effect of Privacy Amplification is also added.
  V3: a simulation with a flawed error correcting method is removed.
</dc:description>
 <dc:description>Comment: 17 pages. arXiv admin note: text overlap with arXiv:1605.04576</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01688</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oracle-Efficient Online Learning and Auction Design</dc:title>
 <dc:creator>Dud&#xed;k, Miroslav</dc:creator>
 <dc:creator>Haghtalab, Nika</dc:creator>
 <dc:creator>Luo, Haipeng</dc:creator>
 <dc:creator>Schapire, Robert E.</dc:creator>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:creator>Vaughan, Jennifer Wortman</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the design of computationally efficient online learning
algorithms in an adversarial setting in which the learner has access to an
offline optimization oracle. We present an algorithm called Generalized
Follow-the-Perturbed-Leader and provide conditions under which it is
oracle-efficient while achieving vanishing regret. Our results make significant
progress on an open problem raised by Hazan and Koren, who showed that
oracle-efficient algorithms do not exist in general and asked whether one can
identify properties under which oracle-efficient online learning may be
possible.
  Our auction-design framework considers an auctioneer learning an optimal
auction for a sequence of adversarially selected valuations with the goal of
achieving revenue that is almost as good as the optimal auction in hindsight,
among a class of auctions. We give oracle-efficient learning results for: (1)
VCG auctions with bidder-specific reserves in single-parameter settings, (2)
envy-free item pricing in multi-item auctions, and (3) s-level auctions of
Morgenstern and Roughgarden for single-item settings. The last result leads to
an approximation of the overall optimal Myerson auction when bidders'
valuations are drawn according to a fast-mixing Markov process, extending prior
work that only gave such guarantees for the i.i.d. setting.
  Finally, we derive various extensions, including: (1) oracle-efficient
algorithms for the contextual learning setting in which the learner has access
to side information (such as bidder demographics), (2) learning with
approximate oracles such as those based on Maximal-in-Range algorithms, and (3)
no-regret bidding in simultaneous auctions, resolving an open problem of
Daskalakis and Syrgkanis.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01690</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fault-tolerance Linguistic Structure for Distributed Applications</dc:title>
 <dc:creator>De Florio, Vincenzo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The structures for the expression of fault-tolerance provisions into the
application software are the central topic of this dissertation. Structuring
techniques provide means to control complexity, the latter being a relevant
factor for the introduction of design faults. This fact and the ever increasing
complexity of today's distributed software justify the need for simple,
coherent, and effective structures for the expression of fault-tolerance in the
application software. A first contribution of this dissertation is the
definition of a base of structural attributes with which application-level
fault-tolerance structures can be qualitatively assessed and compared with each
other and with respect to the above mentioned need. This result is then used to
provide an elaborated survey of the state-of-the-art of software
fault-tolerance structures. The key contribution of this work is a novel
structuring technique for the expression of the fault-tolerance design concerns
in the application layer of those distributed software systems that are
characterized by soft real-time requirements and with a number of processing
nodes known at compile-time. The main thesis of this dissertation is that this
new structuring technique is capable of exhibiting satisfactory values of the
structural attributes in the domain of soft real-time, distributed and parallel
applications. Following this novel approach, beside the conventional
programming language addressing the functional design concerns, a
special-purpose linguistic structure (the so-called &quot;recovery language&quot;) is
available to address error recovery and reconfiguration. This recovery language
comes into play as soon as an error is detected by an underlying error
detection layer, or when some erroneous condition is signaled by the
application processes.
</dc:description>
 <dc:description>Comment: Doctoral thesis, successfully defended on October 13, 2000</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01696</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>More on Compression and Ranking</dc:title>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:creator>Rubery, Daniel</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We study the role that honesty, selectivity, closure properties,
relativization, and target spaces other than $\Sigma^*$ have in the
recursion-theoretic study of compression and ranking.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01698</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Information Encoding in One Dimensional Time Domain Signals</dc:title>
 <dc:creator>Majumdar, Kaushik</dc:creator>
 <dc:creator>Jayachandran, Srinath</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A one dimensional time domain analog signal s(t) can be visualized as a
trajectory of a moving particle in a force field with one degree of freedom.
Then the power of the particle at point t is P(s(t)) = s&quot;(t)s'(t), which is the
rate at which kinetic energy is dissipated (assuming the mass of the particle
is unit) by the particle in order to create the trajectory or give shape to the
signal. Assuming meaning of the signal or the semantic information is in its
shape, we can say that P(s(t)) is the rate at which kinetic energy of the
particle is dissipated to encode semantic information in s(t) at t. After s(t)
is digitized (to make it s[n]) the discrete form P(s[n]) is valid. Considering
the sign changes of P(s[n]) it has been shown that in the smallest neighborhood
of n, in which n is the middle point, semantic information in s[n] can be
encoded in 13 distinct ways. This list is exhaustive. A deterministic finite
automaton (DFA) has been designed which can accept any finite length digital
signal and therefore collection of all finite length digital signals forms a
regular language. The DFA has been generalized to a weighted finite state
transducer (WFST), which has been used to identify action potentials in a spike
train and also to distinguish two speakers when uttering the same phoneme. It
has been shown that in any analog signal semantic information can be encoded at
a point in the form of the shape of its infinitesimal neighborhood in 17
distinct ways. The list is exhaustive. A new entropy measure called semantic
entropy has been introduced. It has been shown that a signal s(t) is traceable
on a piece of paper or in an oscilloscope, only if s&quot;(t) exists on all but at
most a finite number of points within any finite interval. This is an essential
condition for a signal to be the trajectory of a moving particle.
</dc:description>
 <dc:description>Comment: 11 figures, 3 tables</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01702</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency</dc:title>
 <dc:creator>Dieng, Adji B.</dc:creator>
 <dc:creator>Wang, Chong</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Paisley, John</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose TopicRNN, a recurrent neural network (RNN)-based
language model designed to directly capture the global semantic meaning
relating words in a document via latent topics. Because of their sequential
nature, RNNs are good at capturing the local structure of a word sequence -
both semantic and syntactic - but might face difficulty remembering long-range
dependencies. Intuitively, these long-range dependencies are of semantic
nature. In contrast, latent topic models are able to capture the global
underlying semantic structure of a document but do not account for word
ordering. The proposed TopicRNN model integrates the merits of RNNs and latent
topic models: it captures local (syntactic) dependencies using an RNN and
global (semantic) dependencies using latent topics. Unlike previous work on
contextual RNN language modeling, our model is learned end-to-end. Empirical
results on word prediction show that TopicRNN outperforms existing contextual
RNN baselines. In addition, TopicRNN can be used as an unsupervised feature
extractor for documents. We do this for sentiment analysis on the IMDB movie
review dataset and report an error rate of $6.28\%$. This is comparable to the
state-of-the-art $5.91\%$ resulting from a semi-supervised approach. Finally,
TopicRNN also yields sensible topics, making it a useful alternative to
document models such as latent Dirichlet allocation.
</dc:description>
 <dc:description>Comment: International Conference on Learning Representations</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01704</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Optimized Image Compression</dc:title>
 <dc:creator>Ball&#xe9;, Johannes</dc:creator>
 <dc:creator>Laparra, Valero</dc:creator>
 <dc:creator>Simoncelli, Eero P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We describe an image compression method, consisting of a nonlinear analysis
transformation, a uniform quantizer, and a nonlinear synthesis transformation.
The transforms are constructed in three successive stages of convolutional
linear filters and nonlinear activation functions. Unlike most convolutional
neural networks, the joint nonlinearity is chosen to implement a form of local
gain control, inspired by those used to model biological neurons. Using a
variant of stochastic gradient descent, we jointly optimize the entire model
for rate-distortion performance over a database of training images, introducing
a continuous proxy for the discontinuous loss function arising from the
quantizer. Under certain conditions, the relaxed loss function may be
interpreted as the log likelihood of a generative model, as implemented by a
variational autoencoder. Unlike these models, however, the compression model
must operate at any given point along the rate-distortion curve, as specified
by a trade-off parameter. Across an independent set of test images, we find
that the optimized method generally exhibits better rate-distortion performance
than the standard JPEG and JPEG 2000 compression methods. More importantly, we
observe a dramatic improvement in visual quality for all images at all bit
rates, which is supported by objective quality estimates using MS-SSIM.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01706</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-reducible with easy decision version counting problems admit
  additive error approximation. Connections to counting complexity, exponential
  time complexity, and circuit lower bounds</dc:title>
 <dc:creator>Bakali, Eleni</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the class of counting problems,i.e. functions in $\#$P, which are
self reducible, and have easy decision version, i.e. for every input it is easy
to decide if the value of the function $f(x)$ is zero. For example,
$\#$independent-sets of all sizes, is such a problem, and one of the hardest of
this class, since it is equivalent to $\#$SAT under multiplicative
approximation preserving reductions.
  Using these two powerful properties, self reducibility and easy decision, we
prove that all problems/ functions $f$ in this class can be approximated in
probabilistic polynomial time within an absolute exponential error
$\epsilon\cdot 2^{n'}, \forall\epsilon&gt;0$, which for many of those problems
(when $n'=n+$constant) implies additive approximation to the fraction
$f(x)/2^n$. (Where $n'$ is the amount of non-determinism of some associated
NPTM).
  Moreover we show that for all these problems we can have multiplicative error
to the value $f(x)$, of any desired accuracy (i.e. a RAS), in time of order
$2^{2n'/3}poly(n)$, which is strictly smaller than exhaustive search. We also
show that $f(x)&lt;g(x)$ can be decided deterministically in time $g(x)poly(n),
\forall g$.
  Finally we show that the Circuit Acceptance Probability Problem, which is
related to derandomization and circuit lower bounds, can be solved with high
probability and in polynomial time, for the family of all circuits for which
the problems of counting either satisfying or unsatisfying assignments belong
to TotP (which is the Karp-closure of self reducible problems with easy
decision version).
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01708</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Dependencies in Sparse, Multivariate Databases Using
  Probabilistic Programming and Non-parametric Bayes</dc:title>
 <dc:creator>Saad, Feras</dc:creator>
 <dc:creator>Mansinghka, Vikash</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Datasets with hundreds of variables and many missing values are commonplace.
In this setting, it is both statistically and computationally challenging to
detect true predictive relationships between variables and also to suppress
false positives. This paper proposes an approach that combines probabilistic
programming, information theory, and non-parametric Bayes. It shows how to use
Bayesian non-parametric modeling to (i) build an ensemble of joint probability
models for all the variables; (ii) efficiently detect marginal independencies;
and (iii) estimate the conditional mutual information between arbitrary subsets
of variables, subject to a broad class of constraints. Users can access these
capabilities using BayesDB, a probabilistic programming platform for
probabilistic data analysis, by writing queries in a simple, SQL-like language.
This paper demonstrates empirically that the method can (i) detect
context-specific (in)dependencies on challenging synthetic problems and (ii)
yield improved sensitivity and specificity over baselines from statistics and
machine learning, on a real-world database of over 300 sparsely observed
indicators of macroeconomic development and public health.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01710</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deciding Graph non-Hamiltonicity via a Closure Algorithm</dc:title>
 <dc:creator>Swart, E. R.</dc:creator>
 <dc:creator>Gismondi, S. J.</dc:creator>
 <dc:creator>Swart, N. R.</dc:creator>
 <dc:creator>Bell, C. E.</dc:creator>
 <dc:creator>Lee, A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>05C45 68R10 90C05 90C10</dc:subject>
 <dc:description>  We present a matching and LP based heuristic algorithm that decides graph
non-Hamiltonicity. Each of the $n!$ Hamilton cycles in a complete directed
graph on $n+1$ vertices corresponds with each of the $n!$ $n$-permutation
matrices $P$, such that $p_{u,i}=1$ if and only if the $i^{th}$ arc in a cycle
enters vertex $u$, starting and ending at vertex $n+1$. A graph instance ($G$)
is initially coded as exclusion set $E$, whose members are pairs of components
of $P$, $\{p_{u,i} ,p_{v,i+1}\}, i=1,n-1$, for each arc $(u,v)$ not in $G$. For
each $\{p_{u,i} ,p_{v,i+1}\}\in E$, the set of $P$ satisfying
$p_{u,i}=p_{v,i+1}=1$ correspond with a set of cycles not in $G$. Accounting
for all arcs not in $G$, $E$ codes precisely the set of cycles not in $G$. A
doubly stochastic-like $\mathcal{O}$($n^4$) formulation of the Hamilton cycle
decision problem is then constructed. Each $\{p_{u,i} ,p_{v,j}\}$ is coded as
variable $q_{u,i,v,j}$ such that the set of integer extrema is the set of all
permutations. We model $G$ by setting each $q_{u,i,v,j}=0$ in correspondence
with each $\{p_{u,i} ,p_{v,j}\}\in E$ such that for non-Hamiltonian $G$,
integer solutions cannot exist. We recognize non-Hamiltonicity by iteratively
deducing additional $q_{u,i,v,j}$ that can be set zero and expanding $E$ until
the formulation becomes infeasible, in which case we recognize that no integer
solutions exists i.e. $G$ is decided non-Hamiltonian. Over 100 non-Hamiltonian
graphs (10 through 104 vertices) and 2000 randomized 31 vertex non-Hamiltonian
graphs are tested and correctly decided non-Hamiltonian. For Hamiltonian $G$,
the complement of $E$ provides information about covers of matchings, perhaps
useful in searching for cycles. We also present an example where the algorithm
fails to deduce any integral value for any $q_{u,i,v,j}$ i.e. $G$ is undecided.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01711</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causes for Query Answers from Databases: Datalog Abduction,
  View-Updates, and Integrity Constraints</dc:title>
 <dc:creator>Bertossi, Leopoldo</dc:creator>
 <dc:creator>Salimi, Babak</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Causality has been recently introduced in databases, to model, characterize,
and possibly compute causes for query answers. Connections between QA-causality
and consistency-based diagnosis and database repairs (wrt. integrity constraint
violations) have already been established. In this work we establish precise
connections between QA-causality and both abductive diagnosis and the
view-update problem in databases, allowing us to obtain new algorithmic and
complexity results for QA-causality. We also obtain new results on the
complexity of view-conditioned causality, and investigate the notion of
QA-causality in the presence of integrity constraints, obtaining complexity
results from a connection with view-conditioned causality. The abduction
connection under integrity constraints allows us to obtain algorithmic tools
for QA-causality.
</dc:description>
 <dc:description>Comment: To appear in International Journal of Approximate Reasoning. Extended
  version of &quot;Flairs'16&quot; and &quot;UAI'15 WS on Causality&quot; papers</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01714</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Fine Tuning: A Modular Approach to Learning on Small Data</dc:title>
 <dc:creator>Anderson, Ark</dc:creator>
 <dc:creator>Shaffer, Kyle</dc:creator>
 <dc:creator>Yankov, Artem</dc:creator>
 <dc:creator>Corley, Court D.</dc:creator>
 <dc:creator>Hodas, Nathan O.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we present a technique to train neural network models on small
amounts of data. Current methods for training neural networks on small amounts
of rich data typically rely on strategies such as fine-tuning a pre-trained
neural network or the use of domain-specific hand-engineered features. Here we
take the approach of treating network layers, or entire networks, as modules
and combine pre-trained modules with untrained modules, to learn the shift in
distributions between data sets. The central impact of using a modular approach
comes from adding new representations to a network, as opposed to replacing
representations via fine-tuning. Using this technique, we are able surpass
results using standard fine-tuning transfer learning approaches, and we are
also able to significantly increase performance over such approaches when using
smaller amounts of data.
</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01715</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recover Subjective Quality Scores from Noisy Measurements</dc:title>
 <dc:creator>Li, Zhi</dc:creator>
 <dc:creator>Bampis, Christos G.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Simple quality metrics such as PSNR are known to not correlate well with
subjective quality when tested across a wide spectrum of video content or
quality regime. Recently, efforts have been made in designing objective quality
metrics trained on subjective data (e.g. VMAF), demonstrating better
correlation with video quality perceived by human. Clearly, the accuracy of
such a metric heavily depends on the quality of the subjective data that it is
trained on. In this paper, we propose a new approach to recover subjective
quality scores from noisy raw measurements, using maximum likelihood
estimation, by jointly estimating the subjective quality of impaired videos,
the bias and consistency of test subjects, and the ambiguity of video contents
all together. We also derive closed-from expression for the confidence interval
of each estimate. Compared to previous methods which partially exploit the
subjective information, our approach is able to exploit the information in
full, yielding tighter confidence interval and better handling of outliers
without the need for z-scoring or subject rejection. It also handles missing
data more gracefully. Finally, as side information, it provides interesting
insights on the test subjects and video contents.
</dc:description>
 <dc:description>Comment: 16 pages; abridged version appeared in Data Compression Conference
  (DCC) 2017</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01722</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Draw Samples: With Application to Amortized MLE for
  Generative Adversarial Learning</dc:title>
 <dc:creator>Wang, Dilin</dc:creator>
 <dc:creator>Liu, Qiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a simple algorithm to train stochastic neural networks to draw
samples from given target distributions for probabilistic inference. Our method
is based on iteratively adjusting the neural network parameters so that the
output changes along a Stein variational gradient that maximumly decreases the
KL divergence with the target distribution. Our method works for any target
distribution specified by their unnormalized density function, and can train
any black-box architectures that are differentiable in terms of the parameters
we want to adapt. As an application of our method, we propose an amortized MLE
algorithm for training deep energy model, where a neural sampler is adaptively
trained to approximate the likelihood function. Our method mimics an
adversarial game between the deep energy model and the neural sampler, and
obtains realistic-looking images competitive with the state-of-the-art results.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01724</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Words or Characters? Fine-grained Gating for Reading Comprehension</dc:title>
 <dc:creator>Yang, Zhilin</dc:creator>
 <dc:creator>Dhingra, Bhuwan</dc:creator>
 <dc:creator>Yuan, Ye</dc:creator>
 <dc:creator>Hu, Junjie</dc:creator>
 <dc:creator>Cohen, William W.</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Previous work combines word-level and character-level representations using
concatenation or scalar weighting, which is suboptimal for high-level tasks
like reading comprehension. We present a fine-grained gating mechanism to
dynamically combine word-level and character-level representations based on
properties of the words. We also extend the idea of fine-grained gating to
modeling the interaction between questions and paragraphs for reading
comprehension. Experiments show that our approach can improve the performance
on reading comprehension tasks, achieving new state-of-the-art results on the
Children's Book Test dataset. To demonstrate the generality of our gating
mechanism, we also show improved results on a social media tag prediction task.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01726</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSTM-Based System-Call Language Modeling and Robust Ensemble Method for
  Designing Host-Based Intrusion Detection Systems</dc:title>
 <dc:creator>Kim, Gyuwan</dc:creator>
 <dc:creator>Yi, Hayoon</dc:creator>
 <dc:creator>Lee, Jangho</dc:creator>
 <dc:creator>Paek, Yunheung</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In computer security, designing a robust intrusion detection system is one of
the most fundamental and important problems. In this paper, we propose a
system-call language-modeling approach for designing anomaly-based host
intrusion detection systems. To remedy the issue of high false-alarm rates
commonly arising in conventional methods, we employ a novel ensemble method
that blends multiple thresholding classifiers into a single one, making it
possible to accumulate 'highly normal' sequences. The proposed system-call
language model has various advantages leveraged by the fact that it can learn
the semantic meaning and interactions of each system call that existing methods
cannot effectively consider. Through diverse experiments on public benchmark
datasets, we demonstrate the validity and effectiveness of the proposed method.
Moreover, we show that our model possesses high portability, which is one of
the key aspects of realizing successful intrusion detection systems.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01729</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Replica Server Placement Algorithms for Content Delivery
  Networks</dc:title>
 <dc:creator>Sahoo, Jagruti</dc:creator>
 <dc:creator>Salahuddin, Mohammad A.</dc:creator>
 <dc:creator>Glitho, Roch</dc:creator>
 <dc:creator>Elbiaze, Halima</dc:creator>
 <dc:creator>Ajib, Wessam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Content Delivery Networks (CDNs) have gained immense popularity over the
years. Replica server placement is a key design issue in CDNs. It entails
placing replica servers at meticulous locations, such that cost is minimized
and Quality of Service (QoS) of end-users is satisfied. Many replica server
placement models have been proposed in the literature of traditional CDN. As
the CDN architecture is evolving through the adoption of emerging paradigms,
such as, cloud computing and Network Functions Virtualization (NFV), new
algorithms are being proposed. In this paper, we present a comprehensive survey
of replica server placement algorithms in traditional and emerging paradigm
based CDNs. We categorize the algorithms and provide a summary of their
characteristics. Besides, we identify requirements for an efficient replica
server placement algorithm and perform a comparison in the light of the
requirements. Finally, we discuss potential avenues for further research in
replica server placement in CDNs.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Communications Surveys and Tutorials</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01730</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Validation of Tsallis Entropy In Inter-Modality Neuroimage Registration</dc:title>
 <dc:creator>Amaral-Silva, Henrique Tomaz</dc:creator>
 <dc:creator>Murta-Jr, Luiz Otavio</dc:creator>
 <dc:creator>de Azevedo-Marques, Paulo Mazzoncini</dc:creator>
 <dc:creator>Wichert-Ana, Lauro</dc:creator>
 <dc:creator>Prasath, V. B. Surya</dc:creator>
 <dc:creator>Studholme, Colin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Medical image registration plays an important role in determining topographic
and morphological changes for functional diagnostic and therapeutic purposes.
Manual alignment and semi-automated software still have been used; however they
are subjective and make specialists spend precious time. Fully automated
methods are faster and user-independent, but the critical point is registration
reliability. Similarity measurement using Mutual Information (MI) with Shannon
entropy (MIS) is the most common automated method that is being currently
applied in medical images, although more reliable algorithms have been proposed
over the last decade, suggesting improvements and different entropies; such as
Studholme et al, (1999), who demonstrated that the normalization of Mutual
Information (NMI) provides an invariant entropy measure for 3D medical image
registration. In this paper, we described a set of experiments to evaluate the
applicability of Tsallis entropy in the Mutual Information (MIT) and in the
Normalized Mutual Information (NMIT) as cost functions for Magnetic Resonance
Imaging (MRI), Positron Emission Tomography (PET) and Computed Tomography (CT)
exams registration. The effect of changing overlap in a simple image model and
clinical experiments on current entropies (Entropy Correlation Coefficient -
ECC, MIS and NMI) and the proposed ones (MIT and NMT) showed NMI and NMIT with
Tsallis parameter close to 1 as the best options (confidence and accuracy) for
CT to MRI and PET to MRI automatic neuroimaging registration.
</dc:description>
 <dc:description>Comment: 15 pages, 11 figures, 2 tables</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01731</identifier>
 <datestamp>2017-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Label Distribution Learning with Label Ambiguity</dc:title>
 <dc:creator>Gao, Bin-Bin</dc:creator>
 <dc:creator>Xing, Chao</dc:creator>
 <dc:creator>Xie, Chen-Wei</dc:creator>
 <dc:creator>Wu, Jianxin</dc:creator>
 <dc:creator>Geng, Xin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (ConvNets) have achieved excellent recognition
performance in various visual recognition tasks. A large labeled training set
is one of the most important factors for its success. However, it is difficult
to collect sufficient training images with precise labels in some domains such
as apparent age estimation, head pose estimation, multi-label classification
and semantic segmentation. Fortunately, there is ambiguous information among
labels, which makes these tasks different from traditional classification.
Based on this observation, we convert the label of each image into a discrete
label distribution, and learn the label distribution by minimizing a
Kullback-Leibler divergence between the predicted and ground-truth label
distributions using deep ConvNets. The proposed DLDL (Deep Label Distribution
Learning) method effectively utilizes the label ambiguity in both feature
learning and classifier learning, which help prevent the network from
over-fitting even when the training set is small. Experimental results show
that the proposed approach produces significantly better results than
state-of-the-art methods for age estimation and head pose estimation. At the
same time, it also improves recognition performance for multi-label
classification and semantic segmentation tasks.
</dc:description>
 <dc:description>Comment: Accepted by IEEE TIP 2017. Projects page, see
  http://lamda.nju.edu.cn/gaobb/projects/DLDL.html</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01731</dc:identifier>
 <dc:identifier>IEEE Transactions on Image Processing 26(6), 2017:2825-2838</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2689998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01732</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite-Time Elimination of Disagreement of Opinion Dynamics via Covert
  Noise</dc:title>
 <dc:creator>Su, Wei</dc:creator>
 <dc:creator>Chen, Ge</dc:creator>
 <dc:creator>Yu, Yongguang</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  Eliminating disagreement in a group is usually beneficial to the social
stability. In this paper, using the well-known Hegselmann-Krause (HK) model, we
design a quite simple strategy that could resolve the opinion difference of the
system in finite time and induce the opinions synchronized to a targeted value.
To be specific, we intentionally introduce weak random noise to only one agent
to affect its opinion in the evolution and also a leader agent with fixed
opinion in a divisive group, then strictly prove that the disagreement is
finally eliminated and the opinions get synchronized to the leader's opinion in
finite time. Other than that, we calculate the finite stopping time when the
opinions synchronously reach the objective opinion value, which could provide
further guide for designing more efficient noise intervention strategy.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01734</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Biaffine Attention for Neural Dependency Parsing</dc:title>
 <dc:creator>Dozat, Timothy</dc:creator>
 <dc:creator>Manning, Christopher D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper builds off recent work from Kiperwasser &amp; Goldberg (2016) using
neural attention in a simple graph-based dependency parser. We use a larger but
more thoroughly regularized parser than other recent BiLSTM-based approaches,
with biaffine classifiers to predict arcs and labels. Our parser gets state of
the art or near state of the art performance on standard treebanks for six
different languages, achieving 95.7% UAS and 94.1% LAS on the most popular
English PTB dataset. This makes it the highest-performing graph-based parser on
this benchmark---outperforming Kiperwasser Goldberg (2016) by 1.8% and
2.2%---and comparable to the highest performing transition-based parser
(Kuncoro et al., 2016), which achieves 95.8% UAS and 94.6% LAS. We also show
which hyperparameter choices had a significant effect on parsing accuracy,
allowing us to achieve large gains over other graph-based approaches.
</dc:description>
 <dc:description>Comment: Accepted to ICLR 2017; updated with new results and comparison to
  more recent models, including current state-of-the-art</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01742</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytical Derivation of Downlink Data Rate Distribution for 5G HetNets
  with Cell-Edge Located Small Cells</dc:title>
 <dc:creator>Yenihayat, G&#xfc;ven</dc:creator>
 <dc:creator>Kara&#x15f;an, Ezhan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In HetNets, time/frequency resources should be partitioned intelligently in
order to minimize the interference among the users. In this paper, the
probability distributions of per user downlink Data Rate, Spectral Efficiency
(SE) and Energy Efficiency (EE) are analytically derived for a HetNet model
with cell-edge located small cells. The high accuracy of analytically derived
CDFs have been verified by the distributions obtained via simulations. CDF
expressions have then been employed in order to optimize Key Parameter
Indicators (KPI) which are selected here as $10^{th}$ percentile downlink user
Data Rate ($R_{10}$), Spectral Efficiency ($SE_{10}$) and Energy Efficiency
($EE_{10}$).
  In addition to optimizing KPIs separately, employing the analytically derived
distributions, we have also investigated the variation of the KPIs with respect
to each other. The results have shown that the resource allocation parameter
values maximizing $R_{10}$ is very close to the values that maximize $SE_{10}$.
However, the values that are optimal for $SE_{10}$ and $R_{10}$, are not
optimal for $EE_{10}$, which demonstrates the EE and SE trade-off in HetNets.
We have also proposed a metric, $\theta$, aiming to jointly optimize SE and EE.
The results have shown the value of resource sharing parameter optimizing
$\theta$ is closer to the value that maximizes SE. This result shows that SE is
more critical in SE-EE trade-off.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01747</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Compare-Aggregate Model for Matching Text Sequences</dc:title>
 <dc:creator>Wang, Shuohang</dc:creator>
 <dc:creator>Jiang, Jing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Many NLP tasks including machine comprehension, answer selection and text
entailment require the comparison between sequences. Matching the important
units between sequences is a key to solve these problems. In this paper, we
present a general &quot;compare-aggregate&quot; framework that performs word-level
matching followed by aggregation using Convolutional Neural Networks. We
particularly focus on the different comparison functions we can use to match
two vectors. We use four different datasets to evaluate the model. We find that
some simple comparison functions based on element-wise operations can work
better than standard neural network and neural tensor network.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01751</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Convolutional Neural Network Features and the Original Image</dc:title>
 <dc:creator>Parde, Connor J.</dc:creator>
 <dc:creator>Castillo, Carlos</dc:creator>
 <dc:creator>Hill, Matthew Q.</dc:creator>
 <dc:creator>Colon, Y. Ivette</dc:creator>
 <dc:creator>Sankaranarayanan, Swami</dc:creator>
 <dc:creator>Chen, Jun-Cheng</dc:creator>
 <dc:creator>O'Toole, Alice J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face recognition algorithms based on deep convolutional neural networks
(DCNNs) have made progress on the task of recognizing faces in unconstrained
viewing conditions. These networks operate with compact feature-based face
representations derived from learning a very large number of face images. While
the learned features produced by DCNNs can be highly robust to changes in
viewpoint, illumination, and appearance, little is known about the nature of
the face code that emerges at the top level of such networks. We analyzed the
DCNN features produced by two face recognition algorithms. In the first set of
experiments we used the top-level features from the DCNNs as input into linear
classifiers aimed at predicting metadata about the images. The results show
that the DCNN features contain surprisingly accurate information about the yaw
and pitch of a face, and about whether the face came from a still image or a
video frame. In the second set of experiments, we measured the extent to which
individual DCNN features operated in a view-dependent or view-invariant manner.
We found that view-dependent coding was a characteristic of the identities
rather than the DCNN features - with some identities coded consistently in a
view-dependent way and others in a view-independent way. In our third analysis,
we visualized the DCNN feature space for over 24,000 images of 500 identities.
Images in the center of the space were uniformly of low quality (e.g., extreme
views, face occlusion, low resolution). Image quality increased monotonically
as a function of distance from the origin. This result suggests that image
quality information is available in the DCNN features, such that consistently
average feature values reflect coding failures that reliably indicate poor or
unusable images. Combined, the results offer insight into the coding mechanisms
that support robust representation of faces in DCNNs.
</dc:description>
 <dc:description>Comment: Submitted to Face and Gesture Conference, 2017</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01752</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Static Analyzer from Data</dc:title>
 <dc:creator>Bielik, Pavol</dc:creator>
 <dc:creator>Raychev, Veselin</dc:creator>
 <dc:creator>Vechev, Martin</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  To be practically useful, modern static analyzers must precisely model the
effect of both, statements in the programming language as well as frameworks
used by the program under analysis. While important, manually addressing these
challenges is difficult for at least two reasons: (i) the effects on the
overall analysis can be non-trivial, and (ii) as the size and complexity of
modern libraries increase, so is the number of cases the analysis must handle.
  In this paper we present a new, automated approach for creating static
analyzers: instead of manually providing the various inference rules of the
analyzer, the key idea is to learn these rules from a dataset of programs. Our
method consists of two ingredients: (i) a synthesis algorithm capable of
learning a candidate analyzer from a given dataset, and (ii) a counter-example
guided learning procedure which generates new programs beyond those in the
initial dataset, critical for discovering corner cases and ensuring the learned
analysis generalizes to unseen programs.
  We implemented and instantiated our approach to the task of learning
JavaScript static analysis rules for a subset of points-to analysis and for
allocation sites analysis. These are challenging yet important problems that
have received significant research attention. We show that our approach is
effective: our system automatically discovered practical and useful inference
rules for many cases that are tricky to manually identify and are missed by
state-of-the-art, manually tuned analyzers.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01754</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forensics in Industrial Control System: A Case Study</dc:title>
 <dc:creator>Van Vliet, Pieter</dc:creator>
 <dc:creator>Kechadi, M-T.</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Industrial Control Systems (ICS) are used worldwide in critical
infrastructures. An ICS system can be a single embedded system working
stand-alone for controlling a simple process or ICS can also be a very complex
Distributed Control System (DCS) connected to Supervisory Control And Data
Acquisition (SCADA) system(s) in a nuclear power plant. Although ICS are widely
used to-day, there are very little research on the forensic acquisition and
analyze ICS artefacts. In this paper we present a case study of forensics in
ICS where we de-scribe a method of safeguarding important volatile artefacts
from an embedded industrial control system and several other sources
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01761</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Fidelity Model Order Reduction for Microgrids Stability Assessment</dc:title>
 <dc:creator>Vorobev, Petr</dc:creator>
 <dc:creator>Huang, Po-Hsu</dc:creator>
 <dc:creator>Hosani, Mohamed Al</dc:creator>
 <dc:creator>Kirtley, James L.</dc:creator>
 <dc:creator>Turitsyn, Konstantin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Proper modeling of inverter-based microgrids is crucial for accurate
assessment of stability boundaries. It has been recently realized that the
stability conditions for such microgrids are significantly different from those
known for large- scale power systems. While detailed models are available, they
are both computationally expensive and can not provide the insight into the
instability mechanisms and factors. In this paper, a computationally efficient
and accurate reduced-order model is proposed for modeling the inverter-based
microgrids. The main factors affecting microgrid stability are analyzed using
the developed reduced-order model and are shown to be unique for the
microgrid-based network, which has no direct analogy to large-scale power
systems. Particularly, it has been discovered that the stability limits for the
conventional droop-based system (omega - P/V - Q) are determined by the ratio
of inverter rating to network capacity, leading to a smaller stability region
for microgrids with shorter lines. The theoretical derivation has been provided
to verify the above investigation based on both the simplified and generalized
network configurations. More impor- tantly, the proposed reduced-order model
not only maintains the modeling accuracy but also enhances the computation
efficiency. Finally, the results are verified with the detailed model via both
frequency and time domain analyses.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01765</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on 3D CAD model quality assurance and testing tools</dc:title>
 <dc:creator>Gonz&#xe1;lez-Lluch, C.</dc:creator>
 <dc:creator>Company, P.</dc:creator>
 <dc:creator>Contero, M.</dc:creator>
 <dc:creator>Camba, J. D.</dc:creator>
 <dc:creator>Plumed, R.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>J.6</dc:subject>
 <dc:description>  A new taxonomy of issues related to CAD model quality is presented, which
distinguishes between explicit and procedural models. For each type of model,
morphologic, syntactic, and semantic errors are characterized. The taxonomy was
validated successfully when used to classify quality testing tools, which are
aimed at detecting and repairing data errors that may affect the
simplification, interoperability, and reusability of CAD models. The study
shows that low semantic level errors that hamper simplification are reasonably
covered in explicit representations, although many CAD quality testers are
still unaffordable for Small and Medium Enterprises, both in terms of cost and
training time. Interoperability has been reasonably solved by standards like
STEP AP 203 and AP214, but model reusability is not feasible in explicit
representations. Procedural representations are promising, as interactive
modeling editors automatically prevent most morphologic errors derived from
unsuitable modeling strategies. Interoperability problems between procedural
representations are expected to decrease dramatically with STEP AP242. Higher
semantic aspects of quality such as assurance of design intent, however, are
hardly supported by current CAD quality testers.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01765</dc:identifier>
 <dc:identifier>doi:10.1016/j.cad.2016.10.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01769</identifier>
 <datestamp>2017-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LZ-End Parsing in Compressed Space</dc:title>
 <dc:creator>Kempa, Dominik</dc:creator>
 <dc:creator>Kosolobov, Dmitry</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present an algorithm that constructs the LZ-End parsing (a variation of
LZ77) of a given string of length $n$ in $O(n\log\ell)$ expected time and $O(z
+ \ell)$ space, where $z$ is the number of phrases in the parsing and $\ell$ is
the length of the longest phrase. As an option, we can fix $\ell$ (e.g., to the
size of RAM) thus obtaining a reasonable LZ-End approximation with the same
functionality and the length of phrases restricted by $\ell$. This modified
algorithm constructs the parsing in streaming fashion in one left to right pass
on the input string w.h.p. and performs one right to left pass to verify the
correctness of the result. Experimentally comparing this version to other
LZ77-based analogs, we show that it is of practical interest.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figure</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01773</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Shallow End: Empowering Shallower Deep-Convolutional Networks
  through Auxiliary Outputs</dc:title>
 <dc:creator>Guo, Yong</dc:creator>
 <dc:creator>Tan, Mingkui</dc:creator>
 <dc:creator>Wu, Qingyao</dc:creator>
 <dc:creator>Chen, Jian</dc:creator>
 <dc:creator>Hengel, Anton Van Den</dc:creator>
 <dc:creator>Shi, Qinfeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The depth is one of the key factors behind the great success of convolutional
neural networks (CNNs), with the gradient vanishing issue having been largely
addressed by various nets, e.g. ResNet. However, when the depth goes very deep,
the supervision information from the loss function will vanish due to the long
backpropagation path, especially for those shallow layers. This means that
intermediate layers receive less supervision information and will lead to
redundancy in models. As a result, the model becomes very redundant and the
over-fitting issue may happen. To address this, we propose a model, called
AuxNet, by introducing auxiliary outputs at intermediate layers. Different from
existing approaches, we propose a Multi-path training method to propagate not
only gradients but also sufficient supervision
informationfrommultipleauxiliaryoutputs.
TheproposedAuxNetwithmulti-pathtrainingmethodgivesrisetomorecompact networks
which outperform their very deep equivalent (i.e. ResNet). For example, AuxNet
with 44 layers performs better than the ResNet equivalent with 110 layers on
several benchmark data sets, i.e. CIFAR-10, CIFAR-100 and SVHN.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-04-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01778</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simpler and Faster Strongly Polynomial Algorithm for Generalized Flow
  Maximization</dc:title>
 <dc:creator>Olver, Neil</dc:creator>
 <dc:creator>V&#xe9;gh, L&#xe1;szl&#xf3; A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We present a new strongly polynomial algorithm for generalized flow
maximization. The first strongly polynomial algorithm for this problem was
given in [V\'egh16]; our new algorithm is much simpler, and much faster. The
complexity bound $O((m+n\log n)mn\log (n^2/m))$ improves on the previous
estimate in [V\'egh16] by almost a factor $O(n^2)$. Even for small numerical
parameter values, our algorithm is essentially as fast as the best weakly
polynomial algorithms. The key new technical idea is relaxing primal
feasibility conditions. This allows us to work almost exclusively with integral
flows, in contrast to all previous algorithms for the problem.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01779</identifier>
 <datestamp>2017-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Act by Predicting the Future</dc:title>
 <dc:creator>Dosovitskiy, Alexey</dc:creator>
 <dc:creator>Koltun, Vladlen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an approach to sensorimotor control in immersive environments. Our
approach utilizes a high-dimensional sensory stream and a lower-dimensional
measurement stream. The cotemporal structure of these streams provides a rich
supervisory signal, which enables training a sensorimotor control model by
interacting with the environment. The model is trained using supervised
learning techniques, but without extraneous supervision. It learns to act based
on raw sensory input from a complex three-dimensional environment. The
presented formulation enables learning without a fixed goal at training time,
and pursuing dynamically changing goals at test time. We conduct extensive
experiments in three-dimensional simulations based on the classical
first-person game Doom. The results demonstrate that the presented approach
outperforms sophisticated prior formulations, particularly on challenging
tasks. The results also show that trained models successfully generalize across
environments and goals. A model trained using the presented approach won the
Full Deathmatch track of the Visual Doom AI Competition, which was held in
previously unseen environments.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01783</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain Adaptation For Formant Estimation Using Deep Learning</dc:title>
 <dc:creator>Dissen, Yehoshua</dc:creator>
 <dc:creator>Keshet, Joseph</dc:creator>
 <dc:creator>Goldberger, Jacob</dc:creator>
 <dc:creator>Clopper, Cynthia</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In this paper we present a domain adaptation technique for formant estimation
using a deep network. We first train a deep learning network on a small read
speech dataset. We then freeze the parameters of the trained network and use
several different datasets to train an adaptation layer that makes the obtained
network universal in the sense that it works well for a variety of speakers and
speech domains with very different characteristics. We evaluated our adapted
network on three datasets, each of which has different speaker characteristics
and speech styles. The performance of our method compares favorably with
alternative methods for formant estimation.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01786</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Resource Allocation for Multi-User Mobile Edge
  Computing</dc:title>
 <dc:creator>Guo, Junfeng</dc:creator>
 <dc:creator>Song, Zhaozhe</dc:creator>
 <dc:creator>Cui, Ying</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To increase mobile batteries' lifetime and improve quality of experience for
computation-intensive and latency-sensitive applications, mobile edge computing
has received significant interest. Designing energy-efficient mobile edge
computing systems requires joint optimization of communication and computation
resources. In this paper, we consider energy-efficient resource allocation for
a multi-user mobile edge computing system. First, we establish on two
computation-efficient models with negligible and non-negligible base station
(BS) executing durations, respectively. Then, under each model, we formulate
the overall weighted sum energy consumption minimization problem by optimally
allocating communication and computation resources. The optimization problem
for negligible BS executing duration is convex, and we obtain the optimal
solution in closed-form to this problem. The optimization problem for
non-negligible BS executing duration is NP-hard in general, and we obtain a
sub-optimal solution with low-complexity to this problem, by connecting it to a
three-stage flow-shop scheduling problem and wisely utilizing Johnson's
algorithm. Finally, numerical results show that the proposed solutions
outperform some baseline schemes.
</dc:description>
 <dc:description>Comment: submitted to ICC 2017</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01787</identifier>
 <datestamp>2017-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to superoptimize programs</dc:title>
 <dc:creator>Bunel, Rudy</dc:creator>
 <dc:creator>Desmaison, Alban</dc:creator>
 <dc:creator>Kumar, M. Pawan</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Code super-optimization is the task of transforming any given program to a
more efficient version while preserving its input-output behaviour. In some
sense, it is similar to the paraphrase problem from natural language processing
where the intention is to change the syntax of an utterance without changing
its semantics. Code-optimization has been the subject of years of research that
has resulted in the development of rule-based transformation strategies that
are used by compilers. More recently, however, a class of stochastic search
based methods have been shown to outperform these strategies. This approach
involves repeated sampling of modifications to the program from a proposal
distribution, which are accepted or rejected based on whether they preserve
correctness, and the improvement they achieve. These methods, however, neither
learn from past behaviour nor do they try to leverage the semantics of the
program under consideration. Motivated by this observation, we present a novel
learning based approach for code super-optimization. Intuitively, our method
works by learning the proposal distribution using unbiased estimators of the
gradient of the expected improvement. Experiments on benchmarks comprising of
automatically generated as well as existing (&quot;Hacker's Delight&quot;) programs show
that the proposed method is able to significantly outperform state of the art
approaches for code super-optimization.
</dc:description>
 <dc:description>Comment: Accepted to ICLR 2017</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01796</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular Multitask Reinforcement Learning with Policy Sketches</dc:title>
 <dc:creator>Andreas, Jacob</dc:creator>
 <dc:creator>Klein, Dan</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We describe a framework for multitask deep reinforcement learning guided by
policy sketches. Sketches annotate tasks with sequences of named subtasks,
providing information about high-level structural relationships among tasks but
not how to implement them---specifically not providing the detailed guidance
used by much previous work on learning policy abstractions for RL (e.g.
intermediate rewards, subtask completion signals, or intrinsic motivations). To
learn from sketches, we present a model that associates every subtask with a
modular subpolicy, and jointly maximizes reward over full task-specific
policies by tying parameters across shared subpolicies. Optimization is
accomplished via a decoupled actor--critic training objective that facilitates
learning common behaviors from multiple dissimilar reward functions. We
evaluate the effectiveness of our approach in three environments featuring both
discrete and continuous control, and with sparse rewards that can be obtained
only after completing a number of high-level subgoals. Experiments show that
using our approach to learn policies guided by sketches gives better
performance than existing techniques for learning task-specific or shared
policies, while naturally inducing a library of interpretable primitive
behaviors that can be recombined to rapidly adapt to new tasks.
</dc:description>
 <dc:description>Comment: To appear at ICML 2017</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01799</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Adversarial Networks as Variational Training of Energy Based
  Models</dc:title>
 <dc:creator>Zhai, Shuangfei</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Feris, Rogerio</dc:creator>
 <dc:creator>Zhang, Zhongfei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we study deep generative models for effective unsupervised
learning. We propose VGAN, which works by minimizing a variational lower bound
of the negative log likelihood (NLL) of an energy based model (EBM), where the
model density $p(\mathbf{x})$ is approximated by a variational distribution
$q(\mathbf{x})$ that is easy to sample from. The training of VGAN takes a two
step procedure: given $p(\mathbf{x})$, $q(\mathbf{x})$ is updated to maximize
the lower bound; $p(\mathbf{x})$ is then updated one step with samples drawn
from $q(\mathbf{x})$ to decrease the lower bound. VGAN is inspired by the
generative adversarial networks (GANs), where $p(\mathbf{x})$ corresponds to
the discriminator and $q(\mathbf{x})$ corresponds to the generator, but with
several notable differences. We hence name our model variational GANs (VGANs).
VGAN provides a practical solution to training deep EBMs in high dimensional
space, by eliminating the need of MCMC sampling. From this view, we are also
able to identify causes to the difficulty of training GANs and propose viable
solutions. \footnote{Experimental code is available at
https://github.com/Shuangfei/vgan}
</dc:description>
 <dc:description>Comment: Under review at ICLR 2017</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01801</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Activity Recognition Based on Micro-Doppler Signature with In-Home Wi-Fi</dc:title>
 <dc:creator>Chen, Qingchao</dc:creator>
 <dc:creator>Tan, Bo</dc:creator>
 <dc:creator>Chetty, Kevin</dc:creator>
 <dc:creator>Woodbridge, Karl</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Device free activity recognition and monitoring has become a promising
research area with increasing public interest in pattern of life monitoring and
chronic health conditions. This paper proposes a novel framework for in-home
Wi-Fi signal-based activity recognition in e-healthcare applications using
passive micro-Doppler (m-D) signature classification. The framework includes
signal modeling, Doppler extraction and m-D classification. A data collection
campaign was designed to verify the framework where six m-D signatures
corresponding to typical daily activities are sucessfully detected and
classified using our software defined radio (SDR) demo system. Analysis of the
data focussed on potential discriminative characteristics, such as maximum
Doppler frequency and time duration of activity. Finally, a sparsity induced
classifier is applied for adaptting the method in healthcare application
scenarios and the results are compared with those from the well-known Support
Vector Machine (SVM) method.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01802</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Wiring Question Answering Systems</dc:title>
 <dc:creator>Usbeck, Ricardo</dc:creator>
 <dc:creator>Huthmann, Jonathan</dc:creator>
 <dc:creator>Duldhardt, Nico</dc:creator>
 <dc:creator>Ngomo, Axel-Cyrille Ngonga</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Question answering (QA) has been the subject of a resurgence over the past
years. The said resurgence has led to a multitude of question answering (QA)
systems being developed both by companies and research facilities. While a few
components of QA systems get reused across implementations, most systems do not
leverage the full potential of component reuse. Hence, the development of QA
systems is currently still a tedious and time-consuming process. We address the
challenge of accelerating the creation of novel or tailored QA systems by
presenting a concept for a self-wiring approach to composing QA systems. Our
approach will allow the reuse of existing, web-based QA systems or modules
while developing new QA platforms. To this end, it will rely on QA modules
being described using the Web Ontology Language. Based on these descriptions,
our approach will be able to automatically compose QA systems using a
data-driven approach automatically.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, pre-print in lncs</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01805</identifier>
 <datestamp>2017-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic Discrepancy Beyond Partial Coloring</dc:title>
 <dc:creator>Bansal, Nikhil</dc:creator>
 <dc:creator>Garg, Shashwat</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The partial coloring method is one of the most powerful and widely used
method in combinatorial discrepancy problems. However, in many cases it leads
to sub-optimal bounds as the partial coloring step must be iterated a
logarithmic number of times, and the errors can add up in an adversarial way.
We give a new and general algorithmic framework that overcomes the limitations
of the partial coloring method and can be applied in a black-box manner to
various problems. Using this framework, we give new improved bounds and
algorithms for several classic problems in discrepancy. In particular, for
Tusnady's problem, we give an improved $O(\log^2 n)$ bound for discrepancy of
axis-parallel rectangles and more generally an $O_d(\log^dn)$ bound for
$d$-dimensional boxes in $\mathbb{R}^d$. Previously, even non-constructively,
the best bounds were $O(\log^{2.5} n)$ and $O_d(\log^{d+0.5}n)$ respectively.
Similarly, for the Steinitz problem we give the first algorithm that matches
the best known non-constructive bounds due to Banaszczyk [Banaszczyk 2012] in
the $\ell_\infty$ case, and improves the previous algorithmic bounds
substantially in the $\ell_2$ case. Our framework is based upon a substantial
generalization of the techniques developed recently in the context of the
Koml\'os discrepancy problem [BDG16].
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01817</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the Pathways of Adaptation an Avatar 3D Animation Procedures
  and Virtual Reality Arenas in Research of Human Courtship Behaviour and
  Sexual Reactivity in Psychological Research</dc:title>
 <dc:creator>Binter, Jakub</dc:creator>
 <dc:creator>Klapilov&#xe1;, Kate&#x159;ina</dc:creator>
 <dc:creator>Zik&#xe1;nov&#xe1;, Tereza</dc:creator>
 <dc:creator>Nilsson, Tommy</dc:creator>
 <dc:creator>B&#xe1;rtov&#xe1;, Kl&#xe1;ra</dc:creator>
 <dc:creator>Krejcov&#xe1;, Lucie</dc:creator>
 <dc:creator>Androvicov&#xe1;, Renata</dc:creator>
 <dc:creator>Lindov&#xe1;, Jitka</dc:creator>
 <dc:creator>Pru&#x161;ov&#xe1;, Denisa</dc:creator>
 <dc:creator>Wells, Timothy</dc:creator>
 <dc:creator>Riha, Daniel</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  There are many reasons for utilising 3D animation and virtual reality in
sexuality research. Apart from providing a mean with which to (re)experience
certain situations there are four main advantages: a) bespoke animated stimuli
can be created and customized, which is especially important when researching
paraphilia and sexual preferences, b) stimulus production is less expensive and
easier to produce compared to real world stimuli, c) virtual reality allows us
to capture data such as physiological reasons to stimuli, that we would not be
able to otherwise (without resorting to self-report measures which are
especially problematic in this research domain), d) ethical, legal, and health
and safety issues are less complex since neither physical nor psychological
harm is caused to animated characters allowing for the safe presentation of
stimuli involving vulnerable targets. The animation sub-group has been
exploring so far several production quality levels and various animation
procedures in a number of available software. The aim is to develop static as
well as dynamic, interactive sexual stimuli for sexual diagnostic and
therapeutic purposes. We are aware of number of ethical issues related to the
use of virtual reality in proposed research are analysed in this chapter.
</dc:description>
 <dc:description>Comment: 10 pages, Virtual, Augmented and Mixed Reality: Changing the Face of
  Learning, Special Conference Stream within The Experiential Learning in
  Virtual Worlds Project: 5th Global Meeting, Dubrovnik, Croatia, 10-12 May
  2015</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01820</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semi-Automatic Approach for Detecting Dataset References in Social
  Science Texts</dc:title>
 <dc:creator>Ghavimi, Behnam</dc:creator>
 <dc:creator>Mayr, Philipp</dc:creator>
 <dc:creator>Lange, Christoph</dc:creator>
 <dc:creator>Vahdati, Sahar</dc:creator>
 <dc:creator>AUER, S&#xf6;ren</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Today, full-texts of scientific articles are often stored in different
locations than the used datasets. Dataset registries aim at a closer
integration by making datasets citable but authors typically refer to datasets
using inconsistent abbreviations and heterogeneous metadata (e.g. title,
publication year). It is thus hard to reproduce research results, to access
datasets for further analysis, and to determine the impact of a dataset.
Manually detecting references to datasets in scientific articles is
time-consuming and requires expert knowledge in the underlying research
domain.We propose and evaluate a semi-automatic three-step approach for finding
explicit references to datasets in social sciences articles.We first extract
pre-defined special features from dataset titles in the da|ra registry, then
detect references to datasets using the extracted features, and finally match
the references found with corresponding dataset titles. The approach does not
require a corpus of articles (avoiding the cold start problem) and performs
well on a test corpus. We achieved an F-measure of 0.84 for detecting
references in full-texts and an F-measure of 0.83 for finding correct matches
of detected references in the da|ra dataset registry.
</dc:description>
 <dc:description>Comment: Pre-print IS&amp;U journal. arXiv admin note: substantial text overlap
  with arXiv:1603.01774</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01823</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameterized counting of trees, forests and matroid bases</dc:title>
 <dc:creator>Brand, Cornelius</dc:creator>
 <dc:creator>Roth, Marc</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We investigate the complexity of counting trees, forests and bases of
matroids from a parameterized point of view. It turns out that the problems of
computing the number of trees and forests with $k$ edges are $\# W[1]$-hard
when parameterized by $k$. Together with the recent algorithm for deterministic
matrix truncation by Lokshtanov et al. (ICALP 2015), the hardness result for
$k$-forests implies $\# W[1]$-hardness of the problem of counting bases of a
matroid when parameterized by rank or nullity, even if the matroid is
restricted to be representable over a field of characteristic $2$. We
complement this result by pointing out that the problem becomes fixed parameter
tractable for matroids represented over a fixed finite field.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01824</identifier>
 <datestamp>2017-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Distance-Based Formation Control of Multiple Rigid Bodies with
  Orientation Alignment</dc:title>
 <dc:creator>Nikou, Alexandros</dc:creator>
 <dc:creator>Verginis, Christos K.</dc:creator>
 <dc:creator>Dimarogonas, Dimos V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper addresses the problem of distance- and orientation-based formation
control of a class of second-order nonlinear multi-agent systems in 3D space,
under static and undirected communication topologies. More specifically, we
design a decentralized model-free control protocol in the sense that each agent
uses only local information from its neighbors to calculate its own control
signal, without incorporating any knowledge of the model nonlinearities and
exogenous disturbances. Moreover, the transient and steady state response is
solely determined by certain designer-specified performance functions and is
fully decoupled by the agents' dynamic model, the control gain selection, the
underlying graph topology as well as the initial conditions. Additionally, by
introducing certain inter-agent distance constraints, we guarantee collision
avoidance and connectivity maintenance between neighboring agents. Finally,
simulation results verify the performance of the proposed controllers.
</dc:description>
 <dc:description>Comment: IFAC Word Congress 2017</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01825</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust State-Feedback H-infinity Control For Discrete-Time Descriptor
  Systems With Norm-Bounded Parametric Uncertainties</dc:title>
 <dc:creator>Belov, Alexey A.</dc:creator>
 <dc:creator>Andrianova, Olga G.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper deals with a state feedback H-infinity control problem for linear
time-invariant discrete-time descriptor systems with norm-bounded parametric
uncertainties. To this end, bounded real lemma (BRL) is extended on the class
of uncertain descriptor systems. The control design procedure based on the
conditions of BRL for uncertain descriptor systems is proposed. Numerical
example is included to illustrate the effectiveness of the present result.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01827</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Performance Tradeoffs in Control</dc:title>
 <dc:creator>Pandey, Ayush</dc:creator>
 <dc:creator>Kostina, Victoria</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We focus our attention on the most common scenario in networked control
systems where the measured output from the observer is transmitted via a
communication channel to the controller. Using information theoretic results,
we studied the tradeoff between the performance and the accuracy of
observations due to communication constraints for such a scenario. We focused
on three important cases in the communication channel, the additive white
Gaussian noise (AWGN), limited data rate and systems with multiplicative
uncertainty in the system parameters. Using known theoretical results for a
rate limited communication channel, we showed the effect of entropy of the
output of quantizer on the control performance. The same was done for the case
of multiplicative uncertainty in the system . For an AWGN channel, we showed
the effect of channel SNR on the performance. For the analog joint source
channel coding approach (which works only for Gaussian disturbances in the
system), we showed that the known lower bound is tight even for non Gaussian
system disturbances. We also compared the simulated performance of a system
with known upper and lower rate distortion bounds for all the three cases. The
lower bound on the rate is closely approached by a simple uniform quantization
scheme, hence demonstrating its tightness.
</dc:description>
 <dc:description>Comment: Technical Report : Undergraduate Research Internship at Electrical
  Engineering Department, California Institute of Technology</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01835</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed Dynamic Range Majority Data Structures</dc:title>
 <dc:creator>Gagie, Travis</dc:creator>
 <dc:creator>He, Meng</dc:creator>
 <dc:creator>Navarro, Gonzalo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the range $\alpha$-majority query problem, we preprocess a given sequence
$S[1..n]$ for a fixed threshold $\alpha \in (0, 1]$, such that given a query
range $[i..j]$, the symbols that occur more than $\alpha (j-i+1)$ times in
$S[i..j]$ can be reported efficiently. We design the first compressed solution
to this problem in dynamic settings. Our data structure represents $S$ using
$nH_k+ o(n\lg \sigma)$ bits for any $k = o(\log_{\sigma} n)$, where $\sigma$ is
the alphabet size and $H_k$ is the $k$-th order empirical entropy of $S$. It
answers range $\alpha$-majority queries in $O(\frac{\lg n}{\alpha \lg\lg n})$
time, and supports insertions and deletions in $O(\frac{\lg n}{\alpha})$
amortized time. The best previous solution (Elmasry et al., 2016) has the same
query and update times, but uses $O(n)$ words.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01838</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy-SGD: Biasing Gradient Descent Into Wide Valleys</dc:title>
 <dc:creator>Chaudhari, Pratik</dc:creator>
 <dc:creator>Choromanska, Anna</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:creator>Baldassi, Carlo</dc:creator>
 <dc:creator>Borgs, Christian</dc:creator>
 <dc:creator>Chayes, Jennifer</dc:creator>
 <dc:creator>Sagun, Levent</dc:creator>
 <dc:creator>Zecchina, Riccardo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper proposes a new optimization algorithm called Entropy-SGD for
training deep neural networks that is motivated by the local geometry of the
energy landscape. Local extrema with low generalization error have a large
proportion of almost-zero eigenvalues in the Hessian with very few positive or
negative eigenvalues. We leverage upon this observation to construct a
local-entropy-based objective function that favors well-generalizable solutions
lying in large flat regions of the energy landscape, while avoiding
poorly-generalizable solutions located in the sharp valleys. Conceptually, our
algorithm resembles two nested loops of SGD where we use Langevin dynamics in
the inner loop to compute the gradient of the local entropy before each update
of the weights. We show that the new objective has a smoother energy landscape
and show improved generalization over SGD using uniform stability, under
certain assumptions. Our experiments on convolutional and recurrent networks
demonstrate that Entropy-SGD compares favorably to state-of-the-art techniques
in terms of generalization error and training time.
</dc:description>
 <dc:description>Comment: ICLR '17</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01839</identifier>
 <datestamp>2017-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Question Answering for Long Documents</dc:title>
 <dc:creator>Choi, Eunsol</dc:creator>
 <dc:creator>Hewlett, Daniel</dc:creator>
 <dc:creator>Lacoste, Alexandre</dc:creator>
 <dc:creator>Polosukhin, Illia</dc:creator>
 <dc:creator>Uszkoreit, Jakob</dc:creator>
 <dc:creator>Berant, Jonathan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a framework for question answering that can efficiently scale to
longer documents while maintaining or even improving performance of
state-of-the-art models. While most successful approaches for reading
comprehension rely on recurrent neural networks (RNNs), running them over long
documents is prohibitively slow because it is difficult to parallelize over
sequences. Inspired by how people first skim the document, identify relevant
parts, and carefully read these parts to produce an answer, we combine a
coarse, fast model for selecting relevant sentences and a more expensive RNN
for producing the answer from those sentences. We treat sentence selection as a
latent variable trained jointly from the answer only using reinforcement
learning. Experiments demonstrate the state of the art performance on a
challenging subset of the Wikireading and on a new dataset, while speeding up
the model by 3.5x-6.7x.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01843</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Perform Physics Experiments via Deep Reinforcement Learning</dc:title>
 <dc:creator>Denil, Misha</dc:creator>
 <dc:creator>Agrawal, Pulkit</dc:creator>
 <dc:creator>Kulkarni, Tejas D</dc:creator>
 <dc:creator>Erez, Tom</dc:creator>
 <dc:creator>Battaglia, Peter</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  When encountering novel objects, humans are able to infer a wide range of
physical properties such as mass, friction and deformability by interacting
with them in a goal driven way. This process of active interaction is in the
same spirit as a scientist performing experiments to discover hidden facts.
Recent advances in artificial intelligence have yielded machines that can
achieve superhuman performance in Go, Atari, natural language processing, and
complex control problems; however, it is not clear that these systems can rival
the scientific intuition of even a young child. In this work we introduce a
basic set of tasks that require agents to estimate properties such as mass and
cohesion of objects in an interactive simulated environment where they can
manipulate the objects and observe the consequences. We found that state of art
deep reinforcement learning methods can learn to perform the experiments
necessary to discover such hidden properties. By systematically manipulating
the problem difficulty and the cost incurred by the agent for performing
experiments, we found that agents learn different strategies that balance the
cost of gathering information against the cost of making mistakes in different
situations.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01845</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Urban Distribution Grid Topology Estimation via Group Lasso</dc:title>
 <dc:creator>Liao, Yizheng</dc:creator>
 <dc:creator>Weng, Yang</dc:creator>
 <dc:creator>Liu, Guangyi</dc:creator>
 <dc:creator>Rajagopal, Ram</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The growing penetration of distributed energy resources (DERs) in urban areas
raises multiple reliability issues. The topology reconstruction is a critical
step to ensure the robustness of distribution grid operation. However, the bus
connectivity and network topology reconstruction are hard in distribution
grids. The reasons are that 1) the branches are challenging and expensive to
monitor due to underground setup; 2) the inappropriate assumption of radial
topology in many studies that urban grids are mesh. To address these drawbacks,
we propose a new data-driven approach to reconstruct distribution grid topology
by utilizing the newly available smart meter data. Specifically, a graphical
model is built to model the probabilistic relationships among different voltage
measurements. With proof, the bus connectivity and topology estimation problems
are formulated as a linear regression problem with least absolute shrinkage on
grouped variables (Group Lasso) to deal with meshed network structures.
Simulation results show highly accurate estimation in IEEE standard
distribution test systems with and without loops using real smart meter data.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01850</identifier>
 <datestamp>2017-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal High-Resolution Adaptive Sampling of Deterministic Signals</dc:title>
 <dc:creator>Dar, Yehuda</dc:creator>
 <dc:creator>Bruckstein, Alfred M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work we study the topic of high-resolution adaptive sampling of a
given deterministic signal and establish a connection to classic approaches to
high-rate quantization. Specifically, we formulate solutions to the task of
optimal high-resolution sampling, counterparts of well-known results for
high-rate quantization. Our results reveal that the optimal high-resolution
sampling structure is determined by the density of the signal-gradient energy,
just as the probability-density-function defines the optimal high-rate
quantization form. This paper has three main contributions: the first is
establishing a fundamental paradigm bridging the topics of sampling and
quantization. The second is a theoretical analysis of sampling, for arbitrary
signal-dimension, relevant to the emerging field of high-resolution signal
processing. The third is a new approach to nonuniform sampling of
one-dimensional signals that is experimentally shown to outperform an optimized
tree-structured sampling technique.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01851</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Optimisation with Prior Reuse for Motion Planning in Robot
  Soccer</dc:title>
 <dc:creator>Agarwalla, Abhinav</dc:creator>
 <dc:creator>Jain, Arnav Kumar</dc:creator>
 <dc:creator>Manohar, KV</dc:creator>
 <dc:creator>Saxena, Arpit</dc:creator>
 <dc:creator>Mukhopadhyay, Jayanta</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We integrate learning and motion planning for soccer playing differential
drive robots using Bayesian optimisation. Trajectories generated using
end-slope cubic Bezier splines are first optimised globally through Bayesian
optimisation for a set of candidate points with obstacles. The optimised
trajectories along with robot and obstacle positions and velocities are stored
in a database. The closest planning situation is identified from the database
using k-Nearest Neighbour approach. It is further optimised online through
reuse of prior information from previously optimised trajectory. Our approach
reduces computation time of trajectory optimisation considerably. Velocity
profiling generates velocities consistent with robot kinodynamoic constraints,
and avoids collision and slipping. Extensive testing is done on developed
simulator, as well as on physical differential drive robots. Our method shows
marked improvements in mitigating tracking error, and reducing traversal and
computational time over competing techniques under the constraints of
performing tasks in real time.
</dc:description>
 <dc:description>Comment: Accepted at ACM India Joint Conference on Data Science and Management
  of Data 2018</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01853</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MTS Sketch for Accurate Estimation of Set-Expression Cardinalities from
  Small Samples</dc:title>
 <dc:creator>Cohen, Reuven</dc:creator>
 <dc:creator>Katzir, Liran</dc:creator>
 <dc:creator>Yehezkel, Aviv</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Sketch-based streaming algorithms allow efficient processing of big data.
These algorithms use small fixed-size storage to store a summary (&quot;sketch&quot;) of
the input data, and use probabilistic algorithms to estimate the desired
quantity. However, in many real-world applications it is impractical to collect
and process the entire data stream, the common practice is thus to sample and
process only a small part of it. While sampling is crucial for handling massive
data sets, it may reduce accuracy. In this paper we present a new framework
that can accurately estimate the cardinality of any set expression between any
number of streams using only a small sample of each stream. The proposed
framework consists of a new sketch, called Maximal-Term with Subsample (MTS),
and a family of algorithms that use this sketch. An example of a possible query
that can be efficiently answered using the proposed sketch is, How many
distinct tuples appear in tables $T_1$ and $T_2$, but not in $T_3$? The
algorithms presented in this paper answer such queries accurately, processing
only a small sample of the tuples in each table and using a constant amount of
memory. Such estimations are useful for the optimization of queries over very
large database systems. We show that all our algorithms are unbiased, and we
analyze their asymptotic variance.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1508.06216</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01855</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neuro-Symbolic Program Synthesis</dc:title>
 <dc:creator>Parisotto, Emilio</dc:creator>
 <dc:creator>Mohamed, Abdel-rahman</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Zhou, Dengyong</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Recent years have seen the proposal of a number of neural architectures for
the problem of Program Induction. Given a set of input-output examples, these
architectures are able to learn mappings that generalize to new test inputs.
While achieving impressive results, these approaches have a number of important
limitations: (a) they are computationally expensive and hard to train, (b) a
model has to be trained for each task (program) separately, and (c) it is hard
to interpret or verify the correctness of the learnt mapping (as it is defined
by a neural network). In this paper, we propose a novel technique,
Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems.
Once trained, our approach can automatically construct computer programs in a
domain-specific language that are consistent with a set of input-output
examples provided at test time. Our method is based on two novel neural
modules. The first module, called the cross correlation I/O network, given a
set of input-output examples, produces a continuous representation of the set
of I/O examples. The second module, the Recursive-Reverse-Recursive Neural
Network (R3NN), given the continuous representation of the examples,
synthesizes a program by incrementally expanding partial programs. We
demonstrate the effectiveness of our approach by applying it to the rich and
complex domain of regular expression based string transformations. Experiments
show that the R3NN model is not only able to construct programs from new
input-output examples, but it is also able to construct new programs for tasks
that it had never observed before during training.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01856</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of the Triangle Algorithm and SMO for Solving the Hard
  Margin Problem</dc:title>
 <dc:creator>Gupta, Mayank</dc:creator>
 <dc:creator>Kalantari, Bahman</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this article we consider the problem of testing, for two finite sets of
points in the Euclidean space, if their convex hulls are disjoint and computing
an optimal supporting hyperplane if so. This is a fundamental problem of
classification in machine learning known as the hard-margin SVM. The problem
can be formulated as a quadratic programming problem. The SMO algorithm is the
current state of art algorithm for solving it, but it does not answer the
question of separability. An alternative to solving both problems is the
Triangle Algorithm, a geometrically inspired algorithm, initially described for
the convex hull membership problem, a fundamental problem in linear
programming. First, we describe the experimental performance of the Triangle
Algorithm for testing the intersection of two convex hulls. Next, we compare
the performance of Triangle Algorithm with SMO for finding the optimal
supporting hyperplane. Based on experimental results ranging up to 5000 points
in each set in dimensions up to 10000, the Triangle Algorithm outperforms SMO.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1412.0356</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01865</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Approximate Analysis of Energy Detection over n*Rayleigh Fading
  Channels through Cooperative Spectrum Sensing</dc:title>
 <dc:creator>Alghorani, Yahia</dc:creator>
 <dc:creator>Kaddoum, Georges</dc:creator>
 <dc:creator>Muhaidat, Sami</dc:creator>
 <dc:creator>Pierre, Samuel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this letter, we consider the problem of energy detection of unknown
signals in an intervehicular communication (IVC) system over n*Rayleigh fading
channels (also known as cascaded Rayleigh). Novel tight approximations for the
probability of detection are derived for the no-diversity and the maximum ratio
combining (MRC)) diversity schemes. Moreover, we investigate the system
performance when cooperative spectrum sensing (CSS) is considered with and
without imperfect reporting channels. The analytical results show that the
detection reliability is decreased as the fading severity parameter n increases
but reliability is substantially improved when CSS employs MRC schemes.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01865</dc:identifier>
 <dc:identifier>IEEE Wireless Communications Letters, Vol. 4, No. 4, August 2015</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2015.2427283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01866</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Marciani Normal Form of context-free grammars</dc:title>
 <dc:creator>Marciani, Giacomo</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  In this paper, we prove the semidecidability of the problem of saying whether
or not a context-free grammar generates a regular language. We introduce the
notion of context-free grammar in Marciani Normal Form. We prove that a
context-free grammar in Marciani Normal Form always generates a regular
language.
</dc:description>
 <dc:description>Comment: preprint, 4 pages</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01867</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent Attention For If-Then Program Synthesis</dc:title>
 <dc:creator>Chen, Xinyun</dc:creator>
 <dc:creator>Liu, Chang</dc:creator>
 <dc:creator>Shin, Richard</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:creator>Chen, Mingcheng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Automatic translation from natural language descriptions into programs is a
longstanding challenging problem. In this work, we consider a simple yet
important sub-problem: translation from textual descriptions to If-Then
programs. We devise a novel neural network architecture for this task which we
train end-to-end. Specifically, we introduce Latent Attention, which computes
multiplicative weights for the words in the description in a two-stage process
with the goal of better leveraging the natural language structures that
indicate the relevant parts for predicting program elements. Our architecture
reduces the error rate by 28.57% compared to prior art. We also propose a
one-shot learning scenario of If-Then program synthesis and simulate it with
our existing dataset. We demonstrate a variation on the training procedure for
this scenario that outperforms the original procedure, significantly closing
the gap to the model trained with all data.
</dc:description>
 <dc:description>Comment: Accepted by NIPS 2016</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01868</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Truth Discovery with Memory Network</dc:title>
 <dc:creator>Li, Luyang</dc:creator>
 <dc:creator>Qin, Bing</dc:creator>
 <dc:creator>Ren, Wenjing</dc:creator>
 <dc:creator>Liu, Ting</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Truth discovery is to resolve conflicts and find the truth from
multiple-source statements. Conventional methods mostly research based on the
mutual effect between the reliability of sources and the credibility of
statements, however, pay no attention to the mutual effect among the
credibility of statements about the same object. We propose memory network
based models to incorporate these two ideas to do the truth discovery. We use
feedforward memory network and feedback memory network to learn the
representation of the credibility of statements which are about the same
object. Specially, we adopt memory mechanism to learn source reliability and
use it through truth prediction. During learning models, we use multiple types
of data (categorical data and continuous data) by assigning different weights
automatically in the loss function based on their own effect on truth discovery
prediction. The experiment results show that the memory network based models
much outperform the state-of-the-art method and other baseline methods.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01869</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Please Lower Small Cell Antenna Heights in 5G</dc:title>
 <dc:creator>Ding, Ming</dc:creator>
 <dc:creator>Perez, David Lopez</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we present a new and significant theoretical discovery. If the
absolute height difference between base station (BS) antenna and user equipment
(UE) antenna is larger than zero, then the network capacity performance in
terms of the area spectral efficiency (ASE) will continuously decrease as the
BS density increases for ultra-dense (UD) small cell networks (SCNs). This
performance behavior has a tremendous impact on the deployment of UD SCNs in
the 5th-generation (5G) era. Network operators may invest large amounts of
money in deploying more network infrastructure to only obtain an even worse
network performance. Our study results reveal that it is a must to lower the
SCN BS antenna height to the UE antenna height to fully achieve the capacity
gains of UD SCNs in 5G. However, this requires a revolutionized approach of BS
architecture and deployment, which is explored in this paper too.
</dc:description>
 <dc:description>Comment: Final version in IEEE: http://ieeexplore.ieee.org/document/7842150/.
  arXiv admin note: substantial text overlap with arXiv:1608.06694</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01869</dc:identifier>
 <dc:identifier>doi:10.1109/GLOCOM.2016.7842150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01872</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Action2Activity: Recognizing Complex Activities from Sensor Data</dc:title>
 <dc:creator>Liu, Ye</dc:creator>
 <dc:creator>Nie, Liqiang</dc:creator>
 <dc:creator>Han, Lei</dc:creator>
 <dc:creator>Zhang, Luming</dc:creator>
 <dc:creator>Rosenblum, David S</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As compared to simple actions, activities are much more complex, but
semantically consistent with a human's real life. Techniques for action
recognition from sensor generated data are mature. However, there has been
relatively little work on bridging the gap between actions and activities. To
this end, this paper presents a novel approach for complex activity recognition
comprising of two components. The first component is temporal pattern mining,
which provides a mid-level feature representation for activities, encodes
temporal relatedness among actions, and captures the intrinsic properties of
activities. The second component is adaptive Multi-Task Learning, which
captures relatedness among activities and selects discriminant features.
Extensive experiments on a real-world dataset demonstrate the effectiveness of
our work.
</dc:description>
 <dc:description>Comment: IJCAI 2015</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01873</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geodetic Graphs Homeomorphic to a Given Geodetic Graph</dc:title>
 <dc:creator>Frasser, Carlos E.</dc:creator>
 <dc:creator>Vostrov, George N.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  This paper describes a new approach to the problem of generating the class of
all geodetic graphs homeomorphic to a given geodetic one. An algorithmic
procedure is elaborated to carry out a systematic finding of such a class of
graphs. As a result, the enumeration of the class of geodetic graphs
homeomorphic to certain Moore graphs has been performed.
</dc:description>
 <dc:description>Comment: 28 pages, 8 Figures</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01874</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Machine Translation with Reconstruction</dc:title>
 <dc:creator>Tu, Zhaopeng</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Shang, Lifeng</dc:creator>
 <dc:creator>Liu, Xiaohua</dc:creator>
 <dc:creator>Li, Hang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Although end-to-end Neural Machine Translation (NMT) has achieved remarkable
progress in the past two years, it suffers from a major drawback: translations
generated by NMT systems often lack of adequacy. It has been widely observed
that NMT tends to repeatedly translate some source words while mistakenly
ignoring other words. To alleviate this problem, we propose a novel
encoder-decoder-reconstructor framework for NMT. The reconstructor,
incorporated into the NMT model, manages to reconstruct the input source
sentence from the hidden layer of the output target sentence, to ensure that
the information in the source side is transformed to the target side as much as
possible. Experiments show that the proposed framework significantly improves
the adequacy of NMT output and achieves superior translation result over
state-of-the-art NMT and statistical MT systems.
</dc:description>
 <dc:description>Comment: Accepted by AAAI 2017</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01875</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges of Feature Selection for Big Data Analytics</dc:title>
 <dc:creator>Li, Jundong</dc:creator>
 <dc:creator>Liu, Huan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We are surrounded by huge amounts of large-scale high dimensional data. It is
desirable to reduce the dimensionality of data for many learning tasks due to
the curse of dimensionality. Feature selection has shown its effectiveness in
many applications by building simpler and more comprehensive model, improving
learning performance, and preparing clean, understandable data. Recently, some
unique characteristics of big data such as data velocity and data variety
present challenges to the feature selection problem. In this paper, we envision
these challenges of feature selection for big data analytics. In particular, we
first give a brief introduction about feature selection and then detail the
challenges of feature selection for structured, heterogeneous and streaming
data as well as its scalability and stability issues. At last, to facilitate
and promote the feature selection research, we present an open-source feature
selection repository (scikit-feature), which consists of most of current
popular feature selection algorithms.
</dc:description>
 <dc:description>Comment: Special Issue on Big Data, IEEE Intelligent Systems, 2016. arXiv
  admin note: text overlap with arXiv:1601.07996</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01879</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Sketching over $\mathbb F_2$</dc:title>
 <dc:creator>Kannan, Sampath</dc:creator>
 <dc:creator>Mossel, Elchanan</dc:creator>
 <dc:creator>Yaroslavtsev, Grigory</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We initiate a systematic study of linear sketching over $\mathbb F_2$. For a
given Boolean function $f \colon \{0,1\}^n \to \{0,1\}$ a randomized $\mathbb
F_2$-sketch is a distribution $\mathcal M$ over $d \times n$ matrices with
elements over $\mathbb F_2$ such that $\mathcal Mx$ suffices for computing
$f(x)$ with high probability. We study a connection between $\mathbb
F_2$-sketching and a two-player one-way communication game for the
corresponding XOR-function. Our results show that this communication game
characterizes $\mathbb F_2$-sketching under the uniform distribution (up to
dependence on error). Implications of this result include: 1) a composition
theorem for $\mathbb F_2$-sketching complexity of a recursive majority
function, 2) a tight relationship between $\mathbb F_2$-sketching complexity
and Fourier sparsity, 3) lower bounds for a certain subclass of symmetric
functions. We also fully resolve a conjecture of Montanaro and Osborne
regarding one-way communication complexity of linear threshold functions by
designing an $\mathbb F_2$-sketch of optimal size.
  Furthermore, we show that (non-uniform) streaming algorithms that have to
process random updates over $\mathbb F_2$ can be constructed as $\mathbb
F_2$-sketches for the uniform distribution with only a minor loss. In contrast
with the previous work of Li, Nguyen and Woodruff (STOC'14) who show an
analogous result for linear sketches over integers in the adversarial setting
our result doesn't require the stream length to be triply exponential in $n$
and holds for streams of length $\tilde O(n)$ constructed through uniformly
random updates. Finally, we state a conjecture that asks whether optimal
one-way communication protocols for XOR-functions can be constructed as
$\mathbb F_2$-sketches with only a small loss.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01880</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inductive decision based Real Time Occupancy detector in University
  Buildings</dc:title>
 <dc:creator>Jain, Nkita</dc:creator>
 <dc:creator>Gupta, Rachita</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The ability to estimate College Campus Occupancy for Classrooms and Labs in
real time has become one of the major concerns for various Academicians,
authorities and administrators,where still a manual attendance marking system
is being followed. Using a low budget multiple sensor setup installed in a
college auditorium, the goal is to build a real-time occupancy detector. This
paper presents an Inductive real time Decision tree based classifier using
multiple sensor dataset to detect occupancy. Using simple feature based
thresholds, Reverberation time which comes out to be a novel as well as most
distinguishing feature sampled at various frequencies over a given time
interval was used to detect the occupancy with an accuracy of %.Addition of
various other sensor data, decreased the accuracy of classification results.
The detector setup can be used in various college buildings to provide real
time centralised occupancy status thus automating the manual attendance system
being used.
</dc:description>
 <dc:description>Comment: 7 Pages 9 Figures, International Journal of Computer Science and
  Information Security Vol 14 No 10 2016</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01880</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information Security
  14 (10) 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01884</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text
  Classification</dc:title>
 <dc:creator>Liang, Depeng</dc:creator>
 <dc:creator>Zhang, Yongdong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently deeplearning models have been shown to be capable of making
remarkable performance in sentences and documents classification tasks. In this
work, we propose a novel framework called AC-BLSTM for modeling sentences and
documents, which combines the asymmetric convolution neural network (ACNN) with
the Bidirectional Long Short-Term Memory network (BLSTM). Experiment results
demonstrate that our model achieves state-of-the-art results on five tasks,
including sentiment analysis, question type classification, and subjectivity
classification. In order to further improve the performance of AC-BLSTM, we
propose a semi-supervised learning framework called G-AC-BLSTM for text
classification by combining the generative model with AC-BLSTM.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01886</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Information-Theoretic Framework for Fast and Robust Unsupervised
  Learning via Neural Population Infomax</dc:title>
 <dc:creator>Huang, Wentao</dc:creator>
 <dc:creator>Zhang, Kechen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A framework is presented for unsupervised learning of representations based
on infomax principle for large-scale neural populations. We use an asymptotic
approximation to the Shannon's mutual information for a large neural population
to demonstrate that a good initial approximation to the global
information-theoretic optimum can be obtained by a hierarchical infomax method.
Starting from the initial solution, an efficient algorithm based on gradient
descent of the final objective function is proposed to learn representations
from the input datasets, and the method works for complete, overcomplete, and
undercomplete bases. As confirmed by numerical experiments, our method is
robust and highly efficient for extracting salient features from input
datasets. Compared with the main existing methods, our algorithm has a distinct
advantage in both the training speed and the robustness of unsupervised
representation learning. Furthermore, the proposed method is easily extended to
the supervised or unsupervised model for training deep structure networks.
</dc:description>
 <dc:description>Comment: 25 pages, 7 figures, 5th International Conference on Learning
  Representations (ICLR 2017)</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01887</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sum-networks from incidence structures: construction and capacity
  analysis</dc:title>
 <dc:creator>Tripathy, Ardhendu</dc:creator>
 <dc:creator>Ramamoorthy, Aditya</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A sum-network is an instance of a network coding problem over a directed
acyclic network in which each terminal node wants to compute the sum over a
finite field of the information observed at all the source nodes. Many
characteristics of the well-studied multiple unicast network communication
problem also hold for sum-networks due to a known reduction between instances
of these two problems. In this work, we describe an algorithm to construct
families of sum-network instances using incidence structures. The computation
capacity of several of these sum-network families is characterized. We
demonstrate that unlike the multiple unicast problem, the computation capacity
of sum-networks depends on the characteristic of the finite field over which
the sum is computed. This dependence is very strong; we show examples of
sum-networks that have a rate-1 solution over one characteristic but a rate
close to zero over a different characteristic. Additionally, a sum-network can
have an arbitrary different number of computation capacities for different
alphabets. This is contrast to the multiple unicast problem where it is known
that the capacity is independent of the network coding alphabet.
</dc:description>
 <dc:description>Comment: 27 pages, 7 figures, preprint submitted to IEEE Transactions on
  Information Theory</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01890</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OSMnx: New Methods for Acquiring, Constructing, Analyzing, and
  Visualizing Complex Street Networks</dc:title>
 <dc:creator>Boeing, Geoff</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Urban scholars have studied street networks in various ways, but there are
data availability and consistency limitations to the current urban
planning/street network analysis literature. To address these challenges, this
article presents OSMnx, a new tool to make the collection of data and creation
and analysis of street networks simple, consistent, automatable and sound from
the perspectives of graph theory, transportation, and urban design. OSMnx
contributes five significant capabilities for researchers and practitioners:
first, the automated downloading of political boundaries and building
footprints; second, the tailored and automated downloading and constructing of
street network data from OpenStreetMap; third, the algorithmic correction of
network topology; fourth, the ability to save street networks to disk as
shapefiles, GraphML, or SVG files; and fifth, the ability to analyze street
networks, including calculating routes, projecting and visualizing networks,
and calculating metric and topological measures. These measures include those
common in urban design and transportation studies, as well as advanced measures
of the structure and topology of the network. Finally, this article presents a
simple case study using OSMnx to construct and analyze street networks in
Portland, Oregon.
</dc:description>
 <dc:description>Comment: peer-reviewed journal article</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01890</dc:identifier>
 <dc:identifier>Computers, Environment and Urban Systems 65, 126-139</dc:identifier>
 <dc:identifier>doi:10.1016/j.compenvurbsys.2017.05.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01891</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Multimodal Learning with Deep Generative Models</dc:title>
 <dc:creator>Suzuki, Masahiro</dc:creator>
 <dc:creator>Nakayama, Kotaro</dc:creator>
 <dc:creator>Matsuo, Yutaka</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We investigate deep generative models that can exchange multiple modalities
bi-directionally, e.g., generating images from corresponding texts and vice
versa. Recently, some studies handle multiple modalities on deep generative
models, such as variational autoencoders (VAEs). However, these models
typically assume that modalities are forced to have a conditioned relation,
i.e., we can only generate modalities in one direction. To achieve our
objective, we should extract a joint representation that captures high-level
concepts among all modalities and through which we can exchange them
bi-directionally. As described herein, we propose a joint multimodal
variational autoencoder (JMVAE), in which all modalities are independently
conditioned on joint representation. In other words, it models a joint
distribution of modalities. Furthermore, to be able to generate missing
modalities from the remaining modalities properly, we develop an additional
method, JMVAE-kl, that is trained by reducing the divergence between JMVAE's
encoder and prepared networks of respective modalities. Our experiments show
that our proposed method can obtain appropriate joint representation from
multiple modalities and that it can generate and reconstruct them more properly
than conventional VAEs. We further demonstrate that JMVAE can generate multiple
modalities bi-directionally.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01907</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Preserving PageRank Algorithm By Using Secure Multi-Party
  Computation</dc:title>
 <dc:creator>Catak, Ferhat Ozgur</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this work, we study the problem of privacy preserving computation on
PageRank algorithm. The idea is to enforce the secure multi party computation
of the algorithm iteratively using homomorphic encryption based on Paillier
scheme. In the proposed PageRank computation, a user encrypt its own graph data
using asymmetric encryption method, sends the data set into different parties
in a privacy-preserving manner. Each party computes its own encrypted entity,
but learns nothing about the data at other parties.
</dc:description>
 <dc:description>Comment: 8 Pages</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01911</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Me, Myself and My Killfie: Characterizing and Preventing Selfie Deaths</dc:title>
 <dc:creator>Lamba, Hemank</dc:creator>
 <dc:creator>Bharadhwaj, Varun</dc:creator>
 <dc:creator>Vachher, Mayank</dc:creator>
 <dc:creator>Agarwal, Divyansh</dc:creator>
 <dc:creator>Arora, Megha</dc:creator>
 <dc:creator>Kumaraguru, Ponnurangam</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Over the past couple of years, clicking and posting selfies has become a
popular trend. However, since March 2014, 127 people have died and many have
been injured while trying to click a selfie. Researchers have studied selfies
for understanding the psychology of the authors, and understanding its effect
on social media platforms. In this work, we perform a comprehensive analysis of
the selfie-related casualties and infer various reasons behind these deaths. We
use inferences from incidents and from our understanding of the features, we
create a system to make people more aware of the dangerous situations in which
these selfies are taken. We use a combination of text-based, image-based and
location-based features to classify a particular selfie as dangerous or not.
Our method ran on 3,155 annotated selfies collected on Twitter gave 73%
accuracy. Individually the image-based features were the most informative for
the prediction task. The combination of image-based and location-based features
resulted in the best accuracy. We have made our code and dataset available at
http://labs.precog.iiitd.edu.in/killfie.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01919</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision Tree Classification with Differential Privacy: A Survey</dc:title>
 <dc:creator>Fletcher, Sam</dc:creator>
 <dc:creator>Islam, Md Zahidul</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Data mining information about people is becoming increasingly important in
the data-driven society of the 21st century. Unfortunately, sometimes there are
real-world considerations that conflict with the goals of data mining;
sometimes the privacy of the people being data mined needs to be considered.
This necessitates that the output of data mining algorithms be modified to
preserve privacy while simultaneously not ruining the predictive power of the
outputted model. Differential privacy is a strong, enforceable definition of
privacy that can be used in data mining algorithms, guaranteeing that nothing
will be learned about the people in the data that could not already be
discovered without their participation. In this survey, we focus on one
particular data mining algorithm -- decision trees -- and how differential
privacy interacts with each of the components that constitute decision tree
algorithms. We analyze both greedy and random decision trees, and the conflicts
that arise when trying to balance privacy requirements with the accuracy of the
model.
</dc:description>
 <dc:description>Comment: Pre-print of paper submitted to ACM Computing Surveys, 33 pages</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01929</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Averaged-DQN: Variance Reduction and Stabilization for Deep
  Reinforcement Learning</dc:title>
 <dc:creator>Anschel, Oron</dc:creator>
 <dc:creator>Baram, Nir</dc:creator>
 <dc:creator>Shimkin, Nahum</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Instability and variability of Deep Reinforcement Learning (DRL) algorithms
tend to adversely affect their performance. Averaged-DQN is a simple extension
to the DQN algorithm, based on averaging previously learned Q-values estimates,
which leads to a more stable training procedure and improved performance by
reducing approximation error variance in the target values. To understand the
effect of the algorithm, we examine the source of value function estimation
errors and provide an analytical comparison within a simplified model. We
further present experiments on the Arcade Learning Environment benchmark that
demonstrate significantly improved stability and performance due to the
proposed extension.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01934</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Configuration-LP of the Restricted Assignment Problem</dc:title>
 <dc:creator>Jansen, Klaus</dc:creator>
 <dc:creator>Rohwedder, Lars</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the classical problem of Scheduling on Unrelated Machines. In
this problem a set of jobs is to be distributed among a set of machines and the
maximum load (makespan) is to be minimized. The processing time $p_{ij}$ of a
job $j$ depends on the machine $i$ it is assigned to. Lenstra, Shmoys and
Tardos gave a polynomial time $2$-approximation for this problem. In this paper
we focus on a prominent special case, the Restricted Assignment problem, in
which $p_{ij}\in\{p_j,\infty\}$. The configuration-LP is a linear programming
relaxation for the Restricted Assignment problem. It was shown by Svensson that
the multiplicative gap between integral and fractional solution, the
integrality gap, is at most $2 - 1/17 \approx 1.9412$. In this paper we
significantly simplify his proof and achieve a bound of $2 - 1/6 \approx
1.8333$. As a direct consequence this provides a polynomial $(2 - 1/6 +
\epsilon)$-estimation algorithm for the Restricted Assignment problem by
approximating the configuration-LP. The best lower bound known for the
integrality gap is $1.5$ and no estimation algorithm with a guarantee better
than $1.5$ exists unless $\mathrm{P} = \mathrm{NP}$.
</dc:description>
 <dc:description>Comment: Fixed minor errors</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01935</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skewness of citation impact data and covariates of citation
  distributions: A large-scale empirical analysis based on Web of Science data</dc:title>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Using percentile shares, one can visualize and analyze the skewness in
bibliometric data across disciplines and over time. The resulting figures can
be intuitively interpreted and are more suitable for detailed analysis of the
effects of independent and control variables on distributions than regression
analysis. We show this by using percentile shares to analyze so-called &quot;factors
influencing citation impact&quot; (FICs; e.g., the impact factor of the publishing
journal) across year and disciplines. All articles (n= 2,961,789) covered by
WoS in 1990 (n= 637,301), 2000 (n= 919,485), and 2010 (n= 1,405,003) are used.
In 2010, nearly half of the citation impact is accounted for by the 10%
most-frequently cited papers; the skewness is largest in the humanities (68.5%
in the top-10% layer) and lowest in agricultural sciences (40.6%). The
comparison of the effects of the different FICs (the number of cited
references, number of authors, number of pages, and JIF) on citation impact
shows that JIF has indeed the strongest correlations with the citation scores.
However, the correlation between FICs and citation impact is lower, if
citations are normalized instead of using raw citation counts.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01939</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial-Noise-Aided Secure Transmission in Wiretap Channels with
  Transmitter-Side Correlation</dc:title>
 <dc:creator>Yan, Shihao</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:creator>He, Biao</dc:creator>
 <dc:creator>Abhayapala, Thushara D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work for the first time examines the impact of transmitter-side
correlation on the artificial-noise-aided secure transmission, based on which a
new power allocation strategy for artificial noise (AN) is devised for physical
layer security enhancement. Specifically, we design a correlation-based power
allocation (CPA) for AN, of which the optimality in terms of achieving the
minimum secrecy outage probability is analytically proved in the large system
regime with the number of transmit antennas approaching infinity. In order to
fully reveal the benefits of the CPA, we derive easy-to-evaluate expressions
for the secrecy outage probability achieved by the CPA. Our study demonstrates
that the CPA is nearly optimal and significantly outperforms the widely-used
uniform power allocation (UPA) even for a moderately small number of correlated
transmit antennas. Furthermore, our numerical results reveal a fundamental
difference between the CPA and UPA. That is when the number of correlated
transmit antennas increases, the secrecy outage probability of the CPA always
reduces while the secrecy outage probability of the UPA suffers from a
saturation point.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01942</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepSense: A Unified Deep Learning Framework for Time-Series Mobile
  Sensing Data Processing</dc:title>
 <dc:creator>Yao, Shuochao</dc:creator>
 <dc:creator>Hu, Shaohan</dc:creator>
 <dc:creator>Zhao, Yiran</dc:creator>
 <dc:creator>Zhang, Aston</dc:creator>
 <dc:creator>Abdelzaher, Tarek</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobile sensing applications usually require time-series inputs from sensors.
Some applications, such as tracking, can use sensed acceleration and rate of
rotation to calculate displacement based on physical system models. Other
applications, such as activity recognition, extract manually designed features
from sensor inputs for classification. Such applications face two challenges.
On one hand, on-device sensor measurements are noisy. For many mobile
applications, it is hard to find a distribution that exactly describes the
noise in practice. Unfortunately, calculating target quantities based on
physical system and noise models is only as accurate as the noise assumptions.
Similarly, in classification applications, although manually designed features
have proven to be effective, it is not always straightforward to find the most
robust features to accommodate diverse sensor noise patterns and user
behaviors. To this end, we propose DeepSense, a deep learning framework that
directly addresses the aforementioned noise and feature customization
challenges in a unified manner. DeepSense integrates convolutional and
recurrent neural networks to exploit local interactions among similar mobile
sensors, merge local interactions of different sensory modalities into global
interactions, and extract temporal relationships to model signal dynamics.
DeepSense thus provides a general signal estimation and classification
framework that accommodates a wide range of applications. We demonstrate the
effectiveness of DeepSense using three representative and challenging tasks:
car tracking with motion sensors, heterogeneous human activity recognition, and
user identification with biometric motion analysis. DeepSense significantly
outperforms the state-of-the-art methods for all three tasks. In addition,
DeepSense is feasible to implement on smartphones due to its moderate energy
consumption and low latency
</dc:description>
 <dc:description>Comment: Published in WWW2017. Code available on
  https://github.com/yscacaca/DeepSense</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01947</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPECTRA -a Maple library for solving linear matrix inequalities in exact
  arithmetic</dc:title>
 <dc:creator>Henrion, Didier</dc:creator>
 <dc:creator>Naldi, Simone</dc:creator>
 <dc:creator>Din, Mohab Safey El</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  This document describes our freely distributed Maple library {\sc spectra},
for Semidefinite Programming solved Exactly with Computational Tools of Real
Algebra. It solves linear matrix inequalities with symbolic computation in
exact arithmetic and it is targeted to small-size, possibly degenerate problems
for which symbolic infeasibility or feasibility certificates are required.
</dc:description>
 <dc:description>Comment: Significantly extended version</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01950</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pilot Precoding and Combining in Multiuser MIMO Networks</dc:title>
 <dc:creator>Moghadam, Nima N.</dc:creator>
 <dc:creator>Shokri-Ghadikolaei, Hossein</dc:creator>
 <dc:creator>Fodor, Gabor</dc:creator>
 <dc:creator>Bengtsson, Mats</dc:creator>
 <dc:creator>Fischione, Carlo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Although the benefits of precoding and combining of data signals are widely
recognized, the potential of these techniques for pilot transmission is not
fully understood. This is particularly relevant for multiuser multiple-input
multiple-output (MU-MIMO) cellular systems using millimeter-wave (mmWave)
communications, where multiple antennas will have to be used both at the
transmitter and the receiver to overcome the severe path loss. In this paper,
we characterize the gains of pilot precoding and combining in terms of channel
estimation quality and achievable data rate. Specifically, we consider three
uplink pilot transmission scenarios in a mmWave MU-MIMO cellular system: 1)
non-precoded and uncombined, 2) precoded but uncombined, and 3) precoded and
combined. We show that a simple precoder that utilizes only the second-order
statistics of the channel reduces the variance of the channel estimation error
by a factor that is proportional to the number of user equipment (UE) antennas.
We also show that using a linear combiner designed based on the second-order
statistics of the channel significantly reduces multiuser interference and
provides the possibility of reusing some pilots. Specifically, in the large
antenna regime, pilot precoding and combining help to accommodate a large
number of UEs in one cell, significantly improve channel estimation quality,
boost the signal-to-noise ratio of the UEs located close to the cell edges,
alleviate pilot contamination, and address the imbalanced coverage of pilot and
data signals.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Journal on Selected Areas in Communications</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01957</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Convergence of SVRG in Statistical Estimation</dc:title>
 <dc:creator>Qu, Chao</dc:creator>
 <dc:creator>Li, Yan</dc:creator>
 <dc:creator>Xu, Huan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  SVRG and its variants are among the state of art optimization algorithms for
large scale machine learning problems. It is well known that SVRG converges
linearly when the objective function is strongly convex. However this setup can
be restrictive, and does not include several important formulations such as
Lasso, group Lasso, logistic regression, and some non-convex models including
corrected Lasso and SCAD. In this paper, we prove that, for a class of
statistical M-estimators covering examples mentioned above, SVRG solves the
formulation with {\em a linear convergence rate} without strong convexity or
even convexity. Our analysis makes use of {\em restricted strong convexity},
under which we show that SVRG converges linearly to the fundamental statistical
precision of the model, i.e., the difference between true unknown parameter
$\theta^*$ and the optimal solution $\hat{\theta}$ of the model.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01957</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01960</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Error Correction Scheme for Physical Unclonable Functions</dc:title>
 <dc:creator>M&#xfc;elich, Sven</dc:creator>
 <dc:creator>Bossert, Martin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Error correction is an indispensable component when Physical Unclonable
Functions (PUFs) are used in cryptographic applications. So far, there exist
schemes that obtain helper data, which they need within the error correction
process. We introduce a new scheme, which only uses an error correcting code
without any further helper data. The main idea is to construct for each PUF
instance an individual code which contains the initial PUF response as
codeword. In this work we use LDPC codes, however other code classes are also
possible. Our scheme allows a trade-off between code rate and cryptographic
security. In addition, decoding with linear complexity is possible.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01962</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Resolution Semantic Labeling with Convolutional Neural Networks</dc:title>
 <dc:creator>Maggiori, Emmanuel</dc:creator>
 <dc:creator>Tarabalka, Yuliya</dc:creator>
 <dc:creator>Charpiat, Guillaume</dc:creator>
 <dc:creator>Alliez, Pierre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) have received increasing attention over
the last few years. They were initially conceived for image categorization,
i.e., the problem of assigning a semantic label to an entire input image.
  In this paper we address the problem of dense semantic labeling, which
consists in assigning a semantic label to every pixel in an image. Since this
requires a high spatial accuracy to determine where labels are assigned,
categorization CNNs, intended to be highly robust to local deformations, are
not directly applicable.
  By adapting categorization networks, many semantic labeling CNNs have been
recently proposed. Our first contribution is an in-depth analysis of these
architectures. We establish the desired properties of an ideal semantic
labeling CNN, and assess how those methods stand with regard to these
properties. We observe that even though they provide competitive results, these
CNNs often underexploit properties of semantic labeling that could lead to more
effective and efficient architectures.
  Out of these observations, we then derive a CNN framework specifically
adapted to the semantic labeling problem. In addition to learning features at
different resolutions, it learns how to combine these features. By integrating
local and global information in an efficient and flexible manner, it
outperforms previous techniques. We evaluate the proposed framework and compare
it with state-of-the-art architectures on public benchmarks of high-resolution
aerial image labeling.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01964</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Log-time and Log-space Extreme Classification</dc:title>
 <dc:creator>Jasinska, Kalina</dc:creator>
 <dc:creator>Karampatziakis, Nikos</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present LTLS, a technique for multiclass and multilabel prediction that
can perform training and inference in logarithmic time and space. LTLS embeds
large classification problems into simple structured prediction problems and
relies on efficient dynamic programming algorithms for inference. We train LTLS
with stochastic gradient descent on a number of multiclass and multilabel
datasets and show that despite its small memory footprint it is often
competitive with existing approaches.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01965</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relations Between Work and Entropy Production for General
  Information-Driven, Finite-State Engines</dc:title>
 <dc:creator>Merhav, Neri</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a system model of a general finite-state machine (ratchet) that
simultaneously interacts with three kinds of reservoirs: a heat reservoir, a
work reservoir, and an information reservoir, the latter being taken to be a
running digital tape whose symbols interact sequentially with the machine. As
has been shown in earlier work, this finite-state machine can act as a demon
(with memory), which creates a net flow of energy from the heat reservoir into
the work reservoir (thus extracting useful work) at the price of increasing the
entropy of the information reservoir. Under very few assumptions, we propose a
simple derivation of a family of inequalities that relate the work extraction
with the entropy production. These inequalities can be seen as either upper
bounds on the extractable work or as lower bounds on the entropy production,
depending on the point of view. Many of these bounds are relatively easy to
calculate and they are tight in the sense that equality can be approached
arbitrarily closely. In their basic forms, these inequalities are applicable to
any finite number of cycles (and not only asymptotically), and for a general
input information sequence (possibly correlated), which is not necessarily
assumed even stationary. Several known results are obtained as special cases.
</dc:description>
 <dc:description>Comment: 18 pages, 2 figures, submitted for publication</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01965</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/aa58f3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01967</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularizing CNNs with Locally Constrained Decorrelations</dc:title>
 <dc:creator>Rodr&#xed;guez, Pau</dc:creator>
 <dc:creator>Gonz&#xe0;lez, Jordi</dc:creator>
 <dc:creator>Cucurull, Guillem</dc:creator>
 <dc:creator>Gonfaus, Josep M.</dc:creator>
 <dc:creator>Roca, Xavier</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Regularization is key for deep learning since it allows training more complex
models while keeping lower levels of overfitting. However, the most prevalent
regularizations do not leverage all the capacity of the models since they rely
on reducing the effective number of parameters. Feature decorrelation is an
alternative for using the full capacity of the models but the overfitting
reduction margins are too narrow given the overhead it introduces. In this
paper, we show that regularizing negatively correlated features is an obstacle
for effective decorrelation and present OrthoReg, a novel regularization
technique that locally enforces feature orthogonality. As a result, imposing
locality constraints in feature decorrelation removes interferences between
negatively correlated feature weights, allowing the regularizer to reach higher
decorrelation bounds, and reducing the overfitting more effectively. In
particular, we show that the models regularized with OrthoReg have higher
accuracy bounds even when batch normalization and dropout are present.
Moreover, since our regularization is directly performed on the weights, it is
especially suitable for fully convolutional neural networks, where the weight
space is constant compared to the feature map space. As a result, we are able
to reduce the overfitting of state-of-the-art CNNs on CIFAR-10, CIFAR-100, and
SVHN.
</dc:description>
 <dc:description>Comment: Accepted at ICLR2017</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01969</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite-Horizon Throughput Region for Wireless Multi-User Interference
  Channels</dc:title>
 <dc:creator>Cong, Yirui</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Kennedy, Rodney A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies a wireless network consisting of multiple
transmitter-receiver pairs where interference is treated as noise. Previously,
the throughput region of such networks was characterized for either one time
slot or an infinite time horizon. We aim to fill the gap by investigating the
throughput region for transmissions over a finite time horizon. Unlike the
infinite-horizon throughput region, which is simply the convex hull of the
throughput region of one time slot, the finite-horizon throughput region is
generally non-convex. Instead of directly characterizing all achievable
rate-tuples in the finite-horizon throughput region, we propose a metric termed
the rate margin, which not only determines whether any given rate-tuple is
within the throughput region (i.e., achievable or unachievable), but also tells
the amount of scaling that can be done to the given achievable (unachievable)
rate-tuple such that the resulting rate-tuple is still within (brought back
into) the throughput region. Furthermore, we derive an efficient algorithm to
find the rate-achieving policy for any given rate-tuple in the finite-horizon
throughput region.
</dc:description>
 <dc:description>Comment: The paper is accepted for publication in IEEE Transactions on
  Wireless Communications</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01971</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One Class Splitting Criteria for Random Forests</dc:title>
 <dc:creator>Goix, Nicolas</dc:creator>
 <dc:creator>Drougard, Nicolas</dc:creator>
 <dc:creator>Brault, Romain</dc:creator>
 <dc:creator>Chiapino, Ma&#xeb;l</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Random Forests (RFs) are strong machine learning tools for classification and
regression. However, they remain supervised algorithms, and no extension of RFs
to the one-class setting has been proposed, except for techniques based on
second-class sampling. This work fills this gap by proposing a natural
methodology to extend standard splitting criteria to the one-class setting,
structurally generalizing RFs to one-class classification. An extensive
benchmark of seven state-of-the-art anomaly detection algorithms is also
presented. This empirically demonstrates the relevance of our approach.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01972</identifier>
 <datestamp>2017-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed-point Factorized Networks</dc:title>
 <dc:creator>Wang, Peisong</dc:creator>
 <dc:creator>Cheng, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In recent years, Deep Neural Networks (DNN) based methods have achieved
remarkable performance in a wide range of tasks and have been among the most
powerful and widely used techniques in computer vision. However, DNN-based
methods are both computational-intensive and resource-consuming, which hinders
the application of these methods on embedded systems like smart phones. To
alleviate this problem, we introduce a novel Fixed-point Factorized Networks
(FFN) for pretrained models to reduce the computational complexity as well as
the storage requirement of networks. The resulting networks have only weights
of -1, 0 and 1, which significantly eliminates the most resource-consuming
multiply-accumulate operations (MACs). Extensive experiments on large-scale
ImageNet classification task show the proposed FFN only requires one-thousandth
of multiply operations with comparable accuracy.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01974</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Item-to-item recommendation based on Contextual Fisher Information</dc:title>
 <dc:creator>Dar&#xf3;czy, B&#xe1;lint</dc:creator>
 <dc:creator>Ayala-G&#xf3;mez, Frederick</dc:creator>
 <dc:creator>Bencz&#xfa;r, Andr&#xe1;s</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Web recommendation services bear great importance in e-commerce, as they aid
the user in navigating through the items that are most relevant to her needs.
In a typical Web site, long history of previous activities or purchases by the
user is rarely available. Hence in most cases, recommenders propose items that
are similar to the most recent ones viewed in the current user session. The
corresponding task is called session based item-to-item recommendation. For
frequent items, it is easy to present item-to-item recommendations by &quot;people
who viewed this, also viewed&quot; lists. However, most of the items belong to the
long tail, where previous actions are sparsely available. Another difficulty is
the so-called cold start problem, when the item has recently appeared and had
no time yet to accumulate sufficient number of transactions. In order to
recommend a next item in a session in sparse or cold start situations, we also
have to incorporate item similarity models. In this paper we describe a
probabilistic similarity model based on Random Fields to approximate
item-to-item transition probabilities. We give a generative model for the item
interactions based on arbitrary distance measures over the items including
explicit, implicit ratings and external metadata. The model may change in time
to fit better recent events and recommend the next item based on the updated
Fisher Information. Our new model outperforms both simple similarity baseline
methods and recent item-to-item recommenders, under several different
performance metrics and publicly available data sets. We reach significant
gains in particular for recommending a new item following a rare item.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures, 4 tables</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01982</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chinese/English mixed Character Segmentation as Semantic Segmentation</dc:title>
 <dc:creator>Zheng, Huabin</dc:creator>
 <dc:creator>Wang, Jingyu</dc:creator>
 <dc:creator>Huang, Zhengjie</dc:creator>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Pan, Rong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  OCR character segmentation for multilingual printed documents is difficult
due to the diversity of different linguistic characters. Previous approaches
mainly focus on monolingual texts and are not suitable for multilingual-lingual
cases. In this work, we particularly tackle the Chinese/English mixed case by
reframing it as a semantic segmentation problem. We take advantage of the
successful architecture called fully convolutional networks (FCN) in the field
of semantic segmentation. Given a wide enough receptive field, FCN can utilize
the necessary context around a horizontal position to determinate whether this
is a splitting point or not. As a deep neural architecture, FCN can
automatically learn useful features from raw text line images. Although trained
on synthesized samples with simulated random disturbance, our FCN model
generalizes well to real-world samples. The experimental results show that our
model significantly outperforms the previous methods.
</dc:description>
 <dc:description>Comment: Submitted to CVPR 2017</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01985</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Simultaneous Localization and Synchronization in Mobile
  Agent Networks</dc:title>
 <dc:creator>Etzlinger, Bernhard</dc:creator>
 <dc:creator>Meyer, Florian</dc:creator>
 <dc:creator>Hlawatsch, Franz</dc:creator>
 <dc:creator>Springer, Andreas</dc:creator>
 <dc:creator>Wymeersch, Henk</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Cooperative localization in agent networks based on interagent time-of-flight
measurements is closely related to synchronization. To leverage this relation,
we propose a Bayesian factor graph framework for cooperative simultaneous
localization and synchronization (CoSLAS). This framework is suited to mobile
agents and time-varying local clock parameters. Building on the CoSLAS factor
graph, we develop a distributed (decentralized) belief propagation algorithm
for CoSLAS in the practically important case of an affine clock model and
asymmetric time stamping. Our algorithm allows for real-time operation and is
suitable for a time-varying network connectivity. To achieve high accuracy at
reduced complexity and communication cost, the algorithm combines particle
implementations with parametric message representations and takes advantage of
a conditional independence property. Simulation results demonstrate the good
performance of the proposed algorithm in a challenging scenario with
time-varying network connectivity.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures, 3 tables; manuscript submitted to IEEE
  Transaction on Signal Processing</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01985</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2691665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01988</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentiable Functional Program Interpreters</dc:title>
 <dc:creator>Feser, John K.</dc:creator>
 <dc:creator>Brockschmidt, Marc</dc:creator>
 <dc:creator>Gaunt, Alexander L.</dc:creator>
 <dc:creator>Tarlow, Daniel</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Programming by Example (PBE) is the task of inducing computer programs from
input-output examples. It can be seen as a type of machine learning where the
hypothesis space is the set of legal programs in some programming language.
Recent work on differentiable interpreters relaxes the discrete space of
programs into a continuous space so that search over programs can be performed
using gradient-based optimization. While conceptually powerful, so far
differentiable interpreter-based program synthesis has only been capable of
solving very simple problems. In this work, we study modeling choices that
arise when constructing a differentiable programming language and their impact
on the success of synthesis. The main motivation for the modeling choices comes
from functional programming: we study the effect of memory allocation schemes,
immutable data, type systems, and built-in control-flow structures. Empirically
we show that incorporating functional programming ideas into differentiable
programming languages allows us to learn much more complex programs than is
possible with existing differentiable languages.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01989</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepCoder: Learning to Write Programs</dc:title>
 <dc:creator>Balog, Matej</dc:creator>
 <dc:creator>Gaunt, Alexander L.</dc:creator>
 <dc:creator>Brockschmidt, Marc</dc:creator>
 <dc:creator>Nowozin, Sebastian</dc:creator>
 <dc:creator>Tarlow, Daniel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop a first line of attack for solving programming competition-style
problems from input-output examples using deep learning. The approach is to
train a neural network to predict properties of the program that generated the
outputs from the inputs. We use the neural network's predictions to augment
search techniques from the programming languages community, including
enumerative search and an SMT-based solver. Empirically, we show that our
approach leads to an order of magnitude speedup over the strong non-augmented
baselines and a Recurrent Neural Network approach, and that we are able to
solve problems of difficulty comparable to the simplest problems on programming
competition websites.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2017</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.01990</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hamiltonian operator for spectral shape analysis</dc:title>
 <dc:creator>Choukroun, Yoni</dc:creator>
 <dc:creator>Shtern, Alon</dc:creator>
 <dc:creator>Bronstein, Alex</dc:creator>
 <dc:creator>Kimmel, Ron</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many shape analysis methods treat the geometry of an object as a metric space
that can be captured by the Laplace-Beltrami operator. In this paper, we
propose to adapt the classical Hamiltonian operator from quantum mechanics to
the field of shape analysis. To this end we study the addition of a potential
function to the Laplacian as a generator for dual spaces in which shape
processing is performed. We present a general optimization approach for solving
variational problems involving the basis defined by the Hamiltonian using
perturbation theory for its eigenvectors. The suggested operator is shown to
produce better functional spaces to operate with, as demonstrated on different
shape analysis tasks.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.01990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02001</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-primary Spectrum Sharing for Inter-operator Device-to-Device
  Communication</dc:title>
 <dc:creator>Cho, Byungjin</dc:creator>
 <dc:creator>Koufos, Konstantinos</dc:creator>
 <dc:creator>J&#xe4;ntti, Riku</dc:creator>
 <dc:creator>Kim, Seong-Lyun</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The business potential of device-to-device (D2D) communication including
public safety and vehicular communications will be realized only if direct
communication between devices subscribed to different mobile operators (OPs) is
supported. One possible way to implement inter-operator D2D communication may
use the licensed spectrum of the OPs, i.e., OPs agree to share spectrum in a
co-primary manner, and inter-operator D2D communication is allocated over
spectral resources contributed from both parties. In this paper, we consider a
spectrum sharing scenario where a number of OPs construct a spectrum pool
dedicated to support inter-operator D2D communication. OPs negotiate in the
form of a non-cooperative game about how much spectrum each OP contributes to
the spectrum pool. OPs submit proposals to each other in parallel until a
consensus is reached. When every OP has a concave utility function on the
box-constrained region, we identify the conditions guaranteeing the existence
of a unique equilibrium point. We show that the iterative algorithm based on
the OP's best response might not converge to the equilibrium point due to
myopically overreacting to the response of the other OPs, while the Jacobi-play
strategy update algorithm can converge with an appropriate selection of update
parameter. Using the Jacobi-play update algorithm, we illustrate that
asymmetric OPs contribute an unequal amount of resources to the spectrum pool;
However all participating OPs may experience significant performance gains
compared to the scheme without spectrum sharing.
</dc:description>
 <dc:description>Comment: Accepted to appear in IEEE Journal on Selected Areas in
  Communications (JSAC)</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02002</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximal cliques structure for cocomparability graphs and applications</dc:title>
 <dc:creator>Dusart, J&#xe9;r&#xe9;mie</dc:creator>
 <dc:creator>Habib, Michel</dc:creator>
 <dc:creator>Corneil, Derek G.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C85, 16H20, 68R10</dc:subject>
 <dc:description>  A cocomparability graph is a graph whose complement admits a transitive
orientation. An interval graph is the intersection graph of a family of
intervals on the real line. In this paper we investigate the relationships
between interval and cocomparability graphs. This study is motivated by recent
results Corneil,Dalton, Habib (2013) and Dusart, Habib (2016) and that show
that for some problems, the algorithm used on interval graphs can also be used
with small modifications on cocomparability graphs. Many of these algorithms
are based on graph searches that preserve cocomparability orderings.
  First we propose a characterization of cocomparability graphs via a lattice
structure on the set of their maximal cliques. Using this characterization we
can prove that every maximal interval subgraph of a cocomparability graph $G$
is also a maximal chordal subgraph of $G$. Although the size of this lattice of
maximal cliques can be exponential in the size of the graph, it can be used as
a framework to design and prove algorithms on cocomparability graphs. In
particular we show that a new graph search, namely Local Maximal Neighborhood
Search (LocalMNS) leads to an $O(n+mlogn)$ time algorithm to find a maximal
interval subgraph of a cocomparability graph. Similarly we propose a linear
time algorithm to compute all simplicial vertices in a cocomparability graph.
In both cases we improve on the current state of knowledge.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02007</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Keyphrase Annotation with Graph Co-Ranking</dc:title>
 <dc:creator>Bougouin, Adrien</dc:creator>
 <dc:creator>Boudin, Florian</dc:creator>
 <dc:creator>Daille, B&#xe9;atrice</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Keyphrase annotation is the task of identifying textual units that represent
the main content of a document. Keyphrase annotation is either carried out by
extracting the most important phrases from a document, keyphrase extraction, or
by assigning entries from a controlled domain-specific vocabulary, keyphrase
assignment. Assignment methods are generally more reliable. They provide
better-formed keyphrases, as well as keyphrases that do not occur in the
document. But they are often silent on the contrary of extraction methods that
do not depend on manually built resources. This paper proposes a new method to
perform both keyphrase extraction and keyphrase assignment in an integrated and
mutual reinforcing manner. Experiments have been carried out on datasets
covering different domains of humanities and social sciences. They show
statistically significant improvements compared to both keyphrase extraction
and keyphrase assignment state-of-the art methods.
</dc:description>
 <dc:description>Comment: Accepted at the COLING 2016 conference</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02010</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Analysis of Distributed Inference with Vector-Valued
  Gaussian Belief Propagation</dc:title>
 <dc:creator>Du, Jian</dc:creator>
 <dc:creator>Ma, Shaodan</dc:creator>
 <dc:creator>Wu, Yik-Chung</dc:creator>
 <dc:creator>Kar, Soummya</dc:creator>
 <dc:creator>Moura, Jos&#xe9; M. F.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers inference over distributed linear Gaussian models using
factor graphs and Gaussian belief propagation (BP). The distributed inference
algorithm involves only local computation of the information matrix and of the
mean vector, and message passing between neighbors. Under broad conditions, it
is shown that the message information matrix converges to a unique positive
definite limit matrix for arbitrary positive semidefinite initialization, and
it approaches an arbitrarily small neighborhood of this limit matrix at a
doubly exponential rate. A necessary and sufficient convergence condition for
the belief mean vector to converge to the optimal centralized estimator is
provided under the assumption that the message information matrix is
initialized as a positive semidefinite matrix. Further, it is shown that
Gaussian BP always converges when the underlying factor graph is given by the
union of a forest and a single loop. The proposed convergence condition in the
setup of distributed linear Gaussian models is shown to be strictly weaker than
other existing convergence conditions and requirements, including the Gaussian
Markov random field based walk-summability condition, and applicable to a large
class of scenarios.
</dc:description>
 <dc:description>Comment: 38 pages</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02015</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An analysis of New South Wales electronic vote counting</dc:title>
 <dc:creator>Conway, Andrew</dc:creator>
 <dc:creator>Blom, Michelle</dc:creator>
 <dc:creator>Naish, Lee</dc:creator>
 <dc:creator>Teague, Vanessa</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We re-examine the 2012 local government elections in New South Wales,
Australia. The count was conducted electronically using a randomised form of
the Single Transferable Vote (STV). It was already well known that randomness
does make a difference to outcomes in some seats. We describe how the process
could be amended to include a demonstration that the randomness was chosen
fairly.
  Second, and more significantly, we found an error in the official counting
software, which caused a mistake in the count in the council of Griffith, where
candidate Rina Mercuri narrowly missed out on a seat. We believe the software
error incorrectly decreased Mercuri's winning probability to about
10%---according to our count she should have won with 91% probability.
  The NSW Electoral Commission (NSWEC) corrected their code when we pointed out
the error, and made their own announcement.
  We have since investigated the 2016 local government election (held after
correcting the error above) and found two new errors. We notified the NSWEC
about these errors a few days after they posted the results.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02015</dc:identifier>
 <dc:identifier>doi:10.1145/3014812.3014837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02019</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-view Generative Adversarial Networks</dc:title>
 <dc:creator>Chen, Micka&#xeb;l</dc:creator>
 <dc:creator>Denoyer, Ludovic</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning over multi-view data is a challenging problem with strong practical
applications. Most related studies focus on the classification point of view
and assume that all the views are available at any time. We consider an
extension of this framework in two directions. First, based on the BiGAN model,
the Multi-view BiGAN (MV-BiGAN) is able to perform density estimation from
multi-view inputs. Second, it can deal with missing views and is able to update
its prediction when additional views are provided. We illustrate these
properties on a set of experiments over different datasets.
</dc:description>
 <dc:description>Comment: Submitted at ICLR 2017</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02023</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mean Field Type Control with Congestion (II): An Augmented Lagrangian
  Method</dc:title>
 <dc:creator>Achdou, Yves</dc:creator>
 <dc:creator>Lauriere, Mathieu</dc:creator>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This work deals with a numerical method for solving a mean-field type control
problem with congestion. It is the continuation of an article by the same
authors, in which suitably defined weak solutions of the system of partial
differential equations arising from the model were discussed and existence and
uniqueness were proved. Here, the focus is put on numerical methods: a monotone
finite difference scheme is proposed and shown to have a variational
interpretation. Then an Alternating Direction Method of Multipliers for solving
the variational problem is addressed. It is based on an augmented Lagrangian.
Two kinds of boundary conditions are considered: periodic conditions and more
realistic boundary conditions associated to state constrained problems. Various
test cases and numerical results are presented.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02024</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sigma Delta Quantized Networks</dc:title>
 <dc:creator>O'Connor, Peter</dc:creator>
 <dc:creator>Welling, Max</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68T01</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  Deep neural networks can be obscenely wasteful. When processing video, a
convolutional network expends a fixed amount of computation for each frame with
no regard to the similarity between neighbouring frames. As a result, it ends
up repeatedly doing very similar computations. To put an end to such waste, we
introduce Sigma-Delta networks. With each new input, each layer in this network
sends a discretized form of its change in activation to the next layer. Thus
the amount of computation that the network does scales with the amount of
change in the input and layer activations, rather than the size of the network.
We introduce an optimization method for converting any pre-trained deep network
into an optimally efficient Sigma-Delta network, and show that our algorithm,
if run on the appropriate hardware, could cut at least an order of magnitude
from the computational cost of processing video data.
</dc:description>
 <dc:description>Comment: 9 Pages + 1 Reference + 3 Appendix, 5 figures</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02025</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Presenting a New Dataset for the Timeline Generation Problem</dc:title>
 <dc:creator>Holt, Xavier</dc:creator>
 <dc:creator>Radford, Will</dc:creator>
 <dc:creator>Hachey, Ben</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The timeline generation task summarises an entity's biography by selecting
stories representing key events from a large pool of relevant documents. This
paper addresses the lack of a standard dataset and evaluative methodology for
the problem. We present and make publicly available a new dataset of 18,793
news articles covering 39 entities. For each entity, we provide a gold standard
timeline and a set of entity-related articles. We propose ROUGE as an
evaluation metric and validate our dataset by showing that top Google results
outperform straw-man baselines.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02027</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>:telephone::person::sailboat::whale::okhand:; or &quot;Call me Ishmael&quot; - How
  do you translate emoji?</dc:title>
 <dc:creator>Radford, Will</dc:creator>
 <dc:creator>Chisholm, Andrew</dc:creator>
 <dc:creator>Hachey, Ben</dc:creator>
 <dc:creator>Han, Bo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We report on an exploratory analysis of Emoji Dick, a project that leverages
crowdsourcing to translate Melville's Moby Dick into emoji. This distinctive
use of emoji removes textual context, and leads to a varying translation
quality. In this paper, we use statistical word alignment and part-of-speech
tagging to explore how people use emoji. Despite these simple methods, we
observed differences in token and part-of-speech distributions. Experiments
also suggest that semantics are preserved in the translation, and repetition is
more common in emoji.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02041</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Distributionally Robust Supervised Learning in Classification</dc:title>
 <dc:creator>Hu, Weihua</dc:creator>
 <dc:creator>Niu, Gang</dc:creator>
 <dc:creator>Sato, Issei</dc:creator>
 <dc:creator>Sugiyama, Masashi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Distributionally Robust Supervised Learning (DRSL) is necessary for building
reliable machine learning systems. When machine learning is deployed in the
real world, its performance can be significantly degraded because test data may
follow a different distribution from training data. Previous DRSL minimizes the
loss for the worst-case test distribution. However, our theoretical analyses
show that the previous DRSL essentially reduces to ordinary empirical risk
minimization in a classification scenario. This implies that the previous DRSL
ends up learning classifiers exactly for the given training data even though it
is designed to be robust to distribution shift from the training dataset. In
order to learn practically useful robust classifiers, our theoretical analyses
motivate us to structurally constrain the distribution shift considered by
DRSL. To this end, we propose novel DRSL which can incorporate the structural
assumptions on distribution shift and that can learn useful robust decision
boundaries based on the assumptions. We derive efficient gradient-based
optimization algorithms and establish the convergence rate of the model
parameter as well as the order of the estimation error for our DRSL. The
effectiveness of our DRSL is demonstrated through experiments.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02047</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning Approach for Parallelization in Filters
  Aggregation Based Feature Selection Algorithms</dc:title>
 <dc:creator>Smetannikov, Ivan</dc:creator>
 <dc:creator>Isaev, Ilya</dc:creator>
 <dc:creator>Filchenkov, Andrey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  One of the classical problems in machine learning and data mining is feature
selection. A feature selection algorithm is expected to be quick, and at the
same time it should show high performance. MeLiF algorithm effectively solves
this problem using ensembles of ranking filters. This article describes two
different ways to improve MeLiF algorithm performance with parallelization.
Experiments show that proposed schemes significantly improves algorithm
performance and increase feature selection quality.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02049</identifier>
 <datestamp>2017-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-effort place recognition with WiFi fingerprints using deep learning</dc:title>
 <dc:creator>Nowicki, Micha&#x142;</dc:creator>
 <dc:creator>Wietrzykowski, Jan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Using WiFi signals for indoor localization is the main localization modality
of the existing personal indoor localization systems operating on mobile
devices. WiFi fingerprinting is also used for mobile robots, as WiFi signals
are usually available indoors and can provide rough initial position estimate
or can be used together with other positioning systems. Currently, the best
solutions rely on filtering, manual data analysis, and time-consuming parameter
tuning to achieve reliable and accurate localization. In this work, we propose
to use deep neural networks to significantly lower the work-force burden of the
localization system design, while still achieving satisfactory results.
Assuming the state-of-the-art hierarchical approach, we employ the DNN system
for building/floor classification. We show that stacked autoencoders allow to
efficiently reduce the feature space in order to achieve robust and precise
classification. The proposed architecture is verified on the publicly available
UJIIndoorLoc dataset and the results are compared with other solutions.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02049</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-54042-9_57</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02052</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supervisory Output Prediction for Bilinear Systems by Reinforcement
  Learning</dc:title>
 <dc:creator>Chasparis, Georgios C.</dc:creator>
 <dc:creator>Natschlaeger, Thomas</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Online output prediction is an indispensable part of any model predictive
control implementation, especially when simplifications of the underlying
physical model have been considered and/or the operating conditions change
quite often. Furthermore, the selection of an output prediction model is
strongly related to the data available, while designing/altering the data
collection process may not be an option. Thus, in several scenarios, selecting
the most appropriate prediction model needs to be performed during runtime. To
this end, this paper introduces a supervisory output prediction scheme,
tailored specifically for input-output stable bilinear systems, that intends on
automating the process of selecting the most appropriate prediction model
during runtime. The selection process is based upon a reinforcement-learning
scheme, where prediction models are selected according to their prior
prediction performance. An additional selection process is concerned with
appropriately partitioning the control-inputs' domain in order to also allow
for switched-system approximations of the original bilinear dynamics. We show
analytically that the proposed scheme converges (in probability) to the best
model and partition. We finally demonstrate these properties through
simulations of temperature prediction in residential buildings.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02053</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement-based Simultaneous Algorithm and its Hyperparameters
  Selection</dc:title>
 <dc:creator>Efimova, Valeria</dc:creator>
 <dc:creator>Filchenkov, Andrey</dc:creator>
 <dc:creator>Shalyto, Anatoly</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many algorithms for data analysis exist, especially for classification
problems. To solve a data analysis problem, a proper algorithm should be
chosen, and also its hyperparameters should be selected. In this paper, we
present a new method for the simultaneous selection of an algorithm and its
hyperparameters. In order to do so, we reduced this problem to the multi-armed
bandit problem. We consider an algorithm as an arm and algorithm
hyperparameters search during a fixed time as the corresponding arm play. We
also suggest a problem-specific reward function. We performed the experiments
on 10 real datasets and compare the suggested method with the existing one
implemented in Auto-WEKA. The results show that our method is significantly
better in most of the cases and never worse than the Auto-WEKA.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02054</identifier>
 <datestamp>2017-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adopting the FAB-MAP algorithm for indoor localization with WiFi
  fingerprints</dc:title>
 <dc:creator>Wietrzykowski, Jan</dc:creator>
 <dc:creator>Nowicki, Micha&#x142;</dc:creator>
 <dc:creator>Skrzypczy&#x144;ski, Piotr</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Personal indoor localization is usually accomplished by fusing information
from various sensors. A common choice is to use the WiFi adapter that provides
information about Access Points that can be found in the vicinity.
Unfortunately, state-of-the-art approaches to WiFi-based localization often
employ very dense maps of the WiFi signal distribution, and require a
time-consuming process of parameter selection. On the other hand, camera images
are commonly used for visual place recognition, detecting whenever the user
observes a scene similar to the one already recorded in a database. Visual
place recognition algorithms can work with sparse databases of recorded scenes
and are in general simple to parametrize. Therefore, we propose a WiFi-based
global localization method employing the structure of the well-known FAB-MAP
visual place recognition algorithm. Similarly to FAB-MAP our method uses
Chow-Liu trees to estimate a joint probability distribution of re-observation
of a place given a set of features extracted at places visited so far. However,
we are the first who apply this idea to recorded WiFi scans instead of visual
words. The new method is evaluated on the UJIIndoorLoc dataset used in the
EvAAL competition, allowing fair comparison with other solutions.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02054</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-54042-9_58</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02061</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Visual Place Recognition for Personal Localization on a Mobile
  Device</dc:title>
 <dc:creator>Nowicki, Micha&#x142;</dc:creator>
 <dc:creator>Wietrzykowski, Jan</dc:creator>
 <dc:creator>Skrzypczy&#x144;ski, Piotr</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The paper presents an approach to indoor personal localization on a mobile
device based on visual place recognition. We implemented on a smartphone two
state-of-the-art algorithms that are representative to two different approaches
to visual place recognition: FAB-MAP that recognizes places using individual
images, and ABLE-M that utilizes sequences of images. These algorithms are
evaluated in environments of different structure, focusing on problems commonly
encountered when a mobile device camera is used. The conclusions drawn from
this evaluation are guidelines to design the FastABLE system, which is based on
the ABLE-M algorithm, but introduces major modifications to the concept of
image matching. The improvements radically cut down the processing time and
improve scalability, making it possible to localize the user in long image
sequences with the limited computing power of a mobile device. The resulting
place recognition system compares favorably to both the ABLE-M and the FAB-MAP
solutions in the context of real-time personal localization.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02062</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Information Retrieval from Coded Databases with Colluding
  Servers</dc:title>
 <dc:creator>Freij-Hollanti, Ragnar</dc:creator>
 <dc:creator>Gnilke, Oliver</dc:creator>
 <dc:creator>Hollanti, Camilla</dc:creator>
 <dc:creator>Karpuk, David</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present a general framework for Private Information Retrieval (PIR) from
arbitrary coded databases, that allows one to adjust the rate of the scheme
according to the suspected number of colluding servers. If the storage code is
a generalized Reed-Solomon code of length n and dimension k, we design PIR
schemes which simultaneously protect against t colluding servers and provide
PIR rate 1-(k+t-1)/n, for all t between 1 and n-k. This interpolates between
the previously studied cases of t=1 and k=1 and asymptotically achieves the
known capacity bounds in both of these cases, as the size of the database
grows.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02063</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on Reed's Conjecture about $\omega$, $\Delta$ and $\chi$ with
  respect to vertices of high degree</dc:title>
 <dc:creator>Weil, Vera</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Reed conjectured that for every graph, $\chi \leq \left \lceil \frac{\Delta +
\omega + 1}{2} \right \rceil$ holds, where $\chi$, $\omega$ and $\Delta$ denote
the chromatic number, clique number and maximum degree of the graph,
respectively. We develop an algorithm which takes a hypothetical counterexample
as input. The output discloses some hidden structures closely related to high
vertex degrees. Consequently, we deduce two graph classes where Reed's
Conjecture holds: One contains all graphs in which the vertices of degree at
least $5$ form a stable set. The other contains all graphs in which every
induced cycle of odd length contains a vertex of at most degree 3.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02064</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fully Convolutional Neural Network based Structured Prediction
  Approach Towards the Retinal Vessel Segmentation</dc:title>
 <dc:creator>Dasgupta, Avijit</dc:creator>
 <dc:creator>Singh, Sonam</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic segmentation of retinal blood vessels from fundus images plays an
important role in the computer aided diagnosis of retinal diseases. The task of
blood vessel segmentation is challenging due to the extreme variations in
morphology of the vessels against noisy background. In this paper, we formulate
the segmentation task as a multi-label inference task and utilize the implicit
advantages of the combination of convolutional neural networks and structured
prediction. Our proposed convolutional neural network based model achieves
strong performance and significantly outperforms the state-of-the-art for
automatic retinal blood vessel segmentation on DRIVE dataset with 95.33%
accuracy and 0.974 AUC score.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02071</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Hands-off Control by CLOT Norm Minimization</dc:title>
 <dc:creator>Challapalli, Niharika</dc:creator>
 <dc:creator>Nagahara, Masaaki</dc:creator>
 <dc:creator>Vidyasagar, Mathukumalli</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we consider hands-off control via minimization of the CLOT
(Combined L-One and Two) norm. The maximum hands-off control is the L0-optimal
(or the sparsest) control among all feasible controls that are bounded by a
specified value and transfer the state from a given initial state to the origin
within a fixed time duration. In general, the maximum hands-off control is a
bang-off-bang control taking values of +1, -1, and 0. For many real
applications, such discontinuity in the control is not desirable. To obtain a
continuous but still relatively sparse control, we propose to use the CLOT
norm, a convex combination of L1 and L2 norms. We show by numerical simulation
that the CLOT control is continuous and much sparser (i.e. has longer time
duration on which the control takes 0) than the conventional EN (elastic net)
control, which is a convex combination of L1 and squared L2 norms.
</dc:description>
 <dc:description>Comment: 8 pages, 18 figures, 3 tables</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02072</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-driven Structured Realization</dc:title>
 <dc:creator>Schulze, Philipp</dc:creator>
 <dc:creator>Unger, Benjamin</dc:creator>
 <dc:creator>Beattie, Christopher</dc:creator>
 <dc:creator>Gugercin, Serkan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>93B15, 30E05, 93C05</dc:subject>
 <dc:description>  We present a framework for constructing structured realizations of linear
dynamical systems having transfer functions of the form $C(\sum_{k=1}^K
h_k(s)A_k)^{-1}B$ where $h_1,h_2,\ldots,h_K$ are prescribed functions that
specify the surmised structure of the model. Our construction is data-driven in
the sense that an interpolant is derived entirely from measurements of a
transfer function. Our approach extends the Loewner realization framework to
more general system structure that includes second-order (and higher) systems
as well as systems with internal delays. Numerical examples demonstrate the
advantages of this approach.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02090</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Twitter Sentiment around the Earnings Announcement Events</dc:title>
 <dc:creator>Gabrovsek, Peter</dc:creator>
 <dc:creator>Aleksovski, Darko</dc:creator>
 <dc:creator>Mozetic, Igor</dc:creator>
 <dc:creator>Grcar, Miha</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We investigate the relationship between social media, Twitter in particular,
and stock market. We provide an in-depth analysis of the Twitter volume and
sentiment about the 30 companies in the Dow Jones Industrial Average index,
over a period of three years. We focus on Earnings Announcements and show that
there is a considerable difference with respect to when the announcements are
made: before the market opens or after the market closes. The two different
timings of the Earnings Announcements were already investigated in the
financial literature, but not yet in the social media. We analyze the
differences in terms of the Twitter volumes, cumulative abnormal returns, trade
returns, and earnings surprises.
  We report mixed results. On the one hand, we show that the Twitter sentiment
(the collective opinion of the users) on the day of the announcement very well
reflects the stock moves on the same day. We demonstrate this by applying the
event study methodology, where the polarity of the Earnings Announcements is
computed from the Twitter sentiment. Cumulative abnormal returns are high
(2--4\%) and statistically significant. On the other hand, we find only weak
predictive power of the Twitter sentiment one day in advance. It turns out that
it is important how to account for the announcements made after the market
closes. These after-hours announcements draw high Twitter activity immediately,
but volume and price changes in trading are observed only on the next day. On
the day before the announcements, the Twitter volume is low, and the sentiment
has very weak predictive power. A useful lesson learned is the importance of
the proper alignment between the announcements, trading and Twitter data.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02090</dc:identifier>
 <dc:identifier>PLoS ONE 12(2): e0173151, 2017</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0173151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02091</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building a comprehensive syntactic and semantic corpus of Chinese
  clinical texts</dc:title>
 <dc:creator>He, Bin</dc:creator>
 <dc:creator>Dong, Bin</dc:creator>
 <dc:creator>Guan, Yi</dc:creator>
 <dc:creator>Yang, Jinfeng</dc:creator>
 <dc:creator>Jiang, Zhipeng</dc:creator>
 <dc:creator>Yu, Qiubin</dc:creator>
 <dc:creator>Cheng, Jianyi</dc:creator>
 <dc:creator>Qu, Chunyan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Objective: To build a comprehensive corpus covering syntactic and semantic
annotations of Chinese clinical texts with corresponding annotation guidelines
and methods as well as to develop tools trained on the annotated corpus, which
supplies baselines for research on Chinese texts in the clinical domain.
  Materials and methods: An iterative annotation method was proposed to train
annotators and to develop annotation guidelines. Then, by using annotation
quality assurance measures, a comprehensive corpus was built, containing
annotations of part-of-speech (POS) tags, syntactic tags, entities, assertions,
and relations. Inter-annotator agreement (IAA) was calculated to evaluate the
annotation quality and a Chinese clinical text processing and information
extraction system (CCTPIES) was developed based on our annotated corpus.
  Results: The syntactic corpus consists of 138 Chinese clinical documents with
47,424 tokens and 2553 full parsing trees, while the semantic corpus includes
992 documents that annotated 39,511 entities with their assertions and 7695
relations. IAA evaluation shows that this comprehensive corpus is of good
quality, and the system modules are effective.
  Discussion: The annotated corpus makes a considerable contribution to natural
language processing (NLP) research into Chinese texts in the clinical domain.
However, this corpus has a number of limitations. Some additional types of
clinical text should be introduced to improve corpus coverage and active
learning methods should be utilized to promote annotation efficiency.
  Conclusions: In this study, several annotation guidelines and an annotation
method for Chinese clinical texts were proposed, and a comprehensive corpus
with its NLP modules were constructed, providing a foundation for further study
of applying NLP techniques to Chinese texts in the clinical domain.
</dc:description>
 <dc:description>Comment: 27 pages, submitted to Journal of Biomedical Informatics</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02101</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Coordinate Descent for Generalized Linear Models with
  Regularization</dc:title>
 <dc:creator>Trofimov, Ilya</dc:creator>
 <dc:creator>Genkin, Alexander</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generalized linear model with $L_1$ and $L_2$ regularization is a widely used
technique for solving classification, class probability estimation and
regression problems. With the numbers of both features and examples growing
rapidly in the fields like text mining and clickstream data analysis
parallelization and the use of cluster architectures becomes important. We
present a novel algorithm for fitting regularized generalized linear models in
the distributed environment. The algorithm splits data between nodes by
features, uses coordinate descent on each node and line search to merge results
globally. Convergence proof is provided. A modifications of the algorithm
addresses slow node problem. For an important particular case of logistic
regression we empirically compare our program with several state-of-the art
approaches that rely on different algorithmic and data spitting methods.
Experiments demonstrate that our approach is scalable and superior when
training on large and sparse datasets.
</dc:description>
 <dc:description>Comment: fix typos. arXiv admin note: text overlap with arXiv:1411.6520</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02102</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Texture and Color-based Image Retrieval Using the Local Extrema Features
  and Riemannian Distance</dc:title>
 <dc:creator>Pham, Minh-Tan</dc:creator>
 <dc:creator>Mercier, Gr&#xe9;goire</dc:creator>
 <dc:creator>Bombrun, Lionel</dc:creator>
 <dc:creator>Michel, Julien</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A novel efficient method for content-based image retrieval (CBIR) is
developed in this paper using both texture and color features. Our motivation
is to represent and characterize an input image by a set of local descriptors
extracted at characteristic points (i.e. keypoints) within the image. Then,
dissimilarity measure between images is calculated based on the geometric
distance between the topological feature spaces (i.e. manifolds) formed by the
sets of local descriptors generated from these images. In this work, we propose
to extract and use the local extrema pixels as our feature points. Then, the
so-called local extrema-based descriptor (LED) is generated for each keypoint
by integrating all color, spatial as well as gradient information captured by a
set of its nearest local extrema. Hence, each image is encoded by a LED feature
point cloud and riemannian distances between these point clouds enable us to
tackle CBIR. Experiments performed on Vistex, Stex and colored Brodatz texture
databases using the proposed approach provide very efficient and competitive
results compared to the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to a crucial equation
  modification in part II.B</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02108</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cubical Type Theory: a constructive interpretation of the univalence
  axiom</dc:title>
 <dc:creator>Cohen, Cyril</dc:creator>
 <dc:creator>Coquand, Thierry</dc:creator>
 <dc:creator>Huber, Simon</dc:creator>
 <dc:creator>M&#xf6;rtberg, Anders</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This paper presents a type theory in which it is possible to directly
manipulate $n$-dimensional cubes (points, lines, squares, cubes, etc.) based on
an interpretation of dependent type theory in a cubical set model. This enables
new ways to reason about identity types, for instance, function extensionality
is directly provable in the system. Further, Voevodsky's univalence axiom is
provable in this system. We also explain an extension with some higher
inductive types like the circle and propositional truncation. Finally we
provide semantics for this cubical type theory in a constructive meta-theory.
</dc:description>
 <dc:description>Comment: To be published in the post-proceedings of the 21st International
  Conference on Types for Proofs and Programs, TYPES 2015</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02109</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentiable Programs with Neural Libraries</dc:title>
 <dc:creator>Gaunt, Alexander L.</dc:creator>
 <dc:creator>Brockschmidt, Marc</dc:creator>
 <dc:creator>Kushman, Nate</dc:creator>
 <dc:creator>Tarlow, Daniel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop a framework for combining differentiable programming languages
with neural networks. Using this framework we create end-to-end trainable
systems that learn to write interpretable algorithms with perceptual
components. We explore the benefits of inductive biases for strong
generalization and modularity that come from the program-like structure of our
models. In particular, modularity allows us to learn a library of (neural)
functions which grows and improves as more tasks are solved. Empirically, we
show that this leads to lifelong learning systems that transfer knowledge to
new tasks more effectively than baselines.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02112</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending Two-Variable Logic on Trees</dc:title>
 <dc:creator>Bednarczyk, Bartosz</dc:creator>
 <dc:creator>Charatonik, Witold</dc:creator>
 <dc:creator>Kiero&#x144;ski, Emanuel</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The finite satisfiability problem for the two-variable fragment of
first-order logic interpreted over trees was recently shown to be
ExpSpace-complete. We consider two extensions of this logic. We show that
adding either additional binary symbols or counting quantifiers to the logic
does not affect the complexity of the finite satisfiability problem. However,
combining the two extensions and adding both binary symbols and counting
quantifiers leads to an explosion of this complexity.
  We also compare the expressive power of the two-variable fragment over trees
with its extension with counting quantifiers. It turns out that the two logics
are equally expressive, although counting quantifiers do add expressive power
in the restricted case of unordered trees.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02117</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Bufferbloat Problem over Intermittent Multi-Gbps mmWave Links</dc:title>
 <dc:creator>Zhang, Menglei</dc:creator>
 <dc:creator>Mezzavilla, Marco</dc:creator>
 <dc:creator>Zhu, Jing</dc:creator>
 <dc:creator>Rangan, Sundeep</dc:creator>
 <dc:creator>Panwar, Shivendra</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Due to massive available spectrum in the millimeter wave (mmWave) bands,
cellular systems in these frequencies may provides orders of magnitude greater
capacity than networks in conventional lower frequency bands. However, due to
high susceptibility to blocking, mmWave links can be extremely intermittent in
quality. This combination of high peak throughputs and intermittency can cause
significant challenges in end-to-end transport-layer mechanisms such as TCP.
This paper studies the particularly challenging problem of bufferbloat.
Specifically, with current buffering and congestion control mechanisms, high
throughput-high variable links can lead to excessive buffers incurring long
latency. In this paper, we capture the performance trends obtained while
adopting two potential solutions that have been proposed in the literature:
Active queue management (AQM) and dynamic receive window. We show that, over
mmWave links, AQM mitigates the latency but cannot deliver high throughput. The
main reason relies on the fact that the current congestion control was not
designed to cope with high data rates with sudden change. Conversely, the
dynamic receive window approach is more responsive and therefore supports
higher channel utilization while mitigating the delay, thus representing a
viable solution.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02118</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OpenTED Browser: Insights into European Public Spendings</dc:title>
 <dc:creator>Borgne, Yann-A&#xeb;l Le</dc:creator>
 <dc:creator>Homolova, Adriana</dc:creator>
 <dc:creator>Bontempi, Gianluca</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We present the OpenTED browser, a Web application allowing to interactively
browse public spending data related to public procurements in the European
Union. The application relies on Open Data recently published by the European
Commission and the Publications Office of the European Union, from which we
imported a curated dataset of 4.2 million contract award notices spanning the
period 2006-2015. The application is designed to easily filter notices and
visualise relationships between public contracting authorities and private
contractors. The simple design allows for example to quickly find information
about who the biggest suppliers of local governments are, and the nature of the
contracted goods and services. We believe the tool, which we make Open Source,
is a valuable source of information for journalists, NGOs, analysts and
citizens for getting information on public procurement data, from large scale
trends to local municipal developments.
</dc:description>
 <dc:description>Comment: ECML, PKDD, SoGood workshop 2016</dc:description>
 <dc:date>2016-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02119</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EpistAid: Interactive Interface for Document Filtering in Evidence-based
  Health Care</dc:title>
 <dc:creator>Donoso, Ivania</dc:creator>
 <dc:creator>Parra, Denis</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.m</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Evidence-based health care (EBHC) is an important practice of medicine which
attempts to provide systematic scientific evidence to answer clinical
questions. In this context, Epistemonikos (www.epistemonikos.org) is one of the
first and most important online systems in the field, providing an interface
that supports users on searching and filtering scientific articles for
practicing EBHC. The system nowadays requires a large amount of expert human
effort, where close to 500 physicians manually curate articles to be utilized
in the platform. In order to scale up the large and continuous amount of data
to keep the system updated, we introduce EpistAid, an interactive intelligent
interface which supports clinicians in the process of curating documents for
Epistemonikos within lists of papers called evidence matrices. We introduce the
characteristics, design and algorithms of our solution, as well as a prototype
implementation and a case study to show how our solution addresses the
information overload problem in this area.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, pre-print submitted to ACM IUI 2017</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02120</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Networks Designing Neural Networks: Multi-Objective
  Hyper-Parameter Optimization</dc:title>
 <dc:creator>Smithson, Sean C.</dc:creator>
 <dc:creator>Yang, Guang</dc:creator>
 <dc:creator>Gross, Warren J.</dc:creator>
 <dc:creator>Meyer, Brett H.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Artificial neural networks have gone through a recent rise in popularity,
achieving state-of-the-art results in various fields, including image
classification, speech recognition, and automated control. Both the performance
and computational complexity of such models are heavily dependant on the design
of characteristic hyper-parameters (e.g., number of hidden layers, nodes per
layer, or choice of activation functions), which have traditionally been
optimized manually. With machine learning penetrating low-power mobile and
embedded areas, the need to optimize not only for performance (accuracy), but
also for implementation complexity, becomes paramount. In this work, we present
a multi-objective design space exploration method that reduces the number of
solution networks trained and evaluated through response surface modelling.
Given spaces which can easily exceed 1020 solutions, manually designing a
near-optimal architecture is unlikely as opportunities to reduce network
complexity, while maintaining performance, may be overlooked. This problem is
exacerbated by the fact that hyper-parameters which perform well on specific
datasets may yield sub-par results on others, and must therefore be designed on
a per-application basis. In our work, machine learning is leveraged by training
an artificial neural network to predict the performance of future candidate
networks. The method is evaluated on the MNIST and CIFAR-10 image datasets,
optimizing for both recognition accuracy and computational complexity.
Experimental results demonstrate that the proposed method can closely
approximate the Pareto-optimal front, while only exploring a small fraction of
the design space.
</dc:description>
 <dc:description>Comment: To appear in ICCAD'16. The authoritative version will appear in the
  ACM Digital Library</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02126</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependence and Relevance: A probabilistic view</dc:title>
 <dc:creator>Geiger, Dan</dc:creator>
 <dc:creator>Heckerman, David</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We examine three probabilistic concepts related to the sentence &quot;two
variables have no bearing on each other&quot;. We explore the relationships between
these three concepts and establish their relevance to the process of
constructing similarity networks---a tool for acquiring probabilistic knowledge
from human experts. We also establish a precise relationship between
connectedness in Bayesian networks and relevance in probability.
</dc:description>
 <dc:date>2016-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02145</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowdsourcing in Computer Vision</dc:title>
 <dc:creator>Kovashka, Adriana</dc:creator>
 <dc:creator>Russakovsky, Olga</dc:creator>
 <dc:creator>Fei-Fei, Li</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Computer vision systems require large amounts of manually annotated data to
properly learn challenging visual concepts. Crowdsourcing platforms offer an
inexpensive method to capture human knowledge and understanding, for a vast
number of visual perception tasks. In this survey, we describe the types of
annotations computer vision researchers have collected using crowdsourcing, and
how they have ensured that this data is of high quality while annotation effort
is minimized. We begin by discussing data collection on both classic (e.g.,
object recognition) and recent (e.g., visual story-telling) vision tasks. We
then summarize key design decisions for creating effective data collection
interfaces and workflows, and present strategies for intelligently selecting
the most important data instances to annotate. Finally, we conclude with some
thoughts on the future of crowdsourcing in computer vision.
</dc:description>
 <dc:description>Comment: A 69-page meta review of the field, Foundations and Trends in
  Computer Graphics and Vision, 2016</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02145</dc:identifier>
 <dc:identifier>doi:10.1561/0600000073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02147</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error-Bounded and Feature Preserving Surface Remeshing with Minimal
  Angle Improvement</dc:title>
 <dc:creator>Hu, Kaimo</dc:creator>
 <dc:creator>Yan, Dong-Ming</dc:creator>
 <dc:creator>Bommes, David</dc:creator>
 <dc:creator>Alliez, Pierre</dc:creator>
 <dc:creator>Benes, Bedrich</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  The typical goal of surface remeshing consists in finding a mesh that is (1)
geometrically faithful to the original geometry, (2) as coarse as possible to
obtain a low-complexity representation and (3) free of bad elements that would
hamper the desired application. In this paper, we design an algorithm to
address all three optimization goals simultaneously. The user specifies desired
bounds on approximation error {\delta}, minimal interior angle {\theta} and
maximum mesh complexity N (number of vertices). Since such a desired mesh might
not even exist, our optimization framework treats only the approximation error
bound {\delta} as a hard constraint and the other two criteria as optimization
goals. More specifically, we iteratively perform carefully prioritized local
operators, whenever they do not violate the approximation error bound and
improve the mesh otherwise. In this way our optimization framework greedily
searches for the coarsest mesh with minimal interior angle above {\theta} and
approximation error bounded by {\delta}. Fast runtime is enabled by a local
approximation error estimation, while implicit feature preservation is obtained
by specifically designed vertex relocation operators. Experiments show that our
approach delivers high-quality meshes with implicitly preserved features and
better balances between geometric fidelity, mesh complexity and element quality
than the state-of-the-art.
</dc:description>
 <dc:description>Comment: 14 pages, 20 figures. Submitted to IEEE Transactions on Visualization
  and Computer Graphics</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02154</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Non-parametric model to Target Gamification Notifications Using
  Big Data</dc:title>
 <dc:creator>Nia, Meisam Hejazi</dc:creator>
 <dc:creator>Ratchford, Brian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  I suggest an approach that helps the online marketers to target their
Gamification elements to users by modifying the order of the list of tasks that
they send to users. It is more realistic and flexible as it allows the model to
learn more parameters when the online marketers collect more data. The
targeting approach is scalable and quick, and it can be used over streaming
data.
</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02155</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatiotemporal Residual Networks for Video Action Recognition</dc:title>
 <dc:creator>Feichtenhofer, Christoph</dc:creator>
 <dc:creator>Pinz, Axel</dc:creator>
 <dc:creator>Wildes, Richard P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Two-stream Convolutional Networks (ConvNets) have shown strong performance
for human action recognition in videos. Recently, Residual Networks (ResNets)
have arisen as a new technique to train extremely deep architectures. In this
paper, we introduce spatiotemporal ResNets as a combination of these two
approaches. Our novel architecture generalizes ResNets for the spatiotemporal
domain by introducing residual connections in two ways. First, we inject
residual connections between the appearance and motion pathways of a two-stream
architecture to allow spatiotemporal interaction between the two streams.
Second, we transform pretrained image ConvNets into spatiotemporal networks by
equipping these with learnable convolutional filters that are initialized as
temporal residual connections and operate on adjacent feature maps in time.
This approach slowly increases the spatiotemporal receptive field as the depth
of the model increases and naturally integrates image ConvNet design
principles. The whole model is trained end-to-end to allow hierarchical
learning of complex spatiotemporal features. We evaluate our novel
spatiotemporal ResNet using two widely used action recognition benchmarks where
it exceeds the previous state-of-the-art.
</dc:description>
 <dc:description>Comment: NIPS 2016</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02163</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unrolled Generative Adversarial Networks</dc:title>
 <dc:creator>Metz, Luke</dc:creator>
 <dc:creator>Poole, Ben</dc:creator>
 <dc:creator>Pfau, David</dc:creator>
 <dc:creator>Sohl-Dickstein, Jascha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a method to stabilize Generative Adversarial Networks (GANs) by
defining the generator objective with respect to an unrolled optimization of
the discriminator. This allows training to be adjusted between using the
optimal discriminator in the generator's objective, which is ideal but
infeasible in practice, and using the current value of the discriminator, which
is often unstable and leads to poor solutions. We show how this technique
solves the common problem of mode collapse, stabilizes training of GANs with
complex recurrent generators, and increases diversity and coverage of the data
distribution by the generator.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02167</identifier>
 <datestamp>2017-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing Neural Network Architectures using Reinforcement Learning</dc:title>
 <dc:creator>Baker, Bowen</dc:creator>
 <dc:creator>Gupta, Otkrist</dc:creator>
 <dc:creator>Naik, Nikhil</dc:creator>
 <dc:creator>Raskar, Ramesh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  At present, designing convolutional neural network (CNN) architectures
requires both human expertise and labor. New architectures are handcrafted by
careful experimentation or modified from a handful of existing networks. We
introduce MetaQNN, a meta-modeling algorithm based on reinforcement learning to
automatically generate high-performing CNN architectures for a given learning
task. The learning agent is trained to sequentially choose CNN layers using
$Q$-learning with an $\epsilon$-greedy exploration strategy and experience
replay. The agent explores a large but finite space of possible architectures
and iteratively discovers designs with improved performance on the learning
task. On image classification benchmarks, the agent-designed networks
(consisting of only standard convolution, pooling, and fully-connected layers)
beat existing networks designed with the same layer types and are competitive
against the state-of-the-art methods that use more complex layer types. We also
outperform existing meta-modeling approaches for network design on image
classification tasks.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02174</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parse Geometry from a Line: Monocular Depth Estimation with Partial
  Laser Observation</dc:title>
 <dc:creator>Liao, Yiyi</dc:creator>
 <dc:creator>Huang, Lichao</dc:creator>
 <dc:creator>Wang, Yue</dc:creator>
 <dc:creator>Kodagoda, Sarath</dc:creator>
 <dc:creator>Yu, Yinan</dc:creator>
 <dc:creator>Liu, Yong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Many standard robotic platforms are equipped with at least a fixed 2D laser
range finder and a monocular camera. Although those platforms do not have
sensors for 3D depth sensing capability, knowledge of depth is an essential
part in many robotics activities. Therefore, recently, there is an increasing
interest in depth estimation using monocular images. As this task is inherently
ambiguous, the data-driven estimated depth might be unreliable in robotics
applications. In this paper, we have attempted to improve the precision of
monocular depth estimation by introducing 2D planar observation from the
remaining laser range finder without extra cost. Specifically, we construct a
dense reference map from the sparse laser range data, redefining the depth
estimation task as estimating the distance between the real and the reference
depth. To solve the problem, we construct a novel residual of residual neural
network, and tightly combine the classification and regression losses for
continuous depth estimation. Experimental results suggest that our method
achieves considerable promotion compared to the state-of-the-art methods on
both NYUD2 and KITTI, validating the effectiveness of our method on leveraging
the additional sensory information. We further demonstrate the potential usage
of our method in obstacle avoidance where our methodology provides
comprehensive depth information compared to the solution using monocular camera
or 2D laser range finder alone.
</dc:description>
 <dc:date>2016-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02177</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Markov Decision Process Model to Guide Treatment of Abdominal Aortic
  Aneurysms</dc:title>
 <dc:creator>Mattila, Robert</dc:creator>
 <dc:creator>Siika, Antti</dc:creator>
 <dc:creator>Roy, Joy</dc:creator>
 <dc:creator>Wahlberg, Bo</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Quantitative Biology - Other Quantitative Biology</dc:subject>
 <dc:description>  An abdominal aortic aneurysm (AAA) is an enlargement of the abdominal aorta
which, if left untreated, can progressively widen and may rupture with fatal
consequences. In this paper, we determine an optimal treatment policy using
Markov decision process modeling. The policy is optimal with respect to the
number of quality adjusted life-years (QALYs) that are expected to be
accumulated during the remaining life of a patient. The new policy takes into
account factors that are ignored by the current clinical policy (e.g. the
life-expectancy and the age-dependent surgical mortality). The resulting
optimal policy is structurally different from the current policy. In
particular, the policy suggests that young patients with small aneurysms should
undergo surgery. The robustness of the policy structure is demonstrated using
simulations. A gain in the number of expected QALYs is shown, which indicates a
possibility of improved care for patients with AAAs.
</dc:description>
 <dc:description>Comment: This is an extended version of the work presented at the 2016 IEEE
  Conference on Control Applications (CCA 2016)</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02177</dc:identifier>
 <dc:identifier>doi:10.1109/CCA.2016.7587869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02181</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Social Dynamics to Make Individual Predictions: Variational
  Inference with a Stochastic Kinetic Model</dc:title>
 <dc:creator>Xu, Zhen</dc:creator>
 <dc:creator>Dong, Wen</dc:creator>
 <dc:creator>Srihari, Sargur</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Social dynamics is concerned primarily with interactions among individuals
and the resulting group behaviors, modeling the temporal evolution of social
systems via the interactions of individuals within these systems. In
particular, the availability of large-scale data from social networks and
sensor networks offers an unprecedented opportunity to predict state-changing
events at the individual level. Examples of such events include disease
transmission, opinion transition in elections, and rumor propagation. Unlike
previous research focusing on the collective effects of social systems, this
study makes efficient inferences at the individual level. In order to cope with
dynamic interactions among a large number of individuals, we introduce the
stochastic kinetic model to capture adaptive transition probabilities and
propose an efficient variational inference algorithm the complexity of which
grows linearly --- rather than exponentially --- with the number of
individuals. To validate this method, we have performed epidemic-dynamics
experiments on wireless sensor network data collected from more than ten
thousand people over three years. The proposed algorithm was used to track
disease transmission and predict the probability of infection for each
individual. Our results demonstrate that this method is more efficient than
sampling while nonetheless achieving high accuracy.
</dc:description>
 <dc:description>Comment: In proceedings of 29th Conference on Neural Information Processing
  Systems (NIPS 2016)</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02185</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trusting SVM for Piecewise Linear CNNs</dc:title>
 <dc:creator>Berrada, Leonard</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:creator>Kumar, M. Pawan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a novel layerwise optimization algorithm for the learning
objective of Piecewise-Linear Convolutional Neural Networks (PL-CNNs), a large
class of convolutional neural networks. Specifically, PL-CNNs employ piecewise
linear non-linearities such as the commonly used ReLU and max-pool, and an SVM
classifier as the final layer. The key observation of our approach is that the
problem corresponding to the parameter estimation of a layer can be formulated
as a difference-of-convex (DC) program, which happens to be a latent structured
SVM. We optimize the DC program using the concave-convex procedure, which
requires us to iteratively solve a structured SVM problem. This allows to
design an optimization algorithm with an optimal learning rate that does not
require any tuning. Using the MNIST, CIFAR and ImageNet data sets, we show that
our approach always improves over the state of the art variants of
backpropagation and scales to large data and large network settings.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02189</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CoCoA: A General Framework for Communication-Efficient Distributed
  Optimization</dc:title>
 <dc:creator>Smith, Virginia</dc:creator>
 <dc:creator>Forte, Simone</dc:creator>
 <dc:creator>Ma, Chenxin</dc:creator>
 <dc:creator>Takac, Martin</dc:creator>
 <dc:creator>Jordan, Michael I.</dc:creator>
 <dc:creator>Jaggi, Martin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The scale of modern datasets necessitates the development of efficient
distributed optimization methods for machine learning. We present a
general-purpose framework for the distributed environment, CoCoA, that has an
efficient communication scheme and is applicable to a wide variety of problems
in machine learning and signal processing. We extend the framework to cover
general non-strongly convex regularizers, including L1-regularized problems
like lasso, sparse logistic regression, and elastic net regularization, and
show how earlier work can be derived as a special case. We provide convergence
guarantees for the class of convex regularized loss minimization objectives,
leveraging a novel approach in handling non-strongly convex regularizers and
non-smooth loss functions. The resulting framework has markedly improved
performance over state-of-the-art methods, as we illustrate with an extensive
set of experiments on real distributed datasets.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02200</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Cross-Domain Image Generation</dc:title>
 <dc:creator>Taigman, Yaniv</dc:creator>
 <dc:creator>Polyak, Adam</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of transferring a sample in one domain to an analog
sample in another domain. Given two related domains, S and T, we would like to
learn a generative function G that maps an input sample from S to the domain T,
such that the output of a given function f, which accepts inputs in either
domains, would remain unchanged. Other than the function f, the training data
is unsupervised and consist of a set of samples from each domain. The Domain
Transfer Network (DTN) we present employs a compound loss function that
includes a multiclass GAN loss, an f-constancy component, and a regularizing
component that encourages G to map samples from T to themselves. We apply our
method to visual domains including digits and face images and demonstrate its
ability to generate convincing novel images of previously unseen entities,
while preserving their identity.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02205</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Playing SNES in the Retro Learning Environment</dc:title>
 <dc:creator>Bhonker, Nadav</dc:creator>
 <dc:creator>Rozenberg, Shai</dc:creator>
 <dc:creator>Hubara, Itay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Mastering a video game requires skill, tactics and strategy. While these
attributes may be acquired naturally by human players, teaching them to a
computer program is a far more challenging task. In recent years, extensive
research was carried out in the field of reinforcement learning and numerous
algorithms were introduced, aiming to learn how to perform human tasks such as
playing video games. As a result, the Arcade Learning Environment (ALE)
(Bellemare et al., 2013) has become a commonly used benchmark environment
allowing algorithms to train on various Atari 2600 games. In many games the
state-of-the-art algorithms outperform humans. In this paper we introduce a new
learning environment, the Retro Learning Environment --- RLE, that can run
games on the Super Nintendo Entertainment System (SNES), Sega Genesis and
several other gaming consoles. The environment is expandable, allowing for more
video games and consoles to be easily added to the environment, while
maintaining the same interface as ALE. Moreover, RLE is compatible with Python
and Torch. SNES games pose a significant challenge to current algorithms due to
their higher level of complexity and versatility.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02216</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterization and linear-time detection of minimal obstructions to
  concave-round graphs and the circular-ones property</dc:title>
 <dc:creator>Safe, Mart&#xed;n D.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C75, 05B20, 05C85</dc:subject>
 <dc:description>  A graph is concave-round if its vertices can be circularly enumerated so that
the closed neighbourhood of each vertex is an interval in the enumeration. In
this work, we give a minimal forbidden induced subgraph characterization for
the class of concave-round graphs, solving a problem posed by Bang-Jensen,
Huang, and Yeo [SIAM J Discrete Math, 13:179--193, 2000]. In addition, we show
that it is possible to find one such forbidden induced subgraph in linear time
in any given graph that is not concave-round. As part of the analysis, we
obtain characterizations by minimal forbidden submatrices for the circular-ones
property for rows and for the circular-ones property for rows and columns and
show that, also for both variants of the property, one of the corresponding
forbidden submatrices can be found (if present) in any given matrix in linear
time. We make some final remarks regarding connections to some classes of
circular-arc graphs.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02221</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimax-optimal semi-supervised regression on unknown manifolds</dc:title>
 <dc:creator>Moscovich, Amit</dc:creator>
 <dc:creator>Jaffe, Ariel</dc:creator>
 <dc:creator>Nadler, Boaz</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>62G08</dc:subject>
 <dc:description>  We consider semi-supervised regression when the predictor variables are drawn
from an unknown manifold. A simple two step approach to this problem is to: (i)
estimate the manifold geodesic distance between any pair of points using both
the labeled and unlabeled instances; and (ii) apply a k nearest neighbor
regressor based on these distance estimates. We prove that given sufficiently
many unlabeled points, this simple method of geodesic kNN regression achieves
the optimal finite-sample minimax bound on the mean squared error, as if the
manifold were known. Furthermore, we show how this approach can be efficiently
implemented, requiring only O(k N log N) operations to estimate the regression
function at all N labeled and unlabeled points. We illustrate this approach on
two datasets with a manifold structure: indoor localization using WiFi
fingerprints and facial pose estimation. In both cases, geodesic kNN is more
accurate and much faster than the popular Laplacian eigenvector regressor.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02247</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic</dc:title>
 <dc:creator>Gu, Shixiang</dc:creator>
 <dc:creator>Lillicrap, Timothy</dc:creator>
 <dc:creator>Ghahramani, Zoubin</dc:creator>
 <dc:creator>Turner, Richard E.</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Model-free deep reinforcement learning (RL) methods have been successful in a
wide variety of simulated domains. However, a major obstacle facing deep RL in
the real world is their high sample complexity. Batch policy gradient methods
offer stable learning, but at the cost of high variance, which often requires
large batches. TD-style methods, such as off-policy actor-critic and
Q-learning, are more sample-efficient but biased, and often require costly
hyperparameter sweeps to stabilize. In this work, we aim to develop methods
that combine the stability of policy gradients with the efficiency of
off-policy RL. We present Q-Prop, a policy gradient method that uses a Taylor
expansion of the off-policy critic as a control variate. Q-Prop is both sample
efficient and stable, and effectively combines the benefits of on-policy and
off-policy methods. We analyze the connection between Q-Prop and existing
model-free algorithms, and use control variate theory to derive two variants of
Q-Prop with conservative and aggressive adaptation. We show that conservative
Q-Prop provides substantial gains in sample efficiency over trust region policy
optimization (TRPO) with generalized advantage estimation (GAE), and improves
stability over deep deterministic policy gradient (DDPG), the state-of-the-art
on-policy and off-policy methods, on OpenAI Gym's MuJoCo continuous control
environments.
</dc:description>
 <dc:description>Comment: Conference Paper at the International Conference on Learning
  Representations (ICLR) 2017</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02252</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical compositional feature learning</dc:title>
 <dc:creator>L&#xe1;zaro-Gredilla, Miguel</dc:creator>
 <dc:creator>Liu, Yi</dc:creator>
 <dc:creator>Phoenix, D. Scott</dc:creator>
 <dc:creator>George, Dileep</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce the hierarchical compositional network (HCN), a directed
generative model able to discover and disentangle, without supervision, the
building blocks of a set of binary images. The building blocks are binary
features defined hierarchically as a composition of some of the features in the
layer immediately below, arranged in a particular manner. At a high level, HCN
is similar to a sigmoid belief network with pooling. Inference and learning in
HCN are very challenging and existing variational approximations do not work
satisfactorily. A main contribution of this work is to show that both can be
addressed using max-product message passing (MPMP) with a particular schedule
(no EM required). Also, using MPMP as an inference engine for HCN makes new
tasks simple: adding supervision information, classifying images, or performing
inpainting all correspond to clamping some variables of the model to their
known values and running MPMP on the rest. When used for classification, fast
inference with HCN has exactly the same functional form as a convolutional
neural network (CNN) with linear activations and binary weights. However, HCN's
features are qualitatively very different.
</dc:description>
 <dc:description>Comment: Removed the &quot;under review&quot; header from every page, no changes to
  content</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02256</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Big-Data Approach to Handle Many Process Variations: Tensor Recovery
  and Applications</dc:title>
 <dc:creator>Zhang, Zheng</dc:creator>
 <dc:creator>Weng, Tsui-Wei</dc:creator>
 <dc:creator>Daniel, Luca</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Fabrication process variations are a major source of yield degradation in the
nano-scale design of integrated circuits (IC), microelectromechanical systems
(MEMS) and photonic circuits. Stochastic spectral methods are a promising
technique to quantify the uncertainties caused by process variations. Despite
their superior efficiency over Monte Carlo for many design cases, these
algorithms suffer from the curse of dimensionality; i.e., their computational
cost grows very fast as the number of random parameters increases. In order to
solve this challenging problem, this paper presents a high-dimensional
uncertainty quantification algorithm from a big-data perspective. Specifically,
we show that the huge number of (e.g., $1.5 \times 10^{27}$) simulation samples
in standard stochastic collocation can be reduced to a very small one (e.g.,
$500$) by exploiting some hidden structures of a high-dimensional data array.
This idea is formulated as a tensor recovery problem with sparse and low-rank
constraints; and it is solved with an alternating minimization approach.
Numerical results show that our approach can simulate efficiently some ICs, as
well as MEMS and photonic problems with over 50 independent random parameters,
whereas the traditional algorithm can only handle several random parameters.
</dc:description>
 <dc:description>Comment: 8 figures</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02256</dc:identifier>
 <dc:identifier>IEEE Transactions on Component, Packaging and Manufacturing
  Technology, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02257</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiround Private Information Retrieval: Capacity and Storage Overhead</dc:title>
 <dc:creator>Sun, Hua</dc:creator>
 <dc:creator>Jafar, Syed A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The capacity has recently been characterized for the private information
retrieval (PIR) problem as well as several of its variants. In every case it is
assumed that all the queries are generated by the user simultaneously. Here we
consider multiround PIR, where the queries in each round are allowed to depend
on the answers received in previous rounds. We show that the capacity of
multiround PIR is the same as the capacity of single-round PIR (the result is
generalized to also include $T$-privacy constraints). Combined with previous
results, this shows that there is no capacity advantage from multiround over
single-round schemes, non-linear over linear schemes or from $\epsilon$-error
over zero-error schemes. However, we show through an example that there is an
advantage in terms of storage overhead. We provide an example of a multiround,
non-linear, $\epsilon$-error PIR scheme that requires a strictly smaller
storage overhead than the best possible with single-round, linear, zero-error
PIR schemes.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02258</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Time Series Detection Models from Temporally Imprecise Labels</dc:title>
 <dc:creator>Adams, Roy J.</dc:creator>
 <dc:creator>Marlin, Benjamin M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we consider a new low-quality label learning problem: learning
time series detection models from temporally imprecise labels. In this problem,
the data consist of a set of input time series, and supervision is provided by
a sequence of noisy time stamps corresponding to the occurrence of positive
class events. Such temporally imprecise labels commonly occur in areas like
mobile health research where human annotators are tasked with labeling the
occurrence of very short duration events. We propose a general learning
framework for this problem that can accommodate different base classifiers and
noise models. We present results on real mobile health data showing that the
proposed framework significantly outperforms a number of alternatives including
assuming that the label time stamps are noise-free, transforming the problem
into the multiple instance learning framework, and learning on labels that were
manually re-aligned.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02260</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meat adulteration detection through digital image analysis of
  histological cuts using LBP</dc:title>
 <dc:creator>Neto, Jo&#xe3;o J. de Macedo</dc:creator>
 <dc:creator>Santos, Jefersson A. dos</dc:creator>
 <dc:creator>Schwartz, William Robson</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Food fraud has been an area of great concern due to its risk to public
health, reduction of food quality or nutritional value and for its economic
consequences. For this reason, it's been object of regulation in many countries
(e.g. [1], [2]). One type of food that has been frequently object of fraud
through the addition of water or an aqueous solution is bovine meat. The
traditional methods used to detect this kind of fraud are expensive,
time-consuming and depend on physicochemical analysis that require complex
laboratory techniques, specific for each added substance. In this paper, based
on digital images of histological cuts of adulterated and not-adulterated
(normal) bovine meat, we evaluate the of digital image analysis methods to
identify the aforementioned kind of fraud, with focus on the Local Binary
Pattern (LBP) algorithm.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02261</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory-augmented Attention Modelling for Videos</dc:title>
 <dc:creator>Fakoor, Rasool</dc:creator>
 <dc:creator>Mohamed, Abdel-rahman</dc:creator>
 <dc:creator>Mitchell, Margaret</dc:creator>
 <dc:creator>Kang, Sing Bing</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We present a method to improve video description generation by modeling
higher-order interactions between video frames and described concepts. By
storing past visual attention in the video associated to previously generated
words, the system is able to decide what to look at and describe in light of
what it has already looked at and described. This enables not only more
effective local attention, but tractable consideration of the video sequence
while generating each word. Evaluation on the challenging and popular MSVD and
Charades datasets demonstrates that the proposed architecture outperforms
previous video description approaches without requiring external temporal video
features.
</dc:description>
 <dc:description>Comment: Revised version, minor changes, add the link for the source codes</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02266</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Attention Model and Its Application to Knowledge Base Embedding
  and Question Answering</dc:title>
 <dc:creator>Zhang, Liwen</dc:creator>
 <dc:creator>Winn, John</dc:creator>
 <dc:creator>Tomioka, Ryota</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose the Gaussian attention model for content-based neural memory
access. With the proposed attention model, a neural network has the additional
degree of freedom to control the focus of its attention from a laser sharp
attention to a broad attention. It is applicable whenever we can assume that
the distance in the latent space reflects some notion of semantics. We use the
proposed attention model as a scoring function for the embedding of a knowledge
base into a continuous vector space and then train a model that performs
question answering about the entities in the knowledge base. The proposed
attention model can handle both the propagation of uncertainty when following a
series of relations and also the conjunction of conditions in a natural way. On
a dataset of soccer players who participated in the FIFA World Cup 2014, we
demonstrate that our model can handle both path queries and conjunctive queries
well.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02268</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Binary Autoencoding with Pairwise Correlations</dc:title>
 <dc:creator>Balsubramani, Akshay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We formulate learning of a binary autoencoder as a biconvex optimization
problem which learns from the pairwise correlations between encoded and decoded
bits. Among all possible algorithms that use this information, ours finds the
autoencoder that reconstructs its inputs with worst-case optimal loss. The
optimal decoder is a single layer of artificial neurons, emerging entirely from
the minimax loss minimization, and with weights learned by convex optimization.
All this is reflected in competitive experimental results, demonstrating that
binary autoencoding can be done efficiently by conveying information in
pairwise correlations in an optimal fashion.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02272</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neuromorphic Silicon Photonic Networks</dc:title>
 <dc:creator>Tait, Alexander N.</dc:creator>
 <dc:creator>de Lima, Thomas Ferreira</dc:creator>
 <dc:creator>Zhou, Ellen</dc:creator>
 <dc:creator>Wu, Allie X.</dc:creator>
 <dc:creator>Nahmias, Mitchell A.</dc:creator>
 <dc:creator>Shastri, Bhavin J.</dc:creator>
 <dc:creator>Prucnal, Paul R.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  Photonic systems for high-performance information processing have attracted
renewed interest. Neuromorphic silicon photonics has the potential to integrate
processing functions that vastly exceed the capabilities of electronics. We
report first observations of a recurrent silicon photonic neural network, in
which connections are configured by microring weight banks. A mathematical
isomorphism between the silicon photonic circuit and a continuous neural
network model is demonstrated through dynamical bifurcation analysis.
Exploiting this isomorphism, a simulated 24-node silicon photonic neural
network is programmed using &quot;neural compiler&quot; to solve a differential system
emulation task. A 294-fold acceleration against a conventional benchmark is
predicted. We also propose and derive power consumption analysis for
modulator-class neurons that, as opposed to laser-class neurons, are compatible
with silicon photonic platforms. At increased scale, Neuromorphic silicon
photonics could access new regimes of ultrafast information processing for
radio, control, and scientific computing.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, accepted in Scientific Reports</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02272</dc:identifier>
 <dc:identifier>Sci.Rep. 7 (2017) 7430</dc:identifier>
 <dc:identifier>doi:10.1038/s41598-017-07754-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02273</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application-layer Fault-Tolerance Protocols</dc:title>
 <dc:creator>De Florio, Vincenzo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The central topic of this book is application-level fault-tolerance, that is
the methods, architectures, and tools that allow to express a fault-tolerant
system in the application software of our computers. Application-level
fault-tolerance is a sub-class of software fault-tolerance that focuses on the
problems of expressing the problems and solutions of fault-tolerance in the top
layer of the hierarchy of virtual machines that constitutes our computers. This
book shows that application-level fault-tolerance is a key ingredient to craft
truly dependable computer systems--other approaches, such as hardware
fault-tolerance, operating system fault-tolerance, or fault-tolerant
middleware, are also important ingredients to achieve resiliency, but they are
not enough. Failing to address the application layer means leaving a backdoor
open to problems such as design faults, interaction faults, or malicious
attacks, whose consequences on the quality of service could be as unfortunate
as, e.g., a physical fault affecting the system platform. In other words, in
most cases it is simply not possible to achieve complete coverage against a
given set of faults or erroneous conditions without embedding fault-tolerance
provisions also in the application layer.
</dc:description>
 <dc:description>Comment: Preprint of &quot;Application-layer Fault-Tolerance Protocols&quot;, De Florio
  V., IGI Global, Hershey, PA 17033, USA, January 2009. ISBN:
  978-1-60566-182-7. 378 pages. arXiv admin note: substantial text overlap with
  arXiv:1611.01690</dc:description>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02274</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GPU-Based Parallel Integration of Large Numbers of Independent ODE
  Systems</dc:title>
 <dc:creator>Niemeyer, Kyle E</dc:creator>
 <dc:creator>Sung, Chih-Jen</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>80A32 (Primary) 80A30, 65L04, 65L06 (Secondary)</dc:subject>
 <dc:description>  The task of integrating a large number of independent ODE systems arises in
various scientific and engineering areas. For nonstiff systems, common explicit
integration algorithms can be used on GPUs, where individual GPU threads
concurrently integrate independent ODEs with different initial conditions or
parameters. One example is the fifth-order adaptive Runge-Kutta-Cash-Karp
(RKCK) algorithm. In the case of stiff ODEs, standard explicit algorithms
require impractically small time-step sizes for stability reasons, and implicit
algorithms are therefore commonly used instead to allow larger time steps and
reduce the computational expense. However, typical high-order implicit
algorithms based on backwards differentiation formulae (e.g., VODE, LSODE)
involve complex logical flow that causes severe thread divergence when
implemented on GPUs, limiting the performance. Therefore, alternate algorithms
are needed. A GPU-based Runge-Kutta-Chebyshev (RKC) algorithm can handle
moderate levels of stiffness and performs significantly faster than not only an
equivalent CPU version but also a CPU-based implicit algorithm (VODE) based on
results shown in the literature. In this chapter, we present the mathematical
background, implementation details, and source code for the RKCK and RKC
algorithms for use integrating large numbers of independent systems of ODEs on
GPUs. In addition, brief performance comparisons are shown for each algorithm,
demonstrating the potential benefit of moving to GPU-based ODE integrators.
</dc:description>
 <dc:description>Comment: 21 pages, 2 figures</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02274</dc:identifier>
 <dc:identifier>Numerical Computations with GPUs, Ch. 8 (2014) 159-182. V
  Kindratenko (Ed.)</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-06548-9_8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02275</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Application Offloading through Ant-inspired Decision-Making</dc:title>
 <dc:creator>Golchay, Roya</dc:creator>
 <dc:creator>Mou&#xeb;l, Fr&#xe9;d&#xe9;ric Le</dc:creator>
 <dc:creator>Ponge, Julien</dc:creator>
 <dc:creator>Stouls, Nicolas</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  -The explosive trend of smartphone usage as the most effective and convenient
communication tools of human life in recent years make developers build ever
more complex smartphone applications. Gaming, navigation, video editing,
augmented reality, and speech recognition applications require considerable
computational power and energy. Although smart- phones have a wide range of
capabilities - GPS, WiFi, cameras - their inherent limitations - frequent
disconnections, mobility - and significant constraints - size, lower weights,
longer battery life - make difficult to exploiting their full potential to run
complex applications. Several research works have proposed solutions in
application offloading domain, but few ones concerning the highly changing
properties of the environment. To address these issues, we realize an automated
application offloading middleware, ACOMMA, with dynamic and re-adaptable
decision-making engine. The decision engine of ACOMMA is based on an ant-
inspired algorithm.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02275</dc:identifier>
 <dc:identifier>Proceedings of the 13th International Conference on New
  Technologies in Distributed Systems (NOTERE'2016), Jul 2016, Paris, France</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02302</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum spectral analysis: frequency at time (a lecture)</dc:title>
 <dc:creator>Mastriani, Mario</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A quantum time-dependent spectrum analysis, or simply, quantum spectral
analysis (QuSA) is presented in this work, and it is based on Schrodinger
equation, which is a partial differential equation that describes how the
quantum state of a non-relativistic physical system changes with time. In
classic world is named frequency at time (FAT), which is presented here in
opposition and as a complement of traditional spectral analysis
frequency-dependent based on Fourier theory. Besides, FAT is a metric, which
assesses the impact of the flanks of a signal on its frequency spectrum, which
is not taken into account by Fourier theory and even less in real time. Even
more, and unlike all derived tools from Fourier Theory (i.e., continuous,
discrete, fast, short-time, fractional and quantum Fourier Transform, as well
as, Gabor) FAT has the following advantages: a) compact support with excellent
energy output treatment, b) low computational cost, O(N) for signals and O(N2)
for images, c) it does not have phase uncertainties (indeterminate phase for
magnitude = 0) as Discrete and Fast Fourier Transform (DFT, FFT, respectively),
d) among others. In fact, FAT constitutes one side of a triangle (which from
now on is closed) and it consists of the original signal in time, spectral
analysis based on Fourier Theory and FAT. Thus a toolbox is completed, which it
is essential for all applications of Digital Signal Processing (DSP) and
Digital Image Processing (DIP); and, even, in the latter, FAT allows edge
detection (which is called flank detection in case of signals), denoising,
despeckling, compression, and superresolution of still images. Such
applications include signals intelligence and imagery intelligence. On the
other hand, we will present other DIP tools, which are also derived from the
Schrodinger equation.
</dc:description>
 <dc:description>Comment: 140 pages, 78 figures, 8 tables. arXiv admin note: text overlap with
  arXiv:0803.2507, arXiv:1611.02302 by other authors</dc:description>
 <dc:date>2016-10-11</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02304</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Normalizing Flows on Riemannian Manifolds</dc:title>
 <dc:creator>Gemici, Mevlana C.</dc:creator>
 <dc:creator>Rezende, Danilo</dc:creator>
 <dc:creator>Mohamed, Shakir</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider the problem of density estimation on Riemannian manifolds.
Density estimation on manifolds has many applications in fluid-mechanics,
optics and plasma physics and it appears often when dealing with angular
variables (such as used in protein folding, robot limbs, gene-expression) and
in general directional statistics. In spite of the multitude of algorithms
available for density estimation in the Euclidean spaces $\mathbf{R}^n$ that
scale to large n (e.g. normalizing flows, kernel methods and variational
approximations), most of these methods are not immediately suitable for density
estimation in more general Riemannian manifolds. We revisit techniques related
to homeomorphisms from differential geometry for projecting densities to
sub-manifolds and use it to generalize the idea of normalizing flows to more
general Riemannian manifolds. The resulting algorithm is scalable, simple to
implement and suitable for use with automatic differentiation. We demonstrate
concrete examples of this method on the n-sphere $\mathbf{S}^n$.
</dc:description>
 <dc:description>Comment: 3 pages, 2 figures, Submitted to Workshop on Bayesian Deep Learning
  at NIPS 2016</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02305</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Influence Functions from Incomplete Observations</dc:title>
 <dc:creator>He, Xinran</dc:creator>
 <dc:creator>Xu, Ke</dc:creator>
 <dc:creator>Kempe, David</dc:creator>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of learning influence functions under incomplete
observations of node activations. Incomplete observations are a major concern
as most (online and real-world) social networks are not fully observable. We
establish both proper and improper PAC learnability of influence functions
under randomly missing observations. Proper PAC learnability under the
Discrete-Time Linear Threshold (DLT) and Discrete-Time Independent Cascade
(DIC) models is established by reducing incomplete observations to complete
observations in a modified graph. Our improper PAC learnability result applies
for the DLT and DIC models as well as the Continuous-Time Independent Cascade
(CIC) model. It is based on a parametrization in terms of reachability
features, and also gives rise to an efficient and practical heuristic.
Experiments on synthetic and real-world datasets demonstrate the ability of our
method to compensate even for a fairly large fraction of missing observations.
</dc:description>
 <dc:description>Comment: Full version of paper &quot;Learning Influence Functions from Incomplete
  Observations&quot; in NIPS16</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02308</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nested algorithms for optimal reservoir operation and their embedding in
  a decision support platform</dc:title>
 <dc:creator>Delipetrev, Blagoj</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This is a PhD thesis of Blagoj Delipetrev explaining nested dynamic
programming, nested stochastic dynamic programming and nested reinforcement
learning algorithms that are applied in reservoir optimization problem.
Additionally there are also multi-objective version of these algorithms.
</dc:description>
 <dc:date>2016-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02315</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from Untrusted Data</dc:title>
 <dc:creator>Charikar, Moses</dc:creator>
 <dc:creator>Steinhardt, Jacob</dc:creator>
 <dc:creator>Valiant, Gregory</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  The vast majority of theoretical results in machine learning and statistics
assume that the available training data is a reasonably reliable reflection of
the phenomena to be learned or estimated. Similarly, the majority of machine
learning and statistical techniques used in practice are brittle to the
presence of large amounts of biased or malicious data. In this work we consider
two frameworks in which to study estimation, learning, and optimization in the
presence of significant fractions of arbitrary data.
  The first framework, list-decodable learning, asks whether it is possible to
return a list of answers, with the guarantee that at least one of them is
accurate. For example, given a dataset of $n$ points for which an unknown
subset of $\alpha n$ points are drawn from a distribution of interest, and no
assumptions are made about the remaining $(1-\alpha)n$ points, is it possible
to return a list of $\operatorname{poly}(1/\alpha)$ answers, one of which is
correct? The second framework, which we term the semi-verified learning model,
considers the extent to which a small dataset of trusted data (drawn from the
distribution in question) can be leveraged to enable the accurate extraction of
information from a much larger but untrusted dataset (of which only an
$\alpha$-fraction is drawn from the distribution).
  We show strong positive results in both settings, and provide an algorithm
for robust learning in a very general stochastic optimization setting. This
general result has immediate implications for robust estimation in a number of
settings, including for robustly estimating the mean of distributions with
bounded second moments, robustly learning mixtures of such distributions, and
robustly finding planted partitions in random graphs in which significant
portions of the graph have been perturbed by an adversary.
</dc:description>
 <dc:description>Comment: Updated based on STOC camera-ready</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02319</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Improvements in Heterogeneous Wireless Networks for First
  Responders</dc:title>
 <dc:creator>Zhang, Jianqiang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Efficient communications are crucial for disaster response and recovery.
However, most current public safety land mobile radio (LMR) networks only
provide narrowband voice service with limited support of low-speed data
services. In this paper, we study to enhance the interoperability of LMR with
commercial wireless cellular networks, by which a wide variety of benefits can
be offered to disaster responders, including new multimedia services, increased
data rates and low cost devices. Our approach is based on Session Initial
Protocol (SIP) and a joint radio resource management framework. In addition, an
optimal radio resource management scheme is proposed to maximize the overall
radio resource utilization and at the same time guarantee service availability
and continuity quality of service (QoS) for disaster responders. The
effectiveness of the proposed approach is illustrated by numerical examples.
</dc:description>
 <dc:description>Comment: This article has been withdrawn by arXiv administrators due to
  excessive unattributed and verbatim text overlap from external sources</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02320</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Ladder Networks</dc:title>
 <dc:creator>Molano, Juan Maro&#xf1;as</dc:creator>
 <dc:creator>Colomer, Alberto Albiol</dc:creator>
 <dc:creator>Palacios, Roberto Paredes</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The use of unsupervised data in addition to supervised data in training
discriminative neural networks has improved the performance of this clas-
sification scheme. However, the best results were achieved with a training
process that is divided in two parts: first an unsupervised pre-training step
is done for initializing the weights of the network and after these weights are
refined with the use of supervised data. On the other hand adversarial noise
has improved the results of clas- sical supervised learning. Recently, a new
neural network topology called Ladder Network, where the key idea is based in
some properties of hierar- chichal latent variable models, has been proposed as
a technique to train a neural network using supervised and unsupervised data at
the same time with what is called semi-supervised learning. This technique has
reached state of the art classification. In this work we add adversarial noise
to the ladder network and get state of the art classification, with several
important conclusions on how adversarial noise can help in addition with new
possible lines of investi- gation. We also propose an alternative to add
adversarial noise to unsu- pervised data.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02323</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Quasi-physical Quasi-human Algorithm for Packing Equal
  Circles in a Circular Container</dc:title>
 <dc:creator>He, Kun</dc:creator>
 <dc:creator>Ye, Hui</dc:creator>
 <dc:creator>Wang, Zhengli</dc:creator>
 <dc:creator>Liu, Jingfa</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  This paper addresses the equal circle packing problem, and proposes an
efficient Quasi-physical Quasi-human (QPQH) algorithm. QPQH is based on a
modified Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm which we call the
local BFGS and a new basin hopping strategy based on a Chinese idiom: alternate
tension with relaxation. Starting from a random initial layout, we apply the
local BFGS algorithm to reach a local minimum layout. The local BFGS algorithm
fully utilizes the neighborhood information of each circle to considerably
speed up the running time of the gradient descent process, and the efficiency
is very apparent for large scale instances. When yielding a local minimum
layout, the new basin-hopping strategy is to shrink the container size to
different extent to generate several new layouts. Experimental results indicate
that the new basin-hopping strategy is very efficient, especially for a type of
layout with comparatively dense packing in the center and comparatively sparse
packing around the boundary of the container. We test QPQH on the instances of
n = 1,2,...,320, and obtain 66 new layouts which have smaller container sizes
than the current best-known results reported in literature.
</dc:description>
 <dc:description>Comment: 19 pages, 16 figures, 2 tables</dc:description>
 <dc:date>2016-08-02</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02325</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chaos-based Wireless Communication Resisting Multipath Effects</dc:title>
 <dc:creator>Yao, Junliang</dc:creator>
 <dc:creator>Li, Chen</dc:creator>
 <dc:creator>Ren, Haipeng</dc:creator>
 <dc:creator>Grebogi, Celso</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A05</dc:subject>
 <dc:description>  In additive white gaussian noise (AWGN) channel, chaos has been proved to be
the optimal coherent communication waveform in the sense of using very simple
matched filter to maximize the signal-to-noise ratio (SNR). Recently, Lyapunov
exponent spectrum of the chaotic signals after being transmitted through a
wireless channel has been shown to be unaltered, paving the way for wireless
communication using chaos. In wireless communication systems, inter-symbol
interference (ISI) caused by multipath propagation is one of the main obstacles
to achieve high bit transmission rate and low bit error rate (BER). How to
resist multipath effect is a fundamental problem in a chaos-based wireless
communication system (CWCS). In this paper, implementation of a CWCS is
presented. It is built to transmit chaotic signals generated by a hybrid
dynamical system and then to filter the received signals by using the
corresponding matched filter to decrease the noise effect and to detect the
binary information. We find that the multipath effect can be effectively
resisted by regrouping the return map of the received signal and by setting the
corresponding threshold based on the available information. We show that the
optimal threshold is a function of the channel parameters and of the
transmitted information symbols. Practically, the channel parameters are
time-variant, and the future information symbols are unavailable. In this case,
a suboptimal threshold (SOT) is proposed, and the BER using the SOT is derived
analytically. Simulation results show that the CWCS achieves a remarkable
competitive performance even under inaccurate channel parameters.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures, 1 table</dc:description>
 <dc:date>2016-10-09</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02325</dc:identifier>
 <dc:identifier>Phys. Rev. E 96, 032226 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.96.032226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02329</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Analysis of Iterated Best Response for a Trusted Computation
  Game</dc:title>
 <dc:creator>Bopardikar, Shaunak D.</dc:creator>
 <dc:creator>Speranzon, Alberto</dc:creator>
 <dc:creator>Langbort, Cedric</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We introduce a game of trusted computation in which a sensor equipped with
limited computing power leverages a central node to evaluate a specified
function over a large dataset, collected over time. We assume that the central
computer can be under attack and we propose a strategy where the sensor retains
a limited amount of the data to counteract the effect of attack. We formulate
the problem as a two player game in which the sensor (defender) chooses an
optimal fusion strategy using both the non-trusted output from the central
computer and locally stored trusted data. The attacker seeks to compromise the
computation by influencing the fused value through malicious manipulation of
the data stored on the central node. We first characterize all Nash equilibria
of this game, which turn out to be dependent on parameters known to both
players. Next we adopt an Iterated Best Response (IBR) scheme in which, at each
iteration, the central computer reveals its output to the sensor, who then
computes its best response based on a linear combination of its private local
estimate and the untrusted third-party output. We characterize necessary and
sufficient conditions for convergence of the IBR along with numerical results
which show that the convergence conditions are relatively tight.
</dc:description>
 <dc:description>Comment: Contains detailed proofs of all results as well as an additional
  section on &quot;the case of equal means&quot; (Section 5)</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02336</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Dynamic Point Selection for Power Minimization in Multiuser
  Downlink CoMP</dc:title>
 <dc:creator>Nguyen, Duy H. N.</dc:creator>
 <dc:creator>Le, Long B.</dc:creator>
 <dc:creator>Le-Ngoc, Tho</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper examines a CoMP system where multiple base-stations (BS) employ
coordinated beamforming to serve multiple mobile-stations (MS). Under the
dynamic point selection mode, each MS can be assigned to only one BS at any
time. This work then presents a solution framework to optimize the BS
associations and coordinated beamformers for all MSs. With target
signal-to-interference-plus-noise ratios at the MSs, the design objective is to
minimize either the weighted sum transmit power or the per-BS transmit power
margin. Since the original optimization problems contain binary variables
indicating the BS associations, finding their optimal solutions is a
challenging task. To circumvent this difficulty, we first relax the original
problems into new optimization problems by expanding their constraint sets.
Based on the nonconvex quadratic constrained quadratic programming framework,
we show that these relaxed problems can be solved optimally. Interestingly,
with the first design objective, the obtained solution from the relaxed problem
is also optimal to the original problem. With the second design objective, a
suboptimal solution to the original problem is then proposed, based on the
obtained solution from the relaxed problem. Simulation results show that the
resulting jointly optimal BS association and beamforming design significantly
outperforms fixed BS association schemes.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures, accepted to IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02337</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balotage in Argentina 2015, a sentiment analysis of tweets</dc:title>
 <dc:creator>Robins, Daniel</dc:creator>
 <dc:creator>Frati, Fernando Emmanuel</dc:creator>
 <dc:creator>Alvarez, Jonatan</dc:creator>
 <dc:creator>Texier, Jose</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Twitter social network contains a large amount of information generated by
its users. That information is composed of opinions and comments that may
reflect trends in social behavior. There is talk of trend when it is possible
to identify opinions and comments geared towards the same shared by a lot of
people direction. To determine if two or more written opinions share the same
address, techniques Natural Language Processing (NLP) are used. This paper
proposes a methodology for predicting reflected in Twitter from the use of
sentiment analysis functions NLP based on social behaviors. The case study was
selected the 2015 Presidential in Argentina, and a software architecture Big
Data composed Vertica data base with the component called Pulse was used.
Through the analysis it was possible to detect trends in voting intentions with
regard to the presidential candidates, achieving greater accuracy in predicting
that achieved with traditional systems surveys.
</dc:description>
 <dc:description>Comment: in Spanish. Jornadas de Cloud Computing, La Plata - Argentina. 2016</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02337</dc:identifier>
 <dc:language>es</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02338</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Line failure probability bounds for power grids</dc:title>
 <dc:creator>Nesti, Tommaso</dc:creator>
 <dc:creator>Zocca, Alessandro</dc:creator>
 <dc:creator>Zwart, Bert</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We develop upper bounds for line failure probabilities in power grids, under
the DC approximation and assuming Gaussian noise for the power injections. Our
upper bounds are explicit, and lead to characterization of safe operational
capacity regions that are convex and polyhedral, making our tools compatible
with existing planning methods. Our probabilistic bounds are derived through
the use of powerful concentration inequalities.
</dc:description>
 <dc:description>Comment: Submitted to 2017 IEEE Power &amp; Energy Society General Meeting</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02343</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Myopic Target Tracking Strategies for State-Dependent Noise</dc:title>
 <dc:creator>Zhang, Zhonghshun</dc:creator>
 <dc:creator>Tokekar, Pratap</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We study the problem of devising a closed-loop strategy to control the
position of a robot that is tracking a possibly moving target. The robot is
capable of obtaining noisy measurements of the target's position. The key idea
in active target tracking is to choose control laws that drive the robot to
measurement locations that will reduce the uncertainty in the target's
position. The challenge is that measurement uncertainty often is a function of
the (unknown) relative positions of the target and the robot. Consequently, a
closed-loop control policy is desired which can map the current estimate of the
target's position to an optimal control law for the robot.
  Our main contribution is to devise a closed-loop control policy for target
tracking that plans for a sequence of control actions, instead of acting
greedily. We consider scenarios where the noise in measurement is a function of
the state of the target. We seek to minimize the maximum uncertainty (trace of
the posterior covariance matrix) over all possible measurements. We exploit the
structural properties of a Kalman Filter to build a policy tree that is orders
of magnitude smaller than naive enumeration while still preserving optimality
guarantees. We show how to obtain even more computational savings by relaxing
the optimality guarantees. The resulting algorithms are evaluated through
simulations.
</dc:description>
 <dc:description>Comment: Extended version of IEEE CDC 2016 paper</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02344</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Convolutional Encoder Model for Neural Machine Translation</dc:title>
 <dc:creator>Gehring, Jonas</dc:creator>
 <dc:creator>Auli, Michael</dc:creator>
 <dc:creator>Grangier, David</dc:creator>
 <dc:creator>Dauphin, Yann N.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The prevalent approach to neural machine translation relies on bi-directional
LSTMs to encode the source sentence. In this paper we present a faster and
simpler architecture based on a succession of convolutional layers. This allows
to encode the entire source sentence simultaneously compared to recurrent
networks for which computation is constrained by temporal dependencies. On
WMT'16 English-Romanian translation we achieve competitive accuracy to the
state-of-the-art and we outperform several recently published results on the
WMT'15 English-German task. Our models obtain almost the same accuracy as a
very deep LSTM setup on WMT'14 English-French translation. Our convolutional
encoder speeds up CPU decoding by more than two times at the same or higher
accuracy as a strong bi-directional LSTM baseline.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02345</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Taylor Approximations: Convergence and Exploration in Rectifier
  Networks</dc:title>
 <dc:creator>Balduzzi, David</dc:creator>
 <dc:creator>McWilliams, Brian</dc:creator>
 <dc:creator>Butler-Yeoman, Tony</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Modern convolutional networks, incorporating rectifiers and max-pooling, are
neither smooth nor convex. Standard guarantees therefore do not apply.
Nevertheless, methods from convex optimization such as gradient descent and
Adam are widely used as building blocks for deep learning algorithms. This
paper provides the first convergence guarantee applicable to modern convnets.
The guarantee matches a lower bound for convex nonsmooth functions. The key
technical tool is the neural Taylor approximation -- a straightforward
application of Taylor expansions to neural networks -- and the associated
Taylor loss. Experiments on a range of optimizers, layers, and tasks provide
evidence that the analysis accurately captures the dynamics of neural
optimization.
  The second half of the paper applies the Taylor approximation to isolate the
main difficulty in training rectifier nets: that gradients are shattered. We
investigate the hypothesis that, by exploring the space of activation
configurations more thoroughly, adaptive optimizers such as RMSProp and Adam
are able to converge to better solutions.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02351</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chain Reduction Preserves the Unrooted Subtree Prune-and-Regraft
  Distance</dc:title>
 <dc:creator>Whidden, Chris</dc:creator>
 <dc:creator>Matsen IV, Frederick A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The subtree prune-and-regraft (SPR) distance metric is a fundamental way of
comparing evolutionary trees. It has wide-ranging applications, such as to
study lateral genetic transfer, viral recombination, and Markov chain Monte
Carlo phylogenetic inference. Although the rooted version of SPR distance can
be com puted relatively efficiently between rooted trees using
fixed-parameter-tractable algorithms, in the unrooted case previous algorithms
are unable to compute distances larger than 7. One important tool for efficient
computation in the rooted case is called chain reduction, which replaces an
arbitrary chain of subtrees identical in both trees with a chain of three
leaves. Whether chain reduction preserves SPR distance in the unrooted case has
remained an open question since it was conjectured in 2001 by Allen and Steel,
and was presented as a challenge question at the 2007 Isaac Newton Institute
for Mathematical Sciences program on phylogenetics.
  In this paper we prove that chain reduction preserves the unrooted SPR
distance. We do so by introducing a structure called a socket agreement forest
that restricts edge modification to predetermined socket vertices, permitting
detailed analysis and modification of SPR move sequences. This new chain
reduction theorem reduces the unrooted distance problem to a linear size
problem kernel, substantially improving on the previous best quadratic size
kernel.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures. Split from arXiv:1511.07529 and revised as a
  conference paper after feedback suggested that work was too long</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02354</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a condition equivalent to the Maximum Distance Separable conjecture</dc:title>
 <dc:creator>Sun, Jeffery</dc:creator>
 <dc:creator>Damelin, Steven</dc:creator>
 <dc:creator>Kaiser, Daniel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>94B05, 05B35, 12Y05</dc:subject>
 <dc:description>  We denote by $\mathcal{P}_q$ the vector space of functions from a finite
field $\mathbb{F}_q$ to itself, which can be represented as the space
$\mathcal{P}_q := \mathbb{F}_q[x]/(x^q-x)$ of polynomial functions. We denote
by $\mathcal{O}_n \subset \mathcal{P}_q$ the set of polynomials that are either
the zero polynomial, or have at most $n$ distinct roots in $\mathbb{F}_q$.
Given two subspaces $Y,Z$ of $\mathcal{P}_q$, we denote by $\langle Y,Z
\rangle$ their span. We prove that the following are equivalent.
  A) Let $k, q$ integers, with $q$ a prime power and $2 \leq k \leq q$. Suppose
that either:
  1) $q$ is odd
  2) $q$ is even and $k \not\in \{3, q-1\}$.
  Then there do not exist distinct subspaces $Y$ and $Z$ of $\mathcal{P}_q$
such that:
  1') $dim(\langle Y, Z \rangle) = k$
  2') $dim(Y) = dim(Z) = k-1$.
  3') $\langle Y, Z \rangle \subset \mathcal{O}_{k-1}$
  4') $Y, Z \subset \mathcal{O}_{k-2}$
  5') $Y\cap Z \subset \mathcal{O}_{k-3}$.
  B) The MDS conjecture is true for the given $(q,k)$.
</dc:description>
 <dc:description>Comment: This is a minor revision to the original paper</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02355</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Complexity QoS-Aware Coordinated Scheduling for Heterogenous
  Networks</dc:title>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Yang, Hong-Chuan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider a heterogenous network (HetNet), where low-power
indoor femtocells are deployed in the coverage area of the existing macro base
station (MBS). This paper proposes a novel coordinated random beamforming and
user scheduling strategy to improve the throughput of users served by the
femtocell access point (FAP) while satisfying the quality-of-service (QoS)
requirements of users served by both MBS and FAP. The strategy, termed as
QoS-Aware Coodinated Scheduling (QACS), requires limited coordination between
the MBS and FAP, i.e., only the indexes of the qualified beams are shared.
Exact statistical analysis for the ergodic achievable rate of both FAP and MBS
with the proposed strategy are presented. Scheduling fairness is also addressed
for the proposed QACS.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, accepted by IEEE Transactions on Vehicular
  Technology</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02360</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cruciform: Solving Crosswords with Natural Language Processing</dc:title>
 <dc:creator>Radev, Dragomir</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Wilson, Steve</dc:creator>
 <dc:creator>Van Assche, Derek</dc:creator>
 <dc:creator>Gubert, Henrique Spyra</dc:creator>
 <dc:creator>Krivokapic, Alisa</dc:creator>
 <dc:creator>Dong, MeiXing</dc:creator>
 <dc:creator>Wu, Chongruo</dc:creator>
 <dc:creator>Bondera, Spruce</dc:creator>
 <dc:creator>Brandl, Luke</dc:creator>
 <dc:creator>Dohmann, Jeremy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Crossword puzzles are popular word games that require not only a large
vocabulary, but also a broad knowledge of topics. Answering each clue is a
natural language task on its own as many clues contain nuances, puns, or
counter-intuitive word definitions. Additionally, it can be extremely difficult
to ascertain definitive answers without the constraints of the crossword grid
itself. This task is challenging for both humans and computers. We describe
here a new crossword solving system, Cruciform. We employ a group of natural
language components, each of which returns a list of candidate words with
scores when given a clue. These lists are used in conjunction with the fill
intersections in the puzzle grid to formulate a constraint satisfaction
problem, in a manner similar to the one used in the Dr. Fill system. We
describe the results of several of our experiments with the system.
</dc:description>
 <dc:description>Comment: based on feedback, we have determined that the paper needs more work</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02361</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependency Sensitive Convolutional Neural Networks for Modeling
  Sentences and Documents</dc:title>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Lee, Honglak</dc:creator>
 <dc:creator>Radev, Dragomir</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The goal of sentence and document modeling is to accurately represent the
meaning of sentences and documents for various Natural Language Processing
tasks. In this work, we present Dependency Sensitive Convolutional Neural
Networks (DSCNN) as a general-purpose classification system for both sentences
and documents. DSCNN hierarchically builds textual representations by
processing pretrained word embeddings via Long Short-Term Memory networks and
subsequently extracting features with convolution operators. Compared with
existing recursive neural models with tree structures, DSCNN does not rely on
parsers and expensive phrase labeling, and thus is not restricted to
sentence-level tasks. Moreover, unlike other CNN-based models that analyze
sentences locally by sliding windows, our system captures both the dependency
information within each sentence and relationships across sentences in the same
document. Experiment results demonstrate that our approach is achieving
state-of-the-art performance on several tasks, including sentiment analysis,
question type classification, and subjectivity classification.
</dc:description>
 <dc:description>Comment: NAACL2016</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02364</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Object Tracking with Kernelized Correlation Filters in Urban
  Mixed Traffic</dc:title>
 <dc:creator>Yang, Yuebin</dc:creator>
 <dc:creator>Bilodeau, Guillaume-Alexandre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, the Kernelized Correlation Filters tracker (KCF) achieved
competitive performance and robustness in visual object tracking. On the other
hand, visual trackers are not typically used in multiple object tracking. In
this paper, we investigate how a robust visual tracker like KCF can improve
multiple object tracking. Since KCF is a fast tracker, many can be used in
parallel and still result in fast tracking. We build a multiple object tracking
system based on KCF and background subtraction. Background subtraction is
applied to extract moving objects and get their scale and size in combination
with KCF outputs, while KCF is used for data association and to handle
fragmentation and occlusion problems. As a result, KCF and background
subtraction help each other to take tracking decision at every frame. Sometimes
KCF outputs are the most trustworthy (e.g. during occlusion), while in some
other case, it is the background subtraction outputs. To validate the
effectiveness of our system, the algorithm is demonstrated on four urban video
recordings from a standard dataset. Results show that our method is competitive
with state-of-the-art trackers even if we use a much simpler data association
step.
</dc:description>
 <dc:description>Comment: Accepted for CRV 2017</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02365</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NonSTOP: A NonSTationary Online Prediction Method for Time Series</dc:title>
 <dc:creator>Xie, Christopher</dc:creator>
 <dc:creator>Bijral, Avleen</dc:creator>
 <dc:creator>Ferres, Juan Lavista</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present online prediction methods for univariate and multivariate time
series that allow us to handle nonstationary artifacts present in most real
time series. Specifically, we show that applying appropriate transformations to
such time series can lead to improved theoretical and empirical prediction
performance. Moreover, since these transformations are usually unknown, we
employ the learning with experts setting to develop a fully online method
(NonSTOP) for predicting nonstationary time series. This framework allows for
seasonality and/or other trends in univariate time series and cointegration in
multivariate time series. Our algorithms and regret analysis subsumes recent
related work while significantly expanding the applicability of such methods.
For all the methods, we provide sub-linear regret bounds using relaxed
assumptions. We note that the theoretical guarantees do not fully capture the
benefits of the nonstationary transformations, thus we provide a data-dependent
analysis of the follow-the-leader algorithm for least squares loss that
provides insight into the success of using nonstationary transformations. We
support all of our results with experiments on simulated and real data.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02370</identifier>
 <datestamp>2017-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fingerprinting OpenFlow controllers: The first step to attack an SDN
  control plane</dc:title>
 <dc:creator>Azzouni, Abdelhadi</dc:creator>
 <dc:creator>Braham, Othmen</dc:creator>
 <dc:creator>Trang, Nguyen Thi Mai</dc:creator>
 <dc:creator>Pujolle, Guy</dc:creator>
 <dc:creator>Boutaba, Raouf</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Software-Defined Networking (SDN) controllers are considered as Network
Operating Systems (NOSs) and often viewed as a single point of failure.
Detecting which SDN controller is managing a target network is a big step for
an attacker to launch specific/effective attacks against it. In this paper, we
demonstrate the feasibility of fingerpirinting SDN controllers. We propose
techniques allowing an attacker placed in the data plane, which is supposed to
be physically separate from the control plane, to detect which controller is
managing the network. To the best of our knowledge, this is the first work on
fingerprinting SDN controllers, with as primary goal to emphasize the necessity
to highly secure the controller. We focus on OpenFlow-based SDN networks since
OpenFlow is currently the most deployed SDN technology by hardware and software
vendors.
</dc:description>
 <dc:description>Comment: Peer reviewed version can be fount here
  http://ieeexplore.ieee.org/document/7841843/</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-05-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02378</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Surrogate-based Generic Classifier for Chinese TV Series Reviews</dc:title>
 <dc:creator>Ma, Yufeng</dc:creator>
 <dc:creator>Xia, Long</dc:creator>
 <dc:creator>Shen, Wenqi</dc:creator>
 <dc:creator>Zhou, Mi</dc:creator>
 <dc:creator>Fan, Weiguo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  With the emerging of various online video platforms like Youtube, Youku and
LeTV, online TV series' reviews become more and more important both for viewers
and producers. Customers rely heavily on these reviews before selecting TV
series, while producers use them to improve the quality. As a result,
automatically classifying reviews according to different requirements evolves
as a popular research topic and is essential in our daily life. In this paper,
we focused on reviews of hot TV series in China and successfully trained
generic classifiers based on eight predefined categories. The experimental
results showed promising performance and effectiveness of its generalization to
different TV series.
</dc:description>
 <dc:description>Comment: submitted to IDD</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02379</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The sub-$k$-domination number of a graph with applications to
  $k$-domination</dc:title>
 <dc:creator>Amos, David</dc:creator>
 <dc:creator>Asplund, John</dc:creator>
 <dc:creator>Brimkov, Boris</dc:creator>
 <dc:creator>Davila, Randy</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C69</dc:subject>
 <dc:description>  In this paper we introduce and study a new graph invariant derived from the
degree sequence of a graph $G$, called the sub-$k$-domination number and
denoted $sub_k(G)$. We show that $sub_k(G)$ is a computationally efficient
sharp lower bound on the $k$-domination number of $G$, and improves on several
known lower bounds. We also characterize the sub-$k$-domination numbers of
several families of graphs, provide structural results on sub-$k$-domination,
and explore properties of graphs which are $sub_k(G)$-critical with respect to
addition and deletion of vertices and edges.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02380</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Policy Optimization for Content Push via Energy Harvesting Small Cells
  in Heterogeneous Networks</dc:title>
 <dc:creator>Gong, Jie</dc:creator>
 <dc:creator>Zhou, Sheng</dc:creator>
 <dc:creator>Zhou, Zhenyu</dc:creator>
 <dc:creator>Niu, Zhisheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by the rapid development of energy harvesting technology and
content-aware communication in access networks, this paper considers the push
mechanism design in small-cell base stations (SBSs) powered by renewable
energy. A user request can be satisfied by either push or unicast from the SBS.
If the SBS cannot handle the request, the user is blocked by the SBS and is
served by the macro-cell BS (MBS) instead, which typically consumes more
energy. We aim to minimize the ratio of user requests blocked by the SBS. With
finite battery capacity, Markov decision process based problem is formulated,
and the optimal policy is found by dynamic programming (DP). Two
threshold-based policies are proposed: the push-only threshold-based (POTB)
policy and the energy-efficient threshold-based (EETB) policy, and the
closed-form blocking probabilities with infinite battery capacity are derived.
Numerical results show that the proposed policies outperform the conventional
non-push policy if the content popularity changes slowly or the content request
generating rate is high, and can achieve the performance of the greedy optimal
threshold-based (GOTB) policy. In addition, the performance gap between the
threshold-based policies and the DP optimal policy is small when the energy
arrival rate is low or the request generating rate is high.
</dc:description>
 <dc:description>Comment: 30 pages, 7 figures, to appear in IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02385</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining observational and experimental data to find heterogeneous
  treatment effects</dc:title>
 <dc:creator>Peysakhovich, Alexander</dc:creator>
 <dc:creator>Lada, Akos</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Every design choice will have different effects on different units. However
traditional A/B tests are often underpowered to identify these heterogeneous
effects. This is especially true when the set of unit-level attributes is
high-dimensional and our priors are weak about which particular covariates are
important. However, there are often observational data sets available that are
orders of magnitude larger. We propose a method to combine these two data
sources to estimate heterogeneous treatment effects. First, we use
observational time series data to estimate a mapping from covariates to
unit-level effects. These estimates are likely biased but under some conditions
the bias preserves unit-level relative rank orderings. If these conditions
hold, we only need sufficient experimental data to identify a monotonic,
one-dimensional transformation from observationally predicted treatment effects
to real treatment effects. This reduces power demands greatly and makes the
detection of heterogeneous effects much easier. As an application, we show how
our method can be used to improve Facebook page recommendations.
</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02388</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PNP: Fast Path Ensemble Method for Movie Design</dc:title>
 <dc:creator>Koutra, Danai</dc:creator>
 <dc:creator>Dighe, Abhilash</dc:creator>
 <dc:creator>Bhagat, Smriti</dc:creator>
 <dc:creator>Weinsberg, Udi</dc:creator>
 <dc:creator>Ioannidis, Stratis</dc:creator>
 <dc:creator>Faloutsos, Christos</dc:creator>
 <dc:creator>Bolot, Jean</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  How can we design a product or movie that will attract, for example, the
interest of Pennsylvania adolescents or liberal newspaper critics? What should
be the genre of that movie and who should be in the cast? In this work, we seek
to identify how we can design new movies with features tailored to a specific
user population. We formulate the movie design as an optimization problem over
the inference of user-feature scores and selection of the features that
maximize the number of attracted users. Our approach, PNP, is based on a
heterogeneous, tripartite graph of users, movies and features (e.g., actors,
directors, genres), where users rate movies and features contribute to movies.
We learn the preferences by leveraging user similarities defined through
different types of relations, and show that our method outperforms
state-of-the-art approaches, including matrix factorization and other
heterogeneous graph-based analysis. We evaluate PNP on publicly available
real-world data and show that it is highly scalable and effectively provides
movie designs oriented towards different groups of users, including men, women,
and adolescents.
</dc:description>
 <dc:description>Comment: 9 pages, 12 figures</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02392</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sums of Uncertainty: Refinements Go Gradual</dc:title>
 <dc:creator>Jafery, Khurram A.</dc:creator>
 <dc:creator>Dunfield, Joshua</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  A long-standing shortcoming of statically typed functional languages is that
type checking does not rule out pattern-matching failures (run-time match
exceptions). Refinement types distinguish different values of datatypes; if a
program annotated with refinements passes type checking, pattern-matching
failures become impossible. Unfortunately, refinement is a monolithic property
of a type, exacerbating the difficulty of adding refinement types to nontrivial
programs.
  Gradual typing has explored how to incrementally move between static typing
and dynamic typing. We develop a type system of gradual sums that combines
refinement with imprecision. Then, we develop a bidirectional version of the
type system, which rules out excessive imprecision, and give a type-directed
translation to a target language with explicit casts. We prove that the static
sublanguage cannot have match failures, that a well-typed program remains
well-typed if its type annotations are made less precise, and that making
annotations less precise causes target programs to fail later. Several of these
results correspond to criteria for gradual typing given by Siek et al. (2015).
</dc:description>
 <dc:description>Comment: 14 pages + appendix with proofs, to appear at POPL 2017</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02400</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Graph-Theoretic Approach to Multitasking</dc:title>
 <dc:creator>Alon, Noga</dc:creator>
 <dc:creator>Cohen, Jonathan D.</dc:creator>
 <dc:creator>Dey, Biswadip</dc:creator>
 <dc:creator>Griffiths, Tom</dc:creator>
 <dc:creator>Musslick, Sebastian</dc:creator>
 <dc:creator>Ozcimder, Kayhan</dc:creator>
 <dc:creator>Reichman, Daniel</dc:creator>
 <dc:creator>Shinkar, Igor</dc:creator>
 <dc:creator>Wagner, Tal</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A key feature of neural network architectures is their ability to support the
simultaneous interaction among large numbers of units in the learning and
processing of representations. However, how the richness of such interactions
trades off against the ability of a network to simultaneously carry out
multiple independent processes -- a salient limitation in many domains of human
cognition -- remains largely unexplored. In this paper we use a graph-theoretic
analysis of network architecture to address this question, where tasks are
represented as edges in a bipartite graph $G=(A \cup B, E)$. We define a new
measure of multitasking capacity of such networks, based on the assumptions
that tasks that \emph{need} to be multitasked rely on independent resources,
i.e., form a matching, and that tasks \emph{can} be multitasked without
interference if they form an induced matching. Our main result is an inherent
tradeoff between the multitasking capacity and the average degree of the
network that holds \emph{regardless of the network architecture}. These results
are also extended to networks of depth greater than $2$. On the positive side,
we demonstrate that networks that are random-like (e.g., locally sparse) can
have desirable multitasking properties. Our results shed light into the
parallel-processing limitations of neural systems and provide insights that may
be useful for the analysis and design of parallel architectures.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02401</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Divide and Conquer Networks</dc:title>
 <dc:creator>Nowak, Alex</dc:creator>
 <dc:creator>Bruna, Joan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the learning of algorithmic tasks by mere observation of
input-output pairs. Rather than studying this as a black-box discrete
regression problem with no assumption whatsoever on the input-output mapping,
we concentrate on tasks that are amenable to the principle of divide and
conquer, and study what are its implications in terms of learning.
  This principle creates a powerful inductive bias that we leverage with neural
archi- tectures that are defined recursively and dynamically, by learning two
scale-invariant atomic operations: how to split a given input into smaller
sets, and how to merge two partially solved tasks into a larger partial
solution. Our model can be trained in weakly supervised environments, namely by
just observing input-output pairs, and in even weaker environments, using a
non-differentiable reward signal. Moreover, thanks to the dynamic aspect of our
architecture, we can incorporate the computational complexity as a
regularization term that can be optimized by backpropagation. We demonstrate
the flexibility and efficiency of the Divide-and-Conquer Network on three
combinatorial and geometric tasks: sorting, clustering and convex hulls. Thanks
to the dynamic program- ming nature of our model, we show significant
improvements in terms of generalization error and computational complexity
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02412</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modularity promotes epidemic recurrence</dc:title>
 <dc:creator>Jesan, T.</dc:creator>
 <dc:creator>Kuyyamudi, Chandrashekar</dc:creator>
 <dc:creator>Sinha, Sitabhra</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  The long-term evolution of epidemic processes depends crucially on the
structure of contact networks. As empirical evidence indicates that human
populations exhibit strong community organization, we investigate here how such
mesoscopic configurations affect the likelihood of epidemic recurrence. Through
numerical simulations on real social networks and theoretical arguments using
spectral methods, we demonstrate that highly contagious diseases that would
have otherwise died out rapidly can persist indefinitely for an optimal range
of modularity in contact networks.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures + 7 pages supplementary material</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02416</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Approach to Boosting Performance of Deep Spiking Network
  Training</dc:title>
 <dc:creator>Park, Seongsik</dc:creator>
 <dc:creator>Lee, Sang-gil</dc:creator>
 <dc:creator>Nam, Hyunha</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Nowadays deep learning is dominating the field of machine learning with
state-of-the-art performance in various application areas. Recently, spiking
neural networks (SNNs) have been attracting a great deal of attention, notably
owning to their power efficiency, which can potentially allow us to implement a
low-power deep learning engine suitable for real-time/mobile applications.
However, implementing SNN-based deep learning remains challenging, especially
gradient-based training of SNNs by error backpropagation. We cannot simply
propagate errors through SNNs in conventional way because of the property of
SNNs that process discrete data in the form of a series. Consequently, most of
the previous studies employ a workaround technique, which first trains a
conventional weighted-sum deep neural network and then maps the learning
weights to the SNN under training, instead of training SNN parameters directly.
In order to eliminate this workaround, recently proposed is a new class of SNN
named deep spiking networks (DSNs), which can be trained directly (without a
mapping from conventional deep networks) by error backpropagation with
stochastic gradient descent. In this paper, we show that the initialization of
the membrane potential on the backward path is an important step in DSN
training, through diverse experiments performed under various conditions.
Furthermore, we propose a simple and efficient method that can improve DSN
training by controlling the initial membrane potential on the backward path. In
our experiments, adopting the proposed approach allowed us to boost the
performance of DSN training in terms of converging time and accuracy.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02419</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lightweight Interactions for Reciprocal Cooperation in a Social Network
  Game</dc:title>
 <dc:creator>Takano, Masanori</dc:creator>
 <dc:creator>Wada, Kazuya</dc:creator>
 <dc:creator>Fukuda, Ichiro</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  The construction of reciprocal relationships requires cooperative
interactions during the initial meetings. However, cooperative behavior with
strangers is risky because the strangers may be exploiters. In this study, we
show that people increase the likelihood of cooperativeness of strangers by
using lightweight non-risky interactions in risky situations based on the
analysis of a social network game (SNG). They can construct reciprocal
relationships in this manner. The interactions involve low-cost signaling
because they are not generated at any cost to the senders and recipients.
Theoretical studies show that low-cost signals are not guaranteed to be
reliable because the low-cost signals from senders can lie at any time.
However, people used low-cost signals to construct reciprocal relationships in
an SNG, which suggests the existence of mechanisms for generating reliable,
low-cost signals in human evolution.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02419</dc:identifier>
 <dc:identifier>Published in Social Informatics, Volume 10046 of the series
  Lecture Notes in Computer Science, pp 125-137, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-47880-7_8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02421</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Web 2.0 for Small and medium Sized Companies: A practical Case Study</dc:title>
 <dc:creator>Magumba, Mark Abraham</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This project is a holistic analysis of web 2.0 and combines ideas from
systems theory and organizational theory and goes on to attempt to bridge the
gap between the ongoing theoretical discourse and its implications for the
development process. The goal is to shift the discussion from a descriptive,
highly philosophical one to a prescriptive framework that can directly be
applied for the design, evaluation and deployment. Effectively this work posits
that unless a practical framework can be synthesized from this rich debate the
application and development of web 2.0 is at risk of proceeding haphazardly and
this could potentially limit the benefits organizations reap from it. It then
establishes the applicability of web 2.0 to the small organization and
accordingly applies the framework to a practical case study.
</dc:description>
 <dc:description>Comment: MSc Thesis, 80 pages, 14 figures, 3 tables</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02429</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complementing Model Learning with Mutation-Based Fuzzing</dc:title>
 <dc:creator>Smetsers, Rick</dc:creator>
 <dc:creator>Moerman, Joshua</dc:creator>
 <dc:creator>Janssen, Mark</dc:creator>
 <dc:creator>Verwer, Sicco</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  An ongoing challenge for learning algorithms formulated in the Minimally
Adequate Teacher framework is to efficiently obtain counterexamples. In this
paper we compare and combine conformance testing and mutation-based fuzzing
methods for obtaining counterexamples when learning finite state machine models
for the reactive software systems of the Rigorous Exampination of Reactive
Systems (RERS) challenge. We have found that for the LTL problems of the
challenge the fuzzer provided an independent confirmation that the learning
process had been successful, since no additional counterexamples were found.
For the reachability problems of the challenge, however, the fuzzer discovered
more reachable error states than the learner and tester, albeit in some cases
the learner and tester found some that were not discovered by the fuzzer. This
leads us to believe that these orthogonal approaches are complementary in the
context of model learning.
</dc:description>
 <dc:description>Comment: Submitted to the RERS challenge 2016</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02431</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed recovery of jointly sparse signals under communication
  constraints</dc:title>
 <dc:creator>Fosson, Sophie M.</dc:creator>
 <dc:creator>Matamoros, Javier</dc:creator>
 <dc:creator>Anton-Haro, Carles</dc:creator>
 <dc:creator>Magli, Enrico</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The problem of the distributed recovery of jointly sparse signals has
attracted much attention recently. Let us assume that the nodes of a network
observe different sparse signals with common support; starting from linear,
compressed measurements, and exploiting network communication, each node aims
at reconstructing the support and the non-zero values of its observed signal.
In the literature, distributed greedy algorithms have been proposed to tackle
this problem, among which the most reliable ones require a large amount of
transmitted data, which barely adapts to realistic network communication
constraints. In this work, we address the problem through a reweighted $\ell_1$
soft thresholding technique, in which the threshold is iteratively tuned based
on the current estimate of the support. The proposed method adapts to
constrained networks, as it requires only local communication among neighbors,
and the transmitted messages are indices from a finite set. We analytically
prove the convergence of the proposed algorithm and we show that it outperforms
the state-of-the-art greedy methods in terms of balance between recovery
accuracy and communication load.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02431</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2548990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02439</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the First International Workshop on Argumentation in
  Logic Programming and Non-Monotonic Reasoning (Arg-LPNMR 2016)</dc:title>
 <dc:creator>Gaggl, Sarah Alice</dc:creator>
 <dc:creator>Nieves, Juan Carlos</dc:creator>
 <dc:creator>Strass, Hannes</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This volume contains the papers presented at Arg-LPNMR 2016: First
International Workshop on Argumentation in Logic Programming and Nonmonotonic
Reasoning held on July 8-10, 2016 in New York City, NY.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02442</identifier>
 <datestamp>2017-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Price Doubling and Item Halving: Robust Revenue Guarantees for Item
  Pricing</dc:title>
 <dc:creator>Anshelevich, Elliot</dc:creator>
 <dc:creator>Sekar, Shreyas</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study approximation algorithms for revenue maximization based on static
item pricing, where a seller chooses prices for various goods in the market,
and then the buyers purchase utility-maximizing bundles at these given prices.
We formulate two somewhat general techniques for designing good pricing
algorithms for this setting: Price Doubling and Item Halving. Using these
techniques, we unify many of the existing results in the item pricing
literature under a common framework, as well as provide several new item
pricing algorithms for approximating both revenue and social welfare. More
specifically, for a variety of settings with item pricing, we show that it is
possible to deterministically obtain a log-approximation for revenue and a
constant-approximation for social welfare simultaneously: thus one need not
sacrifice revenue if the goal is to still have decent welfare guarantees. %In
addition, we provide a new black-box reduction from revenue to welfare based on
item pricing, which immediately gives us new revenue-approximation algorithms
(e.g., for gross substitutes valuations).
  The main technical contribution of this paper is a $O((\log m + \log
k)^2)$-approximation algorithm for revenue maximization based on the Item
Halving technique, for settings where buyers have XoS valuations, where $m$ is
the number of goods and $k$ is the average supply. Surprisingly, ours is the
first known item pricing algorithm with polylogarithmic approximations for such
general classes of valuations, and partially resolves an important open
question from the algorithmic pricing literature about the existence of item
pricing algorithms with logarithmic factors for general valuations. We also use
the Item Halving framework to form envy-free item pricing mechanisms for the
popular setting of multi-unit markets, providing a log-approximation to revenue
in this case.
</dc:description>
 <dc:description>Comment: To appear in the proceedings of EC 2017</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02442</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02443</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain Adaptation with L2 constraints for classifying images from
  different endoscope systems</dc:title>
 <dc:creator>Tamaki, Toru</dc:creator>
 <dc:creator>Sonoyama, Shoji</dc:creator>
 <dc:creator>Kurita, Takio</dc:creator>
 <dc:creator>Hirakawa, Tsubasa</dc:creator>
 <dc:creator>Raytchev, Bisser</dc:creator>
 <dc:creator>Kaneda, Kazufumi</dc:creator>
 <dc:creator>Koide, Tetsushi</dc:creator>
 <dc:creator>Yoshida, Shigeto</dc:creator>
 <dc:creator>Mieno, Hiroshi</dc:creator>
 <dc:creator>Tanaka, Shinji</dc:creator>
 <dc:creator>Chayama, Kazuaki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a method for domain adaptation that extends the maximum
margin domain transfer (MMDT) proposed by Hoffman et al., by introducing L_2
distance constraints between samples of different domains; thus, our method is
denoted as MMDTL2. Motivated by the differences between the images taken by
narrow band imaging (NBI) endoscopic devices, we utilize different NBI devices
as different domains and estimate the transformations between samples of
different domains, i.e., image samples taken by different NBI endoscope
systems. We first formulate the problem in the primal form, and then derive the
dual form with much lesser computational costs as compared to the naive
approach. From our experimental results using NBI image datasets from two
different NBI endoscopic devices, we find that MMDTL2 is more stable than MMDT
and better than support vector machines without adaptation.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02445</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new GPU implementation for lattice-Boltzmann simulations on sparse
  geometries</dc:title>
 <dc:creator>Tomczak, Tadeusz</dc:creator>
 <dc:creator>Szafran, Roman G.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  We describe a high-performance implementation of the lattice Boltzmann method
(LBM) for sparse 3D geometries on graphic processors (GPU). The main
contribution of this work is a data layout that allows to minimise the number
of redundant memory transactions during the propagation step of LBM. We show
that by using a uniform mesh of small three-dimensional tiles and a careful
data placement it is possible to utilise more than 70% of maximum theoretical
GPU memory bandwidth for D3Q19 lattice and double precision numbers. The
performance of our implementation is thoroughly examined and compared with
other GPU implementations of LBM. The proposed method performs the best for
sparse geometries with good spatial locality.
</dc:description>
 <dc:description>Comment: 20 pages, 20 figures, sent to Computer Physics Comunications, after
  including Reviewers comments</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-10-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02447</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Action Recognition Based on Joint Trajectory Maps Using Convolutional
  Neural Networks</dc:title>
 <dc:creator>Wang, Pichao</dc:creator>
 <dc:creator>Li, Zhaoyang</dc:creator>
 <dc:creator>Hou, Yonghong</dc:creator>
 <dc:creator>Li, Wanqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, Convolutional Neural Networks (ConvNets) have shown promising
performances in many computer vision tasks, especially image-based recognition.
How to effectively use ConvNets for video-based recognition is still an open
problem. In this paper, we propose a compact, effective yet simple method to
encode spatio-temporal information carried in $3D$ skeleton sequences into
multiple $2D$ images, referred to as Joint Trajectory Maps (JTM), and ConvNets
are adopted to exploit the discriminative features for real-time human action
recognition. The proposed method has been evaluated on three public benchmarks,
i.e., MSRC-12 Kinect gesture dataset (MSRC-12), G3D dataset and UTD multimodal
human action dataset (UTD-MHAD) and achieved the state-of-the-art results.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02450</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PipeCNN: An OpenCL-Based FPGA Accelerator for Large-Scale Convolution
  Neuron Networks</dc:title>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:creator>An, Jianjing</dc:creator>
 <dc:creator>Xu, Ke</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) have been widely employed in many
applications such as image classification, video analysis and speech
recognition. Being compute-intensive, CNN computations are mainly accelerated
by GPUs with high power dissipations. Recently, studies were carried out
exploiting FPGA as CNN accelerator because of its reconfigurability and energy
efficiency advantage over GPU, especially when OpenCL-based high-level
synthesis tools are now available providing fast verification and
implementation flows. Previous OpenCL-based design only focused on creating a
generic framework to identify performance-related hardware parameters, without
utilizing FPGA's special capability of pipelining kernel functions to minimize
memory bandwidth requirement. In this work, we propose an FPGA accelerator with
a new architecture of deeply pipelined OpenCL kernels. Data reuse and task
mapping techniques are also presented to improve design efficiency. The
proposed schemes are verified by implementing two representative large-scale
CNNs, AlexNet and VGG on Altera Stratix-V A7 FPGA. We have achieved a similar
peak performance of 33.9 GOPS with a 34% resource reduction on DSP blocks
compared to previous work. Our design is openly accessible and thus can be
reused to explore new architectures for neural network accelerators.
</dc:description>
 <dc:description>Comment: First Draft</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02453</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Data Complexity of Description Logic Ontologies</dc:title>
 <dc:creator>Lutz, Carsten</dc:creator>
 <dc:creator>Wolter, Frank</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We analyze the data complexity of ontology-mediated querying where the
ontologies are formulated in a description logic (DL) of the ALC family and
queries are conjunctive queries, positive existential queries, or acyclic
conjunctive queries. Our approach is non-uniform in the sense that we aim to
understand the complexity of each single ontology instead of for all ontologies
formulated in a certain language. While doing so, we quantify over the queries
and are interested, for example, in the question whether all queries can be
evaluated in polynomial time w.r.t. a given ontology. Our results include a
PTime/coNP-dichotomy for ontologies of depth one in the description logic
ALCFI, the same dichotomy for ALC- and ALCI-ontologies of unrestricted depth,
and the non-existence of such a dichotomy for ALCF-ontologies. For the latter
DL, we additionally show that it is undecidable whether a given ontology admits
PTime query evaluation. We also consider the connection between PTime query
evaluation and rewritability into (monadic) Datalog.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02453</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 4 (November
  13, 2017) lmcs:4060</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(4:7)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02459</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using cognitive agent-based simulation for the evaluation of indoor
  wayfinding systems</dc:title>
 <dc:creator>Schrom-Feiertag, Helmut</dc:creator>
 <dc:creator>Stubenschrott, Martin</dc:creator>
 <dc:creator>Regal, Georg</dc:creator>
 <dc:creator>Schrammel, Johann</dc:creator>
 <dc:creator>Settgast, Volker</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This paper presents a novel approach to simulate human wayfinding behaviour
incorporating visual cognition into a software agent for a computer aided
evaluation of wayfinding systems in large infrastructures. The proposed
approach follows the Sense-Plan-Act paradigm comprised of a model for visual
attention, navigation behaviour and pedestrian movement. Stochastic features of
perception are incorporated to enhance generality and diversity of the
developed wayfinding simulation to reflect a variety of behaviours. The
validity of the proposed approach was evaluated based on empirical data
collected through wayfinding experiments with 20 participants in an immersive
virtual reality environment using a life-sized 3D replica of Vienna's new
central railway station. The results show that the developed cognitive
agent-based simulation provides a further contribution to the simulation of
human wayfinding and subsequently a further step to an effective evaluation
tool for the planning of wayfinding and signage.
</dc:description>
 <dc:description>Comment: 13th International Conference on Design &amp; Decision Support Systems in
  Architecture and Urban Planning. June 2016</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02460</identifier>
 <datestamp>2017-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On coalescence time in graphs--When is coalescing as fast as meeting?</dc:title>
 <dc:creator>Kanade, Varun</dc:creator>
 <dc:creator>Mallmann-Trenn, Frederik</dc:creator>
 <dc:creator>Sauerwald, Thomas</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Coalescing random walks is a fundamental stochastic process, where a set of
particles perform independent discrete-time random walks on an undirected
graph. Whenever two or more particles meet at a given node, they merge and
continue as a single random walk. The {\em coalescence time} is defined as the
expected time until only one particle remains, starting from one particle at
every node. Despite recent progress such as by Cooper et al. and Berenbrink et
al., the coalescence time for graphs such as binary trees, $d$-dimensional
tori, hypercubes and more generally, vertex-transitive graphs, remains
unresolved.
  We provide a powerful toolkit that results in tight bounds for various
topologies including the aforementioned ones. The meeting time is defined as
the worst-case expected time required for two random walks to arrive at the
same node at the same time. As a general result, we establish that for graphs
whose meeting time is only marginally larger than the mixing time (a factor of
$\log^{2} n$), the coalescence time of $n$ random walks equals the meeting time
up to constant factors. This upper bound is complemented by the construction of
a graph family demonstrating that this result is the best possible up to
constant factors. For almost-regular graphs, we bound the coalescence time by
the hitting time, resolving the discrete-time variant of a conjecture by Aldous
for this class of graphs. Finally, we prove that for any graph the coalescence
time is bounded by $O(n^3)$. By duality, our results give bounds on the voter
model.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02463</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single-Tap Precoders and Decoders for Multi-User MIMO FBMC-OQAM under
  Strong Channel Frequency Selectivity</dc:title>
 <dc:creator>Rottenberg, Fran&#xe7;ois</dc:creator>
 <dc:creator>Mestre, Xavier</dc:creator>
 <dc:creator>Horlin, Fran&#xe7;ois</dc:creator>
 <dc:creator>Louveaux, J&#xe9;r&#xf4;me</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The design of linear precoders or decoders for multiuser (MU) multiple-input
multiple-output (MIMO) filterbank multicarrier (FBMC) modulations in the case
of strong channel frequency selectivity is presented. The users and the base
station (BS) communicate using space division multiple access (SDMA). The low
complexity proposed solution is based on a single tap per-subcarrier
precoding/decoding matrix at the base station (BS) in the downlink/uplink. As
opposed to classical approaches that assume flat channel frequency selectivity
at the subcarrier level, the BS does not make this assumption and takes into
account the distortion caused by channel frequency selectivity. The expression
of the FBMC asymptotic mean squared error (MSE) in the case of strong channel
selectivity derived in earlier works is developed and extended. The linear
precoders and decoders are found by optimizing the MSE formula under two design
criteria, namely zero forcing (ZF) or minimum mean squared error (MMSE).
Finally, simulation results demonstrate the performance of the optimized
design. As long as the number of BS antennas is larger than the number of
users, it is shown that those extra degrees of freedom can be used to
compensate for the channel frequency selectivity.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02463</dc:identifier>
 <dc:identifier>IEEE Transactions on Signal Processing (2016)</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2621722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02472</identifier>
 <datestamp>2017-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum sharing in energy harvesting cognitive radio networks: A
  cross-layer perspective</dc:title>
 <dc:creator>Zhang, Tian</dc:creator>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the paper, we present a cross-layer perspective on data transmission in
energy harvesting cognitive radio networks (CRNs). The delay optimal power
allocation is studied while taking into account the randomness of harvested
energy, data generation, channel state and the grid price. To guarantee primary
user (PU)'s transmission, its Signal-Interference-Ratio (SIR) should be no less
than a threshold. Each user, including PU as well as secondary user (SU), has
energy harvesting devices, and the PU can also purchases the grid power. Each
user is rational and selfish to minimize its own the buffer delay. We formulate
a stochastic Stackelberg game in a bilevel manner. After decoupling via
rewriting the objective and constraints, an equivalent tractable reconstruction
is derived. First, we give a distributive algorithm to obtain the Nash
equilibrium (NE) of the lower level SUs' noncooperative stochastic game.
Thereafter, the stochastic Stackelberg game is discussed under the
circumstances that there is no information exchange between PU and SU.
Distributed iterative algorithms are designed. Furthermore, a distributive
online algorithm is proposed. Finally, simulations are carried out to verify
the correctness and demonstrate the effectiveness of proposed algorithms.
</dc:description>
 <dc:description>Comment: Conference paper v2</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02488</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Interplay of Link-Flooding Attacks and Traffic Engineering</dc:title>
 <dc:creator>Gkounis, Dimitrios</dc:creator>
 <dc:creator>Kotronis, Vasileios</dc:creator>
 <dc:creator>Liaskos, Christos</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Link-flooding attacks have the potential to disconnect even entire countries
from the Internet. Moreover, newly proposed indirect link-flooding attacks,
such as 'Crossfire', are extremely hard to expose and, subsequently, mitigate
effectively. Traffic Engineering (TE) is the network's natural way of
mitigating link overload events, balancing the load and restoring connectivity.
This work poses the question: Do we need a new kind of TE to expose an attack
as well? The key idea is that a carefully crafted, attack-aware TE could force
the attacker to follow improbable traffic patterns, revealing his target and
his identity over time. We show that both existing and novel TE modules can
efficiently expose the attack, and study the benefits of each approach. We
implement defense prototypes using simulation mechanisms and evaluate them
extensively on multiple real topologies.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, ACM CCR</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02488</dc:identifier>
 <dc:identifier>ACM SIGCOMM Computer Communications Review, 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2935634.2935636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02491</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Framework for Modeling and Mitigating Distributed Link Flooding
  Attacks</dc:title>
 <dc:creator>Liaskos, hristos</dc:creator>
 <dc:creator>Kotronis, Vasileios</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Distributed link-flooding attacks constitute a new class of attacks with the
potential to segment large areas of the Internet. Their distributed nature
makes detection and mitigation very hard. This work proposes a novel framework
for the analytical modeling and optimal mitigation of such attacks. The
detection is modeled as a problem of relational algebra, representing the
association of potential attackers (bots) to potential targets. The analysis
seeks to optimally dissolve all but the malevolent associations. The framework
is implemented at the level of online Traffic Engineering (TE), which is
naturally triggered on link-flooding events. The key idea is to continuously
re-route traffic in a manner that makes persistent participation to
link-flooding events highly improbable for any benign source. Thus, bots are
forced to adopt a suspicious behavior to remain effective, revealing their
presence. The load-balancing objective of TE is not affected at all. Extensive
simulations on various topologies validate our analytical findings.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures, IEEE INFOCOM 2016</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02491</dc:identifier>
 <dc:identifier>IEEE INFOCOM 2016</dc:identifier>
 <dc:identifier>doi:10.1109/INFOCOM.2016.7524507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02493</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bots, Seeds and People: Web Archives as Infrastructure</dc:title>
 <dc:creator>Summers, Ed</dc:creator>
 <dc:creator>Punzalan, Ricardo</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>K.4.3</dc:subject>
 <dc:description>  The field of web archiving provides a unique mix of human and automated
agents collaborating to achieve the preservation of the web. Centuries old
theories of archival appraisal are being transplanted into the sociotechnical
environment of the World Wide Web with varying degrees of success. The work of
the archivist and bots in contact with the material of the web present a
distinctive and understudied CSCW shaped problem. To investigate this space we
conducted semi-structured interviews with archivists and technologists who were
directly involved in the selection of content from the web for archives. These
semi-structured interviews identified thematic areas that inform the appraisal
process in web archives, some of which are encoded in heuristics and
algorithms. Making the infrastructure of web archives legible to the archivist,
the automated agents and the future researcher is presented as a challenge to
the CSCW and archival community.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02493</dc:identifier>
 <dc:identifier>doi:10.1145/2998181.2998345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02494</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Routing Centralization Across Domains via SDN: A Model and Emulation
  Framework for BGP Evolution</dc:title>
 <dc:creator>Kotronis, Vasileios</dc:creator>
 <dc:creator>Gamperli, Adrian</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this work, we propose a radical, incrementally-deployable Internet routing
paradigm in which the control plane of multiple networks is centralized. This
follows the Software Defined Networking (SDN) paradigm, although at the
inter-domain level involving multiple Autonomous Systems (AS). Multi-domain SDN
centralization can be realized by outsourcing routing functions to an external
contractor, which provides inter-domain routing services facilitated through a
multi-AS network controller. The proposed model promises to become a vehicle
for evolving BGP and uses the bird's eye view over several networks to benefit
aspects of inter-domain routing, such as convergence properties, policy
conflict resolution, inter-domain troubleshooting, and collaborative security.
In addition to the proposed paradigm, we introduce a publicly available
emulation platform built on top of Mininet and the Quagga routing software, for
experimenting in hybrid BGP-SDN AS-level networks. As a proof of concept we
focus specifically on exploiting multi-domain centralization to improve BGP's
slow convergence. We build and make publicly available a first multi-AS
controller tailored to this use case and demonstrate experimentally that SDN
centralization helps to linearly reduce BGP convergence times and churn rates
with expanding SDN deployments.
</dc:description>
 <dc:description>Comment: Elsevier Computer Networks, Vol. 92, pages 227-239, 1/12/2015</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02496</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multidimensional Asymptotic Consensus in Dynamic Networks</dc:title>
 <dc:creator>Charron-Bost, Bernadette</dc:creator>
 <dc:creator>F&#xfc;gger, Matthias</dc:creator>
 <dc:creator>Nowak, Thomas</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We study the problem of asymptotic consensus as it occurs in a wide range of
applications in both man-made and natural systems. In particular, we study
systems with directed communication graphs that may change over time.
  We recently proposed a new family of convex combination algorithms in
dimension one whose weights depend on the received values and not only on the
communication topology. Here, we extend this approach to arbitrarily high
dimensions by introducing two new algorithms: the ExtremePoint and the Centroid
algorithm. Contrary to classical convex combination algorithms, both have
component-wise contraction rates that are constant in the number of agents.
Paired with a speed-up technique for convex combination algorithms, we get a
convergence time linear in the number of agents, which is optimal.
  Besides their respective contraction rates, the two algorithms differ in the
fact that the Centroid algorithm's update rule is independent of any coordinate
system while the ExtremePoint algorithm implicitly assumes a common agreed-upon
coordinate system among agents. The latter assumption may be realistic in some
man-made multi-agent systems but is highly questionable in systems designed for
the modelization of natural phenomena.
  Finally we prove that our new algorithms also achieve asymptotic consensus
under very weak connectivity assumptions, provided that agent interactions are
bidirectional.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02506</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Greedy Approach to Answer Reachability Queries on DAGs</dc:title>
 <dc:creator>Boria, Nicolas</dc:creator>
 <dc:creator>Cabodi, Gianpiero</dc:creator>
 <dc:creator>Camurati, Paolo</dc:creator>
 <dc:creator>Palena, Marco</dc:creator>
 <dc:creator>Pasini, Paolo</dc:creator>
 <dc:creator>Quer, Stefano</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Several modern applications involve huge graphs and require fast answers to
reachability queries. In more than two decades since first proposals, several
approaches have been presented adopting on-line searches, hop labelling or
transitive closure compression. Transitive closure compression techniques
usually construct a graph reachability index, for example by decomposing the
graph into disjoint chains. As memory consumption is proportional to the number
of chains, the target of those algorithms is to decompose the graph into an
optimal number \width\ of chains. However, commonly used techniques fail to
meet general expectations, are exceedingly complex, and their application on
large graphs is impractical. The main contribution of this paper is a novel
approach to construct such reachability indexes. The proposed method decomposes
the graph into a sub-optimal number $\widehat{c}$ of chains by following a
greedy strategy. We show that, given a vertex topological order, such a
decomposition is obtained in $\mathcal{O}(\widehat{c} m)$ time, and requires
$\mathcal{O}(\widehat{c} n)$ space, with $\widehat{c}$ bounded by $[c
\log(\frac{n}{c})]$. We provide experimental evidence suggesting that, on
different categories of automatically generated benchmarks as well as on graphs
arising from the field of logic synthesis and formal verification, the proposed
method produces a number of chains very close to the optimum, while
significantly reducing computation time.
</dc:description>
 <dc:description>Comment: 24 pages, 4 figures, 8 tables</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02508</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Makes a Link Successful on Wikipedia?</dc:title>
 <dc:creator>Dimitrov, Dimitar</dc:creator>
 <dc:creator>Singer, Philipp</dc:creator>
 <dc:creator>Lemmerich, Florian</dc:creator>
 <dc:creator>Strohmaier, Markus</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  While a plethora of hypertext links exist on the Web, only a small amount of
them are regularly clicked. Starting from this observation, we set out to study
large-scale click data from Wikipedia in order to understand what makes a link
successful. We systematically analyze effects of link properties on the
popularity of links. By utilizing mixed-effects hurdle models supplemented with
descriptive insights, we find evidence of user preference towards links leading
to the periphery of the network, towards links leading to semantically similar
articles, and towards links in the top and left-side of the screen. We
integrate these findings as Bayesian priors into a navigational Markov chain
model and by doing so successfully improve the model fits. We further adapt and
improve the well-known classic PageRank algorithm that assumes random
navigation by accounting for observed navigational preferences of users in a
weighted variation. This work facilitates understanding navigational click
behavior and thus can contribute to improving link structures and algorithms
utilizing these structures.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02508</dc:identifier>
 <dc:identifier>doi:10.1145/3038912.3052613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02512</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cognitive Discriminative Mappings for Rapid Learning</dc:title>
 <dc:creator>Fang, Wen-Chieh</dc:creator>
 <dc:creator>Chiang, Yi-ting</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Humans can learn concepts or recognize items from just a handful of examples,
while machines require many more samples to perform the same task. In this
paper, we build a computational model to investigate the possibility of this
kind of rapid learning. The proposed method aims to improve the learning task
of input from sensory memory by leveraging the information retrieved from
long-term memory. We present a simple and intuitive technique called cognitive
discriminative mappings (CDM) to explore the cognitive problem. First, CDM
separates and clusters the data instances retrieved from long-term memory into
distinct classes with a discrimination method in working memory when a sensory
input triggers the algorithm. CDM then maps each sensory data instance to be as
close as possible to the median point of the data group with the same class.
The experimental results demonstrate that the CDM approach is effective for
learning the discriminative features of supervised classifications with few
training sensory input instances.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02516</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tailored Mutants Fit Bugs Better</dc:title>
 <dc:creator>Allamanis, Miltiadis</dc:creator>
 <dc:creator>Barr, Earl T.</dc:creator>
 <dc:creator>Just, Ren&#xe9;</dc:creator>
 <dc:creator>Sutton, Charles</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Mutation analysis measures test suite adequacy, the degree to which a test
suite detects seeded faults: one test suite is better than another if it
detects more mutants. Mutation analysis effectiveness rests on the assumption
that mutants are coupled with real faults i.e. mutant detection is strongly
correlated with real fault detection. The work that validated this also showed
that a large portion of defects remain out of reach.
  We introduce tailored mutation operators to reach and capture these defects.
Tailored mutation operators are built from and apply to an existing codebase
and its history. They can, for instance, identify and replay errors specific to
the project for which they are tailored. As our point of departure, we define
tailored mutation operators for identifiers, which mutation analysis has
largely ignored, because there are too many ways to mutate them. Evaluated on
the Defects4J dataset, our new mutation operators creates mutants coupled to
14% more faults, compared to traditional mutation operators.
  These new mutation operators, however, quadruple the number of mutants. To
combat this problem, we propose a new approach to mutant selection focusing on
the location at which to apply mutation operators and the unnaturalness of the
mutated code. The results demonstrate that the location selection heuristics
produce mutants more closely coupled to real faults for a given budget of
mutation operator applications.
  In summary, this paper defines and explores tailored mutation operators,
advancing the state of the art in mutation testing in two ways: 1) it suggests
mutation operators that mutate identifiers and literals, extending mutation
analysis to a new class of faults and 2) it demonstrates that selecting the
location where a mutation operator is applied decreases the number of generated
mutants without affecting the coupling of mutants and real faults.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02518</identifier>
 <datestamp>2017-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Observer design for piecewise smooth and switched systems via
  contraction theory</dc:title>
 <dc:creator>Fiore, Davide</dc:creator>
 <dc:creator>Coraggio, Marco</dc:creator>
 <dc:creator>di Bernardo, Mario</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The aim of this paper is to present the application of an approach to study
contraction theory recently developed for piecewise smooth and switched
systems. The approach that can be used to analyze incremental stability
properties of so-called Filippov systems (or variable structure systems) is
based on the use of regularization, a procedure to make the vector field of
interest differentiable before analyzing its properties. We show that by using
this extension of contraction theory to nondifferentiable vector fields, it is
possible to design observers for a large class of piecewise smooth systems
using not only Euclidean norms, as also done in previous literature, but also
non-Euclidean norms. This allows greater flexibility in the design and
encompasses the case of both piecewise-linear and piecewise-smooth (nonlinear)
systems. The theoretical methodology is illustrated via a set of representative
examples.
</dc:description>
 <dc:description>Comment: Preprint accepted to IFAC World Congress 2017</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02525</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Loss Surface of Residual Networks: Ensembles and the Role of Batch
  Normalization</dc:title>
 <dc:creator>Littwin, Etai</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Residual Networks present a premium in performance in comparison to
conventional networks of the same depth and are trainable at extreme depths. It
has recently been shown that Residual Networks behave like ensembles of
relatively shallow networks. We show that these ensembles are dynamic: while
initially the virtual ensemble is mostly at depths lower than half the
network's depth, as training progresses, it becomes deeper and deeper. The main
mechanism that controls the dynamic ensemble behavior is the scaling
introduced, e.g., by the Batch Normalization technique. We explain this
behavior and demonstrate the driving force behind it. As a main tool in our
analysis, we employ generalized spin glass models, which we also use in order
to study the number of critical points in the optimization of Residual
Networks.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02528</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LTL Model-Checking for Dynamic Pushdown Networks Communicating via Locks</dc:title>
 <dc:creator>Song, Fu</dc:creator>
 <dc:creator>Touili, Tayssir</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A Dynamic Pushdown Network (DPN) is a set of pushdown systems (PDSs) where
each process can dynamically create new instances of PDSs. DPNs are a natural
model of multi-threaded programs with (possibly recursive) procedure calls and
thread creation. Extending DPNs with locks allows processes to synchronize with
each other. Thus, DPNs with locks are a well adapted formalism to model
multi-threaded programs that synchronize via locks. Therefore, it is important
to have model-checking algorithms for DPNs with locks. We consider in this work
model-checking for DPNs with locks against single-indexed LTL properties of the
form V fi s.t. fi is a LTL formula interpreted over the PDS i. We consider the
model-checking problems w.r.t. simple valuations (i.e, whether a configuration
satisfies an atomic proposition depends only on its control location and held
locks) and w.r.t. regular valuations (i.e., the set of the configurations
satisfying an atomic proposition is a regular set of configurations). We show
that these model-checking problems are decidable.
</dc:description>
 <dc:date>2016-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02530</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Random Dot Product Model for Weighted Networks</dc:title>
 <dc:creator>DeFord, Daryl R.</dc:creator>
 <dc:creator>Rockmore, Daniel N.</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>05C82, 90B15</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:description>  This paper presents a generalization of the random dot product model for
networks whose edge weights are drawn from a parametrized probability
distribution. We focus on the case of integer weight edges and show that many
previously studied models can be recovered as special cases of this
generalization. Our model also determines a dimension--reducing embedding
process that gives geometric interpretations of community structure and
centrality. The dimension of the embedding has consequences for the derived
community structure and we exhibit a stress function for determining
appropriate dimensions. We use this approach to analyze a coauthorship network
and voting data from the U.S. Senate.
</dc:description>
 <dc:description>Comment: 35 pages, 12 Figures</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02537</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network-wide Configuration Synthesis</dc:title>
 <dc:creator>El-Hassany, Ahmed</dc:creator>
 <dc:creator>Tsankov, Petar</dc:creator>
 <dc:creator>Vanbever, Laurent</dc:creator>
 <dc:creator>Vechev, Martin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Computer networks are hard to manage. Given a set of high-level requirements
(e.g., reachability, security), operators have to manually figure out the
individual configuration of potentially hundreds of devices running complex
distributed protocols so that they, collectively, compute a compatible
forwarding state. Not surprisingly, operators often make mistakes which lead to
downtimes. To address this problem, we present a novel synthesis approach that
automatically computes correct network configurations that comply with the
operator's requirements. We capture the behavior of existing routers along with
the distributed protocols they run in stratified Datalog. Our key insight is to
reduce the problem of finding correct input configurations to the task of
synthesizing inputs for a stratified Datalog program. To solve this synthesis
task, we introduce a new algorithm that synthesizes inputs for stratified
Datalog programs. This algorithm is applicable beyond the domain of networks.
We leverage our synthesis algorithm to construct the first network-wide
configuration synthesis system, called SyNET, that support multiple interacting
routing protocols (OSPF and BGP) and static routes. We show that our system is
practical and can infer correct input configurations, in a reasonable amount
time, for networks of realistic size (&gt; 50 routers) that forward packets for
multiple traffic classes.
</dc:description>
 <dc:description>Comment: 24 Pages, short version published in CAV 2017</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02538</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring disease causing genes and their pathways: A mathematical
  perspective</dc:title>
 <dc:creator>Devasia, Jeethu V.</dc:creator>
 <dc:creator>Chandran, Priya</dc:creator>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A system level view of cellular processes for human and several organisms can
be cap- tured by analyzing molecular interaction networks. A molecular
interaction network formed of differentially expressed genes and their
interactions helps to understand key players behind disease development. So, if
the functions of these genes are blocked by altering their interactions, it
would have a great impact in controlling the disease. Due to this promising
consequence, the problem of inferring disease causing genes and their pathways
has attained a crucial position in computational biology research. However,
considering the huge size of interaction networks, executing computations can
be costly. Review of literatures shows that the methods proposed for finding
the set of disease causing genes could be assessed in terms of their accuracy
which a perfect algorithm would find. Along with accuracy, the time complexity
of the method is also important, as high time complexities would limit the
number of pathways that could be found within a pragmatic time interval.
</dc:description>
 <dc:description>Comment: This article had submitted in the journals Bioinformatics and
  Computer Methods and Programs in Biomedicine. But, it was not accepted for
  publication</dc:description>
 <dc:date>2016-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02541</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arc diagrams, flip distances, and Hamiltonian triangulations</dc:title>
 <dc:creator>Cardinal, Jean</dc:creator>
 <dc:creator>Hoffmann, Michael</dc:creator>
 <dc:creator>Kusters, Vincent</dc:creator>
 <dc:creator>T&#xf3;th, Csaba D.</dc:creator>
 <dc:creator>Wettstein, Manuel</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>68R10, 05C62, 05C45</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We show that every triangulation (maximal planar graph) on $n\ge 6$ vertices
can be flipped into a Hamiltonian triangulation using a sequence of less than
$n/2$ combinatorial edge flips. The previously best upper bound uses
$4$-connectivity as a means to establish Hamiltonicity. But in general about
$3n/5$ flips are necessary to reach a $4$-connected triangulation. Our result
improves the upper bound on the diameter of the flip graph of combinatorial
triangulations on $n$ vertices from $5.2n-33.6$ to $5n-23$. We also show that
for every triangulation on $n$ vertices there is a simultaneous flip of less
than $2n/3$ edges to a $4$-connected triangulation. The bound on the number of
edges is tight, up to an additive constant. As another application we show that
every planar graph on $n$ vertices admits an arc diagram with less than $n/2$
biarcs, that is, after subdividing less than $n/2$ (of potentially $3n-6$)
edges the resulting graph admits a $2$-page book embedding.
</dc:description>
 <dc:description>Comment: 29 pages, full version of our STACS 2015 paper corrected wrong author
  affiliation marks from v1</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02546</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UniFlex: Accelerating Networking Research and Experimentation through
  Software-Defined Wireless Networking</dc:title>
 <dc:creator>Gaw&#x142;owicz, Piotr</dc:creator>
 <dc:creator>Zubow, Anatolij</dc:creator>
 <dc:creator>Chwalisz, Mikolaj</dc:creator>
 <dc:creator>Wolisz, Adam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Classical control and management plane for computer networks is addressing
individual parameters of protocol layers within an individual wireless network
device. We argue that this is not sufficient in phase of increasing deployment
of highly re-configurable systems, as well as heterogeneous wireless systems
co-existing in the same radio spectrum which demand harmonized, frequently even
coordinated adaptation of multiple parameters in different protocol layers
(cross-layer) in multiple network devices (cross-node).
  We propose UniFlex, a framework enabling unified and flexible radio and
network control. It provides an API enabling coordinated cross-layer control
and management operation over multiple network nodes. The controller logic may
be implemented either in a centralized or distributed manner. This allows to
place time-sensitive control functions close to the controlled device (i.e.,
local control application), off-load more resource hungry network application
to compute servers and make them work together to control entire network.
  The UniFlex framework was prototypically implemented and provided to the
research community as open-source. We evaluated the the framework in a number
of use-cases, what proved its usability.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02550</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative Acoustic Word Embeddings: Recurrent Neural Network-Based
  Approaches</dc:title>
 <dc:creator>Settle, Shane</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Acoustic word embeddings --- fixed-dimensional vector representations of
variable-length spoken word segments --- have begun to be considered for tasks
such as speech recognition and query-by-example search. Such embeddings can be
learned discriminatively so that they are similar for speech segments
corresponding to the same word, while being dissimilar for segments
corresponding to different words. Recent work has found that acoustic word
embeddings can outperform dynamic time warping on query-by-example search and
related word discrimination tasks. However, the space of embedding models and
training approaches is still relatively unexplored. In this paper we present
new discriminative embedding models based on recurrent neural networks (RNNs).
We consider training losses that have been successful in prior work, in
particular a cross entropy loss for word classification and a contrastive loss
that explicitly aims to separate same-word and different-word pairs in a
&quot;Siamese network&quot; training setting. We find that both classifier-based and
Siamese RNN embeddings improve over previously reported results on a word
discrimination task, with Siamese RNNs outperforming classification models. In
addition, we present analyses of the learned embeddings and the effects of
variables such as dimensionality and network structure.
</dc:description>
 <dc:description>Comment: To appear at SLT 2016</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02552</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Uplink Spectral Efficiency of Full-Duplex Cooperative OFDMA
  Systems</dc:title>
 <dc:creator>Banar, Jafar</dc:creator>
 <dc:creator>Razavizadeh, S. Mohammad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we develop a resource allocation algorithm for uplink of
in-band full-duplex (FD) cellular networks. The FD cellular network is assumed
to be based on orthogonal frequency division multiple access (OFDMA) and
consists of a base station communicating with multiple users. Some of the users
in the network act as relay for other users and help them to transmit their
data to the base station. These relays are FD and work based on amplify and
forward (AF) protocol. By appropriate selection of the relays and optimized
allocation of subcarriers and powers to all users, we try to maximize the total
sum rate of the network. During this optimization, we also impose some
constraints on the users' quality of service (QoS) and power. We propose a new
algorithm to select the best relays based on the users' maximum data rate and
also use Linear Assignment Problem Jonker-Volgenant (LAPJV) algorithm for
subcarrier assignment. It is proved that the resulting optimization problem can
be converted to a convex problem, and hence it can be solved by standard
numerical methods. The simulation results demonstrate the effect of the
proposed scheme on the sum rate and coverage of the network.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, conference</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02554</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Neural Noisy Channel</dc:title>
 <dc:creator>Yu, Lei</dc:creator>
 <dc:creator>Blunsom, Phil</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Grefenstette, Edward</dc:creator>
 <dc:creator>Kocisky, Tomas</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We formulate sequence to sequence transduction as a noisy channel decoding
problem and use recurrent neural networks to parameterise the source and
channel models. Unlike direct models which can suffer from explaining-away
effects during training, noisy channel models must produce outputs that explain
their inputs, and their component models can be trained with not only paired
training samples but also unpaired samples from the marginal output
distribution. Using a latent variable to control how much of the conditioning
sequence the channel model needs to read in order to generate a subsequent
symbol, we obtain a tractable and effective beam search decoder. Experimental
results on abstractive sentence summarisation, morphological inflection, and
machine translation show that noisy channel models outperform direct models,
and that they significantly benefit from increased amounts of unpaired output
data that direct models cannot easily use.
</dc:description>
 <dc:description>Comment: ICLR 2017</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02565</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of SIR epidemiological model: new trends</dc:title>
 <dc:creator>Rodrigues, Helena Sofia</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  The simplest epidemiologic model composed by mutually exclusive compartments
SIR (susceptible-infected-susceptible) is presented to describe a reality. From
health concerns to situations related with marketing, informatics or even
sociology, several are the fields that are using this epidemiological model as
a first approach to better understand a situation. In this paper, the basic
transmission model is analyzed, as well as simple tools that allows us to
extract a great deal of information about possible solutions. A set of
applications - traditional and new ones - is described to show the importance
of this model.
</dc:description>
 <dc:description>Comment: Please cite this paper as: Rodrigues, Helena Sofia (2016).
  Application of SIR epidemiological model: new trends, International Journal
  of Applied Mathematics and Informatics, 10: 92--97</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02565</dc:identifier>
 <dc:identifier>International Journal of Applied Mathematics and Informatics, 10:
  92--97, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02568</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PixelSNE: Visualizing Fast with Just Enough Precision via Pixel-Aligned
  Stochastic Neighbor Embedding</dc:title>
 <dc:creator>Kim, Minjeong</dc:creator>
 <dc:creator>Choi, Minsuk</dc:creator>
 <dc:creator>Lee, Sunwoong</dc:creator>
 <dc:creator>Tang, Jian</dc:creator>
 <dc:creator>Park, Haesun</dc:creator>
 <dc:creator>Choo, Jaegul</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Embedding and visualizing large-scale high-dimensional data in a
two-dimensional space is an important problem since such visualization can
reveal deep insights out of complex data. Most of the existing embedding
approaches, however, run on an excessively high precision, ignoring the fact
that at the end, embedding outputs are converted into coarse-grained discrete
pixel coordinates in a screen space. Motivated by such an observation and
directly considering pixel coordinates in an embedding optimization process, we
accelerate Barnes-Hut tree-based t-distributed stochastic neighbor embedding
(BH-SNE), known as a state-of-the-art 2D embedding method, and propose a novel
method called PixelSNE, a highly-efficient, screen resolution-driven 2D
embedding method with a linear computational complexity in terms of the number
of data items. Our experimental results show the significantly fast running
time of PixelSNE by a large margin against BH-SNE, while maintaining the
minimal degradation in the embedding quality. Finally, the source code of our
method is publicly available at https://github.com/awesome-davian/PixelSNE
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02569</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse multivariate factorization by mean of a few bivariate
  factorizations</dc:title>
 <dc:creator>Parisse, Bernard</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We describe an algorithm to factor sparse multivariate polynomials using O(d)
bivariate factorizations where d is the number of variables. This algorithm is
implemented in the Giac/Xcas computer algebra system.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02588</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contradiction Detection for Rumorous Claims</dc:title>
 <dc:creator>Lendvai, Piroska</dc:creator>
 <dc:creator>Reichel, Uwe D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The utilization of social media material in journalistic workflows is
increasing, demanding automated methods for the identification of mis- and
disinformation. Since textual contradiction across social media posts can be a
signal of rumorousness, we seek to model how claims in Twitter posts are being
textually contradicted. We identify two different contexts in which
contradiction emerges: its broader form can be observed across independently
posted tweets and its more specific form in threaded conversations. We define
how the two scenarios differ in terms of central elements of argumentation:
claims and conversation structure. We design and evaluate models for the two
scenarios uniformly as 3-way Recognizing Textual Entailment tasks in order to
represent claims and conversation structure implicitly in a generic inference
model, while previous studies used explicit or no representation of these
properties. To address noisy text, our classifiers use simple similarity
features derived from the string and part-of-speech level. Corpus statistics
reveal distribution differences for these features in contradictory as opposed
to non-contradictory tweet relations, and the classifiers yield state of the
art performance.
</dc:description>
 <dc:description>Comment: To appear in: Proceedings of Extra-Propositional Aspects of Meaning
  (ExProM) in Computational Linguistics, Osaka, Japan, 2016</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02588</dc:identifier>
 <dc:identifier>Proc. Extra-Propositional Aspects of Meaning (ExProM) in
  Computational Linguistics, Osaka, Japan, 2016, pp 31-40</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02589</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimal Ancestry Labeling Scheme with Applications to XML Trees and
  Universal Posets</dc:title>
 <dc:creator>Fraigniaud, Pierre</dc:creator>
 <dc:creator>Korman, Amos</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper we solve the ancestry-labeling scheme problem which aims at
assigning the shortest possible labels (bit strings) to nodes of rooted trees,
so that ancestry queries between any two nodes can be answered by inspecting
their assigned labels only. This problem was introduced more than twenty years
ago by Kannan et al. [STOC '88], and is among the most well-studied problems in
the field of informative labeling schemes. We construct an ancestry-labeling
scheme for $n$-node trees with label size $\log_2 n + O(\log \log n)$ bits,
thus matching the $\log_2 n + O(\log \log n)$ bits lower bound given by Alstrup
et al. [SODA '03]. Our scheme is based on a simplified ancestry scheme that
operates extremely well on a restricted set of trees. In particular, for the
set of n-node trees with depth at most d, the simplified ancestry scheme enjoys
label size of $\log_2 n + 2 \log_2 d + O(1)$ bits. Since the depth of most XML
trees is at most some small constant, such an ancestry scheme may be of
practical use. In addition, we also obtain an adjacency-labeling scheme that
labels n-node trees of depth d with labels of size $\log_2 n + 3 \log_2 d +
O(1)$ bits. All our schemes assign the labels in linear time, and guarantee
that any query can be answered in constant time. Finally, our ancestry scheme
finds applications to the construction of small universal partially ordered
sets (posets). Specifically, for any fixed integer k, it enables the
construction of a universal poset of size $\tilde O(n^k)$ for the family of
$n$-element posets with tree-dimension at most $k$. Up to lower order terms,
this bound is tight thanks to a lower bound of $n^{k-o(1)}$ due to Alon and
Scheinerman [Order '88].
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02589</dc:identifier>
 <dc:identifier>Journal of the ACM, ACM, 2016, 63, pp.1 - 31</dc:identifier>
 <dc:identifier>doi:10.1145/2794076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02590</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Veracity Computing from Lexical Cues and Perceived Certainty Trends</dc:title>
 <dc:creator>Reichel, Uwe D.</dc:creator>
 <dc:creator>Lendvai, Piroska</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a data-driven method for determining the veracity of a set of
rumorous claims on social media data. Tweets from different sources pertaining
to a rumor are processed on three levels: first, factuality values are assigned
to each tweet based on four textual cue categories relevant for our journalism
use case; these amalgamate speaker support in terms of polarity and commitment
in terms of certainty and speculation. Next, the proportions of these lexical
cues are utilized as predictors for tweet certainty in a generalized linear
regression model. Subsequently, lexical cue proportions, predicted certainty,
as well as their time course characteristics are used to compute veracity for
each rumor in terms of the identity of the rumor-resolving tweet and its binary
resolution value judgment. The system operates without access to
extralinguistic resources. Evaluated on the data portion for which hand-labeled
examples were available, it achieves .74 F1-score on identifying rumor
resolving tweets and .76 F1-score on predicting if a rumor is resolved as true
or false.
</dc:description>
 <dc:description>Comment: to appear in: Proc. 2nd Workshop on Noisy User-generated Text, Osaka,
  Japan, 2016</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02590</dc:identifier>
 <dc:identifier>Proc. 2nd Workshop on Noisy User-generated Text, Osaka, Japan,
  2016, pp 33--42</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02603</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Path-complete positivity of switching systems</dc:title>
 <dc:creator>Forni, Fulvio</dc:creator>
 <dc:creator>Jungers, Raphael M.</dc:creator>
 <dc:creator>Sepulchre, Rodolphe</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The notion of path-complete positivity is introduced as a way to generalize
the property of positivity from one LTI system to a family of switched LTI
systems whose switching rule is constrained by a finite automaton. The
generalization builds upon the analogy between stability and positivity, the
former referring to the contraction of a norm, the latter referring to the
contraction of a cone (or, equivalently, a projective norm). We motivate and
investigate the potential of path-positivity and we propose an algorithm for
the automatic verification of positivity.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02614</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Static Cellular Cooperation between Mutually Nearest
  Neighboring Nodes</dc:title>
 <dc:creator>Corrales, Luis David Alvarez</dc:creator>
 <dc:creator>Giovanidis, Anastasios</dc:creator>
 <dc:creator>Martins, Philippe</dc:creator>
 <dc:creator>Decreusefond, Laurent</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Cooperation in cellular networks is a promising scheme to improve system
performance. Existing works consider that a user dynamically chooses the
stations that cooperate for his/her service, but such assumption often has
practical limitations. Instead, cooperation groups can be predefined and
static, with nodes linked by fixed infrastructure. To analyze such a potential
network, we propose a grouping method based on node proximity. With the
Mutually Nearest Neighbour Relation, we allow the formation of singles and
pairs of nodes. Given an initial topology for the stations, two new point
processes are defined, one for the singles and one for the pairs. We derive
structural characteristics for these processes and analyse the resulting
interference fields. When the node positions follow a Poisson Point Process
(PPP) the processes of singles and pairs are not Poisson. However, the
performance of the original model can be approximated by the superposition of
two PPPs. This allows the derivation of exact expressions for the coverage
probability. Numerical evaluation shows coverage gains from different signal
cooperation that can reach up to 15% compared to the standard noncooperative
coverage. The analysis is general and can be applied to any type of cooperation
in pairs of transmitting nodes.
</dc:description>
 <dc:description>Comment: 17 pages, double column, Appendices A-D, 9 Figures, 18 total
  subfigures. arXiv admin note: text overlap with arXiv:1604.04640</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02616</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Lightweight, Non-intrusive Approach for Orchestrating
  Autonomously-managed Network Elements</dc:title>
 <dc:creator>Liaskos, Christos</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Software-Defined Networking enables the centralized orchestration of data
traffic within a network. However, proposed solutions require a high degree of
architectural penetration. The present study targets the orchestration of
network elements that do not wish to yield much of their internal operations to
an external controller. Backpressure routing principles are used for deriving
flow routing rules that optimally stabilize a network, while maximizing its
throughput. The elements can then accept in full, partially or reject the
proposed routing rule-set. The proposed scheme requires minimal, relatively
infrequent interaction with a controller, limiting its imposed workload,
promoting scalability. The proposed scheme exhibits attracting network
performance gains, as demonstrated by extensive simulations and proven via
mathematical analysis.
</dc:description>
 <dc:description>Comment: 6 pages 7, figures, IEEE ISCC'15</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02616</dc:identifier>
 <dc:identifier>IEEE ISCC 2015</dc:identifier>
 <dc:identifier>doi:10.1109/ISCC.2015.7405537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02619</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Protocol for a Systematic Mapping Study on Collaborative Model-Driven
  Software Engineering</dc:title>
 <dc:creator>Franzago, Mirco</dc:creator>
 <dc:creator>Di Ruscio, Davide</dc:creator>
 <dc:creator>Malavolta, Ivano</dc:creator>
 <dc:creator>Muccini, Henry</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Nowadays, collaborative modeling performed by multiple stakeholders is
gaining a growing interest in both academia and practice. However, it poses a
set of research challenges, such as large and complex models management,
support for multi-user modeling environments, and synchronization mechanisms
like models migration and merging, conflicts management, models versioning and
rollback support. A body of knowledge in the scientific literature about
collaborative model-driven software engineering (MDSE) exists. Still, those
studies are scattered across different independent research areas, such as
software engineering, model-driven engineering languages and systems, model
integrated computing, etc., and a study classifying and comparing the various
approaches and methods for collaborative MDSE is still missing. Under this
perspective, a systematic mapping study (SMS) can help researchers and
practitioners in (i) having a complete, comprehensive and valid picture of the
state of the art about collaborative MDSE, and (ii) identifying potential gaps
in current research and future research directions.
</dc:description>
 <dc:description>Comment: Technical Report TRCS 001/2016 - Department of Information
  Engineering, Computer Science and Mathematics (DISIM) - University of
  L'Aquila - Italy</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02624</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Look into Public IXP Datasets</dc:title>
 <dc:creator>Kloti, Rowan</dc:creator>
 <dc:creator>Ager, Bernhard</dc:creator>
 <dc:creator>Kotronis, Vasileios</dc:creator>
 <dc:creator>Nomikos, George</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Internet eXchange Points (IXPs) are core components of the Internet
infrastructure where Internet Service Providers (ISPs) meet and exchange
traffic. During the last few years, the number and size of IXPs have increased
rapidly, driving the flattening and shortening of Internet paths. However,
understanding the present status of the IXP ecosystem and its potential role in
shaping the future Internet requires rigorous data about IXPs, their presence,
status, participants, etc. In this work, we do the first cross-comparison of
three well-known publicly available IXP databases, namely of PeeringDB,
Euro-IX, and PCH. A key challenge we address is linking IXP identifiers across
databases maintained by different organizations. We find different AS-centric
versus IXP-centric views provided by the databases as a result of their data
collection approaches. In addition, we highlight differences and similarities
w.r.t. IXP participants, geographical coverage, and co-location facilities. As
a side-product of our linkage heuristics, we make publicly available the union
of the three databases, which includes 40.2 % more IXPs and 66.3 % more IXP
participants than the commonly-used PeeringDB. We also publish our analysis
code to foster reproducibility of our experiments and shed preliminary insights
into the accuracy of the union dataset.
</dc:description>
 <dc:description>Comment: ACM Computer Communication Review, Vol. 46 / Issue 1, pages 21-29,
  11/1/2016</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02628</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control Exchange Points: Providing QoS-enabled End-to-End Services via
  SDN-based Inter-domain Routing Orchestration</dc:title>
 <dc:creator>Kotronis, Vasileios</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:creator>Kloti, Rowan</dc:creator>
 <dc:creator>Ager, Bernhard</dc:creator>
 <dc:creator>Georgopoulos, Panagiotis</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper presents the vision of the Control Exchange Point (CXP)
architectural model. The model is motivated by the inflexibility and
ossification of today's inter-domain routing system, which renders critical
QoS-constrained end-to-end (e2e) network services difficult or simply
impossible to provide. CXPs operate on slices of ISP networks and are built on
basic Software Defined Networking (SDN) principles, such as the clean
decoupling of the routing control plane from the data plane and the consequent
logical centralization of control. The main goal of the architectural model is
to provide e2e services with QoS constraints across domains. This is achieved
through defining a new type of business relationship between ISPs, which
advertise partial paths (so-called pathlets) with specific properties, and the
orchestrating role of the CXPs, which dynamically stitch them together and
provision e2e QoS. Revenue from value-added services flows from the clients of
the CXP to the ISPs participating in the service. The novelty of the approach
is the combination of SDN programmability and dynamic path stitching techniques
for inter-domain routing, which extends the value proposition of SDN over
multiple domains. We first describe the challenges related to e2e service
provision with the current inter-domain routing and peering model, and then
continue with the benefits of our approach. Subsequently, we describe the CXP
model in detail and report on an initial feasibility analysis.
</dc:description>
 <dc:description>Comment: Presented as part of the USENIX Open Networking Summit 2014 (ONS
  2014), 2/3/2015</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02629</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RSB Decoupling Property of MAP Estimators</dc:title>
 <dc:creator>Bereyhi, Ali</dc:creator>
 <dc:creator>M&#xfc;ller, Ralf R.</dc:creator>
 <dc:creator>Schulz-Baldes, Hermann</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The large-system decoupling property of a MAP estimator is studied when it
estimates the i.i.d. vector $\boldsymbol{x}$ from the observation
$\boldsymbol{y}=\mathbf{A}\boldsymbol{x}+\boldsymbol{z}$ with $\mathbf{A}$
being chosen from a wide range of matrix ensembles, and the noise vector
$\boldsymbol{z}$ being i.i.d. and Gaussian. Using the replica method, we show
that the marginal joint distribution of any two corresponding input and output
symbols converges to a deterministic distribution which describes the
input-output distribution of a single user system followed by a MAP estimator.
Under the $b$RSB assumption, the single user system is a scalar channel with
additive noise where the noise term is given by the sum of an independent
Gaussian random variable and $b$ correlated interference terms. As the $b$RSB
assumption reduces to RS, the interference terms vanish which results in the
formerly studied RS decoupling principle.
</dc:description>
 <dc:description>Comment: 5 pages, presented in Information Theory Workshop 2016</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02629</dc:identifier>
 <dc:identifier>doi:10.1109/ITW.2016.7606860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02635</identifier>
 <datestamp>2017-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Lyapunov Analysis of Momentum Methods in Optimization</dc:title>
 <dc:creator>Wilson, Ashia C.</dc:creator>
 <dc:creator>Recht, Benjamin</dc:creator>
 <dc:creator>Jordan, Michael I.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Momentum methods play a central role in optimization. Several momentum
methods are provably optimal, and all use a technique called estimate sequences
to analyze their convergence properties. The technique of estimate sequences
has long been considered difficult to understand, leading many researchers to
generate alternative, &quot;more intuitive&quot; methods and analyses. In this paper we
show there is an equivalence between the technique of estimate sequences and a
family of Lyapunov functions in both continuous and discrete time. This
framework allows us to develop a simple and unified analysis of many existing
momentum algorithms, introduce several new algorithms, and most importantly,
strengthen the connection between algorithms and continuous-time dynamical
systems.
</dc:description>
 <dc:description>Comment: Cleaned up the Appendix and fixed typos</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02637</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating motion with principal component regression strategies</dc:title>
 <dc:creator>Carmo, Felipe P. do</dc:creator>
 <dc:creator>Estrela, Vania Vieira</dc:creator>
 <dc:creator>de Assis, Joaquim Teixeira</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, two simple principal component regression methods for
estimating the optical flow between frames of video sequences according to a
pel-recursive manner are introduced. These are easy alternatives to dealing
with mixtures of motion vectors in addition to the lack of prior information on
spatial-temporal statistics (although they are supposed to be normal in a local
sense). The 2D motion vector estimation approaches take into consideration
simple image properties and are used to harmonize regularized least square
estimates. Their main advantage is that no knowledge of the noise distribution
is necessary, although there is an underlying assumption of localized
smoothness. Preliminary experiments indicate that this approach provides robust
estimates of the optical flow.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures. arXiv admin note: substantial text overlap with
  arXiv:1610.02923</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02637</dc:identifier>
 <dc:identifier>Proceedings of the IEEE International Workshop on Multimedia
  Signal Processing, 2009, MMSP '09, 2009</dc:identifier>
 <dc:identifier>doi:10.1109/mmsp.2009.5293264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02639</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradients of Counterfactuals</dc:title>
 <dc:creator>Sundararajan, Mukund</dc:creator>
 <dc:creator>Taly, Ankur</dc:creator>
 <dc:creator>Yan, Qiqi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Gradients have been used to quantify feature importance in machine learning
models. Unfortunately, in nonlinear deep networks, not only individual neurons
but also the whole network can saturate, and as a result an important input
feature can have a tiny gradient. We study various networks, and observe that
this phenomena is indeed widespread, across many inputs.
  We propose to examine interior gradients, which are gradients of
counterfactual inputs constructed by scaling down the original input. We apply
our method to the GoogleNet architecture for object recognition in images, as
well as a ligand-based virtual screening network with categorical features and
an LSTM based language model for the Penn Treebank dataset. We visualize how
interior gradients better capture feature importance. Furthermore, interior
gradients are applicable to a wide variety of deep networks, and have the
attribution property that the feature importance scores sum to the the
prediction score.
  Best of all, interior gradients can be computed just as easily as gradients.
In contrast, previous methods are complex to implement, which hinders practical
adoption.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02642</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stitching Inter-Domain Paths over IXPs</dc:title>
 <dc:creator>Kotronis, Vasileios</dc:creator>
 <dc:creator>Kloti, Rowan</dc:creator>
 <dc:creator>Rost, Matthias</dc:creator>
 <dc:creator>Georgopoulos, Panagiotis</dc:creator>
 <dc:creator>Ager, Bernhard</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Modern Internet applications, from HD video-conferencing to health monitoring
and remote control of power-plants, pose stringent demands on network latency,
bandwidth and availability. An approach to support such applications and
provide inter-domain guarantees, enabling new avenues for innovation, is using
centralized inter-domain routing brokers. These entities centralize routing
control for mission-critical traffic across domains, working in parallel to
BGP. In this work, we propose using IXPs as natural points for stitching
inter-domain paths under the control of inter-domain routing brokers. To
evaluate the potential of this approach, we first map the global substrate of
inter-IXP pathlets that IXP members could offer, based on measurements for 229
IXPs worldwide. We show that using IXPs as stitching points has two useful
properties. Up to 91 % of the total IPv4 address space can be served by such
inter-domain routing brokers when working in concert with just a handful of
large IXPs and their associated ISP members. Second, path diversity on the
inter-IXP graph increases by up to 29 times, as compared to current BGP
valley-free routing. To exploit the rich path diversity, we introduce
algorithms that inter-domain routing brokers can use to embed paths, subject to
bandwidth and latency constraints. We show that our algorithms scale to the
sizes of the measured graphs and can serve diverse simulated path request
mixes. Our work highlights a novel direction for SDN innovation across domains,
based on logically centralized control and programmable IXP fabrics.
</dc:description>
 <dc:description>Comment: Proceedings of ACM SOSR 2016, pages 1-12, 1/1/2016</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02644</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multispectral Deep Neural Networks for Pedestrian Detection</dc:title>
 <dc:creator>Liu, Jingjing</dc:creator>
 <dc:creator>Zhang, Shaoting</dc:creator>
 <dc:creator>Wang, Shu</dc:creator>
 <dc:creator>Metaxas, Dimitris N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multispectral pedestrian detection is essential for around-the-clock
applications, e.g., surveillance and autonomous driving. We deeply analyze
Faster R-CNN for multispectral pedestrian detection task and then model it into
a convolutional network (ConvNet) fusion problem. Further, we discover that
ConvNet-based pedestrian detectors trained by color or thermal images
separately provide complementary information in discriminating human instances.
Thus there is a large potential to improve pedestrian detection by using color
and thermal images in DNNs simultaneously. We carefully design four ConvNet
fusion architectures that integrate two-branch ConvNets on different DNNs
stages, all of which yield better performance compared with the baseline
detector. Our experimental results on KAIST pedestrian benchmark show that the
Halfway Fusion model that performs fusion on the middle-level convolutional
features outperforms the baseline method by 11% and yields a missing rate 3.5%
lower than the other proposed architectures.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures, BMVC 2016 oral</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02646</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On interestingness measures of formal concepts</dc:title>
 <dc:creator>Kuznetsov, Sergei O.</dc:creator>
 <dc:creator>Makhalova, Tatiana</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Formal concepts and closed itemsets proved to be of big importance for
knowledge discovery, both as a tool for concise representation of association
rules and a tool for clustering and constructing domain taxonomies and
ontologies. Exponential explosion makes it difficult to consider the whole
concept lattice arising from data, one needs to select most useful and
interesting concepts. In this paper interestingness measures of concepts are
considered and compared with respect to various aspects, such as efficiency of
computation and applicability to noisy data and performing ranking correlation.
</dc:description>
 <dc:description>Comment: 20 pages, 5 figures, 3 tables</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02648</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Unsupervised Clustering with Gaussian Mixture Variational
  Autoencoders</dc:title>
 <dc:creator>Dilokthanakul, Nat</dc:creator>
 <dc:creator>Mediano, Pedro A. M.</dc:creator>
 <dc:creator>Garnelo, Marta</dc:creator>
 <dc:creator>Lee, Matthew C. H.</dc:creator>
 <dc:creator>Salimbeni, Hugh</dc:creator>
 <dc:creator>Arulkumaran, Kai</dc:creator>
 <dc:creator>Shanahan, Murray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study a variant of the variational autoencoder model (VAE) with a Gaussian
mixture as a prior distribution, with the goal of performing unsupervised
clustering through deep generative models. We observe that the known problem of
over-regularisation that has been shown to arise in regular VAEs also manifests
itself in our model and leads to cluster degeneracy. We show that a heuristic
called minimum information constraint that has been shown to mitigate this
effect in VAEs can also be applied to improve unsupervised clustering
performance with our model. Furthermore we analyse the effect of this heuristic
and provide an intuition of the various processes with the help of
visualizations. Finally, we demonstrate the performance of our model on
synthetic data, MNIST and SVHN, showing that the obtained clusters are
distinct, interpretable and result in achieving competitive performance on
unsupervised clustering to the state-of-the-art results.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, Under review as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02654</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sentence Ordering and Coherence Modeling using Recurrent Neural Networks</dc:title>
 <dc:creator>Logeswaran, Lajanugen</dc:creator>
 <dc:creator>Lee, Honglak</dc:creator>
 <dc:creator>Radev, Dragomir</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Modeling the structure of coherent texts is a key NLP problem. The task of
coherently organizing a given set of sentences has been commonly used to build
and evaluate models that understand such structure. We propose an end-to-end
unsupervised deep learning approach based on the set-to-sequence framework to
address this problem. Our model strongly outperforms prior methods in the order
discrimination task and a novel task of ordering abstracts from scientific
articles. Furthermore, our work shows that useful text representations can be
obtained by learning to order sentences. Visualizing the learned sentence
representations shows that the model captures high-level logical structure in
paragraphs. Our representations perform comparably to state-of-the-art
pre-training methods on sentence similarity and paraphrase detection tasks.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02655</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Statistics of Lattice Graph Percolation Models</dc:title>
 <dc:creator>Kruzick, Stephen</dc:creator>
 <dc:creator>Moura, Jose M. F.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In graph signal processing, the graph adjacency matrix or the graph Laplacian
commonly define the shift operator. The spectral decomposition of the shift
operator plays an important role in that the eigenvalues represent frequencies
and the eigenvectors provide a spectral basis. This is useful, for example, in
the design of filters. However, the graph or network may be uncertain due to
stochastic influences in construction and maintenance, and, under such
conditions, the eigenvalues of the shift matrix become random variables. This
paper examines the spectral distribution of the eigenvalues of random networks
formed by including each link of a D-dimensional lattice supergraph
independently with identical probability, a percolation model. Using the
stochastic canonical equation methods developed by Girko for symmetric matrices
with independent upper triangular entries, a deterministic distribution is
found that asymptotically approximates the empirical spectral distribution of
the scaled adjacency matrix for a model with arbitrary parameters. The main
results characterize the form of the solution to an important system of
equations that leads to this deterministic distribution function and
significantly reduce the number of equations that must be solved to find the
solution for a given set of model parameters. Simulations comparing the
expected empirical spectral distributions and the computed deterministic
distributions are provided for sample parameters.
</dc:description>
 <dc:date>2016-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02659</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GSM based CommSense system to measure and estimate environmental changes</dc:title>
 <dc:creator>Bhatta, Abhishek</dc:creator>
 <dc:creator>Mishra, Amit Kumar</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Facilitating the coexistence of radar systems with communication systems has
been a major area of research in radar engineering. The current work presents a
new way to sense the environment using the channel equalization block of
existing communication systems. We have named this system CommSense. In the
current paper we demonstrate the feasibility of the system using Global System
for Mobile Communications (GSM) signals. The implementation has been done using
open-source Software Defined Radio (SDR) environment. In the preliminary
results obtained in our work we show that it is possible to distinguish
environmental changes using the proposed system. The major advantage of the
system is that it is inexpensive as channel estimation is an inherent block in
any communication system and hence the added cost to make it work as an
environment sensor is minimal. The major challenge, on which we are continuing
our work, is how to characterize the features in the environmental changes.
This is an acute challenge given the fact that the bandwidth available is
narrow and the system is inherently a forward looking radar. However the
initial results, as shown in this paper, are encouraging and we intend to use
an application specific instrumentation (ASIN) scheme to distinguish the
environmental changes.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02659</dc:identifier>
 <dc:identifier>IEEE Aerospace and Electronic Systems Magazine Volume 32 Issue 2
  February 2017</dc:identifier>
 <dc:identifier>doi:10.1109/MAES.2017.150272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02660</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tradeoff Caching Strategy of Outage Probability and Fronthaul Usage in
  Cloud-RAN</dc:title>
 <dc:creator>Ye, Zhun</dc:creator>
 <dc:creator>Pan, Cunhua</dc:creator>
 <dc:creator>Zhu, Huiling</dc:creator>
 <dc:creator>Wang, Jiangzhou</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, optimal content caching strategy is proposed to jointly
minimize the cell average outage probability and fronthaul usage in cloud radio
access network (Cloud-RAN). At first, an accurate closed form expression of the
outage probability conditioned on the user's location is presented, and the
cell average outage probability is obtained through the composite Simpson's
integration. The caching strategy for jointly optimizing the cell average
outage probability and fronthaul usage is then formulated as a weighted sum
minimization problem, which is a nonlinear 0-1 integer NP-hard problem. In
order to deal with the NP-hard problem, two heuristic algorithms are proposed
in this paper. Firstly, a genetic algorithm (GA) based approach is proposed.
Numerical results show that the performance of the proposed GA-based approach
with significantly reduced computational complexity is close to the optimal
performance achieved by exhaustive search based caching strategy. Secondly, in
order to further reduce the computational complexity, a mode selection approach
is proposed. Numerical results show that this approach can achieve near-optimal
performance over a wide range of the weighting factors through a single
computation.
</dc:description>
 <dc:description>Comment: submitted to one journal for possible publication</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02663</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of Local Distributed Graph Problems</dc:title>
 <dc:creator>Ghaffari, Mohsen</dc:creator>
 <dc:creator>Kuhn, Fabian</dc:creator>
 <dc:creator>Maus, Yannic</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper is centered on the complexity of graph problems in the
well-studied LOCAL model of distributed computing, introduced by Linial [FOCS
'87]. It is widely known that for many of the classic distributed graph
problems (including maximal independent set (MIS) and $(\Delta+1)$-vertex
coloring), the randomized complexity is at most polylogarithmic in the size $n$
of the network, while the best deterministic complexity is typically
$2^{O(\sqrt{\log n})}$. Understanding and narrowing down this exponential gap
is considered to be one of the central long-standing open questions in the area
of distributed graph algorithms. We investigate the problem by introducing a
complexity-theoretic framework that allows us to shed some light on the role of
randomness in the LOCAL model. We define the SLOCAL model as a sequential
version of the LOCAL model. Our framework allows us to prove completeness
results with respect to the class of problems which can be solved efficiently
in the SLOCAL model, implying that if any of the complete problems can be
solved deterministically in $\log^{O(1)} n$ rounds in the LOCAL model, we can
deterministically solve all efficient SLOCAL-problems (including MIS and
$(\Delta+1)$-coloring) in $\log^{O(1)} n$ rounds in the LOCAL model. We show
that a rather rudimentary looking graph coloring problem is complete in the
above sense: Color the nodes of a graph with colors red and blue such that each
node of sufficiently large polylogarithmic degree has at least one neighbor of
each color. The problem admits a trivial zero-round randomized solution. The
result can be viewed as showing that the only obstacle to getting efficient
determinstic algorithms in the LOCAL model is an efficient algorithm to
approximately round fractional values into integer values.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02665</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization and parallelization of B-spline based orbital evaluations
  in QMC on multi/many-core shared memory processors</dc:title>
 <dc:creator>Mathuriya, Amrita</dc:creator>
 <dc:creator>Luo, Ye</dc:creator>
 <dc:creator>Benali, Anouar</dc:creator>
 <dc:creator>Shulenburger, Luke</dc:creator>
 <dc:creator>Kim, Jeongnim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  B-spline based orbital representations are widely used in Quantum Monte Carlo
(QMC) simulations of solids, historically taking as much as 50% of the total
run time. Random accesses to a large four-dimensional array make it challenging
to efficiently utilize caches and wide vector units of modern CPUs. We present
node-level optimizations of B-spline evaluations on multi/many-core shared
memory processors. To increase SIMD efficiency and bandwidth utilization, we
first apply data layout transformation from array-of-structures to
structure-of-arrays (SoA). Then by blocking SoA objects, we optimize cache
reuse and get sustained throughput for a range of problem sizes. We implement
efficient nested threading in B-spline orbital evaluation kernels, paving the
way towards enabling strong scaling of QMC simulations. These optimizations are
portable on four distinct cache-coherent architectures and result in up to 5.6x
performance enhancements on Intel Xeon Phi processor 7250P (KNL), 5.7x on Intel
Xeon Phi coprocessor 7120P, 10x on an Intel Xeon processor E5v4 CPU and 9.5x on
BlueGene/Q processor. Our nested threading implementation shows nearly ideal
parallel efficiency on KNL up to 16 threads. We employ roofline performance
analysis to model the impacts of our optimizations. This work combined with our
current efforts of optimizing other QMC kernels, result in greater than 4.5x
speedup of miniQMC on KNL.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures, 4 tables</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02665</dc:identifier>
 <dc:identifier>doi:10.1109/IPDPS.2017.33</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02666</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mosaic: Designing Online Creative Communities for Sharing
  Works-in-Progress</dc:title>
 <dc:creator>Kim, Joy</dc:creator>
 <dc:creator>Agrawala, Maneesh</dc:creator>
 <dc:creator>Bernstein, Michael S.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  Online creative communities allow creators to share their work with a large
audience, maximizing opportunities to showcase their work and connect with fans
and peers. However, sharing in-progress work can be technically and socially
challenging in environments designed for sharing completed pieces. We propose
an online creative community where sharing process, rather than showcasing
outcomes, is the main method of sharing creative work. Based on this, we
present Mosaic---an online community where illustrators share work-in-progress
snapshots showing how an artwork was completed from start to finish. In an
online deployment and observational study, artists used Mosaic as a vehicle for
reflecting on how they can improve their own creative process, developed a
social norm of detailed feedback, and became less apprehensive of sharing early
versions of artwork. Through Mosaic, we argue that communities oriented around
sharing creative process can create a collaborative environment that is
beneficial for creative growth.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02666</dc:identifier>
 <dc:identifier>doi:10.1145/2998181.2998195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02675</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$k$-connectivity of inhomogeneous random key graphs with unreliable
  links</dc:title>
 <dc:creator>Eletreby, Rashad</dc:creator>
 <dc:creator>Ya&#x11f;an, Osman</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider secure and reliable connectivity in wireless sensor networks that
utilize a heterogeneous random key predistribution scheme. We model the
unreliability of wireless links by an on-off channel model that induces an
Erd\H{o}s-R\'enyi graph, while the heterogeneous scheme induces an
inhomogeneous random key graph. The overall network can thus be modeled by the
intersection of both graphs. We present conditions (in the form of zero-one
laws) on how to scale the parameters of the intersection model so that with
high probability i) all of its nodes are connected to at least $k$ other nodes;
i.e., the minimum node degree of the graph is no less than $k$ and ii) the
graph is $k$-connected, i.e., the graph remains connected even if any $k-1$
nodes leave the network. We also present numerical results to support these
conditions in the finite-node regime. Our results are shown to complement and
generalize several previous work in the literature.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Mobile Computing</dc:description>
 <dc:date>2016-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02682</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mechanical Novel: Crowdsourcing Complex Work through Reflection and
  Revision</dc:title>
 <dc:creator>Kim, Joy</dc:creator>
 <dc:creator>Sterman, Sarah</dc:creator>
 <dc:creator>Cohen, Allegra Argent Beal</dc:creator>
 <dc:creator>Bernstein, Michael S.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  Crowdsourcing systems accomplish large tasks with scale and speed by breaking
work down into independent parts. However, many types of complex creative work,
such as fiction writing, have remained out of reach for crowds because work is
tightly interdependent: changing one part of a story may trigger changes to the
overall plot and vice versa. Taking inspiration from how expert authors write,
we propose a technique for achieving interdependent complex goals with crowds.
With this technique, the crowd loops between reflection, to select a high-level
goal, and revision, to decompose that goal into low-level, actionable tasks. We
embody this approach in Mechanical Novel, a system that crowdsources short
fiction stories on Amazon Mechanical Turk. In a field experiment, Mechanical
Novel resulted in higher-quality stories than an iterative crowdsourcing
workflow. Our findings suggest that orienting crowd work around high-level
goals may enable workers to coordinate their effort to accomplish complex work.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02682</dc:identifier>
 <dc:identifier>doi:10.1145/2998181.2998196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02683</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Pretraining for Sequence to Sequence Learning</dc:title>
 <dc:creator>Ramachandran, Prajit</dc:creator>
 <dc:creator>Liu, Peter J.</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Sequence to sequence models are successful tools for supervised sequence
learning tasks, such as machine translation. Despite their success, these
models still require much labeled data and it is unclear how to improve them
using unlabeled data, which is much less expensive to obtain. In this paper, we
present simple changes that lead to a significant improvement in the accuracy
of seq2seq models when the labeled set is small. Our method intializes the
encoder and decoder of the seq2seq model with the trained weights of two
language models, and then all weights are jointly fine-tuned with labeled data.
An additional language modeling loss can be used to regularize the model during
fine-tuning. We apply this method to low-resource tasks in machine translation
and abstractive summarization and find that it significantly improves the
subsequent supervised models. Our main finding is that the pretraining
accelerates training and improves generalization of seq2seq models, achieving
state-of-the-art results on the WMT English$\rightarrow$German task. Our model
obtains an improvement of 1.3 BLEU from the previous best models on both WMT'14
and WMT'15 English$\rightarrow$German. Our ablation study shows that
pretraining helps seq2seq models in different ways depending on the nature of
the task: translation benefits from the improved generalization whereas
summarization benefits from the improved optimization.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02695</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic recognition of child speech for robotic applications in noisy
  environments</dc:title>
 <dc:creator>Fernando, Samuel</dc:creator>
 <dc:creator>Moore, Roger K.</dc:creator>
 <dc:creator>Cameron, David</dc:creator>
 <dc:creator>Collins, Emily C.</dc:creator>
 <dc:creator>Millings, Abigail</dc:creator>
 <dc:creator>Sharkey, Amanda J.</dc:creator>
 <dc:creator>Prescott, Tony J.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Automatic speech recognition (ASR) allows a natural and intuitive interface
for robotic educational applications for children. However there are a number
of challenges to overcome to allow such an interface to operate robustly in
realistic settings, including the intrinsic difficulties of recognising child
speech and high levels of background noise often present in classrooms. As part
of the EU EASEL project we have provided several contributions to address these
challenges, implementing our own ASR module for use in robotics applications.
We used the latest deep neural network algorithms which provide a leap in
performance over the traditional GMM approach, and apply data augmentation
methods to improve robustness to noise and speaker variation. We provide a
close integration between the ASR module and the rest of the dialogue system,
allowing the ASR to receive in real-time the language models relevant to the
current section of the dialogue, greatly improving the accuracy. We integrated
our ASR module into an interactive, multimodal system using a small humanoid
robot to help children learn about exercise and energy. The system was
installed at a public museum event as part of a research study where 320
children (aged 3 to 14) interacted with the robot, with our ASR achieving 90%
accuracy for fluent and near-fluent speech.
</dc:description>
 <dc:description>Comment: Submission to Computer Speech and Language, special issue on
  Interaction Technologies for Children</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02698</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emulated Inertia and Damping of Converter-Interfaced Power Source</dc:title>
 <dc:creator>Wang, Bin</dc:creator>
 <dc:creator>Zhang, Yichen</dc:creator>
 <dc:creator>Sun, Kai</dc:creator>
 <dc:creator>Tomsovic, Kevin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Converter-interfaced power sources (CIPSs), like wind turbine and energy
storage, can be switched to the inertia emulation mode when the detected
frequency deviation exceeds a pre-designed threshold, i.e. dead band, to
support the frequency response of a power grid. This letter proposes an
approach to derive the emulated inertia and damping from a CIPS based on the
linearized model of the CIPS and the power grid, where the grid is represented
by an equivalent single machine. The emulated inertia and damping can be
explicitly expressed in time and turn out to be time-dependent.
</dc:description>
 <dc:description>Comment: 2 pages, 2 figures</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02717</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resilience Design Patterns - A Structured Approach to Resilience at
  Extreme Scale (version 1.0)</dc:title>
 <dc:creator>Hukerikar, Saurabh</dc:creator>
 <dc:creator>Engelmann, Christian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this document, we develop a structured approach to the management of HPC
resilience based on the concept of resilience-based design patterns. A design
pattern is a general repeatable solution to a commonly occurring problem. We
identify the commonly occurring problems and solutions used to deal with
faults, errors and failures in HPC systems. The catalog of resilience design
patterns provides designers with reusable design elements. We define a design
framework that enhances our understanding of the important constraints and
opportunities for solutions deployed at various layers of the system stack. The
framework may be used to establish mechanisms and interfaces to coordinate
flexible fault management across hardware and software components. The
framework also enables optimization of the cost-benefit trade-offs among
performance, resilience, and power consumption. The overall goal of this work
is to enable a systematic methodology for the design and evaluation of
resilience technologies in extreme-scale HPC systems that keep scientific
applications running to a correct solution in a timely and cost-efficient
manner in spite of frequent faults, errors, and failures of various types.
</dc:description>
 <dc:description>Comment: Oak Ridge National Laboratory Technical Report version 1.0</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02721</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unit circle MVDR beamformer</dc:title>
 <dc:creator>Tuladhar, Saurav R</dc:creator>
 <dc:creator>Buck, John R</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The array polynomial is the z-transform of the array weights for a narrowband
planewave beamformer using a uniform linear array (ULA). Evaluating the array
polynomial on the unit circle in the complex plane yields the beampattern. The
locations of the polynomial zeros on the unit circle indicate the nulls of the
beampattern. For planewave signals measured with a ULA, the locations of the
ensemble MVDR polynomial zeros are constrained on the unit circle. However,
sample matrix inversion (SMI) MVDR polynomial zeros generally do not fall on
the unit circle. The proposed unit circle MVDR (UC MVDR) projects the zeros of
the SMI MVDR polynomial radially on the unit circle. This satisfies the
constraint on the zeros of ensemble MVDR polynomial. Numerical simulations show
that the UC MVDR beamformer suppresses interferers better than the SMI MVDR and
the diagonal loaded MVDR beamformer and also improves the white noise gain
(WNG).
</dc:description>
 <dc:description>Comment: Accepted to ICASSP 2015</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02721</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2015.7178418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02723</identifier>
 <datestamp>2017-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bandwidth Enhancement in Multimode Polymer Waveguides Using Waveguide
  Layout for Optical Printed Circuit Boards</dc:title>
 <dc:creator>Chen, Jian</dc:creator>
 <dc:creator>Bamiedakis, Nikos</dc:creator>
 <dc:creator>Vasil'ev, Peter</dc:creator>
 <dc:creator>Penty, Richard V.</dc:creator>
 <dc:creator>White, Ian H.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Dispersion studies demonstrate that waveguide layout can be used to enhance
the bandwidth performance of multimode polymer waveguides for use in
board-level optical interconnects, providing &gt;40 GHzxm without the need for any
launch conditioning.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, Optical Fiber Communication Conference (OFC)</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:date>2017-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02723</dc:identifier>
 <dc:identifier>Optical Fiber Communication Conference (OFC), paper W1E.3, 2016</dc:identifier>
 <dc:identifier>doi:10.1364/OFC.2016.W1E.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02730</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Cardiac Motion Estimation using Ultrafast Ultrasound Data: A
  Low-Rank-Topology-Preserving Approach</dc:title>
 <dc:creator>Aviles, Angelica I.</dc:creator>
 <dc:creator>Widlak, Thomas</dc:creator>
 <dc:creator>Casals, Alicia</dc:creator>
 <dc:creator>Nillesen, Maartje M.</dc:creator>
 <dc:creator>Ammari, Habib</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cardiac motion estimation is an important diagnostic tool to detect heart
diseases and it has been explored with modalities such as MRI and conventional
ultrasound (US) sequences. US cardiac motion estimation still presents
challenges because of the complex motion patterns and the presence of noise. In
this work, we propose a novel approach to estimate the cardiac motion using
ultrafast ultrasound data. -- Our solution is based on a variational
formulation characterized by the L2-regularized class. The displacement is
represented by a lattice of b-splines and we ensure robustness by applying a
maximum likelihood type estimator. While this is an important part of our
solution, the main highlight of this paper is to combine a low-rank data
representation with topology preservation. Low-rank data representation
(achieved by finding the k-dominant singular values of a Casorati Matrix
arranged from the data sequence) speeds up the global solution and achieves
noise reduction. On the other hand, topology preservation (achieved by
monitoring the Jacobian determinant) allows to radically rule out distortions
while carefully controlling the size of allowed expansions and contractions.
Our variational approach is carried out on a realistic dataset as well as on a
simulated one. We demonstrate how our proposed variational solution deals with
complex deformations through careful numerical experiments. While maintaining
the accuracy of the solution, the low-rank preprocessing is shown to speed up
the convergence of the variational problem. Beyond cardiac motion estimation,
our approach is promising for the analysis of other organs that experience
motion.
</dc:description>
 <dc:description>Comment: 15 pages, 10 figures, Physics in Medicine and Biology, 2017</dc:description>
 <dc:date>2016-10-26</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02730</dc:identifier>
 <dc:identifier>doi:10.1088/1361-6560/aa6914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02731</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Lossy Autoencoder</dc:title>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Kingma, Diederik P.</dc:creator>
 <dc:creator>Salimans, Tim</dc:creator>
 <dc:creator>Duan, Yan</dc:creator>
 <dc:creator>Dhariwal, Prafulla</dc:creator>
 <dc:creator>Schulman, John</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Representation learning seeks to expose certain aspects of observed data in a
learned representation that's amenable to downstream tasks like classification.
For instance, a good representation for 2D images might be one that describes
only global structure and discards information about detailed texture. In this
paper, we present a simple but principled method to learn such global
representations by combining Variational Autoencoder (VAE) with neural
autoregressive models such as RNN, MADE and PixelRNN/CNN. Our proposed VAE
model allows us to have control over what the global latent code can learn and
, by designing the architecture accordingly, we can force the global latent
code to discard irrelevant information such as texture in 2D images, and hence
the VAE only &quot;autoencodes&quot; data in a lossy fashion. In addition, by leveraging
autoregressive models as both prior distribution $p(z)$ and decoding
distribution $p(x|z)$, we can greatly improve generative modeling performance
of VAEs, achieving new state-of-the-art results on MNIST, OMNIGLOT and
Caltech-101 Silhouettes density estimation tasks.
</dc:description>
 <dc:description>Comment: Added CIFAR10 experiments; ICLR 2017</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02733</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum node degree in inhomogeneous random key graphs with unreliable
  links</dc:title>
 <dc:creator>Eletreby, Rashad</dc:creator>
 <dc:creator>Ya&#x11f;an, Osman</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider wireless sensor networks under a heterogeneous random key
predistribution scheme and an on-off channel model. The heterogeneous key
predistribution scheme has recently been introduced by Ya\u{g}an - as an
extension to the Eschenauer and Gligor scheme - for the cases when the network
consists of sensor nodes with varying level of resources and/or connectivity
requirements, e.g., regular nodes vs. cluster heads. The network is modeled by
the intersection of the inhomogeneous random key graph (induced by the
heterogeneous scheme) with an Erd\H{o}s-R\'enyi graph (induced by the on/off
channel model). We present conditions (in the form of zero-one laws) on how to
scale the parameters of the intersection model so that with high probability
all of its nodes are connected to at least $k$ other nodes; i.e., the minimum
node degree of the graph is no less than $k$. We also present numerical results
to support our results in the finite-node regime. The numerical results suggest
that the conditions that ensure $k$-connectivity coincide with those ensuring
the minimum node degree being no less than $k$.
</dc:description>
 <dc:description>Comment: In proceedings of the IEEE International Symposium on Information
  Theory (ISIT) 2016. arXiv admin note: substantial text overlap with
  arXiv:1610.07576, arXiv:1611.02675</dc:description>
 <dc:date>2016-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02737</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Discovery of Ontology Functional Dependencies</dc:title>
 <dc:creator>Baskaran, Sridevi</dc:creator>
 <dc:creator>Keller, Alexander</dc:creator>
 <dc:creator>Chiang, Fei</dc:creator>
 <dc:creator>Lukasz, Golab</dc:creator>
 <dc:creator>Szlichta, Jaroslaw</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Poor data quality has become a pervasive issue due to the increasing
complexity and size of modern datasets. Constraint based data cleaning
techniques rely on integrity constraints as a benchmark to identify and correct
errors. Data values that do not satisfy the given set of constraints are
flagged as dirty, and data updates are made to re-align the data and the
constraints. However, many errors often require user input to resolve due to
domain expertise defining specific terminology and relationships. For example,
in pharmaceuticals, 'Advil' \emph{is-a} brand name for 'ibuprofen' that can be
captured in a pharmaceutical ontology. While functional dependencies (FDs) have
traditionally been used in existing data cleaning solutions to model syntactic
equivalence, they are not able to model broader relationships (e.g., is-a)
defined by an ontology. In this paper, we take a first step towards extending
the set of data quality constraints used in data cleaning by defining and
discovering \emph{Ontology Functional Dependencies} (OFDs). We lay out
theoretical and practical foundations for OFDs, including a set of sound and
complete axioms, and a linear inference procedure. We then develop effective
algorithms for discovering OFDs, and a set of optimizations that efficiently
prune the search space. Our experimental evaluation using real data show the
scalability and accuracy of our algorithms.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02739</identifier>
 <datestamp>2017-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursive Regression with Neural Networks: Approximating the HJI PDE
  Solution</dc:title>
 <dc:creator>Royo, Vicen&#xe7; Rubies</dc:creator>
 <dc:creator>Tomlin, Claire</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  The majority of methods used to compute approximations to the
Hamilton-Jacobi-Isaacs partial differential equation (HJI PDE) rely on the
discretization of the state space to perform dynamic programming updates. This
type of approach is known to suffer from the curse of dimensionality due to the
exponential growth in grid points with the state dimension. In this work we
present an approximate dynamic programming algorithm that computes an
approximation of the solution of the HJI PDE by alternating between solving a
regression problem and solving a minimax problem using a feedforward neural
network as the function approximator. We find that this method requires less
memory to run and to store the approximation than traditional gridding methods,
and we test it on a few systems of two, three and six dimensions.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02755</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursive Decomposition for Nonconvex Optimization</dc:title>
 <dc:creator>Friesen, Abram L.</dc:creator>
 <dc:creator>Domingos, Pedro</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Continuous optimization is an important problem in many areas of AI,
including vision, robotics, probabilistic inference, and machine learning.
Unfortunately, most real-world optimization problems are nonconvex, causing
standard convex techniques to find only local optima, even with extensions like
random restarts and simulated annealing. We observe that, in many cases, the
local modes of the objective function have combinatorial structure, and thus
ideas from combinatorial optimization can be brought to bear. Based on this, we
propose a problem-decomposition approach to nonconvex optimization. Similarly
to DPLL-style SAT solvers and recursive conditioning in probabilistic
inference, our algorithm, RDIS, recursively sets variables so as to simplify
and decompose the objective function into approximately independent
sub-functions, until the remaining functions are simple enough to be optimized
by standard techniques like gradient descent. The variables to set are chosen
by graph partitioning, ensuring decomposition whenever possible. We show
analytically that RDIS can solve a broad class of nonconvex optimization
problems exponentially faster than gradient descent with random restarts.
Experimentally, RDIS outperforms standard techniques on problems like structure
from motion and protein folding.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures, pdflatex</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02755</dc:identifier>
 <dc:identifier>Proceedings of the 24th International Joint Conference on
  Artificial Intelligence (2015), pp. 253-259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02756</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Peeling Bipartite Networks for Dense Subgraph Discovery</dc:title>
 <dc:creator>Sariyuce, A. Erdem</dc:creator>
 <dc:creator>Pinar, Ali</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Finding dense bipartite subgraphs and detecting the relations among them is
an important problem for affiliation networks that arise in a range of domains,
such as social network analysis, word-document clustering, the science of
science, internet advertising, and bioinformatics. However, most dense subgraph
discovery algorithms are designed for classic, unipartite graphs. Subsequently,
studies on affiliation networks are conducted on the co-occurrence graphs
(e.g., co-author and co-purchase) that project the bipartite structure to a
unipartite structure by connecting two entities if they share an affiliation.
Despite their convenience, co-occurrence networks come at a cost of loss of
information and an explosion in graph sizes, which limit the quality and the
efficiency of solutions. We study the dense subgraph discovery problem on
bipartite graphs. We define a framework of bipartite subgraphs based on the
butterfly motif (2,2-biclique) to model the dense regions in a hierarchical
structure. We introduce efficient peeling algorithms to find the dense
subgraphs and build relations among them. We can identify denser structures
compared to the state-of-the-art algorithms on co-occurrence graphs in
real-world data. Our analyses on an author-paper network and a user-product
network yield interesting subgraphs and hierarchical relations such as the
groups of collaborators in the same institution and spammers that give fake
ratings.
</dc:description>
 <dc:description>Comment: To appear in WSDM'18</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02758</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ZeroTouch Provisioning (ZTP) Model and Infrastructure Components for
  Multi-provider Cloud Services Provisioning</dc:title>
 <dc:creator>Demchenko, Yuri</dc:creator>
 <dc:creator>Grosso, Paola</dc:creator>
 <dc:creator>de Laat, Cees</dc:creator>
 <dc:creator>Filiposka, Sonja</dc:creator>
 <dc:creator>de Vos, Migiel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper presents results of the ongoing development of the Cloud Services
Delivery Infrastructure (CSDI) that provides a basis for infrastructure centric
cloud services provisioning, operation and management in multi-cloud
multi-provider environment defined as a Zero Touch Provisioning, Operation and
Management (ZTP/ZTPOM) model. The presented work refers to use cases from data
intensive research that require high performance computation resources and
large storage volumes that are typically distributed between datacenters often
involving multiple cloud providers. Automation for large scale scientific (and
industrial) applications should include provisioning of both inter-cloud
network infrastructure and intra-cloud application resources. It should provide
support for the complete application operation workflow together with the
possible application infrastructure and resources changes that can occur during
the application lifecycle. The authors investigate existing technologies for
automation of the service provisioning and management processes aiming to
cross-pollinate best practices from currently disconnected domains such as
cloud based applications provisioning and multi-domain high-performance network
provisioning. The paper refers to the previous and legacy research by authors,
the Open Cloud eXchange (OCX), that has been proposed to address the last mile
problem in cloud services delivery to campuses over trans-national backbone
networks such as GEANT. OCX will serve as an integral component of the
prospective ZTP infrastructure over the GEANT network. Another important
component, the Marketplace, is defined for providing cloud services and
applications discovery (in generally intercloud environment) and may also
support additional services such as services composition and trust brokering
for establishing customer-provider federations.
</dc:description>
 <dc:description>Comment: 6 pages, 2 fugures</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02758</dc:identifier>
 <dc:identifier>Fifth IEEE International Workshop on Cloud Computing Interclouds,
  Multiclouds, Federations, and Interoperability (Intercloud 2016), In Proc.
  IEEE International Conference on Cloud Engineering (IC2E), April 4 - 8, 2016,
  Berlin, Germany</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02764</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring low-dimensional microstructure representations using
  convolutional neural networks</dc:title>
 <dc:creator>Lubbers, Nicholas</dc:creator>
 <dc:creator>Lookman, Turab</dc:creator>
 <dc:creator>Barros, Kipton</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We apply recent advances in machine learning and computer vision to a central
problem in materials informatics: The statistical representation of
microstructural images. We use activations in a pre-trained convolutional
neural network to provide a high-dimensional characterization of a set of
synthetic microstructural images. Next, we use manifold learning to obtain a
low-dimensional embedding of this statistical characterization. We show that
the low-dimensional embedding extracts the parameters used to generate the
images. According to a variety of metrics, the convolutional neural network
method yields dramatically better embeddings than the analogous method derived
from two-point correlations alone.
</dc:description>
 <dc:description>Comment: 25 Pages, 12 Figures</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02764</dc:identifier>
 <dc:identifier>Phys. Rev. E 96, 052111 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.96.052111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02767</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A backward pass through a CNN using a generative model of its
  activations</dc:title>
 <dc:creator>Wang, Huayan</dc:creator>
 <dc:creator>Chen, Anna</dc:creator>
 <dc:creator>Liu, Yi</dc:creator>
 <dc:creator>George, Dileep</dc:creator>
 <dc:creator>Phoenix, D. Scott</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural networks have shown to be a practical way of building a very complex
mapping between a pre-specified input space and output space. For example, a
convolutional neural network (CNN) mapping an image into one of a thousand
object labels is approaching human performance in this particular task. However
the mapping (neural network) does not automatically lend itself to other forms
of queries, for example, to detect/reconstruct object instances, to enforce
top-down signal on ambiguous inputs, or to recover object instances from
occlusion. One way to address these queries is a backward pass through the
network that fuses top-down and bottom-up information. In this paper, we show a
way of building such a backward pass by defining a generative model of the
neural network's activations. Approximate inference of the model would
naturally take the form of a backward pass through the CNN layers, and it
addresses the aforementioned queries in a unified framework.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02770</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delving into Transferable Adversarial Examples and Black-box Attacks</dc:title>
 <dc:creator>Liu, Yanpei</dc:creator>
 <dc:creator>Chen, Xinyun</dc:creator>
 <dc:creator>Liu, Chang</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  An intriguing property of deep neural networks is the existence of
adversarial examples, which can transfer among different architectures. These
transferable adversarial examples may severely hinder deep neural network-based
applications. Previous works mostly study the transferability using small scale
datasets. In this work, we are the first to conduct an extensive study of the
transferability over large models and a large scale dataset, and we are also
the first to study the transferability of targeted adversarial examples with
their target labels. We study both non-targeted and targeted adversarial
examples, and show that while transferable non-targeted adversarial examples
are easy to find, targeted adversarial examples generated using existing
approaches almost never transfer with their target labels. Therefore, we
propose novel ensemble-based approaches to generating transferable adversarial
examples. Using such approaches, we observe a large proportion of targeted
adversarial examples that are able to transfer with their target labels for the
first time. We also present some geometric studies to help understanding the
transferable adversarial examples. Finally, we show that the adversarial
examples generated using ensemble-based approaches can successfully attack
Clarifai.com, which is a black-box image classification system.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02775</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supporting Education in Math Sciences with a Low-budget LMS SAKAI</dc:title>
 <dc:creator>Petrova, Mimoza</dc:creator>
 <dc:creator>Cabukovski, Vanco</dc:creator>
 <dc:creator>Golubovski, Roman</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In this paper we present the Low-budget LMS Sakai, the analysis conducted and
its selection from a list of few popular Low-budget LMSs, as well as its
capability in presentation of math texts and formulas. The MATHEIS e-learning
system for learning mathematics and informatics and its empowering with few
software agent based features including the new developed GUPA (Graphic User
Presentation Agent) software agent is emphasized. The plugins offered for Sakai
allow powerful mathematics presentation capabilities, one of them being the
WIRIS plugin. The paper is focused on the Sakai WIRIS plugin implementation.
</dc:description>
 <dc:description>Comment: 14 pages, 4 figures</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02775</dc:identifier>
 <dc:identifier>Mathematical Bulletin ISSN 0351-336X (print)ISSN 1857-9914
  (online) Vol. 40, No. 2, 2016, p. 95 2016 (95-108)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02776</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Convolutional Neural Network for 6-DOF Image Localization</dc:title>
 <dc:creator>Jia, Daoyuan</dc:creator>
 <dc:creator>Su, Yongchi</dc:creator>
 <dc:creator>Li, Chunping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an accurate and robust method for six degree of freedom image
localization. There are two key-points of our method, 1. automatic immense
photo synthesis and labeling from point cloud model and, 2. pose estimation
with deep convolutional neural networks regression. Our model can directly
regresses 6-DOF camera poses from images, accurately describing where and how
it was captured. We achieved an accuracy within 1 meters and 1 degree on our
out-door dataset, which covers about 2 acres on our school campus.
</dc:description>
 <dc:description>Comment: will update soon</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02779</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning</dc:title>
 <dc:creator>Duan, Yan</dc:creator>
 <dc:creator>Schulman, John</dc:creator>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Bartlett, Peter L.</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep reinforcement learning (deep RL) has been successful in learning
sophisticated behaviors automatically; however, the learning process requires a
huge number of trials. In contrast, animals can learn new tasks in just a few
trials, benefiting from their prior knowledge about the world. This paper seeks
to bridge this gap. Rather than designing a &quot;fast&quot; reinforcement learning
algorithm, we propose to represent it as a recurrent neural network (RNN) and
learn it from data. In our proposed method, RL$^2$, the algorithm is encoded in
the weights of the RNN, which are learned slowly through a general-purpose
(&quot;slow&quot;) RL algorithm. The RNN receives all information a typical RL algorithm
would receive, including observations, actions, rewards, and termination flags;
and it retains its state across episodes in a given Markov Decision Process
(MDP). The activations of the RNN store the state of the &quot;fast&quot; RL algorithm on
the current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both
small-scale and large-scale problems. On the small-scale side, we train it to
solve randomly generated multi-arm bandit problems and finite MDPs. After
RL$^2$ is trained, its performance on new MDPs is close to human-designed
algorithms with optimality guarantees. On the large-scale side, we test RL$^2$
on a vision-based navigation task and show that it scales up to
high-dimensional problems.
</dc:description>
 <dc:description>Comment: 14 pages. Under review as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02787</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Catching Worms, Trojan Horses and PUPs: Unsupervised Detection of Silent
  Delivery Campaigns</dc:title>
 <dc:creator>Kwon, Bum Jun</dc:creator>
 <dc:creator>Srinivas, Virinchi</dc:creator>
 <dc:creator>Deshpande, Amol</dc:creator>
 <dc:creator>Dumitra&#x15f;, Tudor</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The growing commoditization of the underground economy has given rise to
malware delivery networks, which charge fees for quickly delivering malware or
unwanted software to a large number of hosts. To provide this service, a key
method is the orchestration of silent delivery campaigns, which involve a group
of downloaders that receive remote commands and that deliver their payloads
without any user interaction. These campaigns have not been characterized
systematically, unlike other aspects of malware delivery networks. Moreover,
silent delivery campaigns can evade detection by relying on inconspicuous
downloaders on the client side and on disposable domain names on the server
side. We describe Beewolf, a system for detecting silent delivery campaigns
from Internet-wide records of download events. The key observation behind our
system is that the downloaders involved in these campaigns frequently retrieve
payloads in lockstep. Beewolf identifies such locksteps in an unsupervised and
deterministic manner. By exploiting novel techniques and empirical
observations, Beewolf can operate on streaming data. We utilize Beewolf to
study silent delivery campaigns at scale, on a data set of 33.3 million
download events. This investigation yields novel findings, e.g. malware
distributed through compromised software update channels, a substantial overlap
between the delivery ecosystems for malware and unwanted software, and several
types of business relationships within these ecosystems. Beewolf achieves over
92% true positives and fewer than 5% false positives. Moreover, Beewolf can
detect suspicious downloaders a median of 165 days ahead of existing anti-virus
products and payload-hosting domains a median of 196 days ahead of existing
blacklists.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02788</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Shape Models: Joint Text Recognition and Segmentation with
  Very Little Training Data</dc:title>
 <dc:creator>Lou, Xinghua</dc:creator>
 <dc:creator>Kansky, Ken</dc:creator>
 <dc:creator>Lehrach, Wolfgang</dc:creator>
 <dc:creator>Laan, CC</dc:creator>
 <dc:creator>Marthi, Bhaskara</dc:creator>
 <dc:creator>Phoenix, D. Scott</dc:creator>
 <dc:creator>George, Dileep</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We demonstrate that a generative model for object shapes can achieve state of
the art results on challenging scene text recognition tasks, and with orders of
magnitude fewer training images than required for competing discriminative
methods. In addition to transcribing text from challenging images, our method
performs fine-grained instance segmentation of characters. We show that our
model is more robust to both affine transformations and non-affine deformations
compared to previous approaches.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02788</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02792</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-volatile Hierarchical Temporal Memory: Hardware for Spatial Pooling</dc:title>
 <dc:creator>Streat, Lennard</dc:creator>
 <dc:creator>Kudithipudi, Dhireesha</dc:creator>
 <dc:creator>Gomez, Kevin</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Hierarchical Temporal Memory (HTM) is a biomimetic machine learning algorithm
imbibing the structural and algorithmic properties of the neocortex. Two main
functional components of HTM that enable spatio-temporal processing are the
spatial pooler and temporal memory. In this research, we explore a scalable
hardware realization of the spatial pooler closely coupled with the
mathematical formulation of spatial pooler. This class of neuromorphic
algorithms are advantageous in solving a subset of the future engineering
problems by extracting nonintuitive patterns in complex data. The proposed
architecture, Non-volatile HTM (NVHTM), leverages large-scale solid state flash
memory to realize a optimal memory organization, area and power envelope. A
behavioral model of NVHTM is evaluated against the MNIST dataset, yielding
91.98% classification accuracy. A full custom layout is developed to validate
the design in a TSMC 180nm process. The area and power profile of the spatial
pooler are 30.538mm2 and 64.394mW, respectively. This design is a
proof-of-concept that storage processing is a viable platform for large scale
HTM network models.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02796</identifier>
 <datestamp>2017-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models
  with KL-control</dc:title>
 <dc:creator>Jaques, Natasha</dc:creator>
 <dc:creator>Gu, Shixiang</dc:creator>
 <dc:creator>Bahdanau, Dzmitry</dc:creator>
 <dc:creator>Hern&#xe1;ndez-Lobato, Jos&#xe9; Miguel</dc:creator>
 <dc:creator>Turner, Richard E.</dc:creator>
 <dc:creator>Eck, Douglas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper proposes a general method for improving the structure and quality
of sequences generated by a recurrent neural network (RNN), while maintaining
information originally learned from data, as well as sample diversity. An RNN
is first pre-trained on data using maximum likelihood estimation (MLE), and the
probability distribution over the next token in the sequence learned by this
model is treated as a prior policy. Another RNN is then trained using
reinforcement learning (RL) to generate higher-quality outputs that account for
domain-specific incentives while retaining proximity to the prior policy of the
MLE RNN. To formalize this objective, we derive novel off-policy RL methods for
RNNs from KL-control. The effectiveness of the approach is demonstrated on two
applications; 1) generating novel musical melodies, and 2) computational
molecular generation. For both problems, we show that the proposed method
improves the desired properties and structure of the generated sequences, while
maintaining information learned from data.
</dc:description>
 <dc:description>Comment: Add supplementary material</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02803</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Supervised Recognition of the Diploglossus Millepunctatus Lizard
  Species using Artificial Vision Algorithms</dc:title>
 <dc:creator>Giraldo-Zuluaga, Jhony-Heriberto</dc:creator>
 <dc:creator>Salazar, Augusto</dc:creator>
 <dc:creator>Daza, Juan M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Animal biometrics is an important requirement for monitoring and conservation
tasks. The classical animal biometrics risk the animals' integrity, are
expensive for numerous animals, and depend on expert criterion. The
non-invasive biometrics techniques offer alternatives to manage the
aforementioned problems. In this paper we propose an automatic segmentation and
identification algorithm based on artificial vision algorithms to recognize
Diploglossus millepunctatus. Diploglossus millepunctatus is an endangered
lizard species. The algorithm is based on two stages: automatic segmentation to
remove the subjective evaluation, and one identification stage to reduce the
analysis time. A 82.87% of correct segmentation in average is reached.
Meanwhile the identification algorithm is achieved with euclidean distance
point algorithms such as Iterative Closest Point and Procrustes Analysis. A
performance of 92.99% on the top 1, and a 96.82% on the top 5 is reached. The
developed software, and the database used in this paper are publicly available
for download from the web page of the project.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1603.00841</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02806</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gender Politics in the 2016 U.S. Presidential Election: A Computer
  Vision Approach</dc:title>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Feng, Yang</dc:creator>
 <dc:creator>Zhang, Xiyang</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Gender is playing an important role in the 2016 U.S. presidential election,
especially with Hillary Clinton becoming the first female presidential nominee
and Donald Trump being frequently accused of sexism. In this paper, we
introduce computer vision to the study of gender politics and present an
image-driven method that can measure the effects of gender in an accurate and
timely manner. We first collect all the profile images of the candidates'
Twitter followers. Then we train a convolutional neural network using images
that contain gender labels. Lastly, we classify all the follower and unfollower
images. Through two case studies, one on the `woman card' controversy and one
on Sanders followers, we demonstrate how gender is informing the 2016
presidential election. Our framework of analysis can be readily generalized to
other case studies and elections.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02815</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Automated System for Essay Scoring of Online Exams in Arabic based on
  Stemming Techniques and Levenshtein Edit Operations</dc:title>
 <dc:creator>Al-Shalabi, Emad Fawzi</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this article, an automated system is proposed for essay scoring in Arabic
language for online exams based on stemming techniques and Levenshtein edit
operations. An online exam has been developed on the proposed mechanisms,
exploiting the capabilities of light and heavy stemming. The implemented online
grading system has shown to be an efficient tool for automated scoring of essay
questions.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02815</dc:identifier>
 <dc:identifier>IJCSI International Journal of Computer Science Issues, Volume 13,
  Issue 5, September 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02816</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Conversion of Relational Databases into Ontologies: A
  Comparative Analysis of Prot\'eg\'e Plug-ins Performances</dc:title>
 <dc:creator>Mogotlane, Kgotatso Desmond</dc:creator>
 <dc:creator>Fonou-Dombeu, Jean Vincent</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Constructing ontologies from relational databases is an active research topic
in the Semantic Web domain. While conceptual mapping rules/principles of
relational databases and ontology structures are being proposed, several
software modules or plug-ins are being developed to enable the automatic
conversion of relational databases into ontologies. However, the correlation
between the resulting ontologies built automatically with plug-ins from
relational databases and the database-to-ontology mapping principles has been
given little attention. This study reviews and applies two Prot\'eg\'e
plug-ins, namely, DataMaster and OntoBase to automatically construct ontologies
from a relational database. The resulting ontologies are further analysed to
match their structures against the database-to-ontology mapping principles. A
comparative analysis of the matching results reveals that OntoBase outperforms
DataMaster in applying the database-to-ontology mapping principles for
automatically converting relational databases into ontologies.
</dc:description>
 <dc:description>Comment: 7(3/4):21-40</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02816</dc:identifier>
 <dc:identifier>International Journal of Web and Semantic Technology (IJWesT),
  2016</dc:identifier>
 <dc:identifier>doi:10.5121/ijwest.2016.7403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02821</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transforming Hidden Vector Encryption Schemes from Composite to Prime
  Order Groups</dc:title>
 <dc:creator>Lee, Kwangsu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Predicate encryption is a new type of public key encryption that enables
searches on encrypted data. By using predicate encryption, we can search
keywords or attributes on encrypted data without decrypting ciphertexts. Hidden
vector encryption (HVE) is a special kind of predicate encryption. HVE supports
the evaluation of conjunctive equality, comparison, and subset operations
between attributes in ciphertexts and attributes in tokens. In this paper, we
construct efficient HVE schemes in prime order bilinear groups derived from
previous HVE schemes in composite order bilinear groups, and prove their
selective security under simple assumptions. To achieve this result, we present
a conversion method that transforms HVE schemes from composite order bilinear
groups into prime order bilinear groups. Our method supports any types of prime
order bilinear groups and uses simple assumptions.
</dc:description>
 <dc:description>Comment: 21 pages, ICISC 2016</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02823</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language Support for Reliable Memory Regions</dc:title>
 <dc:creator>Hukerikar, Saurabh</dc:creator>
 <dc:creator>Engelmann, Christian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The path to exascale computational capabilities in high-performance computing
(HPC) systems is challenged by the inadequacy of present software technologies
to adapt to the rapid evolution of architectures of supercomputing systems. The
constraints of power have driven system designs to include increasingly
heterogeneous architectures and diverse memory technologies and interfaces.
Future systems are also expected to experience an increased rate of errors,
such that the applications will no longer be able to assume correct behavior of
the underlying machine. To enable the scientific community to succeed in
scaling their applications, and to harness the capabilities of exascale
systems, we need software strategies that provide mechanisms for explicit
management of resilience to errors in the system, in addition to locality of
reference in the complex memory hierarchies of future HPC systems.
  In prior work, we introduced the concept of explicitly reliable memory
regions, called havens. Memory management using havens supports reliability
management through a region-based approach to memory allocations. Havens enable
the creation of robust memory regions, whose resilient behavior is guaranteed
by software-based protection schemes. In this paper, we propose language
support for havens through type annotations that make the structure of a
program's havens more explicit and convenient for HPC programmers to use. We
describe how the extended haven-based memory management model is implemented,
and demonstrate the use of the language-based annotations to affect the
resiliency of a conjugate gradient solver application.
</dc:description>
 <dc:description>Comment: The 29th International Workshop on Languages and Compilers for
  Parallel Computing</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02828</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Is the True Value of Dynamic TDD: A MAC Layer Perspective</dc:title>
 <dc:creator>Ding, Ming</dc:creator>
 <dc:creator>Perez, David Lopez</dc:creator>
 <dc:creator>Mao, Guoqiang</dc:creator>
 <dc:creator>Lin, Zihuai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Small cell networks (SCNs) are envisioned to embrace dynamic time division
duplexing (TDD) in order to tailor downlink (DL)/uplink (UL) subframe resources
to quick variations and burstiness of DL/UL traffic. The study of dynamic TDD
is particularly important because it provides valuable insights on the full
duplex transmission technology, which has been identified as one of the
candidate technologies for the 5th-generation (5G) networks. Up to now, the
existing works on dynamic TDD have shown that the UL of dynamic TDD suffers
from severe performance degradation due to the strong DL-to-UL interference in
the physical (PHY) layer. This conclusion raises a fundamental question:
Despite such obvious technology disadvantage, what is the true value of dynamic
TDD? In this paper, we answer this question from a media access control (MAC)
layer viewpoint and present analytical results on the DL/UL time resource
utilization (TRU) of synchronous dynamic TDD, which has been widely adopted in
the existing 4th-generation (4G) systems. Our analytical results shed new light
on the dynamic TDD in future synchronous 5G networks.
</dc:description>
 <dc:description>Comment: To appear in IEEE GLOBECOM2017</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02830</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Learning for Wireless Distributed Computing</dc:title>
 <dc:creator>Kao, Yi-Hsuan</dc:creator>
 <dc:creator>Wright, Kwame</dc:creator>
 <dc:creator>Krishnamachari, Bhaskar</dc:creator>
 <dc:creator>Bai, Fan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  There has been a growing interest for Wireless Distributed Computing (WDC),
which leverages collaborative computing over multiple wireless devices. WDC
enables complex applications that a single device cannot support individually.
However, the problem of assigning tasks over multiple devices becomes
challenging in the dynamic environments encountered in real-world settings,
considering that the resource availability and channel conditions change over
time in unpredictable ways due to mobility and other factors. In this paper, we
formulate a task assignment problem as an online learning problem using an
adversarial multi-armed bandit framework. We propose MABSTA, a novel online
learning algorithm that learns the performance of unknown devices and channel
qualities continually through exploratory probing and makes task assignment
decisions by exploiting the gained knowledge. For maximal adaptability, MABSTA
is designed to make no stochastic assumption about the environment. We analyze
it mathematically and provide a worst-case performance guarantee for any
dynamic environment. We also compare it with the optimal offline policy as well
as other baselines via emulations on trace-data obtained from a wireless IoT
testbed, and show that it offers competitive and robust performance in all
cases. To the best of our knowledge, MABSTA is the first online algorithm in
this domain of task assignment problems and provides provable performance
guarantee.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures, conference</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02831</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arb: Efficient Arbitrary-Precision Midpoint-Radius Interval Arithmetic</dc:title>
 <dc:creator>Johansson, Fredrik</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Arb is a C library for arbitrary-precision interval arithmetic using the
midpoint-radius representation, also known as ball arithmetic. It supports real
and complex numbers, polynomials, power series, matrices, and evaluation of
many special functions. The core number types are designed for versatility and
speed in a range of scenarios, allowing performance that is competitive with
non-interval arbitrary-precision types such as MPFR and MPC floating-point
numbers. We discuss the low-level number representation, strategies for
precision and error bounds, and the implementation of efficient polynomial
arithmetic with interval coefficients.
</dc:description>
 <dc:description>Comment: 12 pages, 1 figure</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02836</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Lattice-Coded Physical-Layer Network Coding With Practical
  Channel Alignment</dc:title>
 <dc:creator>Tan, Yihua</dc:creator>
 <dc:creator>Liew, Soung Chang</dc:creator>
 <dc:creator>Huang, Tao</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Physical-layer network coding (PNC) is a communications paradigm that
exploits overlapped transmissions to boost the throughput of wireless relay
networks. A high point of PNC research was a theoretical proof that PNC that
makes use of lattice codes could approach the information-theoretic capacity of
a two-way relay network (TWRN), where two end nodes communicate via a relay
node. The capacity cannot be achieved by conventional methods of time-division
or straightforward network coding. Many practical challenges, however, remain
to be addressed before the full potential of lattice-coded PNC can be realized.
Two major challenges are: for good performance in lattice-coded PNC, channels
of simultaneously transmitting nodes must be aligned; for lattice-coded PNC to
be practical, the complexity of lattice encoding at the transmitters and
lattice decoding at the receiver must be reduced. We address these challenges
and implement a first lattice-coded PNC system on a software-defined radio
platform. Specifically, we design and implement a low-overhead channel
precoding system that accurately aligns the channels of distributed nodes. In
our implementation, the nodes only use low-cost temperature-compensated
oscillators---a consequent challenge is that the channel alignment must be done
more frequently and more accurately compared with the use of expensive
oscillators. The low overhead and accurate channel alignment are achieved by
(1)a channel precoding system implemented over FPGA to realize fast feedback of
channel state information; (2)a highly-accurate carrier frequency offset
estimation method; and (3)a partial-feedback channel estimation method that
significantly reduces the feedback information from the receiver to the
transmitters for channel precoding at the transmitters. To reduce lattice
encoding and decoding complexities, we adapt the low-density lattice code for
use in PNC systems.
</dc:description>
 <dc:description>Comment: 22 pages, 18 figures, 3 tables</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02839</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Old Content and Modern Tools - Searching Named Entities in a Finnish
  OCRed Historical Newspaper Collection 1771-1910</dc:title>
 <dc:creator>Kettunen, Kimmo</dc:creator>
 <dc:creator>M&#xe4;kel&#xe4;, Eetu</dc:creator>
 <dc:creator>Ruokolainen, Teemu</dc:creator>
 <dc:creator>Kuokkala, Juha</dc:creator>
 <dc:creator>L&#xf6;fberg, Laura</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Named Entity Recognition (NER), search, classification and tagging of names
and name like frequent informational elements in texts, has become a standard
information extraction procedure for textual data. NER has been applied to many
types of texts and different types of entities: newspapers, fiction, historical
records, persons, locations, chemical compounds, protein families, animals etc.
In general a NER system's performance is genre and domain dependent and also
used entity categories vary (Nadeau and Sekine, 2007). The most general set of
named entities is usually some version of three partite categorization of
locations, persons and organizations. In this paper we report first large scale
trials and evaluation of NER with data out of a digitized Finnish historical
newspaper collection Digi. Experiments, results and discussion of this research
serve development of the Web collection of historical Finnish newspapers.
  Digi collection contains 1,960,921 pages of newspaper material from years
1771-1910 both in Finnish and Swedish. We use only material of Finnish
documents in our evaluation. The OCRed newspaper collection has lots of OCR
errors; its estimated word level correctness is about 70-75 % (Kettunen and
P\&quot;a\&quot;akk\&quot;onen, 2016). Our principal NER tagger is a rule-based tagger of
Finnish, FiNER, provided by the FIN-CLARIN consortium. We show also results of
limited category semantic tagging with tools of the Semantic Computing Research
Group (SeCo) of the Aalto University. Three other tools are also evaluated
briefly.
  This research reports first published large scale results of NER in a
historical Finnish OCRed newspaper collection. Results of the research
supplement NER results of other languages with similar noisy data.
</dc:description>
 <dc:description>Comment: 24 pages, 13 tables</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02842</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Policy-Compliant Path Diversity and Bisection Bandwidth</dc:title>
 <dc:creator>Kloti, Rowan</dc:creator>
 <dc:creator>Kotronis, Vasileios</dc:creator>
 <dc:creator>Ager, Bernhard</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  How many links can be cut before a network is bisected? What is the maximal
bandwidth that can be pushed between two nodes of a network? These questions
are closely related to network resilience, path choice for multipath routing or
bisection bandwidth estimations in data centers. The answer is quantified using
metrics such as the number of edge-disjoint paths between two network nodes and
the cumulative bandwidth that can flow over these paths. In practice though,
such calculations are far from simple due to the restrictive effect of network
policies on path selection. Policies are set by network administrators to
conform to service level agreements, protect valuable resources or optimize
network performance. In this work, we introduce a general methodology for
estimating lower and upper bounds for the policy-compliant path diversity and
bisection bandwidth between two nodes of a network, effectively quantifying the
effect of policies on these metrics. Exact values can be obtained if certain
conditions hold. The approach is based on regular languages and can be applied
in a variety of use cases.
</dc:description>
 <dc:description>Comment: Proceedings of IEEE INFOCOM 2015, pages 675-683, 1/4/2015</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02853</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Stateful Forwarding Abstraction to Implement Scalable Network
  Functions in Software and Hardware</dc:title>
 <dc:creator>Petrucci, Luca</dc:creator>
 <dc:creator>Bonelli, Nicola</dc:creator>
 <dc:creator>Bonola, Marco</dc:creator>
 <dc:creator>Procissi, Gregorio</dc:creator>
 <dc:creator>Cascone, Carmelo</dc:creator>
 <dc:creator>Sanvito, Davide</dc:creator>
 <dc:creator>Pontarelli, Salvatore</dc:creator>
 <dc:creator>Bianchi, Giuseppe</dc:creator>
 <dc:creator>Bifulco, Roberto</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  An effective packet processing abstraction that leverages software or
hardware acceleration techniques can simplify the implementation of
high-performance virtual network functions. In this paper, we explore the
suitability of SDN switches' stateful forwarding abstractions to model
accelerated functions in both software and hardware accelerators, such as
optimized software switches and FPGA-based NICs. In particular, we select an
Extended Finite State Machine abstraction and demonstrate its suitability by
implementing the Linux's iptables interface. By doing so, we provide the
acceleration of functions such as stateful firewalls, load balancers and
dynamic NATs. We find that supporting a flow-level programming consistency
model is an important feature of a programming abstraction in this context.
Furthermore, we demonstrate that such a model simplifies the scaling of the
system when implemented in software, enabling efficient multi-core processing
without harming state consistency.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02854</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lie-Access Neural Turing Machines</dc:title>
 <dc:creator>Yang, Greg</dc:creator>
 <dc:creator>Rush, Alexander M.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6, I.2.8, I.5.1, I.2.2</dc:subject>
 <dc:description>  External neural memory structures have recently become a popular tool for
algorithmic deep learning (Graves et al. 2014, Weston et al. 2014). These
models generally utilize differentiable versions of traditional discrete
memory-access structures (random access, stacks, tapes) to provide the storage
necessary for computational tasks. In this work, we argue that these neural
memory systems lack specific structure important for relative indexing, and
propose an alternative model, Lie-access memory, that is explicitly designed
for the neural setting. In this paradigm, memory is accessed using a continuous
head in a key-space manifold. The head is moved via Lie group actions, such as
shifts or rotations, generated by a controller, and memory access is performed
by linear smoothing in key space. We argue that Lie groups provide a natural
generalization of discrete memory structures, such as Turing machines, as they
provide inverse and identity operators while maintaining differentiability. To
experiment with this approach, we implement a simplified Lie-access neural
Turing machine (LANTM) with different Lie groups. We find that this approach is
able to perform well on a range of algorithmic tasks.
</dc:description>
 <dc:description>Comment: Published at ICLR. Rewrite and improvement of arXiv:1602.08671</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02861</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expected Coverage of Random Walk Mobility Algorithm</dc:title>
 <dc:creator>Kohls, Moritz</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Unmanned aerial vehicles (UAVs) have been increasingly used for exploring
areas. Many mobility algorithms were designed to achieve a fast coverage of a
given area. We focus on analysing the expected coverage of the symmetric random
walk mobility algorithm with independent mobility. Therefore we proof the
dependence of certain events and develop Markov models, in order to provide an
analytical solution for the expected coverage. The analytic solution is
afterwards compared to those of another work and to simulation results.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02862</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Little Engine that Could: Regularization by Denoising (RED)</dc:title>
 <dc:creator>Romano, Yaniv</dc:creator>
 <dc:creator>Elad, Michael</dc:creator>
 <dc:creator>Milanfar, Peyman</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Removal of noise from an image is an extensively studied problem in image
processing. Indeed, the recent advent of sophisticated and highly effective
denoising algorithms lead some to believe that existing methods are touching
the ceiling in terms of noise removal performance. Can we leverage this
impressive achievement to treat other tasks in image processing? Recent work
has answered this question positively, in the form of the Plug-and-Play Prior
($P^3$) method, showing that any inverse problem can be handled by sequentially
applying image denoising steps. This relies heavily on the ADMM optimization
technique in order to obtain this chained denoising interpretation.
  Is this the only way in which tasks in image processing can exploit the image
denoising engine? In this paper we provide an alternative, more powerful and
more flexible framework for achieving the same goal. As opposed to the $P^3$
method, we offer Regularization by Denoising (RED): using the denoising engine
in defining the regularization of the inverse problem. We propose an explicit
image-adaptive Laplacian-based regularization functional, making the overall
objective functional clearer and better defined. With a complete flexibility to
choose the iterative optimization procedure for minimizing the above
functional, RED is capable of incorporating any image denoising algorithm,
treat general inverse problems very effectively, and is guaranteed to converge
to the globally optimal result. We test this approach and demonstrate
state-of-the-art results in the image deblurring and super-resolution problems.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02864</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully-Dynamic Minimum Spanning Forest with Improved Worst-Case Update
  Time</dc:title>
 <dc:creator>Wulff-Nilsen, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We give a Las Vegas data structure which maintains a minimum spanning forest
in an n-vertex edge-weighted dynamic graph undergoing updates consisting of any
mixture of edge insertions and deletions. Each update is supported in O(n^{1/2
- c}) expected worst-case time for some constant c &gt; 0 and this worst-case
bound holds with probability at least 1 - n^{-d} where d is a constant that can
be made arbitrarily large. This is the first data structure achieving an
improvement over the O(n^{1/2}) deterministic worst-case update time of
Eppstein et al., a bound that has been standing for nearly 25 years. In fact,
it was previously not even known how to maintain a spanning forest of an
unweighted graph in worst-case time polynomially faster than Theta(n^{1/2}).
Our result is achieved by first giving a reduction from fully-dynamic to
decremental minimum spanning forest preserving worst-case update time up to
logarithmic factors. Then decremental minimum spanning forest is solved using
several novel techniques, one of which involves keeping track of
low-conductance cuts in a dynamic graph. An immediate corollary of our result
is the first Las Vegas data structure for fully-dynamic connectivity where each
update is handled in worst-case time polynomially faster than Theta(n^{1/2})
w.h.p.; this data structure has O(1) worst-case query time.
</dc:description>
 <dc:description>Comment: Small changes to Section 1.1 and a minor fix of the analysis for
  maintaining an MSF of small clusters. 61 pages, 7 figures, 3 with pseudocode.
  Submitted to STOC'17. Builds on an earlier (unpublished, submitted to
  FOCS'16) version by the same author which had a similar bound for
  fully-dynamic connectivity</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02867</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Algebraic Methods for Constraint Satisfaction Problems</dc:title>
 <dc:creator>Bergman, Clifford</dc:creator>
 <dc:creator>DeMeo, William</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Primary 08A70, Secondary 68Q15, 03C05, 08A40</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  After substantial progress over the last 15 years, the &quot;algebraic
CSP-dichotomy conjecture&quot; reduces to the following: every local constraint
satisfaction problem (CSP) associated with a finite idempotent algebra is
tractable if and only if the algebra has a Taylor term operation. Despite the
tremendous achievements in this area, there remain examples of small algebras
with just a single binary operation whose CSP resists classification as either
tractable or NP-complete using known methods. In this paper we present some new
methods for approaching this problem, with particular focus on those techniques
that help us attack the class of finite algebras known as &quot;commutative
idempotent binars&quot; (CIBs). We demonstrate the utility of these methods by using
them to prove that every CIB of cardinality at most 4 yields a tractable CSP.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02869</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian process regression can turn non-uniform and undersampled
  diffusion MRI data into diffusion spectrum imaging</dc:title>
 <dc:creator>Sj&#xf6;lund, Jens</dc:creator>
 <dc:creator>Eklund, Anders</dc:creator>
 <dc:creator>&#xd6;zarslan, Evren</dc:creator>
 <dc:creator>Knutsson, Hans</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose to use Gaussian process regression to accurately estimate the
diffusion MRI signal at arbitrary locations in q-space. By estimating the
signal on a grid, we can do synthetic diffusion spectrum imaging:
reconstructing the ensemble averaged propagator (EAP) by an inverse Fourier
transform. We also propose an alternative reconstruction method guaranteeing a
nonnegative EAP that integrates to unity. The reconstruction is validated on
data simulated from two Gaussians at various crossing angles. Moreover, we
demonstrate on non-uniformly sampled in vivo data that the method is far
superior to linear interpolation, and allows a drastic undersampling of the
data with only a minor loss of accuracy. We envision the method as a potential
replacement for standard diffusion spectrum imaging, in particular when
acquistion time is limited.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02875</identifier>
 <datestamp>2017-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Content Security Policy Violations due to the Same-Origin Policy</dc:title>
 <dc:creator>Som&#xe9;, Doli&#xe8;re Francis</dc:creator>
 <dc:creator>Bielova, Nataliia</dc:creator>
 <dc:creator>Rezk, Tamara</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Modern browsers implement different security policies such as the Content
Security Policy (CSP), a mechanism designed to mitigate popular web
vulnerabilities, and the Same Origin Policy (SOP), a mechanism that governs
interactions between resources of web pages. In this work, we describe how CSP
may be violated due to the SOP when a page contains an embedded iframe from the
same origin. We analyse 1 million pages from 10,000 top Alexa sites and report
that at least 31.1% of current CSP-enabled pages are potentially vulnerable to
CSP violations. Further considering real-world situations where those pages are
involved in same-origin nested browsing contexts, we found that in at least
23.5% of the cases, CSP violations are possible. During our study, we also
identified a divergence among browsers implementations in the enforcement of
CSP in srcdoc sandboxed iframes, which actually reveals a problem in
Gecko-based browsers CSP implementation. To ameliorate the problematic
conflicts of the security mechanisms, we discuss measures to avoid CSP
violations.
</dc:description>
 <dc:description>Comment: 8 pages + references for the short version, extended to 19 pages for
  detailed appendices</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02875</dc:identifier>
 <dc:identifier>doi:10.1145/3038912.3052634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02879</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audio Visual Speech Recognition using Deep Recurrent Neural Networks</dc:title>
 <dc:creator>Thanda, Abhinav</dc:creator>
 <dc:creator>Venkatesan, Shankar M</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work, we propose a training algorithm for an audio-visual automatic
speech recognition (AV-ASR) system using deep recurrent neural network
(RNN).First, we train a deep RNN acoustic model with a Connectionist Temporal
Classification (CTC) objective function. The frame labels obtained from the
acoustic model are then used to perform a non-linear dimensionality reduction
of the visual features using a deep bottleneck network. Audio and visual
features are fused and used to train a fusion RNN. The use of bottleneck
features for visual modality helps the model to converge properly during
training. Our system is evaluated on GRID corpus. Our results show that
presence of visual modality gives significant improvement in character error
rate (CER) at various levels of noise even when the model is trained without
noisy data. We also provide a comparison of two fusion methods: feature fusion
and decision fusion.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02881</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Assessment of PLC Networking for Front-Hauling in Small
  Radio Cells</dc:title>
 <dc:creator>Tonello, Andrea M.</dc:creator>
 <dc:creator>Marcuzzi, Francesco</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The employment of power lines for communications (PLC) has been theorized
almost a century ago; although the physical medium is not meant for data
transmission, recent technical developments pushed the capacity boundary much
higher than expected, allowing to consider PLC for new applications as the one
considered in this contribution, i.e., as a solution for small cell
back/front-hauling. In principle, back-hauling for cellular networks via PLC is
very attractive given how pervasive the power line infrastructure is. Telecom
operators are looking for solutions that can handle the traffic increase which
is doublying every year. This calls for improvements of both cellular systems
and front-hauling technologies that have to bridge the radio network with the
core network. Small cells are currently advocated as the solution to spatially
fragment the network and offer high capacity in densely populated areas; this
is also due to the availability of spectrum at high frequency (mmWave links)
which inherently offers large bandwidth but forces the cells to become smaller
due to the short distance coverage. Therefore, it appears that mobile operators
may eventually have to deploy an order of magnitude more (small) cells compared
to existing networks having macro cells. This translates in a high density
cellular network that poses more challenges for the back-haul.
</dc:description>
 <dc:description>Comment: This work has been presented at the 10th workshop on PLC (WSPLC 2016)
  -- Paris, France, 10-11 October 2016. The paper consists of 4 pages, 4
  figures</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02885</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding monotonic multi-set preferences using CI-nets: preliminary
  report</dc:title>
 <dc:creator>Diller, Martin</dc:creator>
 <dc:creator>Hunter, Anthony</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  CP-nets and their variants constitute one of the main AI approaches for
specifying and reasoning about preferences. CI-nets, in particular, are a
CP-inspired formalism for representing ordinal preferences over sets of goods,
which are typically required to be monotonic.
  Considering also that goods often come in multi-sets rather than sets, a
natural question is whether CI-nets can be used more or less directly to encode
preferences over multi-sets. We here provide some initial ideas on how to
achieve this, in the sense that at least a restricted form of reasoning on our
framework, which we call &quot;confined reasoning&quot;, can be efficiently reduced to
reasoning on CI-nets. Our framework nevertheless allows for encoding
preferences over multi-sets with unbounded multiplicities. We also show the
extent to which it can be used to represent preferences where multiplicites of
the goods are not stated explicitly (&quot;purely qualitative preferences&quot;) as well
as a potential use of our generalization of CI-nets as a component of a recent
system for evidence aggregation.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02886</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Node-Adapt, Path-Adapt and Tree-Adapt:Model-Transfer Domain Adaptation
  for Random Forest</dc:title>
 <dc:creator>Mozafari, Azadeh S.</dc:creator>
 <dc:creator>Vazquez, David</dc:creator>
 <dc:creator>Jamzad, Mansour</dc:creator>
 <dc:creator>Lopez, Antonio M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Random Forest (RF) is a successful paradigm for learning classifiers due to
its ability to learn from large feature spaces and seamlessly integrate
multi-class classification, as well as the achieved accuracy and processing
efficiency. However, as many other classifiers, RF requires domain adaptation
(DA) provided that there is a mismatch between the training (source) and
testing (target) domains which provokes classification degradation.
Consequently, different RF-DA methods have been proposed, which not only
require target-domain samples but revisiting the source-domain ones, too. As
novelty, we propose three inherently different methods (Node-Adapt, Path-Adapt
and Tree-Adapt) that only require the learned source-domain RF and a relatively
few target-domain samples for DA, i.e. source-domain samples do not need to be
available. To assess the performance of our proposals we focus on image-based
object detection, using the pedestrian detection problem as challenging
proof-of-concept. Moreover, we use the RF with expert nodes because it is a
competitive patch-based pedestrian model. We test our Node-, Path- and
Tree-Adapt methods in standard benchmarks, showing that DA is largely achieved.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02891</identifier>
 <datestamp>2017-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Lower Bounds for the Longest Common Extension Problem</dc:title>
 <dc:creator>Kosolobov, Dmitry</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The longest common extension problem is to preprocess a given string of
length $n$ into a data structure that uses $S(n)$ bits on top of the input and
answers in $T(n)$ time the queries $\mathit{LCE}(i,j)$ computing the length of
the longest string that occurs at both positions $i$ and $j$ in the input. We
prove that the trade-off $S(n)T(n) = \Omega(n\log n)$ holds in the non-uniform
cell-probe model provided that the input string is read-only, each letter
occupies a separate memory cell, $S(n) = \Omega(n)$, and the size of the input
alphabet is at least $2^{8\lceil S(n) / n\rceil}$. It is known that this
trade-off is tight.
</dc:description>
 <dc:description>Comment: 5 pages, accepted to Information Processing Letters</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02905</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Helping HPC Users Specify Job Memory Requirements via Machine Learning</dc:title>
 <dc:creator>Rodrigues, Eduardo R.</dc:creator>
 <dc:creator>Cunha, Renato L. F.</dc:creator>
 <dc:creator>Netto, Marco A. S.</dc:creator>
 <dc:creator>Spriggs, Michael</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Resource allocation in High Performance Computing (HPC) settings is still not
easy for end-users due to the wide variety of application and environment
configuration options. Users have difficulties to estimate the number of
processors and amount of memory required by their jobs, select the queue and
partition, and estimate when job output will be available to plan for next
experiments. Apart from wasting infrastructure resources by making wrong
allocation decisions, overall user response time can also be negatively
impacted. Techniques that exploit batch scheduler systems to predict waiting
time and runtime of user jobs have already been proposed. However, we observed
that such techniques are not suitable for predicting job memory usage. In this
paper we introduce a tool to help users predict their memory requirements using
machine learning. We describe the integration of the tool with a batch
scheduler system, discuss how batch scheduler log data can be exploited to
generate memory usage predictions through machine learning, and present results
of two production systems containing thousands of jobs.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, presented at the Third Annual Workshop on HPC
  User Support Tools</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02908</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coming to Terms with Quantified Reasoning</dc:title>
 <dc:creator>Kovacs, Laura</dc:creator>
 <dc:creator>Robillard, Simon</dc:creator>
 <dc:creator>Voronkov, Andrei</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  The theory of finite term algebras provides a natural framework to describe
the semantics of functional languages. The ability to efficiently reason about
term algebras is essential to automate program analysis and verification for
functional or imperative programs over algebraic data types such as lists and
trees. However, as the theory of finite term algebras is not finitely
axiomatizable, reasoning about quantified properties over term algebras is
challenging.
  In this paper we address full first-order reasoning about properties of
programs manipulating term algebras, and describe two approaches for doing so
by using first-order theorem proving. Our first method is a conservative
extension of the theory of term algebras using a finite number of statements,
while our second method relies on extending the superposition calculus of
first-order theorem provers with additional inference rules.
  We implemented our work in the first-order theorem prover Vampire and
evaluated it on a large number of algebraic data type benchmarks, as well as
game theory constraints. Our experimental results show that our methods are
able to find proofs for many hard problems previously unsolved by
state-of-the-art methods. We also show that Vampire implementing our methods
outperforms existing SMT solvers able to deal with algebraic data types.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02915</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Gating Structure for Reversible Programmable Logic Array</dc:title>
 <dc:creator>Singla, Pradeep</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Throughout the world, the numbers of researchers or hardware designer
struggle for the reducing of power dissipation in low power VLSI systems. This
paper presented an idea of using the power gating structure for reducing the
sub threshold leakage in the reversible system. This concept presented in the
paper is entirely new and presented in the literature of reversible logics. By
using the reversible logics for the digital systems, the energy can be saved up
to the gate level implementation. But at the physical level designing of the
reversible logics by the modern CMOS technology the heat or energy is
dissipated due the sub-threshold leakage at the time of inactivity or standby
mode. The Reversible Programming logic array (RPLA) is one of the important
parts of the low power industrial applications and in this paper the physical
design of the RPLA is presented by using the sleep transistor and the results
is shown with the help of TINA- PRO software. The results for the proposed
design is also compare with the CMOS design and shown that of 40.8% of energy
saving. The Transient response is also produces in the paper for the switching
activity and showing that the proposed design is much better that the modern
CMOS design of the RPLA.
</dc:description>
 <dc:description>Comment: 14 Pages, 9 figures, Electrical and Computer Engineering:
  International Journal, September 2015</dc:description>
 <dc:date>2015-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02915</dc:identifier>
 <dc:identifier>doi:10.14810/ecij.2015.4301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02917</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLA-aware Interactive Workflow Assistant for HPC Parameter Sweeping
  Experiments</dc:title>
 <dc:creator>Silva, Bruno</dc:creator>
 <dc:creator>Netto, Marco A. S.</dc:creator>
 <dc:creator>Cunha, Renato L. F.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  A common workflow in science and engineering is to (i) setup and deploy large
experiments with tasks comprising an application and multiple parameter values;
(ii) generate intermediate results; (iii) analyze them; and (iv) reprioritize
the tasks. These steps are repeated until the desired goal is achieved, which
can be the evaluation/simulation of complex systems or model calibration. Due
to time and cost constraints, sweeping all possible parameter values of the
user application is not always feasible. Experimental Design techniques can
help users reorganize submission-execution-analysis workflows to bring a
solution in a more timely manner. This paper introduces a novel tool that
leverages users' feedback on analyzing intermediate results of parameter
sweeping experiments to advise them about their strategies on parameter
selections tied to their SLA constraints. We evaluated our tool with three
applications of distinct domains and search space shapes. Our main finding is
that users with submission-execution-analysis workflows can benefit from their
interaction with intermediate results and adapt themselves according to their
domain expertise and SLA constraints.
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02920</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficient Barring Factor Enabled Extended Access Barring for IoT
  Devices in LTE-Advanced</dc:title>
 <dc:creator>Wali, Prashant</dc:creator>
 <dc:creator>Das, Debabrata</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Synchronized Random Access Channel (RACH) attempts by Internet of Things
(IoT) devices could result in Radio Access Network (RAN) overload in LTE-A.
3GPP adopted Barring Bitmap Enabled-Extended Access Barring (EAB-BB) mechanism
that announces the EAB information (i.e., a list of barred Access Classes)
through a barring bitmap as the baseline solution to mitigate the RAN overload.
EAB-BB was analyzed for its optimal performance in a recent work. However,
there has been no work that analyzes Barring Factor Enabled-Extended Access
Barring (EAB-BF), an alternative mechanism that was considered during the
standardization process. Due to the modeling complexity involved, not only has
it been difficult to analyze EAB-BF, but also, a much more far-reaching issue,
like the effect of these schemes on key network performance parameter, like
eNodeB energy consumption, has been overlooked. In this regard, for the first
time, we develop a novel analytical model for EAB-BF to obtain its performance
metrics. Results obtained from our analysis and simulation are seen to match
very well. Furthermore, we also build an eNodeB energy consumption model to
serve the IoT RACH requests. We then show that our analytical and energy
consumption models can be combined to obtain EAB-BF settings that can minimize
eNodeB energy consumption, while simultaneously providing optimal Quality of
Service (QoS) performance. Results obtained reveal that the optimal performance
of EAB-BF is better than that of EAB-BB. Furthermore, we also show that not
only all the three 3GPP-proposed EAB-BF settings considered during
standardization provide sub-optimal QoS to devices, but also result in
excessive eNodeB energy consumption, thereby acutely penalizing the network.
Finally, we provide corrections to these 3GPP-settings that can lead to
significant gains in EAB-BF performance.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02923</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automating Verification of Event-B Models</dc:title>
 <dc:creator>Stankaitis, Paulius</dc:creator>
 <dc:creator>Iliasov, Alexei</dc:creator>
 <dc:creator>Adjepon-Yamoah, David</dc:creator>
 <dc:creator>Romanovsky, Alexander</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Event-B is one of more popular notations for model-based, proof driven
specification. It offers a fairly high-level mathematical lan- guage based on
FOL and ZF set theory and an economical yet expres- sive modelling notation.
Model correctness is established by discharging proving a number conjectures
constructed via a syntactic instantiation of schematic conditions. A large
proportion of provable conjectures re- quires proof hints from a user. For
larger models this becomes extremely onerous as identical or similar proofs
have to be repeated over and over, especially after model refactoring stages.
In the paper we briefly present a new Rodin Platform proof back-end based on
the Why3 umbrella prover.
</dc:description>
 <dc:description>Comment: Event-B day 2016, Tokyo</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02929</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coarse mesh partitioning for tree based AMR</dc:title>
 <dc:creator>Burstedde, Carsten</dc:creator>
 <dc:creator>Holke, Johannes</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>65M50, 68W10, 65Y05, 65D18</dc:subject>
 <dc:description>  In tree based adaptive mesh refinement, elements are partitioned between
processes using a space filling curve. The curve establishes an ordering
between all elements that derive from the same root element, the tree. When
representing more complex geometries by patching together several trees, the
roots of these trees form an unstructured coarse mesh. We present an algorithm
to partition the elements of the coarse mesh such that (a) the fine mesh can be
load-balanced to equal element counts per process regardless of the
element-to-tree map and (b) each process that holds fine mesh elements has
access to the meta data of all relevant trees. As an additional feature, the
algorithm partitions the meta data of relevant ghost (halo) trees as well. We
develop in detail how each process computes the communication pattern for the
partition routine without handshaking and with minimal data movement. We
demonstrate the scalability of this approach on up to 917e3 MPI ranks and
.37e12 coarse mesh elements, measuring run times of one second or less.
</dc:description>
 <dc:description>Comment: 28 pages, 11 figures, 6 tables</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02941</identifier>
 <datestamp>2017-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting User Roles in Social Networks using Transfer Learning with
  Feature Transformation</dc:title>
 <dc:creator>Sun, Jun</dc:creator>
 <dc:creator>Kunegis, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Staab, Steffen</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  How can we recognise social roles of people, given a completely unlabelled
social network? We present a transfer learning approach to network role
classification based on feature transformations from each network's local
feature distribution to a global feature space. Experiments are carried out on
real-world datasets. (See manuscript for the full abstract.)
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, IEEE ICDMW 2016</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02941</dc:identifier>
 <dc:identifier>doi:10.1109/ICDMW.2016.0026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02944</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Increasing the throughput of machine translation systems using clouds</dc:title>
 <dc:creator>Vi&#x10d;i&#x10d;, Jernej</dc:creator>
 <dc:creator>Brodnik, Andrej</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The manuscript presents an experiment at implementation of a Machine
Translation system in a MapReduce model. The empirical evaluation was done
using fully implemented translation systems embedded into the MapReduce
programming model. Two machine translation paradigms were studied: shallow
transfer Rule Based Machine Translation and Statistical Machine Translation.
  The results show that the MapReduce model can be successfully used to
increase the throughput of a machine translation system. Furthermore this
method enhances the throughput of a machine translation system without
decreasing the quality of the translation output.
  Thus, the present manuscript also represents a contribution to the seminal
work in natural language processing, specifically Machine Translation. It first
points toward the importance of the definition of the metric of throughput of
translation system and, second, the applicability of the machine translation
task to the MapReduce paradigm.
</dc:description>
 <dc:description>Comment: 20 pages, 7 figures</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02945</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heter-LP: A heterogeneous label propagation algorithm and its
  application in drug repositioning</dc:title>
 <dc:creator>Shahreza, Maryam Lotfi</dc:creator>
 <dc:creator>Ghadiri, Nasser</dc:creator>
 <dc:creator>Mossavi, Seyed Rasul</dc:creator>
 <dc:creator>Varshosaz, Jaleh</dc:creator>
 <dc:creator>Green, James</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>05C82</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Drug repositioning offers an effective solution to drug discovery, saving
both time and resources by finding new indications for existing drugs.
Typically, a drug takes effect via its protein targets in the cell. As a
result, it is necessary for drug development studies to conduct an
investigation into the interrelationships of drugs, protein targets, and
diseases. Although previous studies have made a strong case for the
effectiveness of integrative network-based methods for predicting these
interrelationships, little progress has been achieved in this regard within
drug repositioning research. Moreover, the interactions of new drugs and
targets (lacking any known targets and drugs, respectively) cannot be
accurately predicted by most established methods. In this paper, we propose a
novel semi-supervised heterogeneous label propagation algorithm named Heter-LP,
which applies both local as well as global network features for data
integration. To predict drug-target, disease-target, and drug-disease
associations, we use information about drugs, diseases, and targets as
collected from multiple sources at different levels. Our algorithm integrates
these various types of data into a heterogeneous network and implements a label
propagation algorithm to find new interactions. Statistical analyses of 10-fold
cross-validation results and experimental analysis support the effectiveness of
the proposed algorithm.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02945</dc:identifier>
 <dc:identifier>doi:10.1016/j.jbi.2017.03.006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02955</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The harmonic influence in social networks and its distributed
  computation by message passing</dc:title>
 <dc:creator>Rossi, Wilbert Samuel</dc:creator>
 <dc:creator>Frasca, Paolo</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we elaborate upon a measure of node influence in social
networks, which was recently proposed by Vassio et al., IEEE Trans. Control
Netw. Syst., 2014. This measure quantifies the ability of the node to sway the
average opinion of the network. Following the approach by Vassio et al., we
describe and study a distributed message passing algorithm that aims to compute
the nodes' influence. The algorithm is inspired by an analogy between
potentials in electrical networks and opinions in social networks. If the graph
is a tree, then the algorithm computes the nodes' influence in a number of
steps equal to the diameter of the graph. On general graphs, the algorithm
converges asymptotically to a meaningful approximation of the nodes' influence.
In this paper we detail the proof of convergence, which greatly extends
previous results in the literature, and we provide simulations that illustrate
the usefulness of the returned approximation.
</dc:description>
 <dc:description>Comment: 40 pages, 18 figures, submitted</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02956</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of Word Embeddings for English and Cross-Lingual Chinese
  Word Sense Disambiguation</dc:title>
 <dc:creator>Kang, Hong Jin</dc:creator>
 <dc:creator>Chen, Tao</dc:creator>
 <dc:creator>Chandrasekaran, Muthu Kumar</dc:creator>
 <dc:creator>Kan, Min-Yen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word embeddings are now ubiquitous forms of word representation in natural
language processing. There have been applications of word embeddings for
monolingual word sense disambiguation (WSD) in English, but few comparisons
have been done. This paper attempts to bridge that gap by examining popular
embeddings for the task of monolingual English WSD. Our simplified method leads
to comparable state-of-the-art performance without expensive retraining.
Cross-Lingual WSD - where the word senses of a word in a source language e come
from a separate target translation language f - can also assist in language
learning; for example, when providing translations of target vocabulary for
learners. Thus we have also applied word embeddings to the novel task of
cross-lingual WSD for Chinese and provide a public dataset for further
benchmarking. We have also experimented with using word embeddings for LSTM
networks and found surprisingly that a basic LSTM network does not work well.
We discuss the ramifications of this outcome.
</dc:description>
 <dc:description>Comment: 10 pages. Appears in the Proceedings of The 3rd Workshop on Natural
  Language Processing Techniques for Educational Applications (NLPTEA 2016)</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02956</dc:identifier>
 <dc:identifier>Proceedings of the 3rd Workshop on Natural Language Processing
  Techniques for Educational Applications, pages 30 to 39, Osaka, Japan,
  December 12 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02960</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Maximum Likelihood Approach for Optimal Distribution Property
  Estimation</dc:title>
 <dc:creator>Acharya, Jayadev</dc:creator>
 <dc:creator>Das, Hirakendu</dc:creator>
 <dc:creator>Orlitsky, Alon</dc:creator>
 <dc:creator>Suresh, Ananda Theertha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The advent of data science has spurred interest in estimating properties of
distributions over large alphabets. Fundamental symmetric properties such as
support size, support coverage, entropy, and proximity to uniformity, received
most attention, with each property estimated using a different technique and
often intricate analysis tools.
  We prove that for all these properties, a single, simple, plug-in
estimator---profile maximum likelihood (PML)---performs as well as the best
specialized techniques. This raises the possibility that PML may optimally
estimate many other symmetric properties.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02966</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Near-Linear Approximation Scheme for Multicuts of Embedded Graphs with
  a Fixed Number of Terminals</dc:title>
 <dc:creator>Cohen-Addad, Vincent</dc:creator>
 <dc:creator>de Verdi&#xe8;re, &#xc9;ric Colin</dc:creator>
 <dc:creator>de Mesmay, Arnaud</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  For an undirected edge-weighted graph $G$ and a set $R$ of pairs of vertices
called pairs of terminals, a multicut is a set of edges such that removing
these edges from $G$ disconnects each pair in $R$. We provide an algorithm
computing a $(1+\varepsilon)$-approximation of the minimum multicut of a graph
$G$ in time $(g+t)^{(O(g+t)^3)}\cdot(1/\varepsilon)^{O(g+t)} \cdot n \log n$,
where $g$ is the genus of $G$ and $t$ is the number of terminals.
  This result is tight in several aspects, as the minimum multicut problem is
both APX-hard and W[1]-hard (parameterized by the number of terminals), even on
planar graphs (equivalently, when $g=0$).
  In order to achieve this, our article leverages on a novel characterization
of a minimum multicut as a family of Steiner trees in the universal cover of a
surface on which $G$ is embedded. The algorithm heavily relies on topological
techniques, and in particular on the use of homotopical tools and computations
in covering spaces, which we blend with classic ideas stemming from
approximation schemes for planar graphs and low-dimensional geometric inputs.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02968</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Public Comment on NCCoE's White Paper on Privacy-Enhancing Identity
  Brokers</dc:title>
 <dc:creator>Brand&#xe3;o, Lu&#xed;s T. A. N.</dc:creator>
 <dc:creator>Christin, Nicolas</dc:creator>
 <dc:creator>Danezis, George</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The National Cybersecurity Center of Excellence (NCCoE) (in the United
States) has published on October 19, 2015, a white paper on &quot;privacy-enhanced
identity brokers.&quot; We present here a reply to their request for public
comments. We enumerate concerns whose consideration we find paramount for the
design of a privacy-enhancing identity brokering solution, for identification
and authentication of citizens into myriad online services, and we recommend
how to incorporate them into a revised white paper. Our observations, focused
on privacy, security, auditability and forensics, are mostly based on a
recently published research paper (PETS 2015) about two nation-scale brokered
identification systems.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02988</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distant supervision for emotion detection using Facebook reactions</dc:title>
 <dc:creator>Pool, Chris</dc:creator>
 <dc:creator>Nissim, Malvina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We exploit the Facebook reaction feature in a distant supervised fashion to
train a support vector machine classifier for emotion detection, using several
feature combinations and combining different Facebook pages. We test our models
on existing benchmarks for emotion detection and show that employing only
information that is derived completely automatically, thus without relying on
any handcrafted lexicon as it's usually done, we can achieve competitive
results. The results also show that there is large room for improvement,
especially by gearing the collection of Facebook pages, with a view to the
target domain.
</dc:description>
 <dc:description>Comment: Proceedings of the Workshop on Computational Modeling of People's
  Opinions, Personality, and Emotions in Social Media (PEOPLES 2016), held in
  conjunction with COLING 2016, Osaka, Japan</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02989</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian data assimilation based on a family of outer measures</dc:title>
 <dc:creator>Houssineau, Jeremie</dc:creator>
 <dc:creator>Clark, Daniel E.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>60A10, 62C10</dc:subject>
 <dc:description>  A flexible representation of uncertainty that remains within the standard
framework of probabilistic measure theory is presented along with a study of
its properties. This representation relies on a specific type of outer measure
that is based on the measure of a supremum, hence combining additive and highly
sub-additive components. It is shown that this type of outer measure enables
the introduction of intuitive concepts such as pullback and general data
assimilation operations.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02992</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Authority-based Team Discovery in Social Networks</dc:title>
 <dc:creator>Zihayat, Morteza</dc:creator>
 <dc:creator>An, Aijun</dc:creator>
 <dc:creator>Golab, Lukasz</dc:creator>
 <dc:creator>Kargar, Mehdi</dc:creator>
 <dc:creator>Szlichta, Jaroslaw</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Given a social network of experts, we address the problem of discovering a
team of experts that collectively holds a set of skills required to complete a
given project. Most prior work ranks possible solutions by communication cost,
represented by edge weights in the expert network. Our contribution is to take
experts authority into account, represented by node weights. We formulate
several problems that combine communication cost and authority, we prove that
they are NP-hard, and we propose and experimentally evaluate greedy algorithms
to solve them.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.02992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03000</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bio-Inspired Spiking Convolutional Neural Network using Layer-wise
  Sparse Coding and STDP Learning</dc:title>
 <dc:creator>Tavanaei, Amirhossein</dc:creator>
 <dc:creator>Maida, Anthony S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Hierarchical feature discovery using non-spiking convolutional neural
networks (CNNs) has attracted much recent interest in machine learning and
computer vision. However, it is still not well understood how to create a
biologically plausible network of brain-like, spiking neurons with multi-layer,
unsupervised learning. This paper explores a novel bio-inspired spiking CNN
that is trained in a greedy, layer-wise fashion. The proposed network consists
of a spiking convolutional-pooling layer followed by a feature discovery layer
extracting independent visual features. Kernels for the convolutional layer are
trained using local learning. The learning is implemented using a sparse,
spiking auto-encoder representing primary visual features. The feature
discovery layer extracts independent features by probabilistic, leaky
integrate-and-fire (LIF) neurons that are sparsely active in response to
stimuli. The layer of the probabilistic, LIF neurons implicitly provides
lateral inhibitions to extract sparse and independent features. Experimental
results show that the convolutional layer is stack-admissible, enabling it to
support a multi-layer learning. The visual features obtained from the proposed
probabilistic LIF neurons in the feature discovery layer are utilized for
training a classifier. Classification results contribute to the independent and
informative visual features extracted in a hierarchy of convolutional and
feature discovery layers. The proposed model is evaluated on the MNIST digit
dataset using clean and noisy images. The recognition performance for clean
images is above 98%. The performance loss for recognizing the noisy images is
in the range 0.1% to 8.5% depending on noise types and densities. This level of
performance loss indicates that the network is robust to additive noise.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03006</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-Preserving Genetic Relatedness Test</dc:title>
 <dc:creator>De Cristofaro, Emiliano</dc:creator>
 <dc:creator>Liang, Kaitai</dc:creator>
 <dc:creator>Zhang, Yuruo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  An increasing number of individuals are turning to Direct-To-Consumer (DTC)
genetic testing to learn about their predisposition to diseases, traits, and/or
ancestry. DTC companies like 23andme and Ancestry.com have started to offer
popular and affordable ancestry and genealogy tests, with services allowing
users to find unknown relatives and long-distant cousins. Naturally, access and
possible dissemination of genetic data prompts serious privacy concerns, thus
motivating the need to design efficient primitives supporting private genetic
tests. In this paper, we present an effective protocol for privacy-preserving
genetic relatedness test (PPGRT), enabling a cloud server to run relatedness
tests on input an encrypted genetic database and a test facility's encrypted
genetic sample. We reduce the test to a data matching problem and perform it,
privately, using searchable encryption. Finally, a performance evaluation of
hamming distance based PP-GRT attests to the practicality of our proposals.
</dc:description>
 <dc:description>Comment: A preliminary version of this paper appears in the Proceedings of the
  3rd International Workshop on Genome Privacy and Security (GenoPri'16)</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03012</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New CRT sequence sets for a collision channel without feedback</dc:title>
 <dc:creator>Zhang, Yijin</dc:creator>
 <dc:creator>Lo, Yuan-Hsun</dc:creator>
 <dc:creator>Shum, Kenneth W.</dc:creator>
 <dc:creator>Wong, Wing Shing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Protocol sequences are binary and periodic sequences used for deterministic
multiple access in a collision channel without feedback. In this paper, we
focus on user-irrepressible (UI) protocol sequences that can guarantee a
positive individual throughput per sequence period with probability one for a
slot-synchronous channel, regardless of the delay offsets among the users. As
the sequence period has a fundamental impact on the worst-case channel access
delay, a common objective of designing UI sequences is to make the sequence
period as short as possible. Consider a communication channel that is shared by
$M$ active users, and assume that each protocol sequence has a constant Hamming
weight $w$. To attain a better delay performance than previously known UI
sequences, this paper presents a CRTm construction of UI sequences with
$w=M+1$, which is a variation of the previously known CRT construction. For all
non-prime $M\geq 8$, our construction produces the shortest known sequence
period and the shortest known worst-case delay of UI sequences. Numerical
results show that the new construction enjoys a better average delay
performance than the optimal random access scheme and other constructions with
the same sequence period, in a variety of traffic conditions. In addition, we
derive an asymptotic lower bound on the minimum sequence period for $w=M+1$ if
the sequence structure satisfies some technical conditions, called
equi-difference, and prove the tightness of this lower bound by using the CRTm
construction.
</dc:description>
 <dc:description>Comment: 21 pages, 1 figure, 4 tables</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03014</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy and Bursty Packet Loss Tradeoff over Fading Channels: A System
  Level Model</dc:title>
 <dc:creator>Butt, M. Majid</dc:creator>
 <dc:creator>Jorswieck, Eduard A.</dc:creator>
 <dc:creator>Mohamed, Amr</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Energy efficiency and quality of service (QoS) guarantees are the key design
goals for the 5G wireless communication systems. In this context, we discuss a
multiuser scheduling scheme over fading channels for loss tolerant
applications. The loss tolerance of the application is characterized in terms
of different parameters that contribute to quality of experience for the
application. The mobile users are scheduled opportunistically such that a
minimum QoS is guaranteed. We propose an opportunistic scheduling scheme and
address the cross layer design framework when channel state information is not
perfectly available at the transmitter and the receiver. We characterize the
system energy as a function of different QoS and channel state estimation error
parameters. The optimization problem is formulated using Markov chain framework
and solved using stochastic optimization techniques. The results demonstrate
that the parameters characterizing the packet loss are tightly coupled and
relaxation of one parameter does not benefit the system much if the other
constraints are tight. We evaluate the energy-performance trade-off numerically
and show the effect of channel uncertainty on the packet scheduler design.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03014</dc:identifier>
 <dc:identifier>IEEE Systems Journal, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03016</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Caching in Wireless D2D Networks: Cache Hit Optimal vs.
  Throughput Optimal</dc:title>
 <dc:creator>Chen, Zheng</dc:creator>
 <dc:creator>Pappas, Nikolaos</dc:creator>
 <dc:creator>Kountouris, Marios</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Departing from the conventional cache hit optimization in cache-enabled
wireless networks, we consider an alternative optimization approach for the
probabilistic caching placement in stochastic wireless D2D caching networks
taking into account the reliability of D2D transmissions. Using tools from
stochastic geometry, we provide a closed-form approximation of cache-aided
throughput, which measures the density of successfully served requests by local
device caches, and we obtain the optimal caching probabilities with numerical
optimization. Compared to the cache-hit-optimal case, the optimal caching
probabilities obtained by cache-aided throughput optimization show notable gain
in terms of the density of successfully served user requests, particularly in
dense user environments.
</dc:description>
 <dc:description>Comment: IEEE Communications Letters</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03019</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Access Control in Linked Data Using WebID</dc:title>
 <dc:creator>Mainini, Pascal</dc:creator>
 <dc:creator>Laube-Rosenpflanzer, Annett</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Linked Data technologies become increasingly important in many domains. Key
factors for their breakthrough are security and trust, especially when sensible
or personal data are involved. Classical means for access control lack
granularity when parts of the Linked Data graph must be protected. The WebID,
combining semantic web concepts with methods from certificate based
authentication and authorization, seems promising to fulfill all requirements
concerning security and trust in the semantic web. In the context of the
PerSemID project, we challenged the WebID technology in a practical scenario
coming from the domain of lifelong learning and student mobility. In our use
case of study enrollment, we use WebIDs for authentication and to grant access
to parts of the triple stores of the different stakeholders. Cross domain
triple store interactions are used to exchange data between the involved
parties. Our fully implemented PoC exemplifies an application built on Linked
Data and WebID and allows us to judge the usability and security of WebID
technology in a real world scenario.
</dc:description>
 <dc:description>Comment: Full version of arXiv:1610.04405</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03021</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attributing Hacks</dc:title>
 <dc:creator>Liu, Ziqi</dc:creator>
 <dc:creator>Smola, Alexander J.</dc:creator>
 <dc:creator>Soska, Kyle</dc:creator>
 <dc:creator>Wang, Yu-Xiang</dc:creator>
 <dc:creator>Zheng, Qinghua</dc:creator>
 <dc:creator>Zhou, Jun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  In this paper we describe an algorithm for estimating the provenance of hacks
on websites. That is, given properties of sites and the temporal occurrence of
attacks, we are able to attribute individual attacks to joint causes and
vulnerabilities, as well as estimating the evolution of these vulnerabilities
over time. Specifically, we use hazard regression with a time-varying additive
hazard function parameterized in a generalized linear form. The activation
coefficients on each feature are continuous-time functions over time. We
formulate the problem of learning these functions as a constrained variational
maximum likelihood estimation problem with total variation penalty and show
that the optimal solution is a 0th order spline (a piecewise constant function)
with a finite number of known knots. This allows the inference problem to be
solved efficiently and at scale by solving a finite dimensional optimization
problem. Extensive experiments on real data sets show that our method
significantly outperforms Cox's proportional hazard model. We also conduct a
case study and verify that the fitted functions are indeed recovering
vulnerable features and real-life events such as the release of code to exploit
these features in hacker blogs.
</dc:description>
 <dc:description>Comment: Appeared at AISTATS'17. Full version under review at the Electronic
  Journal of Statistics</dc:description>
 <dc:date>2016-11-07</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03028</identifier>
 <datestamp>2017-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Node Embedding via Word Embedding for Network Community Discovery</dc:title>
 <dc:creator>Ding, Weicong</dc:creator>
 <dc:creator>Lin, Christy</dc:creator>
 <dc:creator>Ishwar, Prakash</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural node embeddings have recently emerged as a powerful representation for
supervised learning tasks involving graph-structured data. We leverage this
recent advance to develop a novel algorithm for unsupervised community
discovery in graphs. Through extensive experimental studies on simulated and
real-world data, we demonstrate that the proposed approach consistently
improves over the current state-of-the-art. Specifically, our approach
empirically attains the information-theoretic limits for community recovery
under the benchmark Stochastic Block Models for graph generation and exhibits
better stability and accuracy over both Spectral Clustering and Acyclic Belief
Propagation in the community recovery limits.
</dc:description>
 <dc:description>Comment: This version has been accepted for publication in a joint special
  issue between IEEE JSTSP and TSIPN</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03044</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Vickrey-Clarke-Groves Mechanism for Electricity Markets</dc:title>
 <dc:creator>Sessa, Pier Giuseppe</dc:creator>
 <dc:creator>Walton, Neil</dc:creator>
 <dc:creator>Kamgarpour, Maryam</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Control reserves are power generation or consumption entities that ensure
balance of supply and demand of electricity in real-time. In many countries,
they are operated through a market mechanism in which entities provide bids.
The system operator determines the accepted bids based on an optimization
algorithm. We develop the Vickrey-Clarke-Groves (VCG) mechanism for these
electricity markets. We show that all advantages of the VCG mechanism including
incentive compatibility of the equilibria and efficiency of the outcome can be
guaranteed in these markets. Furthermore, we derive conditions to ensure
collusion and shill bidding are not profitable. Our results are verified with
numerical examples.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03046</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Estimation for Hybrid Architecture Based Wideband Millimeter
  Wave Systems</dc:title>
 <dc:creator>Venugopal, Kiran</dc:creator>
 <dc:creator>Alkhateeb, Ahmed</dc:creator>
 <dc:creator>Prelcic, Nuria Gonz&#xe1;lez</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Hybrid analog and digital precoding allows millimeter wave (mmWave) systems
to achieve both array and multiplexing gain. The design of the hybrid precoders
and combiners, though, is usually based on knowledge of the channel. Prior work
on mmWave channel estimation with hybrid architectures focused on narrowband
channels. Since mmWave systems will be wideband with frequency selectivity, it
is vital to develop channel estimation solutions for hybrid architectures based
wideband mmWave systems. In this paper, we develop a sparse formulation and
compressed sensing based solutions for the wideband mmWave channel estimation
problem for hybrid architectures. First, we leverage the sparse structure of
the frequency selective mmWave channels and formulate the channel estimation
problem as a sparse recovery in both time and frequency domains. Then, we
propose explicit channel estimation techniques for purely time or frequency
domains and for combined time/frequency domains. Our solutions are suitable for
both SC-FDE and OFDM systems. Simulation results show that the proposed
solutions achieve good channel estimation quality, while requiring small
training overhead. Leveraging the hybrid architecture at the transceivers gives
further improvement in estimation error performance and achievable rates.
</dc:description>
 <dc:description>Comment: 31 pages, 13 figures</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03053</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Bag of System Calls for Anomalous Behavior Detection of
  Applications in Linux Containers</dc:title>
 <dc:creator>Abed, Amr S.</dc:creator>
 <dc:creator>Clancy, T. Charles</dc:creator>
 <dc:creator>Levy, David S.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, we present the results of using bags of system calls for
learning the behavior of Linux containers for use in anomaly-detection based
intrusion detection system. By using system calls of the containers monitored
from the host kernel for anomaly detection, the system does not require any
prior knowledge of the container nature, neither does it require altering the
container or the host kernel.
</dc:description>
 <dc:description>Comment: Published version available on IEEE Xplore
  (http://ieeexplore.ieee.org/document/7414047/) arXiv admin note: substantial
  text overlap with arXiv:1611.03056</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03053</dc:identifier>
 <dc:identifier>2015 IEEE Globecom Workshops (GC Wkshps), San Diego, CA, 2015, pp.
  1-5</dc:identifier>
 <dc:identifier>doi:10.1109/GLOCOMW.2015.7414047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03054</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput Analysis of Decentralized Coded Content Caching in Cellular
  Networks</dc:title>
 <dc:creator>Kiskani, Mohsen Karimzadeh</dc:creator>
 <dc:creator>Sadjadpour, Hamid R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Decentralized coded content caching for next generation cellular networks is
studied. The contents are linearly combined and cached in under-utilized caches
of User Terminals (UTs) and its throughput capacity is compared with
decentralized uncoded content caching. In both scenarios, we consider multihop
Device-to-Device (D2D) communications and the use of femtocaches in the
network. It is shown that decentralized coded content caching can increase the
network throughput capacity compared to decentralized uncoded caching by
reducing the number of hops needed to deliver the desired content. Further, the
throughput capacity for Zipfian content request distribution is computed and it
is shown that the decentralized coded content cache placement can increase the
throughput capacity of cellular networks by a factor of $(\log(n))^2$ where $n$
is the number of nodes served by a femtocache.
</dc:description>
 <dc:description>Comment: Accepted to be published in IEEE Transactions on Wireless
  Communications (November 2016)</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03056</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intrusion Detection System for Applications using Linux Containers</dc:title>
 <dc:creator>Abed, Amr S.</dc:creator>
 <dc:creator>Clancy, Charles</dc:creator>
 <dc:creator>Levy, David S.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Linux containers are gaining increasing traction in both individual and
industrial use, and as these containers get integrated into mission-critical
systems, real-time detection of malicious cyber attacks becomes a critical
operational requirement. This paper introduces a real-time host-based intrusion
detection system that can be used to passively detect malfeasance against
applications within Linux containers running in a standalone or in a cloud
multi-tenancy environment. The demonstrated intrusion detection system uses
bags of system calls monitored from the host kernel for learning the behavior
of an application running within a Linux container and determining anomalous
container behavior. Performance of the approach using a database application
was measured and results are discussed.
</dc:description>
 <dc:description>Comment: The final publication is available at
  http://link.springer.com/chapter/10.1007%2F978-3-319-24858-5_8. arXiv admin
  note: substantial text overlap with arXiv:1611.03053</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03056</dc:identifier>
 <dc:identifier>STM 2015. LNCS, vol. 9331, pp. 123-135. Springer, Heidelberg
  (2015)</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-24858-5_8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03057</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When silver glitters more than gold: Bootstrapping an Italian
  part-of-speech tagger for Twitter</dc:title>
 <dc:creator>Plank, Barbara</dc:creator>
 <dc:creator>Nissim, Malvina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We bootstrap a state-of-the-art part-of-speech tagger to tag Italian Twitter
data, in the context of the Evalita 2016 PoSTWITA shared task. We show that
training the tagger on native Twitter data enriched with little amounts of
specifically selected gold data and additional silver-labelled data scraped
from Facebook, yields better results than using large amounts of manually
annotated data from a mix of genres.
</dc:description>
 <dc:description>Comment: Proceedings of the 5th Evaluation Campaign of Natural Language
  Processing and Speech Tools for Italian (EVALITA 2016)</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03059</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Multiple Surface Segmentation with Convex Priors in Irregularly
  Sampled Space</dc:title>
 <dc:creator>Shah, Abhay</dc:creator>
 <dc:creator>Bai, Junjie</dc:creator>
 <dc:creator>Abramoff, Michael D.</dc:creator>
 <dc:creator>Wu, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Optimal surface segmentation is widely used in numerous medical image
segmentation applications. However, nodes in the graph based optimal surface
segmentation method typically encode uniformly distributed orthogonal voxels of
the volume. Thus the segmentation cannot attain an accuracy greater than a
single unit voxel, i.e. the distance between two adjoining nodes in graph
space. Segmentation accuracy higher than a unit voxel is achievable by
exploiting partial volume information in the voxels which shall result in
non-equidistant spacing between adjoining graph nodes. This paper reports a
generalized graph based optimal multiple surface segmentation method with
convex priors which segments the target surfaces in irregularly sampled space.
The proposed method allows non-equidistant spacing between the adjoining graph
nodes to achieve subvoxel accurate segmentation by utilizing the partial volume
information in the voxels. The partial volume information in the voxels is
exploited by computing a displacement field from the original volume data to
identify the subvoxel accurate centers within each voxel resulting in
non-equidistant spacing between the adjoining graph nodes. The smoothness of
each surface modelled as a convex constraint governs the connectivity and
regularity of the surface. We employ an edge-based graph representation to
incorporate the necessary constraints and the globally optimal solution is
obtained by computing a minimum s-t cut. The proposed method was validated on
25 optical coherence tomography image volumes of the retina and 10
intravascular multi-frame ultrasound image datasets for subvoxel and super
resolution segmentation accuracy. In all cases, the approach yielded highly
accurate results. Our approach can be readily extended to higher-dimensional
segmentations.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03060</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Nonconvex Geometry of Low-Rank Matrix Optimizations with General
  Objective Functions</dc:title>
 <dc:creator>Li, Qiuwei</dc:creator>
 <dc:creator>Tang, Gongguo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This work considers the minimization of a general convex function $f(X)$ over
the cone of positive semi-definite matrices whose optimal solution $X^\star$ is
of low-rank. Standard first-order convex solvers require performing an
eigenvalue decomposition in each iteration, severely limiting their
scalability. A natural nonconvex reformulation of the problem factors the
variable $X$ into the product of a rectangular matrix with fewer columns and
its transpose. For a special class of matrix sensing and completion problems
with quadratic objective functions, local search algorithms applied to the
factored problem have been shown to be much more efficient and, in spite of
being nonconvex, to converge to the global optimum. The purpose of this work is
to extend this line of study to general convex objective functions $f(X)$ and
investigate the geometry of the resulting factored formulations. Specifically,
we prove that when $f(X)$ satisfies restricted strong convexity and smoothness,
each critical point of the factored problem either corresponds to the optimal
solution $X^\star$ or is a strict saddle point where the Hessian matrix has a
negative eigenvalue. Such a geometric structure of the factored formulation
ensures that many local search algorithms can converge to the global optimum
with random initializations.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03065</identifier>
 <datestamp>2017-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Smart Moving Target Defense for Linux Container Resiliency</dc:title>
 <dc:creator>Azab, Mohamed</dc:creator>
 <dc:creator>Mokhtar, Bassem</dc:creator>
 <dc:creator>Abed, Amr S.</dc:creator>
 <dc:creator>Eltoweissy, Mohamed</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents ESCAPE, an informed moving target defense mechanism for
cloud containers. ESCAPE models the interaction between attackers and their
target containers as a &quot;predator searching for a prey&quot; search game. Live
migration of Linux-containers (prey) is used to avoid attacks (predator) and
failures. The entire process is guided by a novel host-based
behavior-monitoring system that seamlessly monitors containers for indications
of intrusions and attacks. To evaluate ESCAPE effectiveness, we simulated the
attack avoidance process based on a mathematical model mimicking the
prey-vs-predator search game. Simulation results show high container survival
probabilities with minimal added overhead.
</dc:description>
 <dc:description>Comment: Published version is available on IEEE Xplore at
  http://ieeexplore.ieee.org/document/7796855</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2016-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03065</dc:identifier>
 <dc:identifier>IEEE 41st Conference on Local Computer Networks (2016) 619-622</dc:identifier>
 <dc:identifier>doi:10.1109/LCN.2016.106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03068</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Sequence Learning</dc:title>
 <dc:creator>de Jong, Edwin D.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep learning research over the past years has shown that by increasing the
scope or difficulty of the learning problem over time, increasingly complex
learning problems can be addressed. We study incremental learning in the
context of sequence learning, using generative RNNs in the form of multi-layer
recurrent Mixture Density Networks. While the potential of incremental or
curriculum learning to enhance learning is known, indiscriminate application of
the principle does not necessarily lead to improvement, and it is essential
therefore to know which forms of incremental or curriculum learning have a
positive effect. This research contributes to that aim by comparing three
instantiations of incremental or curriculum learning.
  We introduce Incremental Sequence Learning, a simple incremental approach to
sequence learning. Incremental Sequence Learning starts out by using only the
first few steps of each sequence as training data. Each time a performance
criterion has been reached, the length of the parts of the sequences used for
training is increased.
  We introduce and make available a novel sequence learning task and data set:
predicting and classifying MNIST pen stroke sequences. We find that Incremental
Sequence Learning greatly speeds up sequence learning and reaches the best test
performance level of regular sequence learning 20 times faster, reduces the
test error by 74%, and in general performs more robustly; it displays lower
variance and achieves sustained progress after all three comparison methods
have stopped improving. The other instantiations of curriculum learning do not
result in any noticeable improvement. A trained sequence prediction model is
also used in transfer learning to the task of sequence classification, where it
is found that transfer learning realizes improved classification performance
compared to methods that learn to classify from scratch.
</dc:description>
 <dc:description>Comment: Updated version: Clarified the contribution (see abstract, intro, and
  conclusion); added figures to illustrate the architecture of the network and
  the difference between training and generation; different selection of
  experiments in Section 6.4; some textual edits</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03069</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NP-Hardness of Reed-Solomon Decoding, and the Prouhet-Tarry-Escott
  Problem</dc:title>
 <dc:creator>Gandikota, Venkata</dc:creator>
 <dc:creator>Ghazi, Badih</dc:creator>
 <dc:creator>Grigorescu, Elena</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Establishing the complexity of {\em Bounded Distance Decoding} for
Reed-Solomon codes is a fundamental open problem in coding theory, explicitly
asked by Guruswami and Vardy (IEEE Trans. Inf. Theory, 2005). The problem is
motivated by the large current gap between the regime when it is NP-hard, and
the regime when it is efficiently solvable (i.e., the Johnson radius).
  We show the first NP-hardness results for asymptotically smaller decoding
radii than the maximum likelihood decoding radius of Guruswami and Vardy.
Specifically, for Reed-Solomon codes of length $N$ and dimension $K=O(N)$, we
show that it is NP-hard to decode more than $ N-K- c\frac{\log N}{\log\log N}$
errors (with $c&gt;0$ an absolute constant). Moreover, we show that the problem is
NP-hard under quasipolynomial-time reductions for an error amount $&gt; N-K-
c\log{N}$ (with $c&gt;0$ an absolute constant).
  These results follow from the NP-hardness of a generalization of the
classical Subset Sum problem to higher moments, called {\em Moments Subset
Sum}, which has been a known open problem, and which may be of independent
interest.
  We further reveal a strong connection with the well-studied
Prouhet-Tarry-Escott problem in Number Theory, which turns out to capture a
main barrier in extending our techniques. We believe the Prouhet-Tarry-Escott
problem deserves further study in the theoretical computer science community.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03071</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness in Reinforcement Learning</dc:title>
 <dc:creator>Jabbari, Shahin</dc:creator>
 <dc:creator>Joseph, Matthew</dc:creator>
 <dc:creator>Kearns, Michael</dc:creator>
 <dc:creator>Morgenstern, Jamie</dc:creator>
 <dc:creator>Roth, Aaron</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We initiate the study of fairness in reinforcement learning, where the
actions of a learning algorithm may affect its environment and future rewards.
Our fairness constraint requires that an algorithm never prefers one action
over another if the long-term (discounted) reward of choosing the latter action
is higher. Our first result is negative: despite the fact that fairness is
consistent with the optimal policy, any learning algorithm satisfying fairness
must take time exponential in the number of states to achieve non-trivial
approximation to the optimal policy. We then provide a provably fair polynomial
time algorithm under an approximate notion of fairness, thus establishing an
exponential gap between exact and approximate fairness
</dc:description>
 <dc:description>Comment: The short version of this paper appears in the proceedings of ICML-17</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03075</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase transitions of extremal cuts for the configuration model</dc:title>
 <dc:creator>Dhara, Souvik</dc:creator>
 <dc:creator>Mukherjee, Debankur</dc:creator>
 <dc:creator>Sen, Subhabrata</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>05C80, 68R10, 68Q87</dc:subject>
 <dc:description>  The $k$-section width and the Max-Cut for the configuration model are shown
to exhibit phase transitions according to the values of certain parameters of
the asymptotic degree distribution. These transitions mirror those observed on
Erd\H{o}s-R\'enyi random graphs, established by Luczak and McDiarmid (2001),
and Coppersmith et al. (2004), respectively.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03075</dc:identifier>
 <dc:identifier>Electron.J.Probab. 22 1 (2017)</dc:identifier>
 <dc:identifier>doi:10.1214/17-EJP109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03079</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fractal Art Generation using GPUs</dc:title>
 <dc:creator>Mayfield, Will. D.</dc:creator>
 <dc:creator>Eiland, Justin. C.</dc:creator>
 <dc:creator>Hutyra, Taylor. J.</dc:creator>
 <dc:creator>Paulsen, Matt. C.</dc:creator>
 <dc:creator>Wyatt, Bryant. M.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Fractal image generation algorithms exhibit extreme parallelizability. Using
general purpose graphics processing unit (GPU) programming to implement
escape-time algorithms for Julia sets of functions,parallel methods generate
visually attractive fractal images much faster than traditional methods. Vastly
improved speeds are achieved using this method of computation, which allow
real-time generation and display of images. A comparison is made between
sequential and parallel implementations of the algorithm. An application
created by the authors demonstrates using the increased speed to create dynamic
imaging of fractals where the user may explore paths of parameter values
corresponding to a given function's Mandelbrot set. Examples are given of
artistic and mathematical insights gained by experiencing fractals
interactively and from the ability to sample the parameter space quickly and
comprehensively.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03081</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VR 'SPACE OPERA': Mimetic Spectralism in an Immersive Starlight
  Audification System</dc:title>
 <dc:creator>Carey, Benedict</dc:creator>
 <dc:creator>Ulas, Burak</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Physics - Popular Physics</dc:subject>
 <dc:description>  This paper describes a system designed as part of an interactive VR opera,
which immerses a real-time composer and an audience (via a network) in the
historical location of Gobeklitepe, in southern Turkey during an imaginary
scenario set in the Pre-Pottery Neolithic period (8500-5500 BCE), viewed by
some to be the earliest example of a temple, or observatory. In this scene
music is generated, where the harmonic material is determined based on
observations of light variation from pulsating stars, that would have
theoretically been overhead on the 1st of October 8000 BC at 23:00 and animal
calls based on the reliefs in the temple. Based on the observations of the
stars V465 Per, HD 217860, 16 Lac, BG CVn and KIC 6382916, frequency
collections were derived and applied to the generation of musical sound and
notation sequences within a custom VR environment using a novel method
incorporating spectralist techniques. Parameters controlling this 'resynthesis'
can be manipulated by the performer using a Leap Motion controller and Oculus
Rift HMD, yielding both sonic and visual results in the environment. The final
opera is to be viewed via Google Cardboard and delivered over the Internet.
This entire process aims to pose questions about real-time composition through
time distortion and invoke a sense of wonder and meaningfulness through a
ritualistic experience.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, 1 table</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03081</dc:identifier>
 <dc:identifier>Proceedings of 13. Sound and Music Computing Conference (2016):
  104-108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03099</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Brief Survey of Non-Residue Based Computational Error Correction</dc:title>
 <dc:creator>Srikanth, Sriseshan</dc:creator>
 <dc:creator>Deng, Bobin</dc:creator>
 <dc:creator>Conte, Thomas M.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  The idea of computational error correction has been around for over half a
century. The motivation has largely been to mitigate unreliable devices,
manufacturing defects or harsh environments, primarily as a mandatory measure
to preserve reliability, or more recently, as a means to lower energy by
allowing soft errors to occasionally creep. While residue codes have shown
great promise for this purpose, there have been several orthogonal non-residue
based techniques. In this article, we provide a high level outline of some of
these non-residual approaches.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03105</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formation Control for Multi-Agent Systems with Connectivity Preservation
  and Event-Triggered Controllers</dc:title>
 <dc:creator>Yi, Xinlei</dc:creator>
 <dc:creator>Wei, Jieqiang</dc:creator>
 <dc:creator>Dimarogonas, Dimos V.</dc:creator>
 <dc:creator>Johansson, Karl H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, event-triggered controllers and corresponding algorithms are
proposed to establish the formation with connectivity preservation for
multi-agent systems. Each agent needs to update its control input and to
broadcast this control input together with the relative state information to
its neighbors at its own triggering times, and to receive information at its
neighbors' triggering times. Two types of system dynamics, single integrators
and double integrators, are considered. As a result, all agents converge to the
formation exponentially with connectivity preservation, and Zeno behavior can
be excluded. Numerical simulations show the effectiveness of the theoretical
results.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03109</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-efficient Machine Learning in Silicon: A Communications-inspired
  Approach</dc:title>
 <dc:creator>Shanbhag, Naresh R.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  This position paper advocates a communications-inspired approach to the
design of machine learning systems on energy-constrained embedded `always-on'
platforms. The communications-inspired approach has two versions - 1) a
deterministic version where existing low-power communication IC design methods
are repurposed, and 2) a stochastic version referred to as Shannon-inspired
statistical information processing employing information-based metrics,
statistical error compensation (SEC), and retraining-based methods to implement
ML systems on stochastic circuit/device fabrics operating at the limits of
energy-efficiency. The communications-inspired approach has the potential to
fully leverage the opportunities afforded by ML algorithms and applications in
order to address the challenges inherent in their deployment on
energy-constrained platforms.
</dc:description>
 <dc:description>Comment: This paper was presented at the 2016 ICML Workshop on On-Device
  Intelligence, June 24, 2016</dc:description>
 <dc:date>2016-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03113</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating the Effect of Centralization on Routing Convergence on a
  Hybrid BGP-SDN Emulation Framework</dc:title>
 <dc:creator>Gamperli, Adrian</dc:creator>
 <dc:creator>Kotronis, Vasileios</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A lot of applications depend on reliable and stable Internet connectivity.
These characteristics are crucial for mission-critical services such as
telemedical applications. An important factor that can affect connection
availability is the convergence time of BGP, the de-facto inter-domain routing
(IDR) protocol in the Internet. After a routing change, it may take several
minutes until the network converges and BGP routing becomes stable again.
Kotronis et al propose a novel Internet routing approach based on SDN
principles that combines several Autonomous Systems (AS) into groups, called
clusters, and introduces a logically centralized routing decision process for
the cluster participants. One of the goals of this concept is to stabilize the
IDR system and bring down its convergence time. However, testing whether such
approaches can improve on BGP problems requires hybrid SDN and BGP
experimentation tools that can emulate multiple ASes. Presently, there is a
lack of an easy to use public tool for this purpose. This work fills this gap
by building a suitable emulation framework and evaluating the effect that a
proof-of-concept IDR controller has on IDR convergence time.
</dc:description>
 <dc:description>Comment: Proceedings of ACM SIGCOMM '14, pages 369-370, 1/1/2015</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03113</dc:identifier>
 <dc:identifier>ACM Computer Communication Review, Vol. 44 / Issue 4, pages
  369-370, 25/2/2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03125</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Modular Theory of Feature Learning</dc:title>
 <dc:creator>McNamara, Daniel</dc:creator>
 <dc:creator>Ong, Cheng Soon</dc:creator>
 <dc:creator>Williamson, Robert C.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning representations of data, and in particular learning features for a
subsequent prediction task, has been a fruitful area of research delivering
impressive empirical results in recent years. However, relatively little is
understood about what makes a representation `good'. We propose the idea of a
risk gap induced by representation learning for a given prediction context,
which measures the difference in the risk of some learner using the learned
features as compared to the original inputs. We describe a set of sufficient
conditions for unsupervised representation learning to provide a benefit, as
measured by this risk gap. These conditions decompose the problem of when
representation learning works into its constituent parts, which can be
separately evaluated using an unlabeled sample, suitable domain-specific
assumptions about the joint distribution, and analysis of the feature learner
and subsequent supervised learner. We provide two examples of such conditions
in the context of specific properties of the unlabeled distribution, namely
when the data lies close to a low-dimensional manifold and when it forms
clusters. We compare our approach to a recently proposed analysis of
semi-supervised learning.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03129</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regular bipartite graphs and intersecting families</dc:title>
 <dc:creator>Kupavskii, Andrey</dc:creator>
 <dc:creator>Zakharov, Dmitriy</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05D05</dc:subject>
 <dc:description>  In this paper we present a simple unifying approach to prove several
statements about intersecting and cross-intersecting families, including the
Erd\H os--Ko--Rado theorem, the Hilton--Milner theorem, a theorem due to Frankl
concerning the size of intersecting families with bounded maximal degree, and
versions of results on the sum of sizes of non-empty cross-intersecting
families due to Frankl and Tokushige. Several new stronger results are also
obtained.
  Our approach is based on the use of regular bipartite graphs. These graphs
are quite often used in Extremal Set Theory problems, however, the approach we
develop proves to be particularly fruitful.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03130</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computationally Efficient Target Classification in Multispectral Image
  Data with Deep Neural Networks</dc:title>
 <dc:creator>Cavigelli, Lukas</dc:creator>
 <dc:creator>Bernath, Dominic</dc:creator>
 <dc:creator>Magno, Michele</dc:creator>
 <dc:creator>Benini, Luca</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Detecting and classifying targets in video streams from surveillance cameras
is a cumbersome, error-prone and expensive task. Often, the incurred costs are
prohibitive for real-time monitoring. This leads to data being stored locally
or transmitted to a central storage site for post-incident examination. The
required communication links and archiving of the video data are still
expensive and this setup excludes preemptive actions to respond to imminent
threats. An effective way to overcome these limitations is to build a smart
camera that transmits alerts when relevant video sequences are detected. Deep
neural networks (DNNs) have come to outperform humans in visual classifications
tasks. The concept of DNNs and Convolutional Networks (ConvNets) can easily be
extended to make use of higher-dimensional input data such as multispectral
data. We explore this opportunity in terms of achievable accuracy and required
computational effort. To analyze the precision of DNNs for scene labeling in an
urban surveillance scenario we have created a dataset with 8 classes obtained
in a field experiment. We combine an RGB camera with a 25-channel VIS-NIR
snapshot sensor to assess the potential of multispectral image data for target
classification. We evaluate several new DNNs, showing that the spectral
information fused together with the RGB frames can be used to improve the
accuracy of the system or to achieve similar accuracy with a 3x smaller
computation effort. We achieve a very high per-pixel accuracy of 99.1%. Even
for scarcely occurring, but particularly interesting classes, such as cars, 75%
of the pixels are labeled correctly with errors occurring only around the
border of the objects. This high accuracy was obtained with a training set of
only 30 labeled images, paving the way for fast adaptation to various
application scenarios.
</dc:description>
 <dc:description>Comment: Presented at SPIE Security + Defence 2016 Proc. SPIE 9997, Target and
  Background Signatures II</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03130</dc:identifier>
 <dc:identifier>doi:10.1117/12.2241383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03131</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diverse Neural Network Learns True Target Functions</dc:title>
 <dc:creator>Xie, Bo</dc:creator>
 <dc:creator>Liang, Yingyu</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural networks are a powerful class of functions that can be trained with
simple gradient descent to achieve state-of-the-art performance on a variety of
applications. Despite their practical success, there is a paucity of results
that provide theoretical guarantees on why they are so effective. Lying in the
center of the problem is the difficulty of analyzing the non-convex loss
function with potentially numerous local minima and saddle points. Can neural
networks corresponding to the stationary points of the loss function learn the
true target function? If yes, what are the key factors contributing to such
nice optimization properties?
  In this paper, we answer these questions by analyzing one-hidden-layer neural
networks with ReLU activation, and show that despite the non-convexity, neural
networks with diverse units have no spurious local minima. We bypass the
non-convexity issue by directly analyzing the first order optimality condition,
and show that the loss can be made arbitrarily small if the minimum singular
value of the &quot;extended feature matrix&quot; is large enough. We make novel use of
techniques from kernel methods and geometric discrepancy, and identify a new
relation linking the smallest singular value to the spectrum of a kernel
function associated with the activation function and to the diversity of the
units. Our results also suggest a novel regularization function to promote unit
diversity for potentially better generalization.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03158</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Neural Networks to Compute Approximate and Guaranteed Feasible
  Hamilton-Jacobi-Bellman PDE Solutions</dc:title>
 <dc:creator>Jiang, Frank</dc:creator>
 <dc:creator>Chou, Glen</dc:creator>
 <dc:creator>Chen, Mo</dc:creator>
 <dc:creator>Tomlin, Claire J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  To sidestep the curse of dimensionality when computing solutions to
Hamilton-Jacobi-Bellman partial differential equations (HJB PDE), we propose an
algorithm that leverages a neural network to approximate the value function. We
show that our final approximation of the value function generates near optimal
controls which are guaranteed to successfully drive the system to a target
state. Our framework is not dependent on state space discretization, leading to
a significant reduction in computation time and space complexity in comparison
with dynamic programming-based approaches. Using this grid-free approach also
enables us to plan over longer time horizons with relatively little additional
computation overhead. Unlike many previous neural network HJB PDE approximating
formulations, our approximation is strictly conservative and hence any
trajectories we generate will be strictly feasible. For demonstration, we
specialize our new general framework to the Dubins car model and discuss how
the framework can be applied to other models with higher-dimensional state
spaces.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Conference on Decision and Control, 2017</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03159</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Compression of a Weighted Graph</dc:title>
 <dc:creator>Khan, Kifayat Ullah</dc:creator>
 <dc:creator>Nawaz, Waqas</dc:creator>
 <dc:creator>Lee, Young-Koo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Graph is a useful data structure to model various real life aspects like
email communications, co-authorship among researchers, interactions among
chemical compounds, and so on. Supporting such real life interactions produce a
knowledge rich massive repository of data. However, efficiently understanding
underlying trends and patterns is hard due to large size of the graph.
Therefore, this paper presents a scalable compression solution to compute
summary of a weighted graph. All the aforementioned interactions from various
domains are represented as edge weights in a graph. Therefore, creating a
summary graph while considering this vital aspect is necessary to learn
insights of different communication patterns. By experimenting the proposed
method on two real world and publically available datasets against a state of
the art technique, we obtain order of magnitude performance gain and better
summarization accuracy.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03168</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tactics and Tallies: Inferring Voter Preferences in the 2016 U.S.
  Presidential Primaries Using Sparse Learning</dc:title>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Feng, Yang</dc:creator>
 <dc:creator>Zhang, Xiyang</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we propose a web-centered framework to infer voter preferences
for the 2016 U.S. presidential primaries. Using Twitter data collected from
Sept. 2015 to March 2016, we first uncover the tweeting tactics of the
candidates and then exploit the variations in the number of 'likes' to infer
voters' preference. With sparse learning, we are able to reveal neutral topics
as well as positive and negative ones.
  Methodologically, we are able to achieve a higher predictive power with
sparse learning. Substantively, we show that for Hillary Clinton the (only)
positive issue area is women's rights. We demonstrate that Hillary Clinton's
tactic of linking herself to President Obama resonates well with her supporters
but the same is not true for Bernie Sanders. In addition, we show that Donald
Trump is a major topic for all the other candidates, and that the women's
rights issue is equally emphasized in Sanders' campaign as in Clinton's.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03169</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On $\mathbb{Z}_{2}\mathbb{Z}_{2}[u]$-$(1+u)$-additive constacyclic</dc:title>
 <dc:creator>Li, Ping</dc:creator>
 <dc:creator>Dai, Wei</dc:creator>
 <dc:creator>Kai, Xiaoshan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study $\mathbb{Z}_{2}\mathbb{Z}_{2}[u]$-$(1+u)$-additive
constacyclic code of arbitrary length. Firstly, we study the algebraic
structure of this family of codes and a set of generator polynomials for this
family as a $(\mathbb{Z}_{2}+u\mathbb{Z}_{2})[x]$-submodule of the ring
$R_{\alpha,\beta}$. Secondly, we give the minimal generating sets of this
family codes, and we determine the relationship of generators between the
$\mathbb{Z}_{2}\mathbb{Z}_{2}[u]$-$(1+u)$-additive constacyclic codes and its
dual and give the parameters in terms of the degrees of the generator
polynomials of the code. Lastly, we also study
$\mathbb{Z}_{2}\mathbb{Z}_{2}[u]$-$(1+u)$-additive constacyclic code in terms
of the Gray images.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03176</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>5G Multimedia Massive MIMO Communications Systems</dc:title>
 <dc:creator>Ge, Xiaohu</dc:creator>
 <dc:creator>Wang, Haichao</dc:creator>
 <dc:creator>Zi, Ran</dc:creator>
 <dc:creator>Li, Qiang</dc:creator>
 <dc:creator>Ni, Qiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the Fifth generation (5G) wireless communication systems, a majority of
the traffic demands is contributed by various multimedia applications. To
support the future 5G multimedia communication systems, the massive
multiple-input multiple-output (MIMO) technique is recognized as a key enabler
due to its high spectral efficiency. The massive antennas and radio frequency
(RF) chains not only improve the implementation cost of 5G wireless
communication systems but also result in an intense mutual coupling effect
among antennas because of the limited space for deploying antennas. To reduce
the cost, an optimal equivalent precoding matrix with the minimum number of RF
chains is proposed for 5G multimedia massive MIMO communication systems
considering the mutual coupling effect. Moreover, an upper bound of the
effective capacity is derived for 5G multimedia massive MIMO communication
systems. Two antenna receive diversity gain models are built and analyzed. The
impacts of the antenna spacing, the number of antennas, the quality of service
(QoS) statistical exponent, and the number of independent incident directions
on the effective capacity of 5G multimedia massive MIMO communication systems
are analyzed. Comparing with the conventional zero-forcing precoding matrix,
simulation results demonstrate that the proposed optimal equivalent precoding
matrix can achieve a higher achievable rate for 5G multimedia massive MIMO
communication systems.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03178</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noise reduction combining microphone and piezoelectric device</dc:title>
 <dc:creator>Takahashi, Naoya</dc:creator>
 <dc:creator>Matsumoto, Mitsuharu</dc:creator>
 <dc:creator>Hashimoto, Shuji</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  It is often required to extract the sound of an objective instrument played
in concert with other instruments. Microphone array is one of the effective
ways to enhance a sound from a specific direction. However it is not effective
in an echoic room such as concert hall. The pickup microphone attached on the
specific musical instrument is often employed to obtain the sound exclusively
from other instrumental sounds. The obtained timbre differ from the one we hear
at the usual listening position. The purpose of this paper is to propose a new
method of sound separation that utilizes the piezoelectric device attached on
the body of the instrument. The signal from the attached device has a different
spectrum from the sound heard by the audience but has the same frequency
components as the instrumental sound. Our idea is to use the device signal as a
modifier of the sound focusing filter applied to the microphone sound at the
listening position. The proposed method firstly estimates the frequency
components of the signal from the piezoelectric device. The frequency
characteristics for filtering the microphone sound are changed so that it pass
the estimated frequency components. Thus we can extractthe target sound without
distortion. The proposed method is a sort of dynamic sparseness approach. It
was found that SNR is improved by 8.7dB through the experiments.
</dc:description>
 <dc:description>Comment: Presented at 19th International Congress on Acoustics (ICA), Madrid,
  2007</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03183</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive Machine Type Communication with Data Aggregation and Resource
  Scheduling</dc:title>
 <dc:creator>Guo, Jing</dc:creator>
 <dc:creator>Durrani, Salman</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Yanikomeroglu, Halim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To enable massive machine type communication (mMTC), data aggregation is a
promising approach to reduce the congestion caused by a massive number of
machine type devices (MTDs). In this work, we consider a two-phase
cellular-based mMTC network where MTDs transmit to aggregators (i.e.,
aggregation phase) and the aggregated data is then relayed to base stations
(i.e., relaying phase). Due to the limited resources, the aggregators not only
aggregate data, but also schedule resources among MTDs. We consider two
scheduling schemes: random resource scheduling (RRS) and channel-aware resource
scheduling (CRS). By leveraging the stochastic geometry, we present a tractable
analytical framework to investigate the signal-to-interference ratio (SIR) for
each phase, thereby computing the MTD success probability, the average number
of successful MTDs and probability of successful channel utilization, which are
the key metrics characterizing the overall mMTC performance. Our numerical
results show that, although the CRS outperforms the RRS in terms of SIR at the
aggregation phase, the simpler RRS has almost the same performance as the CRS
for most cases with regards to the overall mMTC performance. Furthermore, the
provision of more resources at the aggregation phase is not always beneficial
to the mMTC performance.
</dc:description>
 <dc:description>Comment: submitted to possible journal publication</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03183</dc:identifier>
 <dc:identifier>IEEE Transactions on Communications, vol. 65, no. 9, pp.
  4012-4026, Sep. 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03186</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SoK: Applying Machine Learning in Security - A Survey</dc:title>
 <dc:creator>Jiang, Heju</dc:creator>
 <dc:creator>Nagra, Jasvir</dc:creator>
 <dc:creator>Ahammad, Parvez</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The idea of applying machine learning(ML) to solve problems in security
domains is almost 3 decades old. As information and communications grow more
ubiquitous and more data become available, many security risks arise as well as
appetite to manage and mitigate such risks. Consequently, research on applying
and designing ML algorithms and systems for security has grown fast, ranging
from intrusion detection systems(IDS) and malware classification to security
policy management(SPM) and information leak checking. In this paper, we
systematically study the methods, algorithms, and system designs in academic
publications from 2008-2015 that applied ML in security domains. 98 percent of
the surveyed papers appeared in the 6 highest-ranked academic security
conferences and 1 conference known for pioneering ML applications in security.
We examine the generalized system designs, underlying assumptions,
measurements, and use cases in active research. Our examinations lead to 1) a
taxonomy on ML paradigms and security domains for future exploration and
exploitation, and 2) an agenda detailing open and upcoming challenges. Based on
our survey, we also suggest a point of view that treats security as a game
theory problem instead of a batch-trained ML problem.
</dc:description>
 <dc:description>Comment: 18 pages, 2 figures, 11 tables</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03187</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Hinge Patterns for Folding Strips Efficiently into Any Grid
  Polyhedron</dc:title>
 <dc:creator>Benbernou, Nadia M.</dc:creator>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Demaine, Martin L.</dc:creator>
 <dc:creator>Lubiw, Anna</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  We present two universal hinge patterns that enable a strip of material to
fold into any connected surface made up of unit squares on the 3D cube
grid--for example, the surface of any polycube. The folding is efficient: for
target surfaces topologically equivalent to a sphere, the strip needs to have
only twice the target surface area, and the folding stacks at most two layers
of material anywhere. These geometric results offer a new way to build
programmable matter that is substantially more efficient than what is possible
with a square $N \times N$ sheet of material, which can fold into all polycubes
only of surface area $O(N)$ and may stack $\Theta(N^2)$ layers at one point. We
also show how our strip foldings can be executed by a rigid motion without
collisions, which is not possible in general with 2D sheet folding.
  To achieve these results, we develop new approximation algorithms for milling
the surface of a grid polyhedron, which simultaneously give a 2-approximation
in tour length and an 8/3-approximation in the number of turns. Both length and
turns consume area when folding a strip, so we build on past approximation
algorithms for these two objectives from 2D milling.
</dc:description>
 <dc:description>Comment: 20 pages, 15 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03193</identifier>
 <datestamp>2017-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mahalanobis Distance for Class Averaging of Cryo-EM Images</dc:title>
 <dc:creator>Bhamre, Tejal</dc:creator>
 <dc:creator>Zhao, Zhizhen</dc:creator>
 <dc:creator>Singer, Amit</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Single particle reconstruction (SPR) from cryo-electron microscopy (EM) is a
technique in which the 3D structure of a molecule needs to be determined from
its contrast transfer function (CTF) affected, noisy 2D projection images taken
at unknown viewing directions. One of the main challenges in cryo-EM is the
typically low signal to noise ratio (SNR) of the acquired images. 2D
classification of images, followed by class averaging, improves the SNR of the
resulting averages, and is used for selecting particles from micrographs and
for inspecting the particle images. We introduce a new affinity measure, akin
to the Mahalanobis distance, to compare cryo-EM images belonging to different
defocus groups. The new similarity measure is employed to detect similar
images, thereby leading to an improved algorithm for class averaging. We
evaluate the performance of the proposed class averaging procedure on synthetic
datasets, obtaining state of the art classification.
</dc:description>
 <dc:description>Comment: Final version accepted to the 14th IEEE International Symposium on
  Biomedical Imaging (ISBI 2017)</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03193</dc:identifier>
 <dc:identifier>doi:10.1109/ISBI.2017.7950605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03197</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Service Chain Placement and Routing in a Network-enabled Cloud</dc:title>
 <dc:creator>Gupta, Abhishek</dc:creator>
 <dc:creator>Jaumard, Brigitte</dc:creator>
 <dc:creator>Tornatore, Massimo</dc:creator>
 <dc:creator>Mukherjee, Biswanath</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network Function Virtualization (NFV) aims to abstract the functionality of
traditional proprietary hardware into software as Virtual Network Functions
(VNFs), which can run on commercial off the shelf (COTS) servers. Besides
reducing dependency on proprietary support, NFV helps network operators to
deploy multiple services in a agile fashion. Service deployment involves
placement and in sequence routing through VNFs comprising a Service Chain (SC).
Our study is the first to focus on the computationally complex problem of
multiple VNF SC placement and routing while considering VNF service chaining
explicitly. We propose a novel column generation model for placing multiple VNF
SCs and routing, which reduces the computational complexity of the problem
significantly. Our aim here is to determine the ideal NFV Infrastructure (NFVI)
for minimizing network resource consumption. Our results indicate that a
Network enabled Cloud (NeC) results in lower networkresource consumption than a
centralized NFVI (e.g., Data Center) while avoiding infeasibility with a
distributed NFVI.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03199</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Data Drug Discovery with One-shot Learning</dc:title>
 <dc:creator>Altae-Tran, Han</dc:creator>
 <dc:creator>Ramsundar, Bharath</dc:creator>
 <dc:creator>Pappu, Aneesh S.</dc:creator>
 <dc:creator>Pande, Vijay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent advances in machine learning have made significant contributions to
drug discovery. Deep neural networks in particular have been demonstrated to
provide significant boosts in predictive power when inferring the properties
and activities of small-molecule compounds. However, the applicability of these
techniques has been limited by the requirement for large amounts of training
data. In this work, we demonstrate how one-shot learning can be used to
significantly lower the amounts of data required to make meaningful predictions
in drug discovery applications. We introduce a new architecture, the residual
LSTM embedding, that, when combined with graph convolutional neural networks,
significantly improves the ability to learn meaningful distance metrics over
small-molecules. We open source all models introduced in this work as part of
DeepChem, an open-source framework for deep-learning in drug discovery.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03202</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Adaptation of Activity Sensing Policies in Mobile Devices</dc:title>
 <dc:creator>Alsheikh, Mohammad Abu</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Lin, Shaowei</dc:creator>
 <dc:creator>Tan, Hwee-Pink</dc:creator>
 <dc:creator>Kim, Dong In</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  With the proliferation of sensors, such as accelerometers, in mobile devices,
activity and motion tracking has become a viable technology to understand and
create an engaging user experience. This paper proposes a fast adaptation and
learning scheme of activity tracking policies when user statistics are unknown
a priori, varying with time, and inconsistent for different users. In our
stochastic optimization, user activities are required to be synchronized with a
backend under a cellular data limit to avoid overcharges from cellular
operators. The mobile device is charged intermittently using wireless or wired
charging for receiving the required energy for transmission and sensing
operations. Firstly, we propose an activity tracking policy by formulating a
stochastic optimization as a constrained Markov decision process (CMDP).
Secondly, we prove that the optimal policy of the CMDP has a threshold
structure using a Lagrangian relaxation approach and the submodularity concept.
We accordingly present a fast Q-learning algorithm by considering the policy
structure to improve the convergence speed over that of conventional
Q-learning. Finally, simulation examples are presented to support the
theoretical findings of this paper.
</dc:description>
 <dc:description>Comment: 14 pages, 10 figure</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03204</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top-k Spatial-keyword Publish/Subscribe Over Sliding Window</dc:title>
 <dc:creator>Wang, Xiang</dc:creator>
 <dc:creator>Zhang, Ying</dc:creator>
 <dc:creator>Zhang, Wenjie</dc:creator>
 <dc:creator>Lin, Xuemin</dc:creator>
 <dc:creator>Huang, Zengfeng</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  With the prevalence of social media and GPS-enabled devices, a massive amount
of geo-textual data has been generated in a stream fashion, leading to a
variety of applications such as location-based recommendation and information
dissemination. In this paper, we investigate a novel real-time top-k monitoring
problem over sliding window of streaming data; that is, we continuously
maintain the top-k most relevant geo-textual messages (e.g., geo-tagged tweets)
for a large number of spatial-keyword subscriptions (e.g., registered users
interested in local events) simultaneously. To provide the most recent
information under controllable memory cost, sliding window model is employed on
the streaming geo-textual data. To the best of our knowledge, this is the first
work to study top-k spatial-keyword publish/subscribe over sliding window. A
novel centralized system, called Skype (Topk Spatial-keyword
Publish/Subscribe), is proposed in this paper. In Skype, to continuously
maintain top-k results for massive subscriptions, we devise a novel indexing
structure upon subscriptions such that each incoming message can be immediately
delivered on its arrival. To reduce the expensive top-k re-evaluation cost
triggered by message expiration, we develop a novel cost-based k-skyband
technique to reduce the number of re-evaluations in a cost-effective way.
Extensive experiments verify the great efficiency and effectiveness of our
proposed techniques. Furthermore, to support better scalability and higher
throughput, we propose a distributed version of Skype, namely, DSkype, on top
of Storm, which is a popular distributed stream processing system. With the
help of fine-tuned subscription/message distribution mechanisms, DSkype can
achieve orders of magnitude speed-up than its centralized version.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03206</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Energy Management for Building Climate Comfort in Smart
  Thermal Grids with Seasonal Storage Systems</dc:title>
 <dc:creator>Rostampour, V.</dc:creator>
 <dc:creator>Keviczky, T.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents an energy management framework for building climate
comfort systems that are interconnected in a grid via aquifer thermal energy
storage (ATES) systems in the presence of two types of uncertainty, namely
private and common uncertainty sources. The ATES system is considered as a
seasonal storage system that can be a heat source or sink, or a storage for
thermal energy. While the private uncertainty source refers to uncertain
thermal energy demand of individual buildings, the common uncertainty source
describes the uncertain common resource pool (ATES) between neighbors. To this
end, we develop a large-scale stochastic hybrid dynamical model to predict the
thermal energy imbalance in a network of interconnected building climate
comfort systems together with mutual interactions between the local ATES
systems. We formulate a finite-horizon mixed-integer quadratic optimization
problem with multiple chance constraints at each sampling time, which is in
general a non-convex problem and hard to solve. We then provide a
computationally tractable framework based on an extension to the so-called
robust randomized approach which offers a less conservative solution for a
problem with multiple chance constraints. A simulation study is provided to
compare three different configurations, namely: completely decoupled,
centralized and move-blocking centralized solutions. In addition, we present a
numerical study using a geohydrological simulation environment (MODFLOW) to
illustrate the advantages of our proposed framework.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03213</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Length Matters: Clustering System Log Messages using Length of Words</dc:title>
 <dc:creator>Shima, Keiichi</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:description>  The analysis techniques of system log messages (syslog messages) have a long
history from when the syslog mechanism was invented. Typically, the analysis
consists of two parts, one is a message template generation, and the other is
finding something interesting using the messages classified by the inferred
templates. It is important to generate better templates to achieve better,
precise, or convincible analysis results. In this paper, we propose a
classification methodology using the length of words of each message. Our
method is suitable for online template generation because it does not require
two-pass analysis to generate template messages, that is an important factor
considering increasing amount of log messages produced by a large number of
system components such as cloud infrastructure.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03214</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ultimate tensorization: compressing convolutional and FC layers alike</dc:title>
 <dc:creator>Garipov, Timur</dc:creator>
 <dc:creator>Podoprikhin, Dmitry</dc:creator>
 <dc:creator>Novikov, Alexander</dc:creator>
 <dc:creator>Vetrov, Dmitry</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional neural networks excel in image recognition tasks, but this
comes at the cost of high computational and memory complexity. To tackle this
problem, [1] developed a tensor factorization framework to compress
fully-connected layers. In this paper, we focus on compressing convolutional
layers. We show that while the direct application of the tensor framework [1]
to the 4-dimensional kernel of convolution does compress the layer, we can do
better. We reshape the convolutional kernel into a tensor of higher order and
factorize it. We combine the proposed approach with the previous work to
compress both convolutional and fully-connected layers of a network and achieve
80x network compression rate with 1.1% accuracy drop on the CIFAR-10 dataset.
</dc:description>
 <dc:description>Comment: NIPS 2016 workshop: Learning with Tensors: Why Now and How?</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03215</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CMS software and computing for LHC Run 2</dc:title>
 <dc:creator>Bloom, Kenneth</dc:creator>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:description>  The CMS offline software and computing system has successfully met the
challenge of LHC Run 2. In this presentation, we will discuss how the entire
system was improved in anticipation of increased trigger output rate, increased
rate of pileup interactions and the evolution of computing technology. The
primary goals behind these changes was to increase the flexibility of computing
facilities where ever possible, as to increase our operational efficiency, and
to decrease the computing resources needed to accomplish the primary offline
computing workflows. These changes have resulted in a new approach to
distributed computing in CMS for Run 2 and for the future as the LHC luminosity
should continue to increase. We will discuss changes and plans to our data
federation, which was one of the key changes towards a more flexible computing
model for Run 2. Our software framework and algorithms also underwent
significant changes. We will summarize the our experience with a new
multi-threaded framework as deployed on our prompt reconstruction farm for 2015
and across the CMS WLCG Tier-1 facilities. We will discuss our experience with
a analysis data format which is ten times smaller than our primary Run 1
format. This &quot;miniAOD&quot; format has proven to be easier to analyze while be
extremely flexible for analysts. Finally, we describe improvements to our
workflow management system that have resulted in increased automation and
reliability for all facets of CMS production and user analysis operations.
</dc:description>
 <dc:description>Comment: Contribution to proceedings of the 38th International Conference on
  High Energy Physics (ICHEP 2016)</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03217</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real Time Video Analysis using Smart Phone Camera for Stroboscopic Image</dc:title>
 <dc:creator>Mukherjee, Somnath</dc:creator>
 <dc:creator>Ganguly, Soumyajit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Motion capturing and there by segmentation of the motion of any moving object
from a sequence of continuous images or a video is not an exceptional task in
computer vision area. Smart-phone camera application is an added integration
for the development of such tasks and it also provides for a smooth testing. A
new approach has been proposed for segmenting out the foreground moving object
from the background and then masking the sequential motion with the static
background which is commonly known as stroboscopic image. In this paper the
whole process of the stroboscopic image construction technique has been clearly
described along with some necessary constraints which is due to the traditional
problem of estimating and modeling dynamic background changes. The background
subtraction technique has been properly estimated here and number of sequential
motion have also been calculated with the correlation between the motion of the
object and its time of occurrence. This can be a very effective application
that can replace the traditional stroboscopic system using high end SLR
cameras, tripod stand, shutter speed control and position etc.
</dc:description>
 <dc:description>Comment: 5 pages, 2 Figures in SPIE Electronic Imaging 2015</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03218</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Play Guess Who? and Inventing a Grounded Language as a
  Consequence</dc:title>
 <dc:creator>Jorge, Emilio</dc:creator>
 <dc:creator>K&#xe5;geb&#xe4;ck, Mikael</dc:creator>
 <dc:creator>Johansson, Fredrik D.</dc:creator>
 <dc:creator>Gustavsson, Emil</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Acquiring your first language is an incredible feat and not easily
duplicated. Learning to communicate using nothing but a few pictureless books,
a corpus, would likely be impossible even for humans. Nevertheless, this is the
dominating approach in most natural language processing today. As an
alternative, we propose the use of situated interactions between agents as a
driving force for communication, and the framework of Deep Recurrent Q-Networks
for evolving a shared language grounded in the provided environment. We task
the agents with interactive image search in the form of the game Guess Who?.
The images from the game provide a non trivial environment for the agents to
discuss and a natural grounding for the concepts they decide to encode in their
communication. Our experiments show that the agents learn not only to encode
physical concepts in their words, i.e. grounding, but also that the agents
learn to hold a multi-step dialogue remembering the state of the dialogue from
step to step.
</dc:description>
 <dc:description>Comment: Previous version was accepted to Deep Reinforcement Learning Workshop
  at NIPS 2016</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03220</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Kernel Ridge Regression Using Sketching and Preconditioning</dc:title>
 <dc:creator>Avron, Haim</dc:creator>
 <dc:creator>Clarkson, Kenneth L.</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Kernel Ridge Regression (KRR) is a simple yet powerful technique for
non-parametric regression whose computation amounts to solving a linear system.
This system is usually dense and highly ill-conditioned. In addition, the
dimensions of the matrix are the same as the number of data points, so direct
methods are unrealistic for large-scale datasets. In this paper, we propose a
preconditioning technique for accelerating the solution of the aforementioned
linear system. The preconditioner is based on random feature maps, such as
random Fourier features, which have recently emerged as a powerful technique
for speeding up and scaling the training of kernel-based methods, such as
kernel ridge regression, by resorting to approximations. However, random
feature maps only provide crude approximations to the kernel function, so
delivering state-of-the-art results by directly solving the approximated system
requires the number of random features to be very large. We show that random
feature maps can be much more effective in forming preconditioners, since under
certain conditions a not-too-large number of random features is sufficient to
yield an effective preconditioner. We empirically evaluate our method and show
it is highly effective for datasets of up to one million training examples.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03225</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sharper Bounds for Regularized Data Fitting</dc:title>
 <dc:creator>Avron, Haim</dc:creator>
 <dc:creator>Clarkson, Kenneth L.</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We study matrix sketching methods for regularized variants of linear
regression, low rank approximation, and canonical correlation analysis. Our
main focus is on sketching techniques which preserve the objective function
value for regularized problems, which is an area that has remained largely
unexplored. We study regularization both in a fairly broad setting, and in the
specific context of the popular and widely used technique of ridge
regularization; for the latter, as applied to each of these problems, we show
algorithmic resource bounds in which the {\em statistical dimension} appears in
places where in previous bounds the rank would appear. The statistical
dimension is always smaller than the rank, and decreases as the amount of
regularization increases. In particular, for the ridge low-rank approximation
problem $\min_{Y,X} \lVert YX - A \rVert_F^2 + \lambda \lVert Y\rVert_F^2 +
\lambda\lVert X \rVert_F^2$, where $Y\in\mathbb{R}^{n\times k}$ and
$X\in\mathbb{R}^{k\times d}$, we give an approximation algorithm needing \[
O(\mathtt{nnz}(A)) + \tilde{O}((n+d)\varepsilon^{-1}k \min\{k,
\varepsilon^{-1}\mathtt{sd}_\lambda(Y^*)\})+
\mathtt{poly}(\mathtt{sd}_\lambda(Y^*) \varepsilon^{-1}) \] time, where
$s_{\lambda}(Y^*)\le k$ is the statistical dimension of $Y^*$, $Y^*$ is an
optimal $Y$, $\varepsilon$ is an error parameter, and $\mathtt{nnz}(A)$ is the
number of nonzero entries of $A$.This is faster than prior work, even when
$\lambda=0$.
  We also study regularization in a much more general setting. For example, we
obtain sketching-based algorithms for the low-rank approximation problem
$\min_{X,Y} \lVert YX - A \rVert_F^2 + f(Y,X)$ where $f(\cdot,\cdot)$ is a
regularizing function satisfying some very general conditions (chiefly,
invariance under orthogonal transformations).
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03226</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Executing Dynamic Data Rate Actor Networks on OpenCL Platforms</dc:title>
 <dc:creator>Boutellier, Jani</dc:creator>
 <dc:creator>Hautala, Ilkka</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Heterogeneous computing platforms consisting of general purpose processors
(GPPs) and graphics processing units (GPUs) have become commonplace in personal
mobile devices and embedded systems. For years, programming of these platforms
was very tedious and simultaneous use of all available GPP and GPU resources
required low-level programming to ensure efficient synchronization and data
transfer between processors. However, in the last few years several high-level
programming frameworks have emerged, which enable programmers to describe
applications by means of abstractions such as dataflow or Kahn process networks
and leave parallel execution, data transfer and synchronization to be handled
by the framework.
  Unfortunately, even the most advanced high-level programming frameworks have
had shortcomings that limit their applicability to certain classes of
applications. This paper presents a new, dataflow-flavored programming
framework targeting heterogeneous platforms, and differs from previous
approaches by allowing GPU-mapped actors to have data dependent consumption of
inputs / production of outputs. Such flexibility is essential for configurable
and adaptive applications that are becoming increasingly common in signal
processing. In our experiments it is shown that this feature allows up to 5x
increase in application throughput.
  The proposed framework is validated by application examples from the video
processing and wireless communications domains. In the experiments the
framework is compared to a well-known reference framework and it is shown that
the proposed framework enables both a higher degree of flexibility and better
throughput.
</dc:description>
 <dc:description>Comment: 2016 IEEE International Workshop on Signal Processing Systems</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03231</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Policy Search with High-Dimensional Context Variables</dc:title>
 <dc:creator>Tangkaratt, Voot</dc:creator>
 <dc:creator>van Hoof, Herke</dc:creator>
 <dc:creator>Parisi, Simone</dc:creator>
 <dc:creator>Neumann, Gerhard</dc:creator>
 <dc:creator>Peters, Jan</dc:creator>
 <dc:creator>Sugiyama, Masashi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Direct contextual policy search methods learn to improve policy parameters
and simultaneously generalize these parameters to different context or task
variables. However, learning from high-dimensional context variables, such as
camera images, is still a prominent problem in many real-world tasks. A naive
application of unsupervised dimensionality reduction methods to the context
variables, such as principal component analysis, is insufficient as
task-relevant input may be ignored. In this paper, we propose a contextual
policy search method in the model-based relative entropy stochastic search
framework with integrated dimensionality reduction. We learn a model of the
reward that is locally quadratic in both the policy parameters and the context
variables. Furthermore, we perform supervised linear dimensionality reduction
on the context variables by nuclear norm regularization. The experimental
results show that the proposed method outperforms naive dimensionality
reduction via principal component analysis and a state-of-the-art contextual
policy search method.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03233</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale JPEG steganalysis using hybrid deep-learning framework</dc:title>
 <dc:creator>Zeng, Jishen</dc:creator>
 <dc:creator>Tan, Shunquan</dc:creator>
 <dc:creator>Li, Bin</dc:creator>
 <dc:creator>Huang, Jiwu</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Adoption of deep learning in image steganalysis is still in its initial
stage. In this paper we propose a generic hybrid deep-learning framework for
JPEG steganalysis incorporating the domain knowledge behind rich steganalytic
models. Our proposed framework involves two main stages. The first stage is
hand-crafted, corresponding to the convolution phase and the quantization &amp;
truncation phase of the rich models. The second stage is a compound deep neural
network containing multiple deep subnets in which the model parameters are
learned in the training procedure. We provided experimental evidences and
theoretical reflections to argue that the introduction of threshold quantizers,
though disable the gradient-descent-based learning of the bottom convolution
phase, is indeed cost-effective. We have conducted extensive experiments on a
large-scale dataset extracted from ImageNet. The primary dataset used in our
experiments contains 500,000 cover images, while our largest dataset contains
five million cover images. Our experiments show that the integration of
quantization and truncation into deep-learning steganalyzers do boost the
detection performance by a clear margin. Furthermore, we demonstrate that our
framework is insensitive to JPEG blocking artifact alterations, and the learned
model can be easily transferred to a different attacking target and even a
different dataset. These properties are of critical importance in practical
applications.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Information Forensics and Security</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03233</dc:identifier>
 <dc:identifier>doi:10.1109/TIFS.2017.2779446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03236</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The number of satisfying assignments of random regular k-SAT formulas</dc:title>
 <dc:creator>Coja-Oghlan, Amin</dc:creator>
 <dc:creator>Wormald, Nick</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>60C05</dc:subject>
 <dc:description>  Let $\Phi$ be a random $k$-SAT formula in which every variable occurs
precisely $d$ times positively and $d$ times negatively. Assuming that $k$ is
sufficiently large and that $d$ is slightly below the critical degree where the
formula becomes unsatisfiable with high probability, we determine the limiting
distribution of the logarithm of the number of satisfying assignments.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03252</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reduce positive and negative falses from attacks collected from the
  deployment of distributed honeypot network</dc:title>
 <dc:creator>Agnaou, Abdeljalil</dc:creator>
 <dc:creator>Kalam, Anas Abou El</dc:creator>
 <dc:creator>Ouahman, Abdellah Ait</dc:creator>
 <dc:creator>De Montfort, Mina</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Current tools and systems of detecting vulnerabilities simply alert the
administrator of attempted attacks against his network or system. However,
generally, the huge number of alerts to analyze and the amount time required to
update security rules after analyzing alerts provides time and opportunity for
the attacker to inflict damages. Moreover, most of these tools generate
positive and negative falses, which may be important to the attacked network.
Otherwise, many solutions exist such as IPS, but it shows a great defect due,
fundamentally, to false positives. Indeed, attackers often make IPS block a
legitimate traffic when they detect its presence in the attacked network. In
this paper we describe an automated algorithm that gives the ability to detect
attacks before they occurrence, then reduce positive and negative falses rates.
Moreover, we use a set of data related to malicious traffic captured using a
network of honeypots to recognize potential threats sources.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03252</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information Security
  Volume 14 No. 9, September 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03253</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Submodular Maximization via a Non-symmetric Technique</dc:title>
 <dc:creator>Buchbinder, Niv</dc:creator>
 <dc:creator>Feldman, Moran</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W25 (Primary), 68R05, 90C26 (Secondary)</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  The study of combinatorial optimization problems with a submodular objective
has attracted much attention in recent years. Such problems are important in
both theory and practice because their objective functions are very general.
Obtaining further improvements for many submodular maximization problems boils
down to finding better algorithms for optimizing a relaxation of them known as
the multilinear extension.
  In this work we present an algorithm for optimizing the multilinear
relaxation whose guarantee improves over the guarantee of the best previous
algorithm (which was given by Ene and Nguyen (2016)). Moreover, our algorithm
is based on a new technique which is, arguably, simpler and more natural for
the problem at hand. In a nutshell, previous algorithms for this problem rely
on symmetry properties which are natural only in the absence of a constraint.
Our technique avoids the need to resort to such properties, and thus, seems to
be a better fit for constrained problems.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03254</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Engagement Meets Similarity: Efficient (k,r)-Core Computation on
  Social Networks</dc:title>
 <dc:creator>Zhang, Fan</dc:creator>
 <dc:creator>Zhang, Ying</dc:creator>
 <dc:creator>Qin, Lu</dc:creator>
 <dc:creator>Zhang, Wenjie</dc:creator>
 <dc:creator>Lin, Xuemin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In this paper, we investigate the problem of (k,r)-core which intends to find
cohesive subgraphs on social networks considering both user engagement and
similarity perspectives. In particular, we adopt the popular concept of k-core
to guarantee the engagement of the users (vertices) in a group (subgraph) where
each vertex in a (k,r)-core connects to at least k other vertices. Meanwhile,
we also consider the pairwise similarity between users based on their profiles.
For a given similarity metric and a similarity threshold r, the similarity
between any two vertices in a (k,r)-core is ensured not less than r. Efficient
algorithms are proposed to enumerate all maximal (k,r)-cores and find the
maximum (k,r)-core, where both problems are shown to be NP-hard. Effective
pruning techniques significantly reduce the search space of two algorithms and
a novel (k,k')-core based (k,r)-core size upper bound enhances performance of
the maximum (k,r)-core computation. We also devise effective search orders to
accommodate the different nature of two mining algorithms. Comprehensive
experiments on real-life data demonstrate that the maximal/maximum (k,r)-cores
enable us to find interesting cohesive subgraphs, and performance of two mining
algorithms is significantly improved by proposed techniques.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03260</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Approximation for Maximum Independent Set on Unit Disk Graph</dc:title>
 <dc:creator>Nandy, Subhas C.</dc:creator>
 <dc:creator>Pandit, Supantha</dc:creator>
 <dc:creator>Roy, Sasanka</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Maximum independent set from a given set $D$ of unit disks intersecting a
horizontal line can be solved in $O(n^2)$ time and $O(n^2)$ space. As a
corollary, we design a factor 2 approximation algorithm for the maximum
independent set problem on unit disk graph which takes both time and space of
$O(n^2)$. The best known factor 2 approximation algorithm for this problem runs
in $O(n^2 \log n)$ time and takes $O(n^2)$ space [Jallu and Das 2016, Das et
al. 2016].
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03264</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Memristor Crossbar-Based Computation Scheme with High Precision</dc:title>
 <dc:creator>Li, Junyi</dc:creator>
 <dc:creator>Peng, Fulin</dc:creator>
 <dc:creator>Yang, Fan</dc:creator>
 <dc:creator>Zeng, Xuan</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The memristor is promising to be the basic cell of next-generation
computation systems. Compared to the traditional MOSFET device, the memristor
is efficient over energy and area. But one of the biggest challenges faced with
researchers is how to program a memristor's resistance precisely. Recently, an
algorithm designed to save 8 valid bits in each memristor is proposed, but this
is still not sufficient for precise computation. In this paper, we propose a
crossbar-based memristor computation scheme supporting precise computations
whose operands have 32 valid bits. As a brief introduction, in a multiplication
with two operands, one operand is programmed as input signal, and the other
operand is saved into a so-called crossbar structure, which contains a group of
memristors, and each memristor saves several valid bits, usually one or two
bits only. The computation results,i.e. the multiplication of the two operands,
are contained in the outputs of the crossbar structure together with noise.
Analog-to-Digital Converters (ADCs) are then used to extract the valid bits,
which are the most significant bits of outputs. These valid bits can be
combined together with Digital-to-Analog Converters(DACs) to get the final
results. What's more, the precision of this computation scheme can be adjusted
according to the definition of the user, 32 valid bits at most, so it is
qualified for different application contexts.
</dc:description>
 <dc:description>Comment: 6 pages,5 figures,conference</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03267</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite Satisfiability of the Two-Variable Guarded Fragment with
  Transitive Guards and Related Variants</dc:title>
 <dc:creator>Kieronski, Emanuel</dc:creator>
 <dc:creator>Tendera, Lidia</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We consider extensions of the two-variable guarded fragment, GF2, where
distinguished binary predicates that occur only in guards are required to be
interpreted in a special way (as transitive relations, equivalence relations,
pre-orders or partial orders). We prove that the only fragment that retains the
finite (exponential) model property is GF2 with equivalence guards without
equality. For remaining fragments we show that the size of a minimal finite
model is at most doubly exponential. To obtain the result we invent a strategy
of building finite models that are formed from a number of multidimensional
grids placed over a cylindrical surface. The construction yields a
2NExpTime-upper bound on the complexity of the finite satisfiability problem
for these fragments. We improve the bounds and obtain optimal ones for all the
fragments considered, in particular NExpTime for GF2 with equivalence guards,
and 2ExpTime for GF2 with transitive guards. To obtain our results we
essentially use some results from integer programming.
</dc:description>
 <dc:description>Comment: Accepted for ACM TOCL</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03268</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error concealment by means of motion refinement and regularized Bregman
  divergence</dc:title>
 <dc:creator>Coelho, Alessandra M.</dc:creator>
 <dc:creator>Estrela, Vania V.</dc:creator>
 <dc:creator>Carmo, Felipe P. do</dc:creator>
 <dc:creator>Fernandes, Sandro R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work addresses the problem of error concealment in video transmission
systems over noisy channels employing Bregman divergences along with
regularization. Error concealment intends to improve the effects of
disturbances at the reception due to bit-errors or cell loss in packet
networks. Bregman regularization gives accurate answers after just some
iterations with fast convergence, better accuracy, and stability. This
technique has an adaptive nature: the regularization functional is updated
according to Bregman functions that change from iteration to iteration
according to the nature of the neighborhood under study at iteration n.
Numerical experiments show that high-quality regularization parameter estimates
can be obtained. The convergence is sped up while turning the regularization
parameter estimation less empiric, and more automatic.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03270</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Moving Regions in CrowdCam Images</dc:title>
 <dc:creator>Dafni, Adi</dc:creator>
 <dc:creator>Moses, Yael</dc:creator>
 <dc:creator>Avidan, Shai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address the novel problem of detecting dynamic regions in CrowdCam images,
a set of still images captured by a group of people. These regions capture the
most interesting parts of the scene, and detecting them plays an important role
in the analysis of visual data. Our method is based on the observation that
matching static points must satisfy the epipolar geometry constraints, but
computing exact matches is challenging. Instead, we compute the probability
that a pixel has a match, not necessarily the correct one, along the
corresponding epipolar line. The complement of this probability is not
necessarily the probability of a dynamic point because of occlusions, noise,
and matching errors. Therefore, information from all pairs of images is
aggregated to obtain a high quality dynamic probability map, per image.
Experiments on challenging datasets demonstrate the effectiveness of the
algorithm on a broad range of settings; no prior knowledge about the scene, the
camera characteristics or the camera locations is required.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03273</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solutions of Grinberg equation and removable cycles in a cycle basis</dc:title>
 <dc:creator>Jiang, Heping</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let G (V, E) be a simple graph with vertex set V and edge set E. A
generalized cycle is a subgraph such that any vertex degree is even. A simple
cycle (briefly in a cycle) is a connected subgraph such that every vertex has
degree 2. A basis of the cycle space is called a cycle basis of G (V, E). A
cycle basis where the sum of the weights of the cycles is minimal is called a
minimum cycle basis of G. Grinberg theorem is a necessary condition to have a
Hamilton cycle in planar graphs. In this paper, we use the cycles of a cycle
basis to replace the faces and obtain an equality of inner faces in Grinberg
theorem, called Grinberg equation. We explain why Grinberg theorem can only be
a necessary condition of Hamilton graphs and apply the theorem, to be a
necessary and sufficient condition, to simple graphs.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03274</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructions and bounds for separating hash families</dc:title>
 <dc:creator>Niu, X.</dc:creator>
 <dc:creator>Cao, H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we present a new construction for strong separating hash
families by using hypergraphs and obtain some optimal separating hash families.
  We also improve some previously known bounds of separating hash families.
</dc:description>
 <dc:description>Comment: Hash family, separating hash family, strong separating hash family,
  hypergraph</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03279</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracing metaphors in time through self-distance in vector spaces</dc:title>
 <dc:creator>Del Tredici, Marco</dc:creator>
 <dc:creator>Nissim, Malvina</dc:creator>
 <dc:creator>Zaninello, Andrea</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  From a diachronic corpus of Italian, we build consecutive vector spaces in
time and use them to compare a term's cosine similarity to itself in different
time spans. We assume that a drop in similarity might be related to the
emergence of a metaphorical sense at a given time. Similarity-based
observations are matched to the actual year when a figurative meaning was
documented in a reference dictionary and through manual inspection of corpus
occurrences.
</dc:description>
 <dc:description>Comment: Proceedings of the Third Italian Conference on Computational
  Linguistics (CLIC 2016)</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03298</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Role of Temporal Diversity in Inferring Social Ties Based on
  Spatio-Temporal Data</dc:title>
 <dc:creator>Desai, Deshana</dc:creator>
 <dc:creator>Nisar, Harsh</dc:creator>
 <dc:creator>Bhardawaj, Rishab</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The last two decades have seen a tremendous surge in research on social
networks and their implications. The studies includes inferring social
relationships, which in turn have been used for target advertising,
recommendations, search customization etc. However, the offline experiences of
human, the conversations with people and face-to-face interactions that govern
our lives interactions have received lesser attention. We introduce DAIICT
Spatio-Temporal Network (DSSN), a spatiotemporal dataset of 0.7 million data
points of continuous location data logged at an interval of every 2 minutes by
mobile phones of 46 subjects. Our research is focused at inferring relationship
strength between students based on the spatiotemporal data and comparing the
results with the self-reported data. In that pursuit we introduce Temporal
Diversity, which we show to be superior in its contribution to predicting
relationship strength than its counterparts. We also explore the evolving
nature of Temporal Diversity with time. Our rich dataset opens various other
avenues of research that require fine-grained location data with bounded
movement of participants within a limited geographical area. The advantage of
having a bounded geographical area such as a university campus is that it
provides us with a microcosm of the real world, where each such geographic zone
has an internal context and function and a high percentage of mobility is
governed by schedules and time-tables. The bounded geographical region in
addition to the age homogeneous population gives us a minute look into the
active internal socialization of students in a university.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03305</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Getting Started with Neural Models for Semantic Matching in Web Search</dc:title>
 <dc:creator>Onal, Kezban Dilek</dc:creator>
 <dc:creator>Altingovde, Ismail Sengor</dc:creator>
 <dc:creator>Karagoz, Pinar</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The vocabulary mismatch problem is a long-standing problem in information
retrieval. Semantic matching holds the promise of solving the problem. Recent
advances in language technology have given rise to unsupervised neural models
for learning representations of words as well as bigger textual units. Such
representations enable powerful semantic matching methods. This survey is meant
as an introduction to the use of neural models for semantic matching. To remain
focused we limit ourselves to web search. We detail the required background and
terminology, a taxonomy grouping the rapidly growing body of work in the area,
and then survey work on neural models for semantic matching in the context of
three tasks: query suggestion, ad retrieval, and document retrieval. We include
a section on resources and best practices that we believe will help readers who
are new to the area. We conclude with an assessment of the state-of-the-art and
suggestions for future work.
</dc:description>
 <dc:description>Comment: under review for the Information Retrieval Journal</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03307</identifier>
 <datestamp>2017-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization Models for Flexible and Adaptive SDN Network Virtualization
  Layers</dc:title>
 <dc:creator>Zerwas, Johannes</dc:creator>
 <dc:creator>Blenk, Andreas</dc:creator>
 <dc:creator>Kellerer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network hypervisors provide the network virtualization layer for Software
Defined Networking (SDN). They enable virtual network (VN) tenants to bring
their SDN controllers to program their logical networks individually according
to their demands. In order to make use of the high flexibility of virtual SDN
networks and to provide high performance, the deployment of the virtualization
layer needs to adapt to changing VN demands. This paper initializes the study
of the optimization of dynamic SDN network virtualization layers. Based on the
definition of reconfiguration events, we formalized mixed integer programs to
analyze the multi-objective problem of adapting virtualization layers. Our
initial simulation results demonstrate Pareto frontiers of conflicting
objectives, namely control plane latency and hypervisor and control path
reconfigurations.
</dc:description>
 <dc:description>Comment: Accepted as poster on ACM CoNEXT Student Workshop 2016</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03310</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic concepts for the computation of Jacobsthal's function</dc:title>
 <dc:creator>Ziller, Mario</dc:creator>
 <dc:creator>Morack, John F.</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The Jacobsthal function has aroused interest in various contexts in the past
decades. We review several algorithmic ideas for the computation of
Jacobsthal's function for primorial numbers and discuss their practicability
regarding computational effort. The respective function values were computed
for primes up to 251. In addition to the results including previously unknown
data, we provide exhaustive lists of all sequences of the appropriate maximum
lengths in ancillary files.
</dc:description>
 <dc:description>Comment: 27 pages, 2 figures, 1 table, v2: revised description, results
  unchanged</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03313</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>X-ray Scattering Image Classification Using Deep Learning</dc:title>
 <dc:creator>Wang, Boyu</dc:creator>
 <dc:creator>Yager, Kevin</dc:creator>
 <dc:creator>Yu, Dantong</dc:creator>
 <dc:creator>Hoai, Minh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual inspection of x-ray scattering images is a powerful technique for
probing the physical structure of materials at the molecular scale. In this
paper, we explore the use of deep learning to develop methods for automatically
analyzing x-ray scattering images. In particular, we apply Convolutional Neural
Networks and Convolutional Autoencoders for x-ray scattering image
classification. To acquire enough training data for deep learning, we use
simulation software to generate synthetic x-ray scattering images. Experiments
show that deep learning methods outperform previously published methods by 10\%
on synthetic and real datasets.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03318</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variables effecting photomosaic reconstruction and ortho-rectification
  from aerial survey datasets</dc:title>
 <dc:creator>Byrne, Jonathan</dc:creator>
 <dc:creator>Laefer, Debra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unmanned aerial vehicles now make it possible to obtain high quality aerial
imagery at a low cost, but processing those images into a single, useful entity
is neither simple nor seamless. Specifically, there are factors that must be
addressed when merging multiple images into a single coherent one. While
ortho-rectification can be done, it tends to be expensive and time consuming.
Image stitching offers a more economical, low-tech approach. However direct
application tends to fail for low-elevation imagery due to one or more factors
including insufficient keypoints, parallax issues, and homogeneity of the
surveyed area. This paper discusses these problems and possible solutions when
using techniques such as image stitching and structure from motion for
generating ortho-rectified imagery. These are presented in terms of actual
Irish projects including the Boland's Mills building in Dublin's city centre,
the Kilmoon Cross Farm, and the Richview buildings on the University College
Dublin campus. Implications for various Irish industries are explained in terms
of both urban and rural projects.
</dc:description>
 <dc:description>Comment: Presented at CERAI Conference 2016, Galway</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03321</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing threshold functions using dendrites</dc:title>
 <dc:creator>Caz&#xe9;, Romain</dc:creator>
 <dc:creator>Tele&#x144;czuk, Bartozs</dc:creator>
 <dc:creator>Destexhe, Alain</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Neurons, modeled as linear threshold unit (LTU), can in theory compute all
thresh- old functions. In practice, however, some of these functions require
synaptic weights of arbitrary large precision. We show here that dendrites can
alleviate this requirement. We introduce here the non-Linear Threshold Unit
(nLTU) that integrates synaptic input sub-linearly within distinct subunits to
take into account local saturation in dendrites. We systematically search
parameter space of the nTLU and TLU to compare them. Firstly, this shows that
the nLTU can compute all threshold functions with smaller precision weights
than the LTU. Secondly, we show that a nLTU can compute significantly more
functions than a LTU when an input can only make a single synapse. This work
paves the way for a new generation of network made of nLTU with binary
synapses.
</dc:description>
 <dc:description>Comment: 5 pages 3 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03322</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verification of Logical Consistency in Robotic Reasoning</dc:title>
 <dc:creator>Qu, Hongyang</dc:creator>
 <dc:creator>Veres, Sandor M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Most autonomous robotic agents use logic inference to keep themselves to safe
and permitted behaviour. Given a set of rules, it is important that the robot
is able to establish the consistency between its rules, its perception-based
beliefs, its planned actions and their consequences. This paper investigates
how a robotic agent can use model checking to examine the consistency of its
rules, beliefs and actions. A rule set is modelled by a Boolean evolution
system with synchronous semantics, which can be translated into a labelled
transition system (LTS). It is proven that stability and consistency can be
formulated as computation tree logic (CTL) and linear temporal logic (LTL)
properties. Two new algorithms are presented to perform realtime consistency
and stability checks respectively. Their implementation provides us a
computational tool, which can form the basis of efficient consistency checks
on-board robots.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03322</dc:identifier>
 <dc:identifier>Robotics and Autonomous Systems, Vol. 83(2016), 44-56</dc:identifier>
 <dc:identifier>doi:10.1016/j.robot.2016.06.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03328</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Estimation and Learning over Heterogeneous Networks</dc:title>
 <dc:creator>Rahimian, M. Amin</dc:creator>
 <dc:creator>Jadbabaie, Ali</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider several estimation and learning problems that networked agents
face when making decisions given their uncertainty about an unknown variable.
Our methods are designed to efficiently deal with heterogeneity in both size
and quality of the observed data, as well as heterogeneity over time
(intermittence). The goal of the studied aggregation schemes is to efficiently
combine the observed data that is spread over time and across several network
nodes, accounting for all the network heterogeneities. Moreover, we require no
form of coordination beyond the local neighborhood of every network agent or
sensor node. The three problems that we consider are (i) maximum likelihood
estimation of the unknown given initial data sets, (ii) learning the true model
parameter from streams of data that the agents receive intermittently over
time, and (iii) minimum variance estimation of a complete sufficient statistic
from several data points that the networked agents collect over time. In each
case we rely on an aggregation scheme to combine the observations of all
agents; moreover, when the agents receive streams of data over time, we modify
the update rules to accommodate the most recent observations. In every case, we
demonstrate the efficiency of our algorithms by proving convergence to the
globally efficient estimators given the observations of all agents. We
supplement these results by investigating the rate of convergence and providing
finite-time performance guarantees.
</dc:description>
 <dc:description>Comment: In Proceedings of the 53rd Annual Allerton Conference on
  Communication, Control, and Computing, 2016</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03336</identifier>
 <datestamp>2016-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Throughput Analysis of Random CoopMAC Networks in the Presence of
  Shadowing</dc:title>
 <dc:creator>Nikbakht, Homa</dc:creator>
 <dc:creator>Rabiei, Amir Masoud</dc:creator>
 <dc:creator>Shah-Mansouri, Vahid</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The throughput performance of a random cooperative medium access control
(CoopMAC) network in the presence of shadowing is considered. The nodes are
assumed to be randomly distributed according to a homogeneous two-dimensional
Poisson point process with constant intensity. The conditions under which a
helper can improve the transmission rate between a given pair of nodes are
examined. Based on these conditions, an exact analytical expression is derived
for the average cooperative throughput of a random CoopMAC network that is
subject to path loss and shadowing. This expression is then used to investigate
the effects of shadowing, intensity of nodes and the distance between source
and destination nodes on the cooperative throughput of the network. It is
observed that the average cooperative throughput of the network increases only
slightly when the intensity of helpers increases beyond a certain value.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to a crucial sign
  error in equation 21</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2016-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03340</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy of the Internet of Things: A Systematic Literature Review
  (Extended Discussion)</dc:title>
 <dc:creator>Aleisa, Noura</dc:creator>
 <dc:creator>Renaud, Karen</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The Internet of Things' potential for major privacy invasion is a concern.
This paper reports on a systematic literature review of privacy-preserving
solutions appearing in the research literature and in the media. We analysed
proposed solutions in terms of the techniques they deployed and the extent to
which they satisfied core privacy principles. We found that very few solutions
satisfied all core privacy principles. We also identified a number of key
knowledge gaps in the course of the analysis. In particular, we found that most
solution providers assumed that end users would be willing to expend effort to
preserve their privacy; that they would be motivated to act to preserve their
privacy. The validity of this assumption needs to be proved, since it cannot
simply be assumed that people would necessarily be willing to engage with these
solutions. We suggest this as a topic for future research.
</dc:description>
 <dc:description>Comment: Extended version of a paper to appear in HICSS 2017</dc:description>
 <dc:date>2016-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03341</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Algorithm of High-resolution Microwave Imaging Using the
  Non-parametric Generalized Reflectivity Model</dc:title>
 <dc:creator>Wang, Long Gang</dc:creator>
 <dc:creator>Li, Lianlin</dc:creator>
 <dc:creator>Cui, Tie Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an efficient algorithm of high-resolution microwave
imaging based on the concept of generalized reflectivity. The contribution made
in this paper is two-fold. We introduce the concept of non-parametric
generalized reflectivity (GR, for short) as a function of operational
frequencies and view angles, etc. The GR extends the conventional Born-based
imaging model, i.e., single-scattering model, into that accounting for more
realistic interaction between the electromagnetic wavefield and imaged scene.
Afterwards, the GR-based microwave imaging is formulated in the convex of
sparsity-regularized optimization. Typically, the sparsity-regularized
optimization requires the implementation of iterative strategy, which is
computationally expensive, especially for large-scale problems. To break this
bottleneck, we convert the imaging problem into the problem of physics-driven
image processing by introducing a dual transformation. Moreover, this image
processing is performed over overlapping patches, which can be efficiently
solved in the parallel or distributed manner. In this way, the proposed
high-resolution imaging methodology could be applicable to large-scale
microwave imaging problems. Selected simulation results are provided to
demonstrate the state-of-art performance of proposed methodology.
</dc:description>
 <dc:date>2016-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03343</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy Logic-based Implicit Authentication for Mobile Access Control</dc:title>
 <dc:creator>Yao, Feng</dc:creator>
 <dc:creator>Yerima, Suleiman Y.</dc:creator>
 <dc:creator>Kang, BooJoong</dc:creator>
 <dc:creator>Sezer, Sakir</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In order to address the increasing compromise of user privacy on mobile
devices, a Fuzzy Logic based implicit authentication scheme is proposed in this
paper. The proposed scheme computes an aggregate score based on selected
features and a threshold in real-time based on current and historic data
depicting user routine. The tuned fuzzy system is then applied to the
aggregated score and the threshold to determine the trust level of the current
user. The proposed fuzzy-integrated implicit authentication scheme is designed
to: operate adaptively and completely in the background, require minimal
training period, enable high system accuracy while provide timely detection of
abnormal activity. In this paper, we explore Fuzzy Logic based authentication
in depth. Gaussian and triangle-based membership functions are investigated and
compared using real data over several weeks from different Android phone users.
The presented results show that our proposed Fuzzy Logic approach is a highly
effective, and viable scheme for lightweight real-time implicit authentication
on mobile devices.
</dc:description>
 <dc:description>Comment: 8 pages, SAI Computing Conference (SAI),13-15 July 2016, London, UK.
  arXiv admin note: text overlap with arXiv:1607.08101</dc:description>
 <dc:date>2016-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03343</dc:identifier>
 <dc:identifier>doi:10.1109/SAI.2016.7556097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03350</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Impact of Entity Linking in Microblog Real-Time Filtering</dc:title>
 <dc:creator>Berardi, Giacomo</dc:creator>
 <dc:creator>Ceccarelli, Diego</dc:creator>
 <dc:creator>Esuli, Andrea</dc:creator>
 <dc:creator>Marcheggiani, Diego</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.4</dc:subject>
 <dc:description>  Microblogging is a model of content sharing in which the temporal locality of
posts with respect to important events, either of foreseeable or unforeseeable
nature, makes applica- tions of real-time filtering of great practical
interest. We propose the use of Entity Linking (EL) in order to improve the
retrieval effectiveness, by enriching the representation of microblog posts and
filtering queries. EL is the process of recognizing in an unstructured text the
mention of relevant entities described in a knowledge base. EL of short pieces
of text is a difficult task, but it is also a scenario in which the information
EL adds to the text can have a substantial impact on the retrieval process. We
implement a start-of-the-art filtering method, based on the best systems from
the TREC Microblog track realtime adhoc retrieval and filtering tasks , and
extend it with a Wikipedia-based EL method. Results show that the use of EL
significantly improves over non-EL based versions of the filtering methods.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, 1 table. SAC 2015, Salamanca, Spain - April 13 -
  17, 2015</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03350</dc:identifier>
 <dc:identifier>Proceedings of the 30th Annual ACM Symposium on Applied Computing
  (SAC 2015). pp 1066-1071. Salamanca, ES, 2015</dc:identifier>
 <dc:identifier>doi:10.1145/2695664.2695761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03353</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization of Generalized Unary Coding</dc:title>
 <dc:creator>Ravula, Rakshitha</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  This paper proposes an optimum version of the recently advanced scheme for
generalized unary coding. In this method, the block of 1s that identifies the
number is allowed to be broken up, which extends the count. The result is
established by a theorem. The number count is now n(n-k-1)+1 rather than the
previously described (n-k)(n-k)-1.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures</dc:description>
 <dc:date>2016-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03354</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Non-Reversing Magic Mirrors for Screen-Based Augmented Reality
  Systems</dc:title>
 <dc:creator>Bork, Felix</dc:creator>
 <dc:creator>Barmaki, Roghayeh</dc:creator>
 <dc:creator>Eck, Ulrich</dc:creator>
 <dc:creator>Fallavollita, Pascal</dc:creator>
 <dc:creator>Fuerst, Bernhard</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  Screen-based Augmented Reality (AR) systems can be built as a window into the
real world as often done in mobile AR applications or using the Magic Mirror
metaphor, where users can see themselves with augmented graphics on a large
display. Such Magic Mirror systems have been used in digital clothing
environments to create virtual dressing rooms, to teach human anatomy, and for
collaborative design tasks. The term Magic Mirror implies that the display
shows the users enantiomorph, i.e. the mirror image, such that the system
mimics a real-world physical mirror. However, the question arises whether one
should design a traditional mirror, or instead display the true mirror image by
means of a non-reversing mirror? This is an intriguing perceptual question, as
the image one observes in a mirror is not a real view, as it would be seen by
an external observer, but a reflection, i.e. a front-to-back reversed image. In
this paper, we discuss the perceptual differences between these two mirror
visualization concepts and present a first comparative study in the context of
Magic Mirror anatomy teaching. We investigate the ability of users to identify
the correct placement of virtual anatomical structures in our screen-based AR
system for two conditions: a regular mirror and a non-reversing mirror setup.
The results of our study indicate that the latter is more suitable for
applications where previously acquired domain-specific knowledge plays an
important role. The lessons learned open up new research directions in the
fields of user interfaces and interaction in non-reversing mirror environments
and could impact the implementation of general screen-based AR systems in other
domains.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03355</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing, Verification and Improvements of Timeliness in ROS processes</dc:title>
 <dc:creator>Hazim, Mohammed Y.</dc:creator>
 <dc:creator>Qu, Hongyang</dc:creator>
 <dc:creator>Veres, Sandor M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper addresses the problem of improving response times of robots
implemented in the Robotic Operating System (ROS) using formal verification of
computational-time feasibility. In order to verify the real time behaviour of a
robot under uncertain signal processing times, methods of formal verification
of timeliness properties are proposed for data flows in a ROS-based control
system using Probabilistic Timed Programs (PTPs). To calculate the probability
of success under certain time limits, and to demonstrate the strength of our
approach, a case study is implemented for a robotic agent in terms of
operational times verification using the PRISM model checker, which points to
possible enhancements to the operation of the robotic agent.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03355</dc:identifier>
 <dc:identifier>TAROS Conference, Volume 9716 of the series Lecture Notes in
  Computer Science pp 146-157, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03356</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerically robust computation of circular visibility</dc:title>
 <dc:creator>Brummer, Stephan</dc:creator>
 <dc:creator>Maier, Georg</dc:creator>
 <dc:creator>Sauer, Tomas</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We address the question of whether a point inside a domain bounded by a
simple closed arc spline is circularly visible from a specified arc from the
boundary. We provide a simple and numerically stable linear time algorithm that
solves this problem. In particular, we present an easy-to-check criterion that
implies that a point is not visible from a specified boundary arc.
</dc:description>
 <dc:description>Comment: Preprint submitted to CAGD on Nov. 08 2016, accepted Nov. 26 2017</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03358</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of spatial trees for simulation of biological tissue</dc:title>
 <dc:creator>Dmitrenok, Ilya</dc:creator>
 <dc:creator>Drobnyy, Viktor</dc:creator>
 <dc:creator>Johard, Leonard</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Spatial organization is a core challenge for all large agent-based models
with local interactions. In biological tissue models, spatial search and
reinsertion are frequently reported as the most expensive steps of the
simulation. One of the main methods utilized in order to maintain both
favorable algorithmic complexity and accuracy is spatial hierarchies. In this
paper, we seek to clarify to which extent the choice of spatial tree affects
performance, and also to identify which spatial tree families are optimal for
such scenarios. We make use of a prototype of the new BioDynaMo tissue
simulator for evaluating performances as well as for the implementation of the
characteristics of several different trees.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03363</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the Workshop on Brain Analysis using COnnectivity
  Networks - BACON 2016</dc:title>
 <dc:creator>Parisot, Sarah</dc:creator>
 <dc:creator>Passerat-Palmbach, Jonathan</dc:creator>
 <dc:creator>Schirmer, Markus D.</dc:creator>
 <dc:creator>Gutman, Boris</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Understanding brain connectivity in a network-theoretic context has shown
much promise in recent years. This type of analysis identifies brain
organisational principles, bringing a new perspective to neuroscience. At the
same time, large public databases of connectomic data are now available.
However, connectome analysis is still an emerging field and there is a crucial
need for robust computational methods to fully unravelits potential. This
workshop provides a platform to discuss the development of new analytic
techniques; methods for evaluating and validating commonly used approaches; as
well as the effects of variations in pre-processing steps.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03372</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A stochastically verifiable autonomous control architecture with
  reasoning</dc:title>
 <dc:creator>Izzo, Paolo</dc:creator>
 <dc:creator>Qu, Hongyang</dc:creator>
 <dc:creator>Veres, Sandor M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A new agent architecture called Limited Instruction Set Agent (LISA) is
introduced for autonomous control. The new architecture is based on previous
implementations of AgentSpeak and it is structurally simpler than its
predecessors with the aim of facilitating design-time and run-time verification
methods. The process of abstracting the LISA system to two different types of
discrete probabilistic models (DTMC and MDP) is investigated and illustrated.
The LISA system provides a tool for complete modelling of the agent and the
environment for probabilistic verification. The agent program can be
automatically compiled into a DTMC or a MDP model for verification with Prism.
The automatically generated Prism model can be used for both design-time and
run-time verification. The run-time verification is investigated and
illustrated in the LISA system as an internal modelling mechanism for
prediction of future outcomes.
</dc:description>
 <dc:description>Comment: Accepted at IEEE Conf. Decision and Control, 2016</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03379</identifier>
 <datestamp>2016-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temperature-Insensitive Analog Vector-by-Matrix Multiplier Based on 55
  nm NOR Flash Memory Cells</dc:title>
 <dc:creator>Guo, X.</dc:creator>
 <dc:creator>Bayat, F. Merrikh</dc:creator>
 <dc:creator>Prezioso, M.</dc:creator>
 <dc:creator>Chen, Y.</dc:creator>
 <dc:creator>Nguyen, B.</dc:creator>
 <dc:creator>Do, N.</dc:creator>
 <dc:creator>Strukov, D. B.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We have fabricated and successfully tested an analog vector-by-matrix
multiplier, based on redesigned 10x12 arrays of 55 nm commercial NOR flash
memory cells. The modified arrays enable high-precision individual analog
tuning of each cell, with sub-1% accuracy, while keeping the highly optimized
cells, with their long-term state retention, intact. The array has an area of
0.33 um^2 per cell, and is at least one order of magnitude more dense than the
reported prior implementations of nonvolatile analog memories. The demonstrated
vector-by-vector multiplier, using gate coupling to additional periphery cells,
has ~2% precision, limited by the aggregate effect of cell noise, retention,
mismatch, process variations, tuning precision, and capacitive crosstalk. A
differential version of the multiplier has allowed us to demonstrate sub-3%
temperature drift of the output signal in the range between 25C and 85C.
</dc:description>
 <dc:description>Comment: 4 pages, 11 pages</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03380</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In-Storage Embedded Accelerator for Sparse Pattern Processing</dc:title>
 <dc:creator>Jun, Sang-Woo</dc:creator>
 <dc:creator>Nguyen, Huy T.</dc:creator>
 <dc:creator>Gadepally, Vijay N.</dc:creator>
 <dc:creator>Arvind</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We present a novel architecture for sparse pattern processing, using flash
storage with embedded accelerators. Sparse pattern processing on large data
sets is the essence of applications such as document search, natural language
processing, bioinformatics, subgraph matching, machine learning, and graph
processing. One slice of our prototype accelerator is capable of handling up to
1TB of data, and experiments show that it can outperform C/C++ software
solutions on a 16-core system at a fraction of the power and cost; an optimized
version of the accelerator can match the performance of a 48-core server.
</dc:description>
 <dc:description>Comment: Accepted to IEEE HPEC 2016</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03380</dc:identifier>
 <dc:identifier>doi:10.1109/HPEC.2016.7761588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03382</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Summarization with Read-Again and Copy Mechanism</dc:title>
 <dc:creator>Zeng, Wenyuan</dc:creator>
 <dc:creator>Luo, Wenjie</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Encoder-decoder models have been widely used to solve sequence to sequence
prediction tasks. However current approaches suffer from two shortcomings.
First, the encoders compute a representation of each word taking into account
only the history of the words it has read so far, yielding suboptimal
representations. Second, current decoders utilize large vocabularies in order
to minimize the problem of unknown words, resulting in slow decoding times. In
this paper we address both shortcomings. Towards this goal, we first introduce
a simple mechanism that first reads the input sequence before committing to a
representation of each word. Furthermore, we propose a simple copy mechanism
that is able to exploit very small vocabularies and handle out-of-vocabulary
words. We demonstrate the effectiveness of our approach on the Gigaword dataset
and DUC competition outperforming the state-of-the-art.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, 5 tables</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03382</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03383</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disentangling factors of variation in deep representations using
  adversarial training</dc:title>
 <dc:creator>Mathieu, Michael</dc:creator>
 <dc:creator>Zhao, Junbo</dc:creator>
 <dc:creator>Sprechmann, Pablo</dc:creator>
 <dc:creator>Ramesh, Aditya</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a conditional generative model for learning to disentangle the
hidden factors of variation within a set of labeled observations, and separate
them into complementary codes. One code summarizes the specified factors of
variation associated with the labels. The other summarizes the remaining
unspecified variability. During training, the only available source of
supervision comes from our ability to distinguish among different observations
belonging to the same class. Examples of such observations include images of a
set of labeled objects captured at different viewpoints, or recordings of set
of speakers dictating multiple phrases. In both instances, the intra-class
diversity is the source of the unspecified factors of variation: each object is
observed at multiple viewpoints, and each speaker dictates multiple phrases.
Learning to disentangle the specified factors from the unspecified ones becomes
easier when strong supervision is possible. Suppose that during training, we
have access to pairs of images, where each pair shows two different objects
captured from the same viewpoint. This source of alignment allows us to solve
our task using existing methods. However, labels for the unspecified factors
are usually unavailable in realistic scenarios where data acquisition is not
strictly controlled. We address the problem of disentanglement in this more
general setting by combining deep convolutional autoencoders with a form of
adversarial training. Both factors of variation are implicitly captured in the
organization of the learned embedding space, and can be used for solving
single-image analogies. Experimental results on synthetic and real datasets
show that the proposed method is capable of generalizing to unseen classes and
intra-class variabilities.
</dc:description>
 <dc:description>Comment: Conference paper in NIPS 2016</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03385</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximately Sampling Elements with Fixed Rank in Graded Posets</dc:title>
 <dc:creator>Bhakta, Prateek</dc:creator>
 <dc:creator>Cousins, Ben</dc:creator>
 <dc:creator>Fahrbach, Matthew</dc:creator>
 <dc:creator>Randall, Dana</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Graded posets frequently arise throughout combinatorics, where it is natural
to try to count the number of elements of a fixed rank. These counting problems
are often $\#\textbf{P}$-complete, so we consider approximation algorithms for
counting and uniform sampling. We show that for certain classes of posets,
biased Markov chains that walk along edges of their Hasse diagrams allow us to
approximately generate samples with any fixed rank in expected polynomial time.
Our arguments do not rely on the typical proofs of log-concavity, which are
used to construct a stationary distribution with a specific mode in order to
give a lower bound on the probability of outputting an element of the desired
rank. Instead, we infer this directly from bounds on the mixing time of the
chains through a method we call $\textit{balanced bias}$.
  A noteworthy application of our method is sampling restricted classes of
integer partitions of $n$. We give the first provably efficient Markov chain
algorithm to uniformly sample integer partitions of $n$ from general restricted
classes. Several observations allow us to improve the efficiency of this chain
to require $O(n^{1/2}\log(n))$ space, and for unrestricted integer partitions,
expected $O(n^{9/4})$ time. Related applications include sampling permutations
with a fixed number of inversions and lozenge tilings on the triangular lattice
with a fixed average height.
</dc:description>
 <dc:description>Comment: 23 pages, 12 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03385</dc:identifier>
 <dc:identifier>Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on
  Discrete Algorithms (SODA 2017) 1823-1838</dc:identifier>
 <dc:identifier>doi:10.1137/1.9781611974782.119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03398</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>XCSP3: An Integrated Format for Benchmarking Combinatorial Constrained
  Problems</dc:title>
 <dc:creator>Boussemart, Frederic</dc:creator>
 <dc:creator>Lecoutre, Christophe</dc:creator>
 <dc:creator>Piette, C&#xe9;dric</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a major revision of the format XCSP 2.1, called XCSP3, to build
integrated representations of combinatorial constrained problems. This new
format is able to deal with mono/multi optimization, many types of variables,
cost functions, reification, views, annotations, variable quantification,
distributed, probabilistic and qualitative reasoning. The new format is made
compact, highly readable, and rather easy to parse. Interestingly, it captures
the structure of the problem models, through the possibilities of declaring
arrays of variables, and identifying syntactic and semantic groups of
constraints. The number of constraints is kept under control by introducing a
limited set of basic constraint forms, and producing almost automatically some
of their variations through lifting, restriction, sliding, logical combination
and relaxation mechanisms. As a result, XCSP3 encompasses practically all
constraints that can be found in major constraint solvers developed by the CP
community. A website, which is developed conjointly with the format, contains
many models and series of instances. The user can make sophisticated queries
for selecting instances from very precise criteria. The objective of XCSP3 is
to ease the effort required to test and compare different algorithms by
providing a common test-bed of combinatorial constrained instances.
</dc:description>
 <dc:description>Comment: 230 pages</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03404</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning an Astronomical Catalog of the Visible Universe through
  Scalable Bayesian Inference</dc:title>
 <dc:creator>Regier, Jeffrey</dc:creator>
 <dc:creator>Pamnany, Kiran</dc:creator>
 <dc:creator>Giordano, Ryan</dc:creator>
 <dc:creator>Thomas, Rollin</dc:creator>
 <dc:creator>Schlegel, David</dc:creator>
 <dc:creator>McAuliffe, Jon</dc:creator>
 <dc:creator>Prabhat</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>85A35 (Primary), 68W10, 62P35</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>D.2</dc:subject>
 <dc:description>  Celeste is a procedure for inferring astronomical catalogs that attains
state-of-the-art scientific results. To date, Celeste has been scaled to at
most hundreds of megabytes of astronomical images: Bayesian posterior inference
is notoriously demanding computationally. In this paper, we report on a
scalable, parallel version of Celeste, suitable for learning catalogs from
modern large-scale astronomical datasets. Our algorithmic innovations include a
fast numerical optimization routine for Bayesian posterior inference and a
statistically efficient scheme for decomposing astronomical optimization
problems into subproblems.
  Our scalable implementation is written entirely in Julia, a new high-level
dynamic programming language designed for scientific and numerical computing.
We use Julia's high-level constructs for shared and distributed memory
parallelism, and demonstrate effective load balancing and efficient scaling on
up to 8192 Xeon cores on the NERSC Cori supercomputer.
</dc:description>
 <dc:description>Comment: submitting to IPDPS'17</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03407</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating the Potential of the Inter-IXP Multigraph for the
  Provisioning of Guaranteed End-to-End Services</dc:title>
 <dc:creator>Kotronis, Vasileios</dc:creator>
 <dc:creator>Kloti, Rowan</dc:creator>
 <dc:creator>Rost, Matthias</dc:creator>
 <dc:creator>Georgopoulos, Panagiotis</dc:creator>
 <dc:creator>Ager, Bernhard</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this work, we propose utilizing the rich connectivity between IXPs and
ISPs for inter-domain path stitching, supervised by centralized QoS brokers. In
this context, we highlight a novel abstraction of the Internet topology, i.e.,
the inter-IXP multigraph composed of IXPs and paths crossing the domains of
their shared member ISPs. This can potentially serve as a dense Internet-wide
substrate for provisioning guaranteed end-to-end (e2e) services with high path
diversity and global IPv4 address space reach. We thus map the IXP multigraph,
evaluate its potential, and introduce a rich algorithmic framework for path
stitching on such graph structures.
</dc:description>
 <dc:description>Comment: Proceedings of ACM SIGMETRICS '15, pages 429-430, 1/1/2015. arXiv
  admin note: text overlap with arXiv:1611.02642</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03407</dc:identifier>
 <dc:identifier>ACM Performance Evaluation Review, Vol. 43 / Issue 1, pages
  429-430, 24/6/2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03410</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binomial Checkpointing for Arbitrary Programs with No User Annotation</dc:title>
 <dc:creator>Siskind, Jeffrey Mark</dc:creator>
 <dc:creator>Pearlmutter, Barak A.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Heretofore, automatic checkpointing at procedure-call boundaries, to reduce
the space complexity of reverse mode, has been provided by systems like
Tapenade. However, binomial checkpointing, or treeverse, has only been provided
in Automatic Differentiation (AD) systems in special cases, e.g., through
user-provided pragmas on DO loops in Tapenade, or as the nested taping
mechanism in adol-c for time integration processes, which requires that user
code be refactored. We present a framework for applying binomial checkpointing
to arbitrary code with no special annotation or refactoring required. This is
accomplished by applying binomial checkpointing directly to a program trace.
This trace is produced by a general-purpose checkpointing mechanism that is
orthogonal to AD.
</dc:description>
 <dc:description>Comment: Extended abstract presented at the AD 2016 Conference, Sep 2016,
  Oxford UK</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03416</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Implementation of a Higher-Order Language with Built-In AD</dc:title>
 <dc:creator>Siskind, Jeffrey Mark</dc:creator>
 <dc:creator>Pearlmutter, Barak A.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  We show that Automatic Differentiation (AD) operators can be provided in a
dynamic language without sacrificing numeric performance. To achieve this,
general forward and reverse AD functions are added to a simple high-level
dynamic language, and support for them is included in an aggressive optimizing
compiler. Novel technical mechanisms are discussed, which have the ability to
migrate the AD transformations from run-time to compile-time. The resulting
system, although only a research prototype, exhibits startlingly good
performance. In fact, despite the potential inefficiencies entailed by support
of a functional-programming language and a first-class AD operator, performance
is competitive with the fastest available preprocessor-based Fortran AD
systems. On benchmarks involving nested use of the AD operators, it can even
dramatically exceed their performance.
</dc:description>
 <dc:description>Comment: Extended abstract presented at the AD 2016 Conference, Sep 2016,
  Oxford UK</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03420</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Location and Position Estimation in Wireless Sensor Networks</dc:title>
 <dc:creator>Farooq-i-Azam, Muhammad</dc:creator>
 <dc:creator>Ayyaz, Muhammad Naeem</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A wireless sensor network comprises of small sensor nodes each of which
consists of a processing device, small amount of memory, battery and radio
transceiver for communication. The sensor nodes are autonomous and spatially
distributed in an area of investigation. Certain applications and protocols of
wireless sensor networks require that the sensor nodes should be aware of their
position relative to the sensor network. For it to be significant and to be of
value, the data such as temperature, humidity and pressure, gathered by sensor
nodes must be ascribed to the relative position from where it was collected.
For this to happen, the sensor nodes must be aware of their relative positions.
Traditional location finding solutions, such as Global Positioning System, are
not feasible for wireless sensor nodes due to multiple reasons. Therefore, new
methods, techniques and algorithms need to be developed to solve the problem of
location and position estimation of wireless sensor nodes. A number of
algorithms and techniques based upon different characteristics and properties
of sensor nodes have already been proposed for this purpose. This chapter
discusses the basic principles and techniques used in the localization
algorithms, categories of these algorithms and also takes a more closer look at
a few of the representative localization schemes.
</dc:description>
 <dc:date>2016-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03423</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DiffSharp: An AD Library for .NET Languages</dc:title>
 <dc:creator>Baydin, At&#x131;l&#x131;m G&#xfc;ne&#x15f;</dc:creator>
 <dc:creator>Pearlmutter, Barak A.</dc:creator>
 <dc:creator>Siskind, Jeffrey Mark</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  DiffSharp is an algorithmic differentiation or automatic differentiation (AD)
library for the .NET ecosystem, which is targeted by the C# and F# languages,
among others. The library has been designed with machine learning applications
in mind, allowing very succinct implementations of models and optimization
routines. DiffSharp is implemented in F# and exposes forward and reverse AD
operators as general nestable higher-order functions, usable by any .NET
language. It provides high-performance linear algebra primitives---scalars,
vectors, and matrices, with a generalization to tensors underway---that are
fully supported by all the AD operators, and which use a BLAS/LAPACK backend
via the highly optimized OpenBLAS library. DiffSharp currently uses operator
overloading, but we are developing a transformation-based version of the
library using F#'s &quot;code quotation&quot; metaprogramming facility. Work on a
CUDA-based GPU backend is also underway.
</dc:description>
 <dc:description>Comment: Extended abstract presented at the AD 2016 Conference, Sep 2016,
  Oxford UK</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03424</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deciding Hedged Bisimilarity</dc:title>
 <dc:creator>Mansutti, Alessio</dc:creator>
 <dc:creator>Miculan, Marino</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  The spi-calculus is a formal model for the design and analysis of
cryptographic protocols: many security properties, such as authentication and
strong confidentiality, can be reduced to the verification of behavioural
equivalences between spi processes. In this paper we provide an algorithm for
deciding hedged bisimilarity on finite processes, which is equivalent to barbed
equivalence (and coarser than framed bisimilarity). This algorithm works with
any term equivalence satisfying a simple set of conditions, thus encompassing
many different encryption schemata.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03426</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why is it Difficult to Detect Sudden and Unexpected Epidemic Outbreaks
  in Twitter?</dc:title>
 <dc:creator>Stewart, Avar&#xe9;</dc:creator>
 <dc:creator>Romano, Sara</dc:creator>
 <dc:creator>Kanhabua, Nattiya</dc:creator>
 <dc:creator>Di Martino, Sergio</dc:creator>
 <dc:creator>Siberski, Wolf</dc:creator>
 <dc:creator>Mazzeo, Antonino</dc:creator>
 <dc:creator>Nejdl, Wolfgang</dc:creator>
 <dc:creator>Diaz-Aviles, Ernesto</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Social media services such as Twitter are a valuable source of information
for decision support systems. Many studies have shown that this also holds for
the medical domain, where Twitter is considered a viable tool for public health
officials to sift through relevant information for the early detection,
management, and control of epidemic outbreaks. This is possible due to the
inherent capability of social media services to transmit information faster
than traditional channels. However, the majority of current studies have
limited their scope to the detection of common and seasonal health recurring
events (e.g., Influenza-like Illness), partially due to the noisy nature of
Twitter data, which makes outbreak detection and management very challenging.
  Within the European project M-Eco, we developed a Twitter-based Epidemic
Intelligence (EI) system, which is designed to also handle a more general class
of unexpected and aperiodic outbreaks. In particular, we faced three main
research challenges in this endeavor:
  1) dynamic classification to manage terminology evolution of Twitter
messages, 2) alert generation to produce reliable outbreak alerts analyzing the
(noisy) tweet time series, and 3) ranking and recommendation to support domain
experts for better assessment of the generated alerts.
  In this paper, we empirically evaluate our proposed approach to these
challenges using real-world outbreak datasets and a large collection of tweets.
We validate our solution with domain experts, describe our experiences, and
give a more realistic view on the benefits and issues of analyzing social media
for public health.
</dc:description>
 <dc:description>Comment: ACM CCS Concepts: Applied computing - Health informatics; Information
  systems - Web mining; Document filtering; Novelty in information retrieval;
  Recommender systems; Human-centered computing - Social media</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03427</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Task Multiple Kernel Relationship Learning</dc:title>
 <dc:creator>Murugesan, Keerthiram</dc:creator>
 <dc:creator>Carbonell, Jaime</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents a novel multitask multiple kernel learning framework that
efficiently learns the kernel weights leveraging the relationship across
multiple tasks. The idea is to automatically infer this task relationship in
the \textit{RKHS} space corresponding to the given base kernels. The problem is
formulated as a regularization-based approach called \textit{Multi-Task
Multiple Kernel Relationship Learning} (\textit{MK-MTRL}), which models the
task relationship matrix from the weights learned from latent feature spaces of
task-specific base kernels. Unlike in previous work, the proposed formulation
allows one to incorporate prior knowledge for simultaneously learning several
related tasks. We propose an alternating minimization algorithm to learn the
model parameters, kernel weights and task relationship matrix. In order to
tackle large-scale problems, we further propose a two-stage \textit{MK-MTRL}
online learning algorithm and show that it significantly reduces the
computational time, and also achieves performance comparable to that of the
joint learning framework. Experimental results on benchmark datasets show that
the proposed formulations outperform several state-of-the-art multitask
learning methods.
</dc:description>
 <dc:description>Comment: 17th SIAM International Conference on Data Mining (SDM 2017),
  Houston, Texas, USA, 2017</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03429</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolving the Incremental {\lambda} Calculus into a Model of Forward
  Automatic Differentiation (AD)</dc:title>
 <dc:creator>Kelly, Robert</dc:creator>
 <dc:creator>Pearlmutter, Barak A.</dc:creator>
 <dc:creator>Siskind, Jeffrey Mark</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Formal transformations somehow resembling the usual derivative are
surprisingly common in computer science, with two notable examples being
derivatives of regular expressions and derivatives of types. A newcomer to this
list is the incremental $\lambda$-calculus, or ILC, a &quot;theory of changes&quot; that
deploys a formal apparatus allowing the automatic generation of efficient
update functions which perform incremental computation. The ILC is not only
defined, but given a formal machine-understandable definition---accompanied by
mechanically verifiable proofs of various properties, including in particular
correctness of various sorts. Here, we show how the ILC can be mutated into
propagating tangents, thus serving as a model of Forward Accumulation Mode
Automatic Differentiation. This mutation is done in several steps. These steps
can also be applied to the proofs, resulting in machine-checked proofs of the
correctness of this model of forward AD.
</dc:description>
 <dc:description>Comment: Extended abstract presented at the AD 2016 Conference, Sep 2016,
  Oxford UK</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03451</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Importance Sampling with Unequal Support</dc:title>
 <dc:creator>Thomas, Philip S.</dc:creator>
 <dc:creator>Brunskill, Emma</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Importance sampling is often used in machine learning when training and
testing data come from different distributions. In this paper we propose a new
variant of importance sampling that can reduce the variance of importance
sampling-based estimates by orders of magnitude when the supports of the
training and testing distributions differ. After motivating and presenting our
new importance sampling estimator, we provide a detailed theoretical analysis
that characterizes both its bias and variance relative to the ordinary
importance sampling estimator (in various settings, which include cases where
ordinary importance sampling is biased, while our new estimator is not, and
vice versa). We conclude with an example of how our new importance sampling
estimator can be used to improve estimates of how well a new treatment policy
for diabetes will work for an individual, using only data from when the
individual used a previous treatment policy.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03453</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Service-Chaining Strategies using Virtual Network Functions in
  Operator Networks</dc:title>
 <dc:creator>Gupta, Abhishek</dc:creator>
 <dc:creator>Habib, M. Farhan</dc:creator>
 <dc:creator>Mandal, Uttam</dc:creator>
 <dc:creator>Chowdhury, Pulak</dc:creator>
 <dc:creator>Tornatore, Massimo</dc:creator>
 <dc:creator>Mukherjee, Biswanath</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network functions (e.g., firewalls, load balancers, etc.) have been
traditionally provided through proprietary hardware appliances. Often, hardware
appliances need to be hardwired back to back to form a service chain providing
chained network functions. Hardware appliances cannot be provisioned on demand
since they are statically embedded in the network topology, making creation,
insertion, modification, upgrade, and removal of service chains complex, and
also slowing down service innovation. Hence, network operators are starting to
deploy Virtual Network Functions (VNFs), which are virtualized over commodity
hardware. VNFs can be deployed in Data Centers (DCs) or in Network Function
Virtualization (NFV) capable network elements (nodes) such as routers and
switches. NFV capable nodes and DCs together form a Network enabled Cloud (NeC)
that helps to facilitate the dynamic service chaining required to support
evolving network traffic and its service demands. In this study, we focus on
the VNF service chain placement and traffic routing problem, and build a model
for placing a VNF service chain while minimizing network resource consumption.
Our results indicate that a NeC having a DC and NFV capable nodes can
significantly reduce network-resource consumption.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03466</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Syntactic Enhancement to VSIMM for Roadmap Based Anomalous Trajectory
  Detection: A Natural Language Processing Approach</dc:title>
 <dc:creator>Krishnamurthy, Vikram</dc:creator>
 <dc:creator>Gao, Sijia</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The aim of syntactic tracking is to classify spatio-temporal patterns of a
target's motion using natural language processing models. In this paper, we
generalize earlier work by considering a constrained stochastic context free
grammar (CSCFG) for modeling patterns confined to a roadmap. The constrained
grammar facilitates modeling specific directions and road names in a roadmap.
We present a novel particle filtering algorithm that exploits the CSCFG model
for estimating the target's patterns. This meta-level algorithm operates in
conjunction with a base-level tracking algorithm. Extensive numerical results
using simulated ground moving target indicator (GMTI) radar measurements show
substantial improvement in target tracking accuracy.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03469</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Urbanization from Satellite and Aerial Images by means of a
  statistical approach to the texture analysis</dc:title>
 <dc:creator>Sparavigna, Amelia Carolina</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Statistical methods are usually applied in the processing of digital images
for the analysis of the textures displayed by them. Aiming to evaluate the
urbanization of a given location from satellite or aerial images, here we
consider a simple processing to distinguish in them the 'urban' from the
'rural' texture. The method is based on the mean values and the standard
deviations of the colour tones of image pixels. The processing of the input
images allows to obtain some maps from which a quantitative evaluation of the
textures can be obtained.
</dc:description>
 <dc:description>Comment: Keywords: Image analysis, 2D textures; texture functions, satellite
  images, aerial images</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03473</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Query Lower Bounds for Robust Estimation of High-dimensional
  Gaussians and Gaussian Mixtures</dc:title>
 <dc:creator>Diakonikolas, Ilias</dc:creator>
 <dc:creator>Kane, Daniel M.</dc:creator>
 <dc:creator>Stewart, Alistair</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We describe a general technique that yields the first {\em Statistical Query
lower bounds} for a range of fundamental high-dimensional learning problems
involving Gaussian distributions. Our main results are for the problems of (1)
learning Gaussian mixture models (GMMs), and (2) robust (agnostic) learning of
a single unknown Gaussian distribution. For each of these problems, we show a
{\em super-polynomial gap} between the (information-theoretic) sample
complexity and the computational complexity of {\em any} Statistical Query
algorithm for the problem. Our SQ lower bound for Problem (1) is qualitatively
matched by known learning algorithms for GMMs. Our lower bound for Problem (2)
implies that the accuracy of the robust learning algorithm
in~\cite{DiakonikolasKKLMS16} is essentially best possible among all
polynomial-time SQ algorithms.
  Our SQ lower bounds are attained via a unified moment-matching technique that
is useful in other contexts and may be of broader interest. Our technique
yields nearly-tight lower bounds for a number of related unsupervised
estimation problems. Specifically, for the problems of (3) robust covariance
estimation in spectral norm, and (4) robust sparse mean estimation, we
establish a quadratic {\em statistical--computational tradeoff} for SQ
algorithms, matching known upper bounds. Finally, our technique can be used to
obtain tight sample complexity lower bounds for high-dimensional {\em testing}
problems. Specifically, for the classical problem of robustly {\em testing} an
unknown mean (known covariance) Gaussian, our technique implies an
information-theoretic sample lower bound that scales {\em linearly} in the
dimension. Our sample lower bound matches the sample complexity of the
corresponding robust {\em learning} problem and separates the sample complexity
of robust testing from standard (non-robust) testing.
</dc:description>
 <dc:description>Comment: Changes from v1: Revised presentation. Added more applications of the
  technique (SQ lower bounds for robust sparse mean estimation and robust
  covariance estimation in spectral norm). Sharpened testing lower bound to
  linear in the dimension (compared to nearly-linear in first version)</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03477</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Song From PI: A Musically Plausible Network for Pop Music Generation</dc:title>
 <dc:creator>Chu, Hang</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present a novel framework for generating pop music. Our model is a
hierarchical Recurrent Neural Network, where the layers and the structure of
the hierarchy encode our prior knowledge about how pop music is composed. In
particular, the bottom layers generate the melody, while the higher levels
produce the drums and chords. We conduct several human studies that show strong
preference of our generated music over that produced by the recent method by
Google. We additionally show two applications of our framework: neural dancing
and karaoke, as well as neural story singing.
</dc:description>
 <dc:description>Comment: under review at ICLR 2017</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03482</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconfigurable Dual Mode IEEE 802.15.4 Digital Baseband Receiver for
  Diverse IoT Applications</dc:title>
 <dc:creator>Zubair, Mohammed Abdullah</dc:creator>
 <dc:creator>Rajalakshmi, P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  IEEE 802.15.4 takes a center stage in IoT as Low- Rate Wireless Personal Area
Networks(LR-WPANs). The standard specifies Offset Quadrature Phase Shift Keying
Physical Layer (O-QPSK PHY) with half-sine pulse shaping which can be either
analyzed under the class of M-ary PSK signals (QPSK signal with offset) or as
Minimum Shift Keying (MSK) signal. M-ary PSK demodulation is requires perfect
carrier and has minimal error. MSK signals which falls under Continuous Phase
Frequency Shift Keying can be demodulated non-coherently but error performance
is not as good. In our paper, this dual nature of IEEE 802.15.4 PHY is
exploited to propose a dual mode receiver comprising of QPSK demodulator chain
and MSK demodulator chain as a single system on chip. The mode can be
configured manually depending on the type of application or based on the
feedback from a Signal to Noise (SNR) indicator employed in the proposed
receiver. M-ary PSK chain is selected for lower SNRs and MSK for higher SNRs.
Each of these properties are analyzed in detail for both demodulator chains and
we go on to prove that MSK detection can be used for low power, low complex and
low latency while QPSK detection is employed for minimal error.
</dc:description>
 <dc:date>2016-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03524</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantified CTL with imperfect information</dc:title>
 <dc:creator>Berthon, Rapha&#xeb;l</dc:creator>
 <dc:creator>Maubert, Bastien</dc:creator>
 <dc:creator>Murano, Aniello</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B44</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  Quantified CTL (QCTL) is a well-studied temporal logic that extends CTL with
quantification over atomic propositions. It has recently come to the fore as a
powerful intermediary framework to study logics for strategic reasoning. We
extend it to include imperfect information by parameterising quantifiers with
an observation that defines how well they observe the model, thus constraining
their behaviour. We consider two different semantics, one related to the notion
of no memory, the other to perfect recall. We study the expressiveness of our
logic, and show that it coincides with MSO for the first semantics and with MSO
with equal level for the second one. We establish that the model-checking
problem is Pspace-complete for the first semantics. While it is undecidable for
the second one, we identify a syntactic fragment, defined by a notion of
hierarchical formula, which we prove to be decidable thanks to an
automata-theoretic approach.
</dc:description>
 <dc:description>Comment: New version: corrected typos</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03530</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding deep learning requires rethinking generalization</dc:title>
 <dc:creator>Zhang, Chiyuan</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:creator>Hardt, Moritz</dc:creator>
 <dc:creator>Recht, Benjamin</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Despite their massive size, successful deep artificial neural networks can
exhibit a remarkably small difference between training and test performance.
Conventional wisdom attributes small generalization error either to properties
of the model family, or to the regularization techniques used during training.
  Through extensive systematic experiments, we show how these traditional
approaches fail to explain why large neural networks generalize well in
practice. Specifically, our experiments establish that state-of-the-art
convolutional networks for image classification trained with stochastic
gradient methods easily fit a random labeling of the training data. This
phenomenon is qualitatively unaffected by explicit regularization, and occurs
even if we replace the true images by completely unstructured random noise. We
corroborate these experimental findings with a theoretical construction showing
that simple depth two neural networks already have perfect finite sample
expressivity as soon as the number of parameters exceeds the number of data
points as it usually does in practice.
  We interpret our experimental findings by comparison with traditional models.
</dc:description>
 <dc:description>Comment: Published in ICLR 2017</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03533</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Landmark-based consonant voicing detection on multilingual corpora</dc:title>
 <dc:creator>Kong, Xiang</dc:creator>
 <dc:creator>Yang, Xuesong</dc:creator>
 <dc:creator>Hasegawa-Johnson, Mark</dc:creator>
 <dc:creator>Choi, Jeung-Yoon</dc:creator>
 <dc:creator>Shattuck-Hufnagel, Stefanie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper tests the hypothesis that distinctive feature classifiers anchored
at phonetic landmarks can be transferred cross-lingually without loss of
accuracy. Three consonant voicing classifiers were developed: (1) manually
selected acoustic features anchored at a phonetic landmark, (2) MFCCs (either
averaged across the segment or anchored at the landmark), and(3) acoustic
features computed using a convolutional neural network (CNN). All detectors are
trained on English data (TIMIT),and tested on English, Turkish, and Spanish
(performance measured using F1 and accuracy). Experiments demonstrate that
manual features outperform all MFCC classifiers, while CNNfeatures outperform
both. MFCC-based classifiers suffer an F1reduction of 16% absolute when
generalized from English to other languages. Manual features suffer only a 5%
F1 reduction,and CNN features actually perform better in Turkish and Span-ish
than in the training language, demonstrating that features capable of
representing long-term spectral dynamics (CNN and landmark-based features) are
able to generalize cross-lingually with little or no loss of accuracy
</dc:description>
 <dc:description>Comment: ready to submit to JASA-EL</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03533</dc:identifier>
 <dc:identifier>doi:10.1121/1.4987203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03538</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vision-aided Localization and Navigation Based on Trifocal Tensor</dc:title>
 <dc:creator>Fang, Qiang</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, a novel method for vision-aided navigation based on trifocal
tensor is presented. The main goal of the proposed method is to provide
position estimation in GPS-denied environments for vehicles equipped with a
standard inertial navigation systems(INS) and a single camera only. We treat
the trifocal tensor as the measurement model, being only concerned about the
vehicle state and do not estimate the the position of the tracked landmarks.
The performance of the proposed method is demonstrated using simulation and
experimental data.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03543</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple Data and Workflow Management with the signac Framework</dc:title>
 <dc:creator>Adorf, Carl S.</dc:creator>
 <dc:creator>Dodd, Paul M.</dc:creator>
 <dc:creator>Ramasubramani, Vyas</dc:creator>
 <dc:creator>Glotzer, Sharon C.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Researchers in the field of materials science, chemistry, and computational
physics are regularly posed with the challenge of managing large and
heterogeneous data spaces. The amount of data increases in lockstep with
computational efficiency multiplied by the amount of available computational
resources, which shifts the bottleneck in the scientific process from data
acquisition to data processing and analysis. We present a framework designed to
aid in the integration of various specialized data formats, tools and
workflows. The signac framework provides all basic components required to
create a well-defined and thus collectively accessible and searchable data
space, simplifying data access and modification through a homogeneous data
interface that is largely agnostic to the data source, i.e., computation or
experiment. The framework's data model is designed to not require absolute
commitment to the presented implementation, simplifying adaption into existing
data sets and workflows. This approach not only increases the efficiency with
which scientific results can be produced, but also significantly lowers
barriers for collaborations requiring shared data access.
</dc:description>
 <dc:description>Comment: 19 pages, 4 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03553</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Sum-Product Theorem: A Foundation for Learning Tractable Models</dc:title>
 <dc:creator>Friesen, Abram L.</dc:creator>
 <dc:creator>Domingos, Pedro</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Inference in expressive probabilistic models is generally intractable, which
makes them difficult to learn and limits their applicability. Sum-product
networks are a class of deep models where, surprisingly, inference remains
tractable even when an arbitrary number of hidden layers are present. In this
paper, we generalize this result to a much broader set of learning problems:
all those where inference consists of summing a function over a semiring. This
includes satisfiability, constraint satisfaction, optimization, integration,
and others. In any semiring, for summation to be tractable it suffices that the
factors of every product have disjoint scopes. This unifies and extends many
previous results in the literature. Enforcing this condition at learning time
thus ensures that the learned models are tractable. We illustrate the power and
generality of this approach by applying it to a new type of structured
prediction problem: learning a nonconvex function that can be globally
optimized in polynomial time. We show empirically that this greatly outperforms
the standard approach of learning without regard to the cost of optimization.
</dc:description>
 <dc:description>Comment: 15 pages (10 body, 5 pages of appendices)</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03553</dc:identifier>
 <dc:identifier>Proceedings of the 33rd International Conference on Machine
  Learning, pp. 1909-1918, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03558</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Networks Models for Entity Discovery and Linking</dc:title>
 <dc:creator>Liu, Dan</dc:creator>
 <dc:creator>Lin, Wei</dc:creator>
 <dc:creator>Zhang, Shiliang</dc:creator>
 <dc:creator>Wei, Si</dc:creator>
 <dc:creator>Jiang, Hui</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper describes the USTC_NELSLIP systems submitted to the Trilingual
Entity Detection and Linking (EDL) track in 2016 TAC Knowledge Base Population
(KBP) contests. We have built two systems for entity discovery and mention
detection (MD): one uses the conditional RNNLM and the other one uses the
attention-based encoder-decoder framework. The entity linking (EL) system
consists of two modules: a rule based candidate generation and a neural
networks probability ranking model. Moreover, some simple string matching rules
are used for NIL clustering. At the end, our best system has achieved an F1
score of 0.624 in the end-to-end typed mention ceaf plus metric.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03562</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Moving Participants Turtle Consensus</dc:title>
 <dc:creator>Nikolaou, Stavros</dc:creator>
 <dc:creator>van Renesse, Robbert</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present Moving Participants Turtle Consensus (MPTC), an asynchronous
consensus protocol for crash and Byzantine-tolerant distributed systems. MPTC
uses various moving target defense strategies to tolerate certain
Denial-of-Service (DoS) attacks issued by an adversary capable of compromising
a bounded portion of the system. MPTC supports on the fly reconfiguration of
the consensus strategy as well as of the processes executing this strategy when
solving the problem of agreement. It uses existing cryptographic techniques to
ensure that reconfiguration takes place in an unpredictable fashion thus
eliminating the adversary's advantage on predicting protocol and
execution-specific information that can be used against the protocol.
  We implement MPTC as well as a State Machine Replication protocol and
evaluate our design under different attack scenarios. Our evaluation shows that
MPTC approximates best case scenario performance even under a well-coordinated
DoS attack.
</dc:description>
 <dc:description>Comment: 31 pages, 4 figures, OPODIS</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03566</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Construction Inspection through Spatial Database</dc:title>
 <dc:creator>Hasan, Ahmad</dc:creator>
 <dc:creator>Qadir, Ashraf</dc:creator>
 <dc:creator>Nordeng, Ian</dc:creator>
 <dc:creator>Neubert, Jeremiah</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel pipeline for development of an efficient set of
tools for extracting information from the video of a structure, captured by an
Unmanned Aircraft System (UAS) to produce as-built documentation to aid
inspection of large multi-storied building during construction. Our system uses
the output from a Simultaneous Localization and Mapping system and a 3D CAD
model of the structure in order to construct a spatial database to store images
into the 3D CAD model space. This allows the user to perform a spatial query
for images through spatial indexing into the 3D CAD model space. The image
returned by the spatial query is used to extract metric information. The
spatial database is also used to generate a 3D textured model which provides a
visual as-built documentation.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figues, 3 tables, 1 graph</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03578</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple and Efficient Parallelization for Probabilistic Temporal Tensor
  Factorization</dc:title>
 <dc:creator>Li, Guangxi</dc:creator>
 <dc:creator>Xu, Zenglin</dc:creator>
 <dc:creator>Wang, Linnan</dc:creator>
 <dc:creator>Ye, Jinmian</dc:creator>
 <dc:creator>King, Irwin</dc:creator>
 <dc:creator>Lyu, Michael</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Probabilistic Temporal Tensor Factorization (PTTF) is an effective algorithm
to model the temporal tensor data. It leverages a time constraint to capture
the evolving properties of tensor data. Nowadays the exploding dataset demands
a large scale PTTF analysis, and a parallel solution is critical to accommodate
the trend. Whereas, the parallelization of PTTF still remains unexplored. In
this paper, we propose a simple yet efficient Parallel Probabilistic Temporal
Tensor Factorization, referred to as P$^2$T$^2$F, to provide a scalable PTTF
solution. P$^2$T$^2$F is fundamentally disparate from existing parallel tensor
factorizations by considering the probabilistic decomposition and the temporal
effects of tensor data. It adopts a new tensor data split strategy to subdivide
a large tensor into independent sub-tensors, the computation of which is
inherently parallel. We train P$^2$T$^2$F with an efficient algorithm of
stochastic Alternating Direction Method of Multipliers, and show that the
convergence is guaranteed. Experiments on several real-word tensor datasets
demonstrate that P$^2$T$^2$F is a highly effective and efficiently scalable
algorithm dedicated for large scale probabilistic temporal tensor analysis.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03579</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collision-based Testers are Optimal for Uniformity and Closeness</dc:title>
 <dc:creator>Diakonikolas, Ilias</dc:creator>
 <dc:creator>Gouleakis, Themis</dc:creator>
 <dc:creator>Peebles, John</dc:creator>
 <dc:creator>Price, Eric</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We study the fundamental problems of (i) uniformity testing of a discrete
distribution, and (ii) closeness testing between two discrete distributions
with bounded $\ell_2$-norm. These problems have been extensively studied in
distribution testing and sample-optimal estimators are known for
them~\cite{Paninski:08, CDVV14, VV14, DKN:15}.
  In this work, we show that the original collision-based testers proposed for
these problems ~\cite{GRdist:00, BFR+:00} are sample-optimal, up to constant
factors. Previous analyses showed sample complexity upper bounds for these
testers that are optimal as a function of the domain size $n$, but suboptimal
by polynomial factors in the error parameter $\epsilon$. Our main contribution
is a new tight analysis establishing that these collision-based testers are
information-theoretically optimal, up to constant factors, both in the
dependence on $n$ and in the dependence on $\epsilon$.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03589</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Deep Pyramid Matching for Remote Sensing Scene Classification</dc:title>
 <dc:creator>Liu, Qingshan</dc:creator>
 <dc:creator>Hang, Renlong</dc:creator>
 <dc:creator>Song, Huihui</dc:creator>
 <dc:creator>Zhu, Fuping</dc:creator>
 <dc:creator>Plaza, Javier</dc:creator>
 <dc:creator>Plaza, Antonio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) have attracted increasing attention in
the remote sensing community. Most CNNs only take the last fully-connected
layers as features for the classification of remotely sensed images, discarding
the other convolutional layer features which may also be helpful for
classification purposes. In this paper, we propose a new adaptive deep pyramid
matching (ADPM) model that takes advantage of the features from all of the
convolutional layers for remote sensing image classification. To this end, the
optimal fusing weights for different convolutional layers are learned from the
data itself. In remotely sensed scenes, the objects of interest exhibit
different scales in distinct scenes, and even a single scene may contain
objects with different sizes. To address this issue, we select the CNN with
spatial pyramid pooling (SPP-net) as the basic deep network, and further
construct a multi-scale ADPM model to learn complementary information from
multi-scale images. Our experiments have been conducted using two widely used
remote sensing image databases, and the results show that the proposed method
significantly improves the performance when compared to other state-of-the-art
methods.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03591</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Multi-Scale Deep Features for High-Resolution Satellite Image
  Classification</dc:title>
 <dc:creator>Liu, Qingshan</dc:creator>
 <dc:creator>Hang, Renlong</dc:creator>
 <dc:creator>Song, Huihui</dc:creator>
 <dc:creator>Li, Zhi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a multi-scale deep feature learning method for
high-resolution satellite image classification. Specifically, we firstly warp
the original satellite image into multiple different scales. The images in each
scale are employed to train a deep convolutional neural network (DCNN).
However, simultaneously training multiple DCNNs is time-consuming. To address
this issue, we explore DCNN with spatial pyramid pooling (SPP-net). Since
different SPP-nets have the same number of parameters, which share the
identical initial values, and only fine-tuning the parameters in
fully-connected layers ensures the effectiveness of each network, thereby
greatly accelerating the training process. Then, the multi-scale satellite
images are fed into their corresponding SPP-nets respectively to extract
multi-scale deep features. Finally, a multiple kernel learning method is
developed to automatically learn the optimal combination of such features.
Experiments on two difficult datasets show that the proposed method achieves
favorable performance compared to other state-of-the-art methods.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03592</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Teams and Decentralized Control Problems with Substitutable
  Actions</dc:title>
 <dc:creator>Asghari, Seyed Mohammad</dc:creator>
 <dc:creator>Nayyar, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers two problems -- a dynamic team problem and a
decentralized control problem. The problems we consider do not belong to the
known classes of &quot;simpler&quot; dynamic team/decentralized control problems such as
partially nested or quadratically invariant problems. However, we show that our
problems admit simple solutions under an assumption referred to as the
substitutability assumption. Intuitively, substitutability in a team (resp.
decentralized control) problem means that the effects of one team member's
(resp. controller's) action on the cost function and the information (resp.
state dynamics) can be achieved by an action of another member (resp.
controller). For the non-partially-nested LQG dynamic team problem, it is shown
that under certain conditions linear strategies are optimal. For the
non-partially-nested decentralized LQG control problem, the state structure can
be exploited to obtain optimal control strategies with recursively update-able
sufficient statistics. These results suggest that substitutability can work as
a counterpart of the information structure requirements that enable
simplification of dynamic teams and decentralized control problems.
</dc:description>
 <dc:description>Comment: 25 pages, Accepted for publication in IEEE Transactions on Automatic
  Control</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03596</identifier>
 <datestamp>2017-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Entropies and the Similarity of Texts</dc:title>
 <dc:creator>Altmann, Eduardo G.</dc:creator>
 <dc:creator>Dias, Laercio</dc:creator>
 <dc:creator>Gerlach, Martin</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We show how generalized Gibbs-Shannon entropies can provide new insights on
the statistical properties of texts. The universal distribution of word
frequencies (Zipf's law) implies that the generalized entropies, computed at
the word level, are dominated by words in a specific range of frequencies. Here
we show that this is the case not only for the generalized entropies but also
for the generalized (Jensen-Shannon) divergences, used to compute the
similarity between different texts. This finding allows us to identify the
contribution of specific words (and word frequencies) for the different
generalized entropies and also to estimate the size of the databases needed to
obtain a reliable estimation of the divergences. We test our results in large
databases of books (from the Google n-gram database) and scientific papers
(indexed by Web of Science).
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures; Results presented at the StatPhys-2016 meeting
  in Lyon</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03596</dc:identifier>
 <dc:identifier>J. Stat. Mech. 014002 (2017)</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/aa53f5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03599</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UTCNN: a Deep Learning Model of Stance Classificationon on Social Media
  Text</dc:title>
 <dc:creator>Chen, Wei-Fan</dc:creator>
 <dc:creator>Ku, Lun-Wei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Most neural network models for document classification on social media focus
on text infor-mation to the neglect of other information on these platforms. In
this paper, we classify post stance on social media channels and develop UTCNN,
a neural network model that incorporates user tastes, topic tastes, and user
comments on posts. UTCNN not only works on social media texts, but also
analyzes texts in forums and message boards. Experiments performed on Chinese
Facebook data and English online debate forum data show that UTCNN achieves a
0.755 macro-average f-score for supportive, neutral, and unsupportive stance
classes on Facebook data, which is significantly better than models in which
either user, topic, or comment information is withheld. This model design
greatly mitigates the lack of data for the minor class without the use of
oversampling. In addition, UTCNN yields a 0.842 accuracy on English online
debate forum data, which also significantly outperforms results from previous
work as well as other deep learning models, showing that UTCNN performs well
regardless of language or platform.
</dc:description>
 <dc:description>Comment: 11 pages, to appear in COLING 2016</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03607</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Recurrent Neural Network for Mobile Human Activity Recognition with
  High Throughput</dc:title>
 <dc:creator>Inoue, Masaya</dc:creator>
 <dc:creator>Inoue, Sozo</dc:creator>
 <dc:creator>Nishida, Takeshi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we propose a method of human activity recognition with high
throughput from raw accelerometer data applying a deep recurrent neural network
(DRNN), and investigate various architectures and its combination to find the
best parameter values. The &quot;high throughput&quot; refers to short time at a time of
recognition. We investigated various parameters and architectures of the DRNN
by using the training dataset of 432 trials with 6 activity classes from 7
people. The maximum recognition rate was 95.42% and 83.43% against the test
data of 108 segmented trials each of which has single activity class and 18
multiple sequential trials, respectively. Here, the maximum recognition rates
by traditional methods were 71.65% and 54.97% for each. In addition, the
efficiency of the found parameters was evaluated by using additional dataset.
Further, as for throughput of the recognition per unit time, the constructed
DRNN was requiring only 1.347 [ms], while the best traditional method required
11.031 [ms] which includes 11.027 [ms] for feature calculation. These
advantages are caused by the compact and small architecture of the constructed
real time oriented DRNN.
</dc:description>
 <dc:description>Comment: 10 pages, 13 figures</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03608</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Greedy Step Averaging: A parameter-free stochastic optimization method</dc:title>
 <dc:creator>Zhang, Xiatian</dc:creator>
 <dc:creator>Yao, Fan</dc:creator>
 <dc:creator>Tian, Yongjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we present the greedy step averaging(GSA) method, a
parameter-free stochastic optimization algorithm for a variety of machine
learning problems. As a gradient-based optimization method, GSA makes use of
the information from the minimizer of a single sample's loss function, and
takes average strategy to calculate reasonable learning rate sequence. While
most existing gradient-based algorithms introduce an increasing number of hyper
parameters or try to make a trade-off between computational cost and
convergence rate, GSA avoids the manual tuning of learning rate and brings in
no more hyper parameters or extra cost. We perform exhaustive numerical
experiments for logistic and softmax regression to compare our method with the
other state of the art ones on 16 datasets. Results show that GSA is robust on
various scenarios.
</dc:description>
 <dc:description>Comment: 23 pages, 24 figures</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03616</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Of Hags and bitches. Ageist attitudes in 2016 presidential debate on
  twitter</dc:title>
 <dc:creator>Bartlomiej, Balcerzak</dc:creator>
 <dc:creator>Radoslaw, Nielek</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this article we present our exploratory research into the occurrence of
ageist attitudes within the discussion related to the US 2016 presidential
election. We use natural processing techniques to analyze the content tweets
related to Hillary Clinton and Donald Trump. Content analysis shows that
although ageist attitudes are scarce in the discussion, they are mostly focused
on Hillary Clinton rather than Donald Trump. Also, ageist arguments against
Donald Trump appear mostly as a reply to controversies connected with the
health of Hillary Clinton.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03618</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smartphone-based Vehicle Telematics - A Ten-Year Anniversary</dc:title>
 <dc:creator>Wahlstr&#xf6;m, Johan</dc:creator>
 <dc:creator>Skog, Isaac</dc:creator>
 <dc:creator>H&#xe4;ndel, Peter</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Just like it has irrevocably reshaped social life, the fast growth of
smartphone ownership is now beginning to revolutionize the driving experience
and change how we think about automotive insurance, vehicle safety systems, and
traffic research. This paper summarizes the first ten years of research in
smartphone-based vehicle telematics, with a focus on user-friendly
implementations and the challenges that arise due to the mobility of the
smartphone. Notable academic and industrial projects are reviewed, and system
aspects related to sensors, energy consumption, cloud computing, vehicular ad
hoc networks, and human-machine interfaces are examined. Moreover, we highlight
the differences between traditional and smartphonebased automotive navigation,
and survey the state-of-the-art in smartphone-based transportation mode
classification, driver classification, and road condition monitoring. Future
advances are expected to be driven by improvements in sensor technology,
evidence of the societal benefits of current implementations, and the
establishment of industry standards for sensor fusion and driver assessment
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03624</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invertibility and Largest Eigenvalue of Symmetric Matrix Signings</dc:title>
 <dc:creator>Carlson, Charles</dc:creator>
 <dc:creator>Chandrasekaran, Karthekeyan</dc:creator>
 <dc:creator>Chang, Hsien-Chih</dc:creator>
 <dc:creator>Kolla, Alexandra</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The spectra of signed matrices have played a fundamental role in social
sciences, graph theory, and control theory. In this work, we investigate the
computational problems of identifying symmetric signings of matrices with
natural spectral properties. Our results are twofold:
  1. We show NP-completeness for the following three problems: verifying
whether a given matrix has a symmetric signing that is positive
semi-definite/singular/has bounded eigenvalues. However, we also illustrate
that the complexity could substantially differ for input matrices that are
adjacency matrices of graphs.
  2. We exhibit a stark contrast between invertibility and the above-mentioned
spectral properties: we show a combinatorial characterization of matrices with
invertible symmetric signings and design an efficient algorithm using this
characterization to verify whether a given matrix has an invertible symmetric
signing. Next, we give an efficient algorithm to solve the search problem of
finding an invertible symmetric signing for matrices whose support graph is
bipartite. We also provide a lower bound on the number of invertible symmetric
signed adjacency matrices. Finally, we give an efficient algorithm to find a
minimum increase in support of a given symmetric matrix so that it has an
invertible symmetric signing.
  We use combinatorial and spectral techniques in addition to classic results
from matching theory. Our combinatorial characterization of matrices with
invertible symmetric signings might be of independent interest.
</dc:description>
 <dc:description>Comment: 24 pages; title changed, abstract updated, paper reorganized,
  connections and motivations section revised, new results added in several
  sections</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03628</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Proving Confluence Modulo Equivalence for Constraint Handling Rules</dc:title>
 <dc:creator>Christiansen, Henning</dc:creator>
 <dc:creator>Kirkeby, Maja H.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Previous results on proving confluence for Constraint Handling Rules are
extended in two ways in order to allow a larger and more realistic class of CHR
programs to be considered confluent. Firstly, we introduce the relaxed notion
of confluence modulo equivalence into the context of CHR: while confluence for
a terminating program means that all alternative derivations for a query lead
to the exact same final state, confluence modulo equivalence only requires the
final states to be equivalent with respect to an equivalence relation tailored
for the given program. Secondly, we allow non-logical built-in predicates such
as var/1 and incomplete ones such as is/2, that are ignored in previous work on
confluence.
  To this end, a new operational semantics for CHR is developed which includes
such predicates. In addition, this semantics differs from earlier approaches by
its simplicity without loss of generality, and it may also be recommended for
future studies of CHR.
  For the purely logical subset of CHR, proofs can be expressed in first-order
logic, that we show is not sufficient in the present case. We have introduced a
formal meta-language that allows reasoning about abstract states and
derivations with meta-level restrictions that reflect the non-logical and
incomplete predicates. This language represents subproofs as diagrams, which
facilitates a systematic enumeration of proof cases, pointing forward to a
mechanical support for such proofs.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03628</dc:identifier>
 <dc:identifier>doi:10.1007/s00165-016-0396-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03631</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voxblox: Incremental 3D Euclidean Signed Distance Fields for On-Board
  MAV Planning</dc:title>
 <dc:creator>Oleynikova, Helen</dc:creator>
 <dc:creator>Taylor, Zachary</dc:creator>
 <dc:creator>Fehr, Marius</dc:creator>
 <dc:creator>Nieto, Juan</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Micro Aerial Vehicles (MAVs) that operate in unstructured, unexplored
environments require fast and flexible local planning, which can replan when
new parts of the map are explored. Trajectory optimization methods fulfill
these needs, but require obstacle distance information, which can be given by
Euclidean Signed Distance Fields (ESDFs).
  We propose a method to incrementally build ESDFs from Truncated Signed
Distance Fields (TSDFs), a common implicit surface representation used in
computer graphics and vision. TSDFs are fast to build and smooth out sensor
noise over many observations, and are designed to produce surface meshes.
Meshes allow human operators to get a better assessment of the robot's
environment, and set high-level mission goals.
  We show that we can build TSDFs faster than Octomaps, and that it is more
accurate to build ESDFs out of TSDFs than occupancy maps. Our complete system,
called voxblox, will be available as open source and runs in real-time on a
single CPU core. We validate our approach on-board an MAV, by using our system
with a trajectory optimization local planner, entirely on-board and in
real-time.
</dc:description>
 <dc:description>Comment: Submitted to IROS 2017. Videos available at
  https://www.youtube.com/watch?v=PlqT5zNsvwM and
  https://www.youtube.com/watch?v=lrGSwAPzMOQ</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03636</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial mixing of the edge-flip Markov chain for unbiased dyadic
  tilings</dc:title>
 <dc:creator>Cannon, Sarah</dc:creator>
 <dc:creator>Levin, David</dc:creator>
 <dc:creator>Stauffer, Alexandre</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We give the first polynomial upper bound on the mixing time of the edge-flip
Markov chain for unbiased dyadic tilings, resolving an open problem originally
posed by Janson, Randall, and Spencer in 2002. A dyadic tiling of size n is a
tiling of the unit square by n non-overlapping dyadic rectangles, each of area
1/n, where a dyadic rectangle is any rectangle that can be written in the form
[a2^{-s}, (a+1)2^{-s}] \times [b2^{-t}, (b+1)2^{-t}] for non-negative integers
a,b,s,t. The edge-flip Markov chain selects a random edge of the tiling and
replaces it with its perpendicular bisector if doing so yields a valid dyadic
tiling. Specifically, we show that the relaxation time of the edge-flip Markov
chain for dyadic tilings is at most O(n^{4.09}), which implies that the mixing
time is at most O(n^{5.09}). We complement this by showing that the relaxation
time is at least \Omega(n^{1.38}), improving upon the previously best lower
bound of \Omega(n\log n) coming from the diameter of the chain.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03641</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Reliability of Word Similarity Evaluation by Redesigning
  Annotation Task and Performance Measure</dc:title>
 <dc:creator>Avraham, Oded</dc:creator>
 <dc:creator>Goldberg, Yoav</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We suggest a new method for creating and using gold-standard datasets for
word similarity evaluation. Our goal is to improve the reliability of the
evaluation, and we do this by redesigning the annotation task to achieve higher
inter-rater agreement, and by defining a performance measure which takes the
reliability of each annotation decision in the dataset into account.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03652</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Show me the material evidence: Initial experiments on evaluating
  hypotheses from user-generated multimedia data</dc:title>
 <dc:creator>Gon&#xe7;alves, Bernardo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Subjective questions such as `does neymar dive', or `is clinton lying', or
`is trump a fascist', are popular queries to web search engines, as can be seen
by autocompletion suggestions on Google, Yahoo and Bing. In the era of
cognitive computing, beyond search, they could be handled as hypotheses issued
for evaluation. Our vision is to leverage on unstructured data and metadata of
the rich user-generated multimedia that is often shared as material evidence in
favor or against hypotheses in social media platforms. In this paper we present
two preliminary experiments along those lines and discuss challenges for a
cognitive computing system that collects material evidence from user-generated
multimedia towards aggregating it into some form of collective decision on the
hypothesis.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, 3 tables in Proc. of the 1st Workshop on
  Multimedia Support for Decision-Making Processes, at IEEE Intl. Symposium on
  Multimedia (ISM'16), San Jose, CA, 2016</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03655</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Belief Propagation Decoding of Polar Codes Using Scattered
  EXIT Charts</dc:title>
 <dc:creator>Elkelesh, A.</dc:creator>
 <dc:creator>Ebada, M.</dc:creator>
 <dc:creator>Cammerer, S.</dc:creator>
 <dc:creator>Brink, S. ten</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For finite length polar codes, channel polarization leaves a significant
number of channels not fully polarized. Adding a Cyclic Redundancy Check (CRC)
to better protect information on the semi-polarized channels has already been
successfully applied in the literature, and is straightforward to be used in
combination with Successive Cancellation List (SCL) decoding. Belief
Propagation (BP) decoding, however, offers more potential for exploiting
parallelism in hardware implementation, and thus, we focus our attention on
improving the BP decoder. Specifically, similar to the CRC strategy in the
SCL-case, we use a short-length &quot;auxiliary&quot; LDPC code together with the polar
code to provide a significant improvement in terms of BER. We present the novel
concept of &quot;scattered&quot; EXIT charts to design such auxiliary LDPC codes, and
achieve net coding gains (Le. for the same total rate) of 0.4 dB at BER of 1E-5
compared to the conventional BP decoder.
</dc:description>
 <dc:description>Comment: 6 pages, 2016 IEEE Information Theory Workshop (ITW)</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03656</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compatibility Properties of Synchronously and Asynchronously
  Communicating Components</dc:title>
 <dc:creator>Hennicker, Rolf</dc:creator>
 <dc:creator>Bidoit, Michel</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We study interacting components and their compatibility with respect to
synchronous and asynchronous composition. The behavior of components is
formalized by I/O-transition systems. Synchronous composition is based on
simultaneous execution of shared output and input actions of two components
while asynchronous composition uses unbounded FIFO-buffers for message
transfer. In both contexts we study compatibility notions based on the idea
that any output issued by one component should be accepted as an input by the
other. We distinguish between strong and weak versions of compatibility, the
latter allowing the execution of internal actions before a message is accepted.
We consider open systems and study conditions under which (strong/weak)
synchronous compatibility is sufficient and necessary to get (strong/weak)
asynchronous compatibility. We show that these conditions characterize
half-duplex systems. Then we focus on the verification of weak asynchronous
compatibility for possibly non half-duplex systems and provide a decidable
criterion that ensures weak asynchronous compatibility. We investigate
conditions under which this criterion is complete, i.e. if it is not satisfied
then the asynchronous system is not weakly asynchronously compatible. Finally,
we discuss deadlock-freeness and investigate relationships between
deadlock-freeness in the synchronous and in the asynchronous case.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03660</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using text mining and machine learning for detection of child abuse</dc:title>
 <dc:creator>Amrit, Chintan</dc:creator>
 <dc:creator>Paauw, Tim</dc:creator>
 <dc:creator>Aly, Robin</dc:creator>
 <dc:creator>Lavric, Miha</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.4.2</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Abuse in any form is a grave threat to a child's health. Public health
institutions in the Netherlands try to identify and prevent different kinds of
abuse, and building a decision support system can help such institutions
achieve this goal. Such decision support relies on the analysis of relevant
child health data. A significant part of the medical data that the institutions
have on children is unstructured, and in the form of free text notes. In this
research, we employ machine learning and text mining techniques to detect
patterns of possible child abuse in the data. The resulting model achieves a
high score in classifying cases of possible abuse. We then describe our
implementation of the decision support API at a municipality in the
Netherlands.
</dc:description>
 <dc:description>Comment: 31 pages, 7 figures and 12 tables</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03664</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stylized facts in social networks: Community-based static modeling</dc:title>
 <dc:creator>Jo, Hang-Hyun</dc:creator>
 <dc:creator>Murase, Yohsuke</dc:creator>
 <dc:creator>T&#xf6;r&#xf6;k, J&#xe1;nos</dc:creator>
 <dc:creator>Kert&#xe9;sz, J&#xe1;nos</dc:creator>
 <dc:creator>Kaski, Kimmo</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The past analyses of datasets of social networks have enabled us to make
empirical findings of a number of aspects of human society, which are commonly
featured as stylized facts of social networks, such as broad distributions of
network quantities, existence of communities, assortative mixing, and
intensity-topology correlations. Since the understanding of the structure of
these complex social networks is far from complete, for deeper insight into
human society more comprehensive datasets and modeling of the stylized facts
are needed. Although the existing dynamical and static models can generate some
stylized facts, here we take an alternative approach by devising a
community-based static model with heterogeneous community sizes and larger
communities having smaller link density and weight. With these few assumptions
we are able to generate realistic social networks that show most stylized facts
for a wide range of parameters, as demonstrated numerically and analytically.
Since our community-based static model is simple to implement and easily
scalable, it can be used as a reference system, benchmark, or testbed for
further applications.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures, 1 table</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03666</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oriented bounding boxes using multiresolution contours for fast
  interference detection of arbitrary geometry objects</dc:title>
 <dc:creator>Rivera, L. A.</dc:creator>
 <dc:creator>Estrela, Vania V.</dc:creator>
 <dc:creator>Carvalho, P. C. P.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Interference detection of arbitrary geometric objects is not a trivial task
due to the heavy computational load imposed by implementation issues. The
hierarchically structured bounding boxes help us to quickly isolate the contour
of segments in interference. In this paper, a new approach is introduced to
treat the interference detection problem involving the representation of
arbitrary shaped objects. Our proposed method relies upon searching for the
best possible way to represent contours by means of hierarchically structured
rectangular oriented bounding boxes. This technique handles 2D objects
boundaries defined by closed B-spline curves with roughness details. Each
oriented box is adapted and fitted to the segments of the contour using second
order statistical indicators from some elements of the segments of the object
contour in a multiresolution framework. Our method is efficient and robust when
it comes to 2D animations in real time. It can deal with smooth curves and
polygonal approximations as well results are present to illustrate the
performance of the new method.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03666</dc:identifier>
 <dc:identifier>The 12-th International Conference in Central Europe on Computer
  Graphics, Visualization and Computer Vision'2004, WSCG 2004, University of
  West Bohemia, Campus Bory, Plzen-Bory, Czech Republic, February 2-6, 2004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03671</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Well-Quasi-Ordering versus Clique-Width: New Results on Bigenic Classes</dc:title>
 <dc:creator>Dabrowski, Konrad K.</dc:creator>
 <dc:creator>Lozin, Vadim V.</dc:creator>
 <dc:creator>Paulusma, Dani&#xeb;l</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Daligault, Rao and Thomass\'e asked whether a hereditary class of graphs
well-quasi-ordered by the induced subgraph relation has bounded clique-width.
Lozin, Razgon and Zamaraev recently showed that this is not true for classes
defined by infinitely many forbidden induced subgraphs. However, in the case of
finitely many forbidden induced subgraphs the question remains open and we
conjecture that in this case the answer is positive. The conjecture is known to
hold for classes of graphs defined by a single forbidden induced subgraph $H$,
as such graphs are well-quasi-ordered and are of bounded clique-width if and
only if $H$ is an induced subgraph of $P_4$. For bigenic classes of graphs,
i.e. ones defined by two forbidden induced subgraphs, there are several open
cases in both classifications. In the present paper we obtain a number of new
results on well-quasi-orderability of bigenic classes, each of which supports
the conjecture.
</dc:description>
 <dc:description>Comment: 26 pages, 3 figures. An extended abstract of this paper appeared in
  the proceedings of IWOCA 2016</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03673</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Navigate in Complex Environments</dc:title>
 <dc:creator>Mirowski, Piotr</dc:creator>
 <dc:creator>Pascanu, Razvan</dc:creator>
 <dc:creator>Viola, Fabio</dc:creator>
 <dc:creator>Soyer, Hubert</dc:creator>
 <dc:creator>Ballard, Andrew J.</dc:creator>
 <dc:creator>Banino, Andrea</dc:creator>
 <dc:creator>Denil, Misha</dc:creator>
 <dc:creator>Goroshin, Ross</dc:creator>
 <dc:creator>Sifre, Laurent</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:creator>Kumaran, Dharshan</dc:creator>
 <dc:creator>Hadsell, Raia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Learning to navigate in complex environments with dynamic elements is an
important milestone in developing AI agents. In this work we formulate the
navigation question as a reinforcement learning problem and show that data
efficiency and task performance can be dramatically improved by relying on
additional auxiliary tasks leveraging multimodal sensory inputs. In particular
we consider jointly learning the goal-driven reinforcement learning problem
with auxiliary depth prediction and loop closure classification tasks. This
approach can learn to navigate from raw sensory input in complicated 3D mazes,
approaching human-level performance even under conditions where the goal
location changes frequently. We provide detailed analysis of the agent
behaviour, its ability to localise, and its network activity dynamics, showing
that the agent implicitly learns key navigation abilities.
</dc:description>
 <dc:description>Comment: 11 pages, 5 appendix pages, 11 figures, 3 tables, under review as a
  conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03677</identifier>
 <datestamp>2017-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Primal-Dual Optimization for Fluids</dc:title>
 <dc:creator>Inglis, Tiffany</dc:creator>
 <dc:creator>Eckert, Marie-Lena</dc:creator>
 <dc:creator>Gregson, James</dc:creator>
 <dc:creator>Thuerey, Nils</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.6.8</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  We apply a novel optimization scheme from the image processing and machine
learning areas, a fast Primal-Dual method, to achieve controllable and
realistic fluid simulations. While our method is generally applicable to many
problems in fluid simulations, we focus on the two topics of fluid guiding and
separating solid-wall boundary conditions. Each problem is posed as an
optimization problem and solved using our method, which contains acceleration
schemes tailored to each problem. In fluid guiding, we are interested in
partially guiding fluid motion to exert control while preserving fluid
characteristics. With our method, we achieve explicit control over both
large-scale motions and small-scale details which is valuable for many
applications, such as level-of-detail adjustment (after running the coarse
simulation), spatially varying guiding strength, domain modification, and
resimulation with different fluid parameters. For the separating solid-wall
boundary conditions problem, our method effectively eliminates unrealistic
artifacts of fluid crawling up solid walls and sticking to ceilings, requiring
few changes to existing implementations. We demonstrate the fast convergence of
our Primal-Dual method with a variety of test cases for both model problems.
</dc:description>
 <dc:description>Comment: 14 pages, 18 figures, supplemental video
  https://www.youtube.com/watch?v=Pgbat5MXo8Q</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03677</dc:identifier>
 <dc:identifier>doi:10.1111/cgf.13084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03679</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Convolutional Neural Network for Inverse Problems in Imaging</dc:title>
 <dc:creator>Jin, Kyong Hwan</dc:creator>
 <dc:creator>McCann, Michael T.</dc:creator>
 <dc:creator>Froustey, Emmanuel</dc:creator>
 <dc:creator>Unser, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel deep convolutional neural network
(CNN)-based algorithm for solving ill-posed inverse problems. Regularized
iterative algorithms have emerged as the standard approach to ill-posed inverse
problems in the past few decades. These methods produce excellent results, but
can be challenging to deploy in practice due to factors including the high
computational cost of the forward and adjoint operators and the difficulty of
hyper parameter selection. The starting point of our work is the observation
that unrolled iterative methods have the form of a CNN (filtering followed by
point-wise non-linearity) when the normal operator (H*H, the adjoint of H times
H) of the forward model is a convolution. Based on this observation, we propose
using direct inversion followed by a CNN to solve normal-convolutional inverse
problems. The direct inversion encapsulates the physical model of the system,
but leads to artifacts when the problem is ill-posed; the CNN combines
multiresolution decomposition and residual learning in order to learn to remove
these artifacts while preserving image structure. We demonstrate the
performance of the proposed network in sparse-view reconstruction (down to 50
views) on parallel beam X-ray computed tomography in synthetic phantoms as well
as in real experimental sinograms. The proposed network outperforms total
variation-regularized iterative reconstruction for the more realistic phantoms
and requires less than a second to reconstruct a 512 x 512 image on GPU.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03679</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2713099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03680</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DB-Nets: on The Marriage of Colored Petri Nets and Relational Databases</dc:title>
 <dc:creator>Montali, Marco</dc:creator>
 <dc:creator>Rivkin, Andrey</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The integrated management of business processes and mas- ter data is being
increasingly considered as a fundamental problem, by both the academia and the
industry. In this position paper, we focus on the foundations of the problem,
arguing that contemporary approaches struggle to find a suitable equilibrium
between data- and process-related aspects. We then propose db-nets, a new
formal model that balances such two pillars through the marriage of colored
Petri nets and relational databases. We invite the research community to build
on this model, discussing its potential in modeling, formal verification, and
simulation.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03686</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Discrete-Time Kalman Filtering within Singular Value
  Decomposition</dc:title>
 <dc:creator>Kulikova, Maria V.</dc:creator>
 <dc:creator>Tsyganova, Julia V.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The paper presents a new Kalman filter (KF) implementation useful in
applications where the accuracy of numerical solution of the associated Riccati
equation might be crucially reduced by influence of roundoff errors. Since the
appearance of the KF in 1960s, it has been recognized that the factored-form of
the KF is preferable for practical implementation. The most popular and
beneficial techniques are found in the class of square-root algorithms based on
the Cholesky decomposition of error covariance matrix. Another important matrix
factorization method is the singular value decomposition (SVD) and, hence,
further encouraging implementations might be found under this approach. The
analysis presented here exposes that the previously proposed SVD-based KF
variant is still sensitive to roundoff errors and poorly treats ill-conditioned
situations, although the SVD-based strategy is inherently more stable than the
conventional KF approach. In this paper we design a new SVD-based KF
implementation for enhancing the robustness against roundoff errors, provide
its detailed derivation, and discuss the numerical stability issues. A set of
numerical experiments are performed for comparative study. The obtained results
illustrate that the new SVD-based method is algebraically equivalent to the
conventional KF and to the previously proposed SVD-based method, but it
outperforms the mentioned techniques for estimation accuracy in ill-conditioned
situations.
</dc:description>
 <dc:description>Comment: Revised version. Following the strong recommendation of the referee,
  only one SVD-based method is left. 7 pages, 2 tables</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03686</dc:identifier>
 <dc:identifier>IET Control Theory &amp; Applications, 11(15): 2412-2418, 2017</dc:identifier>
 <dc:identifier>doi:10.1049/iet-cta.2016.1282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03699</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Analysis of Compressive Antenna Arrays for Direction of
  Arrival Estimation</dc:title>
 <dc:creator>Ibrahim, Mohamed</dc:creator>
 <dc:creator>Ramireddy, Venkatesh</dc:creator>
 <dc:creator>Lavrenko, Anastasia</dc:creator>
 <dc:creator>K&#xf6;nig, Jonas</dc:creator>
 <dc:creator>R&#xf6;mer, Florian</dc:creator>
 <dc:creator>Landmann, Markus</dc:creator>
 <dc:creator>Grossmann, Marcus</dc:creator>
 <dc:creator>Del Galdo, Giovanni</dc:creator>
 <dc:creator>Thom&#xe4;, Reiner S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we investigate the design of compressive antenna arrays for
direction of arrival (DOA) estimation that aim to provide a larger aperture
with a reduced hardware complexity by a linear combination of the antenna
outputs to a lower number of receiver channels. We present a basic receiver
architecture of such a compressive array and introduce a generic system model
that includes different options for the hardware implementation. We then
discuss the design of the analog combining network that performs the receiver
channel reduction, and propose two design approaches. The first approach is
based on the spatial correlation function which is a low-complexity scheme that
in certain cases admits a closed-form solution. The second approach is based on
minimizing the Cramer-Rao Bound (CRB) with the constraint to limit the
probability of false detection of paths to a pre-specified level. Our numerical
simulations demonstrate the superiority of the proposed optimized compressive
arrays compared to the sparse arrays of the same complexity and to compressive
arrays with randomly chosen combining kernels.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03714</identifier>
 <datestamp>2017-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Interpretations of Markov's principle</dc:title>
 <dc:creator>Manighetti, Matteo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03F03, 03F30, 03F50, 03F55</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Markov's principle is a statement that originated in the Russian school of
Constructive Mathematics and stated originally that &quot;if it is impossible that
an algorithm does not terminate, then it will terminate&quot;. This principle has
been adapted to many different contexts, and in particular we are interested in
its most common version for arithmetic, which can be stated as &quot;given a total
recursive function f , if it is impossible that there is no n for which f(n) =
0, then there exists an n such that f(n) = 0&quot;. This is in general not accepted
in constructivism, where stating an existential statement requires one to be
able to show at request a witness for the statement: here there is no clear way
to choose such an n. We introduce more in detail the context of constructive
mathematics from different points of view, and we show how they are related to
Markov's principle. In particular, several realizability semantics are
presented, which provide interpretations of logical systems by means of
different computational concepts (mainly, recursive functions and lambda
calculi). This field of research gave origin to the well known paradigm often
called Curry-Howrd isomorphism, or also propositions as types, that states a
correspondence between proofs in logic and programs in computer science. Thanks
to this the field of proof theory, that is the metamathematical investigations
of proofs as mathematical objects, became of interest for computer science and
in particular for the study of programming languages. By using modern research
on the Curry-Howard isomorphism, we will obtain a more refined interpretation
of Markov's principle. We will then use this results to investigate the logical
properties of systems related to the principle, and introduce a proof
transformation technique to interpret constructively some non-constructive
proofs of arithmetic.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2016-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03715</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the optimality of ternary arithmetic for compactness and hardware
  design</dc:title>
 <dc:creator>Georgiou, Harris V.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  In this paper, the optimality of ternary arithmetic is investigated under
strict mathematical formulation. The arithmetic systems are presented in
generic form, as the means to encode numeric values, and the choice of radix is
asserted as the main parameter to assess the efficiency of the representation,
in terms of information compactness and estimated implementation cost in
hardware. Using proper formulations for the optimization task, the universal
constant 'e' (base of natural logarithms) is proven as the most efficient radix
and ternary is asserted as the closest integer choice.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures</dc:description>
 <dc:date>2016-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03718</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Object Detection with Deep Reinforcement Learning</dc:title>
 <dc:creator>Bellver, Miriam</dc:creator>
 <dc:creator>Giro-i-Nieto, Xavier</dc:creator>
 <dc:creator>Marques, Ferran</dc:creator>
 <dc:creator>Torres, Jordi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a method for performing hierarchical object detection in images
guided by a deep reinforcement learning agent. The key idea is to focus on
those parts of the image that contain richer information and zoom on them. We
train an intelligent agent that, given an image window, is capable of deciding
where to focus the attention among five different predefined region candidates
(smaller windows). This procedure is iterated providing a hierarchical image
analysis.We compare two different candidate proposal strategies to guide the
object search: with and without overlap. Moreover, our work compares two
different strategies to extract features from a convolutional neural network
for each region proposal: a first one that computes new feature maps for each
region proposal, and a second one that computes the feature maps for the whole
image to later generate crops for each region proposal. Experiments indicate
better results for the overlapping candidate proposal strategy and a loss of
performance for the cropped image features due to the loss of spatial
resolution. We argue that, while this loss seems unavoidable when working with
large amounts of object candidates, the much more reduced amount of region
proposals generated by our reinforcement learning agent allows considering to
extract features for each location without sharing convolutional computation
among regions.
</dc:description>
 <dc:description>Comment: Deep Reinforcement Learning Workshop (NIPS 2016). Project page at
  https://imatge-upc.github.io/detection-2016-nipsws/</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03721</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-Temporal Waveform Design for Multi-user Massive MIMO Downlink
  with 1-bit Receivers</dc:title>
 <dc:creator>Gokceoglu, Ahmet</dc:creator>
 <dc:creator>Bjornson, Emil</dc:creator>
 <dc:creator>Larsson, Erik</dc:creator>
 <dc:creator>Valkama, Mikko</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Internet-of-Things (IoT) refers to a high-density network of low-cost
low-bitrate terminals and sensors where also low energy consumption is one
central feature. As the power-budget of classical receiver chains is dominated
by the high-resolution analog-to-digital converters (ADCs), there is a growing
interest towards deploying receiver architectures with reduced-bit or even
1-bit ADCs. In this paper, we study waveform design, optimization and detection
aspects of multi-user massive MIMO downlink where user terminals adopt very
simple 1-bit ADCs with oversampling. In order to achieve spectral efficiency
higher than 1 bit/s/Hz per real-dimension, we propose a two-stage precoding,
namely a novel quantization precoder followed by maximum-ratio transmission
(MRT) or zero-forcing (ZF) type spatial channel precoder which jointly form the
multi-user-multiantenna transmit waveform. The quantization precoder outputs
are optimized, under appropriate transmitter and receiver filter bandwidth
constraints, to provide controlled inter-symbol-interference (ISI) enabling the
input symbols to be uniquely detected from 1-bit quantized observations with a
low-complexity symbol detector in the absence of noise. An additional
optimization constraint is also imposed in the quantization precoder design to
increase the robustness against noise and residual inter-user-interference
(IUI). The purpose of the spatial channel precoder, in turn, is to suppress the
IUI and provide high beamforming gains such that good symbol-error rates (SERs)
can be achieved in the presence of noise and interference. Extensive numerical
evaluations illustrate that the proposed spatio-temporal precoder based
multiantenna waveform design can facilitate good multi-user link performance,
despite the extremely simple 1-bit ADCs in the receivers, hence being one
possible enabling technology for the future low-complexity IoT networks.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03721</dc:identifier>
 <dc:identifier>doi:10.1109/JSTSP.2016.2628347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03725</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Interpolation for Spectrum Cartography through Local Path Loss
  Modeling</dc:title>
 <dc:creator>Sagari, Shweta</dc:creator>
 <dc:creator>Greenstein, Larry</dc:creator>
 <dc:creator>Trappe, Wade</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  A fundamental building block for supporting better utilization of radio
spectrum involves predicting the impact that an emitter will have at different
geographic locations. To this end, fixed sensors can be deployed to spatially
sample the RF environment over an area of interest, with interpolation methods
used to infer received power at locations between sensors. This paper describes
a radio map interpolation method that exploits the known properties of most
path loss models, with the aim of minimizing the RMS errors in predicted
dB-power. We show that the results come very close to those for ideal Simple
Kriging. Moreover, the method is simpler in terms of real-time computation by
the network and it requires no knowledge of the spatial correlation of shadow
fading. Our analysis of the method is general, but we exemplify it for a
specific network geometry, comprising a grid-like pattern of sensors. We also
provide comparisons to other widely used interpolation methods.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03736</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formal Definition for Configuration</dc:title>
 <dc:creator>Yanguas, Mar&#xed;a Carmen Calvo</dc:creator>
 <dc:creator>Don&#xe1;zar, Carmen Elvira</dc:creator>
 <dc:creator>Lado, Raquel Trillo</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:description>  There exists a wide set of techniques to perform keyword-based search over
relational databases but all of them match the keywords in the users' queries
to elements of the databases to be queried as first step. The matching process
is a time-consuming and complex task. So, improving the performance of this
task is a key issue to improve the keyword based search on relational data
sources.In this work, we show how to model the matching process on
keyword-based search on relational databases by means of the symmetric group.
Besides, how this approach reduces the search space is explained in detail.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03739</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diminishable Parameterized Problems and Strict Polynomial Kernelization</dc:title>
 <dc:creator>Fernau, Henning</dc:creator>
 <dc:creator>Fluschnik, Till</dc:creator>
 <dc:creator>Hermelin, Danny</dc:creator>
 <dc:creator>Krebs, Andreas</dc:creator>
 <dc:creator>Molter, Hendrik</dc:creator>
 <dc:creator>Niedermeier, Rolf</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Kernelization---a mathematical key concept for provably effective
polynomial-time preprocessing of NP-hard problems---plays a central role in
parameterized complexity and has triggered an extensive line of research. This
is in part due to a lower bounds framework that allows to exclude
polynomial-size kernels under the assumption of NP $\nsubseteq$ coNP$/$poly. In
this paper we consider a restricted yet natural variant of kernelization,
namely strict kernelization, where one is not allowed to increase the parameter
of the reduced instance (the kernel) by more than an additive constant.
  Building on earlier work of Chen, Flum, and M\&quot;{u}ller [Theory Comput. Syst.
2011] and developing a general and remarkably simple framework, we show that a
variety of FPT problems does not admit strict polynomial kernels under the
weaker assumption of P $\neq$ NP. In particular, we show that various
(multicolored) graph problems and Turing machine computation problems do not
admit strict polynomial kernels unless P $=$ NP. To this end, a key concept we
use are diminishable problems; these are parameterized problems that allow to
decrease the parameter of the input instance by at least one in polynomial
time, thereby outputting an equivalent problem instance. Finally, we study a
relaxation of the notion of strict kernels and reveal its limitations.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03745</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Spanning Forest with Worst-Case Update Time: Adaptive, Las
  Vegas, and $O(n^{1/2-\epsilon})$-Time</dc:title>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:creator>Saranurak, Thatchaphol</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present two algorithms for dynamically maintaining a spanning forest of a
graph undergoing edge insertions and deletions. Our algorithms guarantee {\em
worst-case update time} and work against an adaptive adversary, meaning that an
edge update can depend on previous outputs of the algorithms. We provide the
first polynomial improvement over the long-standing $O(\sqrt{n})$ bound of
[Frederickson STOC'83, Eppstein, Galil, Italiano and Nissenzweig FOCS'92] for
such type of algorithms. The previously best improvement was $O(\sqrt{n
(\log\log n)^2/\log n})$ [Kejlberg-Rasmussen, Kopelowitz, Pettie and Thorup
ESA'16]. We note however that these bounds were obtained by deterministic
algorithms while our algorithms are randomized.
  Our first algorithm is Monte Carlo and guarantees an $O(n^{0.4+o(1)})$
worst-case update time, where the $o(1)$ term hides the $O(\sqrt{\log\log
n/\log n})$ factor. Our second algorithm is Las Vegas and guarantees an
$O(n^{0.49306})$ worst-case update time with high probability. Algorithms with
better update time either needed to assume that the adversary is oblivious
(e.g. [Kapron, King and Mountjoy SODA'13]) or can only guarantee an amortized
update time. Our second result answers an open problem by Kapron et al. To the
best of our knowledge, our algorithms are among a few non-trivial randomized
dynamic algorithms that work against adaptive adversaries.
</dc:description>
 <dc:description>Comment: Submitted to STOC'17. Announced partially at China Theory Week 2016
  (http://www.itcsc.cuhk.edu.hk/Workshops/CTW16_Workshop/chinatheoryweek.html).
  An independent result on the dynamic MST problem can be found at
  arXiv:1611.02864</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03748</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Systematic Classification of Side-Channel Attacks: A Case Study for
  Mobile Devices</dc:title>
 <dc:creator>Spreitzer, Raphael</dc:creator>
 <dc:creator>Moonsamy, Veelasha</dc:creator>
 <dc:creator>Korak, Thomas</dc:creator>
 <dc:creator>Mangard, Stefan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Side-channel attacks on mobile devices have gained increasing attention since
their introduction in 2007. While traditional side-channel attacks, such as
power analysis attacks and electromagnetic analysis attacks, required physical
presence of the attacker as well as expensive equipment, an (unprivileged)
application is all it takes to exploit the leaking information on modern mobile
devices. Given the vast amount of sensitive information that are stored on
smartphones, the ramifications of side-channel attacks affect both the security
and privacy of users and their devices.
  In this paper, we propose a new categorization system for side-channel
attacks, which is necessary as side-channel attacks have evolved significantly
since their scientific investigations during the smart card era in the 1990s.
Our proposed classification system allows to analyze side-channel attacks
systematically, and facilitates the development of novel countermeasures.
Besides this new categorization system, the extensive survey of existing
attacks and attack strategies provides valuable insights into the evolving
field of side-channel attacks, especially when focusing on mobile devices. We
conclude by discussing open issues and challenges in this context and outline
possible future research directions.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03748</dc:identifier>
 <dc:identifier>doi:10.1109/COMST.2017.2779824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03749</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MCMC Shape Sampling for Image Segmentation with Nonparametric Shape
  Priors</dc:title>
 <dc:creator>Erdil, Ertunc</dc:creator>
 <dc:creator>Y&#x131;ld&#x131;r&#x131;m, Sinan</dc:creator>
 <dc:creator>&#xc7;etin, M&#xfc;jdat</dc:creator>
 <dc:creator>Ta&#x15f;dizen, Tolga</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmenting images of low quality or with missing data is a challenging
problem. Integrating statistical prior information about the shapes to be
segmented can improve the segmentation results significantly. Most shape-based
segmentation algorithms optimize an energy functional and find a point estimate
for the object to be segmented. This does not provide a measure of the degree
of confidence in that result, neither does it provide a picture of other
probable solutions based on the data and the priors. With a statistical view,
addressing these issues would involve the problem of characterizing the
posterior densities of the shapes of the objects to be segmented. For such
characterization, we propose a Markov chain Monte Carlo (MCMC) sampling-based
image segmentation algorithm that uses statistical shape priors. In addition to
better characterization of the statistical structure of the problem, such an
approach would also have the potential to address issues with getting stuck at
local optima, suffered by existing shape-based segmentation methods. Our
approach is able to characterize the posterior probability density in the space
of shapes through its samples, and to return multiple solutions, potentially
from different modes of a multimodal probability density, which would be
encountered, e.g., in segmenting objects from multiple shape classes. We
present promising results on a variety of data sets. We also provide an
extension for segmenting shapes of objects with parts that can go through
independent shape variations. This extension involves the use of local shape
priors on object parts and provides robustness to limitations in shape training
data size.
</dc:description>
 <dc:description>Comment: Computer Vision and Pattern Recognition conference, 2016</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03751</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top-k String Auto-Completion with Synonyms</dc:title>
 <dc:creator>Xu, Pengfei</dc:creator>
 <dc:creator>Lu, Jiaheng</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Auto-completion is one of the most prominent features of modern information
systems. The existing solutions of auto-completion provide the suggestions
based on the beginning of the currently input character sequence (i.e. prefix).
However, in many real applications, one entity often has synonyms or
abbreviations. For example, &quot;DBMS&quot; is an abbreviation of &quot;Database Management
Systems&quot;. In this paper, we study a novel type of auto-completion by using
synonyms and abbreviations. We propose three trie-based algorithms to solve the
top-k auto-completion with synonyms; each one with different space and time
complexity trade-offs. Experiments on large-scale datasets show that it is
possible to support effective and efficient synonym-based retrieval of
completions of a million strings with thousands of synonyms rules at about a
microsecond per-completion, while taking small space overhead (i.e. 160-200
bytes per string). The source code of our experiments can be download at:
http://udbms.cs.helsinki.fi/?projects/autocompletion/download .
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03765</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emulating Batteries with Deferrable Energy Demand: Fundamental
  Trade-offs and Scheduling Policies</dc:title>
 <dc:creator>Madjidian, Daria</dc:creator>
 <dc:creator>Roozbehani, Mardavij</dc:creator>
 <dc:creator>Dahleh, Munther A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  We investigate the ability of a homogeneous collection of deferrable energy
loads to behave as a battery; that is, to absorb and release energy in a
controllable fashion up to fixed and predetermined limits on volume, charge
rate and discharge rate. We derive explicit bounds on the battery capacity that
can be offered, and show that there is a fundamental trade-off between the
abilities of collective load to absorb and release energy at high aggregate
rates. Finally, we introduce a new class of dynamic priority-driven feedback
policies that balance these abilities, and characterize the batteries that they
can emulate.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1610.01973</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03777</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tricks from Deep Learning</dc:title>
 <dc:creator>Baydin, At&#x131;l&#x131;m G&#xfc;ne&#x15f;</dc:creator>
 <dc:creator>Pearlmutter, Barak A.</dc:creator>
 <dc:creator>Siskind, Jeffrey Mark</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The deep learning community has devised a diverse set of methods to make
gradient optimization, using large datasets, of large and highly complex models
with deeply cascaded nonlinearities, practical. Taken as a whole, these methods
constitute a breakthrough, allowing computational structures which are quite
wide, very deep, and with an enormous number and variety of free parameters to
be effectively optimized. The result now dominates much of practical machine
learning, with applications in machine translation, computer vision, and speech
recognition. Many of these methods, viewed through the lens of algorithmic
differentiation (AD), can be seen as either addressing issues with the gradient
itself, or finding ways of achieving increased efficiency using tricks that are
AD-related, but not provided by current AD systems.
  The goal of this paper is to explain not just those methods of most relevance
to AD, but also the technical constraints and mindset which led to their
discovery. After explaining this context, we present a &quot;laundry list&quot; of
methods developed by the deep learning community. Two of these are discussed in
further mathematical detail: a way to dramatically reduce the size of the tape
when performing reverse-mode AD on a (theoretically) time-reversible process
like an ODE integrator; and a new mathematical insight that allows for the
implementation of a stochastic Newton's method.
</dc:description>
 <dc:description>Comment: Extended abstract presented at the AD 2016 Conference, Sep 2016,
  Oxford UK</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03780</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GeoCUTS: Geographic Clustering Using Travel Statistics</dc:title>
 <dc:creator>Rolnick, David</dc:creator>
 <dc:creator>Aydin, Kevin</dc:creator>
 <dc:creator>Kamali, Shahab</dc:creator>
 <dc:creator>Mirrokni, Vahab</dc:creator>
 <dc:creator>Najmi, Amir</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Web-based services often run experiments to improve their products. To carry
out an effective experiment and evaluate the results appropriately, there must
be a control group and at least one treatment group. Ideally all of these
groups are disjoint, so that each user is given a specific treatment. Using
geographical locations as units of experimentation is desirable because this
does not require tracking individual users or browser cookies. With the
popularity of mobile devices, a user may issue queries from multiple
geographical locations. Hence, to be used as units of experimentation,
geographical partitions should be chosen in a way that reduces transit between
regions.
  The strategy of clustering users by region is common in advertising.
Designated marketing areas (DMAs) are specifically designed for this purpose.
However, DMAs are restricted to the US and their granularity is inflexible
(there are around two hundred in total). Moreover, they are built based on
population density - one DMA per metropolitan area - rather than mobile
movement patterns.
  In this paper, we present GeoCUTS, an algorithm that forms geographical
clusters to minimize movement between clusters while preserving rough balance
in cluster size. We use a random sample of anonymized mobile user traffic to
form a graph representing user movements, then construct a geographically
coherent clustering of the graph. We propose a statistical framework to measure
the effectiveness of clusterings and perform empirical evaluations showing that
the performance of GeoCUTS is comparable to hand-crafted DMAs with respect to
both novel and existing metrics. GeoCUTS offers a general and flexible
framework for conducting geo-based experiments in any part of the world.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03786</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation the Impact of Library and Information Science Master's Degree
  (MLIS) on Graduates in Iran</dc:title>
 <dc:creator>Asemi, Asefeh</dc:creator>
 <dc:creator>Aghajan, Elham</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The study aimed to examine the effect of MLIS degree on graduates in Iran
from different dimensions. The study examined the effects of MLIS on scientific
progress, the development of subject expertise, employment, individual
characteristics, skills and capabilities, and scientific activities of Iran's
graduates. The study was a descriptive-survey and researcher-made questionnaire
is used for data collection. The overall effect average of degree of MLIS on
Iranian graduates was equal to 3/25. The findings showed that the average
effect of MLIS degree associated with each studied factors on the graduates in
the country were: Scientific progress (3/13), development of subject expertise
(3/27), employment (3/27), individual characteristics (2/75), skills and
capabilities (3/48), scientific activities (3/57(. Discussion: Based on the
results, the effect of MLIS degree on Iranian graduates was more than moderate.
Generally, it can be concluded that MLIS courses at universities in the
country, can increase the value of a master's degree of graduates at an
acceptable level, but is not perfect; it seems that the authorities should
increase their efforts to promote the value of a master's degree in graduates.
</dc:description>
 <dc:date>2016-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03789</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Distance Queries and Cycle Counting by Frobenius Normal Form</dc:title>
 <dc:creator>Sankowski, Piotr</dc:creator>
 <dc:creator>W&#x119;grzycki, Karol</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Consider an unweighted, directed graph $G$ with the diameter $D$. In this
paper, we introduce the framework for counting cycles and walks of given length
in matrix multiplication time $\widetilde{O}(n^\omega)$. The framework is based
on the fast decomposition into Frobenius normal form and the Hankel
matrix-vector multiplication. It allows us to solve the following problems
efficiently:
  - All Nodes Shortest Cycles -- for every node return the length of the
shortest cycle containing it. We give an $\widetilde{O}(n^\omega)$ algorithm
that improves Yuster [30] $\widetilde{O}(n^{(\omega + 3)/2})$ algorithm for
unweighted digraphs.
  - We show how to compute all $D$ sets of vertices lying on cycles of length
$c\in \{1,\ldots,D\}$ in time $\widetilde{O}(n^\omega)$ randomized time. It
improves upon Cygan et al. [9] where algorithm that computes a single set is
presented.
  - We present a functional improvement of distance queries [32] for directed,
unweighted graphs.
  - All Pairs All Walks. We show almost optimal $\widetilde{O}(n^3)$ time
algorithm for all walks counting problem. We improve upon the naive $O(D
n^{\omega})$ time algorithm.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, STACS 2017</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03789</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.STACS.2017.56</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03796</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Length Polar Codes through Graph Based Augmentation</dc:title>
 <dc:creator>Elkelesh, A.</dc:creator>
 <dc:creator>Ebada, M.</dc:creator>
 <dc:creator>Cammerer, S.</dc:creator>
 <dc:creator>Brink, S. ten</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The structure of polar codes inherently requires block lengths to be powers
of two. In this paper, we investigate how different block lengths can be
realized by coupling of several short-length polar codes. For this, we first
analyze &quot;code augmentation&quot; to better protect the semipolarized channels,
improving the BER performance under belief propagation decoding. Several serial
and parallel augmentation schemes are discussed. A coding gain of $0.3$ dB at a
BER of $10^{-5}$ can be observed for the same total rate and length. Further,
we extend this approach towards coupling of several &quot;sub-polar codes&quot;, leading
to a reduced computational complexity and enabling the construction of flexible
length polar codes.
</dc:description>
 <dc:description>Comment: 11th International ITG Conference on Systems, Communications and
  Coding (SCC) 2017, Hamburg, Germany</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03799</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Chatbots to the Internet of Things: Opportunities and
  Architectural Elements</dc:title>
 <dc:creator>Kar, Rohan</dc:creator>
 <dc:creator>Haldar, Rishin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Internet of Things (IoT) is emerging as a significant technology in shaping
the future by connecting physical devices or things with internet. It also
presents various opportunities for intersection of other technological trends
which can allow it to become even more intelligent and efficient. In this paper
we focus our attention on the integration of Intelligent Conversational
Software Agents or Chatbots with IoT. Literature surveys have looked into
various applications, features, underlying technologies and known challenges of
IoT. On the other hand, Chatbots are being adopted in greater numbers due to
major strides in development of platforms and frameworks. The novelty of this
paper lies in the specific integration of Chatbots in the IoT scenario. We
analyzed the shortcomings of existing IoT systems and put forward ways to
tackle them by incorporating chatbots. A general architecture is proposed for
implementing such a system, as well as platforms and frameworks, both
commercial and open source, which allow for implementation of such systems.
Identification of the newer challenges and possible future directions with this
new integration, have also been addressed.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures, 5 Use Cases</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03799</dc:identifier>
 <dc:identifier>doi:10.14569/IJACSA.2016.071119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03811</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HoneyFaces: Increasing the Security and Privacy of Authentication Using
  Synthetic Facial Images</dc:title>
 <dc:creator>Ohana, Mor</dc:creator>
 <dc:creator>Dunkelman, Orr</dc:creator>
 <dc:creator>Gibson, Stuart</dc:creator>
 <dc:creator>Osadchy, Margarita</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One of the main challenges faced by Biometric-based authentication systems is
the need to offer secure authentication while maintaining the privacy of the
biometric data. Previous solutions, such as Secure Sketch and Fuzzy Extractors,
rely on assumptions that cannot be guaranteed in practice, and often affect the
authentication accuracy.
  In this paper, we introduce HoneyFaces: the concept of adding a large set of
synthetic faces (indistinguishable from real) into the biometric &quot;password
file&quot;. This password inflation protects the privacy of users and increases the
security of the system without affecting the accuracy of the authentication. In
particular, privacy for the real users is provided by &quot;hiding&quot; them among a
large number of fake users (as the distributions of synthetic and real faces
are equal). In addition to maintaining the authentication accuracy, and thus
not affecting the security of the authentication process, HoneyFaces offer
several security improvements: increased exfiltration hardness, improved
leakage detection, and the ability to use a Two-server setting like in
HoneyWords. Finally, HoneyFaces can be combined with other security and privacy
mechanisms for biometric data.
  We implemented the HoneyFaces system and tested it with a password file
composed of 270 real users. The &quot;password file&quot; was then inflated to
accommodate up to $2^{36.5}$ users (resulting in a 56.6 TB &quot;password file&quot;). At
the same time, the inclusion of additional faces does not affect the true
acceptance rate or false acceptance rate which were 93.33\% and 0.01\%,
respectively.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03814</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Science of Security and Privacy in Machine Learning</dc:title>
 <dc:creator>Papernot, Nicolas</dc:creator>
 <dc:creator>McDaniel, Patrick</dc:creator>
 <dc:creator>Sinha, Arunesh</dc:creator>
 <dc:creator>Wellman, Michael</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Advances in machine learning (ML) in recent years have enabled a dizzying
array of applications such as data analytics, autonomous systems, and security
diagnostics. ML is now pervasive---new systems and models are being deployed in
every domain imaginable, leading to rapid and widespread deployment of software
based inference and decision making. There is growing recognition that ML
exposes new vulnerabilities in software systems, yet the technical community's
understanding of the nature and extent of these vulnerabilities remains
limited. We systematize recent findings on ML security and privacy, focusing on
attacks identified on these systems and defenses crafted to date. We articulate
a comprehensive threat model for ML, and categorize attacks and defenses within
an adversarial framework. Key insights resulting from works both in the ML and
security communities are identified and the effectiveness of approaches are
related to structural elements of ML algorithms and the data used to train
them. We conclude by formally exploring the opposing relationship between model
accuracy and resilience to adversarial manipulation. Through these
explorations, we show that there are (possibly unavoidable) tensions between
model complexity, accuracy, and resilience that must be calibrated for the
environments in which they will be used.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03819</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recovery Guarantee of Non-negative Matrix Factorization via Alternating
  Updates</dc:title>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:creator>Liang, Yingyu</dc:creator>
 <dc:creator>Risteski, Andrej</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Non-negative matrix factorization is a popular tool for decomposing data into
feature and weight matrices under non-negativity constraints. It enjoys
practical success but is poorly understood theoretically. This paper proposes
an algorithm that alternates between decoding the weights and updating the
features, and shows that assuming a generative model of the data, it provably
recovers the ground-truth under fairly mild conditions. In particular, its only
essential requirement on features is linear independence. Furthermore, the
algorithm uses ReLU to exploit the non-negativity for decoding the weights, and
thus can tolerate adversarial noise that can potentially be as large as the
signal, and can tolerate unbiased noise much larger than the signal. The
analysis relies on a carefully designed coupling between two potential
functions, which we believe is of independent interest.
</dc:description>
 <dc:description>Comment: To appear in NIPS 2016. 8 pages of extended abstract; 48 pages in
  total</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03824</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Learn without Gradient Descent by Gradient Descent</dc:title>
 <dc:creator>Chen, Yutian</dc:creator>
 <dc:creator>Hoffman, Matthew W.</dc:creator>
 <dc:creator>Colmenarejo, Sergio Gomez</dc:creator>
 <dc:creator>Denil, Misha</dc:creator>
 <dc:creator>Lillicrap, Timothy P.</dc:creator>
 <dc:creator>Botvinick, Matt</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We learn recurrent neural network optimizers trained on simple synthetic
functions by gradient descent. We show that these learned optimizers exhibit a
remarkable degree of transfer in that they can be used to efficiently optimize
a broad range of derivative-free black-box functions, including Gaussian
process bandits, simple control objectives, global optimization benchmarks and
hyper-parameter tuning tasks. Up to the training horizon, the learned
optimizers learn to trade-off exploration and exploitation, and compare
favourably with heavily engineered Bayesian optimization packages for
hyper-parameter tuning.
</dc:description>
 <dc:description>Comment: Accepted by ICML 2017. Previous version &quot;Learning to Learn for Global
  Optimization of Black Box Functions&quot; was published in the Deep Reinforcement
  Learning Workshop, NIPS 2016</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03841</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing Security-Aware Incentives for Computation Offloading via
  Device-to-Device Communication</dc:title>
 <dc:creator>Xu, Jie</dc:creator>
 <dc:creator>Chen, Lixing</dc:creator>
 <dc:creator>Liu, Kun</dc:creator>
 <dc:creator>Shen, Cong</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Computation offloading via device-to-device (D2D) communication, or D2D
offloading, has recently been proposed to enhance mobile computing performance
by exploiting spare computing resources of nearby user devices. The success of
D2D offloading relies on user participation in collaborative service
provisioning, which incurs extra costs to users providing the service, thus
mandating an incentive mechanism that can compensate for these costs. Although
incentive mechanism design has been intensively studied in the literature, this
paper considers a much more challenging yet less investigated problem in which
selfish users are also facing interdependent security risks, such as infectious
proximity-based attacks. Security cost is significantly different in nature
from conventional service provisioning costs such as energy consumption, since
security risks often depend on the collective behavior of all users. To this
end, we build a novel mathematical framework by leveraging the combined power
of game theory and epidemic theory to investigate the interplay between user
incentives and interdependent security risks in D2D offloading, thereby
enabling the design of security-aware incentive mechanisms. Our analysis
discovers an interesting &quot;less is more&quot; phenomenon: although giving users more
incentives promotes more participation, it may harm the network operator's
utility. This is because too much participation may foster persistent security
risks and as a result, the effective participation level does not improve. Our
model and analysis shed new insights on the optimization of D2D offloading
networks in the presence of interdependent security risks. Extensive
simulations are carried out to verify our analytical conclusions.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03852</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Connection between Generative Adversarial Networks, Inverse
  Reinforcement Learning, and Energy-Based Models</dc:title>
 <dc:creator>Finn, Chelsea</dc:creator>
 <dc:creator>Christiano, Paul</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Generative adversarial networks (GANs) are a recently proposed class of
generative models in which a generator is trained to optimize a cost function
that is being simultaneously learned by a discriminator. While the idea of
learning cost functions is relatively new to the field of generative modeling,
learning costs has long been studied in control and reinforcement learning (RL)
domains, typically for imitation learning from demonstrations. In these fields,
learning cost function underlying observed behavior is known as inverse
reinforcement learning (IRL) or inverse optimal control. While at first the
connection between cost learning in RL and cost learning in generative modeling
may appear to be a superficial one, we show in this paper that certain IRL
methods are in fact mathematically equivalent to GANs. In particular, we
demonstrate an equivalence between a sample-based algorithm for maximum entropy
IRL and a GAN in which the generator's density can be evaluated and is provided
as an additional input to the discriminator. Interestingly, maximum entropy IRL
is a special case of an energy-based model. We discuss the interpretation of
GANs as an algorithm for training energy-based models, and relate this
interpretation to other recent work that seeks to connect GANs and EBMs. By
formally highlighting the connection between GANs, IRL, and EBMs, we hope that
researchers in all three communities can better identify and apply transferable
ideas from one domain to another, particularly for developing more stable and
scalable algorithms: a major challenge in all three domains.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop on Adversarial Training. First two authors
  contributed equally</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03854</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive MIMO-Enabled Full-Duplex Cellular Networks</dc:title>
 <dc:creator>Shojaeifard, Arman</dc:creator>
 <dc:creator>Wong, Kai-Kit</dc:creator>
 <dc:creator>Di Renzo, Marco</dc:creator>
 <dc:creator>Zheng, Gan</dc:creator>
 <dc:creator>Hamdi, Khairi Ashour</dc:creator>
 <dc:creator>Tang, Jie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we provide a theoretical framework for the study of massive
multiple-input multiple-output (MIMO)-enabled full-duplex (FD) cellular
networks in which the self-interference (SI) channels follow the Rician
distribution and other channels are Rayleigh distributed. To facilitate
bi-directional wireless functionality, we adopt (i) a downlink (DL) linear
zero-forcing with self-interference-nulling (ZF-SIN) precoding scheme at the FD
base stations (BSs), and (ii) an uplink (UL) self-interference-aware (SIA)
fractional power control mechanism at the FD user equipments (UEs). Linear ZF
receivers are further utilized for signal detection in the UL. The results
indicate that the UL rate bottleneck in the baseline FD single-antenna system
can be overcome via exploiting massive MIMO. On the other hand, the findings
may be viewed as a reality-check, since we show that, under state-of-the-art
system parameters, the spectral efficiency (SE) gain of FD massive MIMO over
its half-duplex (HD) counterpart largely depends on the SI cancellation
capability of the UEs. In addition, the anticipated two-fold increase in SE is
shown to be only achievable with an infinitely large number of antennas.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03873</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective sparse representation of X-Ray medical images</dc:title>
 <dc:creator>Rebollo-Neira, Laura</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Effective sparse representation of X-Ray medical images within the context of
data reduction is considered. The proposed framework is shown to render an
enormous reduction in the cardinality of the data set required to represent
this class of images at very good quality. The particularity of the approach is
that it can be implemented at very competitive processing time and low memory
requirements
</dc:description>
 <dc:description>Comment: Routines for implementing the approach are available on
  http://www.nonlinear-approx.info/examples/node06.html</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03879</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM</dc:title>
 <dc:creator>Li, Chun-Liang</dc:creator>
 <dc:creator>Ravanbakhsh, Siamak</dc:creator>
 <dc:creator>Poczos, Barnabas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Restricted Boltzmann Machine (RBM) is a bipartite graphical model that is
used as the building block in energy-based deep generative models. Due to
numerical stability and quantifiability of the likelihood, RBM is commonly used
with Bernoulli units. Here, we consider an alternative member of exponential
family RBM with leaky rectified linear units -- called leaky RBM. We first
study the joint and marginal distributions of leaky RBM under different
leakiness, which provides us important insights by connecting the leaky RBM
model and truncated Gaussian distributions. The connection leads us to a simple
yet efficient method for sampling from this model, where the basic idea is to
anneal the leakiness rather than the energy; -- i.e., start from a fully
Gaussian/Linear unit and gradually decrease the leakiness over iterations. This
serves as an alternative to the annealing of the temperature parameter and
enables numerical estimation of the likelihood that are more efficient and more
accurate than the commonly used annealed importance sampling (AIS). We further
demonstrate that the proposed sampling algorithm enjoys faster mixing property
than contrastive divergence algorithm, which benefits the training without any
additional computational cost.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03889</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A PTAS for Three-Edge Connectivity in Planar Graphs</dc:title>
 <dc:creator>Borradaile, Glencora</dc:creator>
 <dc:creator>Zheng, Baigong</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of finding the minimum-weight subgraph that satisfies
given connectivity requirements. Specifically, given a requirement $r \in
\{0,1,2,3\}$ for every vertex, we seek the minimum-weight subgraph that
contains, for every pair of vertices $u$ and $v$, at least $\min\{ r(v),
r(u)\}$ edge-disjoint $u$-to-$v$ paths. We give a polynomial-time approximation
scheme (PTAS) for this problem when the input graph is planar and the subgraph
may use multiple copies of any given edge. This generalizes an earlier result
for $r \in \{0,1,2\}$. In order to achieve this PTAS, we prove some properties
of triconnected planar graphs that may be of independent interest.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03890</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theory of Taxonomy</dc:title>
 <dc:creator>D'Amico, Guido</dc:creator>
 <dc:creator>Rabadan, Raul</dc:creator>
 <dc:creator>Kleban, Matthew</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  A taxonomy is a standardized framework to classify and organize items into
categories. Hierarchical taxonomies are ubiquitous, ranging from the
classification of organisms to the file system on a computer. Characterizing
the typical distribution of items within taxonomic categories is an important
question with applications in many disciplines. Ecologists have long sought to
account for the patterns observed in species-abundance distributions (the
number of individuals per species found in some sample), and computer
scientists study the distribution of files per directory. Is there a universal
statistical distribution describing how many items are typically found in each
category in large taxonomies? Here, we analyze a wide array of large,
real-world datasets -- including items lost and found on the New York City
transit system, library books, and a bacterial microbiome -- and discover such
an underlying commonality. A simple, non-parametric branching model that
randomly categorizes items and takes as input only the total number of items
and the total number of categories successfully reproduces the abundance
distributions in these datasets. This result may shed light on patterns in
species-abundance distributions long observed in ecology. The model also
predicts the number of taxonomic categories that remain unrepresented in a
finite sample.
</dc:description>
 <dc:description>Comment: 7+13 pages, 5 figures. Comments welcome</dc:description>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03894</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning For Effective User Engagement on Social Media</dc:title>
 <dc:creator>Pham, Thai</dc:creator>
 <dc:creator>Simoiu, Camelia</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we investigate the effectiveness of unsupervised feature
learning techniques in predicting user engagement on social media.
Specifically, we compare two methods to predict the number of feedbacks (i.e.,
comments) that a blog post is likely to receive. We compare Principal Component
Analysis (PCA) and sparse Autoencoder to a baseline method where the data are
only centered and scaled, on each of two models: Linear Regression and
Regression Tree. We find that unsupervised learning techniques significantly
improve the prediction accuracy on both models. For the Linear Regression
model, sparse Autoencoder achieves the best result, with an improvement in the
root mean squared error (RMSE) on the test set of 42% over the baseline method.
For the Regression Tree model, PCA achieves the best result, with an
improvement in RMSE of 15% over the baseline.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03895</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>traIXroute: Detecting IXPs in traceroute paths</dc:title>
 <dc:creator>Nomikos, George</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Internet eXchange Points (IXP) are critical components of the Internet
infrastructure that affect its performance, evolution, security and economics.
In this work, we introduce techniques to augment the well-known traceroute tool
with the capability of identifying if and where exactly IXPs are crossed in
endto- end paths. Knowing this information can help end-users have more
transparency over how their traffic flows in the Internet. Our tool, called
traIXroute, exploits data from the PeeringDB (PDB) and the Packet Clearing
House (PCH) about IXP IP addresses of BGP routers, IXP members, and IXP
prefixes. We show that the used data are both rich, i.e., we find 12,716 IP
addresses of BGP routers in 460 IXPs, and mostly accurate, i.e., our validation
shows 92-93% accuracy. In addition, 78.2% of the detected IXPs in our data are
based on multiple diverse evidence and therefore help have higher confidence on
the detected IXPs than when relying solely on IXP prefixes. To demonstrate the
utility of our tool, we use it to show that one out of five paths in our data
cross an IXP and that paths do not normally cross more than a single IXP, as it
is expected based on the valley-free model about Internet policies.
Furthermore, although the top IXPs both in terms of paths and members are
located in Europe, US IXPs attract many more paths than their number of members
indicates.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03898</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Latency Anomaly Detection and Bayesian Network Prediction of Anomaly
  Likelihood</dc:title>
 <dc:creator>Farren, Derek</dc:creator>
 <dc:creator>Pham, Thai</dc:creator>
 <dc:creator>Alban-Hidalgo, Marco</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We develop a supervised machine learning model that detects anomalies in
systems in real time. Our model processes unbounded streams of data into time
series which then form the basis of a low-latency anomaly detection model.
Moreover, we extend our preliminary goal of just anomaly detection to
simultaneous anomaly prediction. We approach this very challenging problem by
developing a Bayesian Network framework that captures the information about the
parameters of the lagged regressors calibrated in the first part of our
approach and use this structure to learn local conditional probability
distributions.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03899</identifier>
 <datestamp>2017-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal incentives for collective intelligence</dc:title>
 <dc:creator>Mann, Richard P.</dc:creator>
 <dc:creator>Helbing, Dirk</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Collective intelligence is the ability of a group to perform more effectively
than any individual alone. Diversity among group members is a key condition for
the emergence of collective intelligence, but maintaining diversity is
challenging in the face of social pressure to imitate one's peers. We
investigate the role incentives play in maintaining useful diversity through an
evolutionary game-theoretic model of collective prediction. We show that
market-based incentive systems produce herding effects, reduce information
available to the group and suppress collective intelligence. In response, we
propose a new incentive scheme that rewards accurate minority predictions, and
show that this produces optimal diversity and collective predictive accuracy.
We conclude that real-world systems should reward those who have demonstrated
accuracy when majority opinion has been in error.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03899</dc:identifier>
 <dc:identifier>PNAS 2017 114 (20) 5077-5082</dc:identifier>
 <dc:identifier>doi:10.1073/pnas.1618722114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03906</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Help, It Looks Confusing: GUI Task Automation Through Demonstration and
  Follow-up Questions</dc:title>
 <dc:creator>Intharah, Thanapong</dc:creator>
 <dc:creator>Turmukhambetov, Daniyar</dc:creator>
 <dc:creator>Brostow, Gabriel J.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Non-programming users should be able to create their own customized scripts
to perform computer-based tasks for them, just by demonstrating to the machine
how it's done. To that end, we develop a system prototype which
learns-by-demonstration called HILC (Help, It Looks Confusing). Users train
HILC to synthesize a task script by demonstrating the task, which produces the
needed screenshots and their corresponding mouse-keyboard signals. After the
demonstration, the user answers follow-up questions.
  We propose a user-in-the-loop framework that learns to generate scripts of
actions performed on visible elements of graphical applications. While pure
programming-by-demonstration is still unrealistic, we use quantitative and
qualitative experiments to show that non-programming users are willing and
effective at answering follow-up queries posed by our system. Our models of
events and appearance are surprisingly simple, but are combined effectively to
cope with varying amounts of supervision.
  The best available baseline, Sikuli Slides, struggled with the majority of
the tests in our user study experiments. The prototype with our proposed
approach successfully helped users accomplish simple linear tasks, complicated
tasks (monitoring, looping, and mixed), and tasks that span across multiple
executables. Even when both systems could ultimately perform a task, ours was
trained and refined by the user in less time.
</dc:description>
 <dc:description>Comment: Camera Ready version. Accepted to be presented at the ACM IUI 2017</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03907</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning in Rich-Observation MDPs using Spectral Methods</dc:title>
 <dc:creator>Azizzadenesheli, Kamyar</dc:creator>
 <dc:creator>Lazaric, Alessandro</dc:creator>
 <dc:creator>Anandkumar, Animashree</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Designing effective exploration-exploitation algorithms in Markov decision
processes (MDPs) with large state-action spaces is the main challenge in
reinforcement learning (RL). In fact, the learning performance degrades with
the number of states and actions in the MDP. However, MDPs often exhibit a
low-dimensional latent structure in practice, where a small hidden state is
observable through a possibly large number of observations. In this paper, we
study the setting of rich-observation Markov decision processes (\richmdp),
where hidden states are mapped to observations through an injective mapping, so
that an observation can be generated by only one hidden state. While this
mapping is unknown a priori, we introduce a spectral decomposition method that
consistently estimates how observations are clustered in the hidden states. The
estimated clustering is then integrated into an optimistic algorithm for RL
(UCRL), which operates on the smaller clustered space. The resulting algorithm
proceeds through phases and we show that its per-step regret (i.e., the
difference in cumulative reward between the algorithm and the optimal policy)
decreases as more observations are clustered together and finally, matches the
(ideal) performance of an RL algorithm running directly on the hidden MDP.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-06-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03915</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Fashion Meets Big Data: Discriminative Mining of Best Selling
  Clothing Features</dc:title>
 <dc:creator>Chen, Kuan-Ting</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the prevalence of e-commence websites and the ease of online shopping,
consumers are embracing huge amounts of various options in products.
Undeniably, shopping is one of the most essential activities in our society and
studying consumer's shopping behavior is important for the industry as well as
sociology and psychology. Indisputable, one of the most popular e-commerce
categories is clothing business. There arises the needs for analysis of popular
and attractive clothing features which could further boost many emerging
applications, such as clothing recommendation and advertising. In this work, we
design a novel system that consists of three major components: 1) exploring and
organizing a large-scale clothing dataset from a online shopping website, 2)
pruning and extracting images of best-selling products in clothing item data
and user transaction history, and 3) utilizing a machine learning based
approach to discovering fine-grained clothing attributes as the representative
and discriminative characteristics of popular clothing style elements. Through
the experiments over a large-scale online clothing shopping dataset, we
demonstrate the effectiveness of our proposed system, and obtain useful
insights on clothing consumption trends and profitable clothing features.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03921</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite-state independence</dc:title>
 <dc:creator>Becher, Ver&#xf3;nica</dc:creator>
 <dc:creator>Carton, Olivier</dc:creator>
 <dc:creator>Heiber, Pablo Ariel</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this work we introduce a notion of independence based on finite-state
automata: two infinite words are independent if no one helps to compress the
other using one-to-one finite-state transducers with auxiliary input. We prove
that, as expected, the set of independent pairs of infinite words has Lebesgue
measure 1. We show that the join of two independent normal words is normal.
However, the independence of two normal words is not guaranteed if we just
require that their join is normal. To prove this we construct a normal word
$x_1x_2x_3\ldots$ where $x_{2n}=x_n$ for every $n$.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03932</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training IBM Watson using Automatically Generated Question-Answer Pairs</dc:title>
 <dc:creator>Lee, Jangho</dc:creator>
 <dc:creator>Kim, Gyuwan</dc:creator>
 <dc:creator>Yoo, Jaeyoon</dc:creator>
 <dc:creator>Jung, Changwoo</dc:creator>
 <dc:creator>Kim, Minseok</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  IBM Watson is a cognitive computing system capable of question answering in
natural languages. It is believed that IBM Watson can understand large corpora
and answer relevant questions more effectively than any other
question-answering system currently available. To unleash the full power of
Watson, however, we need to train its instance with a large number of
well-prepared question-answer pairs. Obviously, manually generating such pairs
in a large quantity is prohibitively time consuming and significantly limits
the efficiency of Watson's training. Recently, a large-scale dataset of over 30
million question-answer pairs was reported. Under the assumption that using
such an automatically generated dataset could relieve the burden of manual
question-answer generation, we tried to use this dataset to train an instance
of Watson and checked the training efficiency and accuracy. According to our
experiments, using this auto-generated dataset was effective for training
Watson, complementing manually crafted question-answer pairs. To the best of
the authors' knowledge, this work is the first attempt to use a large-scale
dataset of automatically generated question-answer pairs for training IBM
Watson. We anticipate that the insights and lessons obtained from our
experiments will be useful for researchers who want to expedite Watson training
leveraged by automatically generated question-answer pairs.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03934</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personalized Donor-Recipient Matching for Organ Transplantation</dc:title>
 <dc:creator>Yoon, Jinsung</dc:creator>
 <dc:creator>Alaa, Ahmed M.</dc:creator>
 <dc:creator>Cadeiras, Martin</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Organ transplants can improve the life expectancy and quality of life for the
recipient but carries the risk of serious post-operative complications, such as
septic shock and organ rejection. The probability of a successful transplant
depends in a very subtle fashion on compatibility between the donor and the
recipient but current medical practice is short of domain knowledge regarding
the complex nature of recipient-donor compatibility. Hence a data-driven
approach for learning compatibility has the potential for significant
improvements in match quality. This paper proposes a novel system
(ConfidentMatch) that is trained using data from electronic health records.
ConfidentMatch predicts the success of an organ transplant (in terms of the 3
year survival rates) on the basis of clinical and demographic traits of the
donor and recipient. ConfidentMatch captures the heterogeneity of the donor and
recipient traits by optimally dividing the feature space into clusters and
constructing different optimal predictive models to each cluster. The system
controls the complexity of the learned predictive model in a way that allows
for assuring more granular and confident predictions for a larger number of
potential recipient-donor pairs, thereby ensuring that predictions are
&quot;personalized&quot; and tailored to individual characteristics to the finest
possible granularity. Experiments conducted on the UNOS heart transplant
dataset show the superiority of the prognostic value of ConfidentMatch to other
competing benchmarks; ConfidentMatch can provide predictions of success with
95% confidence for 5,489 patients of a total population of 9,620 patients,
which corresponds to 410 more patients than the most competitive benchmark
algorithm (DeepBoost).
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03935</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Elementary Proof of Convex Phase Retrieval in the Natural Parameter
  Space via the Linear Program PhaseMax</dc:title>
 <dc:creator>Hand, Paul</dc:creator>
 <dc:creator>Voroninski, Vladislav</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The phase retrieval problem has garnered significant attention since the
development of the PhaseLift algorithm, which is a convex program that operates
in a lifted space of matrices. Because of the substantial computational cost
due to lifting, many approaches to phase retrieval have been developed,
including non-convex optimization algorithms which operate in the natural
parameter space, such as Wirtinger Flow. Very recently, a convex formulation
called PhaseMax has been discovered, and it has been proven to achieve phase
retrieval via linear programming in the natural parameter space under optimal
sample complexity. The current proofs of PhaseMax rely on statistical learning
theory or geometric probability theory. Here, we present a short and elementary
proof that PhaseMax exactly recovers real-valued vectors from random
measurements under optimal sample complexity. Our proof only relies on standard
probabilistic concentration and covering arguments, yielding a simpler and more
direct proof than those that require statistical learning theory, geometric
probability or the highly technical arguments for Wirtinger Flow-like
approaches.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03941</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomaly Detection in Bitcoin Network Using Unsupervised Learning Methods</dc:title>
 <dc:creator>Pham, Thai</dc:creator>
 <dc:creator>Lee, Steven</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The problem of anomaly detection has been studied for a long time. In short,
anomalies are abnormal or unlikely things. In financial networks, thieves and
illegal activities are often anomalous in nature. Members of a network want to
detect anomalies as soon as possible to prevent them from harming the network's
community and integrity. Many Machine Learning techniques have been proposed to
deal with this problem; some results appear to be quite promising but there is
no obvious superior method. In this paper, we consider anomaly detection
particular to the Bitcoin transaction network. Our goal is to detect which
users and transactions are the most suspicious; in this case, anomalous
behavior is a proxy for suspicious behavior. To this end, we use three
unsupervised learning methods including k-means clustering, Mahalanobis
distance, and Unsupervised Support Vector Machine (SVM) on two graphs generated
by the Bitcoin transaction network: one graph has users as nodes, and the other
has transactions as nodes.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03942</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomaly Detection in the Bitcoin System - A Network Perspective</dc:title>
 <dc:creator>Pham, Thai</dc:creator>
 <dc:creator>Lee, Steven</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The problem of anomaly detection has been studied for a long time, and many
Network Analysis techniques have been proposed as solutions. Although some
results appear to be quite promising, no method is clearly to be superior to
the rest. In this paper, we particularly consider anomaly detection in the
Bitcoin transaction network. Our goal is to detect which users and transactions
are the most suspicious; in this case, anomalous behavior is a proxy for
suspicious behavior. To this end, we use the laws of power degree and
densification and local outlier factor (LOF) method (which is proceeded by
k-means clustering method) on two graphs generated by the Bitcoin transaction
network: one graph has users as nodes, and the other has transactions as nodes.
  We remark that the methods used here can be applied to any type of setting
with an inherent graph structure, including, but not limited to, computer
networks, telecommunications networks, auction networks, security networks,
social networks, Web networks, or any financial networks. We use the Bitcoin
transaction network in this paper due to the availability, size, and
attractiveness of the data set.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03946</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New method of averaging diffeomorphisms based on Jacobian determinant
  and curl vector</dc:title>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Liao, Guojun</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Averaging diffeomorphisms is a challenging problem, and it has great
applications in areas like medical image atlases. The simple Euclidean average
can neither guarantee the averaged transformation is a diffeomorphism, nor get
reasonable result when there is a local rotation. The goal of this paper is to
propose a new approach to averaging diffeomorphisms based on the Jacobian
determinant and the curl vector of the diffeomorphisms. Instead of averaging
the diffeomorphisms directly, we average the Jacobian determinants and the curl
vectors, and then construct a diffeomorphism based on the averaged Jacobian
determinant and averaged curl vector as the average of diffeomorphisms.
Numerical examples with convincible results are presented to demonstrate the
method.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03947</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Algorithm for Maintaining Acyclicity in Concurrent Graph
  Objects</dc:title>
 <dc:creator>Peri, Sathya</dc:creator>
 <dc:creator>Sa, Muktikanta</dc:creator>
 <dc:creator>Singhal, Nandini</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper, we propose an algorithm for maintaining a concurrent directed
graph (for shared memory architecture) that is concurrently being updated by
threads adding/deleting vertices and edges. The update methods of the algorithm
are deadlock-free while the contains methods are wait-free. To the the best of
our knowledge, this is the first work to propose a concurrent data structure
for an adjacency list representation of the graphs. We extend the lazy list
implementation of concurrent set for achieving this.
  We believe that there are many applications that can benefit from this
concurrent graph structure. An important application that inspired us is SGT in
databases and Transactional Memory. Motivated by this application, on this
concurrent graph data-structure, we pose the constraint that the graph should
always be acyclic. We ensure this by checking for graph acyclicity whenever we
add an edge. To detect the cycle efficiently we have proposed a Wait-free
reachability algorithm. We have compared the performance of the proposed
concurrent data structure with coarse-grained locking implementation which has
been traditionally used in implementing SGT. We show that our algorithm
achieves on an average 8x improvement in throughput as compared to
coarse-grained and sequential implementations.
</dc:description>
 <dc:description>Comment: Under submission</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03949</identifier>
 <datestamp>2017-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linguistically Regularized LSTMs for Sentiment Classification</dc:title>
 <dc:creator>Qian, Qiao</dc:creator>
 <dc:creator>Huang, Minlie</dc:creator>
 <dc:creator>Lei, Jinhao</dc:creator>
 <dc:creator>Zhu, Xiaoyan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Sentiment understanding has been a long-term goal of AI in the past decades.
This paper deals with sentence-level sentiment classification. Though a variety
of neural network models have been proposed very recently, however, previous
models either depend on expensive phrase-level annotation, whose performance
drops substantially when trained with only sentence-level annotation; or do not
fully employ linguistic resources (e.g., sentiment lexicons, negation words,
intensity words), thus not being able to produce linguistically coherent
representations. In this paper, we propose simple models trained with
sentence-level annotation, but also attempt to generating linguistically
coherent representations by employing regularizers that model the linguistic
role of sentiment lexicons, negation words, and intensity words. Results show
that our models are effective to capture the sentiment shifting effect of
sentiment, negation, and intensity words, while still obtain competitive
results without sacrificing the models' simplicity.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03954</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilingual Knowledge Graph Embeddings for Cross-lingual Knowledge
  Alignment</dc:title>
 <dc:creator>Chen, Muhao</dc:creator>
 <dc:creator>Tian, Yingtao</dc:creator>
 <dc:creator>Yang, Mohan</dc:creator>
 <dc:creator>Zaniolo, Carlo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Many recent works have demonstrated the benefits of knowledge graph
embeddings in completing monolingual knowledge graphs. Inasmuch as related
knowledge bases are built in several different languages, achieving
cross-lingual knowledge alignment will help people in constructing a coherent
knowledge base, and assist machines in dealing with different expressions of
entity relationships across diverse human languages. Unfortunately, achieving
this highly desirable crosslingual alignment by human labor is very costly and
errorprone. Thus, we propose MTransE, a translation-based model for
multilingual knowledge graph embeddings, to provide a simple and automated
solution. By encoding entities and relations of each language in a separated
embedding space, MTransE provides transitions for each embedding vector to its
cross-lingual counterparts in other spaces, while preserving the
functionalities of monolingual embeddings. We deploy three different techniques
to represent cross-lingual transitions, namely axis calibration, translation
vectors, and linear transformations, and derive five variants for MTransE using
different loss functions. Our models can be trained on partially aligned
graphs, where just a small portion of triples are aligned with their
cross-lingual counterparts. The experiments on cross-lingual entity matching
and triple-wise alignment verification show promising results, with some
variants consistently outperforming others on different tasks. We also explore
how MTransE preserves the key properties of its monolingual counterpart TransE.
</dc:description>
 <dc:description>Comment: Extended version of the IJCAI-17 paper</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03959</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Smart Query Routing: For Distributed Graph Querying with Decoupled
  Storage</dc:title>
 <dc:creator>Khan, Arijit</dc:creator>
 <dc:creator>Segovia, Gustavo</dc:creator>
 <dc:creator>Kossmann, Donald</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We study online graph queries that retrieve nearby nodes of a query node from
a large network. To answer such queries with high throughput and low latency,
we partition the graph and process the data in parallel across a cluster of
servers. State-of-the-art distributed graph querying systems place each graph
partition on a separate server, where query answering over that partition takes
place. This design has two major disadvantages. First, the router needs to
maintain a fixed routing table. Hence, these systems are less flexible with
respect to query routing, fault tolerance, and graph updates. Second, the graph
data must be partitioned such that the workload across the servers is balanced,
and the inter-machine communication is minimized. In addition, it is required
to update the existing partitions based on workload changes over graph nodes.
However, graph partitioning, online monitoring of workloads, and dynamically
updating the graph partitions are expensive. In this work, we mitigate both
these problems by decoupling graph storage from query processors, and by
developing smart routing strategies that improve the cache locality in query
processors. Since a query processor is no longer assigned any fixed part of the
graph, it is equally capable of handling any request, thus facilitating load
balancing and fault tolerance. On the other hand, due to our smart routing
strategies, query processors can effectively leverage their cache contents,
reducing the overall impact of how the graph is partitioned across storage
servers. A detailed experimental evaluation with several real-world, large
graph datasets demonstrates that our proposed framework, gRouting - even with
simple hash partitioning of the data - achieves up to an order of magnitude
better query throughput compared to existing graph querying systems that employ
expensive graph partitioning and re-partitioning strategies.
</dc:description>
 <dc:description>Comment: 12 pages, 16 Figures</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2017-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03967</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signal Processing with Pulse Trains: An Algebraic Approach- Part I</dc:title>
 <dc:creator>Nallathambi, Gabriel</dc:creator>
 <dc:creator>Principe, Jose</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Recently we have shown that it is possible to represent continuous amplitude,
continuous time, band limited signals with an error as small as desired using
pulse trains via the integrate and fire converter (IFC). The IFC is an ultra
low power converter and processing with pulse trains is compatible with the
trends in the silicon technology for very low supply voltages. This paper
presents the definition of addition in pulse trains created by the IFC using
exclusively timing information, and proofs that it constitutes an Abelian group
in the space of IFC pulse trains. We also show that pulse domain addition
corresponds to pointwise addition of analog signals.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03968</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Generative-Discriminative Model for Object Detection in Video: An
  Unsupervised Learning Framework</dc:title>
 <dc:creator>Luo, Dapeng</dc:creator>
 <dc:creator>Zeng, Zhipeng</dc:creator>
 <dc:creator>Wei, Longsheng</dc:creator>
 <dc:creator>Luo, Chen</dc:creator>
 <dc:creator>Chen, Jun</dc:creator>
 <dc:creator>Sang, Nong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Traditional single-view object detection methods often perform worse under
unconstrained video environments. To address this problem, many modern
multi-view detection approaches model complex 3D appearance representations to
predict the optimal viewing angle for detection. Most of these approaches
require an intensive training process on large database, collected in advance.
In this paper, the proposed framework takes a remarkably different direction to
resolve multi-view detection problem in a bottom-up fashion. First, a
scene-specific objector is obtained from a fully autonomous learning process
triggered by marking several bounding boxes around the object in the first
video frame via a mouse. Here the human labeled training data or a generic
detector are not needed. Second, this learning process is conveniently
replicated many times in different surveillance scenes and results in a
particular detector under various camera viewpoints. Thus, the proposed
framework can be employed in multi-view object detection applications from
unsupervised learning process. Obviously, the initial scene-specific detector,
initialed by several bounding boxes, exhibits poor detection performance and is
difficult to improve with traditional online learning algorithm. Consequently,
we propose Generative-Discriminative model to partition detection response
space and assign each partition an individual descriptor that progressively
achieves high classification accuracy. A novel online gradual learning
algorithm is proposed to train the Generative-Discriminative model
automatically and focus online learning on the hard samples: the most
informative samples lying around the decision boundary. The output is a hybrid
classifier based scene-specific detector which achieves decent performance
under different viewing angles.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03969</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Introduction to MM Algorithms for Machine Learning and Statistical</dc:title>
 <dc:creator>Nguyen, Hien D.</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  MM (majorization--minimization) algorithms are an increasingly popular tool
for solving optimization problems in machine learning and statistical
estimation. This article introduces the MM algorithm framework in general and
via three popular example applications: Gaussian mixture regressions,
multinomial logistic regressions, and support vector machines. Specific
algorithms for the three examples are derived and numerical demonstrations are
presented. Theoretical and practical aspects of MM algorithm design are
discussed.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03970</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signal Processing with Pulse Trains: An Algebraic Approach- Part II</dc:title>
 <dc:creator>Nallathambi, Gabriel</dc:creator>
 <dc:creator>Principe, Jose</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The integrate and fire converter (IFC) enables an alternative to digital
signal processing. IFC converts analog signal voltages into time between pulses
and it is possible to reconstruct the analog signal from the IFC pulses with an
error as small as required. In this paper, we present the definition of
multiplication in pulse trains created by the IFC based on time domain
operations and prove that it constitutes an Abelian group in the space of IFC
pulse trains. We also show that pulse domain multiplication corresponds to
pointwise multiplication of analog signals. It is further proved that pulse
domain multiplication is distributive over pulse domain addition and hence it
forms a field in the space of IFC pulse trains, which is an important property
for linear signal processing.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03971</identifier>
 <datestamp>2016-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User characterization for online social networks</dc:title>
 <dc:creator>Tuna, Tayfun</dc:creator>
 <dc:creator>Akbas, Esra</dc:creator>
 <dc:creator>Aksoy, Ahmet</dc:creator>
 <dc:creator>Canbaz, Muhammed Abdullah</dc:creator>
 <dc:creator>Karabiyik, Umit</dc:creator>
 <dc:creator>Gonen, Bilal</dc:creator>
 <dc:creator>Aygun, Ramazan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online social network analysis has attracted great attention with a vast
number of users sharing information and availability of APIs that help to crawl
online social network data. In this paper, we study the research studies that
are helpful for user characterization as online users may not always reveal
their true identity or attributes. We especially focused on user attribute
determination such as gender, age, etc.; user behavior analysis such as motives
for deception; mental models that are indicators of user behavior; user
categorization such as bots vs. humans; and entity matching on different social
networks. We believe our summary of analysis of user characterization will
provide important insights to researchers and better services to online users.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2016-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03971</dc:identifier>
 <dc:identifier>Soc. Netw. Anal. Min. (2016) 6: 104. doi:10.1007/s13278-016-0412-3</dc:identifier>
 <dc:identifier>doi:10.1007/s13278-016-0412-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03977</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Review on Algorithms for Constraint-based Causal Discovery</dc:title>
 <dc:creator>Yu, Kui</dc:creator>
 <dc:creator>Li, Jiuyong</dc:creator>
 <dc:creator>Liu, Lin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Causal discovery studies the problem of mining causal relationships between
variables from data, which is of primary interest in science. During the past
decades, significant amount of progresses have been made toward this
fundamental data mining paradigm. Recent years, as the availability of abundant
large-sized and complex observational data, the constrain-based approaches have
gradually attracted a lot of interest and have been widely applied to many
diverse real-world problems due to the fast running speed and easy generalizing
to the problem of causal insufficiency. In this paper, we aim to review the
constraint-based causal discovery algorithms. Firstly, we discuss the learning
paradigm of the constraint-based approaches. Secondly and primarily, the
state-of-the-art constraint-based casual inference algorithms are surveyed with
the detailed analysis. Thirdly, several related open-source software packages
and benchmark data repositories are briefly summarized. As a conclusion, some
open problems in constraint-based causal discovery are outlined for future
research.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to further
  improvement</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03981</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Teaching: A Practical Semi-supervised Wrapper Method</dc:title>
 <dc:creator>Liu, Fuqaing</dc:creator>
 <dc:creator>Deng, Chenwei</dc:creator>
 <dc:creator>Bi, Fukun</dc:creator>
 <dc:creator>Yang, Yiding</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Semi-supervised wrapper methods are concerned with building effective
supervised classifiers from partially labeled data. Though previous works have
succeeded in some fields, it is still difficult to apply semi-supervised
wrapper methods to practice because the assumptions those methods rely on tend
to be unrealistic in practice. For practical use, this paper proposes a novel
semi-supervised wrapper method, Dual Teaching, whose assumptions are easy to
set up. Dual Teaching adopts two external classifiers to estimate the false
positives and false negatives of the base learner. Only if the recall of every
external classifier is greater than zero and the sum of the precision is
greater than one, Dual Teaching will train a base learner from partially
labeled data as effectively as the fully-labeled-data-trained classifier. The
effectiveness of Dual Teaching is proved in both theory and practice.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, 1 table</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03982</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Proofs of Retrievability with Public Verifiability for Dynamic
  Cloud Storage</dc:title>
 <dc:creator>Sengupta, Binanda</dc:creator>
 <dc:creator>Ruj, Sushmita</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cloud service providers offer various facilities to their clients. The
clients with limited resources opt for some of these facilities. They can
outsource their bulk data to the cloud server. The cloud server maintains these
data in lieu of monetary benefits. However, a malicious cloud server might
delete some of these data to save some space and offer this extra amount of
storage to another client. Therefore, the client might not retrieve her file
(or some portions of it) as often as needed. Proofs of retrievability (POR)
provide an assurance to the client that the server is actually storing all of
her data appropriately and they can be retrieved at any point of time. In a
dynamic POR scheme, the client can update her data after she uploads them to
the cloud server. Moreover, in publicly verifiable POR schemes, the client can
delegate her auditing task to some third party specialized for this purpose. In
this work, we exploit the homomorphic hashing technique to design a publicly
verifiable dynamic POR scheme that is more efficient (in terms of bandwidth
required between the client and the server) than the &quot;state-of-the-art&quot;
publicly verifiable dynamic POR scheme. We also analyze security and
performance of our scheme.
</dc:description>
 <dc:description>Comment: A version of the paper with the same title has been published in IEEE
  Transactions on Cloud Computing (DOI: 10.1109/TCC.2017.2767584)</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2017-12-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03991</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Further Step Towards an Understanding of the Tournament Equilibrium
  Set</dc:title>
 <dc:creator>Yang, Yongjie</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study some problems pertaining to the tournament equilibrium set (TEQ for
short). A tournament $H$ is a TEQ-retentive tournament if there is a tournament
$T$ which has a minimal TEQ-retentive set $R$ such that $T[R]$ is isomorphic to
$H$. We study TEQ-retentive tournaments and achieve many significant results.
In particular, we prove that there are no TEQ-retentive tournaments of size 4,
only 2 non-isomorphic TEQ-retentive tournaments of sizes 5 and 6, respectively,
and 26 non-isomorphic TEQ-retentive tournaments of size 7. For three
tournaments $H_1, H_2$ and $T$, we say $T$ is a $(H_1,H_2)$-TEQ-retentive
tournament if $T$ has two minimal TEQ-retentive sets $R_1$ and $R_2$ such that
$T[R_1]$ and $T[R_2]$ are isomorphic to $H_1$ and $H_2$, respectively. We show
that there are no $(H_1,H_2)$-retentive tournaments for $H_1$ and $H_2$ being
small tournaments. Our results imply that Schwartz's Conjecture holds in all
tournaments of size at most 14. Finally, we study Schwartz's Conjecture in
several classes of tournaments. To achieve these results, we study the relation
between (directed) domination graphs of tournaments and TEQ-retentive sets, and
derive a number of properties on minimal TEQ-retentive sets.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03993</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Riemannian Tensor Completion with Side Information</dc:title>
 <dc:creator>Zhou, Tengfei</dc:creator>
 <dc:creator>Qian, Hui</dc:creator>
 <dc:creator>Shen, Zebang</dc:creator>
 <dc:creator>Xu, Congfu</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  By restricting the iterate on a nonlinear manifold, the recently proposed
Riemannian optimization methods prove to be both efficient and effective in low
rank tensor completion problems. However, existing methods fail to exploit the
easily accessible side information, due to their format mismatch. Consequently,
there is still room for improvement in such methods. To fill the gap, in this
paper, a novel Riemannian model is proposed to organically integrate the
original model and the side information by overcoming their inconsistency. For
this particular model, an efficient Riemannian conjugate gradient descent
solver is devised based on a new metric that captures the curvature of the
objective.Numerical experiments suggest that our solver is more accurate than
the state-of-the-art without compromising the efficiency.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03995</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Shelflisting</dc:title>
 <dc:creator>Yang, Yongjie</dc:creator>
 <dc:creator>Dimitrov, Dinko</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Optimal shelflisting invites profit maximization to become sensitive to the
ways in which purchasing decisions are order-dependent. We study the
computational complexity of the corresponding product arrangement problem when
consumers are either rational maximizers, use a satisficing procedure, or apply
successive choice. The complexity results we report are shown to crucially
depend on the size of the top cycle in consumers' preferences over products and
on the direction in which alternatives on the shelf are encountered.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03999</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized clothes segmentation to boost gender classification in
  unconstrained scenarios</dc:title>
 <dc:creator>Freire-Obreg&#xf3;n, D.</dc:creator>
 <dc:creator>Castrill&#xf3;n-Santana, M.</dc:creator>
 <dc:creator>Lorenzo-Navarro, J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Several applications require demographic information of ordinary people in
unconstrained scenarios. This is not a trivial task due to significant human
appearance variations. In this work, we introduce trixels for clustering image
regions, enumerating their advantages compared to superpixels. The classical
GrabCut algorithm is later modified to segment trixels instead of pixels in an
unsupervised context. Combining with face detection lead us to a clothes
segmentation approach close to real time. The study uses the challenging Pascal
VOC dataset for segmentation evaluation experiments. A final experiment
analyzes the fusion of clothes features with state-of-the-art gender
classifiers in ClothesDB, revealing a significant performance improvement in
gender classification.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.03999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04010</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Language Identification Using Convolutional Recurrent Neural
  Network</dc:title>
 <dc:creator>Lakhani, Vrishabh Ajay</dc:creator>
 <dc:creator>Mahadev, Rohan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Language Identification, being an important aspect of Automatic Speaker
Recognition has had many changes and new approaches to ameliorate performance
over the last decade. We compare the performance of using audio spectrum in the
log scale and using Polyphonic sound sequences from raw audio samples to train
the neural network and to classify speech as either English or Spanish. To
achieve this, we use the novel approach of using a Convolutional Recurrent
Neural Network using Long Short Term Memory (LSTM) or a Gated Recurrent Unit
(GRU) for forward propagation of the neural network. Our hypothesis is that the
performance of using polyphonic sound sequence as features and both LSTM and
GRU as the gating mechanisms for the neural network outperform the traditional
MFCC features using a unidirectional Deep Neural Network.
</dc:description>
 <dc:description>Comment: Further experiments were performed on the model using LibriVox speech
  dataset and it was found that a Time Distributed CRNN model performed better
  and represented our initial ideas about the speaker recognition task better.
  The dataset contains speech in three languages - English, Spanish and Czech.
  A report on our findings along with experimental results will be published
  soon</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04012</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trust-based Secure Routing in Software-defined Vehicular Ad Hoc Networks</dc:title>
 <dc:creator>Zhang, Dajun</dc:creator>
 <dc:creator>Yu, F. Richard</dc:creator>
 <dc:creator>Wei, Zhexiong</dc:creator>
 <dc:creator>Boukerche, Azzedine</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the rising interest of expedient, safe, and high-efficient
transportation, vehicular ad hoc networks (VANETs) have turned into a critical
technology in smart transportation systems. Because of the high mobility of
nodes, VANETs are vulnerable to security attacks. In this paper, we propose a
novel framework of software-defined VANETs with trust management. Specifically,
we separate the forwarding plane in VANETs from the control plane, which is
responsible for the control functionality, such as routing protocols and trust
management in VANETs. Using the on-demand distance vector routing (TAODV)
protocol as an example, we present a routing protocol named software-defined
trust based ad hoc on-demand distance vector routing (SD-TAODV). Simulation
results are presented to show the effectiveness of the proposed
software-defined VANETs with trust management.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04017</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine to Machine (M2M) Communications in Virtualized Vehicular Ad Hoc
  Networks</dc:title>
 <dc:creator>Li, Meng</dc:creator>
 <dc:creator>Yu, F. Richard</dc:creator>
 <dc:creator>Si, Pengbo</dc:creator>
 <dc:creator>Sun, Enchang</dc:creator>
 <dc:creator>Zhang, Yanhua</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the growing interest in the use of internet of things (IoT),
machine-to-machine (M2M) communications have become an important networking
paradigm. In this paper, with recent advances in wireless network
virtualization (WNV), we propose a novel framework for M2M communications in
vehicular ad-hoc networks (VANETs) with WNV. In the proposed framework,
according to different applications and quality of service (QoS) requirements
of vehicles, a hypervisor enables the virtualization of the physical vehicular
network, which is abstracted and sliced into multiple virtual networks.
Moreover, the process of resource blocks (RBs) selection and random access in
each virtual vehicular network is formulated as a partially observable Markov
decision process (POMDP), which can achieve the maximum reward about
transmission capacity. The optimal policy for RBs selection is derived by
virtue of a dynamic programming approach. Extensive simulation results with
different system parameters are presented to show the performance improvement
of the proposed scheme.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04021</identifier>
 <datestamp>2016-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Video Descriptions to Learn Video Question Answering</dc:title>
 <dc:creator>Zeng, Kuo-Hao</dc:creator>
 <dc:creator>Chen, Tseng-Hung</dc:creator>
 <dc:creator>Chuang, Ching-Yao</dc:creator>
 <dc:creator>Liao, Yuan-Hong</dc:creator>
 <dc:creator>Niebles, Juan Carlos</dc:creator>
 <dc:creator>Sun, Min</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  We propose a scalable approach to learn video-based question answering (QA):
answer a &quot;free-form natural language question&quot; about a video content. Our
approach automatically harvests a large number of videos and descriptions
freely available online. Then, a large number of candidate QA pairs are
automatically generated from descriptions rather than manually annotated. Next,
we use these candidate QA pairs to train a number of video-based QA methods
extended fromMN (Sukhbaatar et al. 2015), VQA (Antol et al. 2015), SA (Yao et
al. 2015), SS (Venugopalan et al. 2015). In order to handle non-perfect
candidate QA pairs, we propose a self-paced learning procedure to iteratively
identify them and mitigate their effects in training. Finally, we evaluate
performance on manually generated video-based QA pairs. The results show that
our self-paced learning procedure is effective, and the extended SS model
outperforms various baselines.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures. Accepted to AAAI 2017. Camera-ready version</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2016-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04022</identifier>
 <datestamp>2016-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timestamps for Partial Replication</dc:title>
 <dc:creator>Xiang, Zhuolun</dc:creator>
 <dc:creator>Vaidya, Nitin H.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Maintaining causal consistency in distributed shared memory systems using
vector timestamps has received a lot of attention from both theoretical and
practical prospective. However, most of the previous literature focuses on full
replication where each data is stored in all replicas, which may not be
scalable due to the increasing amount of data. In this report, we investigate
how to achieve causal consistency in partial replicated systems, where each
replica may store different set of data. We propose an algorithm that tracks
causal dependencies via vector timestamp in client-server model for partial
replication. The cost of our algorithm in terms of timestamps size varies as a
function of the manner in which the replicas share data, and the set of
replicas accessed by each client. We also establish a connection between our
algorithm with the previous work on full replication.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2016-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04023</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparsey: Event Recognition via Deep Hierarchical Spare Distributed Codes</dc:title>
 <dc:creator>Rinkus, Gerard J.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68</dc:subject>
 <dc:description>  Visual cortex's hierarchical, multi-level organization is captured in many
biologically inspired computational vision models, the general idea being that
progressively larger scale, more complex spatiotemporal features are
represented in progressively higher areas. However, most earlier models use
localist representations (codes) in each representational field, which we
equate with the cortical macrocolumn (mac), at each level. In localism, each
represented feature/event (item) is coded by a single unit. Our model, Sparsey,
is also hierarchical but crucially, uses sparse distributed coding (SDC) in
every mac in all levels. In SDC, each represented item is coded by a small
subset of the mac's units. SDCs of different items can overlap and the size of
overlap between items can represent their similarity. The difference between
localism and SDC is crucial because SDC allows the two essential operations of
associative memory, storing a new item and retrieving the best-matching stored
item, to be done in fixed time for the life of the model. Since the model's
core algorithm, which does both storage and retrieval (inference), makes a
single pass over all macs on each time step, the overall model's
storage/retrieval operation is also fixed-time, a criterion we consider
essential for scalability to huge datasets. A 2010 paper described a
nonhierarchical version of this model in the context of purely spatial pattern
processing. Here, we elaborate a fully hierarchical model (arbitrary numbers of
levels and macs per level), describing novel model principles like progressive
critical periods, dynamic modulation of principal cells' activation functions
based on a mac-level familiarity measure, representation of multiple
simultaneously active hypotheses, a novel method of time warp invariant
recognition, and we report results showing learning/recognition of
spatiotemporal patterns.
</dc:description>
 <dc:description>Comment: This is a manuscript form of a paper published in Frontiers in
  Computational Neuroscience in 2014
  (http://dx.doi.org/10.3389/fncom.2014.00160). 65 pages, 28 figures, 8 tables</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04023</dc:identifier>
 <dc:identifier>Frontiers in Computational Neuroscience, Vol. 8, Article 160
  (2014)</dc:identifier>
 <dc:identifier>doi:10.3389/fncom.2014.00160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04033</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>1.5 billion words Arabic Corpus</dc:title>
 <dc:creator>El-khair, Ibrahim Abu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This study is an attempt to build a contemporary linguistic corpus for Arabic
language. The corpus produced, is a text corpus includes more than five million
newspaper articles. It contains over a billion and a half words in total, out
of which, there is about three million unique words. The data were collected
from newspaper articles in ten major news sources from eight Arabic countries,
over a period of fourteen years. The corpus was encoded with two types of
encoding, namely: UTF-8, and Windows CP-1256. Also it was marked with two
mark-up languages, namely: SGML, and XML.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04034</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fair Public Decision Making</dc:title>
 <dc:creator>Conitzer, Vincent</dc:creator>
 <dc:creator>Freeman, Rupert</dc:creator>
 <dc:creator>Shah, Nisarg</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We generalize the classic problem of fairly allocating indivisible goods to
the problem of \emph{fair public decision making}, in which a decision must be
made on several social issues simultaneously, and, unlike the classic setting,
a decision can provide positive utility to multiple players. We extend the
popular fairness notion of proportionality (which is not guaranteeable) to our
more general setting, and introduce three novel relaxations ---
\emph{proportionality up to one issue, round robin share, and pessimistic
proportional share} --- that are also interesting in the classic goods
allocation setting. We show that the Maximum Nash Welfare solution, which is
known to satisfy appealing fairness properties in the classic setting,
satisfies or approximates all three relaxations in our framework. We also
provide polynomial time algorithms and hardness results for finding allocations
satisfying these axioms, with or without insisting on Pareto optimality.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04035</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropic Causal Inference</dc:title>
 <dc:creator>Kocaoglu, Murat</dc:creator>
 <dc:creator>Dimakis, Alexandros G.</dc:creator>
 <dc:creator>Vishwanath, Sriram</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of identifying the causal direction between two
discrete random variables using observational data. Unlike previous work, we
keep the most general functional model but make an assumption on the unobserved
exogenous variable: Inspired by Occam's razor, we assume that the exogenous
variable is simple in the true causal direction. We quantify simplicity using
R\'enyi entropy. Our main result is that, under natural assumptions, if the
exogenous variable has low $H_0$ entropy (cardinality) in the true direction,
it must have high $H_0$ entropy in the wrong direction. We establish several
algorithmic hardness results about estimating the minimum entropy exogenous
variable. We show that the problem of finding the exogenous variable with
minimum entropy is equivalent to the problem of finding minimum joint entropy
given $n$ marginal distributions, also known as minimum entropy coupling
problem. We propose an efficient greedy algorithm for the minimum entropy
coupling problem, that for $n=2$ provably finds a local optimum. This gives a
greedy algorithm for finding the exogenous variable with minimum $H_1$ (Shannon
Entropy). Our greedy entropy-based causal inference algorithm has similar
performance to the state of the art additive noise models in real datasets. One
advantage of our approach is that we make no use of the values of random
variables but only their distributions. Our method can therefore be used for
causal inference for both ordinal and also categorical data, unlike additive
noise models.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2017</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04049</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prognostics of Surgical Site Infections using Dynamic Health Data</dc:title>
 <dc:creator>Ke, Chuyang</dc:creator>
 <dc:creator>Jin, Yan</dc:creator>
 <dc:creator>Evans, Heather</dc:creator>
 <dc:creator>Lober, Bill</dc:creator>
 <dc:creator>Qian, Xiaoning</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:creator>Huang, Shuai</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Surgical Site Infection (SSI) is a national priority in healthcare research.
Much research attention has been attracted to develop better SSI risk
prediction models. However, most of the existing SSI risk prediction models are
built on static risk factors such as comorbidities and operative factors. In
this paper, we investigate the use of the dynamic wound data for SSI risk
prediction. There have been emerging mobile health (mHealth) tools that can
closely monitor the patients and generate continuous measurements of many
wound-related variables and other evolving clinical variables. Since existing
prediction models of SSI have quite limited capacity to utilize the evolving
clinical data, we develop the corresponding solution to equip these mHealth
tools with decision-making capabilities for SSI prediction with a seamless
assembly of several machine learning models to tackle the analytic challenges
arising from the spatial-temporal data. The basic idea is to exploit the
low-rank property of the spatial-temporal data via the bilinear formulation,
and further enhance it with automatic missing data imputation by the matrix
completion technique. We derive efficient optimization algorithms to implement
these models and demonstrate the superior performances of our new predictive
model on a real-world dataset of SSI, compared to a range of state-of-the-art
methods.
</dc:description>
 <dc:description>Comment: 23 pages, 8 figures</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04051</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GANS for Sequences of Discrete Elements with the Gumbel-softmax
  Distribution</dc:title>
 <dc:creator>Kusner, Matt J.</dc:creator>
 <dc:creator>Hern&#xe1;ndez-Lobato, Jos&#xe9; Miguel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative Adversarial Networks (GAN) have limitations when the goal is to
generate sequences of discrete elements. The reason for this is that samples
from a distribution on discrete objects such as the multinomial are not
differentiable with respect to the distribution parameters. This problem can be
avoided by using the Gumbel-softmax distribution, which is a continuous
approximation to a multinomial distribution parameterized in terms of the
softmax function. In this work, we evaluate the performance of GANs based on
recurrent neural networks with Gumbel-softmax output distributions in the task
of generating sequences of discrete elements.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04052</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-automatic Simultaneous Interpreting Quality Evaluation</dc:title>
 <dc:creator>Zhang, Xiaojun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Increasing interpreting needs a more objective and automatic measurement. We
hold a basic idea that 'translating means translating meaning' in that we can
assessment interpretation quality by comparing the meaning of the interpreting
output with the source input. That is, a translation unit of a 'chunk' named
Frame which comes from frame semantics and its components named Frame Elements
(FEs) which comes from Frame Net are proposed to explore their matching rate
between target and source texts. A case study in this paper verifies the
usability of semi-automatic graded semantic-scoring measurement for human
simultaneous interpreting and shows how to use frame and FE matches to score.
Experiments results show that the semantic-scoring metrics have a significantly
correlation coefficient with human judgment.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04052</dc:identifier>
 <dc:identifier>International Journal on Natural Language Computing (IJNLC) Vol.
  5, No.5, October 2016</dc:identifier>
 <dc:identifier>doi:10.5121/ijnlc.2016.5501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04059</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Not Only Horses Wear Blinkers: The Missing Perspectives in IS Research</dc:title>
 <dc:creator>Clarke, Roger</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  When we devise a method to address a particular research question, we think
about many things, including the unit of study. But do we think about the
perspective from which we observe whatever it is that's within our field of
view? In the majority of mainstream IS research, one perspective dominates.
Organisations use IS and IT as a means of intervening into a context. And the
behaviour of the phenomena is mostly observed from the viewpoint of those
organisations. Is that viewpoint the only legitimate one for IS research to
adopt? Even if it is, are the clients' interests best served by IS research
that adopts that perspective alone? This paper identifies alternative
perspectives. It draws attention to negative consequences of wearing blinkers
to restrict our field of view, and to opportunities we can grasp by taking off
the blinkers. It proposes that these alternatives need to be defined as being
within the IS discipline rather than outside it.
</dc:description>
 <dc:description>Comment: ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on
  Information Systems 2015 (arXiv:1605.01032)</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04061</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contact activity and dynamics of the online elite</dc:title>
 <dc:creator>Mones, Enys</dc:creator>
 <dc:creator>Stopczynski, Arkadiusz</dc:creator>
 <dc:creator>Lehmann, Sune</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Humans interact through numerous channels to build and maintain social
connections: they meet face-to-face, initiate phone calls or send text
messages, and interact via social media. Although it is known that the network
of physical contacts, for example, is distinct from the network arising from
communication events via phone calls and instant messages, the extent to which
these networks differ is not clear. In fact, the network structure of these
channels shows large structural variations. Each network of interactions,
however, contains both central and peripheral individuals: central members are
characterized by higher connectivity and can reach a high fraction of the
network within a low number of connections, contrary to the nodes on the
periphery. Here we show that the various channels account for diverse
relationships between pairs of individuals and the corresponding interaction
patterns across channels differ to an extent that hinders the simple reduction
of social ties to a single layer. Furthemore, the origin and purpose of each
network also determine the role of their respective central members: highly
connected individuals in the person-to-person networks interact with their
environment in a regular manner, while members central in the social
communication networks display irregular behavior with respect to their
physical contacts and are more active through rare, social events. These
results suggest that due to the inherently different functions of communication
channels, each one favors different social behaviors and different strategies
for interacting with the environment. Our findings can facilitate the
understanding of the varying roles and impact individuals have on the
population, which can further shed light on the prediction and prevention of
epidemic outbreaks, or information propagation.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04069</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-rank and Adaptive Sparse Signal (LASSI) Models for Highly
  Accelerated Dynamic Imaging</dc:title>
 <dc:creator>Ravishankar, Saiprasad</dc:creator>
 <dc:creator>Moore, Brian E.</dc:creator>
 <dc:creator>Nadakuditi, Raj Rao</dc:creator>
 <dc:creator>Fessler, Jeffrey A.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sparsity-based approaches have been popular in many applications in image
processing and imaging. Compressed sensing exploits the sparsity of images in a
transform domain or dictionary to improve image recovery from undersampled
measurements. In the context of inverse problems in dynamic imaging, recent
research has demonstrated the promise of sparsity and low-rank techniques. For
example, the patches of the underlying data are modeled as sparse in an
adaptive dictionary domain, and the resulting image and dictionary estimation
from undersampled measurements is called dictionary-blind compressed sensing,
or the dynamic image sequence is modeled as a sum of low-rank and sparse (in
some transform domain) components (L+S model) that are estimated from limited
measurements. In this work, we investigate a data-adaptive extension of the L+S
model, dubbed LASSI, where the temporal image sequence is decomposed into a
low-rank component and a component whose spatiotemporal (3D) patches are sparse
in some adaptive dictionary domain. We investigate various formulations and
efficient methods for jointly estimating the underlying dynamic signal
components and the spatiotemporal dictionary from limited measurements. We also
obtain efficient sparsity penalized dictionary-blind compressed sensing methods
as special cases of our LASSI approaches. Our numerical experiments demonstrate
the promising performance of LASSI schemes for dynamic magnetic resonance image
reconstruction from limited k-t space data compared to recent methods such as
k-t SLR and L+S, and compared to the proposed dictionary-blind compressed
sensing method.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04074</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Stochastic ADMM with Variance Reduction</dc:title>
 <dc:creator>Zhang, Chao</dc:creator>
 <dc:creator>Shen, Zebang</dc:creator>
 <dc:creator>Qian, Hui</dc:creator>
 <dc:creator>Zhou, Tengfei</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Alternating Direction Method of Multipliers (ADMM) is a popular method in
solving Machine Learning problems. Stochastic ADMM was firstly proposed in
order to reduce the per iteration computational complexity, which is more
suitable for big data problems. Recently, variance reduction techniques have
been integrated with stochastic ADMM in order to get a fast convergence rate,
such as SAG-ADMM and SVRG-ADMM,but the convergence is still suboptimal w.r.t
the smoothness constant. In this paper, we propose a new accelerated stochastic
ADMM algorithm with variance reduction, which enjoys a faster convergence than
all the other stochastic ADMM algorithms. We theoretically analyze its
convergence rate and show its dependence on the smoothness constant is optimal.
We also empirically validate its effectiveness and show its priority over other
stochastic ADMM algorithms.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04076</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Least Squares Generative Adversarial Networks</dc:title>
 <dc:creator>Mao, Xudong</dc:creator>
 <dc:creator>Li, Qing</dc:creator>
 <dc:creator>Xie, Haoran</dc:creator>
 <dc:creator>Lau, Raymond Y. K.</dc:creator>
 <dc:creator>Wang, Zhen</dc:creator>
 <dc:creator>Smolley, Stephen Paul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised learning with generative adversarial networks (GANs) has proven
hugely successful. Regular GANs hypothesize the discriminator as a classifier
with the sigmoid cross entropy loss function. However, we found that this loss
function may lead to the vanishing gradients problem during the learning
process. To overcome such a problem, we propose in this paper the Least Squares
Generative Adversarial Networks (LSGANs) which adopt the least squares loss
function for the discriminator. We show that minimizing the objective function
of LSGAN yields minimizing the Pearson $\chi^2$ divergence. There are two
benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher
quality images than regular GANs. Second, LSGANs perform more stable during the
learning process. We evaluate LSGANs on five scene datasets and the
experimental results show that the images generated by LSGANs are of better
quality than the ones generated by regular GANs. We also conduct two comparison
experiments between LSGANs and regular GANs to illustrate the stability of
LSGANs.
</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2017-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04077</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Reasonable Effectiveness of Agent-Based Simulations in Evolutionary
  Game Theory</dc:title>
 <dc:creator>Adami, Christoph</dc:creator>
 <dc:creator>Schossau, Jory</dc:creator>
 <dc:creator>Hintze, Arend</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  This is a Reply to comments published in Physics of Life Reviews, on our
article &quot;Evolutionary game theory using agent-based methods&quot; (Physics of Life
Reviews, 2016, arXiv:1404.0994).
</dc:description>
 <dc:description>Comment: 5 pages. To appear in Physics of Life Reviews</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04077</dc:identifier>
 <dc:identifier>Physics of Life Reviews 19 (2016) 38-42</dc:identifier>
 <dc:identifier>doi:10.1016/j.plrev.2016.11.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04088</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Batched Gaussian Process Bandit Optimization via Determinantal Point
  Processes</dc:title>
 <dc:creator>Kathuria, Tarun</dc:creator>
 <dc:creator>Deshpande, Amit</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Gaussian Process bandit optimization has emerged as a powerful tool for
optimizing noisy black box functions. One example in machine learning is
hyper-parameter optimization where each evaluation of the target function
requires training a model which may involve days or even weeks of computation.
Most methods for this so-called &quot;Bayesian optimization&quot; only allow sequential
exploration of the parameter space. However, it is often desirable to propose
batches or sets of parameter values to explore simultaneously, especially when
there are large parallel processing facilities at our disposal. Batch methods
require modeling the interaction between the different evaluations in the
batch, which can be expensive in complex scenarios. In this paper, we propose a
new approach for parallelizing Bayesian optimization by modeling the diversity
of a batch via Determinantal point processes (DPPs) whose kernels are learned
automatically. This allows us to generalize a previous result as well as prove
better regret bounds based on DPP sampling. Our experiments on a variety of
synthetic and real-world robotics and hyper-parameter optimization tasks
indicate that our DPP-based methods, especially those based on DPP sampling,
outperform state-of-the-art methods.
</dc:description>
 <dc:description>Comment: To appear at NIPS 2016</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04099</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Industrial Case Study on Measuring the Quality of the Requirements
  Scoping Process</dc:title>
 <dc:creator>Wnuk, Krzysztof</dc:creator>
 <dc:creator>Borg, Markus</dc:creator>
 <dc:creator>Sulaman, Sardar Muhammad</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Decision making and requirements scoping occupy central roles in helping to
develop products that are demanded by the customers and ensuring company
strategies are accurately realized in product scope. Many companies experience
continuous and frequent scope changes and fluctuations but struggle to measure
the phenomena and correlate the measurement to the quality of the requirements
process. We present the results from an exploratory interview study among 22
participants working with requirements management processes at a large company
that develops embedded systems for a global market. Our respondents shared
their opinions about the current set of requirements management process metrics
as well as what additional metrics they envisioned as useful. We present a set
of metrics that describe the quality of the requirements scoping process. The
findings provide practical insights that can be used as input when introducing
new measurement programs for requirements management and decision making.
</dc:description>
 <dc:description>Comment: 8 pages, accepted as short paper at PROFES 2016</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04100</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An FPTAS for Counting Proper Four-Colorings on Cubic Graphs</dc:title>
 <dc:creator>Lu, Pinyan</dc:creator>
 <dc:creator>Yang, Kuan</dc:creator>
 <dc:creator>Zhang, Chihao</dc:creator>
 <dc:creator>Zhu, Minshen</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Graph coloring is arguably the most exhaustively studied problem in the area
of approximate counting. It is conjectured that there is a fully
polynomial-time (randomized) approximation scheme (FPTAS/FPRAS) for counting
the number of proper colorings as long as $q \geq \Delta + 1$, where $q$ is the
number of colors and $\Delta$ is the maximum degree of the graph. The bound of
$q = \Delta + 1$ is the uniqueness threshold for Gibbs measure on
$\Delta$-regular infinite trees. However, the conjecture remained open even for
any fixed $\Delta\geq 3$ (The cases of $\Delta=1, 2$ are trivial). In this
paper, we design an FPTAS for counting the number of proper $4$-colorings on
graphs with maximum degree $3$ and thus confirm the conjecture in the case of
$\Delta=3$. This is the first time to achieve this optimal bound of $q = \Delta
+ 1$. Previously, the best FPRAS requires $q &gt; \frac{11}{6} \Delta$ and the
best deterministic FPTAS requires $q &gt; 2.581\Delta + 1$ for general graphs. In
the case of $\Delta=3$, the best previous result is an FPRAS for counting
proper 5-colorings. We note that there is a barrier to go beyond $q = \Delta +
2$ for single-site Glauber dynamics based FPRAS and we overcome this by
correlation decay approach. Moreover, we develop a number of new techniques for
the correlation decay approach which can find applications in other approximate
counting problems.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04109</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Entropy Region is not Closed Under Duality</dc:title>
 <dc:creator>Kaced, Tarik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We import a duality notion coming from polymatroids to define duality for
information inequalities. We show that the entropy region for $n\ge 5$ is not
closed under duality. Our result answers an open question of Mat\`u\v{s}
(1992).
</dc:description>
 <dc:description>Comment: submitted</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04112</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of coherent quantum cryptography protocol vulnerability to an
  active beam-splitting attack</dc:title>
 <dc:creator>Kronberg, D. A.</dc:creator>
 <dc:creator>Kiktenko, E. O.</dc:creator>
 <dc:creator>Fedorov, A. K.</dc:creator>
 <dc:creator>Kurochkin, Y. V.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a new type of attack on a coherent quantum key distribution
protocol [coherent one-way (COW) protocol]. The main idea of the attack
consists in measuring individually the intercepted states and sending the rest
of them unchanged. We have calculated the optimum values of the attack
parameters for an arbitrary length of a channel length and compared this novel
attack with a standard beam-splitting attack.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures; comments are welcome</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04112</dc:identifier>
 <dc:identifier>Quantum Electron. 47, 163 (2017)</dc:identifier>
 <dc:identifier>doi:10.1070/QEL16240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04120</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WINDOW: Wideband Demodulator for Optical Waveforms</dc:title>
 <dc:creator>Lev, Omri</dc:creator>
 <dc:creator>Wiener, Tal</dc:creator>
 <dc:creator>Cohen, Deborah</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Optical communication systems, which operate at very high rates, are often
limited by the sampling rate bottleneck. The optical wideband regime may exceed
analog to digital converters (ADCs) front-end bandwidth. Multi-channel sampling
approaches, such as multicoset or interleaved ADCs, have been proposed to
sample the wideband signal using several channels. Each channel samples below
the Nyquist rate such that the overall sampling rate is preserved. However,
this scheme suffers from two practical limitations that make its implementation
difficult. First, the inherent anti-aliasing filter of the samplers distorts
the wideband signal. Second, it requires accurate time shifts on the order of
the signal's Nyquist rate, which are challenging to maintain. In this work, we
propose an alternative multi-channel sampling scheme, the wideband demodulator
for optical waveforms (WINDOW), based on analog RF demodulation, where each
channel aliases the spectrum using a periodic mixing function before
integration and sampling. We show that intentionally using the inherent ADC
filter to perform integration increases the signal to noise ratio (SNR). We
demonstrate both theoretically and through numerical experiments that our
system outperforms multicoset in terms of signal recovery and symbol estimation
in the presence of both thermal and quantization noise but is slightly less
robust to timing jitter.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04120</dc:identifier>
 <dc:identifier>doi:10.1364/OE.25.019444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04122</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-lingual Dataless Classification for Languages with Small Wikipedia
  Presence</dc:title>
 <dc:creator>Song, Yangqiu</dc:creator>
 <dc:creator>Mayhew, Stephen</dc:creator>
 <dc:creator>Roth, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents an approach to classify documents in any language into an
English topical label space, without any text categorization training data. The
approach, Cross-Lingual Dataless Document Classification (CLDDC) relies on
mapping the English labels or short category description into a Wikipedia-based
semantic representation, and on the use of the target language Wikipedia.
Consequently, performance could suffer when Wikipedia in the target language is
small. In this paper, we focus on languages with small Wikipedias,
(Small-Wikipedia languages, SWLs). We use a word-level dictionary to convert
documents in a SWL to a large-Wikipedia language (LWLs), and then perform CLDDC
based on the LWL's Wikipedia. This approach can be applied to thousands of
languages, which can be contrasted with machine translation, which is a
supervision heavy approach and can be done for about 100 languages. We also
develop a ranking algorithm that makes use of language similarity metrics to
automatically select a good LWL, and show that this significantly improves
classification of SWLs' documents, performing comparably to the best bridge
possible.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04125</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Representation Learning of Text and Knowledge for Knowledge Graph
  Completion</dc:title>
 <dc:creator>Han, Xu</dc:creator>
 <dc:creator>Liu, Zhiyuan</dc:creator>
 <dc:creator>Sun, Maosong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Joint representation learning of text and knowledge within a unified semantic
space enables us to perform knowledge graph completion more accurately. In this
work, we propose a novel framework to embed words, entities and relations into
the same continuous vector space. In this model, both entity and relation
embeddings are learned by taking knowledge graph and plain text into
consideration. In experiments, we evaluate the joint learning model on three
tasks including entity prediction, relation prediction and relation
classification from text. The experiment results show that our model can
significantly and consistently improve the performance on the three tasks as
compared with other baselines.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04135</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Responses to Critiques on Machine Learning of Criminality Perceptions
  (Addendum of arXiv:1611.04135)</dc:title>
 <dc:creator>Wu, Xiaolin</dc:creator>
 <dc:creator>Zhang, Xi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In November 2016 we submitted to arXiv our paper &quot;Automated Inference on
Criminality Using Face Images&quot;. It generated a great deal of discussions in the
Internet and some media outlets. Our work is only intended for pure academic
discussions; how it has become a media consumption is a total surprise to us.
Although in agreement with our critics on the need and importance of policing
AI research for the general good of the society, we are deeply baffled by the
ways some of them mispresented our work, in particular the motive and objective
of our research.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04138</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hand Gesture Recognition for Contactless Device Control in Operating
  Rooms</dc:title>
 <dc:creator>Nasr-Esfahani, Ebrahim</dc:creator>
 <dc:creator>Karimi, Nader</dc:creator>
 <dc:creator>Soroushmehr, S. M. Reza</dc:creator>
 <dc:creator>Jafari, M. Hossein</dc:creator>
 <dc:creator>Khorsandi, M. Amin</dc:creator>
 <dc:creator>Samavi, Shadrokh</dc:creator>
 <dc:creator>Najarian, Kayvan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hand gesture is one of the most important means of touchless communication
between human and machines. There is a great interest for commanding electronic
equipment in surgery rooms by hand gesture for reducing the time of surgery and
the potential for infection. There are challenges in implementation of a hand
gesture recognition system. It has to fulfill requirements such as high
accuracy and fast response. In this paper we introduce a system of hand gesture
recognition based on a deep learning approach. Deep learning is known as an
accurate detection model, but its high complexity prevents it from being
fabricated as an embedded system. To cope with this problem, we applied some
changes in the structure of our work to achieve low complexity. As a result,
the proposed method could be implemented on a naive embedded system. Our
experiments show that the proposed system results in higher accuracy while
having less complexity in comparison with the existing comparable methods.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04138</dc:identifier>
 <dc:identifier>doi:10.1007/s11548-017-1588-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04144</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Dense 3D Semantic Mapping from Monocular SLAM</dc:title>
 <dc:creator>Li, Xuanpeng</dc:creator>
 <dc:creator>Belaroussi, Rachid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The bundle of geometry and appearance in computer vision has proven to be a
promising solution for robots across a wide variety of applications. Stereo
cameras and RGB-D sensors are widely used to realise fast 3D reconstruction and
trajectory tracking in a dense way. However, they lack flexibility of seamless
switch between different scaled environments, i.e., indoor and outdoor scenes.
In addition, semantic information are still hard to acquire in a 3D mapping. We
address this challenge by combining the state-of-art deep learning method and
semi-dense Simultaneous Localisation and Mapping (SLAM) based on video stream
from a monocular camera. In our approach, 2D semantic information are
transferred to 3D mapping via correspondence between connective Keyframes with
spatial consistency. There is no need to obtain a semantic segmentation for
each frame in a sequence, so that it could achieve a reasonable computation
time. We evaluate our method on indoor/outdoor datasets and lead to an
improvement in the 2D semantic labelling over baseline single frame
predictions.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04145</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation in Wireless Powered Relay Networks: A Bargaining
  Game Approach</dc:title>
 <dc:creator>Zheng, Zijie</dc:creator>
 <dc:creator>Song, Lingyang</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Simultaneously information and power transfer in mobile relay networks have
recently emerged, where the relay can harvest the radio frequency (RF) energy
and then use this energy for data forwarding and system operation. Most of the
previous works do not consider that the relay may have its own objectives, such
as using the harvested energy for its own transmission instead of maximizing
transmission of the network. Therefore, in this paper, we propose a Nash
bargaining approach to balance the information transmission efficiency of
source-destination pairs and the harvested energy of the relay in a wireless
powered relay network with multiple source-destination pairs and one relay. We
analyze and prove that the Nash bargaining problem has several desirable
properties such as the discreteness and quasi-concavity, when it is decomposed
into three sub-problems: the energy transmission power optimization, the power
control for data transmission and the time division between energy transmission
and data transmission. Based on the theoretical analysis, we propose an
alternating power control and time division algorithm to find a suboptimal
solution. Simulation results clearly show and demonstrate the properties of the
problem and the convergence of our algorithm.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures, journal paper</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04146</identifier>
 <datestamp>2016-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Commonsense Knowledge Enhanced Embeddings for Solving Pronoun
  Disambiguation Problems in Winograd Schema Challenge</dc:title>
 <dc:creator>Liu, Quan</dc:creator>
 <dc:creator>Jiang, Hui</dc:creator>
 <dc:creator>Ling, Zhen-Hua</dc:creator>
 <dc:creator>Zhu, Xiaodan</dc:creator>
 <dc:creator>Wei, Si</dc:creator>
 <dc:creator>Hu, Yu</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we propose commonsense knowledge enhanced embeddings (KEE) for
solving the Pronoun Disambiguation Problems (PDP). The PDP task we investigate
in this paper is a complex coreference resolution task which requires the
utilization of commonsense knowledge. This task is a standard first round test
set in the 2016 Winograd Schema Challenge. In this task, traditional linguistic
features that are useful for coreference resolution, e.g. context and gender
information, are no longer effective anymore. Therefore, the KEE models are
proposed to provide a general framework to make use of commonsense knowledge
for solving the PDP problems. Since the PDP task doesn't have training data,
the KEE models would be used during the unsupervised feature extraction
process. To evaluate the effectiveness of the KEE models, we propose to
incorporate various commonsense knowledge bases, including ConceptNet, WordNet,
and CauseCom, into the KEE training process. We achieved the best performance
by applying the proposed methods to the 2016 Winograd Schema Challenge. In
addition, experiments conducted on the standard PDP task indicate that, the
proposed KEE models could solve the PDP problems by achieving 66.7% accuracy,
which is a new state-of-the-art performance.
</dc:description>
 <dc:description>Comment: Winograd Schema Challenge, Pronoun Disambiguation Problems, Neural
  Embedding Methods, Commonsense Knowledge</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2016-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04149</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Variance Reduced Block Coordinate Descent</dc:title>
 <dc:creator>Shen, Zebang</dc:creator>
 <dc:creator>Qian, Hui</dc:creator>
 <dc:creator>Zhang, Chao</dc:creator>
 <dc:creator>Zhou, Tengfei</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Algorithms with fast convergence, small number of data access, and low
per-iteration complexity are particularly favorable in the big data era, due to
the demand for obtaining \emph{highly accurate solutions} to problems with
\emph{a large number of samples} in \emph{ultra-high} dimensional space.
Existing algorithms lack at least one of these qualities, and thus are
inefficient in handling such big data challenge. In this paper, we propose a
method enjoying all these merits with an accelerated convergence rate
$O(\frac{1}{k^2})$. Empirical studies on large scale datasets with more than
one million features are conducted to show the effectiveness of our methods in
practice.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04150</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Based Adaptive Multiple Access in LPWAN IoT Systems with Energy
  Harvesting</dc:title>
 <dc:creator>Michelusi, Nicolo</dc:creator>
 <dc:creator>Levorato, Marco</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper develops a control framework for a network of energy harvesting
nodes connected to a Base Station (BS) over a multiple access channel. The
objective is to adapt their transmission strategy to the state of the network,
including the energy available to the individual nodes. In order to reduce the
complexity of control, an optimization framework is proposed where energy
storage dynamics are replaced by dynamic average power constraints induced by
the time correlated energy supply, thus enabling lightweight and flexible
network control. Specifically, the BS adapts the packet transmission
probability of the &quot;active&quot; nodes (those currently under a favorable energy
harvesting state) so as to maximize the average long-term throughput, under
these dynamic average power constraints. The resulting policy takes the form of
the packet transmission probability as a function of the energy harvesting
state and number of active nodes. The structure of the throughput-optimal
genie-aided policy, in which the number of active nodes is known non-causally
at the BS, is proved. Inspired by the genie-aided policy, a Bayesian estimation
approach is presented to address the case where the BS estimates the number of
active nodes based on the observed network transmission pattern. It is shown
that the proposed scheme outperforms by 20% a scheme in which the nodes operate
based on local state information only, and performs well even when energy
storage dynamics are taken into account.
</dc:description>
 <dc:description>Comment: Submitted to IEEE ISIT 2017</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04156</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Planning system for deliveries in Medell\'in</dc:title>
 <dc:creator>Pati&#xf1;o-Forero, Catalina</dc:creator>
 <dc:creator>Agudelo-Toro, Mateo</dc:creator>
 <dc:creator>Toro, Mauricio</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Here we present the implementation of an application capable of planning the
shortest delivery route in the city of Medell\'in, Colombia. We discuss the
different approaches to this problem which is similar to the famous Traveling
Salesman Problem (TSP), but differs in the fact that, in our problem, we can
visit each place (or vertex) more than once. Solving this problem is important
since it would help people, especially stores with delivering services, to save
time and money spent in fuel, because they can plan any route in an efficient
way.
</dc:description>
 <dc:description>Comment: 5 pages, 9 figures</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04159</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Solutions in Machine Scheduling Games</dc:title>
 <dc:creator>Giessler, Paul</dc:creator>
 <dc:creator>Mamageishvili, Akaki</dc:creator>
 <dc:creator>Mihalak, Matus</dc:creator>
 <dc:creator>Penna, Paolo</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the classical machine scheduling, where n jobs need to be
scheduled on m machines, with the goal of minimizing the makespan, i.e., the
maximum load of any machine in the schedule. We study inefficiency of schedules
that are obtained when jobs arrive sequentially one by one, and choose
themselves the machine on which they will be scheduled. Every job is only
interested to be on a machine with a small load (and does not care about the
loads of other machines). We measure the inefficiency of a schedule as the
ratio of the makespan obtained in the worst-case equilibrium schedule, and of
the optimum makespan. This ratio is known as the sequential price of anarchy.
We also introduce alternative inefficiency measures, which allow for a
favorable choice of the order in which the jobs make their decisions. We first
disprove the conjecture of Hassin and Yovel (OR Letters, 2015) claiming that
for unrelated machines, i.e., for the setting where every job can have a
different processing time on every machine, the sequential price of anarchy for
m = 2 machines is at most 3. We provide an answer for the setting with m = 2
and show that the sequential price of anarchy grows at least linearly with the
number of players. Furthermore, we show that for a certain order of the jobs,
the resulting makespan is at most linearly larger than the optimum makespan.
Furthermore, we show that if an authority can change the order of the jobs
adaptively to the decisions made by the jobs so far (but cannot influence the
decisions of the jobs), then there exists an adaptive ordering in which the
jobs end up in an optimum schedule. To the end we consider identical machines,
i.e., the setting where every job has the same processing time on every
machine, and provide matching lower bound examples to the existing upper bounds
on the sequential price of anarchy.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04167</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A parallel workload has extreme variability</dc:title>
 <dc:creator>Henwood, R.</dc:creator>
 <dc:creator>Watkins, N. W.</dc:creator>
 <dc:creator>Chapman, S. C.</dc:creator>
 <dc:creator>McLay, R.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  In both high-performance computing (HPC) environments and the public cloud,
the duration of time to retrieve or save your results is simultaneously
unpredictable and important to your over all resource budget. It is generally
accepted (&quot;Google: Taming the Long Latency Tail - When More Machines Equals
Worse Results&quot;, Todd Hoff, highscalability.com 2012), but without a robust
explanation, that identical parallel tasks do take different durations to
complete -- a phenomena known as variability. This paper advances understanding
of this topic. We carefully choose a model from which system-level complexity
emerges that can be studied directly. We find that a generalized extreme value
(GEV) model for variability naturally emerges. Using the public cloud, we find
real-world observations have excellent agreement with our model. Since the GEV
distribution is a limit distribution this suggests a universal property of
parallel systems gated by the slowest communication element of some sort.
Hence, this model is applicable to a variety of processing and IO tasks in
parallel environments. These findings have important implications, ranging from
characterizing ideal performance for parallel codes to detecting degraded
behaviour at extreme scales.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures, 1 code listing</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04175</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognizing and Eliciting Weakly Single Crossing Profiles on Trees</dc:title>
 <dc:creator>Dey, Palash</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The domain of single crossing preference profiles is a widely studied domain
in social choice theory. It has been generalized to the domain of single
crossing preference profiles with respect to trees which inherits many
desirable properties from the single crossing domain, for example, transitivity
of majority relation, existence of polynomial time algorithms for finding
winners of Kemeny voting rule, etc. In this paper, we consider a further
generalization of the domain of single crossing profiles on trees to the domain
consisting of all preference profiles which can be extended to single crossing
preference profiles with respect to some tree by adding more preferences to it.
We call this domain the weakly single crossing domain on trees. We present a
polynomial time algorithm for recognizing weakly single crossing profiles on
trees. We then move on to develop a polynomial time algorithm with low query
complexity for eliciting weakly single crossing profiles on trees even when we
do not know any tree with respect to which the closure of the input profile is
single crossing and the preferences can be queried only sequentially; moreover,
the sequential order is also unknown. We complement the performance of our
preference elicitation algorithm by proving that our algorithm makes an optimal
number of queries up to constant factors when the number of preferences is
large compared to the number of candidates, even if the input profile is known
to be single crossing with respect to some given tree and the preferences can
be accessed randomly.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04178</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the $\mathcal{NP}$-hardness of GRacSim Drawing and k-SEFE Problems</dc:title>
 <dc:creator>Grilli, Luca</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the complexity of two problems in simultaneous graph drawing. The
first problem, GRacSim Drawing, asks for finding a simultaneous geometric
embedding of two graphs such that only crossings at right angles are allowed.
The second problem, k-SEFE, is a restricted version of the topological
simultaneous embedding with fixed edges (SEFE) problem, for two planar graphs,
in which every private edge may receive at most $k$ crossings, where $k$ is a
prescribed positive integer. We show that GRacSim Drawing is
$\mathcal{NP}$-hard and that k-SEFE is $\mathcal{NP}$-complete. The
$\mathcal{NP}$-hardness of both problems is proved using two similar reductions
from 3-Partition.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04180</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Gather Information via Imitation</dc:title>
 <dc:creator>Choudhury, Sanjiban</dc:creator>
 <dc:creator>Kapoor, Ashish</dc:creator>
 <dc:creator>Ranade, Gireeja</dc:creator>
 <dc:creator>Dey, Debadeepta</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The budgeted information gathering problem - where a robot with a fixed fuel
budget is required to maximize the amount of information gathered from the
world - appears in practice across a wide range of applications in autonomous
exploration and inspection with mobile robots. Although there is an extensive
amount of prior work investigating effective approximations of the problem,
these methods do not address the fact that their performance is heavily
dependent on distribution of objects in the world. In this paper, we attempt to
address this issue by proposing a novel data-driven imitation learning
framework.
  We present an efficient algorithm, EXPLORE, that trains a policy on the
target distribution to imitate a clairvoyant oracle - an oracle that has full
information about the world and computes non-myopic solutions to maximize
information gathered. We validate the approach on a spectrum of results on a
number of 2D and 3D exploration problems that demonstrates the ability of
EXPLORE to adapt to different object distributions. Additionally, our analysis
provides theoretical insight into the behavior of EXPLORE. Our approach paves
the way forward for efficiently applying data-driven methods to the domain of
information gathering.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04181</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Logic Properly Displayed</dc:title>
 <dc:creator>Greco, Giuseppe</dc:creator>
 <dc:creator>Palmigiano, Alessandra</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  We introduce proper display calculi for intuitionistic, bi-intuitionistic and
classical linear logics with exponentials, which are sound, complete,
conservative, and enjoy cut-elimination and subformula property. Based on the
same design, we introduce a variant of Lambek calculus with exponentials, aimed
at capturing the controlled application of exchange and associativity.
Properness (i.e. closure under uniform substitution of all parametric parts in
rules) is the main interest and added value of the present proposal, and allows
for the smoothest proof of cut-elimination. Our proposal builds on an algebraic
and order-theoretic analysis of linear logic, and applies the guidelines of the
multi-type methodology in the design of display calculi.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04192</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A power consensus algorithm for DC microgrids</dc:title>
 <dc:creator>De Persis, Claudio</dc:creator>
 <dc:creator>Weitenberg, Erik</dc:creator>
 <dc:creator>Dorfler, Florian</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A novel power consensus algorithm for DC microgrids is proposed and analyzed.
DC microgrids are networks composed of DC sources, loads, and interconnecting
lines. They are represented by differential-algebraic equations connected over
an undirected weighted graph that models the electrical circuit. A second graph
represents the communication network over which the source nodes exchange
information about the instantaneous powers, which is used to adjust the
injected current accordingly. This give rise to a nonlinear consensus-like
system of differential-algebraic equations that is analyzed via Lyapunov
functions inspired by the physics of the system. We establish convergence to
the set of equilibria consisting of weighted consensus power vectors as well as
preservation of the weighted geometric mean of the source voltages. The results
apply to networks with constant impedance, constant current and constant power
loads.
</dc:description>
 <dc:description>Comment: Abridged version submitted to the 20th IFAC World Congress, Toulouse,
  France</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04196</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Calibration and Bilinear Inverse Problems via Linear Least Squares</dc:title>
 <dc:creator>Ling, Shuyang</dc:creator>
 <dc:creator>Strohmer, Thomas</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Whenever we use devices to take measurements, calibration is indispensable.
While the purpose of calibration is to reduce bias and uncertainty in the
measurements, it can be quite difficult, expensive, and sometimes even
impossible to implement. We study a challenging problem called
\emph{self-calibration}, i.e., the task of designing an algorithm for devices
so that the algorithm is able to perform calibration automatically. More
precisely, we consider the setup $\boldsymbol{y} = \mathcal{A}(\boldsymbol{d})
\boldsymbol{x} + \boldsymbol{\epsilon}$ where only partial information about
the sensing matrix $\mathcal{A}(\boldsymbol{d})$ is known and where
$\mathcal{A}(\boldsymbol{d})$ linearly depends on $\boldsymbol{d}$. The goal is
to estimate the calibration parameter $\boldsymbol{d}$ (resolve the uncertainty
in the sensing process) and the signal/object of interests $\boldsymbol{x}$
simultaneously. For three different models of practical relevance, we show how
such a \emph{bilinear} inverse problem, including blind deconvolution as an
important example, can be solved via a simple \emph{linear least squares}
approach. As a consequence, the proposed algorithms are numerically extremely
efficient, thus potentially allowing for real-time deployment. We also present
a variation of the least squares approach, which leads to a~\emph{spectral
method}, where the solution to the bilinear inverse problem can be found by
computing the singular vector associated with the smallest singular value of a
certain matrix derived from the bilinear system. Explicit theoretical
guarantees and stability theory are derived for both techniques; and the number
of sampling complexity is nearly optimal (up to a poly-log factor).
Applications in imaging sciences and signal processing are discussed and
numerical simulations are presented to demonstrate the effectiveness and
efficiency of our approach.
</dc:description>
 <dc:description>Comment: Accepted to SIAM Journal on Imaging Sciences</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04199</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realistic risk-mitigating recommendations via inverse classification</dc:title>
 <dc:creator>Lash, Michael T.</dc:creator>
 <dc:creator>Street, W. Nick</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Inverse classification, the process of making meaningful perturbations to a
test point such that it is more likely to have a desired classification, has
previously been addressed using data from a single static point in time. Such
an approach yields inflated probability estimates, stemming from an implicitly
made assumption that recommendations are implemented instantaneously. We
propose using longitudinal data to alleviate such issues in two ways. First, we
use past outcome probabilities as features in the present. Use of such past
probabilities ties historical behavior to the present, allowing for more
information to be taken into account when making initial probability estimates
and subsequently performing inverse classification. Secondly, following inverse
classification application, optimized instances' unchangeable features
(e.g.,~age) are updated using values from the next longitudinal time period.
Optimized test instance probabilities are then reassessed. Updating the
unchangeable features in this manner reflects the notion that improvements in
outcome likelihood, which result from following the inverse classification
recommendations, do not materialize instantaneously. As our experiments
demonstrate, more realistic estimates of probability can be obtained by
factoring in such considerations.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04201</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CAD2RL: Real Single-Image Flight without a Single Real Image</dc:title>
 <dc:creator>Sadeghi, Fereshteh</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Deep reinforcement learning has emerged as a promising and powerful technique
for automatically acquiring control policies that can process raw sensory
inputs, such as images, and perform complex behaviors. However, extending deep
RL to real-world robotic tasks has proven challenging, particularly in
safety-critical domains such as autonomous flight, where a trial-and-error
learning process is often impractical. In this paper, we explore the following
question: can we train vision-based navigation policies entirely in simulation,
and then transfer them into the real world to achieve real-world flight without
a single real training image? We propose a learning method that we call
CAD$^2$RL, which can be used to perform collision-free indoor flight in the
real world while being trained entirely on 3D CAD models. Our method uses
single RGB images from a monocular camera, without needing to explicitly
reconstruct the 3D geometry of the environment or perform explicit motion
planning. Our learned collision avoidance policy is represented by a deep
convolutional neural network that directly processes raw monocular images and
outputs velocity commands. This policy is trained entirely on simulated images,
with a Monte Carlo policy evaluation algorithm that directly optimizes the
network's ability to produce collision-free flight. By highly randomizing the
rendering settings for our simulated training set, we show that we can train a
policy that generalizes to the real world, without requiring the simulator to
be particularly realistic or high-fidelity. We evaluate our method by flying a
real quadrotor through indoor environments, and further evaluate the design
choices in our simulator through a series of ablation studies on depth
prediction. For supplementary video see: https://youtu.be/nXBWmzFrj5s
</dc:description>
 <dc:description>Comment: To appear at Robotics: Science and Systems Conference (R:SS), 2017.
  Supplementary video: https://www.youtube.com/watch?v=nXBWmzFrj5s</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04203</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Polarization and Finite-Length Scaling for Non-Stationary Channels</dc:title>
 <dc:creator>Mahdavifar, Hessam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of polar coding for transmission over a
non-stationary sequence of independent binary-input memoryless symmetric (BMS)
channels $\left\{W_i\right\}_{i=1}^{\infty}$, where the $i$-th encoded bit is
transmitted over $W_i$. We show, for the first time, a polar coding scheme that
achieves the effective average symmetric capacity $$
\overline{I}(\left\{W_i\right\}_{i=1}^{\infty}) \ := \lim_{N\rightarrow \infty}
\frac{1}{N}\sum_{i=1}^N I(W_i), $$ assuming that the limit exists. The polar
coding scheme is constructed using Ar{\i}kan's channel polarization
transformation in combination with certain permutations at each polarization
level and certain skipped operations. This guarantees a fast polarization
process that results in polar coding schemes with block lengths upper bounded
by a polynomial of $1/\epsilon$, where $\epsilon$ is the gap to the average
capacity. More specifically, given an arbitrary sequence of BMS channels
$\left\{W_i\right\}_{i=1}^{N}$ and $P_e$, where $0 &lt; P_e &lt;1$, we construct a
polar code of length $N$ and rate $R$ guaranteeing a block error probability of
at most $P_e$ for transmission over $\left\{W_i\right\}_{i=1}^{N}$ such that $$
N \leq \frac{\kappa}{(\overline{I}_N - R)^{\mu}} $$ where $\mu$ is a constant,
$\kappa$ is a constant depending on $P_e$ and $\mu$, and $\overline{I}_N$ is
the average of the symmetric capacities $I(W_i)$, for $i=1,2,,\dots,N$. We
further show a numerical upper bound on $\mu$ that is: $\mu \leq 10.78$. The
encoding and decoding complexities of the constructed polar code preserves $O(N
\log N)$ complexity of Ar{\i}kan's polar codes.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04209</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotically Optimal Amplifiers for the Moran Process</dc:title>
 <dc:creator>Goldberg, Leslie Ann</dc:creator>
 <dc:creator>Lapinskas, John</dc:creator>
 <dc:creator>Lengler, Johannes</dc:creator>
 <dc:creator>Meier, Florian</dc:creator>
 <dc:creator>Panagiotou, Konstantinos</dc:creator>
 <dc:creator>Pfister, Pascal</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  We study the Moran process as adapted by Lieberman, Hauert and Nowak. This is
a model of an evolving population on a graph where certain individuals, called
&quot;mutants&quot; have fitness r and other individuals, called &quot;non-mutants&quot; have
fitness 1. We focus on the situation where the mutation is advantageous, in the
sense that r &gt; 1. A family of directed graphs is said to be strongly amplifying
if the extinction probability tends to 0 when the Moran process is run on
graphs in this family. The most-amplifying known family of directed graphs is
the family of megastars of Galanis et al. We show that this family is optimal,
up to logarithmic factors, since every strongly-connected n-vertex digraph has
extinction probability Omega(n^(-1/2)). Next, we show that there is an infinite
family of undirected graphs, called dense incubators, whose extinction
probability is O(n^(-1/3)). We show that this is optimal, up to constant
factors. Finally, we introduce sparse incubators, for varying edge density, and
show that the extinction probability of these graphs is O(n/m), where m is the
number of edges. Again, we show that this is optimal, up to constant factors.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04211</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Location Hiding in Distributed Systems</dc:title>
 <dc:creator>Gotfryd, Karol</dc:creator>
 <dc:creator>Klonowski, Marek</dc:creator>
 <dc:creator>Paj&#x105;k, Dominik</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider the following problem - a group of mobile agents perform some
task on a terrain modeled as a graph. In a given moment of time an adversary
gets an access to the graph and positions of the agents. Shortly before
adversary's observation the mobile agents have a chance to relocate themselves
in order to hide their initial configuration. We assume that the initial
configuration may possibly reveal to the adversary some information about the
task they performed. Clearly agents have to change their location in possibly
short time using minimal energy. In our paper we introduce a definition of a
\emph{well hiding} algorithm in which the starting and final configurations of
the agents have small mutual information. Then we discuss the influence of
various features of the model on the running time of the optimal well-hiding
algorithm. We show that if the topology of the graph is known to the agents,
then the number of steps proportional to the diameter of the graph is
sufficient and necessary. In the unknown topology scenario we only consider a
single agent case. We first show that the task is impossible in the
deterministic case if the agent has no memory. Then we present a polynomial
randomized algorithm. Finally in the model with memory we show that the number
of steps proportional to the number of edges of the graph is sufficient and
necessary. In some sense we investigate how complex is the problem of &quot;losing&quot;
information about location (both physical and logical) for different settings.
</dc:description>
 <dc:description>Comment: Submitted to 10th International Conference on Algorithms and
  Complexity CIAC 2017</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04212</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Millimeter Wave Beam Alignment: Large Deviations Analysis and Design
  Insights</dc:title>
 <dc:creator>Liu, Chunshan</dc:creator>
 <dc:creator>Li, Min</dc:creator>
 <dc:creator>Hanly, Stephen V.</dc:creator>
 <dc:creator>Collings, Iain B.</dc:creator>
 <dc:creator>Whiting, Philip</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In millimeter wave cellular communication, fast and reliable beam alignment
via beam training is crucial to harvest sufficient beamforming gain for the
subsequent data transmission. In this paper, we establish fundamental limits in
beam-alignment performance under both the exhaustive search and the
hierarchical search that adopts multi-resolution beamforming codebooks,
accounting for time-domain training overhead. Specifically, we derive lower and
upper bounds on the probability of misalignment for an arbitrary level in the
hierarchical search, based on a single-path channel model. Using the method of
large deviations, we characterize the decay rate functions of both bounds and
show that the bounds coincide as the training sequence length goes large. We go
on to characterize the asymptotic misalignment probability of both the
hierarchical and exhaustive search, and show that the latter asymptotically
outperforms the former, subject to the same training overhead and codebook
resolution. We show via numerical results that this relative performance
behavior holds in the non-asymptotic regime. Moreover, the exhaustive search is
shown to achieve significantly higher worst-case spectrum efficiency than the
hierarchical search, when the pre-beamforming signal-to-noise ratio (SNR) is
relatively low. This study hence implies that the exhaustive search is more
effective for users situated further from base stations, as they tend to have
low SNR.
</dc:description>
 <dc:description>Comment: Author final manuscript, to appear in IEEE Journal on Selected Areas
  in Communications (JSAC), Special Issue on Millimeter Wave Communications for
  Future Mobile Networks, 2017 (corresponding author: Min Li)</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04212</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2699360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04213</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Optimal Placement Delivery Arrays</dc:title>
 <dc:creator>Cheng, Minquan</dc:creator>
 <dc:creator>Jiang, Jing</dc:creator>
 <dc:creator>Yan, Qifa</dc:creator>
 <dc:creator>Tang, Xiaohu</dc:creator>
 <dc:creator>Cao, Haitao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In wireless networks, coded caching is an effective technique to reduce
network congestion during peak traffic times. Recently, a new concept called
placement delivery array (PDA) was proposed to characterize the coded caching
scheme. So far, only one class of PDAs by Maddah-Ali and Niesen is known to be
optimal. In this paper, we mainly focus on constructing optimal PDAs. Firstly,
we derive some lower bounds. Next, we present several infinite classes of PDAs,
which are shown to be optimal with respect to the new bounds.
</dc:description>
 <dc:description>Comment: 13pages, Coded caching scheme, placement delivery array, lower bound,
  optimal</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04215</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Regression for Visual Tracking</dc:title>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:creator>Tao, Wenbing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, discriminatively learned correlation filters (DCF) has drawn much
attention in visual object tracking community. The success of DCF is
potentially attributed to the fact that a large amount of samples are utilized
to train the ridge regression model and predict the location of object. To
solve the regression problem in an efficient way, these samples are all
generated by circularly shifting from a search patch. However, these synthetic
samples also induce some negative effects which weaken the robustness of DCF
based trackers.
  In this paper, we propose a Convolutional Regression framework for visual
tracking (CRT). Instead of learning the linear regression model in a closed
form, we try to solve the regression problem by optimizing a one-channel-output
convolution layer with Gradient Descent (GD). In particular, the receptive
field size of the convolution layer is set to the size of object. Contrary to
DCF, it is possible to incorporate all &quot;real&quot; samples clipped from the whole
image. A critical issue of the GD approach is that most of the convolutional
samples are negative and the contribution of positive samples will be
suppressed. To address this problem, we propose a novel Automatic Hard Negative
Mining method to eliminate easy negatives and enhance positives. Extensive
experiments are conducted on a widely-used benchmark with 100 sequences. The
results show that the proposed algorithm achieves outstanding performance and
outperforms almost all the existing DCF based algorithms.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04216</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ghosts of Deletions Past: New Secure Deletion Challenges and Solutions</dc:title>
 <dc:creator>Diesburg, Sarah M.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.2</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  Is secure deletion of data still a problem?
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, pre-print</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04218</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preference Completion from Partial Rankings</dc:title>
 <dc:creator>Gunasekar, Suriya</dc:creator>
 <dc:creator>Koyejo, Oluwasanmi</dc:creator>
 <dc:creator>Ghosh, Joydeep</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a novel and efficient algorithm for the collaborative preference
completion problem, which involves jointly estimating individualized rankings
for a set of entities over a shared set of items, based on a limited number of
observed affinity values. Our approach exploits the observation that while
preferences are often recorded as numerical scores, the predictive quantity of
interest is the underlying rankings. Thus, attempts to closely match the
recorded scores may lead to overfitting and impair generalization performance.
Instead, we propose an estimator that directly fits the underlying preference
order, combined with nuclear norm constraints to encourage low--rank
parameters. Besides (approximate) correctness of the ranking order, the
proposed estimator makes no generative assumption on the numerical scores of
the observations. One consequence is that the proposed estimator can fit any
consistent partial ranking over a subset of the items represented as a directed
acyclic graph (DAG), generalizing standard techniques that can only fit
preference scores. Despite this generality, for supervision representing total
or blockwise total orders, the computational complexity of our algorithm is
within a $\log$ factor of the standard algorithms for nuclear norm
regularization based estimates for matrix completion. We further show promising
empirical results for a novel and challenging application of collaboratively
ranking of the associations between brain--regions and cognitive neuroscience
terms.
</dc:description>
 <dc:description>Comment: NIPS 2016</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04224</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BDMA for Millimeter-Wave/Terahertz Massive MIMO Transmission with
  Per-Beam Synchronization</dc:title>
 <dc:creator>You, Li</dc:creator>
 <dc:creator>Gao, Xiqi</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:creator>Xia, Xiang-Gen</dc:creator>
 <dc:creator>Ma, Ni</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose beam division multiple access (BDMA) with per-beam synchronization
(PBS) in time and frequency for wideband massive multiple-input multiple-output
(MIMO) transmission over millimeter-wave (mmW)/Terahertz (THz) bands. We first
introduce a physically motivated beam domain channel model for massive MIMO and
demonstrate that the envelopes of the beam domain channel elements tend to be
independent of time and frequency when both the numbers of antennas at base
station and user terminals (UTs) tend to infinity. Motivated by the derived
beam domain channel properties, we then propose PBS for mmW/THz massive MIMO.
We show that both the effective delay and Doppler frequency spreads of wideband
massive MIMO channels with PBS are reduced by a factor of the number of UT
antennas compared with the conventional synchronization approaches.
Subsequently, we apply PBS to BDMA, investigate beam scheduling to maximize the
achievable ergodic rates for both uplink and downlink BDMA, and develop a
greedy beam scheduling algorithm. Simulation results verify the effectiveness
of BDMA with PBS for mmW/THz wideband massive MIMO systems in typical mobility
scenarios.
</dc:description>
 <dc:description>Comment: 29 pages, 4 figures</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04224</dc:identifier>
 <dc:identifier>IEEE Journal on Selected Areas in Communications, vol. 35, no. 7,
  pp. 1550-1563 (Jul. 2017)</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2699100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04226</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An algebraic framework for end-to-end physical-layer network coding</dc:title>
 <dc:creator>Gorla, Elisa</dc:creator>
 <dc:creator>Ravagnani, Alberto</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:description>  We propose an algebraic setup for end-to-end physical-layer network coding
based on submodule transmission. We introduce a distance function between
modules, describe how it relates to information loss and errors, and show how
to compute it. Then we propose a definition of submodule error-correcting code,
and investigate bounds and constructions for such codes.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04227</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Consensus-Based Network Intrusion Detection in Presence of
  Byzantine Attacks</dc:title>
 <dc:creator>Toulouse, Michel</dc:creator>
 <dc:creator>Le, Hai</dc:creator>
 <dc:creator>Phung, Cao Vien</dc:creator>
 <dc:creator>Hock, Denis</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Consensus algorithms provide strategies to solve problems in a distributed
system with the added constraint that data can only be shared between adjacent
computing nodes. We find these algorithms in applications for wireless and
sensor networks, spectrum sensing for cognitive radio, even for some IoT
services. However, consensus-based applications are not resilient to
compromised nodes sending falsified data to their neighbors, i.e. they can be
the target of Byzantine attacks. Several solutions have been proposed in the
literature inspired from reputation based systems, outlier detection or
model-based fault detection techniques in process control. We have reviewed
some of these solutions, and propose two mitigation techniques to protect the
consensus-based Network Intrusion Detection System in
\cite{toulouse2015consensus}. We analyze several implementation issues such as
computational overhead, fine tuning of the solution parameters, impacts on the
convergence of the consensus phase, accuracy of the intrusion detection system.
</dc:description>
 <dc:description>Comment: The seventh international symposium of information and communication
  technology</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04228</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Sparse, Distributed Representations using the Hebbian Principle</dc:title>
 <dc:creator>Wadhwa, Aseem</dc:creator>
 <dc:creator>Madhow, Upamanyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The &quot;fire together, wire together&quot; Hebbian model is a central principle for
learning in neuroscience, but surprisingly, it has found limited applicability
in modern machine learning. In this paper, we take a first step towards
bridging this gap, by developing flavors of competitive Hebbian learning which
produce sparse, distributed neural codes using online adaptation with minimal
tuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning
(AHL). We illustrate the distributed nature of the learned representations via
output entropy computations for synthetic data, and demonstrate superior
performance, compared to standard alternatives such as autoencoders, in
training a deep convolutional net on standard image datasets.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04230</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SummaRuNNer: A Recurrent Neural Network based Sequence Model for
  Extractive Summarization of Documents</dc:title>
 <dc:creator>Nallapati, Ramesh</dc:creator>
 <dc:creator>Zhai, Feifei</dc:creator>
 <dc:creator>Zhou, Bowen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present SummaRuNNer, a Recurrent Neural Network (RNN) based sequence model
for extractive summarization of documents and show that it achieves performance
better than or comparable to state-of-the-art. Our model has the additional
advantage of being very interpretable, since it allows visualization of its
predictions broken up by abstract features such as information content,
salience and novelty. Another novel contribution of our work is abstractive
training of our extractive model that can train on human generated reference
summaries alone, eliminating the need for sentence-level extractive labels.
</dc:description>
 <dc:description>Comment: Published at AAAI 2017, The Thirty-First AAAI Conference on
  Artificial Intelligence (AAAI-2017)</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04231</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identity Matters in Deep Learning</dc:title>
 <dc:creator>Hardt, Moritz</dc:creator>
 <dc:creator>Ma, Tengyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  An emerging design principle in deep learning is that each layer of a deep
artificial neural network should be able to easily express the identity
transformation. This idea not only motivated various normalization techniques,
such as \emph{batch normalization}, but was also key to the immense success of
\emph{residual networks}.
  In this work, we put the principle of \emph{identity parameterization} on a
more solid theoretical footing alongside further empirical progress. We first
give a strikingly simple proof that arbitrarily deep linear residual networks
have no spurious local optima. The same result for linear feed-forward networks
in their standard parameterization is substantially more delicate. Second, we
show that residual networks with ReLu activations have universal finite-sample
expressivity in the sense that the network can represent any function of its
sample provided that the model has more parameters than the sample size.
  Directly inspired by our theory, we experiment with a radically simple
residual architecture consisting of only residual convolutional layers and ReLu
activations, but no batch normalization, dropout, or max pool. Our model
improves significantly on previous all-convolutional networks on the CIFAR10,
CIFAR100, and ImageNet classification benchmarks.
</dc:description>
 <dc:description>Comment: fixed minor errors in the previous version</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2016-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04233</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Recurrent Neural CRF for Learning Non-linear Edge Features</dc:title>
 <dc:creator>Ma, Shuming</dc:creator>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Conditional Random Field (CRF) and recurrent neural models have achieved
success in structured prediction. More recently, there is a marriage of CRF and
recurrent neural models, so that we can gain from both non-linear dense
features and globally normalized CRF objective. These recurrent neural CRF
models mainly focus on encode node features in CRF undirected graphs. However,
edge features prove important to CRF in structured prediction. In this work, we
introduce a new recurrent neural CRF model, which learns non-linear edge
features, and thus makes non-linear features encoded completely. We compare our
model with different neural models in well-known structured prediction tasks.
Experiments show that our model outperforms state-of-the-art methods in NP
chunking, shallow parsing, Chinese word segmentation and POS tagging.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04234</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>F-Score Driven Max Margin Neural Network for Named Entity Recognition in
  Chinese Social Media</dc:title>
 <dc:creator>He, Hangfeng</dc:creator>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We focus on named entity recognition (NER) for Chinese social media. With
massive unlabeled text and quite limited labelled corpus, we propose a
semi-supervised learning model based on B-LSTM neural network. To take
advantage of traditional methods in NER such as CRF, we combine transition
probability with deep learning in our model. To bridge the gap between label
accuracy and F-score of NER, we construct a model which can be directly trained
on F-score. When considering the instability of F-score driven method and
meaningful information provided by label accuracy, we propose an integrated
method to train on both F-score and label accuracy. Our integrated model yields
7.44\% improvement over previous state-of-the-art result.
</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04235</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sub-channel and Power Allocation for Non-orthogonal Multiple Access
  Relay Networks with Amplify-and-Forward Protocol</dc:title>
 <dc:creator>Zhang, Shuhang</dc:creator>
 <dc:creator>Di, Boya</dc:creator>
 <dc:creator>Song, Lingyang</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the resource allocation problem for a single-cell
non-orthogonal multiple access (NOMA) relay network where an OFDM
amplify-and-forward (AF) relay allocates the spectrum and power resources to
the source-destination (SD) pairs. We aim to optimize the resource allocation
to maximize the average sum-rate. The optimal approach requires an exhaustive
search, leading to an NP-hard problem. To solve this problem, we propose two
efficient many-to-many two-sided SD pair-subchannel matching algorithms in
which the SD pairs and sub-channels are considered as two sets of players
chasing their own interests. The proposed algorithms can provide a sub-optimal
solution to this resource allocation problem in affordable time. Both the
static matching algorithm and dynamic matching algorithm converge to a
pair-wise stable matching after a limited number of iterations. Simulation
results show that the capacity of both proposed algorithms in the NOMA scheme
significantly outperforms the conventional orthogonal multiple access scheme.
The proposed matching algorithms in NOMA scheme also achieve a better
user-fairness performance than the conventional orthogonal multiple access.
</dc:description>
 <dc:description>Comment: 30 pages, 6 figures, submit to Tran. Wireless Commun</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04244</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classify or Select: Neural Architectures for Extractive Document
  Summarization</dc:title>
 <dc:creator>Nallapati, Ramesh</dc:creator>
 <dc:creator>Zhou, Bowen</dc:creator>
 <dc:creator>Ma, Mingbo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present two novel and contrasting Recurrent Neural Network (RNN) based
architectures for extractive summarization of documents. The Classifier based
architecture sequentially accepts or rejects each sentence in the original
document order for its membership in the final summary. The Selector
architecture, on the other hand, is free to pick one sentence at a time in any
arbitrary order to piece together the summary. Our models under both
architectures jointly capture the notions of salience and redundancy of
sentences. In addition, these models have the advantage of being very
interpretable, since they allow visualization of their predictions broken up by
abstract features such as information content, salience and redundancy. We show
that our models reach or outperform state-of-the-art supervised models on two
different corpora. We also recommend the conditions under which one
architecture is superior to the other based on experimental evidence.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1611.04230</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04246</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Growing Interpretable Part Graphs on ConvNets via Multi-Shot Learning</dc:title>
 <dc:creator>Zhang, Quanshi</dc:creator>
 <dc:creator>Cao, Ruiming</dc:creator>
 <dc:creator>Wu, Ying Nian</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a learning strategy that extracts object-part concepts
from a pre-trained convolutional neural network (CNN), in an attempt to 1)
explore explicit semantics hidden in CNN units and 2) gradually grow a
semantically interpretable graphical model on the pre-trained CNN for
hierarchical object understanding. Given part annotations on very few (e.g.,
3-12) objects, our method mines certain latent patterns from the pre-trained
CNN and associates them with different semantic parts. We use a four-layer
And-Or graph to organize the mined latent patterns, so as to clarify their
internal semantic hierarchy. Our method is guided by a small number of part
annotations, and it achieves superior performance (about 13%-107% improvement)
in part center prediction on the PASCAL VOC and ImageNet datasets.
</dc:description>
 <dc:description>Comment: in the Thirty-First AAAI Conference on Artificial Intelligence
  (AAAI-17)</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:date>2017-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04251</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Baseline CNN structure analysis for facial expression recognition</dc:title>
 <dc:creator>Shin, Minchul</dc:creator>
 <dc:creator>Kim, Munsang</dc:creator>
 <dc:creator>Kwon, Dong-Soo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a baseline convolutional neural network (CNN) structure and image
preprocessing methodology to improve facial expression recognition algorithm
using CNN. To analyze the most efficient network structure, we investigated
four network structures that are known to show good performance in facial
expression recognition. Moreover, we also investigated the effect of input
image preprocessing methods. Five types of data input (raw, histogram
equalization, isotropic smoothing, diffusion-based normalization, difference of
Gaussian) were tested, and the accuracy was compared. We trained 20 different
CNN models (4 networks x 5 data input types) and verified the performance of
each network with test images from five different databases. The experiment
result showed that a three-layer structure consisting of a simple convolutional
and a max pooling layer with histogram equalization image input was the most
efficient. We describe the detailed training procedure and analyze the result
of the test accuracy based on considerable observation.
</dc:description>
 <dc:description>Comment: 6 pages, RO-MAN2016 Conference</dc:description>
 <dc:date>2016-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04254</identifier>
 <datestamp>2017-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Information Privacy for the Internet of Things</dc:title>
 <dc:creator>Sun, Meng</dc:creator>
 <dc:creator>Tay, Wee Peng</dc:creator>
 <dc:creator>He, Xin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In an Internet of Things network, multiple sensors send information to a
fusion center for it to infer a public hypothesis of interest. However, the
same sensor information may be used by the fusion center to make inferences of
a private nature that the sensors wish to protect. To model this, we adopt a
decentralized hypothesis testing framework with binary public and private
hypotheses. Each sensor makes a private observation and utilizes a local sensor
decision rule or privacy mapping to summarize that observation independently of
the other sensors. The local decision made by a sensor is then sent to the
fusion center. Without assuming knowledge of the joint distribution of the
sensor observations and hypotheses, we adopt a nonparametric learning approach
to design local privacy mappings. We introduce the concept of an empirical
normalized risk, which provides a theoretical guarantee for the network to
achieve information privacy for the private hypothesis with high probability
when the number of training samples is large. We develop iterative optimization
algorithms to determine an appropriate privacy threshold and the best sensor
privacy mappings, and show that they converge. Finally, we extend our approach
to the case of a private multiple hypothesis. Numerical results on both
synthetic and real data sets suggest that our proposed approach yields low
error rates for inferring the public hypothesis, but high error rates for
detecting the private hypothesis.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, submitted to IEEE transaction on signal
  processing</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04255</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Communications in Training Large Scale Neural Networks</dc:title>
 <dc:creator>Wang, Linnan</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:creator>Bosilca, George</dc:creator>
 <dc:creator>Vuduc, Richard</dc:creator>
 <dc:creator>Xu, Zenglin</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider the problem of how to reduce the cost of communication that is
required for the parallel training of a neural network. The state-of-the-art
method, Bulk Synchronous Parallel Stochastic Gradient Descent (BSP-SGD),
requires many collective communication operations, like broadcasts of
parameters or reductions for sub-gradient aggregations, which for large
messages quickly dominates overall execution time and limits parallel
scalability. To address this problem, we develop a new technique for collective
operations, referred to as Linear Pipelining (LP). It is tuned to the message
sizes that arise in BSP-SGD, and works effectively on multi-GPU systems.
Theoretically, the cost of LP is invariant to $P$, where $P$ is the number of
GPUs, while the cost of more conventional Minimum Spanning Tree (MST) scales
like $O(\log P)$. LP also demonstrate up to 2x faster bandwidth than
Bidirectional Exchange (BE) techniques that are widely adopted by current MPI
implementations. We apply these collectives to BSP-SGD, showing that the
proposed implementations reduce communication bottlenecks in practice while
preserving the attractive convergence properties of BSP-SGD.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to a crucial sign
  error in equation 1</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04256</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A linear-time benchmarking tool for generalized surface codes</dc:title>
 <dc:creator>Delfosse, Nicolas</dc:creator>
 <dc:creator>Iyer, Pavithran</dc:creator>
 <dc:creator>Poulin, David</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Quantum information processors need to be protected against errors and
faults. One of the most widely considered fault-tolerant architecture is based
on surface codes. While the general principles of these codes are well
understood and basic code properties such as minimum distance and rate are easy
to characterize, a code's average performance depends on the detailed geometric
layout of the qubits. To date, optimizing a surface code architecture and
comparing different geometric layouts relies on costly numerical simulations.
Here, we propose a benchmarking algorithm for simulating the performance of
surface codes, and generalizations thereof, that runs in linear time. We
implemented this algorithm in a software that generates performance reports and
allows to quickly compare different architectures.
</dc:description>
 <dc:description>Comment: Software available online: http://quantum-squab.com</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04268</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AntMonitor: A System for On-Device Mobile Network Monitoring and its
  Applications</dc:title>
 <dc:creator>Shuba, Anastasia</dc:creator>
 <dc:creator>Le, Anh</dc:creator>
 <dc:creator>Alimpertis, Emmanouil</dc:creator>
 <dc:creator>Gjoka, Minas</dc:creator>
 <dc:creator>Markopoulou, Athina</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we present a complete system for on-device passive monitoring,
collection, and analysis of fine grained, large-scale packet measurements from
mobile devices. First, we describe the design and implementation of AntMonitor
as a userspace mobile app based on a VPN-service but only on the device
(without the need to route through a remote VPN server) and using only the
minimum resources required. We evaluate our prototype and show that it
significantly outperforms prior state-of-the-art approaches: it achieves
throughput of over 90 Mbps downlink and 65 Mbps uplink, which is 2x and 8x
faster than mobile-only baselines and is 94% of the throughput without VPN,
while using 2-12x less energy. Second, we show that AntMonitor is uniquely
positioned to serve as a platform for passive on-device mobile network
monitoring and to enable a number of applications, including: (i) real-time
detection and prevention of private information leakage from the device to the
network; (ii) passive network performance monitoring; and (iii) application
classification and user profiling. We showcase preliminary results from a pilot
user study at a university campus.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04273</identifier>
 <datestamp>2017-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Quantitative Analysis of Decoder-Based Generative Models</dc:title>
 <dc:creator>Wu, Yuhuai</dc:creator>
 <dc:creator>Burda, Yuri</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:creator>Grosse, Roger</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The past several years have seen remarkable progress in generative models
which produce convincing samples of images and other modalities. A shared
component of many powerful generative models is a decoder network, a parametric
deep neural net that defines a generative distribution. Examples include
variational autoencoders, generative adversarial networks, and generative
moment matching networks. Unfortunately, it can be difficult to quantify the
performance of these models because of the intractability of log-likelihood
estimation, and inspecting samples can be misleading. We propose to use
Annealed Importance Sampling for evaluating log-likelihoods for decoder-based
models and validate its accuracy using bidirectional Monte Carlo. The
evaluation code is provided at https://github.com/tonywu95/eval_gen. Using this
technique, we analyze the performance of decoder-based models, the
effectiveness of existing log-likelihood estimators, the degree of overfitting,
and the degree to which these models miss important modes of the data
distribution.
</dc:description>
 <dc:description>Comment: Accepted to ICLR2017</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04276</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Byzantine Processors and Cuckoo Birds: Confining Maliciousness to the
  Outset</dc:title>
 <dc:creator>Dolev, Danny</dc:creator>
 <dc:creator>Gafni, Eli</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.4.7</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:description>  Are there Byzantine Animals? A Fooling Behavior is exhibited by the Cuckoo
bird. It sneakily replaces some of the eggs of other species with its own. Lest
the Cuckoo extinct itself by destroying its host, it self-limits its power: It
does not replace too large a fraction of the eggs. Here, we show that any
Byzantine Behavior that does not destroy the system it attacks, i.e. allows the
system to solve an easy task like epsilon-agreement, then its maliciousness can
be confined to be the exact replica of the Cuckoo bird behavior: Undetectably
replace an input of a processor and let the processor behave correctly
thereafter with respect to the new input. In doing so we reduce the study of
Byzantine behavior to fail-stop (benign) behavior with the Cuckoo caveat of a
fraction of the inputs replaced. We establish a complete correspondence between
the Byzantine and the Benign, modulo different thresholds, and replaced inputs.
This work is yet another step in a line of work unifying seemingly distinct
distributed system models, dispelling the Myth that Distributed Computing is a
plethora of distinct isolated models, each requiring its specialized tools and
ideas in order to determine solvability of tasks. Thus, hereafter, Byzantine
Computability questions can be reduced to questions in the benign failure
setting. We also show that the known results about correlated faults in the
asynchronous benign setting can be imported verbatim to the asynchronous
Byzantine setting. Finally, as in the benign case in which we have the property
that a processor can output once its faulty behavior stops for long enough, we
show this can be done in a similar manner in the Byzantine case. This
necessitated the generalization of Reliable Broadcast to what we term
Recoverable Reliable Broadcast.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1607.01210</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04278</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting 802.11 for User Fairness and Efficient Channel Utilization in
  Presence of LTE-U</dc:title>
 <dc:creator>Baswade, Anand M.</dc:creator>
 <dc:creator>Atif, Touheed Anwar</dc:creator>
 <dc:creator>Tamma, Bheemarjuna Reddy</dc:creator>
 <dc:creator>A, Antony Franklin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A promising solution satisfying the industry's demand to have minimum
alterations in LTE for its operation in unlicensed spectrum is duty cycled
LTE-U scheme, which adopts discontinuous transmission to ensure fair
coexistence with 802.11 (Wi-Fi) WLANs. Even though the scheme guarantees to
maintain Wi-Fi network performance, the fairness among Wi-Fi users still
remains arcane. In this work, we present a practical scenario where LTE-U,
despite being discontinuous (by following an ON-OFF cycle), results in not only
unfair throughput distribution among Wi-Fi users but also causes degradation in
Wi-Fi APs downlink performance. This is due to the domination of few Wi-Fi
users who harness channel in both ON and OFF durations of LTE-U, namely
non-victim users over those who get access only in OFF duration, called victim
users. In this paper, we studied the performance of victim and non-victim Wi-Fi
users, and Wi-Fi AP while varying LTE-U ON duration (i.e., duty cycle). A
propitious scheme is proposed for WLANs, with regard to ease of implementation,
employing Point Coordination Function (PCF) mode of 802.11, promising fairness
among Wi-Fi users with improvement in the channel utilization of Wi-Fi network.
An analytical model is developed to demonstrate guaranteed improvement and
validate the simulation results.
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures, submitted to IEEE ICC 2017</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04279</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chromatic number of ISK4-free graphs</dc:title>
 <dc:creator>Le, Ngoc Khang</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A graph $G$ is said to be ISK4-free if it does not contain any subdivision of
$K_4$ as an induced subgraph. In this paper, we propose new upper bounds for
chromatic number of ISK4-free graphs and $\{$ISK4, triangle$\}$-free graphs.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04288</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Web-based Data Imputation with Graph Model</dc:title>
 <dc:creator>Tang, Yiwen</dc:creator>
 <dc:creator>Wang, Hongzhi</dc:creator>
 <dc:creator>Zhang, Shiwei</dc:creator>
 <dc:creator>Zhang, Huijun</dc:creator>
 <dc:creator>Shi, Ruoxi</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  A challenge for data imputation is the lack of knowledge. In this paper, we
attempt to address this challenge by involving extra knowledge from web. To
achieve high-performance web-based imputation, we use the dependency, i.e.FDs
and CFDs, to impute as many as possible values automatically and fill in the
other missing values with the minimal access of web, whose cost is relatively
large. To make sufficient use of dependencies, We model the dependency set on
the data as a graph and perform automatical imputation and keywords generation
for web-based imputation based on such graph model. With the generated
keywords, we design two algorithms to extract values for imputation from the
search results. Extensive experimental results based on real-world data
collections show that the proposed approach could impute missing values
efficiently and effectively compared to existing approach.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04298</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A DNN Framework For Text Image Rectification From Planar Transformations</dc:title>
 <dc:creator>Yan, Chengzhe</dc:creator>
 <dc:creator>Hu, Jie</dc:creator>
 <dc:creator>Zhang, Changshui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a novel neural network architecture is proposed attempting to
rectify text images with mild assumptions. A new dataset of text images is
collected to verify our model and open to public. We explored the capability of
deep neural network in learning geometric transformation and found the model
could segment the text image without explicit supervised segmentation
information. Experiments show the architecture proposed can restore planar
transformations with wonderful robustness and effectiveness.
</dc:description>
 <dc:description>Comment: 9 pages, 10 figures</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04308</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncertain Graph Sparsification</dc:title>
 <dc:creator>Parchas, Panos</dc:creator>
 <dc:creator>Papailiou, Nikolaos</dc:creator>
 <dc:creator>Papadias, Dimitris</dc:creator>
 <dc:creator>Bonchi, Francesco</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Uncertain graphs are prevalent in several applications including
communications systems, biological databases and social networks. The ever
increasing size of the underlying data renders both graph storage and query
processing extremely expensive. Sparsification has often been used to reduce
the size of deterministic graphs by maintaining only the important edges.
However, adaptation of deterministic sparsification methods fails in the
uncertain setting. To overcome this problem, we introduce the first
sparsification techniques aimed explicitly at uncertain graphs. The proposed
methods reduce the number of edges and redistribute their probabilities in
order to decrease the graph size, while preserving its underlying structure.
The resulting graph can be used to efficiently and accurately approximate any
query and mining tasks on the original graph. An extensive experimental
evaluation with real and synthetic datasets illustrates the effectiveness of
our techniques on several common graph tasks, including clustering coefficient,
page rank, reliability and shortest path distance.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04324</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ILP formulations for the two-stage stochastic Steiner tree problem</dc:title>
 <dc:creator>Zey, Bernd</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We give an overview of new and existing cut- and flow-based ILP formulations
for the two-stage stochastic Steiner tree problem and compare the strength of
the LP relaxations.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04326</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>`Who would have thought of that!': A Hierarchical Topic Model for
  Extraction of Sarcasm-prevalent Topics and Sarcasm Detection</dc:title>
 <dc:creator>Joshi, Aditya</dc:creator>
 <dc:creator>Jain, Prayas</dc:creator>
 <dc:creator>Bhattacharyya, Pushpak</dc:creator>
 <dc:creator>Carman, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Topic Models have been reported to be beneficial for aspect-based sentiment
analysis. This paper reports a simple topic model for sarcasm detection, a
first, to the best of our knowledge. Designed on the basis of the intuition
that sarcastic tweets are likely to have a mixture of words of both sentiments
as against tweets with literal sentiment (either positive or negative), our
hierarchical topic model discovers sarcasm-prevalent topics and topic-level
sentiment. Using a dataset of tweets labeled using hashtags, the model
estimates topic-level, and sentiment-level distributions. Our evaluation shows
that topics such as `work', `gun laws', `weather' are sarcasm-prevalent topics.
Our model is also able to discover the mixture of sentiment-bearing words that
exist in a text of a given sentiment-related label. Finally, we apply our model
to predict sarcasm in tweets. We outperform two prior work based on statistical
classifiers with specific features, by around 25\%.
</dc:description>
 <dc:description>Comment: This version of the paper contains corrected changes, after the
  camera -ready submission. These changes were observed based on an issue in
  the output returned by SVM Perf. This paper will be presented at ExPROM
  workshop at COLING 2016</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04330</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Experimental Design for Path-following Performance Assessment
  of Unmanned Vehicles</dc:title>
 <dc:creator>Saggini, Eleonora</dc:creator>
 <dc:creator>Riccomagno, Eva</dc:creator>
 <dc:creator>Caccia, Massimo</dc:creator>
 <dc:creator>Wynn, Henry P.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  The definition of Good Experimental Methodologies (GEMs) in robotics is a
topic of widespread interest due also to the increasing employment of robots in
everyday civilian life. The present work contributes to the ongoing discussion
on GEMs for Unmanned Surface Vehicles (USVs). It focuses on the definition of
GEMs and provides specific guidelines for path-following experiments.
Statistically designed experiments (DoE) offer a valid basis for developing an
empirical model of the system being investigated. A two-step adaptive
experimental procedure for evaluating path-following performance and based on
DoE, is tested on the simulator of the Charlie USV. The paper argues the
necessity of performing extensive simulations prior to the execution of field
trials.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04333</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fisher Information Framework for Time Series Modeling</dc:title>
 <dc:creator>Venkatesan, R. C.</dc:creator>
 <dc:creator>Plastino, A.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  A robust prediction model invoking the Takens embedding theorem, whose
\textit{working hypothesis} is obtained via an inference procedure based on the
minimum Fisher information principle, is presented. The coefficients of the
ansatz, central to the \textit{working hypothesis} satisfy a time independent
Schr\&quot;{o}dinger-like equation in a vector setting. The inference of i) the
probability density function of the coefficients of the \textit{working
hypothesis} and ii) the establishing of constraint driven pseudo-inverse
condition for the modeling phase of the prediction scheme, is made, for the
case of normal distributions, with the aid of the quantum mechanical virial
theorem. The well-known reciprocity relations and the associated Legendre
transform structure for the Fisher information measure (FIM, hereafter)-based
model in a vector setting (with least square constraints) are self-consistently
derived. These relations are demonstrated to yield an intriguing form of the
FIM for the modeling phase, which defines the \textit{working hypothesis},
solely in terms of the observed data. Cases for prediction employing time
series' obtained from the: $(i)$ the Mackey-Glass delay-differential equation,
$(ii)$ one ECG sample from the MIT-Beth Israel Deaconess Hospital (MIT-BIH)
cardiac arrhythmia database, and $(iii)$ one ECG from the Creighton University
ventricular tachyarrhythmia database. The ECG samples were obtained from the
Physionet online repository. These examples demonstrate the efficiency of the
prediction model. Numerical examples for exemplary cases are provided.
</dc:description>
 <dc:description>Comment: 30 pages, 8 figures. Minor typographical and syntactical changes
  made. Eqs. (57)-(61) in Version 1 specialized to the case of \alpha=1 to be
  consistent with Eq. (56). Fig.'s 3, 5, 7, and 8 enlarged to enable better
  visual coherence. Missing labels added to Fig.'s 3 and 4</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04333</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2017.02.076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04341</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting generalized Reed-Solomon codes</dc:title>
 <dc:creator>Beelen, Peter</dc:creator>
 <dc:creator>Glynn, David</dc:creator>
 <dc:creator>H&#xf8;holdt, Tom</dc:creator>
 <dc:creator>Kaipa, Krishna</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this article we count the number of generalized Reed-Solomon (GRS) codes
of dimension k and length n, including the codes coming from a non-degenerate
conic plus nucleus. We compare our results with known formulae for the number
of 3-dimensional MDS codes of length n=6,7,8,9.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04349</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds and Constructions for $\overline{3}$-Strongly Separable Codes
  with Length $3$</dc:title>
 <dc:creator>Zhang, Xuli</dc:creator>
 <dc:creator>Jiang, Jing</dc:creator>
 <dc:creator>Cheng, Minquan</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  As separable code (SC, IEEE Trans Inf Theory 57:4843-4851, 2011) and
frameproof code (FPC, IEEE Trans Inf Theory 44:1897-1905, 1998) do in
multimedia fingerprinting, strongly separable code (SSC, Des. Codes and
Cryptogr.79:303-318, 2016) can be also used to construct anti-collusion codes.
Furthermore, SSC is better than FPC and SC in the applications for multimedia
fingerprinting since SSC has lower tracing complexity than that of SC (the same
complexity as FPC) and weaker structure than that of FPC. In this paper, we
first derive several upper bounds on the number of codewords of
$\overline{t}$-SSC. Then we focus on $\overline{3}$-SSC with codeword length
$3$, and obtain the following two main results: (1) An equivalence between an
SSC and an SC. %Consequently a more tighter upper bound $(3q^2/4)$ and lower
bound $(q^{3/2})$ on the number of codewords are obtained; (2) An improved
lower bound $\Omega (q^{5/3}+q^{4/3}-q)$ on the size of a $q$-ary SSC when
$q=q_1^6$ for any prime power $q_1\equiv\ 1 \pmod 6$, better than the before
known bound $\lfloor\sqrt{q}\rfloor^{3}$, which is obtained by means of
difference matrix and the known result on the subset of $\mathbb{F}^{n}_q$
containing no three points on a line.
</dc:description>
 <dc:description>Comment: 17 pages, separable codes, strongly separable codes,submitted to
  Cryptography and Communications</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04353</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Herding Generalizes Diverse M -Best Solutions</dc:title>
 <dc:creator>Ozkan, Ece</dc:creator>
 <dc:creator>Roig, Gemma</dc:creator>
 <dc:creator>Goksel, Orcun</dc:creator>
 <dc:creator>Boix, Xavier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We show that the algorithm to extract diverse M -solutions from a Conditional
Random Field (called divMbest [1]) takes exactly the form of a Herding
procedure [2], i.e. a deterministic dynamical system that produces a sequence
of hypotheses that respect a set of observed moment constraints. This
generalization enables us to invoke properties of Herding that show that
divMbest enforces implausible constraints which may yield wrong assumptions for
some problem settings. Our experiments in semantic segmentation demonstrate
that seeing divMbest as an instance of Herding leads to better alternatives for
the implausible constraints of divMbest.
</dc:description>
 <dc:description>Comment: 8 pages, 2 algorithms, 3 figures</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04357</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selfie Detection by Synergy-Constraint Based Convolutional Neural
  Network</dc:title>
 <dc:creator>Annadani, Yashas</dc:creator>
 <dc:creator>Naganoor, Vijayakrishna</dc:creator>
 <dc:creator>Jagadish, Akshay Kumar</dc:creator>
 <dc:creator>Chemmangat, Krishnan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Categorisation of huge amount of data on the multimedia platform is a crucial
task. In this work, we propose a novel approach to address the subtle problem
of selfie detection for image database segregation on the web, given rapid rise
in number of selfies clicked. A Convolutional Neural Network (CNN) is modeled
to learn a synergy feature in the common subspace of head and shoulder
orientation, derived from Local Binary Pattern (LBP) and Histogram of Oriented
Gradients (HOG) features respectively. This synergy was captured by projecting
the aforementioned features using Canonical Correlation Analysis (CCA). We show
that the resulting network's convolutional activations in the neighbourhood of
spatial keypoints captured by SIFT are discriminative for selfie-detection. In
general, proposed approach aids in capturing intricacies present in the image
data and has the potential for usage in other subtle image analysis scenarios
apart from just selfie detection. We investigate and analyse the performance of
popular CNN architectures (GoogleNet, AlexNet), used for other image
classification tasks, when subjected to the task of detecting the selfies on
the multimedia platform. The results of the proposed approach are compared with
these popular architectures on a dataset of ninety thousand images comprising
of roughly equal number of selfies and non-selfies. Experimental results on
this dataset shows the effectiveness of the proposed approach.
</dc:description>
 <dc:description>Comment: 8 Pages, Accepted for Publication at IEEE SITIS 2016</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04358</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Character-level Convolutional Network for Text Classification Applied to
  Chinese Corpus</dc:title>
 <dc:creator>Huang, Weijie</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This article provides an interesting exploration of character-level
convolutional neural network solving Chinese corpus text classification
problem. We constructed a large-scale Chinese language dataset, and the result
shows that character-level convolutional neural network works better on Chinese
corpus than its corresponding pinyin format dataset. This is the first time
that character-level convolutional neural network applied to text
classification problem.
</dc:description>
 <dc:description>Comment: MSc Thesis, 44 pages</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04359</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gray Box Identification of State-Space Models Using Difference of Convex
  Programming</dc:title>
 <dc:creator>Yu, Chengpu</dc:creator>
 <dc:creator>Ljung, Lennart</dc:creator>
 <dc:creator>Verhaegen, Michel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Gray-box identification is prevalent in modeling physical and networked
systems. However, due to the non-convex nature of the gray-box identification
problem, good initial parameter estimates are crucial for a successful
application. In this paper, a new identification method is proposed by
exploiting the low-rank and structured Hankel matrix of impulse response. This
identification problem is recasted into a difference-of-convex programming
problem, which is then solved by the sequential convex programming approach
with the associated initialization obtained by nuclear-norm optimization. The
presented method aims to achieve the maximum impulse-response fitting while not
requiring additional (non-convex) conditions to secure non-singularity of the
similarity transformation relating the given state-space matrices to the
gray-box parameterized ones. This overcomes a persistent shortcoming in a
number of recent contributions on this topic, and the new method can be applied
for the structured state-space realization even if the involved system
parameters are unidentifiable. The method can be used both for directly
estimating the gray-box parameters and for providing initial parameter
estimates for further iterative search in a conventional gray-box
identification setup.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04361</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attending to Characters in Neural Sequence Labeling Models</dc:title>
 <dc:creator>Rei, Marek</dc:creator>
 <dc:creator>Crichton, Gamal K. O.</dc:creator>
 <dc:creator>Pyysalo, Sampo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Sequence labeling architectures use word embeddings for capturing similarity,
but suffer when handling previously unseen or rare words. We investigate
character-level extensions to such models and propose a novel architecture for
combining alternative word representations. By using an attention mechanism,
the model is able to dynamically decide how much information to use from a
word- or character-level component. We evaluated different architectures on a
range of sequence labeling datasets, and character-level extensions were found
to improve performance on every benchmark. In addition, the proposed
attention-based architecture delivered the best results even with a smaller
number of trainable parameters.
</dc:description>
 <dc:description>Comment: Proceedings of COLING 2016</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04363</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning for Expertise Matching with Declination Prediction</dc:title>
 <dc:creator>Qian, Yujie</dc:creator>
 <dc:creator>Tang, Jie</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We study the problem of finding appropriate experts who are able to complete
timely reviews and would not say &quot;no&quot; to the invitation. The problem is a
central issue in many question-and-answer systems, but has received little
research attention. Different from most existing studies that focus on
expertise matching, we want to further predict the expert's response: given a
question, how can we find the expert who is able to provide a quality review
and will agree to do it. We formalize the problem as a ranking problem. We
first present an embedding-based question-to-expert distance metric for
expertise matching and propose a ranking factor graph (RankFG) model to predict
expert response. For online evaluation, we developed a Chrome Extension for
reviewer recommendation and deployed it in the Google Chrome Web Store, and
then collected the reviewers' feedback. We also used the review bidding of a CS
conference for evaluation. In the experiments, the proposed method demonstrates
its superiority (+6.6-21.2% by MAP) over several state-of-the-art algorithms.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04366</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Decentralized Event-Triggered Control Strategies for
  Cyber-Physical Systems</dc:title>
 <dc:creator>Kartakis, Sokratis</dc:creator>
 <dc:creator>Fu, Anqi</dc:creator>
 <dc:creator>Mazo Jr., Manuel</dc:creator>
 <dc:creator>McCann, Julie A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Energy constraint long-range wireless sensor/ actuator based solutions are
theoretically the perfect choice to support the next generation of city-scale
cyber-physical systems. Traditional systems adopt periodic control which
increases network congestion and actuations while burdens the energy
consumption. Recent control theory studies overcome these problems by
introducing aperiodic strategies, such as event trigger control. In spite of
the potential savings, these strategies assume actuator continuous listening
while ignoring the sensing energy costs. In this paper, we fill this gap, by
enabling sensing and actuator listening duty-cycling and proposing two
innovative MAC protocols for three decentralized event trigger control
approaches. A laboratory experimental testbed, which emulates a smart water
network, was modelled and extended to evaluate the impact of system parameters
and the performance of each approach. Experimental results reveal the
predominance of the decentralized event-triggered control against the classic
periodic control either in terms of communication or actuation by promising
significant system lifetime extension.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04369</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Engineering and Ensemble Modeling for Paper Acceptance Rank
  Prediction</dc:title>
 <dc:creator>Qian, Yujie</dc:creator>
 <dc:creator>Dong, Yinpeng</dc:creator>
 <dc:creator>Ma, Ye</dc:creator>
 <dc:creator>Jin, Hailong</dc:creator>
 <dc:creator>Li, Juanzi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Measuring research impact and ranking academic achievement are important and
challenging problems. Having an objective picture of research institution is
particularly valuable for students, parents and funding agencies, and also
attracts attention from government and industry. KDD Cup 2016 proposes the
paper acceptance rank prediction task, in which the participants are asked to
rank the importance of institutions based on predicting how many of their
papers will be accepted at the 8 top conferences in computer science. In our
work, we adopt a three-step feature engineering method, including basic
features definition, finding similar conferences to enhance the feature set,
and dimension reduction using PCA. We propose three ranking models and the
ensemble methods for combining such models. Our experiment verifies the
effectiveness of our approach. In KDD Cup 2016, we achieved the overall rank of
the 2nd place.
</dc:description>
 <dc:description>Comment: 2nd place winner report of KDD Cup 2016. More details can be found at
  https://kddcup2016.azurewebsites.net</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04394</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Efficiency and Delay Tradeoff of 10GBase-T Energy Efficient
  Ethernet Protocol</dc:title>
 <dc:creator>Pan, Xiaodan</dc:creator>
 <dc:creator>Ye, Tong</dc:creator>
 <dc:creator>Lee, Tony T.</dc:creator>
 <dc:creator>Hu, Weisheng</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we study the power efficiency and delay performance of the
IEEE 802.3az Energy Efficient Ethernet (EEE) protocol. A new approach is
proposed to analyze the M/G/1 queue with the vacation time that is governed by
the arrival process and the parameter {\tau} and N of the BTR strategy. Our key
idea is to establish the connection between the vacation time and the arrival
process to account for their dependency. We first derive the distribution of
the number of arrivals during a vacation time based on an event tree of the BTR
strategy, from which we obtain the mean vacation time and the power efficiency.
Next, from the condition on the number of arrivals at the end of a vacation
period, we derive a generalized P-K formula of the mean delay for EEE systems,
and prove that the classical P-K formula of the vacation model is only a
special case when the vacation time is independent of the arrival process. Our
analysis demonstrates that the {\tau} policy and N policy of the BTR strategy
are compensating each other. The {\tau} policy ensures the frame delay is
bounded when the traffic load is light, while the N policy ensures the queue
length at the end of vacation is bounded when the traffic load is heavy. These
results, in turn, provide the rules to select appropriate {\tau} and N. Our
analytical results are confirmed by simulations.
</dc:description>
 <dc:description>Comment: 12 pages,8 figure</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04399</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Graph Decomposition and Node Labeling: Problem, Algorithms,
  Applications</dc:title>
 <dc:creator>Levinkov, Evgeny</dc:creator>
 <dc:creator>Uhrig, Jonas</dc:creator>
 <dc:creator>Tang, Siyu</dc:creator>
 <dc:creator>Omran, Mohamed</dc:creator>
 <dc:creator>Insafutdinov, Eldar</dc:creator>
 <dc:creator>Kirillov, Alexander</dc:creator>
 <dc:creator>Rother, Carsten</dc:creator>
 <dc:creator>Brox, Thomas</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:creator>Andres, Bjoern</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We state a combinatorial optimization problem whose feasible solutions define
both a decomposition and a node labeling of a given graph. This problem offers
a common mathematical abstraction of seemingly unrelated computer vision tasks,
including instance-separating semantic segmentation, articulated human body
pose estimation and multiple object tracking. Conceptually, the problem we
state generalizes the unconstrained integer quadratic program and the minimum
cost lifted multicut problem, both of which are NP-hard. In order to find
feasible solutions efficiently, we define two local search algorithms that
converge monotonously to a local optimum, offering a feasible solution at any
time. To demonstrate their effectiveness in tackling computer vision tasks, we
apply these algorithms to instances of the problem that we construct from
published data, using published algorithms. We report state-of-the-art
application-specific accuracy for the three above-mentioned applications.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04407</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fair and Throughput-Optimal Routing in Multi-Modal Underwater Networks</dc:title>
 <dc:creator>Diamant, Roee</dc:creator>
 <dc:creator>Casari, Paolo</dc:creator>
 <dc:creator>Campagnaro, Filippo</dc:creator>
 <dc:creator>Kebkal, Oleksiy</dc:creator>
 <dc:creator>Kebkal, Veronika</dc:creator>
 <dc:creator>Zorzi, Michele</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  While acoustic communications have been considered the prominent technology
to communicate under water for several years, other technologies are being
developed based, e.g., on optical and radio-frequency electro-magnetic waves.
Each technology has its own advantages and drawbacks: for example, acoustic
signals achieve long communication ranges at order-of-kbit/s bit rate, whereas
optical signals offer order-of-Mbit/s transmission rates but only over short
transmitter--receiver distances. Such a technological diversity can be
leveraged by multi-modal systems, which integrate different technologies and
provide intelligence to decide which one should be used at any given time. In
this paper, we address a fundamental part of this intelligence by proposing a
novel routing protocol for networks of multi-modal nodes. The protocol makes
distributed decisions about the flow in each link and over each technology at
any given time, in order to advance a packet towards its destination. Our
routing protocol prevents bottlenecks and allocates resources fairly to
different nodes. We analyze the performance of our protocol via simulations and
in a field experiment. The results show that our protocol successfully
leverages all technologies to deliver data, even in the presence of imperfect
topology information. To permit the reproduction of our results, we share our
simulation code.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04413</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic discovery of discriminative parts as a quadratic assignment
  problem</dc:title>
 <dc:creator>Sicre, Ronan</dc:creator>
 <dc:creator>Rabin, Julien</dc:creator>
 <dc:creator>Avrithis, Yannis</dc:creator>
 <dc:creator>Furon, Teddy</dc:creator>
 <dc:creator>Jurie, Frederic</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Part-based image classification consists in representing categories by small
sets of discriminative parts upon which a representation of the images is
built. This paper addresses the question of how to automatically learn such
parts from a set of labeled training images. The training of parts is cast as a
quadratic assignment problem in which optimal correspondences between image
regions and parts are automatically learned. The paper analyses different
assignment strategies and thoroughly evaluates them on two public datasets:
Willow actions and MIT 67 scenes. State-of-the art results are obtained on
these datasets.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04414</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Cancellation at Receivers in Cache-Enabled Wireless
  Networks</dc:title>
 <dc:creator>Yang, Chenchen</dc:creator>
 <dc:creator>Yao, Yao</dc:creator>
 <dc:creator>Xia, Bin</dc:creator>
 <dc:creator>Huang, Kaibin</dc:creator>
 <dc:creator>Xie, Weiliang</dc:creator>
 <dc:creator>Zhao, Yong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose to exploit the limited cache packets as side
information to cancel incoming interference at the receiver side. We consider a
stochastic network where the random locations of base stations and users are
modeled using Poisson point processes. Caching schemes to reap both the local
caching gain and the interference cancellation gain for the users are developed
based on two factors: the density of different user subsets and the packets
cached in the corresponding subsets. The packet loss rate (PLR) is analyzed,
which depends on both the cached packets and the channel state information
(CSI) available at the receiver. Theoretical results reveal the tradeoff
between caching resource and wireless resource. The performance for different
caching schemes are analyzed and the minimum achievable PLR for the distributed
caching is derived.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04416</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On numerical approximation schemes for expectation propagation</dc:title>
 <dc:creator>Roche, Alexis</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Several numerical approximation strategies for the expectation-propagation
algorithm are studied in the context of large-scale learning: the Laplace
method, a faster variant of it, Gaussian quadrature, and a deterministic
version of variational sampling (i.e., combining quadrature with variational
approximation). Experiments in training linear binary classifiers show that the
expectation-propagation algorithm converges best using variational sampling,
while it also converges well using Laplace-style methods with smooth factors
but tends to be unstable with non-differentiable ones. Gaussian quadrature
yields unstable behavior or convergence to a sub-optimal solution in most
experiments.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04417</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leech Constellations of Construction-A Lattices</dc:title>
 <dc:creator>di Pietro, Nicola</dc:creator>
 <dc:creator>Boutros, Joseph J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of communicating over the additive white Gaussian noise (AWGN)
channel with lattice codes is addressed in this paper. Theoretically, Voronoi
constellations have proved to yield very powerful lattice codes when the
fine/coding lattice is AWGN-good and the coarse/shaping lattice has an optimal
shaping gain. However, achieving Shannon capacity with these premises and
practically implementable encoding algorithms is in general not an easy task.
In this work, a new way to encode and demap Construction-A Voronoi lattice
codes is presented. As a meaningful application of this scheme, the second part
of the paper is focused on Leech constellations of low-density Construction-A
(LDA) lattices: LDA Voronoi lattice codes are presented whose numerically
measured waterfall region is situated at less than 0.8 dB from Shannon
capacity. These LDA lattice codes are based on dual-diagonal nonbinary
low-density parity-check codes. With this choice, encoding, iterative decoding,
and demapping have all linear complexity in the blocklength.
</dc:description>
 <dc:description>Comment: This paper contains 28 pages and 5 figures; in July 2017, it was
  accepted for publication on the IEEE Transactions on Communications</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04419</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Buffering Time Strategies for Wireless Full-duplex Systems under Poisson
  Traffic</dc:title>
 <dc:creator>Kobayashi, Makoto</dc:creator>
 <dc:creator>Saruwatari, Shunsuke</dc:creator>
 <dc:creator>Watanabe, Takashi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Full-duplex wireless communication has the potential to double the capacity
of wireless networks by reducing the band occupancy of transmissions. However,
a full-duplex capability cannot always reduce the band occupancy because the
real traffic is not fully buffered. Buffering time while waiting for a packet
to arrive at an opposite node is expected to reduce the band occupancy. In this
study, we provide the first theoretical analysis of band occupancy and the mean
waiting time for full-duplex communication with and without buffering time
under traffic that is not fully buffered based on queueing theory, as well as
the closed-form results. We also present the results of simulations of band
occupancy and the mean waiting time. The basic analysis provided in this study
shows how the mean waiting time and band occupancy are affected by the
buffering time. When the buffering time is half the packet length, the band
occupancy is reduced by approximately 15 %. In addition, under asymmetrical
traffic, the results suggest that the buffering time should not be set at the
node who has a higher traffic intensity compared with another node. These
results support the design of a full-duplex medium access control protocol and
devices.
</dc:description>
 <dc:description>Comment: 30 pages, 21 figures, Submitted to IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04426</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantifying the Information Leak in Cache Attacks through Symbolic
  Execution</dc:title>
 <dc:creator>Chattopadhyay, Sudipta</dc:creator>
 <dc:creator>Beck, Moritz</dc:creator>
 <dc:creator>Rezine, Ahmed</dc:creator>
 <dc:creator>Zeller, Andreas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cache timing attacks allow attackers to infer the properties of a secret
execution by observing cache hits and misses. But how much information can
actually leak through such attacks? For a given program, a cache model, and an
input, our CHALICE framework leverages symbolic execution to compute the amount
of information that can possibly leak through cache attacks. At the core of
CHALICE is a novel approach to quantify information leak that can highlight
critical cache side-channel leaks on arbitrary binary code. In our evaluation
on real-world programs from OpenSSL and Linux GDK libraries, CHALICE
effectively quantifies information leaks: For an AES-128 implementation on
Linux, for instance, CHALICE finds that a cache attack can leak as much as 127
out of 128 bits of the encryption key.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04429</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matrix Characterization for GFDM Systems: Low-Complexity MMSE Receivers
  and Optimal Prototype Filters</dc:title>
 <dc:creator>Chen, Po-Chih</dc:creator>
 <dc:creator>Su, Borching</dc:creator>
 <dc:creator>Huang, Yenming</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a new matrix-based characterization of
generalized-frequency-division-multiplexing (GFDM) transmitter matrices is
proposed, as opposed to traditional vector-based characterization with
prototype filters. The characterization facilitates deriving properties of GFDM
(transmitter) matrices, including conditions for GFDM matrices being
nonsingular and unitary, respectively. Using the new characterization, the
necessary and sufficient conditions for the existence of a form of
low-complexity implementation for a minimum mean square error (MMSE) receiver
are derived. Such an implementation exists under multipath channels if the GFDM
transmitter matrix is selected to be unitary. For cases where this
implementation does not exist, a low-complexity suboptimal MMSE receiver is
proposed, with its performance approximating that of an MMSE receiver. The new
characterization also enables derivations of optimal prototype filters in terms
of minimizing receiver mean square error (MSE). They are found to correspond to
the use of unitary GFDM matrices under many scenarios. The use of such optimal
filters in GFDM systems does not cause the problem of noise enhancement,
thereby demonstrating the same MSE performance as orthogonal frequency division
multiplexing. Moreover, we find that GFDM matrices with a size of power of two
are verified to exist in the class of unitary GFDM matrices. Finally, while the
out-of-band (OOB) radiation performance of systems using a unitary GFDM matrix
is not optimal in general, it is shown that the OOB radiation can be
satisfactorily low if parameters in the new characterization are carefully
chosen.
</dc:description>
 <dc:description>Comment: This version is accepted to IEEE Transactions on Signal Processing.
  16 pages, 15 figures</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04429</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2718971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04433</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Quamoco Product Quality Modelling and Assessment Approach</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Lochmann, Klaus</dc:creator>
 <dc:creator>Heinemann, Lars</dc:creator>
 <dc:creator>Kl&#xe4;s, Michael</dc:creator>
 <dc:creator>Trendowicz, Adam</dc:creator>
 <dc:creator>Pl&#xf6;sch, Reinhold</dc:creator>
 <dc:creator>Seidl, Andreas</dc:creator>
 <dc:creator>Goeb, Andreas</dc:creator>
 <dc:creator>Streit, Jonathan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Published software quality models either provide abstract quality attributes
or concrete quality assessments. There are no models that seamlessly integrate
both aspects. In the project Quamoco, we built a comprehensive approach with
the aim to close this gap.
  For this, we developed in several iterations a meta quality model specifying
general concepts, a quality base model covering the most important quality
factors and a quality assessment approach. The meta model introduces the new
concept of a product factor, which bridges the gap between concrete
measurements and abstract quality aspects. Product factors have measures and
instruments to operationalise quality by measurements from manual inspection
and tool analysis. The base model uses the ISO 25010 quality attributes, which
we refine by 200 factors and 600 measures for Java and C# systems.
  We found in several empirical validations that the assessment results fit to
the expectations of experts for the corresponding systems. The empirical
analyses also showed that several of the correlations are statistically
significant and that the maintainability part of the base model has the highest
correlation, which fits to the fact that this part is the most comprehensive.
Although we still see room for extending and improving the base model, it shows
a high correspondence with expert opinions and hence is able to form the basis
for repeatable and understandable quality assessments in practice.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures, Proc. 34th International Conference on Software
  Engineering (ICSE'12). IEEE, 2012</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04433</dc:identifier>
 <dc:identifier>doi:10.1109/ICSE.2012.6227106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04444</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Possibilistic semantics for a modal KD45 extension of G\&quot;odel fuzzy
  logic</dc:title>
 <dc:creator>Bou, F&#xe9;lix</dc:creator>
 <dc:creator>Esteva, Francesc</dc:creator>
 <dc:creator>Godo, Llu&#xed;s</dc:creator>
 <dc:creator>Rodriguez, Ricardo Oscar</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this paper we provide a simplified semantics for the logic KD45(G), i.e.
the many-valued G\&quot;odel counterpart of the classical modal logic KD45. More
precisely, we characterize KD45(G) as the set of valid formulae of the class of
possibilistic G\&quot;odel Kripke Frames $\langle W,\pi \rangle$, where $W$ is a
non-empty set of worlds and $\pi: W \longrightarrow [0, 1]$ is a normalized
possibility distribution on $W$.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04444</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-40581-0_11</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04447</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nuclei and automorphism groups of generalized twisted Gabidulin codes</dc:title>
 <dc:creator>Trombetti, Rocco</dc:creator>
 <dc:creator>Zhou, Yue</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Generalized twisted Gabidulin codes are one of the few known families of
maximum rank matrix codes over finite fields. As a subset of m by n matrices,
when m=n, the automorphism group of any generalized twisted Gabidulin code has
been completely determined by the authors recently. In this paper, we consider
the same problem for m&lt;n. Under certain conditions on their parameters, we
determine their middle nuclei and right nuclei, which are important invariants
with respect to the equivalence for rank metric codes. Furthermore, we also use
them to derive necessary conditions on the automorphisms of generalized twisted
Gabidulin codes.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04455</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Columbia MVSO Image Sentiment Dataset</dc:title>
 <dc:creator>Dalmia, Vaidehi</dc:creator>
 <dc:creator>Liu, Hongyi</dc:creator>
 <dc:creator>Chang, Shih-Fu</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The Multilingual Visual Sentiment Ontology (MVSO) consists of 15,600 concepts
in 12 different languages that are strongly related to emotions and sentiments
expressed in images. These concepts are defined in the form of Adjective-Noun
Pair (ANP), which are crawled and discovered from online image forum Flickr. In
this work, we used Amazon Mechanical Turk as a crowd-sourcing platform to
collect human judgments on sentiments expressed in images that are uniformly
sampled over 3,911 English ANPs extracted from a tag-restricted subset of MVSO.
Our goal is to use the dataset as a benchmark for the evaluation of systems
that automatically predict sentiments in images or ANPs.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04456</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TiO$_2$-based Memristors and ReRAM: Materials, Mechanisms and Models (a
  Review)</dc:title>
 <dc:creator>Gale, Ella</dc:creator>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>68Mxx, 92Exx, 92Fxx, 94Cxx</dc:subject>
 <dc:subject>B.3.1</dc:subject>
 <dc:subject>B.6.1</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:description>  The memristor is the fundamental non-linear circuit element, with uses in
computing and computer memory. ReRAM (Resistive Random Access Memory) is a
resistive switching memory proposed as a non-volatile memory. In this review we
shall summarise the state of the art for these closely-related fields,
concentrating on titanium dioxide, the well-utilised and archetypal material
for both. We shall cover material properties, switching mechanisms and models
to demonstrate what ReRAM and memristor scientists can learn from each other
and examine the outlook for these technologies.
</dc:description>
 <dc:description>Comment: Review, 29 pages, 2 figures, journal</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04456</dc:identifier>
 <dc:identifier>Semiconductor Science and Technology, Volume 29, Number 10,
  104004, (2014)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04465</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advancing Memristive Analog Neuromorphic Networks: Increasing
  Complexity, and Coping with Imperfect Hardware Components</dc:title>
 <dc:creator>Bayat, F. Merrikh</dc:creator>
 <dc:creator>Prezioso, M.</dc:creator>
 <dc:creator>Chakrabarti, B.</dc:creator>
 <dc:creator>Kataeva, I.</dc:creator>
 <dc:creator>Strukov, D. B.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We experimentally demonstrate classification of 4x4 binary images into 4
classes, using a 3-layer mixed-signal neuromorphic network (&quot;MLP perceptron&quot;),
based on two passive 20x20 memristive crossbar arrays, board-integrated with
discrete CMOS components. The network features 10 hidden-layer and 4
output-layer analog CMOS neurons and 428 metal-oxide memristors, i.e. is almost
an order of magnitude more complex than any previously reported functional
memristor circuit. Moreover, the inference operation of this classifier is
performed entirely in the integrated hardware. To deal with larger crossbar
arrays, we have developed a semi-automatic approach to their forming and
testing, and compared several memristor training schemes for coping with
imperfect behavior of these devices, as well as with variability of analog CMOS
neurons. The effectiveness of the proposed schemes for defect and variation
tolerance was verified experimentally using the implemented network and,
additionally, by modeling the operation of a larger network, with 300
hidden-layer neurons, on the MNIST benchmark. Finally, we propose a simple
modification of the implemented memristor-based vector-by-matrix multiplier to
allow its operation in a wider temperature range.
</dc:description>
 <dc:description>Comment: 4 pages, 13 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04474</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting FPGA Acceleration of Molecular Dynamics Simulation with
  Dynamic Data Flow Behavior in High-Level Synthesis</dc:title>
 <dc:creator>Cong, Jason</dc:creator>
 <dc:creator>Fang, Zhenman</dc:creator>
 <dc:creator>Kianinejad, Hassan</dc:creator>
 <dc:creator>Wei, Peng</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Physics - Atomic Physics</dc:subject>
 <dc:description>  Molecular dynamics (MD) simulation is one of the past decade's most important
tools for enabling biology scientists and researchers to explore human health
and diseases. However, due to the computation complexity of the MD algorithm,
it takes weeks or even months to simulate a comparatively simple biology entity
on conventional multicore processors. The critical path in molecular dynamics
simulations is the force calculation between particles inside the simulated
environment, which has abundant parallelism. Among various acceleration
platforms, FPGA is an attractive alternative because of its low power and high
energy efficiency. However, due to its high programming cost using RTL, none of
the mainstream MD software packages has yet adopted FPGA for acceleration.
  In this paper we revisit the FPGA acceleration of MD in high-level synthesis
(HLS) so as to provide affordable programming cost. Our experience with the MD
acceleration demonstrates that HLS optimizations such as loop pipelining,
module duplication and memory partitioning are essential to improve the
performance, achieving a speedup of 9.5X compared to a 12-core CPU. More
importantly, we observe that even the fully optimized HLS design can still be
2X slower than the reference RTL architecture due to the common dynamic
(conditional) data flow behavior that is not yet supported by current HLS
tools. To support such behavior, we further customize an array of processing
elements together with a data-driven streaming network through a common RTL
template, and fully automate the design flow. Our final experimental results
demonstrate a 19.4X performance speedup and 39X energy efficiency for the
widely used ApoA1 MD benchmark on the Convey HC1ex FPGA compared to a 12-core
Intel Xeon server.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04481</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can fully convolutional networks perform well for general image
  restoration problems?</dc:title>
 <dc:creator>Chaudhury, Subhajit</dc:creator>
 <dc:creator>Roy, Hiya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a fully convolutional network(FCN) based approach for color image
restoration. FCNs have recently shown remarkable performance for high-level
vision problem like semantic segmentation. In this paper, we investigate if FCN
models can show promising performance for low-level problems like image
restoration as well. We propose a fully convolutional model, that learns a
direct end-to-end mapping between the corrupted images as input and the desired
clean images as output. Our proposed method takes inspiration from domain
transformation techniques but presents a data-driven task specific approach
where filters for novel basis projection, task dependent coefficient
alterations, and image reconstruction are represented as convolutional
networks. Experimental results show that our FCN model outperforms traditional
sparse coding based methods and demonstrates competitive performance compared
to the state-of-the-art methods for image denoising. We further show that our
proposed model can solve the difficult problem of blind image inpainting and
can produce reconstructed images of impressive visual quality.
</dc:description>
 <dc:description>Comment: Accepted at IAPR MVA 2017</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04482</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Secure Aggregation for Federated Learning on User-Held Data</dc:title>
 <dc:creator>Bonawitz, Keith</dc:creator>
 <dc:creator>Ivanov, Vladimir</dc:creator>
 <dc:creator>Kreuter, Ben</dc:creator>
 <dc:creator>Marcedone, Antonio</dc:creator>
 <dc:creator>McMahan, H. Brendan</dc:creator>
 <dc:creator>Patel, Sarvar</dc:creator>
 <dc:creator>Ramage, Daniel</dc:creator>
 <dc:creator>Segal, Aaron</dc:creator>
 <dc:creator>Seth, Karn</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Secure Aggregation protocols allow a collection of mutually distrust parties,
each holding a private value, to collaboratively compute the sum of those
values without revealing the values themselves. We consider training a deep
neural network in the Federated Learning model, using distributed stochastic
gradient descent across user-held training data on mobile devices, wherein
Secure Aggregation protects each user's model gradient. We design a novel,
communication-efficient Secure Aggregation protocol for high-dimensional data
that tolerates up to 1/3 users failing to complete the protocol. For 16-bit
input values, our protocol offers 1.73x communication expansion for $2^{10}$
users and $2^{20}$-dimensional vectors, and 1.98x expansion for $2^{14}$ users
and $2^{24}$ dimensional vectors.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure. To appear at the NIPS 2016 workshop on Private
  Multi-Party Machine Learning</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04488</identifier>
 <datestamp>2017-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Models and Model Criticism via Optimized Maximum Mean
  Discrepancy</dc:title>
 <dc:creator>Sutherland, Dougal J.</dc:creator>
 <dc:creator>Tung, Hsiao-Yu</dc:creator>
 <dc:creator>Strathmann, Heiko</dc:creator>
 <dc:creator>De, Soumyajit</dc:creator>
 <dc:creator>Ramdas, Aaditya</dc:creator>
 <dc:creator>Smola, Alex</dc:creator>
 <dc:creator>Gretton, Arthur</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  We propose a method to optimize the representation and distinguishability of
samples from two probability distributions, by maximizing the estimated power
of a statistical test based on the maximum mean discrepancy (MMD). This
optimized MMD is applied to the setting of unsupervised learning by generative
adversarial networks (GAN), in which a model attempts to generate realistic
samples, and a discriminator attempts to tell these apart from data samples. In
this context, the MMD may be used in two roles: first, as a discriminator,
either directly on the samples, or on features of the samples. Second, the MMD
can be used to evaluate the performance of a generative model, by testing the
model's samples against a reference data set. In the latter role, the optimized
MMD is particularly helpful, as it gives an interpretable indication of how the
model and data distributions differ, even in cases where individual model
samples are not easily distinguished either by eye or by classifier.
</dc:description>
 <dc:description>Comment: Published at ICLR 2017 (public comments:
  http://openreview.net/forum?id=HJWHIKqgl ). v4: minor edits</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04489</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bijections for Weyl Chamber walks ending on an axis, using arc diagrams
  and Schnyder woods</dc:title>
 <dc:creator>Courtiel, Julien</dc:creator>
 <dc:creator>Fusy, &#xc9;ric</dc:creator>
 <dc:creator>Lepoutre, Mathias</dc:creator>
 <dc:creator>Mishna, Marni</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05A15</dc:subject>
 <dc:description>  In the study of lattice walks there are several examples of enumerative
equivalences which amount to a trade-off between domain and endpoint
constraints. We present a family of such bijections for simple walks in Weyl
chambers which use arc diagrams in a natural way. One consequence is a set of
new bijections for standard Young tableaux of bounded height. A modification of
the argument in two dimensions yields a bijection between Baxter permutations
and walks ending on an axis, answering a recent question of Burrill et al.
(2016). Some of our arguments (and related results) are proved using Schnyder
woods. Our strategy for simple walks extends to any dimension and yields a new
bijective connection between standard Young tableaux of height at most $2k$ and
certain walks with prescribed endpoints in the $k$-dimensional Weyl chamber of
type D.
</dc:description>
 <dc:description>Comment: This is a full version, published in the European Journal of
  Combinatorics. It is 19 pages long and have 8 Figures</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04489</dc:identifier>
 <dc:identifier>European Journal of Combinatorics, 2018, vol. 69, p. 126-142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04491</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranking medical jargon in electronic health record notes by adapted
  distant supervision</dc:title>
 <dc:creator>Chen, Jinying</dc:creator>
 <dc:creator>Jagannatha, Abhyuday N.</dc:creator>
 <dc:creator>Jarad, Samah J.</dc:creator>
 <dc:creator>Yu, Hong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Objective: Allowing patients to access their own electronic health record
(EHR) notes through online patient portals has the potential to improve
patient-centered care. However, medical jargon, which abounds in EHR notes, has
been shown to be a barrier for patient EHR comprehension. Existing knowledge
bases that link medical jargon to lay terms or definitions play an important
role in alleviating this problem but have low coverage of medical jargon in
EHRs. We developed a data-driven approach that mines EHRs to identify and rank
medical jargon based on its importance to patients, to support the building of
EHR-centric lay language resources.
  Methods: We developed an innovative adapted distant supervision (ADS) model
based on support vector machines to rank medical jargon from EHRs. For distant
supervision, we utilized the open-access, collaborative consumer health
vocabulary, a large, publicly available resource that links lay terms to
medical jargon. We explored both knowledge-based features from the Unified
Medical Language System and distributed word representations learned from
unlabeled large corpora. We evaluated the ADS model using physician-identified
important medical terms.
  Results: Our ADS model significantly surpassed two state-of-the-art automatic
term recognition methods, TF*IDF and C-Value, yielding 0.810 ROC-AUC versus
0.710 and 0.667, respectively. Our model identified 10K important medical
jargon terms after ranking over 100K candidate terms mined from over 7,500 EHR
narratives.
  Conclusion: Our work is an important step towards enriching lexical resources
that link medical jargon to lay terms/definitions to support patient EHR
comprehension. The identified medical jargon terms and their rankings are
available upon request.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04495</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection Performance with Many Antennas Available for
  Bandwidth-Efficient Uplink Transmission in MU-MIMO Systems</dc:title>
 <dc:creator>Torres, Paulo</dc:creator>
 <dc:creator>Gusmao, Antonio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper is concerned with SC/FDE for bandwidth-efficient uplink block
transmission, with QAM schemes, in a MU MIMO system. The number of BS receiver
antennas is assumed to be large, but not necessarily much larger than the
overall number of transmitter antennas jointly using the same time/frequency
resource at MT.
  In this context, we consider several detection techniques and evaluate, in
detail, the corresponding detection performances (discussed with the help of
selected performance bounds), for a range of values regarding the number of
available BS receiver antennas. From our performance results, we conclude that
simple linear detection techniques, designed to avoid the need of complex
matrix inversions, can lead to unacceptably high error floor levels. However,
by combining the use of such simple linear detectors with an appropriate
interference cancellation procedure - within an iterative DF technique -, a
close approximation to the SIMO MFB performance can be achieved after a few
iterations, even for 64-QAM schemes, when the number of BS antennas is, at
least, five times higher than the number of antennas which are jointly used at
the user terminals.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:1502.05597</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04496</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-view Recurrent Neural Acoustic Word Embeddings</dc:title>
 <dc:creator>He, Wanjia</dc:creator>
 <dc:creator>Wang, Weiran</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent work has begun exploring neural acoustic word
embeddings---fixed-dimensional vector representations of arbitrary-length
speech segments corresponding to words. Such embeddings are applicable to
speech retrieval and recognition tasks, where reasoning about whole words may
make it possible to avoid ambiguous sub-word representations. The main idea is
to map acoustic sequences to fixed-dimensional vectors such that examples of
the same word are mapped to similar vectors, while different-word examples are
mapped to very different vectors. In this work we take a multi-view approach to
learning acoustic word embeddings, in which we jointly learn to embed acoustic
sequences and their corresponding character sequences. We use deep
bidirectional LSTM embedding models and multi-view contrastive losses. We study
the effect of different loss variants, including fixed-margin and
cost-sensitive losses. Our acoustic word embeddings improve over previous
approaches for the task of word discrimination. We also present results on
other tasks that are enabled by the multi-view approach, including cross-view
word discrimination and word similarity.
</dc:description>
 <dc:description>Comment: Appearing in ICLR 2017</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04499</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Post Training in Deep Learning with Last Kernel</dc:title>
 <dc:creator>Moreau, Thomas</dc:creator>
 <dc:creator>Audiffren, Julien</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  One of the main challenges of deep learning methods is the choice of an
appropriate training strategy. In particular, additional steps, such as
unsupervised pre-training, have been shown to greatly improve the performances
of deep structures. In this article, we propose an extra training step, called
post-training, which only optimizes the last layer of the network. We show that
this procedure can be analyzed in the context of kernel theory, with the first
layers computing an embedding of the data and the last layer a statistical
model to solve the task based on this embedding. This step makes sure that the
embedding, or representation, of the data is used in the best possible way for
the considered task. This idea is then tested on multiple architectures with
various data sets, showing that it consistently provides a boost in
performance.
</dc:description>
 <dc:description>Comment: submitted to ICLR 2018</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04500</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning with Sets and Point Clouds</dc:title>
 <dc:creator>Ravanbakhsh, Siamak</dc:creator>
 <dc:creator>Schneider, Jeff</dc:creator>
 <dc:creator>Poczos, Barnabas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce a simple permutation equivariant layer for deep learning with
set structure.This type of layer, obtained by parameter-sharing, has a simple
implementation and linear-time complexity in the size of each set. We use deep
permutation-invariant networks to perform point-could classification and
MNIST-digit summation, where in both cases the output is invariant to
permutations of the input. In a semi-supervised setting, where the goal is make
predictions for each instance within a set, we demonstrate the usefulness of
this type of layer in set-outlier detection as well as semi-supervised learning
with clustering side-information.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04503</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-resource Machine Translation by Multimodal Encoder-decoder Network
  with Multimedia Pivot</dc:title>
 <dc:creator>Nakayama, Hideki</dc:creator>
 <dc:creator>Nishida, Noriki</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  We propose an approach to build a neural machine translation system with no
supervised resources (i.e., no parallel corpora) using multimodal embedded
representation over texts and images. Based on the assumption that text
documents are often likely to be described with other multimedia information
(e.g., images) somewhat related to the content, we try to indirectly estimate
the relevance between two languages. Using multimedia as the &quot;pivot&quot;, we
project all modalities into one common hidden space where samples belonging to
similar semantic concepts should come close to each other, whatever the
observed space of each sample is. This modality-agnostic representation is the
key to bridging the gap between different modalities. Putting a decoder on top
of it, our network can flexibly draw the outputs from any input modality.
Notably, in the testing phase, we need only source language texts as the input
for translation. In experiments, we tested our method on two benchmarks to show
that it can achieve reasonable translation performance. We compared and
investigated several possible implementations and found that an end-to-end
model that simultaneously optimized both rank loss in multimodal encoders and
cross-entropy loss in decoders performed the best.
</dc:description>
 <dc:description>Comment: Some error corrections in Sect.2.2 and Table 5, Machine Translation,
  2017</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04506</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the visualization of the detected communities in dynamic networks: A
  case study of Twitter's network</dc:title>
 <dc:creator>Abdelsadek, Youcef</dc:creator>
 <dc:creator>Chelghoum, Kamel</dc:creator>
 <dc:creator>Herrmann, Francine</dc:creator>
 <dc:creator>Kacem, Imed</dc:creator>
 <dc:creator>Otjacques, Beno&#xee;t</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Understanding the information behind social relationships represented by a
network is very challenging, especially, when the social interactions change
over time inducing updates on the network topology. In this context, this paper
proposes an approach for analysing dynamic social networks, more precisely for
Twitter's network. Our approach relies on two complementary steps: (i) an
online community identification based on a dynamic community detection
algorithm called Dyci. The main idea of Dyci is to track whether a connected
component of the weighted graph becomes weak over time, in order to merge it
with the &quot;dominant&quot; neighbour community. Additionally, (ii) a community
visualization is provided by our visualization tool called NLCOMS, which
combines between two methods of dynamic network visualization. In order to
assess the efficiency and the applicability of the proposed approach, we
consider real-world data of the ANR-Info-RSN project, which deals with
community analysis in Twitter.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04519</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Task-Specific Target Detection via Graph Based Constraints
  Representation and Checking</dc:title>
 <dc:creator>Luan, Went</dc:creator>
 <dc:creator>Yang, Yezhou</dc:creator>
 <dc:creator>Fermuller, Cornelia</dc:creator>
 <dc:creator>Baras, John S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we present a fast target detection framework for real-world
robotics applications. Considering that an intelligent agent attends to a
task-specific object target during execution, our goal is to detect the object
efficiently. We propose the concept of early recognition, which influences the
candidate proposal process to achieve fast and reliable detection performance.
To check the target constraints efficiently, we put forward a novel policy to
generate a sub-optimal checking order, and prove that it has bounded time cost
compared to the optimal checking sequence, which is not achievable in
polynomial time. Experiments on two different scenarios: 1) rigid object and 2)
non-rigid body part detection validate our pipeline. To show that our method is
widely applicable, we further present a human-robot interaction system based on
our non-rigid body part detection.
</dc:description>
 <dc:description>Comment: The paper is withdrawn for another work's convenience. We will upload
  it later</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04520</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Normalizing the Normalizers: Comparing and Extending Network
  Normalization Schemes</dc:title>
 <dc:creator>Ren, Mengye</dc:creator>
 <dc:creator>Liao, Renjie</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:creator>Sinz, Fabian H.</dc:creator>
 <dc:creator>Zemel, Richard S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Normalization techniques have only recently begun to be exploited in
supervised learning tasks. Batch normalization exploits mini-batch statistics
to normalize the activations. This was shown to speed up training and result in
better models. However its success has been very limited when dealing with
recurrent neural networks. On the other hand, layer normalization normalizes
the activations across all activities within a layer. This was shown to work
well in the recurrent setting. In this paper we propose a unified view of
normalization techniques, as forms of divisive normalization, which includes
layer and batch normalization as special cases. Our second contribution is the
finding that a small modification to these normalization schemes, in
conjunction with a sparse regularizer on the activations, leads to significant
benefits over standard normalization techniques. We demonstrate the
effectiveness of our unified divisive normalization framework in the context of
convolutional neural nets and recurrent neural networks, showing improvements
over baselines in image classification, language modeling as well as
super-resolution.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04524</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Activity Selection on Social Networks</dc:title>
 <dc:creator>Igarashi, Ayumi</dc:creator>
 <dc:creator>Peters, Dominik</dc:creator>
 <dc:creator>Elkind, Edith</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We propose a new variant of the group activity selection problem (GASP),
where the agents are placed on a social network and activities can only be
assigned to connected subgroups. We show that if multiple groups can
simultaneously engage in the same activity, finding a stable outcome is easy as
long as the network is acyclic. In contrast, if each activity can be assigned
to a single group only, finding stable outcomes becomes intractable, even if
the underlying network is very simple: the problem of determining whether a
given instance of a GASP admits a Nash stable outcome turns out to be NP-hard
when the social network is a path, a star, or if the size of each connected
component is bounded by a constant. On the other hand, we obtain
fixed-parameter tractability results for this problem with respect to the
number of activities.
</dc:description>
 <dc:description>Comment: 10 pages, full version of accepted AAAI-17 paper</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04528</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking Quantum Hardware for Training of Fully Visible Boltzmann
  Machines</dc:title>
 <dc:creator>Korenkevych, Dmytro</dc:creator>
 <dc:creator>Xue, Yanbo</dc:creator>
 <dc:creator>Bian, Zhengbing</dc:creator>
 <dc:creator>Chudak, Fabian</dc:creator>
 <dc:creator>Macready, William G.</dc:creator>
 <dc:creator>Rolfe, Jason</dc:creator>
 <dc:creator>Andriyash, Evgeny</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Quantum annealing (QA) is a hardware-based heuristic optimization and
sampling method applicable to discrete undirected graphical models. While
similar to simulated annealing, QA relies on quantum, rather than thermal,
effects to explore complex search spaces. For many classes of problems, QA is
known to offer computational advantages over simulated annealing. Here we
report on the ability of recent QA hardware to accelerate training of fully
visible Boltzmann machines. We characterize the sampling distribution of QA
hardware, and show that in many cases, the quantum distributions differ
significantly from classical Boltzmann distributions. In spite of this
difference, training (which seeks to match data and model statistics) using
standard classical gradient updates is still effective. We investigate the use
of QA for seeding Markov chains as an alternative to contrastive divergence
(CD) and persistent contrastive divergence (PCD). Using $k=50$ Gibbs steps, we
show that for problems with high-energy barriers between modes, QA-based seeds
can improve upon chains with CD and PCD initializations. For these hard
problems, QA gradient estimates are more accurate, and allow for faster
learning. Furthermore, and interestingly, even the case of raw QA samples (that
is, $k=0$) achieved similar improvements. We argue that this relates to the
fact that we are training a quantum rather than classical Boltzmann
distribution in this case. The learned parameters give rise to hardware QA
distributions closely approximating classical Boltzmann distributions that are
hard to train with CD/PCD.
</dc:description>
 <dc:description>Comment: 22 pages, 13 figures, D-Wave quantum system for sampling Boltzmann
  machines</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04529</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can information be spread as a virus? Viral Marketing as epidemiological
  model</dc:title>
 <dc:creator>Rodrigues, Helena Sofia</dc:creator>
 <dc:creator>Fonseca, Manuel Jos&#xe9;</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>34A34, 92D30, 91F99</dc:subject>
 <dc:description>  In epidemiology, an epidemic is defined as the spread of an infectious
disease to a large number of people in a given population within a short period
of time. In the marketing context, a message is viral when it is broadly sent
and received by the target market through person-to-person transmission. This
specific marketing communication strategy is commonly referred as viral
marketing. Due to this similarity between an epidemic and the viral marketing
process and because the understanding of the critical factors to this
communications strategy effectiveness remain largely unknown, the mathematical
models in epidemiology are presented in this marketing specific field. In this
paper, an epidemiological model SIR (Susceptible- Infected-Recovered) to study
the effects of a viral marketing strategy is presented. It is made a comparison
between the disease parameters and the marketing application, and Matlab
simulations are performed. Finally, some conclusions are carried out and their
marketing implications are exposed: interactions across the parameters suggest
some recommendations to marketers, as the profitability of the investment or
the need to improve the targeting criteria of the communications campaigns.
</dc:description>
 <dc:description>Comment: Please cite this paper as: Rodrigues, Helena Sofia and Fonseca,
  Manuel Jos\'e (2016) . Can information be spread as a virus? Viral Marketing
  as epidemiological model, Mathematical Methods in the Applied Sciences, 39:
  4780--4786. arXiv admin note: substantial text overlap with arXiv:1507.06986</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04529</dc:identifier>
 <dc:identifier>Mathematical Methods in the Applied Sciences,39: 4780--4786, 2016</dc:identifier>
 <dc:identifier>doi:10.1002/mma.3783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04531</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retrofit Control: Localization of Controller Design and Implementation</dc:title>
 <dc:creator>Ishizaki, Takayuki</dc:creator>
 <dc:creator>Sadamoto, Tomonori</dc:creator>
 <dc:creator>Imura, Jun-ichi</dc:creator>
 <dc:creator>Sandberg, Henrik</dc:creator>
 <dc:creator>Johansson, Karl Henrik</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  In this paper, we propose a retrofit control method for stable network
systems. The proposed approach is a decentralized control method that, rather
than an entire system model, requires a model of the subsystem of interest for
controller design. To design the retrofit controller, we use a novel approach
based on hierarchical state-space expansion that generates a higher-dimensional
cascade realization of a given network system. The upstream dynamics of the
cascade realization corresponds to an isolated model of the subsystem of
interest, which is stabilized by a local controller. The downstream dynamics
can be seen as a dynamical model representing the propagation of interference
signals among subsystems, the stability of which is equivalent to that of the
original system. This cascade structure enables a systematic analysis of both
the stability and control performance of the resultant closed-loop system. The
resultant retrofit controller is formed as a cascade interconnection of the
local controller and a localizing compensator that filtrates an output signal
of the subsystem of interest so as to conform to an output signal of the
isolated subsystem model while acquiring complementary signals neglected in the
local controller design, such as interconnection signals. Finally, the
efficiency of the retrofit control method is demonstrated through numerical
examples of power systems control and vehicle platoon control.
</dc:description>
 <dc:date>2016-11-08</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04534</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3-D Convolutional Neural Networks for Glioblastoma Segmentation</dc:title>
 <dc:creator>Yi, Darvin</dc:creator>
 <dc:creator>Zhou, Mu</dc:creator>
 <dc:creator>Chen, Zhao</dc:creator>
 <dc:creator>Gevaert, Olivier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNN) have emerged as powerful tools for
learning discriminative image features. In this paper, we propose a framework
of 3-D fully CNN models for Glioblastoma segmentation from multi-modality MRI
data. By generalizing CNN models to true 3-D convolutions in learning 3-D tumor
MRI data, the proposed approach utilizes a unique network architecture to
decouple image pixels. Specifically, we design a convolutional layer with
pre-defined Difference- of-Gaussian (DoG) filters to perform true 3-D
convolution incorporating local neighborhood information at each pixel. We then
use three trained convolutional layers that act to decouple voxels from the
initial 3-D convolution. The proposed framework allows identification of
high-level tumor structures on MRI. We evaluate segmentation performance on the
BRATS segmentation dataset with 274 tumor samples. Extensive experimental
results demonstrate encouraging performance of the proposed approach comparing
to the state-of-the-art methods. Our data-driven approach achieves a median
Dice score accuracy of 89% in whole tumor glioblastoma segmentation, revealing
a generalized low-bias possibility to learn from medium-size MRI datasets.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04535</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning-Theoretic Foundations of Algorithm Configuration for
  Combinatorial Partitioning Problems</dc:title>
 <dc:creator>Balcan, Maria-Florina</dc:creator>
 <dc:creator>Nagarajan, Vaishnavh</dc:creator>
 <dc:creator>Vitercik, Ellen</dc:creator>
 <dc:creator>White, Colin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Max-cut, clustering, and many other partitioning problems that are of
significant importance to machine learning and other scientific fields are
NP-hard, a reality that has motivated researchers to develop a wealth of
approximation algorithms and heuristics. Although the best algorithm to use
typically depends on the specific application domain, a worst-case analysis is
often used to compare algorithms. This may be misleading if worst-case
instances occur infrequently, and thus there is a demand for optimization
methods which return the algorithm configuration best suited for the given
application's typical inputs. We address this problem for clustering, max-cut,
and other partitioning problems, such as integer quadratic programming, by
designing computationally efficient and sample efficient learning algorithms
which receive samples from an application-specific distribution over problem
instances and learn a partitioning algorithm with high expected performance.
Our algorithms learn over common integer quadratic programming and clustering
algorithm families: SDP rounding algorithms and agglomerative clustering
algorithms with dynamic programming. For our sample complexity analysis, we
provide tight bounds on the pseudodimension of these algorithm classes, and
show that surprisingly, even for classes of algorithms parameterized by a
single parameter, the pseudo-dimension is superconstant. In this way, our work
both contributes to the foundations of algorithm configuration and pushes the
boundaries of learning theory, since the algorithm classes we analyze consist
of multi-stage optimization procedures and are significantly more complex than
classes typically studied in learning theory.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04535</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04539</identifier>
 <datestamp>2017-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Good Integers and Applications in Coding Theory</dc:title>
 <dc:creator>Jitman, Somphong</dc:creator>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>11N25, 11B83, 94B15, 94B60</dc:subject>
 <dc:description>  A class of good integers has been introduced by P. Moree in $1997$ together
with the characterization of good odd integers. Such integers have shown to
have nice number theoretical properties and wide applications. In this paper, a
complete characterization of all good integers is given.
  Two subclasses of good integers are introduced, namely, oddly-good and
evenly-good integers. The characterization and properties of good integers in
these two subclasses are determined.
  As applications, good integers and oddly-good integers are applied in the
study of the hulls of abelian codes. The average dimension of the hulls of
abelian codes is given together with some upper and lower bounds.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04548</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real Stable Polynomials and Matroids: Optimization and Counting</dc:title>
 <dc:creator>Straszak, Damian</dc:creator>
 <dc:creator>Vishnoi, Nisheeth K.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  A great variety of fundamental optimization and counting problems arising in
computer science, mathematics and physics can be reduced to one of the
following computational tasks involving polynomials and set systems: given an
$m$-variate real polynomial $g$ and a family of subsets $B$ of $[m]$, (1) find
$S\in B$ such that the monomial in $g$ corresponding to $S$ has the largest
coefficient in $g$, or (2) compute the sum of coefficients of monomials in $g$
corresponding to all the sets in $B$. Special cases of these problems, such as
computing permanents, sampling from DPPs and maximizing subdeterminants have
been topics of recent interest in theoretical computer science.
  In this paper we present a general convex programming framework geared to
solve both of these problems. We show that roughly, when $g$ is a real stable
polynomial with non-negative coefficients and $B$ is a matroid, the integrality
gap of our relaxation is finite and depends only on $m$ (and not on the
coefficients of g).
  Prior to our work, such results were known only in sporadic cases that relied
on the structure of $g$ and $B$; it was not even clear if one could formulate a
convex relaxation that has a finite integrality gap beyond these special cases.
Two notable examples are a result by Gurvits on the van der Waerden conjecture
for real stable $g$ when $B$ is a single element and a result by Nikolov and
Singh for multilinear real stable polynomials when $B$ is a partition matroid.
Our work, which encapsulates most interesting cases of $g$ and $B$, benefits
from both - we were inspired by the latter in deriving the right convex
programming relaxation and the former in establishing the integrality gap.
However, proving our results requires significant extensions of both; in that
process we come up with new notions and connections between stable polynomials
and matroids which should be of independent interest.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04552</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Model-Predictive Motion Planner for the IARA Autonomous Car</dc:title>
 <dc:creator>Cardoso, Vinicius</dc:creator>
 <dc:creator>Oliveira, Josias</dc:creator>
 <dc:creator>Teixeira, Thomas</dc:creator>
 <dc:creator>Badue, Claudine</dc:creator>
 <dc:creator>Mutz, Filipe</dc:creator>
 <dc:creator>Oliveira-Santos, Thiago</dc:creator>
 <dc:creator>Veronese, Lucas</dc:creator>
 <dc:creator>De Souza, Alberto F.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:description>  We present the Model-Predictive Motion Planner (MPMP) of the Intelligent
Autonomous Robotic Automobile (IARA). IARA is a fully autonomous car that uses
a path planner to compute a path from its current position to the desired
destination. Using this path, the current position, a goal in the path and a
map, IARA's MPMP is able to compute smooth trajectories from its current
position to the goal in less than 50 ms. MPMP computes the poses of these
trajectories so that they follow the path closely and, at the same time, are at
a safe distance of eventual obstacles. Our experiments have shown that MPMP is
able to compute trajectories that precisely follow a path produced by a Human
driver (distance of 0.15 m in average) while smoothly driving IARA at speeds of
up to 32.4 km/h (9 m/s).
</dc:description>
 <dc:description>Comment: This is a preprint. Accepted by 2017 IEEE International Conference on
  Robotics and Automation (ICRA)</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04552</dc:identifier>
 <dc:identifier>IEEE International Conference on Robotics and Automation (ICRA
  2017), 2017, pp. 225-230</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2017.7989028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04553</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear Modal Decoupling of Multi-Oscillator Systems with Applications
  to Power Systems</dc:title>
 <dc:creator>Wang, Bin</dc:creator>
 <dc:creator>Sun, Kai</dc:creator>
 <dc:creator>Kang, Wei</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Many natural and manmade dynamical systems that are modeled as large
nonlinear multi-oscillator systems like power systems are hard to analyze. For
such a system, we propose a nonlinear modal decoupling (NMD) approach inversely
constructing as many decoupled nonlinear oscillators as the system oscillation
modes so that individual decoupled oscillators can easily be analyzed to infer
dynamics and stability of the original system. The NMD follows a similar idea
to the normal form except that we eliminate inter-modal terms but allow
intra-modal terms of desired nonlinearities in decoupled systems, so decoupled
systems can flexibly be shaped into desired forms of nonlinear oscillators. The
NMD is then applied to power systems towards two types of nonlinear
oscillators, i.e. the single-machine-infinite-bus (SMIB) systems and a proposed
non-SMIB oscillator. Numerical studies on a 3-machine 9-bus system and New
England 10-machine 39-bus system show that (i) decoupled oscillators keep a
majority of the original system modal nonlinearities and the NMD provides a
bigger validity region than the normal form, and (ii) decoupled non-SMIB
oscillators may keep more authentic dynamics of the original system than
decoupled SMIB systems.
</dc:description>
 <dc:description>Comment: This manuscript has been submitted to IEEE Transactions on Automatic
  Control, containing 12 pages and 10 figures</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04558</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Google's Multilingual Neural Machine Translation System: Enabling
  Zero-Shot Translation</dc:title>
 <dc:creator>Johnson, Melvin</dc:creator>
 <dc:creator>Schuster, Mike</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:creator>Krikun, Maxim</dc:creator>
 <dc:creator>Wu, Yonghui</dc:creator>
 <dc:creator>Chen, Zhifeng</dc:creator>
 <dc:creator>Thorat, Nikhil</dc:creator>
 <dc:creator>Vi&#xe9;gas, Fernanda</dc:creator>
 <dc:creator>Wattenberg, Martin</dc:creator>
 <dc:creator>Corrado, Greg</dc:creator>
 <dc:creator>Hughes, Macduff</dc:creator>
 <dc:creator>Dean, Jeffrey</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a simple solution to use a single Neural Machine Translation (NMT)
model to translate between multiple languages. Our solution requires no change
in the model architecture from our base system but instead introduces an
artificial token at the beginning of the input sentence to specify the required
target language. The rest of the model, which includes encoder, decoder and
attention, remains unchanged and is shared across all languages. Using a shared
wordpiece vocabulary, our approach enables Multilingual NMT using a single
model without any increase in parameters, which is significantly simpler than
previous proposals for Multilingual NMT. Our method often improves the
translation quality of all involved language pairs, even while keeping the
total number of model parameters constant. On the WMT'14 benchmarks, a single
multilingual model achieves comparable performance for
English$\rightarrow$French and surpasses state-of-the-art results for
English$\rightarrow$German. Similarly, a single multilingual model surpasses
state-of-the-art results for French$\rightarrow$English and
German$\rightarrow$English on WMT'14 and WMT'15 benchmarks respectively. On
production corpora, multilingual models of up to twelve language pairs allow
for better translation of many individual pairs. In addition to improving the
translation quality of language pairs that the model was trained with, our
models can also learn to perform implicit bridging between language pairs never
seen explicitly during training, showing that transfer learning and zero-shot
translation is possible for neural translation. Finally, we show analyses that
hints at a universal interlingua representation in our models and show some
interesting examples when mixing languages.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04561</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Splitting matters: how monotone transformation of predictor variables
  may improve the predictions of decision tree models</dc:title>
 <dc:creator>Galili, Tal</dc:creator>
 <dc:creator>Meilijson, Isaac</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  It is widely believed that the prediction accuracy of decision tree models is
invariant under any strictly monotone transformation of the individual
predictor variables. However, this statement may be false when predicting new
observations with values that were not seen in the training-set and are close
to the location of the split point of a tree rule. The sensitivity of the
prediction error to the split point interpolation is high when the split point
of the tree is estimated based on very few observations, reaching 9%
misclassification error when only 10 observations are used for constructing a
split, and shrinking to 1% when relying on 100 observations. This study
compares the performance of alternative methods for split point interpolation
and concludes that the best choice is taking the mid-point between the two
closest points to the split point of the tree. Furthermore, if the (continuous)
distribution of the predictor variable is known, then using its probability
integral for transforming the variable (&quot;quantile transformation&quot;) will reduce
the model's interpolation error by up to about a half on average. Accordingly,
this study provides guidelines for both developers and users of decision tree
models (including bagging and random forest).
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04578</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Earliness-Aware Deep Convolutional Networks for Early Time Series
  Classification</dc:title>
 <dc:creator>Wang, Wenlin</dc:creator>
 <dc:creator>Chen, Changyou</dc:creator>
 <dc:creator>Wang, Wenqi</dc:creator>
 <dc:creator>Rai, Piyush</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present Earliness-Aware Deep Convolutional Networks (EA-ConvNets), an
end-to-end deep learning framework, for early classification of time series
data. Unlike most existing methods for early classification of time series
data, that are designed to solve this problem under the assumption of the
availability of a good set of pre-defined (often hand-crafted) features, our
framework can jointly perform feature learning (by learning a deep hierarchy of
\emph{shapelets} capturing the salient characteristics in each time series),
along with a dynamic truncation model to help our deep feature learning
architecture focus on the early parts of each time series. Consequently, our
framework is able to make highly reliable early predictions, outperforming
various state-of-the-art methods for early time series classification, while
also being competitive when compared to the state-of-the-art time series
classification algorithms that work with \emph{fully observed} time series
data. To the best of our knowledge, the proposed framework is the first to
perform data-driven (deep) feature learning in the context of early
classification of time series data. We perform a comprehensive set of
experiments, on several benchmark data sets, which demonstrate that our method
yields significantly better predictions than various state-of-the-art methods
designed for early time series classification. In addition to obtaining high
accuracies, our experiments also show that the learned deep shapelets based
features are also highly interpretable and can help gain better understanding
of the underlying characteristics of time series data.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04580</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some conjectures on codes</dc:title>
 <dc:creator>De Felice, Clelia</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Variable-length codes are the bases of the free submonoids of a free monoid.
There are some important longstanding open questions about the structure of
finite maximal codes. In this paper we discuss this conjectures and their
relations with factorizations of cyclic groups.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04581</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to scale distributed deep learning?</dc:title>
 <dc:creator>Jin, Peter H.</dc:creator>
 <dc:creator>Yuan, Qiaochu</dc:creator>
 <dc:creator>Iandola, Forrest</dc:creator>
 <dc:creator>Keutzer, Kurt</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Training time on large datasets for deep neural networks is the principal
workflow bottleneck in a number of important applications of deep learning,
such as object classification and detection in automatic driver assistance
systems (ADAS). To minimize training time, the training of a deep neural
network must be scaled beyond a single machine to as many machines as possible
by distributing the optimization method used for training. While a number of
approaches have been proposed for distributed stochastic gradient descent
(SGD), at the current time synchronous approaches to distributed SGD appear to
be showing the greatest performance at large scale. Synchronous scaling of SGD
suffers from the need to synchronize all processors on each gradient step and
is not resilient in the face of failing or lagging processors. In asynchronous
approaches using parameter servers, training is slowed by contention to the
parameter server. In this paper we compare the convergence of synchronous and
asynchronous SGD for training a modern ResNet network architecture on the
ImageNet classification problem. We also propose an asynchronous method,
gossiping SGD, that aims to retain the positive features of both systems by
replacing the all-reduce collective operation of synchronous training with a
gossip aggregation algorithm. We find, perhaps counterintuitively, that
asynchronous SGD, including both elastic averaging and gossiping, converges
faster at fewer nodes (up to about 32 nodes), whereas synchronous SGD scales
better to more nodes (up to about 100 nodes).
</dc:description>
 <dc:description>Comment: Extended version of paper accepted at ML Sys 2016 (at NIPS 2016)</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04583</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Degree Distribution, Rank-size Distribution, and Leadership Persistence
  in Mediation-Driven Attachment Networks</dc:title>
 <dc:creator>Hassan, Md. Kamrul</dc:creator>
 <dc:creator>Islam, Liana</dc:creator>
 <dc:creator>Haque, Syed Arefinul</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We investigate the growth of a class of networks in which a new node first
picks a mediator at random and connects with $m$ randomly chosen neighbors of
the mediator at each time step. We show that degree distribution in such a
mediation-driven attachment (MDA) network exhibits power-law $P(k)\sim
k^{-\gamma(m)}$ with a spectrum of exponents depending on $m$. To appreciate
the contrast between MDA and Barab\'{a}si-Albert (BA) networks, we then discuss
their rank-size distribution. To quantify how long a leader, the node with the
maximum degree, persists in its leadership as the network evolves, we
investigate the leadership persistence probability $F(\tau)$ i.e. the
probability that a leader retains its leadership up to time $\tau$. We find
that it exhibits a power-law $F(\tau)\sim \tau^{-\theta(m)}$ with persistence
exponent $\theta(m) \approx 1.51 \ \forall \ m$ in the MDA networks and
$\theta(m) \rightarrow 1.53$ exponentially with $m$ in the BA networks.
</dc:description>
 <dc:description>Comment: 7 pages, 8 figures, accepted for publication in Physica A</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04583</dc:identifier>
 <dc:identifier>Physica A vol. 469 (2017) page 23-30</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2016.11.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04636</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Saliency Meets Sentiment: Understanding How Image Content Invokes
  Emotion and Sentiment</dc:title>
 <dc:creator>Zheng, Honglin</dc:creator>
 <dc:creator>Chen, Tianlang</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sentiment analysis is crucial for extracting social signals from social media
content. Due to the prevalence of images in social media, image sentiment
analysis is receiving increasing attention in recent years. However, most
existing systems are black-boxes that do not provide insight on how image
content invokes sentiment and emotion in the viewers. Psychological studies
have confirmed that salient objects in an image often invoke emotions. In this
work, we investigate more fine-grained and more comprehensive interaction
between visual saliency and visual sentiment. In particular, we partition
images in several primary scene-type dimensions, including: open-closed,
natural-manmade, indoor-outdoor, and face-noface. Using state of the art
saliency detection algorithm and sentiment classification algorithm, we examine
how the sentiment of the salient region(s) in an image relates to the overall
sentiment of the image. The experiments on a representative image emotion
dataset have shown interesting correlation between saliency and sentiment in
different scene types and in turn shed light on the mechanism of visual
sentiment evocation.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, submitted to AAAI-17</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04639</identifier>
 <datestamp>2017-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Day of the week effect in paper submission/acceptance/rejection to/in/by
  peer review journals. II. An ARCH econometric-like modeling</dc:title>
 <dc:creator>Ausloos, Marcel</dc:creator>
 <dc:creator>Nedic, Olgica</dc:creator>
 <dc:creator>Dekanski, Aleksandar</dc:creator>
 <dc:creator>Mrowinski, Maciej J.</dc:creator>
 <dc:creator>Fronczak, Piotr</dc:creator>
 <dc:creator>Fronczak, Agata</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  This paper aims at providing a statistical model for the preferred behavior
of authors submitting a paper to a scientific journal. The electronic
submission of (about 600) papers to the Journal of the Serbian Chemical Society
has been recorded for every day from Jan. 01, 2013 till Dec. 31, 2014, together
with the acceptance or rejection paper fate. Seasonal effects and editor roles
(through desk rejection and subfield editors) are examined. An ARCH-like
econometric model is derived stressing the main determinants of the favorite
day-of-week process.
</dc:description>
 <dc:description>Comment: 35 pages, 48 references, 10 figures, 5 tables; prepared for Physica A</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04639</dc:identifier>
 <dc:identifier>Physica A 468 (2017) 462-474</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2016.10.078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04642</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traversing Knowledge Graph in Vector Space without Symbolic Space
  Guidance</dc:title>
 <dc:creator>Shen, Yelong</dc:creator>
 <dc:creator>Huang, Po-Sen</dc:creator>
 <dc:creator>Chang, Ming-Wei</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent studies on knowledge base completion, the task of recovering missing
facts based on observed facts, demonstrate the importance of learning
embeddings from multi-step relations. Due to the size of knowledge bases,
previous works manually design relation paths of observed triplets in symbolic
space (e.g. random walk) to learn multi-step relations during training.
However, these approaches suffer some limitations as most paths are not
informative, and it is prohibitively expensive to consider all possible paths.
To address the limitations, we propose learning to traverse in vector space
directly without the need of symbolic space guidance. To remember the
connections between related observed triplets and be able to adaptively change
relation paths in vector space, we propose Implicit ReasoNets (IRNs), that is
composed of a global memory and a controller module to learn multi-step
relation paths in vector space and infer missing facts jointly without any
human-designed procedure. Without using any axillary information, our proposed
model achieves state-of-the-art results on popular knowledge base completion
benchmarks.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04645</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview on Resource Allocation Techniques for Multi-User MIMO
  Systems</dc:title>
 <dc:creator>Casta&#xf1;eda, Eduardo</dc:creator>
 <dc:creator>Silva, Ad&#xe3;o</dc:creator>
 <dc:creator>Gameiro, At&#xed;lio</dc:creator>
 <dc:creator>Kountouris, Marios</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Remarkable research activities and major advances have been occurred over the
past decade in multiuser multiple-input multiple-output (MU-MIMO) systems.
Several transmission technologies and precoding techniques have been developed
in order to exploit the spatial dimension so that simultaneous transmission of
independent data streams reuse the same radio resources. The achievable
performance of such techniques heavily depends on the channel characteristics
of the selected users, the amount of channel knowledge, and how efficiently
interference is mitigated. In systems where the total number of receivers is
larger than the number of total transmit antennas, user selection becomes a key
approach to benefit from multiuser diversity and achieve full multiplexing
gain. The overall performance of MU-MIMO systems is a complex joint
multi-objective optimization problem since many variables and parameters have
to be optimized, including the number of users, the number of antennas, spatial
signaling, rate and power allocation, and transmission technique. The objective
of this literature survey is to provide a comprehensive overview of the various
methodologies used to approach the aforementioned joint optimization task in
the downlink of MU-MIMO communication systems.
</dc:description>
 <dc:description>Comment: 45 pages, 12 figures, accepted in IEEE Communications Surveys and
  Tutorials</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04645</dc:identifier>
 <dc:identifier>IEEE Communications Surveys and Tutorials, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/COMST.2016.2618870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04648</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Framework for Tracking Multiple Targets: Hybrid Systems meets
  Computational Geometry</dc:title>
 <dc:creator>Laguna, Guillermo J.</dc:creator>
 <dc:creator>Zou, Rui</dc:creator>
 <dc:creator>Bhattacharya, Sourabh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We investigate a variation of the art gallery problem in which a team of
mobile guards tries to track an unpredictable intruder in a simply-connected
polygonal environment. In this work, we use the deployment strategy for
diagonal guards originally proposed in [1]. The guards are confined to move
along the diagonals of a polygon and the intruder can move freely within the
environment. We define critical regions to generate event-triggered strategies
for the guards. We design a hybrid automaton based on the critical regions to
model the tracking problem. Based on reachability analysis, we provide
necessary and sufficient conditions for tracking in terms of the maximal
controlled invariant set of the hybrid system. We express these conditions in
terms of the critical curves to find sufficient conditions for n/4 guards to
track the mobile intruder using the reachability analysis.
</dc:description>
 <dc:description>Comment: The paper contains 8 pages, 9 figures, and it is a conference paper</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04653</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event Detection and Localization in Distribution Grids with Phasor
  Measurement Units</dc:title>
 <dc:creator>Ardakanian, Omid</dc:creator>
 <dc:creator>Yuan, Ye</dc:creator>
 <dc:creator>Dobbe, Roel</dc:creator>
 <dc:creator>von Meier, Alexandra</dc:creator>
 <dc:creator>Low, Steven</dc:creator>
 <dc:creator>Tomlin, Claire</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The recent introduction of synchrophasor technology into power distribution
systems has given impetus to various monitoring, diagnostic, and control
applications, such as system identification and event detection, which are
crucial for restoring service, preventing outages, and managing equipment
health. Drawing on the existing framework for inferring topology and
admittances of a power network from voltage and current phasor measurements,
this paper proposes an online algorithm for event detection and localization in
unbalanced three-phase distribution systems. Using a convex relaxation and a
matrix partitioning technique, the proposed algorithm is capable of identifying
topology changes and attributing them to specific categories of events. The
performance of this algorithm is evaluated on a standard test distribution
feeder with synthesized loads, and it is shown that a tripped line can be
detected and localized in an accurate and timely fashion, highlighting its
potential for real-world applications.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04654</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Performance Analysis of Majority Sentiment Detection in
  Online Social Networks</dc:title>
 <dc:creator>Tong, Tian</dc:creator>
 <dc:creator>Negi, Rohit</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We analyze the problem of majority sentiment detection in Online Social
Networks (OSN), and relate the detection error probability to the underlying
graph of the OSN. Modeling the underlying social network as an Ising Markov
random field prior based on a given graph, we show that in the case of the
empty graph (independent sentiments) and the chain graph, the detection is
always inaccurate, even when the number of users grow to infinity. In the case
of the complete graph, the detection is inaccurate if the connection strength
is below a certain critical value, while it is asymptotically accurate if the
strength is above that critical value, which is analogous to the phase
transition phenomenon in statistical physics.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04655</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion Estimated-Compensated Reconstruction with Preserved-Features in
  Free-Breathing Cardiac MRI</dc:title>
 <dc:creator>Bustin, Aurelien</dc:creator>
 <dc:creator>Menini, Anne</dc:creator>
 <dc:creator>Janich, Martin A.</dc:creator>
 <dc:creator>Burschka, Darius</dc:creator>
 <dc:creator>Felblinger, Jacques</dc:creator>
 <dc:creator>Brau, Anja C. S.</dc:creator>
 <dc:creator>Odille, Freddy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  To develop an efficient motion-compensated reconstruction technique for
free-breathing cardiac magnetic resonance imaging (MRI) that allows
high-quality images to be reconstructed from multiple undersampled single-shot
acquisitions. The proposed method is a joint image reconstruction and motion
correction method consisting of several steps, including a non-rigid motion
extraction and a motion-compensated reconstruction. The reconstruction includes
a denoising with the Beltrami regularization, which offers an ideal compromise
between feature preservation and staircasing reduction. Results were assessed
in simulation, phantom and volunteer experiments. The proposed joint image
reconstruction and motion correction method exhibits visible quality
improvement over previous methods while reconstructing sharper edges. Moreover,
when the acceleration factor increases, standard methods show blurry results
while the proposed method preserves image quality. The method was applied to
free-breathing single-shot cardiac MRI, successfully achieving high image
quality and higher spatial resolution than conventional segmented methods, with
the potential to offer high-quality delayed enhancement scans in challenging
patients.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, accepted at MICCAI 2016</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04660</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causal Inference in Observational Data</dc:title>
 <dc:creator>Yadav, Pranjul</dc:creator>
 <dc:creator>Prunelli, Lisiane</dc:creator>
 <dc:creator>Hoff, Alexander</dc:creator>
 <dc:creator>Steinbach, Michael</dc:creator>
 <dc:creator>Westra, Bonnie</dc:creator>
 <dc:creator>Kumar, Vipin</dc:creator>
 <dc:creator>Simon, Gyorgy</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Our aging population increasingly suffers from multiple chronic diseases
simultaneously, necessitating the comprehensive treatment of these conditions.
Finding the optimal set of drugs for a combinatorial set of diseases is a
combinatorial pattern exploration problem. Association rule mining is a popular
tool for such problems, but the requirement of health care for finding causal,
rather than associative, patterns renders association rule mining unsuitable.
To address this issue, we propose a novel framework based on the Rubin-Neyman
causal model for extracting causal rules from observational data, correcting
for a number of common biases. Specifically, given a set of interventions and a
set of items that define subpopulations (e.g., diseases), we wish to find all
subpopulations in which effective intervention combinations exist and in each
such subpopulation, we wish to find all intervention combinations such that
dropping any intervention from this combination will reduce the efficacy of the
treatment. A key aspect of our framework is the concept of closed intervention
sets which extend the concept of quantifying the effect of a single
intervention to a set of concurrent interventions. We also evaluated our causal
rule mining framework on the Electronic Health Records (EHR) data of a large
cohort of patients from Mayo Clinic and showed that the patterns we extracted
are sufficiently rich to explain the controversial findings in the medical
literature regarding the effect of a class of cholesterol drugs on Type-II
Diabetes Mellitus (T2DM).
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04665</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Physical Unclonable Function with Redox-based Nanoionic Resistive
  Memory</dc:title>
 <dc:creator>Kim, Jeeson</dc:creator>
 <dc:creator>Ahmed, Taimur</dc:creator>
 <dc:creator>Nili, Hussein</dc:creator>
 <dc:creator>Yang, Jiawei</dc:creator>
 <dc:creator>Jeong, Doo Seok</dc:creator>
 <dc:creator>Beckett, Paul</dc:creator>
 <dc:creator>Sriram, Sharath</dc:creator>
 <dc:creator>Ranasinghe, Damith C.</dc:creator>
 <dc:creator>Kavehei, Omid</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:description>  A unique set of characteristics are packed in emerging nonvolatile
reduction-oxidation (redox)-based resistive switching memories (ReRAMs) such as
their underlying stochastic switching processes alongside their intrinsic
highly nonlinear current-voltage characteristic, which in addition to known
nano-fabrication process variation make them a promising candidate for the next
generation of low-cost, low-power, tiny and secure Physically Unclonable
Functions (PUFs). This paper takes advantage of this otherwise disadvantageous
ReRAM feature using a combination of novel architectural and peripheral
circuitry. We present a physical one-way function, nonlinear resistive Physical
Unclonable Function (nrPUF), potentially applicable in variety of
cyber-physical security applications given its performance characteristics. We
experimentally verified performance of Valency Change Mechanism (VCM)-based
ReRAM in nano-fabricated crossbar arrays across multiple dies and runs. In
addition to a massive pool of Challenge-Response Pairs (CRPs), using a
combination of experimental and simulation, our proposed PUF shows a
reliability of 98.67%, a uniqueness of 49.85%, a diffuseness of 49.86%, a
uniformity of 47.28%, and a bit-aliasing of 47.48%.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04666</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generic Coordinate Descent Framework for Learning from Implicit
  Feedback</dc:title>
 <dc:creator>Bayer, Immanuel</dc:creator>
 <dc:creator>He, Xiangnan</dc:creator>
 <dc:creator>Kanagal, Bhargav</dc:creator>
 <dc:creator>Rendle, Steffen</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In recent years, interest in recommender research has shifted from explicit
feedback towards implicit feedback data. A diversity of complex models has been
proposed for a wide variety of applications. Despite this, learning from
implicit feedback is still computationally challenging. So far, most work
relies on stochastic gradient descent (SGD) solvers which are easy to derive,
but in practice challenging to apply, especially for tasks with many items. For
the simple matrix factorization model, an efficient coordinate descent (CD)
solver has been previously proposed. However, efficient CD approaches have not
been derived for more complex models.
  In this paper, we provide a new framework for deriving efficient CD
algorithms for complex recommender models. We identify and introduce the
property of k-separable models. We show that k-separability is a sufficient
property to allow efficient optimization of implicit recommender problems with
CD. We illustrate this framework on a variety of state-of-the-art models
including factorization machines and Tucker decomposition. To summarize, our
work provides the theory and building blocks to derive efficient implicit CD
algorithms for complex recommender models.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04683</identifier>
 <datestamp>2017-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time kinematic positioning of LEO satellites using a
  single-frequency GPS receiver</dc:title>
 <dc:creator>Chen, Pei</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:creator>Sun, Xiucong</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Due to their low cost and low power consumption, single-frequency GPS
receivers are considered suitable for low-cost space applications such as small
satellite missions. Recently, requirements have emerged for real-time accurate
orbit determination at sub-meter level in order to carry out onboard geocoding
of high-resolution imagery, open-loop operation of altimeters and radio
occultation. This study proposes an improved real-time kinematic positioning
method for LEO satellites using single-frequency receivers. The C/A code and L1
phase are combined to eliminate ionospheric effects. The epoch-differenced
carrier phase measurements are utilized to acquire receiver position changes
which are further used to smooth the absolute positions. A kinematic Kalman
filter is developed to implement kinematic orbit determination. Actual flight
data from China small satellite SJ-9A are used to test the navigation
performance. Results show that the proposed method outperforms traditional
kinematic positioning method in terms of accuracy. A 3D position accuracy of
0.72 m and 0.79 m has been achieved using the predicted portion of IGS
ultra-rapid products and broadcast ephemerides, respectively.
</dc:description>
 <dc:description>Comment: 27 pages, 8 figures, ready for publication in GPS Solutions</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04683</dc:identifier>
 <dc:identifier>doi:10.1007/s10291-016-0586-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04684</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Enhanced Hybrid Neural Network for Text Matching</dc:title>
 <dc:creator>Wu, Yu</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:creator>Li, Zhoujun</dc:creator>
 <dc:creator>Zhou, Ming</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Long text brings a big challenge to semantic matching due to their
complicated semantic and syntactic structures. To tackle the challenge, we
consider using prior knowledge to help identify useful information and filter
out noise to matching in long text. To this end, we propose a knowledge
enhanced hybrid neural network (KEHNN). The model fuses prior knowledge into
word representations by knowledge gates and establishes three matching channels
with words, sequential structures of sentences given by Gated Recurrent Units
(GRU), and knowledge enhanced representations. The three channels are processed
by a convolutional neural network to generate high level features for matching,
and the features are synthesized as a matching score by a multilayer
perceptron. The model extends the existing methods by conducting matching on
words, local structures of sentences, and global context of sentences.
Evaluation results from extensive experiments on public data sets for question
answering and conversation show that KEHNN can significantly outperform
the-state-of-the-art matching models and particularly improve the performance
on pairs with long text.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04686</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Matrix Regression</dc:title>
 <dc:creator>Zhang, Hang</dc:creator>
 <dc:creator>Zhu, Fengyuan</dc:creator>
 <dc:creator>Li, Shixin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Modern technologies are producing datasets with complex intrinsic structures,
and they can be naturally represented as matrices instead of vectors. To
preserve the latent data structures during processing, modern regression
approaches incorporate the low-rank property to the model and achieve
satisfactory performance for certain applications. These approaches all assume
that both predictors and labels for each pair of data within the training set
are accurate. However, in real-world applications, it is common to see the
training data contaminated by noises, which can affect the robustness of these
matrix regression methods. In this paper, we address this issue by introducing
a novel robust matrix regression method. We also derive efficient proximal
algorithms for model training. To evaluate the performance of our methods, we
apply it to real world applications with comparative studies. Our method
achieves the state-of-the-art performance, which shows the effectiveness and
the practical value of our method.
</dc:description>
 <dc:description>Comment: 8 pages, 4 tables</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04687</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intrinsic Geometric Information Transfer Learning on Multiple
  Graph-Structured Datasets</dc:title>
 <dc:creator>Lee, Jaekoo</dc:creator>
 <dc:creator>Kim, Hyunjae</dc:creator>
 <dc:creator>Lee, Jongsun</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Graphs provide a powerful means for representing complex interactions between
entities. Recently, deep learning approaches are emerging for representing and
modeling graph-structured data, although the conventional deep learning methods
(such as convolutional neural networks and recurrent neural networks) have
mainly focused on grid-structured inputs (image and audio). Leveraged by the
capability of representation learning, deep learning based techniques are
reporting promising results for graph applications by detecting structural
characteristics of graphs in an automated fashion. In this paper, we attempt to
advance deep learning for graph-structured data by incorporating another
component, transfer learning. By transferring the intrinsic geometric
information learned in the source domain, our approach can help us to construct
a model for a new but related task in the target domain without collecting new
data and without training a new model from scratch. We thoroughly test our
approach with large-scale real corpora and confirm the effectiveness of the
proposed transfer learning framework for deep learning on graphs. According to
our experiments, transfer learning is most effective when the source and target
domains bear a high level of structural similarity in their graph
representations.
</dc:description>
 <dc:description>Comment: AAAI 2017 Conference</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04689</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Similarity Search Combining Query Relaxation and Diversification</dc:title>
 <dc:creator>Shi, Ruoxi</dc:creator>
 <dc:creator>Wang, Hongzhi</dc:creator>
 <dc:creator>Wang, Tao</dc:creator>
 <dc:creator>Hou, Yutai</dc:creator>
 <dc:creator>Tang, Yiwen</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We study the similarity search problem which aims to find the similar query
results according to a set of given data and a query string. To balance the
result number and result quality, we combine query result diversity with query
relaxation. Relaxation guarantees the number of the query results, returning
more relevant elements to the query if the results are too few, while the
diversity tries to reduce the similarity among the returned results. By making
a trade-off of similarity and diversity, we improve the user experience. To
achieve this goal, we define a novel goal function combining similarity and
diversity. Aiming at this goal, we propose three algorithms. Among them,
algorithms genGreedy and genCluster perform relaxation first and select part of
the candidates to diversify. The third algorithm CB2S splits the dataset into
smaller pieces using the clustering algorithm of k-means and processes queries
in several small sets to retrieve more diverse results. The balance of
similarity and diversity is determined through setting a threshold, which has a
default value and can be adjusted according to users' preference. The
performance and efficiency of our system are demonstrated through extensive
experiments based on various datasets.
</dc:description>
 <dc:description>Comment: Conference: DASFAA 2017</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04704</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SIR Asymptotics in General Network Models</dc:title>
 <dc:creator>Guo, Anjin</dc:creator>
 <dc:creator>Haenggi, Martin</dc:creator>
 <dc:creator>Ganti, Radha Krishna</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  In the performance analyses of wireless networks, asymptotic quantities and
properties often pro- vide useful results and insights. The asymptotic analyses
become especially important when complete analytical expressions of the
performance metrics of interest are not available, which is often the case if
one departs from very specific modeling assumptions. In this paper, we consider
the asymptotics of the SIR distribution in general wireless network models,
including ad hoc and cellular networks, simple and non-simple point processes,
and singular and bounded path loss models, for which, in most cases, finding
analytical expressions of the complete SIR distribution seems hopeless. We show
that the lower tails of the SIR distributions decay polynomially with the order
solely determined by the path loss exponent or the fading parameter, while the
upper tails decay exponentially, with the exception of cellular networks with
singular path loss. In addition, we analyze the impact of the nearest
interferer on the asymptotic properties of the SIR distributions, and we
formulate three crisp conjectures that -if true- determine the asymptotic
behavior in many cases based on the large-scale path loss properties of the
desired signal and/or nearest interferer only.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04705</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimally Leveraging Density and Locality to Support LIMIT Queries</dc:title>
 <dc:creator>Kim, Albert</dc:creator>
 <dc:creator>Xu, Liqi</dc:creator>
 <dc:creator>Siddiqui, Tarique</dc:creator>
 <dc:creator>Huang, Silu</dc:creator>
 <dc:creator>Madden, Samuel</dc:creator>
 <dc:creator>Parameswaran, Aditya</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Existing database systems are not optimized for queries with a LIMIT
clause---operating instead in an all-or-nothing manner. In this paper, we
propose a fast LIMIT query evaluation engine, called NeedleTail, aimed at
letting analysts browse a small sample of the query results on large datasets
as quickly as possible, independent of the overall size of the result set.
NeedleTail introduces density maps, a lightweight in-memory indexing structure,
and a set of efficient algorithms (with desirable theoretical guarantees) to
quickly locate promising blocks, trading off locality and density. In settings
where the samples are used to compute aggregates, we extend techniques from
survey sampling to mitigate the bias in our samples. Our experimental results
demonstrate that NeedleTail returns results 4x faster on HDDs and 9x faster on
SSDs on average, while occupying up to 23x less memory than existing
techniques.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04706</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Dimensional Stochastic Optimal Control using Continuous Tensor
  Decompositions</dc:title>
 <dc:creator>Gorodetsky, Alex A.</dc:creator>
 <dc:creator>Karaman, Sertac</dc:creator>
 <dc:creator>Marzouk, Youssef M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>93E20, 49L20, 90C40</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:description>  Motion planning and control problems are embedded and essential in almost all
robotics applications. These problems are often formulated as stochastic
optimal control problems and solved using dynamic programming algorithms.
Unfortunately, most existing algorithms that guarantee convergence to optimal
solutions suffer from the curse of dimensionality: the run time of the
algorithm grows exponentially with the dimension of the state space of the
system. We propose novel dynamic programming algorithms that alleviate the
curse of dimensionality in problems that exhibit certain low-rank structure.
The proposed algorithms are based on continuous tensor decompositions recently
developed by the authors. Essentially, the algorithms represent
high-dimensional functions (e.g., the value function) in a compressed format,
and directly perform dynamic programming computations (e.g., value iteration,
policy iteration) in this format. Under certain technical assumptions, the new
algorithms guarantee convergence towards optimal solutions with arbitrary
precision. Furthermore, the run times of the new algorithms scale polynomially
with the state dimension and polynomially with the ranks of the value function.
This approach realizes substantial computational savings in &quot;compressible&quot;
problem instances, where value functions admit low-rank approximations. We
demonstrate the new algorithms in a wide range of problems, including a
simulated six-dimensional agile quadcopter maneuvering example and a
seven-dimensional aircraft perching example. In some of these examples, we
estimate computational savings of up to ten orders of magnitude over standard
value iteration algorithms. We further demonstrate the algorithms running in
real time on board a quadcopter during a flight experiment under motion
capture.
</dc:description>
 <dc:description>Comment: 32 pages, 20 figures</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04709</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recoverability of Joint Distribution from Missing Data</dc:title>
 <dc:creator>Tian, Jin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A probabilistic query may not be estimable from observed data corrupted by
missing values if the data are not missing at random (MAR). It is therefore of
theoretical interest and practical importance to determine in principle whether
a probabilistic query is estimable from missing data or not when the data are
not MAR. We present an algorithm that systematically determines whether the
joint probability is estimable from observed data with missing values, assuming
that the data-generation model is represented as a Bayesian network containing
unobserved latent variables that not only encodes the dependencies among the
variables but also explicitly portrays the mechanisms responsible for the
missingness process. The result significantly advances the existing work.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04717</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>#Exploration: A Study of Count-Based Exploration for Deep Reinforcement
  Learning</dc:title>
 <dc:creator>Tang, Haoran</dc:creator>
 <dc:creator>Houthooft, Rein</dc:creator>
 <dc:creator>Foote, Davis</dc:creator>
 <dc:creator>Stooke, Adam</dc:creator>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Duan, Yan</dc:creator>
 <dc:creator>Schulman, John</dc:creator>
 <dc:creator>De Turck, Filip</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Count-based exploration algorithms are known to perform near-optimally when
used in conjunction with tabular reinforcement learning (RL) methods for
solving small discrete Markov decision processes (MDPs). It is generally
thought that count-based methods cannot be applied in high-dimensional state
spaces, since most states will only occur once. Recent deep RL exploration
strategies are able to deal with high-dimensional continuous state spaces
through complex heuristics, often relying on optimism in the face of
uncertainty or intrinsic motivation. In this work, we describe a surprising
finding: a simple generalization of the classic count-based approach can reach
near state-of-the-art performance on various high-dimensional and/or continuous
deep RL benchmarks. States are mapped to hash codes, which allows to count
their occurrences with a hash table. These counts are then used to compute a
reward bonus according to the classic count-based exploration theory. We find
that simple hash functions can achieve surprisingly good results on many
challenging tasks. Furthermore, we show that a domain-dependent learned hash
code may further improve these results. Detailed analysis reveals important
aspects of a good hash function: 1) having appropriate granularity and 2)
encoding information relevant to solving the MDP. This exploration strategy
achieves near state-of-the-art performance on both continuous control tasks and
Atari 2600 games, hence providing a simple yet powerful baseline for solving
MDPs that require considerable exploration.
</dc:description>
 <dc:description>Comment: 10 pages main text + 10 pages supplementary. Published at NIPS 2017</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04741</identifier>
 <datestamp>2017-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural Architecture Mimicking Humans End-to-End for Natural Language
  Inference</dc:title>
 <dc:creator>Paria, Biswajit</dc:creator>
 <dc:creator>Annervaz, K. M.</dc:creator>
 <dc:creator>Dukkipati, Ambedkar</dc:creator>
 <dc:creator>Chatterjee, Ankush</dc:creator>
 <dc:creator>Podder, Sanjay</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this work we use the recent advances in representation learning to propose
a neural architecture for the problem of natural language inference. Our
approach is aligned to mimic how a human does the natural language inference
process given two statements. The model uses variants of Long Short Term Memory
(LSTM), attention mechanism and composable neural networks, to carry out the
task. Each part of our model can be mapped to a clear functionality humans do
for carrying out the overall task of natural language inference. The model is
end-to-end differentiable enabling training by stochastic gradient descent. On
Stanford Natural Language Inference(SNLI) dataset, the proposed model achieves
better accuracy numbers than all published models in literature.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04748</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Handover Through Dual Connectivity in 5G mmWave Mobile Networks</dc:title>
 <dc:creator>Polese, Michele</dc:creator>
 <dc:creator>Giordani, Marco</dc:creator>
 <dc:creator>Mezzavilla, Marco</dc:creator>
 <dc:creator>Rangan, Sundeep</dc:creator>
 <dc:creator>Zorzi, Michele</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The millimeter wave (mmWave) bands offer the possibility of orders of
magnitude greater throughput for fifth generation (5G) cellular systems.
However, since mmWave signals are highly susceptible to blockage, channel
quality on any one mmWave link can be extremely intermittent. This paper
implements a novel dual connectivity protocol that enables mobile user
equipment (UE) devices to maintain physical layer connections to 4G and 5G
cells simultaneously. A novel uplink control signaling system combined with a
local coordinator enables rapid path switching in the event of failures on any
one link. This paper provides the first comprehensive end-to-end evaluation of
handover mechanisms in mmWave cellular systems. The simulation framework
includes detailed measurement-based channel models to realistically capture
spatial dynamics of blocking events, as well as the full details of MAC, RLC
and transport protocols. Compared to conventional handover mechanisms, the
study reveals significant benefits of the proposed method under several
metrics.
</dc:description>
 <dc:description>Comment: 16 pages, 13 figures, to appear on the 2017 IEEE JSAC Special Issue
  on Millimeter Wave Communications for Future Mobile Networks</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04748</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2720338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04760</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Opening Scholarly Communication in Social Sciences project OSCOSS</dc:title>
 <dc:creator>Mayr, Philipp</dc:creator>
 <dc:creator>Lange, Christoph</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The OSCOSS project (Opening Scholarly Communication in Social Sciences),
which will be outlined, aims at providing integrated support for all steps of
the scholarly communication process. Incl. collaborative writing of a
scientific paper, collecting data related to existing publications,
interpreting and including data in a paper, submitting the paper for peer
review, reviewing the paper, publishing an article, and, finally, facilitating
its consumption by readers. The OSCOSS project will support this process
considering in particular the perspective of three main actors detailed in the
use case descriptions below: readers, authors and reviewers.
</dc:description>
 <dc:description>Comment: 9 pages, 1 figure, Book chapter in the Festschrift for Konrad Umlauf.
  &quot;Bibliothek. Forschung f\&quot;ur die Praxis&quot;</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04766</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentiable Genetic Programming</dc:title>
 <dc:creator>Izzo, Dario</dc:creator>
 <dc:creator>Biscani, Francesco</dc:creator>
 <dc:creator>Mereta, Alessio</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce the use of high order automatic differentiation, implemented via
the algebra of truncated Taylor polynomials, in genetic programming. Using the
Cartesian Genetic Programming encoding we obtain a high-order Taylor
representation of the program output that is then used to back-propagate errors
during learning. The resulting machine learning framework is called
differentiable Cartesian Genetic Programming (dCGP). In the context of symbolic
regression, dCGP offers a new approach to the long unsolved problem of constant
representation in GP expressions. On several problems of increasing complexity
we find that dCGP is able to find the exact form of the symbolic expression as
well as the constants values. We also demonstrate the use of dCGP to solve a
large class of differential equations and to find prime integrals of dynamical
systems, presenting, in both cases, results that confirm the efficacy of our
approach.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04767</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of Seasonal Temperature Using Soft Computing Techniques:
  Application in Benevento (Southern Italy) Area</dc:title>
 <dc:creator>Rampone, Salvatore</dc:creator>
 <dc:creator>Valente, Alessio</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Atmospheric and Oceanic Physics</dc:subject>
 <dc:description>  In this work two soft computing methods, Artificial Neural Networks and
Genetic Programming, are proposed in order to forecast the mean temperature
that will occur in future seasons. The area in which the soft computing
techniques were applied is that of the surroundings of the town of Benevento,
in the south of Italy, having geographic coordinates (lat. 41{\deg}07'50&quot;N;
long.14{\deg}47'13&quot;E). This area is not affected by maritime influences as well
as by winds coming from the west. The methods are fed by data recorded in the
meteorological stations of Benevento and Castelvenere, located in the hilly
area, which characterizes the territory surrounding this city, at 144 m a.s.l.
Both the applied methods show low error rates, while the Genetic Programming
offers an explicit rule representation (a formula) explaining the prevision.
  Keywords Seasonal Temperature Forecasting; Soft Computing; Artificial Neural
Networks; Genetic Programming; Southern Italy.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04767</dc:identifier>
 <dc:identifier>Journal of Ambient Intelligence and Humanized Computing (2016)</dc:identifier>
 <dc:identifier>doi:10.1007/s12652-016-0403-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04782</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Extraction and Soft Computing Methods for Aerospace Structure
  Defect Classification</dc:title>
 <dc:creator>D'Angelo, Gianni</dc:creator>
 <dc:creator>Rampone, Salvatore</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This study concerns the effectiveness of several techniques and methods of
signals processing and data interpretation for the diagnosis of aerospace
structure defects. This is done by applying different known feature extraction
methods, in addition to a new CBIR-based one; and some soft computing
techniques including a recent HPC parallel implementation of the U-BRAIN
learning algorithm on Non Destructive Testing data. The performance of the
resulting detection systems are measured in terms of Accuracy, Sensitivity,
Specificity, and Precision. Their effectiveness is evaluated by the Matthews
correlation, the Area Under Curve (AUC), and the F-Measure. Several experiments
are performed on a standard dataset of eddy current signal samples for aircraft
structures. Our experimental results evidence that the key to a successful
defect classifier is the feature extraction method - namely the novel
CBIR-based one outperforms all the competitors - and they illustrate the
greater effectiveness of the U-BRAIN algorithm and the MLP neural network among
the soft computing methods in this kind of application.
  Keywords- Non-destructive testing (NDT); Soft Computing; Feature Extraction;
Classification Algorithms; Content-Based Image Retrieval (CBIR); Eddy Currents
(EC).
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04782</dc:identifier>
 <dc:identifier>Measurement Volume 85, May 2016, Pages 192-209</dc:identifier>
 <dc:identifier>doi:10.1016/j.measurement.2016.02.027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04783</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of Brain Networks with Unknown Correspondences</dc:title>
 <dc:creator>Ktena, Sofia Ira</dc:creator>
 <dc:creator>Parisot, Sarah</dc:creator>
 <dc:creator>Passerat-Palmbach, Jonathan</dc:creator>
 <dc:creator>Rueckert, Daniel</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Graph theory has drawn a lot of attention in the field of Neuroscience during
the last decade, mainly due to the abundance of tools that it provides to
explore the interactions of elements in a complex network like the brain. The
local and global organization of a brain network can shed light on mechanisms
of complex cognitive functions, while disruptions within the network can be
linked to neurodevelopmental disorders. In this effort, the construction of a
representative brain network for each individual is critical for further
analysis. Additionally, graph comparison is an essential step for inference and
classification analyses on brain graphs. In this work we explore a method based
on graph edit distance for evaluating graph similarity, when correspondences
between network elements are unknown due to different underlying subdivisions
of the brain. We test this method on 30 unrelated subjects as well as 40 twin
pairs and show that this method can accurately reflect the higher similarity
between two related networks compared to unrelated ones, while identifying node
correspondences.
</dc:description>
 <dc:description>Comment: Presented at The MICCAI-BACON 16 Workshop
  (https://arxiv.org/abs/1611.03363)</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04784</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate of convergence of major cost incurred in the in-situ permutation
  algorithm</dc:title>
 <dc:creator>Jha, Sumit Kumar</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The in-situ permutation algorithm due to MacLeod replaces
$(x_{1},\cdots,x_{n})$ by $(x_{p(1)},\cdots,x_{p(n)})$ where
$\pi=(p(1),\cdots,p(n))$ is a permutation of $\{1,2,\cdots,n\}$ using at most
$O(1)$ space. Kirshenhofer, Prodinger and Tichy have shown that the major cost
incurred in the algorithm satisfies a recurrence similar to sequence of the
number of key comparisons needed by the Quicksort algorithm to sort an array of
$n$ randomly permuted items. Further, Hwang has proved that the normalized cost
converges in distribution. Here, following Neininger and R\&quot;uschendorf, we
prove the that rate of convergence to be of the order $\Theta(\ln(n)/n)$ in the
Zolotarev metric.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04784</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04786</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AdversariaLib: An Open-source Library for the Security Evaluation of
  Machine Learning Algorithms Under Attack</dc:title>
 <dc:creator>Corona, Igino</dc:creator>
 <dc:creator>Biggio, Battista</dc:creator>
 <dc:creator>Maiorca, Davide</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present AdversariaLib, an open-source python library for the security
evaluation of machine learning (ML) against carefully-targeted attacks. It
supports the implementation of several attacks proposed thus far in the
literature of adversarial learning, allows for the evaluation of a wide range
of ML algorithms, runs on multiple platforms, and has multi-processing enabled.
The library has a modular architecture that makes it easy to use and to extend
by implementing novel attacks and countermeasures. It relies on other
widely-used open-source ML libraries, including scikit-learn and FANN.
Classification algorithms are implemented and optimized in C/C++, allowing for
a fast evaluation of the simulated attacks. The package is distributed under
the GNU General Public License v3, and it is available for download at
http://sourceforge.net/projects/adversarialib.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04798</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Multilingual Neural Machine Translation with Universal Encoder
  and Decoder</dc:title>
 <dc:creator>Ha, Thanh-Le</dc:creator>
 <dc:creator>Niehues, Jan</dc:creator>
 <dc:creator>Waibel, Alexander</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we present our first attempts in building a multilingual
Neural Machine Translation framework under a unified approach. We are then able
to employ attention-based NMT for many-to-many multilingual translation tasks.
Our approach does not require any special treatment on the network architecture
and it allows us to learn minimal number of free parameters in a standard way
of training. Our approach has shown its effectiveness in an under-resourced
translation scenario with considerable improvements up to 2.6 BLEU points. In
addition, the approach has achieved interesting and promising results when
applied in the translation task that there is no direct parallel corpus between
source and target languages.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04810</identifier>
 <datestamp>2017-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The NOESIS Network-Oriented Exploration, Simulation, and Induction
  System</dc:title>
 <dc:creator>Mart&#xed;nez, V&#xed;ctor</dc:creator>
 <dc:creator>Berzal, Fernando</dc:creator>
 <dc:creator>Cubero, Juan-Carlos</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Network data mining has become an important area of study due to the large
number of problems it can be applied to. This paper presents NOESIS, an open
source framework for network data mining that provides a large collection of
network analysis techniques, including the analysis of network structural
properties, community detection methods, link scoring, and link prediction, as
well as network visualization algorithms. It also features a complete
stand-alone graphical user interface that facilitates the use of all these
techniques. The NOESIS framework has been designed using solid object-oriented
design principles and structured parallel programming. As a lightweight library
with minimal external dependencies and a permissive software license, NOESIS
can be incorporated into other software projects. Released under a BSD license,
it is available from http://noesis.ikor.org.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04821</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint load balancing and interference mitigation in 5G HETNETS</dc:title>
 <dc:creator>Vu, Trung Kien</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Samarakoon, Sumudu</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:creator>Latva-aho, Matti</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  We study the problem of joint load balancing and interference mitigation in
heterogeneous networks (HetNets) in which massive multiple-input
multiple-output (MIMO) macro cell base station (BS) equipped with a large
number of antennas, overlaid with wireless self-backhauled small cells (SCs)
are assumed. Self-backhauled SC BSs with full-duplex communication employing
regular antenna arrays serve both macro users and SC users by using the
wireless backhaul from macro BS in the same frequency band. We formulate the
joint load balancing and interference mitigation problem as a network utility
maximization subject to wireless backhaul constraints. Subsequently, leveraging
the framework of stochastic optimization, the problem is decoupled into dynamic
scheduling of macro cell users, backhaul provisioning of SCs, and offloading
macro cell users to SCs as a function of interference and backhaul links. Via
numerical results, we show the performance gains of our proposed framework
under the impact of small cells density, number of base station antennas, and
transmit power levels at low and high frequency bands. We further provide
insights into the performance analysis and convergence of the proposed
framework. The numerical results show that the proposed user association
algorithm outperforms other baselines. Interestingly, we find that even at
lower frequency band the performance of open access small cell is close to that
of closed access at some operating points, the open access full- duplex small
cell still yields higher gain as compared to the closed access at higher
frequency bands. With increasing the small cell density or the wireless
backhaul quality, the open access full- duplex small cells outperform and
achieve a 5.6x gain in terms of cell-edge performance as compared to the closed
access ones in ultra-dense networks with 350 small cell base stations per km2 .
</dc:description>
 <dc:description>Comment: Published by IEEE Transactions on Wireless Communications, in which
  1) Integrated access and backhaul architecture for the considered 5G network
  scenario is proposed. 2) Joint user association and user scheduling scheme in
  5G mmWave Networks is presented, IEEE Transactions on Wireless
  Communications, 2017, Volume: PP Issue: 99</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04821</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2017.2718504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="109000" completeListSize="155308">2369777|110001</resumptionToken>
</ListRecords>
</OAI-PMH>
