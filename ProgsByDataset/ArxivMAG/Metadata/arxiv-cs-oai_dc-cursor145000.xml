<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:43:29Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|145001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04117</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Will This Video Go Viral? Explaining and Predicting the Popularity of
  Youtube Videos</dc:title>
 <dc:creator>Kong, Quyu</dc:creator>
 <dc:creator>Rizoiu, Marian-Andrei</dc:creator>
 <dc:creator>Wu, Siqi</dc:creator>
 <dc:creator>Xie, Lexing</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  What makes content go viral? Which videos become popular and why others
don't? Such questions have elicited significant attention from both researchers
and industry, particularly in the context of online media. A range of models
have been recently proposed to explain and predict popularity; however, there
is a short supply of practical tools, accessible for regular users, that
leverage these theoretical results. HIPie -- an interactive visualization
system -- is created to fill this gap, by enabling users to reason about the
virality and the popularity of online videos. It retrieves the metadata and the
past popularity series of Youtube videos, it employs Hawkes Intensity Process,
a state-of-the-art online popularity model for explaining and predicting video
popularity, and it presents videos comparatively in a series of interactive
plots. This system will help both content consumers and content producers in a
range of data-driven inquiries, such as to comparatively analyze videos and
channels, to explain and predict future popularity, to identify viral videos,
and to estimate response to online promotion.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04131</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Partly Overloaded Spreading Sequences with Variable Spreading Factor</dc:title>
 <dc:creator>Karrenbauer, Michael</dc:creator>
 <dc:creator>Weinand, Andreas</dc:creator>
 <dc:creator>Schotten, Hans D.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Future wireless communications systems are expected to support multi-service
operation, i.e. especially multi-rate as well as multi-level quality of service
(QoS) requirements. This evolution is mainly driven by the success of the
Internet of Things (IoT) and the growing presence of machine type communication
(MTC). Whereas in the last years information in wireless communication systems
was mainly generated or at least requested by humans and was also processed by
humans, we can now see a paradigm shift since so-called machine type
communication is gaining growing importance. Along with these changes we also
encounter changes regarding the quality of service requirements, data rate
requirements, latency constraints, different duty cycles et cetera. The
challenge for new communication systems will therefore be to enable different
user types and their different requirements efficiently. In this paper, we
present partly overloaded spreading sequences, i.e. sequences which are
globally orthogonal and sequences which interfere with a subset of sequences
while being orthogonal to the globally orthogonal sequences. Additionally, we
are able to vary the spreading factor of these sequences, which allows us to
flexibly assign appropriate sequences to different service types or user types
respectively. We propose the use of these sequences for a CDMA channel access
method which is able to flexibly support different traffic types.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04134</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic
  Experiences for Robot Action Execution</dc:title>
 <dc:creator>Rothfuss, Jonas</dc:creator>
 <dc:creator>Ferreira, Fabio</dc:creator>
 <dc:creator>Aksoy, Eren Erdal</dc:creator>
 <dc:creator>Zhou, You</dc:creator>
 <dc:creator>Asfour, Tamim</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a novel deep neural network architecture for representing robot
experiences in an episodic-like memory which facilitates encoding, recalling,
and predicting action experiences. Our proposed unsupervised deep episodic
memory model 1) encodes observed actions in a latent vector space and, based on
this latent encoding, 2) infers action categories, 3) reconstructs original
frames, and 4) predicts future frames. We evaluate the proposed model on two
different large-scale action datasets. Results show that conceptually similar
actions are mapped into the same region of the latent vector space. Results
show that conceptual similarity of videos is reflected by the proximity of
their vector representations in the latent space.Based on this contribution, we
introduce an action matching and retrieval mechanism and evaluate its
performance and generalization capability on a real humanoid robot in an action
execution scenario.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04137</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multisensor Online Transfer Learning for 3D LiDAR-based Human
  Classification with a Mobile Robot</dc:title>
 <dc:creator>Yan, Zhi</dc:creator>
 <dc:creator>Sun, Li</dc:creator>
 <dc:creator>Duckett, Tom</dc:creator>
 <dc:creator>Bellotto, Nicola</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Human detection and tracking is an essential task for service robots, where
the combined use of multiple sensors has potential advantages that are yet to
be exploited. In this paper, we introduce a framework allowing a robot to learn
a new 3D LiDAR-based human classifier from other sensors over time, taking
advantage of a multisensor tracking system. The main innovation is the use of
different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to
train, online, a new 3D LiDAR-based human classifier, exploiting a so-called
trajectory probability. Our framework uses this probability to check whether
new detections belongs to a human trajectory, estimated by different sensors
and/or detectors, and to learn a human classifier in a semi-supervised fashion.
The framework has been implemented and tested on a real-world dataset collected
by a mobile robot. We present experiments illustrating that our system is able
to effectively learn from different sensors and from the environment, and that
the performance of the 3D LiDAR-based human classification improves with the
number of sensors/detectors used.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, conference</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04153</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Quadrature for Multiple Related Integrals</dc:title>
 <dc:creator>Xi, Xiaoyue</dc:creator>
 <dc:creator>Briol, Fran&#xe7;ois-Xavier</dc:creator>
 <dc:creator>Girolami, Mark</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Bayesian probabilistic numerical methods are a set of tools providing
posterior distributions on the output of numerical methods. The use of these
methods is usually motivated by the fact that they can represent our
uncertainty due to incomplete/finite information about the continuous
mathematical problem being approximated. In this paper, we demonstrate that
this paradigm can provide additional advantages, such as the possibility of
transferring information between several numerical methods. This allows users
to represent uncertainty in a more faithful manner and, as a by-product,
provide increased numerical efficiency. We propose the first such numerical
method by extending the well-known Bayesian quadrature algorithm to the case
where we are interested in computing the integral of several related functions.
We then demonstrate its efficiency in the context of multi-fidelity models for
complex engineering systems, as well as a problem of global illumination in
computer graphics.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04159</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Who-Edits-What Predict Edit Survival?</dc:title>
 <dc:creator>Yard&#x131;m, Ali Batuhan</dc:creator>
 <dc:creator>Kristof, Victor</dc:creator>
 <dc:creator>Maystre, Lucas</dc:creator>
 <dc:creator>Grossglauser, Matthias</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The Internet has enabled the emergence of massive online collaborative
projects. As the number of contributors to these projects grows, it becomes
increasingly important to understand and predict whether the edits that users
make will eventually impact the project positively. Existing solutions either
rely on a user reputation system or consist of a highly-specialized predictor
tailored to a specific peer-production system. In this work, we explore a
different point in the solution space, which does not involve any content-based
feature of the edits. To this end, we formulate a statistical model of edit
outcomes. We view each edit as a game between the editor and the component of
the project. We posit that the probability of a positive outcome is a function
of the editor's skill, of the difficulty of editing the component and of a
user-component interaction term. Our model is broadly applicable, as it only
requires observing data about who makes an edit, what the edit affects and
whether the edit survives or not. Then, we consider Wikipedia and the Linux
kernel, two examples of large-scale collaborative projects, and we seek to
understand whether this simple model can effectively predict edit survival: in
both cases, we provide a positive answer. Our approach significantly
outperforms those based solely on user reputation and bridges the gap with
specialized predictors that use content-based features. Furthermore, inspecting
the model parameters enables us to discover interesting structure in the data.
Our method is simple to implement, computationally inexpensive, and it produces
interpretable results; as such, we believe that it is a valuable tool to
analyze collaborative systems.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04160</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Desingularization in the $q$-Weyl algebra</dc:title>
 <dc:creator>Koutschan, Christoph</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  In this paper, we study the desingularization problem in the first $q$-Weyl
algebra. We give an order bound for desingularized operators, and thus derive
an algorithm for computing desingularized operators in the first $q$-Weyl
algebra. Moreover, an algorithm is presented for computing a generating set of
the first $q$-Weyl closure of a given $q$-difference operator. As an
application, we certify that several instances of the colored Jones polynomial
are Laurent polynomial sequences by computing the corresponding desingularized
operator.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04161</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QuickNAT: Segmenting MRI Neuroanatomy in 20 seconds</dc:title>
 <dc:creator>Roy, Abhijit Guha</dc:creator>
 <dc:creator>Conjeti, Sailesh</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:creator>Wachinger, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Whole brain segmentation from structural magnetic resonance imaging is a
prerequisite for most morphological analyses, but requires hours of processing
time and therefore delays the availability of image markers after scan
acquisition. We introduce QuickNAT, a fully convolution neural network that
segments a brain scan in 20 seconds. To enable training of the complex network
with limited annotated data, we propose to pre-train on auxiliary labels
created from existing segmentation software and to subsequently fine-tune on
manual labels. In an extensive set of evaluations on eight datasets that cover
a wide age range, pathology, and different scanners, we demonstrate that
QuickNAT achieves superior performance to state-of-the-art methods, while being
about 700 times faster. This drastic speed up greatly facilitates the
processing of large data repositories and supports the translation of imaging
biomarkers by making them almost instantaneously available.
</dc:description>
 <dc:description>Comment: Under Review</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04163</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tableaux Calculus for Reducing Proof Size</dc:title>
 <dc:creator>Lettmann, Michael Peter</dc:creator>
 <dc:creator>Peltier, Nicolas</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A tableau calculus is proposed, based on a compressed representation of
clauses, where literals sharing a similar shape may be merged. The inferences
applied on these literals are fused when possible, which reduces the size of
the proof. It is shown that the obtained proof procedure is sound,
refutationally complete and allows to reduce the size of the tableau by an
exponential factor. The approach is compatible with all usual refinements of
tableaux.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04167</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mailbox Types for Unordered Interactions</dc:title>
 <dc:creator>de'Liguoro, Ugo</dc:creator>
 <dc:creator>Padovani, Luca</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:description>  We propose a type system for reasoning on protocol conformance and deadlock
freedom in networks of processes that communicate through unordered mailboxes.
We model these networks in the mailbox calculus, a mild extension of the
asynchronous {\pi}-calculus with first-class mailboxes and selective input. The
calculus subsumes the actor model and allows us to analyze networks with
dynamic topologies and varying number of processes possibly mixing different
concurrency abstractions. Well-typed processes are deadlock free and never fail
because of unexpected messages. For a non-trivial class of them, junk freedom
is also guaranteed. We illustrate the expressiveness of the calculus and of the
type system by encoding instances of non-uniform, concurrent objects, binary
sessions extended with joins and forks, and some known actor benchmarks.
</dc:description>
 <dc:description>Comment: working draft</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04170</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilayered Model of Speech</dc:title>
 <dc:creator>Chistyakov, Andrey</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Human speech is the most important part of General Artificial Intelligence
and subject of much research. The hypothesis proposed in this article provides
explanation of difficulties that modern science tackles in the field of human
brain simulation. The hypothesis is based on the author's conviction that the
brain of any given person has different ability to process and store
information. Therefore, the approaches that are currently used to create
General Artificial Intelligence have to be altered.
</dc:description>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04175</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A fast spectral divide-and-conquer method for banded matrices</dc:title>
 <dc:creator>&#x160;u&#x161;njara, Ana</dc:creator>
 <dc:creator>Kressner, Daniel</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65F15, 65F30, 65F50, 15A18</dc:subject>
 <dc:description>  Based on the spectral divide-and-conquer algorithm by Nakatsukasa and Higham
[SIAM J. Sci. Comput., 35(3): A1325-A1349, 2013], we propose a new algorithm
for computing all the eigenvalues and eigenvectors of a symmetric banded
matrix. For this purpose, we combine our previous work on the fast computation
of spectral projectors in the so called HODLR format, with a novel technique
for extracting a basis for the range of such a HODLR matrix. The numerical
experiments demonstrate that our algorithm exhibits quasilinear complexity and
allows for conveniently dealing with large-scale matrices.
</dc:description>
 <dc:description>Comment: 21 pages, 6 figures</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04179</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arhuaco: Deep Learning and Isolation Based Security for Distributed
  High-Throughput Computing</dc:title>
 <dc:creator>Ramirez, A. Gomez</dc:creator>
 <dc:creator>Lara, C.</dc:creator>
 <dc:creator>Betev, L.</dc:creator>
 <dc:creator>Bilanovic, D.</dc:creator>
 <dc:creator>Kebschull, U.</dc:creator>
 <dc:creator>Collaboration, for the ALICE</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Grid computing systems require innovative methods and tools to identify
cybersecurity incidents and perform autonomous actions i.e. without
administrator intervention. They also require methods to isolate and trace job
payload activity in order to protect users and find evidence of malicious
behavior. We introduce an integrated approach of security monitoring via
Security by Isolation with Linux Containers and Deep Learning methods for the
analysis of real time data in Grid jobs running inside virtualized
High-Throughput Computing infrastructure in order to detect and prevent
intrusions. A dataset for malware detection in Grid computing is described. We
show in addition the utilization of generative methods with Recurrent Neural
Networks to improve the collected dataset. We present Arhuaco, a prototype
implementation of the proposed methods. We empirically study the performance of
our technique. The results show that Arhuaco outperforms other methods used in
Intrusion Detection Systems for Grid Computing. The study is carried out in the
ALICE Collaboration Grid, part of the Worldwide LHC Computing Grid.
</dc:description>
 <dc:description>Comment: Manuscript submitted to the Journal of Grid Computing</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04185</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A reference model for interaction semantics</dc:title>
 <dc:creator>Reich, Johannes</dc:creator>
 <dc:creator>Schr&#xf6;der, Tizian</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Understanding the issue of semantic interoperability will be key in the
design of future IoT-devices and cyber physical systems. In this article, we
introduce a reference model for the interaction semantics of networking systems
to provide the basis for such an understanding. The notions of system,
function, information, action, event, interaction, process and meaning are
defined in a well suited way bridging the gap between the world of physics,
information and meaning. We apply the reference model to classify interaction
interfaces and components as well as to define the software layer and the role
concept. This provides important elements of a reference architecture to design
interoperable IoT-devices and cyber physical systems more easily.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04187</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MSDNN: Multi-Scale Deep Neural Network for Salient Object Detection</dc:title>
 <dc:creator>Xiao, Fen</dc:creator>
 <dc:creator>Deng, Wenzheng</dc:creator>
 <dc:creator>Peng, Liangchan</dc:creator>
 <dc:creator>Cao, Chunhong</dc:creator>
 <dc:creator>Hu, Kai</dc:creator>
 <dc:creator>Gao, Xieping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Salient object detection is a fundamental problem and has been received a
great deal of attentions in computer vision. Recently deep learning model
became a powerful tool for image feature extraction. In this paper, we propose
a multi-scale deep neural network (MSDNN) for salient object detection. The
proposed model first extracts global high-level features and context
information over the whole source image with recurrent convolutional neural
network (RCNN). Then several stacked deconvolutional layers are adopted to get
the multi-scale feature representation and obtain a series of saliency maps.
Finally, we investigate a fusion convolution module (FCM) to build a final
pixel level saliency map. The proposed model is extensively evaluated on four
salient object detection benchmark datasets. Results show that our deep model
significantly outperforms other 12 state-of-the-art approaches.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04190</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Youla Coding and Computation of Gaussian Feedback Capacity</dc:title>
 <dc:creator>Li, Chong</dc:creator>
 <dc:creator>Elia, Nicola</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose an approach to numerically compute the feedback
capacity of stationary finite dimensional Gaussian channels and construct
(arbitrarily close to) capacity-achieving feedback codes. In particular, we
first extend the interpretation of feedback communication over stationary
finite dimensional Gaussian channels as feedback control systems by showing
that, the problem of finding stabilizing feedback controllers with maximal
reliable transmission rate over Youla parameters coincides with the problem of
finding strictly causal filters to achieve feedback capacity derived in [2].
This extended interpretation provides an approach to construct deterministic
feedback coding schemes with double exponential decaying error probability. We
next propose asymptotic capacity-achieving upper bounds, which can be
numerically evaluated by solving finite dimensional convex optimizations. From
the filters that achieve the upper bounds, we apply the Youla-based
interpretation to construct feasible filters, i.e., feedback codes, leading to
a sequence of lower bounds. We prove the sequence of lower bounds is
asymptotically capacity-achieving.
</dc:description>
 <dc:description>Comment: 35 pages, 5 figures, submitted to IEEE Transactions on Information
  Theory</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04191</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing permanents of complex diagonally dominant matrices and tensors</dc:title>
 <dc:creator>Barvinok, Alexander</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>15A15, 05C65, 41A10, 68W25, 68R05</dc:subject>
 <dc:description>  We prove that for any $\lambda &gt; 1$, fixed in advance, the permanent of an $n
\times n$ complex matrix, where the absolute value of each diagonal entry is at
least $\lambda$ times bigger than the sum of the absolute values of all other
entries in the same row, can be approximated within any relative error $0 &lt;
\epsilon &lt; 1$ in quasi-polynomial $n^{O(\ln n - \ln \epsilon)}$ time. We extend
this result to multidimensional permanents of tensors and discuss its
application to weighted counting of perfect matchings in hypergraphs.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04199</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SwarmRob: A Toolkit for Reproducibility and Sharing of Experimental
  Artifacts in Robotics Research</dc:title>
 <dc:creator>P&#xf6;rtner, Aljoscha</dc:creator>
 <dc:creator>Hoffmann, Martin</dc:creator>
 <dc:creator>K&#xf6;nig, Matthias</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Due to the complexity of robotics, the reproducibility of results and
experiments is one of the fundamental problems in robotics research. While the
problem has been identified by the community, the approaches that address the
problem appropriately are limited. The toolkit proposed in this paper tries to
deal with the problem of reproducibility and sharing of experimental artifacts
in robotics research by a holistic approach based on operating-system-level
virtualization. The experimental artifacts of an experiment are isolated in
&quot;containers&quot; that can be distributed to other researchers. Based on this, this
paper presents a novel experimental workflow to describe, execute and
distribute experimental software-artifacts to heterogeneous robots dynamically.
As a result, the proposed solution supports researchers in executing and
reproducing experimental evaluations.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04211</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Sampling from Arbitrary Probability Distributions</dc:title>
 <dc:creator>Horger, Felix</dc:creator>
 <dc:creator>W&#xfc;rfl, Tobias</dc:creator>
 <dc:creator>Christlein, Vincent</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper proposes a fully connected neural network model to map samples
from a uniform distribution to samples of any explicitly known probability
density function. During the training, the Jensen-Shannon divergence between
the distribution of the model's output and the target distribution is
minimized. We experimentally demonstrate that our model converges towards the
desired state. It provides an alternative to existing sampling methods such as
inversion sampling, rejection sampling, Gaussian mixture models and
Markov-Chain-Monte-Carlo. Our model has high sampling efficiency and is easily
applied to any probability distribution, without the need of further analytical
or numerical calculations. It can produce correlated samples, such that the
output distribution converges faster towards the target than for independent
samples. But it is also able to produce independent samples, if single values
are fed into the network and the input values are independent as well. We focus
on one-dimensional sampling, but additionally illustrate a two-dimensional
example with a target distribution of dependent variables.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04215</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A unifying Perron-Frobenius theorem for nonnegative tensors via
  multi-homogeneous maps</dc:title>
 <dc:creator>Gautier, Antoine</dc:creator>
 <dc:creator>Tudisco, Francesco</dc:creator>
 <dc:creator>Hein, Matthias</dc:creator>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Inspired by the definition of symmetric decomposition, we introduce the
concept of shape partition of a tensor and formulate a general tensor spectral
problem that includes all the relevant spectral problems as special cases. We
formulate irreducibility and symmetry properties of a nonnegative tensor $T$ in
terms of the associated shape partition. We recast the spectral problem for $T$
as a fixed point problem on a suitable product of projective spaces. This
allows us to use the theory of multi-homogeneous order-preserving maps to
derive a general and unifying Perron-Frobenius theorem for nonnegative tensors
that either implies previous results of this kind or improves them by weakening
the assumptions there considered. We introduce a general power method for the
computation of the dominant tensor eigenpair, and provide a detailed
convergence analysis.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04223</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Intelligence Techniques for Next-Generation Context-Aware
  Wireless Networks</dc:title>
 <dc:creator>Bogale, Tadilo Endeshaw</dc:creator>
 <dc:creator>Wang, Xianbin</dc:creator>
 <dc:creator>Le, Long Bao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The next generation wireless networks (i.e. 5G and beyond), which would be
extremely dynamic and complex due to the ultra-dense deployment of
heterogeneous networks (HetNets), poses many critical challenges for network
planning, operation, management and troubleshooting. At the same time,
generation and consumption of wireless data are becoming increasingly
distributed with ongoing paradigm shift from people-centric to machine-oriented
communications, making the operation of future wireless networks even more
complex. In mitigating the complexity of future network operation, new
approaches of intelligently utilizing distributed computational resources with
improved context-awareness becomes extremely important. In this regard, the
emerging fog (edge) computing architecture aiming to distribute computing,
storage, control, communication, and networking functions closer to end users,
have a great potential for enabling efficient operation of future wireless
networks. These promising architectures make the adoption of artificial
intelligence (AI) principles which incorporate learning, reasoning and
decision-making mechanism, as natural choices for designing a tightly
integrated network. Towards this end, this article provides a comprehensive
survey on the utilization of AI integrating machine learning, data analytics
and natural language processing (NLP) techniques for enhancing the efficiency
of wireless network operation. In particular, we provide comprehensive
discussion on the utilization of these techniques for efficient data
acquisition, knowledge discovery, network planning, operation and management of
the next generation wireless networks. A brief case study utilizing the AI
techniques for this network has also been provided.
</dc:description>
 <dc:description>Comment: ITU Special Issue N.1 The impact of Artificial Intelligence (AI) on
  communication networks and services, (To appear)</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04229</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>List Decoding of Locally Repairable Codes</dc:title>
 <dc:creator>Holzbaur, Lukas</dc:creator>
 <dc:creator>Wachter-Zeh, Antonia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We show that locally repairable codes (LRCs) can be list decoded efficiently
beyond the Johnson radius for a large range of parameters by utilizing the
local error correction capabilities. The new decoding radius is derived and the
asymptotic behavior is analyzed. We give a general list decoding algorithm for
LRCs that achieves this radius along with an explicit realization for a class
of LRCs based on Reed-Solomon codes (Tamo-Barg LRCs). Further, a probabilistic
algorithm for unique decoding of low complexity is given and its success
probability analyzed.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04241</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Streaming Codes for Channels with Burst and Arbitrary Erasures</dc:title>
 <dc:creator>Fong, Silas L.</dc:creator>
 <dc:creator>Khisti, Ashish</dc:creator>
 <dc:creator>Li, Baochun</dc:creator>
 <dc:creator>Tan, Wai-Tian</dc:creator>
 <dc:creator>Zhu, Xiaoqing</dc:creator>
 <dc:creator>Apostolopoulos, John</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers transmitting a sequence of messages (a streaming source)
over a packet erasure channel. In each time slot, the source constructs a
packet based on the current and the previous messages and transmits the packet,
which may be erased when the packet travels from the source to the destination.
Every source message must be recovered perfectly at the destination subject to
a fixed decoding delay. We assume that the channel loss model induces either
one burst erasure or multiple arbitrary erasures in any fixed-sized sliding
window. Under this channel loss model assumption, we fully characterize the
maximum achievable rate by constructing streaming codes that achieve the
optimal rate. In addition, our construction of optimal streaming codes implies
the full characterization of the maximum achievable rate for convolutional
codes with any given column distance, column span and decoding delay. Numerical
results demonstrate that the optimal streaming codes outperform existing
streaming codes of comparable complexity over some instances of the
Gilbert-Elliott channel and the Fritchman channel.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04242</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of Energy Models for Design Space Exploration of Embedded
  Many-Core Systems</dc:title>
 <dc:creator>Klarhorst, Christian</dc:creator>
 <dc:creator>Flasskamp, Martin</dc:creator>
 <dc:creator>Ax, Johannes</dc:creator>
 <dc:creator>Jungeblut, Thorsten</dc:creator>
 <dc:creator>Kelly, Wayne</dc:creator>
 <dc:creator>Porrmann, Mario</dc:creator>
 <dc:creator>R&#xfc;ckert, Ulrich</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper introduces a methodology to develop energy models for the design
space exploration of embedded many-core systems. The design process of such
systems can benefit from sophisticated models. Software and hardware can be
specifically optimized based on comprehensive knowledge about application
scenario and hardware behavior. The contribution of our work is an automated
framework to estimate the energy consumption at an arbitrary abstraction level
without the need to provide further information about the system. We validated
our framework with the configurable many-core system CoreVA-MPSoC. Compared to
a simulation of the CoreVA-MPSoC on gate level in a 28nm FD-SOI standard cell
technology, our framework shows an average estimation error of about 4%.
</dc:description>
 <dc:description>Comment: Presented at HIP3ES, 2018</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04249</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe Privatization in Transactional Memory</dc:title>
 <dc:creator>Khyzha, Artem</dc:creator>
 <dc:creator>Attiya, Hagit</dc:creator>
 <dc:creator>Gotsman, Alexey</dc:creator>
 <dc:creator>Rinetzky, Noam</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Transactional memory (TM) facilitates the development of concurrent
applications by letting the programmer designate certain code blocks as atomic.
Programmers using a TM often would like to access the same data both inside and
outside transactions, e.g., to improve performance or to support legacy code.
In this case, programmers would ideally like the TM to guarantee strong
atomicity, where transactions can be viewed as executing atomically also with
respect to non-transactional accesses. Since guaranteeing strong atomicity for
arbitrary programs is prohibitively expensive, researchers have suggested
guaranteeing it only for certain data-race free (DRF) programs, particularly
those that follow the privatization idiom: from some point on, threads agree
that a given object can be accessed non-transactionally. Supporting
privatization safely in a TM is nontrivial, because this often requires
correctly inserting transactional fences, which wait until all active
transactions complete.
  Unfortunately, there is currently no consensus on a single definition of
transactional DRF, in particular, because no existing notion of DRF takes into
account transactional fences. In this paper we propose such a notion and prove
that, if a TM satisfies a certain condition generalizing opacity and a program
using it is DRF assuming strong atomicity, then the program indeed has strongly
atomic semantics. We show that our DRF notion allows the programmer to use
privatization idioms. We also propose a method for proving our generalization
of opacity and apply it to the TL2 TM.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04260</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Probability Models for Deep Image Compression</dc:title>
 <dc:creator>Mentzer, Fabian</dc:creator>
 <dc:creator>Agustsson, Eirikur</dc:creator>
 <dc:creator>Tschannen, Michael</dc:creator>
 <dc:creator>Timofte, Radu</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep Neural Networks trained as image auto-encoders have recently emerged as
a promising direction for advancing the state of the art in image compression.
The key challenge in learning such networks is twofold: to deal with
quantization, and to control the trade-off between reconstruction error
(distortion) and entropy (rate) of the latent image representation. In this
paper, we focus on the latter challenge and propose a new technique to navigate
the rate-distortion trade-off for an image compression auto-encoder. The main
idea is to directly model the entropy of the latent representation by using a
context model: a 3D-CNN which learns a conditional probability model of the
latent distribution of the auto-encoder. During training, the auto-encoder
makes use of the context model to estimate the entropy of its representation,
and the context model is concurrently updated to learn the dependencies between
the symbols in the latent representation. Our experiments show that this
approach yields a state-of-the-art image compression system based on a simple
convolutional auto-encoder.
</dc:description>
 <dc:description>Comment: Submitted to CVPR 2018. The first two authors contributed equally</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04261</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep saliency: What is learnt by a deep network about saliency?</dc:title>
 <dc:creator>He, Sen</dc:creator>
 <dc:creator>Pugeault, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional neural networks have achieved impressive performance on a
broad range of problems, beating prior art on established benchmarks, but it
often remains unclear what are the representations learnt by those systems and
how they achieve such performance. This article examines the specific problem
of saliency detection, where benchmarks are currently dominated by CNN-based
approaches, and investigates the properties of the learnt representation by
visualizing the artificial neurons' receptive fields.
  We demonstrate that fine tuning a pre-trained network on the saliency
detection task lead to a profound transformation of the network's deeper
layers. Moreover we argue that this transformation leads to the emergence of
receptive fields conceptually similar to the centre-surround filters
hypothesized by early research on visual saliency.
</dc:description>
 <dc:description>Comment: Accepted paper in 2nd Workshop on Visualisation for Deep Learning in
  the 34th International Conference On Machine Learning</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04263</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Probabilistic Model Checking of Smart Building Maintenance
  using Fault Maintenance Trees</dc:title>
 <dc:creator>Cauchi, Nathalie</dc:creator>
 <dc:creator>Hoque, Khaza Anuarul</dc:creator>
 <dc:creator>Abate, Alessandro</dc:creator>
 <dc:creator>Stoelinga, Marielle</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Cyber-physical systems, like Smart Buildings and power plants, have to meet
high standards, both in terms of reliability and availability. Such metrics are
typically evaluated using Fault trees (FTs) and do not consider maintenance
strategies which can significantly improve lifespan and reliability. Fault
Maintenance trees (FMTs) -- an extension of FTs that also incorporate
maintenance and degradation models, are a novel technique that serve as a good
planning platform for balancing total costs and dependability of a system. In
this work, we apply the FMT formalism to a Smart Building application. We
propose a framework for modelling FMTs using probabilistic model checking and
present an algorithm for performing abstraction of the FMT in order to reduce
the size of its equivalent Continuous Time Markov Chain. This allows us to
apply the probabilistic model checking more efficiently. We demonstrate the
applicability of our proposed approach by evaluating various dependability
metrics and maintenance strategies of a Heating, Ventilation and
Air-Conditioning system's FMT.
</dc:description>
 <dc:description>Comment: conference</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04264</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-world Anomaly Detection in Surveillance Videos</dc:title>
 <dc:creator>Sultani, Waqas</dc:creator>
 <dc:creator>Chen, Chen</dc:creator>
 <dc:creator>Shah, Mubarak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Surveillance videos are able to capture a variety of realistic anomalies. In
this paper, we propose to learn anomalies by exploiting both normal and
anomalous videos. To avoid annotating the anomalous segments or clips in
training videos, which is very time consuming, we propose to learn anomaly
through the deep multiple instance ranking framework by leveraging weakly
labeled training videos, i.e. the training labels (anomalous or normal) are at
video-level instead of clip-level. In our approach, we consider normal and
anomalous videos as bags and video segments as instances in multiple instance
learning (MIL), and automatically learn a deep anomaly ranking model that
predicts high anomaly scores for anomalous video segments. Furthermore, we
introduce sparsity and temporal smoothness constraints in the ranking loss
function to better localize anomaly during training. We also introduce a new
large-scale first of its kind dataset of 128 hours of videos. It consists of
1900 long and untrimmed real-world surveillance videos, with 13 realistic
anomalies such as fighting, road accident, burglary, robbery, etc. as well as
normal activities. This dataset can be used for two tasks. First, general
anomaly detection considering all anomalies in one group and all normal
activities in another group. Second, for recognizing each of 13 anomalous
activities. Our experimental results show that our MIL method for anomaly
detection achieves significant improvement on anomaly detection performance as
compared to the state-of-the-art approaches. We provide the results of several
recent deep learning baselines on anomalous activity recognition. The low
recognition performance of these baselines reveals that our dataset is very
challenging and opens more opportunities for future work.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04267</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Management's Perspective on Critical Success Factors Affecting Mobile
  Learning in Higher Education Institutions - An Empirical Study</dc:title>
 <dc:creator>Alrasheedi, Muasaad</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>Raza, Arif</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Mobile learning (m-Learning) is considered to be one of the fastest growing
learning platforms. The immense interest in m-Learning is attributed to the
incredible rate of growth of mobile technology and its proliferation into every
aspect of modern life. Despite this, m-Learning has not experienced a similar
adoption rate in the education sector, chiefly higher education. Researchers
have attempted to explain this anomaly by conducting several studies in the
area. However, mostly the research in m-Learning is examined from the
perspective of the students and educators. In this research, it is contended
that there is a third important stakeholder group whose opinion is equally
important in determining the success of m-Learning: the university management.
Although diversified by nature, heads of departments, deans, and IT system
administrators are nevertheless considered members of any university
management. The results of the research show that university commitment to
m-Learning, university learning practices, and change management practices were
the factors critical to the success of m-Learning, from the university
management perspective.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04267</dc:identifier>
 <dc:identifier>Volume 2015, pp. 1-22</dc:identifier>
 <dc:identifier>doi:10.1177/0735633115620387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04270</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Partially Overlapping Coexistence for Dynamic Spectrum Access in
  Cognitive Radio</dc:title>
 <dc:creator>Bedeer, Ebrahim</dc:creator>
 <dc:creator>Marey, Mohamed</dc:creator>
 <dc:creator>Dobre, Octavia</dc:creator>
 <dc:creator>Baddour, Kareem</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study partially overlapping co- existence scenarios in
cognitive radio environment. We consider an Orthogonal Frequency Division
Multiplexing (OFDM) cogni- tive system coexisting with a narrow-band (NB) and
an OFDM primary system, respectively. We focus on finding the minimum frequency
separation between the coexisting systems to meet a certain target BER.
Windowing and nulling are used as simple techniques to reduce the OFDM
out-of-band radiations, and, hence decrease the separation. The effect of these
techniques on the OFDM spectral efficiency and PAPR is also studied.
</dc:description>
 <dc:description>Comment: CAMAD 2011</dc:description>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04271</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative Study on Generative Adversarial Networks</dc:title>
 <dc:creator>Hitawala, Saifuddin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In recent years, there have been tremendous advancements in the field of
machine learning. These advancements have been made through both academic as
well as industrial research. Lately, a fair amount of research has been
dedicated to the usage of generative models in the field of computer vision and
image classification. These generative models have been popularized through a
new framework called Generative Adversarial Networks. Moreover, many modified
versions of this framework have been proposed in the last two years. We study
the original model proposed by Goodfellow et al. as well as modifications over
the original model and provide a comparative analysis of these models.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04288</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determination of Critical Success Factors Affecting Mobile Learning: A
  Meta-Analysis Approach</dc:title>
 <dc:creator>Alrasheedi, Muasaad</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  With rapid technological advancements, mobile learning (m-Learning) offers
incredible opportunities, especially in the area of higher education. However,
while interest in this area has been significant and several pilot studies have
been conducted within universities, relatively less is known about how higher
educational institutions can make efficient use of the m-Learning platform to
support teaching and learning. Although there are numerous studies in the area,
the lack of this insight is mostly due to the fact that very little effort has
been made to collate these studies and determine a common set of key success
factors that affect the acceptance of m-Learning within universities. This
study conducts a systematic analysis of several studies conducted in the area
of m-Learning to assess the critical success factors, by making use of the
meta-analysis technique. Our investigation has shown that the most important
perceived advantages of m-Learning, from learner perspectives, are
collaboration during studies, the prospect of ubiquitous learning in space and
time, and user friendly application design.
</dc:description>
 <dc:description>Comment: 41-51</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04288</dc:identifier>
 <dc:identifier>Turkish Online Journal of Educational Technology, 14(2):41-51,
  April 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04289</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Stochastic Variational Inference</dc:title>
 <dc:creator>Mohamad, Saad</dc:creator>
 <dc:creator>Bouchachia, Abdelhamid</dc:creator>
 <dc:creator>Sayed-Mouchaweh, Moamar</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Stochastic variational inference (SVI) employs stochastic optimization to
scale up Bayesian computation to massive data. Since SVI is at its core a
stochastic gradient-based algorithm, horizontal parallelism can be harnessed to
allow larger scale inference. We propose a lock-free parallel implementation
for SVI which allows distributed computations over multiple slaves in an
asynchronous style. We show that our implementation leads to linear speed-up
while guaranteeing an asymptotic ergodic convergence rate $O(1/\sqrt(T)$ )
given that the number of slaves is bounded by $\sqrt(T)$ ($T$ is the total
number of iterations). The implementation is done in a high-performance
computing (HPC) environment using message passing interface (MPI) for python
(MPI4py). The extensive empirical evaluation shows that our parallel SVI is
lossless, performing comparably well to its counterpart serial SVI with linear
speed-up.
</dc:description>
 <dc:description>Comment: 7 pages, 8 figures, 1 table, 2 algorithms, The paper has been
  submitted for publication</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04290</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Control Toolbox - An Open-Source C++ Library for Robotics, Optimal
  and Model Predictive Control</dc:title>
 <dc:creator>Giftthaler, Markus</dc:creator>
 <dc:creator>Neunert, Michael</dc:creator>
 <dc:creator>St&#xe4;uble, Markus</dc:creator>
 <dc:creator>Buchli, Jonas</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We introduce the Control Toolbox (CT), an open-source C++ library for
efficient modelling, control, estimation, trajectory optimization and model
predictive control. The CT is applicable to a broad class of dynamic systems,
but features additional modelling tools specially designed for robotics. This
paper outlines its general concept, its major building blocks and highlights
selected application examples. The CT was designed for intuitive modelling of
systems governed by ordinary differential- or difference equations. It supports
rapid prototyping of cost functions and constraints and provides common
interfaces for different optimal control solvers. To date, we support Single
Shooting, the iterative Linear-Quadratic Regulator, Gauss-Newton Multiple
Shooting and classical Direct Multiple Shooting. We provide interfaces to
different NLP and linear-quadratic solvers, such as IPOPT, SNOPT, HPIPM, or a
custom Riccati solver. The CT was designed with performance for online control
in mind and allows to solve large-scale optimal control problems highly
efficiently. Some of the key features enabling fast run-time performance are
full support for Automatic Differentiation, derivative code generation and
thorough multi-threading. For robotics problems, the we offer an interface to a
fully auto-differentiable rigid-body dynamics modelling engine. In combination
with derivative code generation, this allows for an unprecedented performance
in solving optimal control problems for complex articulated robotic systems.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04293</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical Success Factors to Improve the Game Development Process from a
  Developers Perspective</dc:title>
 <dc:creator>Aleem, Saiqa</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>Ahmed, Faheem</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The growth of the software game development industry is enormous and is
gaining importance day by day. This growth imposes severe pressure and a number
of issues and challenges on the game development community. Game development is
a complex process, and one important game development choice is to consider the
developer perspective to produce good quality software games by improving the
game development process. The objective of this study is to provide a better
understanding of the developers dimension as a factor in software game success.
It focuses mainly on an empirical investigation of the effect of key developer
factors on the software game development process and eventually on the quality
of the resulting game. A quantitative survey was developed and conducted to
identify key developer factors for an enhanced game development process. For
this study, the developed survey was used to test the research model and
hypotheses. The results provide evidence that game development organizations
must deal with multiple key factors to remain competitive and to handle high
pressure in the software game industry. The main contribution of this paper is
to investigate empirically the influence of key developer factors on the game
development process.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04293</dc:identifier>
 <dc:identifier>Journal of Computer Science and Technology, 31(5):925-950, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/s11390-</dc:identifier>
 <dc:identifier>doi:016-1673-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04295</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalization Error Bounds for Noisy, Iterative Algorithms</dc:title>
 <dc:creator>Pensia, Ankit</dc:creator>
 <dc:creator>Jog, Varun</dc:creator>
 <dc:creator>Loh, Po-Ling</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In statistical learning theory, generalization error is used to quantify the
degree to which a supervised machine learning algorithm may overfit to training
data. Recent work [Xu and Raginsky (2017)] has established a bound on the
generalization error of empirical risk minimization based on the mutual
information $I(S;W)$ between the algorithm input $S$ and the algorithm output
$W$, when the loss function is sub-Gaussian. We leverage these results to
derive generalization error bounds for a broad class of iterative algorithms
that are characterized by bounded, noisy updates with Markovian structure. Our
bounds are very general and are applicable to numerous settings of interest,
including stochastic gradient Langevin dynamics (SGLD) and variants of the
stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm. Furthermore, our
error bounds hold for any output function computed over the path of iterates,
including the last iterate of the algorithm or the average of subsets of
iterates, and also allow for non-uniform sampling of data in successive updates
of the algorithm.
</dc:description>
 <dc:description>Comment: A shorter version of this paper was submitted to ISIT 2018. 14 pages,
  1 figure</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04297</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Floating Locations in Hard Disk Drive by Solving Max-min
  Optimization</dc:title>
 <dc:creator>Liu, Victor</dc:creator>
 <dc:creator>Yang, Hongtao</dc:creator>
 <dc:creator>Li, Haiming</dc:creator>
 <dc:creator>Yang, Chifu</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Floating operation is very critical in power management in hard disk drive
(HDD), during which no control command is applied to the read/write head but a
fixed current to counteract actuator flex bias. External disturbance induced
drift of head may result in interference of head and bump on the disk during
drifting, leading to consequent scratches and head degradation, which is a
severe reliability concern in HDD. This paper proposes a unique systematic
methodology to minimize the chances of hitting bump on the disk during drive
floating. Essentially, it provides a heuristic solution to a class of max-min
optimization problem which achieves desirable trade-off between optimality and
computation complexity. Multivariable nonlinear optimization problem of this
sort is reduced from NP-hard to an arithmetic problem. Also, worst-case is
derived for arbitrary bump locations.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04299</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Belief Propagation Decoding of Polar Codes on Permuted Factor Graphs</dc:title>
 <dc:creator>Elkelesh, Ahmed</dc:creator>
 <dc:creator>Ebada, Moustafa</dc:creator>
 <dc:creator>Cammerer, Sebastian</dc:creator>
 <dc:creator>Brink, Stephan ten</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We show that the performance of iterative belief propagation (BP) decoding of
polar codes can be enhanced by decoding over different carefully chosen factor
graph realizations. With a genie-aided stopping condition, it can achieve the
successive cancellation list (SCL) decoding performance which has already been
shown to achieve the maximum likelihood (ML) bound provided that the list size
is sufficiently large. The proposed decoder is based on different realizations
of the polar code factor graph with randomly permuted stages during decoding.
Additionally, a different way of visualizing the polar code factor graph is
presented, facilitating the analysis of the underlying factor graph and the
comparison of different graph permutations. In our proposed decoder, a high
rate Cyclic Redundancy Check (CRC) code is concatenated with a polar code and
used as an iteration stopping criterion (i.e., genie) to even outperform the
SCL decoder of the plain polar code (without the CRC-aid). Although our
permuted factor graph-based decoder does not outperform the SCL-CRC decoder, it
achieves, to the best of our knowledge, the best performance of all iterative
polar decoders presented thus far.
</dc:description>
 <dc:description>Comment: in IEEE Wireless Commun. and Networking Conf. (WCNC), April 2018</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04301</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Family of Tractable Graph Distances</dc:title>
 <dc:creator>Bento, Jose</dc:creator>
 <dc:creator>Ioannidis, Stratis</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Important data mining problems such as nearest-neighbor search and clustering
admit theoretical guarantees when restricted to objects embedded in a metric
space. Graphs are ubiquitous, and clustering and classification over graphs
arise in diverse areas, including, e.g., image processing and social networks.
Unfortunately, popular distance scores used in these applications, that scale
over large graphs, are not metrics and thus come with no guarantees. Classic
graph distances such as, e.g., the chemical and the CKS distance are arguably
natural and intuitive, and are indeed also metrics, but they are intractable:
as such, their computation does not scale to large graphs. We define a broad
family of graph distances, that includes both the chemical and the CKS
distance, and prove that these are all metrics. Crucially, we show that our
family includes metrics that are tractable. Moreover, we extend these distances
by incorporating auxiliary node attributes, which is important in practice,
while maintaining both the metric property and tractability.
</dc:description>
 <dc:description>Comment: Extended version of paper appearing in SDM 2018</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04306</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Workload Analysis of NSF's Innovative HPC Resources Using XDMoD</dc:title>
 <dc:creator>Simakov, Nikolay A.</dc:creator>
 <dc:creator>White, Joseph P.</dc:creator>
 <dc:creator>DeLeon, Robert L.</dc:creator>
 <dc:creator>Gallo, Steven M.</dc:creator>
 <dc:creator>Jones, Matthew D.</dc:creator>
 <dc:creator>Palmer, Jeffrey T.</dc:creator>
 <dc:creator>Plessinger, Benjamin</dc:creator>
 <dc:creator>Furlani, Thomas R.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>68M14, 68M20, 68U20</dc:subject>
 <dc:subject>I.6.3</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:subject>K.6.4</dc:subject>
 <dc:description>  Workload characterization is an integral part of performance analysis of high
performance computing (HPC) systems. An understanding of workload properties
sheds light on resource utilization and can be used to inform performance
optimization both at the software and system configuration levels. It can
provide information on how computational science usage modalities are changing
that could potentially aid holistic capacity planning for the wider HPC
ecosystem. Here, we report on the results of a detailed workload analysis of
the portfolio of supercomputers comprising the NSF Innovative HPC program in
order to characterize its past and current workload and look for trends to
understand the nature of how the broad portfolio of computational science
research is being supported and how it is changing over time. The workload
analysis also sought to illustrate a wide variety of usage patterns and
performance requirements for jobs running on these systems. File system
performance, memory utilization and the types of parallelism employed by users
(MPI, threads, etc) were also studied for all systems for which job level
performance data was available.
</dc:description>
 <dc:description>Comment: 93 pages, 82 figures, 19 tables</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04307</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Sparse Fourier Transform Based on The Fourier Projection-Slice
  Theorem</dc:title>
 <dc:creator>Wang, Shaogang</dc:creator>
 <dc:creator>Patel, Vishal M.</dc:creator>
 <dc:creator>Petropulu, Athina</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The state-of-the-art automotive radars employ multidimensional discrete
Fourier transforms (DFT) in order to estimate various target parameters. The
DFT is implemented using the fast Fourier transform (FFT), at sample and
computational complexity of $O(N)$ and $O(N \log N)$, respectively, where $N$
is the number of samples in the signal space. We have recently proposed a
sparse Fourier transform based on the Fourier projection-slice theorem
(FPS-SFT), which applies to multidimensional signals that are sparse in the
frequency domain. FPS-SFT achieves sample complexity of $O(K)$ and
computational complexity of $O(K \log K)$ for a multidimensional, $K$-sparse
signal. While FPS-SFT considers the ideal scenario, i.e., exactly sparse data
that contains on-grid frequencies, in this paper, by extending FPS-SFT into a
robust version (RFPS-SFT), we emphasize on addressing noisy signals that
contain off-grid frequencies; such signals arise from radar applications. This
is achieved by employing a windowing technique and a voting-based frequency
decoding procedure; the former reduces the frequency leakage of the off-grid
frequencies below the noise level to preserve the sparsity of the signal, while
the latter significantly lowers the frequency localization error stemming from
the noise. The performance of the proposed method is demonstrated both
theoretically and numerically.
</dc:description>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04310</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Hop Framework for Multi-Source, Multi-Relay, All-Cast Channels</dc:title>
 <dc:creator>Ponniah, Jonathan</dc:creator>
 <dc:creator>Xie, Liang-Liang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The decode-forward region is characterized for multi-source, multi-relay,
all-cast channels with independent input distributions. Flow decompositions are
introduced as abstractions of the encoding/decoding schemes at each node that
recover rate vectors in the region. An arbitrary collection of flow
decompositions may or may not be causal. Necessary and sufficient conditions
are derived that determine when an equivalent collection of causal flow
decompositions exists.
</dc:description>
 <dc:description>Comment: In support of a submission to ISIT 2018</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04314</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Light Field Super-Resolution using a Low-Rank Prior and Deep
  Convolutional Neural Networks</dc:title>
 <dc:creator>Farrugia, Reuben A.</dc:creator>
 <dc:creator>Guillemot, Christine</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Light field imaging has recently known a regain of interest due to the
availability of practical light field capturing systems that offer a wide range
of applications in the field of computer vision. However, capturing
high-resolution light fields remains technologically challenging since the
increase in angular resolution is often accompanied by a significant reduction
in spatial resolution. This paper describes a learning-based spatial light
field super-resolution method that allows the restoration of the entire light
field with consistency across all sub-aperture images. The algorithm first uses
optical flow to align the light field and then reduces its angular dimension
using low-rank approximation. We then consider the linearly independent columns
of the resulting low-rank model as an embedding, which is restored using a deep
convolutional neural network (DCNN). The super-resolved embedding is then used
to reconstruct the remaining sub-aperture images. The original disparities are
restored using inverse warping where missing pixels are approximated using a
novel light field inpainting algorithm. Experimental results show that the
proposed method outperforms existing light field super-resolution algorithms,
achieving PSNR gains of 0.23 dB over the second best performing method. This
performance can be further improved using iterative back-projection as a
post-processing step.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04315</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Markings in Perpetual Free-Choice Nets Are Fully Characterized by Their
  Enabled Transitions</dc:title>
 <dc:creator>van der Aalst, Wil M. P.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A marked Petri net is lucent if there are no two different reachable markings
enabling the same set of transitions, i.e., states are fully characterized by
the transitions they enable. This paper explores the class of marked Petri nets
that are lucent and proves that perpetual marked free-choice nets are lucent.
Perpetual free-choice nets are free-choice Petri nets that are live and bounded
and have a home cluster, i.e., there is a cluster such that from any reachable
state there is a reachable state marking the places of this cluster. A home
cluster in a perpetual net serves as a &quot;regeneration point&quot; of the process,
e.g., to start a new process instance (case, job, cycle, etc.). Many
&quot;well-behaved&quot; process models fall into this class. For example, the class of
short-circuited sound workflow nets is perpetual. Also, the class of processes
satisfying the conditions of the {\alpha} algorithm for process discovery falls
into this category. This paper shows that the states in a perpetual marked
free-choice net are fully characterized by the transitions they enable, i.e.,
these process models are lucent. Having a one-to-one correspondence between the
actions that can happen and the state of the process, is valuable in a variety
of application domains. The full characterization of markings in terms of
enabled transitions makes perpetual free-choice nets interesting for workflow
analysis and process mining. In fact, we anticipate new verification, process
discovery, and conformance checking techniques for the subclasses identified.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04326</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Not All Ops Are Created Equal!</dc:title>
 <dc:creator>Lai, Liangzhen</dc:creator>
 <dc:creator>Suda, Naveen</dc:creator>
 <dc:creator>Chandra, Vikas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Efficient and compact neural network models are essential for enabling the
deployment on mobile and embedded devices. In this work, we point out that
typical design metrics for gauging the efficiency of neural network
architectures -- total number of operations and parameters -- are not
sufficient. These metrics may not accurately correlate with the actual
deployment metrics such as energy and memory footprint. We show that throughput
and energy varies by up to 5X across different neural network operation types
on an off-the-shelf Arm Cortex-M7 microcontroller. Furthermore, we show that
the memory required for activation data also need to be considered, apart from
the model parameters, for network architecture exploration studies.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04329</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effect of Meltdown and Spectre Patches on the Performance of HPC
  Applications</dc:title>
 <dc:creator>Simakov, Nikolay A.</dc:creator>
 <dc:creator>Innus, Martins D.</dc:creator>
 <dc:creator>Jones, Matthew D.</dc:creator>
 <dc:creator>White, Joseph P.</dc:creator>
 <dc:creator>Gallo, Steven M.</dc:creator>
 <dc:creator>DeLeon, Robert L.</dc:creator>
 <dc:creator>Furlani, Thomas R.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  In this work we examine how the updates addressing Meltdown and Spectre
vulnerabilities impact the performance of HPC applications. To study this we
use the application kernel module of XDMoD to test the performance before and
after the application of the vulnerability patches. We tested the performance
difference for multiple application and benchmarks including: NWChem, NAMD,
HPCC, IOR, MDTest and IMB. The results show that although some specific
functions can have performance decreased by as much as 74%, the majority of
individual metrics indicates little to no decrease in performance. The
real-world applications show a 2-3% decrease in performance for single node
jobs and a 5-11% decrease for parallel multi node jobs.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04331</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prototypicality effects in global semantic description of objects</dc:title>
 <dc:creator>Pino, Omar Vidal</dc:creator>
 <dc:creator>Campos, Mario Fernando Montenegro</dc:creator>
 <dc:creator>Nascimento, Erickson Rangel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new approach to face the semantic features descriptions of
objects based in the prototypicality effects of prototypes theory. Our
descriptor, called global semantic descriptor, is capable of coding and storing
a semantic (central and peripheral) meaning of object. Our model compute the
semantic prototype of object using features extracted by CNN-classifications
models. We propose a simple method to reduce the dimensionality of semantic
prototype without semantic information lost. We demonstrated that our
descriptor preserved de semantic information used by the CNN-models for
classifications task. The experiments on MNIST and ImageNet Datasets
demonstrated that our model allows clustering the elements into family
resemblance (typicality value) within the category.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04334</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TieNet: Text-Image Embedding Network for Common Thorax Disease
  Classification and Reporting in Chest X-rays</dc:title>
 <dc:creator>Wang, Xiaosong</dc:creator>
 <dc:creator>Peng, Yifan</dc:creator>
 <dc:creator>Lu, Le</dc:creator>
 <dc:creator>Lu, Zhiyong</dc:creator>
 <dc:creator>Summers, Ronald M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Chest X-rays are one of the most common radiological examinations in daily
clinical routines. Reporting thorax diseases using chest X-rays is often an
entry-level task for radiologist trainees. Yet, reading a chest X-ray image
remains a challenging job for learning-oriented machine intelligence, due to
(1) shortage of large-scale machine-learnable medical image datasets, and (2)
lack of techniques that can mimic the high-level reasoning of human
radiologists that requires years of knowledge accumulation and professional
training. In this paper, we show the clinical free-text radiological reports
can be utilized as a priori knowledge for tackling these two key problems. We
propose a novel Text-Image Embedding network (TieNet) for extracting the
distinctive image and text representations. Multi-level attention models are
integrated into an end-to-end trainable CNN-RNN architecture for highlighting
the meaningful text words and image regions. We first apply TieNet to classify
the chest X-rays by using both image features and text embeddings extracted
from associated reports. The proposed auto-annotation framework achieves high
accuracy (over 0.9 on average in AUCs) in assigning disease labels for our
hand-label evaluation dataset. Furthermore, we transform the TieNet into a
chest X-ray reporting system. It simulates the reporting process and can output
disease classification and a preliminary report together. The classification
results are significantly improved (6% increase on average in AUCs) compared to
the state-of-the-art baseline on an unseen and hand-labeled dataset (OpenI).
</dc:description>
 <dc:description>Comment: v1: Main paper + supplementary material</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04335</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The DCS Theorem</dc:title>
 <dc:creator>Slepak, Greg</dc:creator>
 <dc:creator>Petrova, Anya</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Blockchain design involves many tradeoffs, and much debate has focused on
tradeoffs related to scaling parameters such as blocksize. To address some of
the confusion around this subject, we present a probability proof of the DCS
Triangle. We use the triangle to show decentralized consensus systems, like
blockchains, can have Decentralization, Consensus, or Scale, but not all three
properties simultaneously. We then describe two methods for getting around the
limitations suggested by the triangle.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04337</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forest Categories</dc:title>
 <dc:creator>Straubing, Howard</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We extend Tilson's theory of the algebra of finite categories, in particular,
the Derived Category Theorem, to the setting of forest algebras. As an
illustration of the usefulness of this method, we provide a new proof of a
result of Place and Segoufin characterizing locally testable tree languages.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04339</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating the Number of Connected Components in a Graph via Subgraph
  Sampling</dc:title>
 <dc:creator>Klusowski, Jason M.</dc:creator>
 <dc:creator>Wu, Yihong</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning properties of large graphs from samples has been an important
problem in statistical network analysis since the early work of Goodman
\cite{Goodman1949} and Frank \cite{Frank1978}. We revisit a problem formulated
by Frank \cite{Frank1978} of estimating the number of connected components in a
large graph based on the subgraph sampling model, in which we randomly sample a
subset of the vertices and observe the induced subgraph. The key question is
whether accurate estimation is achievable in the \emph{sublinear} regime where
only a vanishing fraction of the vertices are sampled. We show that it is
impossible if the parent graph is allowed to contain high-degree vertices or
long induced cycles. For the class of chordal graphs, where induced cycles of
length four or above are forbidden, we characterize the optimal sample
complexity within constant factors and construct linear-time estimators that
provably achieve these bounds. This significantly expands the scope of previous
results which have focused on unbiased estimators and special classes of graphs
such as forests or cliques.
  Both the construction and the analysis of the proposed methodology rely on
combinatorial properties of chordal graphs and identities of induced subgraph
counts. They, in turn, also play a key role in proving minimax lower bounds
based on construction of random instances of graphs with matching structures of
small subgraphs.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04340</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Future Lane Changes of Other Highway Vehicles using RNN-based
  Deep Models</dc:title>
 <dc:creator>Patel, Sajan</dc:creator>
 <dc:creator>Griffin, Brent</dc:creator>
 <dc:creator>Kusano, Kristofer</dc:creator>
 <dc:creator>Corso, Jason J.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In the event of sensor failure, it is necessary for autonomous vehicles to
safely execute emergency maneuvers while avoiding other vehicles on the road.
In order to accomplish this, the sensor-failed vehicle must predict the future
semantic behaviors of other drivers, such as lane changes, as well as their
future trajectories given a small window of past sensor observations. We
address the first issue of semantic behavior prediction in this paper, by
introducing a prediction framework that leverages the power of recurrent neural
networks (RNNs) and graphical models. Our prediction goal is to predict the
future categorical driving intent, for lane changes, of neighboring vehicles up
to three seconds into the future given as little as a one-second window of past
LIDAR, GPS, inertial, and map data.
  We collect real-world data containing over 500,000 samples of highway driving
using an autonomous Toyota vehicle. We propose a pair of models that leverage
RNNs: first, a monolithic RNN model that tries to directly map inputs to future
behavior through a long-short-term-memory network. Second, we propose a
composite RNN model by adopting the methodology of Structural Recurrent Neural
Networks (RNNs) to learn factor functions and take advantage of both the
high-level structure of graphical models and the sequence modeling power of
RNNs, which we expect to afford more transparent modeling and activity than the
monolithic RNN. To demonstrate our approach, we validate our models using
authentic interstate highway driving to predict the future lane change
maneuvers of other vehicles neighboring our autonomous vehicle. We find that
both RNN models outperform baselines, and they outperform each other in certain
conditions.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04342</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Symbolic and Function Evaluation Expressions In Neural
  Programs</dc:title>
 <dc:creator>Arabshahi, Forough</dc:creator>
 <dc:creator>Singh, Sameer</dc:creator>
 <dc:creator>Anandkumar, Animashree</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural programming involves training neural networks to learn programs from
data. Previous works have failed to achieve good generalization performance,
especially on programs with high complexity or on large domains. This is
because they mostly rely either on black-box function evaluations that do not
capture the structure of the program, or on detailed execution traces that are
expensive to obtain, and hence the training data has poor coverage of the
domain under consideration. We present a novel framework that utilizes
black-box function evaluations, in conjunction with symbolic expressions that
integrate relationships between the given functions. We employ tree LSTMs to
incorporate the structure of the symbolic expression trees. We use tree
encoding for numbers present in function evaluation data, based on their
decimal representation. We present an evaluation benchmark for this task to
demonstrate our proposed model combines symbolic reasoning and function
evaluation in a fruitful manner, obtaining high accuracies in our experiments.
Our framework generalizes significantly better to expressions of higher depth
and is able to fill partial equations with valid completions.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04345</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Engineering Cooperative Smart Things based on Embodied Cognition</dc:title>
 <dc:creator>Nascimento, Nathalia Moraes do</dc:creator>
 <dc:creator>de Lucena, Carlos Jose Pereira</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The goal of the Internet of Things (IoT) is to transform any thing around us,
such as a trash can or a street light, into a smart thing. A smart thing has
the ability of sensing, processing, communicating and/or actuating. In order to
achieve the goal of a smart IoT application, such as minimizing waste
transportation costs or reducing energy consumption, the smart things in the
application scenario must cooperate with each other without a centralized
control. Inspired by known approaches to design swarm of cooperative and
autonomous robots, we modeled our smart things based on the embodied cognition
concept. Each smart thing is a physical agent with a body composed of a
microcontroller, sensors and actuators, and a brain that is represented by an
artificial neural network. This type of agent is commonly called an embodied
agent. The behavior of these embodied agents is autonomously configured through
an evolutionary algorithm that is triggered according to the application
performance. To illustrate, we have designed three homogeneous prototypes for
smart street lights based on an evolved network. This application has shown
that the proposed approach results in a feasible way of modeling decentralized
smart things with self-developed and cooperative capabilities.
</dc:description>
 <dc:description>Comment: IEEE 2017 NASA/ESA Conference on Adaptive Hardware and Systems (AHS)</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04345</dc:identifier>
 <dc:identifier>doi:10.1109/AHS.2017.8046366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04346</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Computational Model of Commonsense Moral Decision Making</dc:title>
 <dc:creator>Kim, Richard</dc:creator>
 <dc:creator>Kleiman-Weiner, Max</dc:creator>
 <dc:creator>Abeliuk, Andres</dc:creator>
 <dc:creator>Awad, Edmond</dc:creator>
 <dc:creator>Dsouza, Sohan</dc:creator>
 <dc:creator>Tenenbaum, Josh</dc:creator>
 <dc:creator>Rahwan, Iyad</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce a new computational model of moral decision making, drawing on a
recent theory of commonsense moral learning via social dynamics. Our model
describes moral dilemmas as a utility function that computes trade-offs in
values over abstract moral dimensions, which provide interpretable parameter
values when implemented in machine-led ethical decision-making. Moreover,
characterizing the social structures of individuals and groups as a
hierarchical Bayesian model, we show that a useful description of an
individual's moral values - as well as a group's shared values - can be
inferred from a limited amount of observed data. Finally, we apply and evaluate
our approach to data from the Moral Machine, a web application that collects
human judgments on moral dilemmas involving autonomous vehicles.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04348</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comprehensive Optimization of Parametric Kernels for Graphics Processing
  Units</dc:title>
 <dc:creator>Chen, Xiaohui</dc:creator>
 <dc:creator>Moreno-Maza, Marc</dc:creator>
 <dc:creator>Paudel, Jeeva</dc:creator>
 <dc:creator>Xie, Ning</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  This work deals with the optimization of computer programs targeting Graphics
Processing Units (GPUs). The goal is to lift, from programmers to optimizing
compilers, the heavy burden of determining program details that are dependent
on the hardware characteristics. The expected benefit is to improve robustness,
portability and efficiency of the generated computer programs. We address these
requirements by: (1) treating machine and program parameters as unknown symbols
during code generation, and (2) generating optimized programs in the form of a
case discussion, based on the possible values of the machine and program
parameters. By taking advantage of recent advances in the area of computer
algebra, preliminary experimentation yield promising results.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04352</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Capacity Region of the Deterministic Y-Channel with Common and
  Private Messages</dc:title>
 <dc:creator>Ibrahim, Mohamed S.</dc:creator>
 <dc:creator>Nafie, Mohammed</dc:creator>
 <dc:creator>Mohasseb, Yahya</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In multi user Gaussian relay networks, it is desirable to transmit private
information to each user as well as common information to all of them. However,
the capacity region of such networks with both kinds of information is not easy
to characterize. The prior art used simple linear deterministic models in order
to approximate the capacities of these Gaussian networks. This paper discusses
the capacity region of the deterministic Y-channel with private and common
messages. In this channel, each user aims at delivering two private messages to
the other two users in addition to a common message directed towards both of
them. As there is no direct link between the users, all messages must pass
through an intermediate relay. We present outer-bounds on the rate region using
genie aided and cut-set bounds. Then, we develop a greedy scheme to define an
achievable region and show that at a certain number of levels at the relay, our
achievable region coincides with the upper bound. Finally, we argue that these
bounds for this setup are not sufficient to characterize the capacity region.
</dc:description>
 <dc:description>Comment: 4 figures, 7 pages</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04354</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Black-box Generation of Adversarial Text Sequences to Evade Deep
  Learning Classifiers</dc:title>
 <dc:creator>Gao, Ji</dc:creator>
 <dc:creator>Lanchantin, Jack</dc:creator>
 <dc:creator>Soffa, Mary Lou</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although various techniques have been proposed to generate adversarial
samples for white-box attacks on text, little attention has been paid to a
black-box attack, which is a more realistic scenario. In this paper, we present
a novel algorithm, DeepWordBug, to effectively generate small text
perturbations in a black-box setting that forces a deep-learning classifier to
misclassify a text input. We develop novel scoring strategies to find the most
important words to modify such that the deep classifier makes a wrong
prediction. Simple character-level transformations are applied to the
highest-ranked words in order to minimize the edit distance of the
perturbation. We evaluated DeepWordBug on two real-world text datasets: Enron
spam emails and IMDB movie reviews. Our experimental results indicate that
DeepWordBug can reduce the classification accuracy from $99\%$ to around $40\%$
on Enron data and from $87\%$ to about $26\%$ on IMDB. Also, our experimental
results strongly demonstrate that the generated adversarial sequences from a
deep-learning model can similarly evade other deep models.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04356</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Space Transfer for Data Augmentation</dc:title>
 <dc:creator>Liu, Bo</dc:creator>
 <dc:creator>Dixit, Mandar</dc:creator>
 <dc:creator>Kwitt, Roland</dc:creator>
 <dc:creator>Vasconcelos, Nuno</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The problem of data augmentation in feature space is considered. A new
architecture, denoted the FeATure TransfEr Network (FATTEN), is proposed for
the modeling of feature trajectories induced by variations of object pose. This
architecture exploits a parametrization of the pose manifold in terms of pose
and appearance. This leads to a deep encoder/decoder network architecture,
where the encoder factors into an appearance and a pose predictor. Unlike
previous attempts at trajectory transfer, FATTEN can be efficiently trained
end-to-end, with no need to train separate feature transfer functions. This is
realized by supplying the decoder with information about a target pose and the
use of a multi-task loss that penalizes category- and pose-mismatches. In
result, FATTEN discourages discontinuous or non-smooth trajectories that fail
to capture the structure of the pose manifold, and generalizes well on object
recognition tasks involving large pose variation. Experimental results on the
artificial ModelNet database show that it can successfully learn to map source
features to target features of a desired pose, while preserving class identity.
Most notably, by using feature space transfer for data augmentation (w.r.t.
pose and depth) on SUN-RGBD objects, we demonstrate considerable performance
improvements on one/few-shot object recognition in a transfer learning setup,
compared to current state-of-the-art methods.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04357</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coded Cooperative Computation for Internet of Things</dc:title>
 <dc:creator>Keshtkarjahromi, Yasaman</dc:creator>
 <dc:creator>Seferoglu, Hulya</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Cooperative computation is a promising approach for localized data processing
for Internet of Things (IoT), where computationally intensive tasks in a device
could be divided into sub-tasks, and offloaded to other devices or servers in
close proximity. However, exploiting the potential of cooperative computation
is challenging mainly due to the heterogeneous nature of IoT devices. Indeed,
IoT devices may have different and time-varying computing power and energy
resources, and could be mobile.
  Coded computation, which advocates mixing data in sub-tasks by employing
erasure codes and offloading these sub-tasks to other devices for computation,
is recently gaining interest, thanks to its higher reliability, smaller delay,
and lower communication costs. In this paper, we develop a coded cooperative
computation framework, which we name Computation Control Protocol (CCP), by
taking into account heterogeneous computing power and energy resources of IoT
devices. CCP dynamically allocates sub-tasks to helpers and is adaptive to
time-varying resources. We show that (i) CCP improves task completion delay
significantly as compared to baselines, (ii) task completion delay of CCP is
very close to its theoretical characterization, and (iii) the efficiency of CCP
in terms of resource utilization is higher than 99%, which is significant.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04359</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Queue-aware Energy Efficient Control for Dense Wireless Networks</dc:title>
 <dc:creator>Larranaga, Maialen</dc:creator>
 <dc:creator>Assaad, Mohamad</dc:creator>
 <dc:creator>De Turck, Koen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of long term power allocation in dense wireless
networks. The framework considered in this paper is of interest for
machine-type communications (MTC). In order to guarantee an optimal operation
of the system while being as power efficient as possible, the allocation policy
must take into account both the channel and queue states of the devices. This
is a complex stochastic optimization problem, that can be cast as a Markov
Decision Process (MDP) over a huge state space. In order to tackle this state
space explosion, we perform a mean-field approximation on the MDP. Letting the
number of devices grow to infinity the MDP converges to a deterministic control
problem. By solving the Hamilton-Jacobi-Bellman Equation, we obtain a
well-performing power allocation policy for the original stochastic problem,
which turns out to be a threshold-based policy and can then be easily
implemented in practice.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04366</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation in the group action channel</dc:title>
 <dc:creator>Abbe, Emmanuel</dc:creator>
 <dc:creator>Pereira, Jo&#xe3;o M.</dc:creator>
 <dc:creator>Singer, Amit</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A15, 62B10</dc:subject>
 <dc:description>  We analyze the problem of estimating a signal from multiple measurements on a
$\mbox{group action channel}$ that linearly transforms a signal by a random
group action followed by a fixed projection and additive Gaussian noise. This
channel is motivated by applications such as multi-reference alignment and
cryo-electron microscopy. We focus on the large noise regime prevalent in these
applications. We give a lower bound on the mean square error (MSE) of any
asymptotically unbiased estimator of the signal's orbit in terms of the
signal's moment tensors, which implies that the MSE is bounded away from 0 when
$N/\sigma^{2d}$ is bounded from above, where $N$ is the number of observations,
$\sigma$ is the noise standard deviation, and $d$ is the so-called
$\mbox{moment order cutoff}$. In contrast, the maximum likelihood estimator is
shown to be consistent if $N /\sigma^{2d}$ diverges.
</dc:description>
 <dc:description>Comment: 5 pages, conference</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04372</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCLib: A Practical and Lightweight Defense against Component Hijacking
  in Android Applications</dc:title>
 <dc:creator>Wu, Daoyuan</dc:creator>
 <dc:creator>Cheng, Yao</dc:creator>
 <dc:creator>Gao, Debin</dc:creator>
 <dc:creator>Li, Yingjiu</dc:creator>
 <dc:creator>Deng, Robert H.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cross-app collaboration via inter-component communication is a fundamental
mechanism on Android. Although it brings the benefits such as functionality
reuse and data sharing, a threat called component hijacking is also introduced.
By hijacking a vulnerable component in victim apps, an attack app can escalate
its privilege for operations originally prohibited. Many prior studies have
been performed to understand and mitigate this issue, but no defense is being
deployed in the wild, largely due to the deployment difficulties and
performance concerns. In this paper we present SCLib, a secure component
library that performs in-app mandatory access control on behalf of app
components. It does not require firmware modification or app repackaging as in
previous works. The library-based nature also makes SCLib more accessible to
app developers, and enables them produce secure components in the first place
over fragmented Android devices. As a proof of concept, we design six mandatory
policies and overcome unique implementation challenges to mitigate attacks
originated from both system weaknesses and common developer mistakes. Our
evaluation using ten high-profile open source apps shows that SCLib can protect
their 35 risky components with negligible code footprint (less than 0.3% stub
code) and nearly no slowdown to normal intra-app communications. The worst-case
performance overhead to stop attacks is about 5%.
</dc:description>
 <dc:description>Comment: This is the extended technical report version of our SCLib paper
  accepted by ACM CODASPY 2018
  (http://www.ycheng.org/codaspy/2018/accepted.html)</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04378</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness in Supervised Learning: An Information Theoretic Approach</dc:title>
 <dc:creator>Ghassami, AmirEmad</dc:creator>
 <dc:creator>Khodadadian, Sajad</dc:creator>
 <dc:creator>Kiyavash, Negar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Automated decision making systems are increasingly being used in real-world
applications. In these systems for the most part, the decision rules are
derived by minimizing the training error on the available historical data.
Therefore, if there is a bias related to a sensitive attribute such as gender,
race, religion, etc. in the data, say, due to cultural/historical
discriminatory practices against a certain demographic, the system could
continue discrimination in decisions by including the said bias in its decision
rule. We present an information theoretic framework for designing fair
predictors from data, which aim to prevent discrimination against a specified
sensitive attribute in a supervised learning setting. We use equalized odds as
the criterion for discrimination, which demands that the prediction should be
independent of the protected attribute conditioned on the actual label. To
ensure fairness and generalization simultaneously, we compress the data to an
auxiliary variable, which is used for the prediction task. This auxiliary
variable is chosen such that it is decontaminated from the discriminatory
attribute in the sense of equalized odds. The final predictor is obtained by
applying a Bayesian decision rule to the auxiliary variable.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04380</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SuperNeurons: Dynamic GPU Memory Management for Training Deep Neural
  Networks</dc:title>
 <dc:creator>Wang, Linnan</dc:creator>
 <dc:creator>Ye, Jinmian</dc:creator>
 <dc:creator>Zhao, Yiyang</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:creator>Li, Ang</dc:creator>
 <dc:creator>Song, Shuaiwen Leon</dc:creator>
 <dc:creator>Xu, Zenglin</dc:creator>
 <dc:creator>Kraska, Tim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Going deeper and wider in neural architectures improves the accuracy, while
the limited GPU DRAM places an undesired restriction on the network design
domain. Deep Learning (DL) practitioners either need change to less desired
network architectures, or nontrivially dissect a network across multiGPUs.
These distract DL practitioners from concentrating on their original machine
learning tasks. We present SuperNeurons: a dynamic GPU memory scheduling
runtime to enable the network training far beyond the GPU DRAM capacity.
SuperNeurons features 3 memory optimizations, \textit{Liveness Analysis},
\textit{Unified Tensor Pool}, and \textit{Cost-Aware Recomputation}, all
together they effectively reduce the network-wide peak memory usage down to the
maximal memory usage among layers. We also address the performance issues in
those memory saving techniques. Given the limited GPU DRAM, SuperNeurons not
only provisions the necessary memory for the training, but also dynamically
allocates the memory for convolution workspaces to achieve the high
performance. Evaluations against Caffe, Torch, MXNet and TensorFlow have
demonstrated that SuperNeurons trains at least 3.2432 deeper network than
current ones with the leading performance. Particularly, SuperNeurons can train
ResNet2500 that has $10^4$ basic network layers on a 12GB K40c.
</dc:description>
 <dc:description>Comment: PPoPP '2018: 23nd ACM SIGPLAN Symposium on Principles and Practice of
  Parallel Programming</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04380</dc:identifier>
 <dc:identifier>doi:10.1145/3178487.3178491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04381</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverted Residuals and Linear Bottlenecks: Mobile Networks for
  Classification, Detection and Segmentation</dc:title>
 <dc:creator>Sandler, Mark</dc:creator>
 <dc:creator>Howard, Andrew</dc:creator>
 <dc:creator>Zhu, Menglong</dc:creator>
 <dc:creator>Zhmoginov, Andrey</dc:creator>
 <dc:creator>Chen, Liang-Chieh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we describe a new mobile architecture, MobileNetV2, that
improves the state of the art performance of mobile models on multiple tasks
and benchmarks as well as across a spectrum of different model sizes. We also
describe efficient ways of applying these mobile models to object detection in
a novel framework we call SSDLite. Additionally, we demonstrate how to build
mobile semantic segmentation models through a reduced form of DeepLabv3 which
we call Mobile DeepLabv3.
  The MobileNetV2 architecture is based on an inverted residual structure where
the input and output of the residual block are thin bottleneck layers opposite
to traditional residual models which use expanded representations in the input
an MobileNetV2 uses lightweight depthwise convolutions to filter features in
the intermediate expansion layer. Additionally, we find that it is important to
remove non-linearities in the narrow layers in order to maintain
representational power. We demonstrate that this improves performance and
provide an intuition that led to this design. Finally, our approach allows
decoupling of the input/output domains from the expressiveness of the
transformation, which provides a convenient framework for further analysis. We
measure our performance on Imagenet classification, COCO object detection, VOC
image segmentation. We evaluate the trade-offs between accuracy, and number of
operations measured by multiply-adds (MAdd), as well as the number of
parameters
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04384</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Multi-User Secret Sharing</dc:title>
 <dc:creator>Soleymani, Mahdi</dc:creator>
 <dc:creator>Mahdavifar, Hessam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A distributed secret sharing system is considered that consists of a dealer,
$n$ storage nodes, and $m$ users. Each user is given access to a certain subset
of storage nodes where it can download the data. The dealer wants to securely
convey a specific secret $s_j$ to user $j$ via storage nodes, for
$j=1,2,\dots,m$, in such a way that no user gets any information about other
users' secrets in an information-theoretic sense. To this end, we propose to
study protocols where the dealer encodes secrets into several secret shares and
loads them into the storage nodes. Given a certain number of storage nodes we
find the maximum number of users that can be served in such protocols and
construct schemes that achieve this. We further define two major properties for
such distributed secret sharing systems; communication complexity is defined as
the total amount of data that needs to be downloaded by users in order to
reconstruct their secrets; and storage overhead is defined as the total amount
of data loaded by the dealer into the storage nodes normalized by the total
size of secrets. The minimum possible communication complexity and a lower
bound on storage overhead are characterized given any $n$ and $m$. Furthermore,
we construct distributed secret sharing protocols, under certain conditions on
the system parameters, that achieve the minimum communication complexity and
attain the lower bound on the storage overhead thereby providing schemes that
are optimal in terms of both the communication complexity and storage overhead.
It is shown how to modify the proposed protocols in order to construct schemes
for any set of parameters while providing a nearly optimal storage overhead.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04385</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can you Trust the Trend: Discovering Simpson's Paradoxes in Social Data</dc:title>
 <dc:creator>Alipourfard, Nazanin</dc:creator>
 <dc:creator>Fennell, Peter G.</dc:creator>
 <dc:creator>Lerman, Kristina</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We investigate how Simpson's paradox affects analysis of trends in social
data. According to the paradox, the trends observed in data that has been
aggregated over an entire population may be different from, and even opposite
to, those of the underlying subgroups. Failure to take this effect into account
can lead analysis to wrong conclusions. We present a statistical method to
automatically identify Simpson's paradox in data by comparing statistical
trends in the aggregate data to those in the disaggregated subgroups. We apply
the approach to data from Stack Exchange, a popular question-answering
platform, to analyze factors affecting answerer performance, specifically, the
likelihood that an answer written by a user will be accepted by the asker as
the best answer to his or her question. Our analysis confirms a known Simpson's
paradox and identifies several new instances. These paradoxes provide novel
insights into user behavior on Stack Exchange.
</dc:description>
 <dc:description>Comment: to appear in the Proceedings of WSDM-2018</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04386</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computation of Extended Robust Kalman Filter for Real-Time Attitude and
  Position Estimation</dc:title>
 <dc:creator>Yengera, Gaurav</dc:creator>
 <dc:creator>Inoue, Roberto</dc:creator>
 <dc:creator>Narasimhappa, Mundla</dc:creator>
 <dc:creator>Terra, Marco H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper deals with the implementation of the extended robust Kalman filter
(ERKF) which was developed considering uncertainties in the parameter matrices
of the underlying state-space model. A key contribution of this work is the
demonstration of a method for real-time computation of the filter on parallel
computing devices. The solution of the filter is expressed as a set of
simultaneous linear equations, which can then be evaluated based on QR
decomposition using Givens rotation. This paper also presents the application
of the ERKF in the development of an attitude and position reference system for
a cargo transport vehicle. This work concludes by analyzing the performance of
the ERKF and verifying the validity of the Givens rotation method.
</dc:description>
 <dc:description>Comment: Published in the Brazilian Symposium for Intelligent Automation
  (SBAI) 2017</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04387</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Problem of Correlation and Substitution in SPARQL -- Extended
  Version</dc:title>
 <dc:creator>Hern&#xe1;ndez, Daniel</dc:creator>
 <dc:creator>Gutierrez, Claudio</dc:creator>
 <dc:creator>Angles, Renzo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Implementations of a standard language are expected to give same outputs to
identical queries. In this paper we study why different implementations of
SPARQL (Fuseki, Virtuoso, Blazegraph and rdf4j) behave differently when
evaluating queries with correlated variables. We show that at the core of this
problem lies the historically troubling notion of logical substitution. We
present a formal framework to study this issue based on Datalog that besides
clarifying the problem, gives a solid base to define and implement nesting.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04396</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost-Sensitive Convolution based Neural Networks for Imbalanced
  Time-Series Classification</dc:title>
 <dc:creator>Geng, Yue</dc:creator>
 <dc:creator>Luo, Xinyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Some deep convolutional neural networks were proposed for time-series
classification and class imbalanced problems. However, those models performed
degraded and even failed to recognize the minority class of an imbalanced
temporal sequences dataset. Minority samples would bring troubles for temporal
deep learning classifiers due to the equal treatments of majority and minority
class. Until recently, there were few works applying deep learning on
imbalanced time-series classification (ITSC) tasks. Here, this paper aimed at
tackling ITSC problems with deep learning. An adaptive cost-sensitive learning
strategy was proposed to modify temporal deep learning models. Through the
proposed strategy, classifiers could automatically assign misclassification
penalties to each class. In the experimental section, the proposed method was
utilized to modify five neural networks. They were evaluated on a large volume,
real-life and imbalanced time-series dataset with six metrics. Each single
network was also tested alone and combined with several mainstream data
samplers. Experimental results illustrated that the proposed cost-sensitive
modified networks worked well on ITSC tasks. Compared to other methods, the
cost-sensitive convolution neural network and residual network won out in the
terms of all metrics. Consequently, the proposed cost-sensitive learning
strategy can be used to modify deep learning classifiers from cost-insensitive
to cost-sensitive. Those cost-sensitive convolutional networks can be
effectively applied to address ITSC issues.
</dc:description>
 <dc:description>Comment: 22 pages,12 figures</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04403</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Advantage with Mixed Entangled States</dc:title>
 <dc:creator>Das, Aritra</dc:creator>
 <dc:creator>Chowdhury, Pratyusha</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  It has been extensively shown in past literature that Bayesian Game Theory
and Quantum Non-locality have strong ties between them. Pure Entangled States
have been used, in both common and conflict interest games, to gain
advantageous payoffs, both at the individual and social level. In this paper we
construct a game for a Mixed Entangled State such that this state gives higher
payoffs than classically possible, both at the individual level and the social
level. Also, we use the I-3322 inequality so that states that aren't helpful as
advice for Bell-CHSH inequality can also be used. Finally, the measurement
setting we use is a Restricted Social Welfare Strategy (given this particular
state).
</dc:description>
 <dc:description>Comment: 12 pages, ISI Project</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04405</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Compiler Autotuning using Machine Learning</dc:title>
 <dc:creator>Ashouri, Amir H.</dc:creator>
 <dc:creator>Killian, William</dc:creator>
 <dc:creator>Cavazos, John</dc:creator>
 <dc:creator>Palermo, Gianluca</dc:creator>
 <dc:creator>Silvano, Cristina</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Since the mid-1990s, researchers have been trying to use machine-learning
based approaches to solve a number of different compiler optimization problems.
These techniques primarily enhance the quality of the obtained results and,
more importantly, make it feasible to tackle two main compiler optimization
problems: optimization selection (choosing which optimizations to apply) and
phase-ordering (choosing the order of applying optimizations). The compiler
optimization space continues to grow due to the advancement of applications,
increasing number of compiler optimizations, and new target architectures.
Generic optimization passes in compilers cannot fully leverage newly introduced
optimizations and, therefore, cannot keep up with the pace of increasing
options. This survey summarizes and classifies the recent advances in using
machine learning for the compiler optimization field, particularly on the two
major problems of (1) selecting the best optimizations and (2) the
phase-ordering of optimizations. The survey highlights the approaches taken so
far, the obtained results, the fine-grain classification among different
approaches and finally, the influential papers of the field.
</dc:description>
 <dc:description>Comment: version 1.0 (updated on January 2018)- Preprint version for our ACM
  CSUR 2018 article (41 pages) - Updated Quarterly</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04406</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the convergence properties of GAN training</dc:title>
 <dc:creator>Mescheder, Lars</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Recent work has shown local convergence of GAN training for absolutely
continuous data and generator distributions. In this note we show that the
requirement of absolute continuity is necessary: we describe a simple yet
prototypical counterexample showing that in the more realistic case of
distributions that are not absolutely continuous, unregularized GAN training is
generally not convergent. Furthermore, we discuss recent regularization
strategies that were proposed to stabilize GAN training. Our analysis shows
that while GAN training with instance noise or gradient penalties converges,
Wasserstein-GANs and Wasserstein-GANs-GP with a finite number of discriminator
updates per generator update do in general not converge to the equilibrium
point. We explain these results and show that both instance noise and gradient
penalties constitute solutions to the problem of purely imaginary eigenvalues
of the Jacobian of the gradient vector field. Based on our analysis, we also
propose a simplified gradient penalty with the same effects on local
convergence as more complicated penalties.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04407</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a more efficient representation of imputation operators in TPOT</dc:title>
 <dc:creator>Garciarena, Unai</dc:creator>
 <dc:creator>Mendiburu, Alexander</dc:creator>
 <dc:creator>Santana, Roberto</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T99</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Automated Machine Learning encompasses a set of meta-algorithms intended to
design and apply machine learning techniques (e.g., model selection,
hyperparameter tuning, model assessment, etc.). TPOT, a software for optimizing
machine learning pipelines based on genetic programming (GP), is a novel
example of this kind of applications. Recently we have proposed a way to
introduce imputation methods as part of TPOT. While our approach was able to
deal with problems with missing data, it can produce a high number of
unfeasible pipelines. In this paper we propose a strongly-typed-GP based
approach that enforces constraint satisfaction by GP solutions. The enhancement
we introduce is based on the redefinition of the operators and implicit
enforcement of constraints in the generation of the GP trees. We evaluate the
method to introduce imputation methods as part of TPOT. We show that the method
can notably increase the efficiency of the GP search for optimal pipelines.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures. Continuation of a previous work</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04414</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Bounds for $\ell_p$ Oblivious Subspace Embeddings</dc:title>
 <dc:creator>Wang, Ruosong</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  An $\ell_p$ oblivious subspace embedding is a distribution over $r \times n$
matrices $\Pi$ such that for any fixed $n \times d$ matrix $A$,
$$\Pr_{\Pi}[\textrm{for all }x, \ \|Ax\|_p \leq \|\Pi Ax\|_p \leq \kappa
\|Ax\|_p] \geq 9/10,$$ where $r$ is the dimension of the embedding, $\kappa$ is
the distortion of the embedding, and for an $n$-dimensional vector $y$,
$\|y\|_p$ is the $\ell_p$-norm. Another important property is the sparsity of
$\Pi$, that is, the maximum number of non-zero entries per column, as this
determines the running time of computing $\Pi \cdot A$. While for $p = 2$ there
are nearly optimal tradeoffs in terms of the dimension, distortion, and
sparisty, for the important case of $1 \leq p &lt; 2$, much less was known. In
this paper we obtain nearly optimal tradeoffs for $\ell_p$ oblivious subspace
embeddings for every $1 \leq p &lt; 2$.
  We show for every $1 \leq p &lt; 2$, any oblivious subspace embedding with
dimension $r$ has distortion $\kappa = \Omega
\left(\frac{1}{\left(\frac{1}{d}\right)^{1 / p} \cdot \log^{2 / p}r +
\left(\frac{r}{n}\right)^{1 / p - 1 / 2}}\right).$ When $r = \mathrm{poly}(d)$
in applications, this gives a $\kappa = \Omega(d^{1/p}\log^{-2/p} d)$ lower
bound, and shows the oblivious subspace embedding of Sohler and Woodruff (STOC,
2011) for $p = 1$ and the oblivious subspace embedding of Meng and Mahoney
(STOC, 2013) for $1 &lt; p &lt; 2$ are optimal up to $\mathrm{poly}(\log(d))$
factors. We also give sparse oblivious subspace embeddings for every $1 \leq p
&lt; 2$ which are optimal in dimension and distortion, up to $\mathrm{poly}(\log
d)$ factors.
  Oblivious subspace embeddings are crucial for distributed and streaming
environments, as well as entrywise $\ell_p$ low rank approximation. Our results
give improved algorithms for these applications.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04416</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MOF-BC: A Memory Optimized and Flexible BlockChain for Large Scale
  Networks</dc:title>
 <dc:creator>Dorri, Ali</dc:creator>
 <dc:creator>Kanhere, Salil S.</dc:creator>
 <dc:creator>Jurdak, Raja</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  BlockChain (BC) immutability ensures BC resilience against modification or
removal of the stored data. In large scale networks like the Internet of Things
(IoT), however, this feature significantly increases BC storage size and raises
privacy challenges. In this paper, we propose a Memory Optimized and Flexible
BC (MOF-BC) that enables the IoT users and service providers to remove or
summarize their transactions and age their data and to exercise the &quot;right to
be forgotten&quot;. To increase privacy, a user may employ multiple keys for
different transactions. To allow for the removal of stored transactions, all
keys would need to be stored which complicates key management and storage.
MOF-BC introduces the notion of a Generator Verifier (GV) which is a signed
hash of a Generator Verifier Secret (GVS). The GV changes for each transaction
to provide privacy yet is signed by a unique key, thus minimizing the
information that needs to be stored. A flexible transaction fee model and a
reward mechanism is proposed to incentivize users to participate in optimizing
memory consumption. Qualitative security and privacy analysis demonstrates that
MOF-BC is resilient against several security attacks. Evaluation results show
that MOF-BC decreases BC memory consumption by up to 25\% and the user cost by
more than two orders of magnitude compared to conventional BC instantiations.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04420</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LDPC Codes over Gaussian Multiple Access Wiretap Channel</dc:title>
 <dc:creator>Shahbaz, Sahar</dc:creator>
 <dc:creator>Akhbari, Bahareh</dc:creator>
 <dc:creator>Asvadi, Reza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the problem of two-user Gaussian multiple access channel (GMAC) in
the presence of an external eavesdropper. In this problem, an eavesdropper
receives a signal with a lower signal-to-noise ratio (SNR) compared to the
legitimate receiver and all transmitted messages should be kept confidential
against the eavesdropper. For this purpose, we propose a secure coding scheme
on this channel which utilizes low-density parity-check (LDPC) codes by
employing random bit insertion and puncturing techniques. At each encoder, the
confidential message with some random bits as a random message are
systematically encoded, and then the associated bits to the confidential
message are punctured. Next, the encoders send their unpunctured bits over a
Gaussian multiple access wiretap channel (GMAC-WT). The puncturing distribution
applied to the LDPC code is considered in two cases: random and optimized. We
utilize a modified extrinsic information transfer (EXIT) chart analysis to
optimize the puncturing distribution for each encoder. The security gap is used
as a measure of secrecy for the sent messages over GMAC-WT which should be made
as small as possible. We compare the achieved secure rate pair with an
achievable secrecy rate region of GMAC-WT to show the effective performance of
the proposed scheme. In this paper, equal and unequal power conditions at the
transmitters are investigated. For both cases, we attain a fairly small
security gap which is equivalent to achieve the points near the secrecy rate
region of GMAC-WT.
</dc:description>
 <dc:description>Comment: 21 pages, 8 figures, A Revision Submitted to IET Communications</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04422</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Distribution of Multilevel Channel Polarization for a Certain
  Class of Erasure Channels</dc:title>
 <dc:creator>Sakai, Yuta</dc:creator>
 <dc:creator>Iwata, Ken-ichi</dc:creator>
 <dc:creator>Fujisaki, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This study examines multilevel channel polarization for a certain class of
erasure channels that the input alphabet size is an arbitrary composite number.
We derive limiting proportions of partially noiseless channels for such a
class. The results of this study are proved by an argument of convergent
sequences, inspired by Alsan and Telatar's simple proof of polarization, and
without martingale convergence theorems for polarization process.
</dc:description>
 <dc:description>Comment: 31 pages; 1 figure; 1 table; a short version of this paper has been
  submitted to the 2018 IEEE International Symposium on Information Theory
  (ISIT2018)</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04425</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Longest Common Prefixes with $k$-Errors and Applications</dc:title>
 <dc:creator>Ayad, Lorraine A. K.</dc:creator>
 <dc:creator>Charalampopoulos, Panagiotis</dc:creator>
 <dc:creator>Iliopoulos, Costas S.</dc:creator>
 <dc:creator>Pissis, Solon P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Although real-world text datasets, such as DNA sequences, are far from being
uniformly random, average-case string searching algorithms perform
significantly better than worst-case ones in most applications of interest. In
this paper, we study the problem of computing the longest prefix of each suffix
of a given string of length $n$ over a constant-sized alphabet that occurs
elsewhere in the string with $k$-errors. This problem has already been studied
under the Hamming distance model. Our first result is an improvement upon the
state-of-the-art average-case time complexity for non-constant $k$ and using
only linear space under the Hamming distance model. Notably, we show that our
technique can be extended to the edit distance model with the same time and
space complexities. Specifically, our algorithms run in $\mathcal{O}(n \log^k n
\log \log n)$ time on average using $\mathcal{O}(n)$ space. We show that our
technique is applicable to several algorithmic problems in computational
biology and elsewhere.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04427</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse NOMA: A Closed-Form Characterization</dc:title>
 <dc:creator>Zaidel, Benjamin M.</dc:creator>
 <dc:creator>Shental, Ori</dc:creator>
 <dc:creator>Shamai, Shlomo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Understanding fundamental limits of the various technologies suggested for
future 5G and beyond cellular systems is crucial for developing efficient
state-of-the-art designs. A leading technology of major interest is
non-orthogonal multiple-access (NOMA). In this paper, we derive an explicit
rigorous closed-form analytical expression for the optimum spectral efficiency
in the large-system limit of regular sparse NOMA, where only a fixed and finite
number of orthogonal resources are allocated to any designated user, and vice
versa. The basic Verd\'u-Shamai formula for (dense) randomly-spread
code-division multiple-access (RS-CDMA) turns out to coincide with the limit of
the derived expression, when the number of orthogonal resources per user grows
large. Furthermore, regular sparse NOMA is rigorously shown to be spectrally
more efficient than RS-CDMA across the entire system load range. It may
therefore serve as an efficient means for reducing the throughput gap to
orthogonal transmission in the underloaded regime, and to the ultimate
Cover-Wyner bound in overloaded systems. The results analytically reinforce
preliminary conclusions in [1], which mostly relied on heuristics and numerical
observations. The spectral efficiency is also derived in closed form for the
suboptimal linear minimum-mean-square-error (LMMSE) receiver, which again
extends the corresponding Verd\'u-Shamai LMMSE formula to regular sparse NOMA.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04433</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Offensive Language in Tweets Using Deep Learning</dc:title>
 <dc:creator>Pitsilis, Georgios K.</dc:creator>
 <dc:creator>Ramampiaro, Heri</dc:creator>
 <dc:creator>Langseth, Helge</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper addresses the important problem of discerning hateful content in
social media. We propose a detection scheme that is an ensemble of Recurrent
Neural Network (RNN) classifiers, and it incorporates various features
associated with user-related information, such as the users' tendency towards
racism or sexism. These data are fed as input to the above classifiers along
with the word frequency vectors derived from the textual content. Our approach
has been evaluated on a publicly available corpus of 16k tweets, and the
results demonstrate its effectiveness in comparison to existing state of the
art solutions. More specifically, our scheme can successfully distinguish
racism and sexism messages from normal text, and achieve higher classification
quality than current state-of-the-art algorithms.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04437</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the social media studies of science: social media metrics,
  present and future</dc:title>
 <dc:creator>Costas, Rodrigo</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In this paper we aim at providing a general reflection around the present and
future of social media metrics (or altmetrics) and how they could evolve into a
new discipline focused on the study of the relationships and interactions
between science and social media, in what could be seen as the social media
studies of science.
</dc:description>
 <dc:description>Comment: Spanish version:
  http://revistas.bnjm.cu/index.php/anales/article/view/4172</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04437</dc:identifier>
 <dc:identifier>Bibliotecas. Anales de Investigacion. 2017. 13(1), 1-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04438</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised Fisher vector network</dc:title>
 <dc:creator>Palasek, Petar</dc:creator>
 <dc:creator>Patras, Ioannis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we explore how the architecture proposed in [8], which expresses
the processing steps of the classical Fisher vector pipeline approaches, i.e.
dimensionality reduction by principal component analysis (PCA) projection,
Gaussian mixture model (GMM) and Fisher vector descriptor extraction as network
layers, can be modified into a hybrid network that combines the benefits of
both unsupervised and supervised training methods, resulting in a model that
learns a semi-supervised Fisher vector descriptor of the input data. We
evaluate the proposed model at image classification and action recognition
problems and show how the model's classification performance improves as the
amount of unlabeled data increases during training.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04439</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variable-Length Resolvability for Mixed Sources and its Application to
  Variable-Length Source Coding</dc:title>
 <dc:creator>Yagi, Hideki</dc:creator>
 <dc:creator>Han, Te Sun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the problem of variable-length $\delta$-channel resolvability, the channel
output is approximated by encoding a variable-length uniform random number
under the constraint that the variational distance between the target and
approximated distributions should be within a given constant $\delta$
asymptotically. In this paper, we assume that the given channel input is a
mixed source whose components may be general sources. To analyze the minimum
achievable length rate of the uniform random number, called the
$\delta$-resolvability, we introduce a variant problem of the variable-length
$\delta$-channel resolvability. A general formula for the
$\delta$-resolvability in this variant problem is established for a general
channel. When the channel is an identity mapping, it is shown that the
$\delta$-resolvability in the original and variant problems coincide. This
relation leads to a direct derivation of a single-letter formula for the
$\delta$-resolvability when the given source is a mixed memoryless source. We
extend the result to the second-order case. As a byproduct, we obtain the
first-order and second-order formulas for fixed-to-variable length source
coding allowing error probability up to $\delta$.
</dc:description>
 <dc:description>Comment: 9 pages, submitted to 2018 IEEE International Symposium on
  Information Theory (ISIT2018)</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04441</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Communications in NOMA System: Subcarrier Assignment and Power
  Allocation</dc:title>
 <dc:creator>Zhang, Haijun</dc:creator>
 <dc:creator>Yang, Ning</dc:creator>
 <dc:creator>Long, Keping</dc:creator>
 <dc:creator>Pan, Miao</dc:creator>
 <dc:creator>Karagiannidis, George K.</dc:creator>
 <dc:creator>Leung, Victor C. M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Secure communication is a promising technology for wireless networks because
it ensures secure transmission of information. In this paper, we investigate
the joint subcarrier (SC) assignment and power allocation problem for
non-orthogonal multiple access (NOMA) amplify-and-forward two-way relay
wireless networks, in the presence of eavesdroppers. By exploiting cooperative
jamming (CJ) to enhance the security of the communication link, we aim to
maximize the achievable secrecy energy efficiency by jointly designing the SC
assignment, user pair scheduling and power allocation. Assuming the perfect
knowledge of the channel state information (CSI) at the relay station, we
propose a low-complexity subcarrier assignment scheme (SCAS-1), which is
equivalent to many-to-many matching games, and then SCAS-2 is formulated as a
secrecy energy efficiency maximization problem. The secure power allocation
problem is modeled as a convex geometric programming problem, and then solved
by interior point methods. Simulation results demonstrate that the
effectiveness of the proposed SSPA algorithms under scenarios of using and not
using CJ, respectively.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04453</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable De Novo Genome Assembly Using Pregel</dc:title>
 <dc:creator>Yan, Da</dc:creator>
 <dc:creator>Chen, Hongzhi</dc:creator>
 <dc:creator>Cheng, James</dc:creator>
 <dc:creator>Cai, Zhenkun</dc:creator>
 <dc:creator>Shao, Bin</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  De novo genome assembly is the process of stitching short DNA sequences to
generate longer DNA sequences, without using any reference sequence for
alignment. It enables high-throughput genome sequencing and thus accelerates
the discovery of new genomes. In this paper, we present a toolkit, called
PPA-assembler, for de novo genome assembly in a distributed setting. The
operations in our toolkit provide strong performance guarantees, and can be
assembled to implement various sequencing strategies. PPA-assembler adopts the
popular {\em de Bruijn graph} based approach for sequencing, and each operation
is implemented as a program in Google's Pregel framework for big graph
processing. Experiments on large real and simulated datasets demonstrate that
PPA-assembler is much more efficient than the state-of-the-arts and provides
good sequencing quality.
</dc:description>
 <dc:description>Comment: This is the long version of our ICDE'18 short paper</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04457</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PrivacEye: Privacy-Preserving First-Person Vision Using Image Features
  and Eye Movement Analysis</dc:title>
 <dc:creator>Steil, Julian</dc:creator>
 <dc:creator>Koelle, Marion</dc:creator>
 <dc:creator>Heuten, Wilko</dc:creator>
 <dc:creator>Boll, Susanne</dc:creator>
 <dc:creator>Bulling, Andreas</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  As first-person cameras in head-mounted displays become increasingly
prevalent, so does the problem of infringing user and bystander privacy. To
address this challenge, we present PrivacEye, a proof-of-concept system that
detects privacysensitive everyday situations and automatically enables and
disables the first-person camera using a mechanical shutter. To close the
shutter, PrivacEye detects sensitive situations from first-person camera videos
using an end-to-end deep-learning model. To open the shutter without visual
input, PrivacEye uses a separate, smaller eye camera to detect changes in
users' eye movements to gauge changes in the &quot;privacy level&quot; of the current
situation. We evaluate PrivacEye on a dataset of first-person videos recorded
in the daily life of 17 participants that they annotated with privacy
sensitivity levels. We discuss the strengths and weaknesses of our
proof-of-concept system based on a quantitative technical evaluation as well as
qualitative insights from semi-structured interviews.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04461</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Size-to-depth: A New Perspective for Single Image Depth Estimation</dc:title>
 <dc:creator>Wu, Yiran</dc:creator>
 <dc:creator>Ying, Sihao</dc:creator>
 <dc:creator>Zheng, Lianmin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we consider the problem of single monocular image depth
estimation. It is a challenging problem due to its ill-posedness nature and has
found wide application in industry. Previous efforts belongs roughly to two
families: learning-based method and interactive method. Learning-based method,
in which deep convolutional neural network (CNN) is widely used, can achieve
good result. But they suffer low generalization ability and typically perform
poorly for unfamiliar scenes. Besides, data-hungry nature for such method makes
data aquisition expensive and time-consuming. Interactive method requires human
annotation of depth which, however, is errorneous and of large variance.
  To overcome these problems, we propose a new perspective for single monocular
image depth estimation problem: size to depth. Our method require sparse label
for real-world size of object rather than raw depth. A Coarse depth map is then
inferred following geometric relationships according to size labels. Then we
refine the depth map by doing energy function optimization on conditional
random field(CRF). We experimentally demonstrate that our method outperforms
traditional depth-labeling methods and can produce satisfactory depth maps.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04462</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boolean functions: noise stability, non-interactive correlation, and
  mutual information</dc:title>
 <dc:creator>Li, Jiange</dc:creator>
 <dc:creator>Medard, Muriel</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Let $\epsilon\in[0, 1/2]$ be the noise parameter and $p&gt;1$. We study the
isoperimetric problem that for fixed mean $\E f$ which Boolean function $f$
maximizes the $p$-th moment $\E(T_\epsilon f)^p$ of the noise operator
$T_{\epsilon}$ acting on Boolean functions $f:\{0, 1\}^n\mapsto \{0, 1\}$. Our
findings are: in the low noise scenario, i.e., $\epsilon$ is small, the maximum
is achieved by the lexicographical function; in the high noise scenario, i.e.,
$\epsilon$ is close to 1/2, the maximum is achieved by Boolean functions with
the maximal degree-1 Fourier weight; and when $p$ is a large integer, the
maximum is achieved by some monotone function, which particularly implies that,
among balanced Boolean functions, the maximum is achieved by any function which
is 0 on all strings with fewer than $n/2$ 1's. Our results recover Mossel and
O'Donnell's results about the problem of non-interactive correlation
distillation, and confirm Courtade and Kumar's Conjecture on the most
informative Boolean function in the low noise and high noise regimes. We also
observe that Courtade and Kumar's Conjecture is equivalent to that the dictator
function maximizes $\E(T_\epsilon f)^p$ for $p$ close to 1.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04463</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Scalable Belief Propagation Algorithm for Radio Signal Based SLAM</dc:title>
 <dc:creator>Leitinger, Erik</dc:creator>
 <dc:creator>Meyer, Florian</dc:creator>
 <dc:creator>Hlawatsch, Franz</dc:creator>
 <dc:creator>Witrisal, Klaus</dc:creator>
 <dc:creator>Tufvesson, Fredrik</dc:creator>
 <dc:creator>Win, Moe Z.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a simultaneous localization and mapping (SLAM) algorithm that is
based on radio signals and the association of specular multipath components
(MPCs) with geometric features. Especially in indoor scenarios, localization
from radio signals is challenging due to diffuse multipath propagation and the
unknown MPC-featureassociation. In our approach, specular reflections at flat
surfaces (e.g., walls) are described in terms of virtual anchors (VAs). The
positions of these VAs are unknown and possibly time-varying. We develop a
Bayesian model of the SLAM problem including the unknown MPC-VA association. We
represent this model by a factor graph, which enables the use of the belief
propagation (BP) scheme for efficient marginalization of the joint posterior
distribution. The resulting BP-based SLAM algorithm detects the VAs and
estimates the time-varying position of the mobile agent and the possibly
time-varying positions of the VAs, thereby leveraging the MPCs in the radio
signal for improved accuracy and robustness of agent localization. A core
aspect of the algorithm is BP-based probabilistic MPC-VA association. Moreover,
for improved initialization of new VA positions, the states of unobserved
potential VAs are modeled as a random finite set and propagated in time by
means of a &quot;zero-measurement&quot; probability hypothesis density filter. The
proposed BP-based SLAM algorithm has a low computational complexity and scales
well in all relevant system parameters. Experimental results using both
synthetically generated measurements and realultra-wideband radio signals
demonstrate the excellent performance of the algorithm in challenging indoor
environments.
</dc:description>
 <dc:description>Comment: 30 pages (one column), 6 figures, submitted to Transaction on
  Wireless Communications</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04466</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice Erasure Codes of Low Rank with Noise Margins</dc:title>
 <dc:creator>Vaishampayan, Vinay A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We consider the following generalization of an $(n,k)$ MDS code for
application to an erasure channel with additive noise. Like an MDS code, our
code is required to be decodable from any $k$ received symbols, in the absence
of noise. In addition, we require that the noise margin for every allowable
erasure pattern be as large as possible and that the code satisfy a power
constraint. In this paper we derive performance bounds and present a few
designs for low rank lattice codes for an additive noise channel with erasures.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04470</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EmbedRank: Unsupervised Keyphrase Extraction using Sentence Embeddings</dc:title>
 <dc:creator>Bennani-Smires, Kamil</dc:creator>
 <dc:creator>Musat, Claudiu</dc:creator>
 <dc:creator>Jaggi, Martin</dc:creator>
 <dc:creator>Hossmann, Andreea</dc:creator>
 <dc:creator>Baeriswyl, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Keyphrase extraction is the task of automatically selecting a small set of
phrases that best describe a given free text document. Keyphrases can be used
for indexing, searching, aggregating and summarizing text documents, serving
many automatic as well as human-facing use cases. Existing supervised systems
for keyphrase extraction require large amounts of labeled training data and
generalize very poorly outside the domain of the training data. At the same
time, unsupervised systems found in the literature have poor accuracy, and
often do not generalize well, as they require the input document to belong to a
larger corpus also given as input. Furthermore, both supervised and
unsupervised methods are often too slow for real-time scenarios and suffer from
over-generation. Addressing these drawbacks, in this paper, we introduce an
unsupervised method for keyphrase extraction from single documents that
leverages sentence embeddings. By selecting phrases whose semantic embeddings
are close to the embeddings of the whole document, we are able to separate the
best candidate phrases from the rest. We show that our embedding-based method
is not only simpler, but also more effective than graph-based state of the art
systems, achieving higher F-scores on standard datasets. Simplicity is a
significant advantage, especially when processing large amounts of documents
from the Web, resulting in considerable speed gains. Moreover, we describe how
to increase coverage and diversity among the selected keyphrases by introducing
an embedding-based maximal marginal relevance (MMR) for new phrases. A user
study including over 200 votes showed that, although reducing the phrase
semantic overlap leads to no gains in terms of F-score, our diversity enriched
selection is preferred by humans.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04472</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Not-All-Equal and 1-in-Degree Decompositions: Algorithmic Complexity and
  Applications</dc:title>
 <dc:creator>Dehghan, Ali</dc:creator>
 <dc:creator>Sadeghi, Mohammad-Reza</dc:creator>
 <dc:creator>Ahadi, Arash</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A Not-All-Equal (NAE) decomposition of a graph $G$ is a decomposition of the
vertices of $G$ into two parts such that each vertex in $G$ has at least one
neighbor in each part. Also, a 1-in-Degree decomposition of a graph $G$ is a
decomposition of the vertices of $G$ into two parts $A$ and $B$ such that each
vertex in the graph $G$ has exactly one neighbor in part $A$. Among our
results, we show that for a given graph $G$, if $G$ does not have any cycle of
length congruent to 2 mod 4, then there is a polynomial time algorithm to
decide whether $G$ has a 1-in-Degree decomposition. In sharp contrast, we prove
that for every $r$, $r\geq 3$, for a given $r$-regular bipartite graph $G$
determining whether $G$ has a 1-in-Degree decomposition is $ \mathbf{NP}
$-complete. These complexity results have been especially useful in proving $
\mathbf{NP} $-completeness of various graph related problems for restricted
classes of graphs. In consequence of these results we show that for a given
bipartite 3-regular graph $G$ determining whether there is a vector in the
null-space of the 0,1-adjacency matrix of $G$ such that its entries belong to
$\{\pm 1,\pm 2\}$ is $\mathbf{NP} $-complete. Among other results, we introduce
a new version of {Planar 1-in-3 SAT} and we prove that this version is also $
\mathbf{NP} $-complete. In consequence of this result, we show that for a given
planar $(3,4)$-semiregular graph $G$ determining whether there is a vector in
the null-space of the 0,1-incidence matrix of $G$ such that its entries belong
to $\{\pm 1,\pm 2\}$ is $\mathbf{NP} $-complete.
</dc:description>
 <dc:description>Comment: To appear in Algorithmica</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04473</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Whispering: a Protocol for Physical Layer Group Key Generation.
  Application to IR-UWB through Deconvolution</dc:title>
 <dc:creator>Tunaru, Iulia</dc:creator>
 <dc:creator>Denis, Beno&#xee;t</dc:creator>
 <dc:creator>Perrier, R&#xe9;gis</dc:creator>
 <dc:creator>Uguen, Bernard</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  As wireless ad hoc and mobile networks are emerging and the transferred data
become more sensitive, information security measures should make use of all the
available contextual resources to secure information flows. The physical layer
security framework provides models, algorithms, and proofs of concept for
generating pairwise symmetric keys over single links between two nodes within
communication range. In this study, we focus on cooperative group key
generation over multiple Impulse Radio - Ultra Wideband (IR-UWB) channels
according to the source model. The main idea, proposed in previous work,
consists in generating receiver-specific signals, also called s-signals, so
that only the intended receiver has access to the non-observable channels
corresponding to its non-adjacent links. Herein, we complete the analysis of
the proposed protocol and investigate several signal processing algorithms to
generate the s-signal expressed as a solution to a deconvolution problem in the
case of IR-UWB. Our findings indicate that it is compulsory to add a
parameterizable constraint to the searched s-signal and that the
Expectation-Maximization algorithm can provide a stable self-parameterizable
solution. Compared to physical layer key distribution methods, the proposed key
generation protocol requires less traffic overhead for small cooperative groups
while being robust at medium and high signal-to-noise ratios.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04479</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Organization Systems (KOS) in the Semantic Web: A
  Multi-Dimensional Review</dc:title>
 <dc:creator>Zeng, Marcia Lei</dc:creator>
 <dc:creator>Mayr, Philipp</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Since the Simple Knowledge Organization System (SKOS) specification and its
SKOS eXtension for Labels (SKOS-XL) became formal W3C recommendations in 2009 a
significant number of conventional knowledge organization systems (KOS)
(including thesauri, classification schemes, name authorities, and lists of
codes and terms, produced before the arrival of the ontology-wave) have made
their journeys to join the Semantic Web mainstream. This paper uses &quot;LOD KOS&quot;
as an umbrella term to refer to all of the value vocabularies and lightweight
ontologies within the Semantic Web framework. The paper provides an overview of
what the LOD KOS movement has brought to various communities and users. These
are not limited to the colonies of the value vocabulary constructors and
providers, nor the catalogers and indexers who have a long history of applying
the vocabularies to their products. The LOD dataset producers and LOD service
providers, the information architects and interface designers, and researchers
in sciences and humanities, are also direct beneficiaries of LOD KOS. The paper
examines a set of the collected cases (experimental or in real applications)
and aims to find the usages of LOD KOS in order to share the practices and
ideas among communities and users. Through the viewpoints of a number of
different user groups, the functions of LOD KOS are examined from multiple
dimensions. This paper focuses on the LOD dataset producers, vocabulary
producers, and researchers (as end-users of KOS).
</dc:description>
 <dc:description>Comment: 31 pages, 12 figures, accepted paper in International Journal on
  Digital Libraries</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04480</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MAC-Oriented Programmable Terahertz PHY via Graphene-based Yagi-Uda
  Antennas</dc:title>
 <dc:creator>Hosseininejad, Seyed E.</dc:creator>
 <dc:creator>Abadal, Sergi</dc:creator>
 <dc:creator>Neshat, Mohammad</dc:creator>
 <dc:creator>Faraji-Dana, Reza</dc:creator>
 <dc:creator>Lemme, Max C.</dc:creator>
 <dc:creator>Suessmeier, Christoph</dc:creator>
 <dc:creator>Bol&#xed;var, Peter Haring</dc:creator>
 <dc:creator>Alarc&#xf3;n, Eduard</dc:creator>
 <dc:creator>Cabellos-Aparicio, Albert</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Graphene is enabling a plethora of applications in a wide range of fields due
to its unique electrical, mechanical, and optical properties. In the realm of
wireless communications, graphene shows great promise for the implementation of
miniaturized and tunable antennas in the terahertz band. These unique
advantages open the door to new reconfigurable antenna structures which, in
turn, enable novel communication protocols at different levels of the stack.
This paper explores both aspects by, first, presenting a terahertz
Yagi-Uda-like antenna concept that achieves reconfiguration both in frequency
and beam direction simultaneously. Then, a programmable antenna controller
design is proposed to expose the reconfigurability to the PHY and MAC layers,
and several examples of its applicability are given. The performance and cost
of the proposed scheme is evaluated through full-wave simulations and
comparative analysis, demonstrating reconfigurability at nanosecond granularity
with overheads below 0.02 mm$^{2}$ and 0.2 mW.
</dc:description>
 <dc:description>Comment: Accepted for presentation in IEEE WCNC '18</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04482</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic integration of UML class diagram with semantic validation on
  segments of mappings</dc:title>
 <dc:creator>Elasri, Hicham</dc:creator>
 <dc:creator>Elabbassi, Elmustapha</dc:creator>
 <dc:creator>Abderrahim, Sekkaki</dc:creator>
 <dc:creator>Fahad, Muhammad</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Recently, attention has focused on the software development, specially by
differ-ent teams that are geographically distant to support collaborative work.
Manage-ment, description and modeling in such collaborative approach are
through sever-al tools and techniques based on UML models. It is now supported
by a large number of tools. Most of these systems have the ability to compare
different UML models, assist developers, designers and also provide operations
for the merging and integration, to produce a coherent model. The contribution
in this ar-ticle is both to integrate a set of UML class diagrams using
mappings that are re-sult of alignment and assist designers and developers in
the integration. In addi-tion, we will present a detail integration of UML
models with the validation of mappings between them. Such validation helps to
achieve correct, consistent and coherent integrated model.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04483</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Waring's Theorem for Binary Powers</dc:title>
 <dc:creator>Kane, Daniel M.</dc:creator>
 <dc:creator>Sanna, Carlo</dc:creator>
 <dc:creator>Shallit, Jeffrey</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A natural number is a binary $k$'th power if its binary representation
consists of $k$ consecutive identical blocks. We prove an analogue of Waring's
theorem for sums of binary $k$'th powers. More precisely, we show that for each
integer $k \geq 2$, there exists a positive integer $W(k)$ such that every
sufficiently large multiple of $E_k := \gcd(2^k - 1, k)$ is the sum of at most
$W(k)$ binary $k$'th powers. (The hypothesis of being a multiple of $E_k$
cannot be omitted, since we show that the $\gcd$ of the binary $k$'th powers is
$E_k$.) Also, we explain how our results can be extended to arbitrary integer
bases $b &gt; 2$.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04486</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Computers Create Art?</dc:title>
 <dc:creator>Hertzmann, Aaron</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper discusses whether computers, using Artifical Intelligence (AI),
could create art. The first part concerns AI-based tools for assisting with art
making. The history of technologies that automated aspects of art is covered,
including photography and animation. In each case, we see initial fears and
denial of the technology, followed by a blossoming of new creative and
professional opportunities for artists. The hype and reality of Artificial
Intelligence (AI) tools for art making is discussed, together with predictions
about how AI tools will be used. The second part speculates about whether it
could ever happen that AI systems could conceive of artwork, and be credited
with authorship of an artwork.
</dc:description>
 <dc:description>Comment: To be submitted to Arts special issue on Machine as Artist (21st
  Century)</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04487</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Better Runtime Guarantees Via Stochastic Domination</dc:title>
 <dc:creator>Doerr, Benjamin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Apart from few exceptions, the mathematical runtime analysis of evolutionary
algorithms is mostly concerned with expected runtimes. In this work, we argue
that stochastic domination is a notion that should be used more frequently in
this area. Stochastic domination allows to formulate much more informative
performance guarantees than the expectation alone, it allows to decouple the
algorithm analysis into the true algorithmic part of detecting a domination
statement and probability theoretic part of deriving the desired probabilistic
guarantees from this statement, and it allows simpler and more natural proofs.
  As particular results, we prove a fitness level theorem which shows that the
runtime is dominated by a sum of independent geometric random variables, we
prove tail bounds for several classic problems, and we give a short and natural
proof for Witt's result that the runtime of any $(\mu,p)$ mutation-based
algorithm on any function with unique optimum is subdominated by the runtime of
a variant of the (1+1) evolutionary algorithm on the OneMax function.
</dc:description>
 <dc:description>Comment: To appear in the proceedings of EvoCOP 2018</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04489</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Stochastic Singular Vector Based MIMO Channel Model for MAC Layer
  Tracking</dc:title>
 <dc:creator>Brown, Tim W. C.</dc:creator>
 <dc:creator>Eggers, Patrick C. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  A novel stochastic technique is presented to directly model singular vectors
and singular values of a multiple input multiple output channel. Thus the
component smodeled directly in the eigen domain can be adapted to exhibit
realistic physical domain behavior when assembled. The model exploites natural
paths of eigenmodes, such that a simple Doppler filter generator process can be
used. Furthermore it is possible to directly manipulate the singular vector
dynamics in a way that an unrealistic &quot;stress channel&quot; can be modeled in the
eigen domain. This is particularly useful for testing the eigenmode channel
tracking ability internal to a communication device such as a modem, where
impairments in tracking will cause interference between eigenmodes. The model
can also facilitate mode tracking testing as it directly produces tracked
ungtangled eigenmodes, providing the narrowest possible singular vector Doppler
spectra and consequently lowest required update rates of each eigenmode. The
singular vector based model targets testing of the eigen domain functionality
of MIMO modems/devices, an apparatus focus, without the need for including the
decomposition stages.
</dc:description>
 <dc:description>Comment: ArXiv Submission</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04492</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Explicit Convergence Rate for Nesterov's Method from SDP</dc:title>
 <dc:creator>Safavi, Sam</dc:creator>
 <dc:creator>Joshi, Bikash</dc:creator>
 <dc:creator>Fran&#xe7;a, Guilherme</dc:creator>
 <dc:creator>Bento, Jos&#xe9;</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The framework of Integral Quadratic Constraints (IQC) introduced by Lessard
et al. (2014) reduces the computation of upper bounds on the convergence rate
of several optimization algorithms to semi-definite programming (SDP). In
particular, this technique was applied to Nesterov's accelerated method (NAM).
For quadratic functions, this SDP was explicitly solved leading to a new bound
on the convergence rate of NAM, and for arbitrary strongly convex functions it
was shown numerically that IQC can improve bounds from Nesterov (2004).
Unfortunately, an explicit analytic solution to the SDP was not provided. In
this paper, we provide such an analytical solution, obtaining a new general and
explicit upper bound on the convergence rate of NAM, which we further optimize
over its parameters. To the best of our knowledge, this is the best, and
explicit, upper bound on the convergence rate of NAM for strongly convex
functions.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04497</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-optimal approximation algorithm for simultaneous Max-Cut</dc:title>
 <dc:creator>Bhangale, Amey</dc:creator>
 <dc:creator>Khot, Subhash</dc:creator>
 <dc:creator>Kopparty, Swastik</dc:creator>
 <dc:creator>Sachdeva, Sushant</dc:creator>
 <dc:creator>Thiruvenkatachari, Devanathan</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the simultaneous Max-Cut problem, we are given $k$ weighted graphs on the
same set of $n$ vertices, and the goal is to find a cut of the vertex set so
that the minimum, over the $k$ graphs, of the cut value is as large as
possible. Previous work [BKS15] gave a polynomial time algorithm which achieved
an approximation factor of $1/2 - o(1)$ for this problem (and an approximation
factor of $1/2 + \epsilon_k$ in the unweighted case, where $\epsilon_k
\rightarrow 0$ as $k \rightarrow \infty$).
  In this work, we give a polynomial time approximation algorithm for
simultaneous Max-Cut with an approximation factor of $0.8780$ (for all constant
$k$). The natural SDP formulation for simultaneous Max-Cut was shown to have an
integrality gap of $1/2+\epsilon_k$ in [BKS15]. In achieving the better
approximation guarantee, we use a stronger Sum-of-Squares hierarchy SDP
relaxation and a rounding algorithm based on Raghavendra-Tan [RT12], in
addition to techniques from [BKS15].
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04498</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Methods for Solving the Cluster Containment Problem for
  Phylogenetic Networks</dc:title>
 <dc:creator>Gunawan, Andreas D. M.</dc:creator>
 <dc:creator>Lu, Bingxin</dc:creator>
 <dc:creator>Zhang, Louxin</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Genetic and comparative genomic studies indicate that extant genomes are more
properly considered to be a fusion product of random mutations over generations
and genomic material transfers between individuals of different lineages. This
has motivated researchers to adopt phylogenetic networks and other general
models to study genome evolution. One important problem arising from
reconstruction and verification of phylogenetic networks is the cluster
containment problem, namely determining whether or not a cluster of taxa is
displayed in a phylogenetic network. In this work, a new upper bound for this
NP-complete problem is established through an efficient reduction to the SAT
problem. Two efficient (albeit exponential time) methods are also implemented.
It is developed on the basis of generalization of the so-called
reticulation-visible property of phylogenetic networks.
</dc:description>
 <dc:description>Comment: 8 figure, 19 pages</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04503</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multivariate LSTM-FCNs for Time Series Classification</dc:title>
 <dc:creator>Karim, Fazle</dc:creator>
 <dc:creator>Majumdar, Somshubra</dc:creator>
 <dc:creator>Darabi, Houshang</dc:creator>
 <dc:creator>Harford, Samuel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Over the past decade, multivariate time series classification has been
receiving a lot of attention. We propose augmenting the existing univariate
time series classification models, LSTM-FCN and ALSTM-FCN with a squeeze and
excitation block to further improve performance. Our proposed models outperform
most of the state of the art models while requiring minimum preprocessing. The
proposed models work efficiently on various complex multivariate time series
classification tasks such as activity recognition or action recognition.
Furthermore, the proposed models are highly efficient at test time and small
enough to deploy on memory constrained systems.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures, 5 tables</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04504</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Orthogonal Multiple Access for mmWave Drone Networks with Limited
  Feedback</dc:title>
 <dc:creator>Rupasinghe, Nadisanka</dc:creator>
 <dc:creator>Yapici, Yavuz</dc:creator>
 <dc:creator>Guvenc, Ismail</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Unmanned aerial vehicle (UAV)-aided wireless communication networks can be a
smart solution to provide connectivity during temporary events and after
disasters. However, achieving high spectral efficiency is of paramount
importance for UAVs due to limited energy resources on board of a UAV. In this
paper, we introduce non-orthogonal multiple access (NOMA) transmission for UAVs
serving as aerial base stations (BSs) at a large stadium potentially with
several hundreds or thousands of mobile users. In particular, considering
millimeter-wave (mmWave) transmission, we make use of multi-antenna techniques
to generate directional beams specifically taking into consideration the
physical constraints of the antenna array. Multiple users are served
simultaneously within the same beam employing NOMA techniques. We focus on a
limited feedback scheme in which user distances are considered for user
ordering during NOMA formulation. For each user participating in NOMA, a target
rate based on their quality of service (QoS) requirements is defined and UAV-BS
hovering altitude is optimized to serve more users at their requested target
rates. We develop a comprehensive framework over which outage probabilities and
respective sum rates are derived rigorously for the distance feedback
mechanism, which are verified through extensive simulations. Our analytical and
simulation results depict that NOMA with distance feedback can provide better
outage sum rates compared to its orthogonal counterpart. We investigate the
optimal operation altitude of UAV-BS to maximize the sum rates using the tools
of developed analytical framework. The importance of identifying a proper user
pair for maximizing sum rates with NOMA transmission is also investigated.
</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04508</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voltage Control of DC Islanded Microgrids: Scalable Decentralised L1
  Adaptive Controllers</dc:title>
 <dc:creator>O'Keeffe, Daniel</dc:creator>
 <dc:creator>Riverso, Stefano</dc:creator>
 <dc:creator>Albiol-Tendillo, Laura</dc:creator>
 <dc:creator>Lightbody, Gordon</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Voltage stability is a critical feature of an efficiently operating power
distribution system such as a DC islanded microgrid. Large-scale autonomous
power systems can be defined by heterogeneous elements, uncertainty and
changing conditions. This paper proposes a novel scalable decentralised control
scheme at the primary level of the typical hierarchical control architecture of
DC islanded microgrids with arbitrary topology. Local state-feedback
$\mathcal{L}_1$ adaptive controllers are retrofitted to existing baseline
voltage controllers of DC-DC boost converters, which interface distributed
generation units with loads. The use of $\mathcal{L}_1$ adaptive controllers
achieves fast and robust microgrid voltage stability in the presence of dynamic
uncertainty and plug-and-play operations. Furthermore, local controller
synthesis is modular as it only requires approximate information about the line
parameters that couple neighbouring units. The performance of the proposed
architecture is evaluated using a heterogeneous DC islanded-microgrid that
consists of 6 DC-DC boost converters configured in a radial and meshed
topology. The use of $\mathcal{L}_1$ adaptive controllers achieves fast and
robust microgrid voltage stability in the presence of plug-and-play operations,
unknown load and voltage reference changes, and unmodelled dynamics. Finally,
sufficient conditions for global stability of the overall system are provided.
</dc:description>
 <dc:description>Comment: 36 pages, 69 figures, Conference paper pre-print</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04510</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brain EEG Time Series Selection: A Novel Graph-Based Approach for
  Classification</dc:title>
 <dc:creator>Dai, Chenglong</dc:creator>
 <dc:creator>Wu, Jia</dc:creator>
 <dc:creator>Pi, Dechang</dc:creator>
 <dc:creator>Cui, Lin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Brain Electroencephalography (EEG) classification is widely applied to
analyze cerebral diseases in recent years. Unfortunately, invalid/noisy EEGs
degrade the diagnosis performance and most previously developed methods ignore
the necessity of EEG selection for classification. To this end, this paper
proposes a novel maximum weight clique-based EEG selection approach, named
mwcEEGs, to map EEG selection to searching maximum similarity-weighted cliques
from an improved Fr\'{e}chet distance-weighted undirected EEG graph
simultaneously considering edge weights and vertex weights. Our mwcEEGs
improves the classification performance by selecting intra-clique pairwise
similar and inter-clique discriminative EEGs with similarity threshold
$\delta$. Experimental results demonstrate the algorithm effectiveness compared
with the state-of-the-art time series selection algorithms on real-world EEG
datasets.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04520</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Parametric Transformation Networks</dc:title>
 <dc:creator>Pal, Dipan K.</dc:creator>
 <dc:creator>Savvides, Marios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  ConvNets have been very effective in many applications where it is required
to learn invariances to within-class nuisance transformations. However, through
their architecture, ConvNets only enforce invariance to translation. In this
paper, we introduce a new class of convolutional architectures called
Non-Parametric Transformation Networks (NPTNs) which can learn general
invariances and symmetries directly from data. NPTNs are a direct and natural
generalization of ConvNets and can be optimized directly using gradient
descent. They make no assumption regarding structure of the invariances present
in the data and in that aspect are very flexible and powerful. We also model
ConvNets and NPTNs under a unified framework called Transformation Networks
which establishes the natural connection between the two. We demonstrate the
efficacy of NPTNs on natural data such as MNIST and CIFAR 10 where it
outperforms ConvNet baselines with the same number of parameters. We show it is
effective in learning invariances unknown apriori directly from data from
scratch. Finally, we apply NPTNs to Capsule Networks and show that they enable
them to perform even better.
</dc:description>
 <dc:description>Comment: Preprint only</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04523</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shrink or Substitute: Handling Process Failures in HPC Systems using
  In-situ Recovery</dc:title>
 <dc:creator>Ashraf, Rizwan A.</dc:creator>
 <dc:creator>Hukerikar, Saurabh</dc:creator>
 <dc:creator>Engelmann, Christian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Efficient utilization of today's high-performance computing (HPC) systems
with complex hardware and software components requires that the HPC
applications are designed to tolerate process failures at runtime. With low
mean time to failure (MTTF) of current and future HPC systems, long running
simulations on these systems require capabilities for gracefully handling
process failures by the applications themselves. In this paper, we explore the
use of fault tolerance extensions to Message Passing Interface (MPI) called
user-level failure mitigation (ULFM) for handling process failures without the
need to discard the progress made by the application. We explore two
alternative recovery strategies, which use ULFM along with application-driven
in-memory checkpointing. In the first case, the application is recovered with
only the surviving processes, and in the second case, spares are used to
replace the failed processes, such that the original configuration of the
application is restored. Our experimental results demonstrate that graceful
degradation is a viable alternative for recovery in environments where spares
may not be available.
</dc:description>
 <dc:description>Comment: 26th Euromicro International Conference on Parallel, Distributed and
  network-based Processing (PDP 2018)</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04528</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy Measures of Human Communication Dynamics</dc:title>
 <dc:creator>Kulisiewicz, Marcin</dc:creator>
 <dc:creator>Kazienko, Przemys&#x142;aw</dc:creator>
 <dc:creator>Szyma&#x144;ski, Boles&#x142;aw K.</dc:creator>
 <dc:creator>Michalski, Rados&#x142;aw</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Human communication is commonly represented as a temporal social network, and
evaluated in terms of its uniqueness. We propose a set of new entropy-based
measures for human communication dynamics represented within the temporal
social network as event sequences. Using real world datasets and random
interaction series of different types we find that real human contact events
always significantly differ from random ones. This human distinctiveness
increases over time and by means of the proposed entropy measures, we can
observe sociological processes that take place within dynamic communities.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04530</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bio-inspired Collision Detecotr for Small Quadcopter</dc:title>
 <dc:creator>Zhao, Jiannan</dc:creator>
 <dc:creator>Hu, Cheng</dc:creator>
 <dc:creator>Zhang, Chun</dc:creator>
 <dc:creator>Wang, Zhihua</dc:creator>
 <dc:creator>Yue, Shigang</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Sense and avoid capability enables insects to fly versatilely and robustly in
dynamic complex environment. Their biological principles are so practical and
efficient that inspired we human imitating them in our flying machines. In this
paper, we studied a novel bio-inspired collision detector and its application
on a quadcopter. The detector is inspired from LGMD neurons in the locusts, and
modeled into an STM32F407 MCU. Compared to other collision detecting methods
applied on quadcopters, we focused on enhancing the collision selectivity in a
bio-inspired way that can considerably increase the computing efficiency during
an obstacle detecting task even in complex dynamic environment. We designed the
quadcopter's responding operation imminent collisions and tested this
bio-inspired system in an indoor arena. The observed results from the
experiments demonstrated that the LGMD collision detector is feasible to work
as a vision module for the quadcopter's collision avoidance task.
</dc:description>
 <dc:description>Comment: 7 pages, 29 figures</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04537</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed Neighbour Discovery using Sparse Kerdock Matrices</dc:title>
 <dc:creator>Thompson, Andrew</dc:creator>
 <dc:creator>Calderbank, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A05</dc:subject>
 <dc:description>  We study the network-wide neighbour discovery problem in wireless networks in
which each node in a network must discovery the network interface addresses
(NIAs) of its neighbours. We work within the rapid on-off division duplex
framework proposed by Guo and Zhang (2010) in which all nodes are assigned
different on-off signatures which allow them listen to the transmissions of
neighbouring nodes during their off slots, leading to a compressed sensing
problem at each node with a collapsed codebook determined by a given node's
transmission signature. We propose sparse Kerdock matrices as codebooks for the
neighbour discovery problem. These matrices share the same row space as certain
Delsarte-Goethals frames based upon Reed Muller codes, whilst at the same time
being extremely sparse. We present numerical experiments using two different
compressed sensing recovery algorithms, One Step Thresholding (OST) and
Normalised Iterative Hard Thresholding (NIHT). For both algorithms, a higher
proportion of neighbours are successfully identified using sparse Kerdock
matrices compared to codebooks based on Reed Muller codes with random erasures
as proposed by Zhang and Guo (2011). We argue that the improvement is due to
the better interference cancellation properties of sparse Kerdock matrices when
collapsed according to a given node's transmission signature. We show by
explicit calculation that the coherence of the collapsed codebooks resulting
from sparse Kerdock matrices remains near-optimal.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04540</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fix your classifier: the marginal value of training the last weight
  layer</dc:title>
 <dc:creator>Hoffer, Elad</dc:creator>
 <dc:creator>Hubara, Itay</dc:creator>
 <dc:creator>Soudry, Daniel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural networks are commonly used as models for classification for a wide
variety of tasks. Typically, a learned affine transformation is placed at the
end of such models, yielding a per-class value used for classification. This
classifier can have a vast number of parameters, which grows linearly with the
number of possible classes, thus requiring increasingly more resources.
  In this work we argue that this classifier can be fixed, up to a global scale
constant, with little or no loss of accuracy for most tasks, allowing memory
and computational benefits. Moreover, we show that by initializing the
classifier with a Hadamard matrix we can speed up inference as well. We discuss
the implications for current understanding of neural network models.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04541</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Multi-Agent Reinforcement Learning for Low-Level Wireless
  Communication</dc:title>
 <dc:creator>de Vrieze, Colin</dc:creator>
 <dc:creator>Barratt, Shane</dc:creator>
 <dc:creator>Tsai, Daniel</dc:creator>
 <dc:creator>Sahai, Anant</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Traditional radio systems are strictly co-designed on the lower levels of the
OSI stack for compatibility and efficiency. Although this has enabled the
success of radio communications, it has also introduced lengthy standardization
processes and imposed static allocation of the radio spectrum. Various
initiatives have been undertaken by the research community to tackle the
problem of artificial spectrum scarcity by both making frequency allocation
more dynamic and building flexible radios to replace the static ones. There is
reason to believe that just as computer vision and control have been overhauled
by the introduction of machine learning, wireless communication can also be
improved by utilizing similar techniques to increase the flexibility of
wireless networks. In this work, we pose the problem of discovering low-level
wireless communication schemes ex-nihilo between two agents in a fully
decentralized fashion as a reinforcement learning problem. Our proposed
approach uses policy gradients to learn an optimal bi-directional communication
scheme and shows surprisingly sophisticated and intelligent learning behavior.
We present the results of extensive experiments and an analysis of the fidelity
of our approach.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04544</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hire the Experts: Combinatorial Auction Based Scheme for Experts
  Selection in E-Healthcare</dc:title>
 <dc:creator>Singh, Vikash Kumar</dc:creator>
 <dc:creator>Mukhopadhyay, Sajal</dc:creator>
 <dc:creator>Xhafa, Fatos</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  During the last decade, scheduling the healthcare services (such as staffs
and OTs) inside the hospitals have assumed a central role in healthcare.
Recently, some works are addressed in the direction of hiring the expert
consultants (mainly doctors) for the critical healthcare scenarios from outside
of the medical unit, in both strategic and non-strategic settings under
monetary and non-monetary perspectives. In this paper, we have tried to
investigate the experts hiring problem with multiple patients and multiple
experts; where each patient reports a preferred set of experts which is private
information alongwith their private cost for consultancy. To the best of our
knowledge, this is the first step in the direction of modeling the experts
hiring problem in the combinatorial domain. In this paper, the combinatorial
auction based scheme is proposed for hiring experts from outside of the
hospitals to have expertise by the preferred doctors set to the patients.
</dc:description>
 <dc:description>Comment: 7 Pages</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04545</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput Maximization for UAV-Enabled Wireless Powered Communication
  Networks</dc:title>
 <dc:creator>Xie, Lifeng</dc:creator>
 <dc:creator>Xu, Jie</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies an unmanned aerial vehicle (UAV)-enabled wireless powered
communication network (WPCN), in which a UAV is dispatched as a mobile access
point (AP) to serve a set of ground users. The UAV employs the radio frequency
(RF) signals based wireless power transfer (WPT) to charge the users in the
downlink, and the users use the harvested RF energy to send individual
information back to the UAV in the uplink. Unlike the conventional WPCN with
fixed APs, the UAV-enabled WPCN can exploit the mobility of the UAV via
trajectory optimization, jointly with the wireless resource allocation, to
improve the system performance. In particular, we aim to maximize the uplink
common throughput among all ground users over a particular finite time period,
subject to the UAV's maximum speed constraint and the users' energy harvesting
constraints. The decision variables include the UAV's trajectory design, as
well as the UAV's downlink power allocation for WPT and the users' uplink power
allocation for wireless information transfer (WIT). This problem is non-convex
and thus very difficult to be solved optimally. To overcome this issue, we
first consider a special case when the maximum UAV speed constraint is ignored,
and obtain the optimal solution to this relaxed problem. The optimal solution
shows that the UAV should hover above a finite number of ground locations over
time for downlink WPT, and then hover above each user at different time for
uplink WIT. Next, based on the optimal multi-location-hovering solution to the
relaxed problem, we propose the successive hover-and-fly trajectory, jointly
with the downlink and uplink power allocation, to efficiently solve the
original problem with the maximum UAV speed constraint. Numerical results show
that the proposed UAV-enabled WPCN achieves much higher uplink common
throughput than the conventional WPCN with fixed-location AP.
</dc:description>
 <dc:description>Comment: To appear in IEEE VTC 2018 Spring</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04546</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Machine Learning Fameworks on Finis Terrae II</dc:title>
 <dc:creator>Tato, Andres Gomez</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine Learning (ML) and Deep Learning (DL) are two technologies used to
extract representations of the data for a specific purpose. ML algorithms take
a set of data as input to generate one or several predictions. To define the
final version of one model, usually there is an initial step devoted to train
the algorithm (get the right final values of the parameters of the model).
There are several techniques, from supervised learning to reinforcement
learning, which have different requirements. On the market, there are some
frameworks or APIs that reduce the effort for designing a new ML model. In this
report, using the benchmark DLBENCH, we will analyse the performance and the
execution modes of some well-known ML frameworks on the Finis Terrae II
supercomputer when supervised learning is used. The report will show that
placement of data and allocated hardware can have a large influence on the
final timeto-solution.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04548</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frame Moments and Welch Bound with Erasures</dc:title>
 <dc:creator>Haikin, Marina</dc:creator>
 <dc:creator>Zamir, Ram</dc:creator>
 <dc:creator>Gavish, Matan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Welch Bound is a lower bound on the root mean square cross correlation
between $n$ unit-norm vectors $f_1,...,f_n$ in the $m$ dimensional space
($\mathbb{R} ^m$ or $\mathbb{C} ^m$), for $n\geq m$. Letting $F =
[f_1|...|f_n]$ denote the $m$-by-$n$ frame matrix, the Welch bound can be
viewed as a lower bound on the second moment of $F$, namely on the trace of the
squared Gram matrix $(F'F)^2$. We consider an erasure setting, in which a
reduced frame, composed of a random subset of Bernoulli selected vectors, is of
interest. We extend the Welch bound to this setting and present the {\em
erasure Welch bound} on the expected value of the Gram matrix of the reduced
frame. Interestingly, this bound generalizes to the $d$-th order moment of $F$.
We provide simple, explicit formulae for the generalized bound for $d=2,3,4$,
which is the sum of the $d$-th moment of Wachter's classical MANOVA
distribution and a vanishing term (as $n$ goes to infinity with $\frac{m}{n}$
held constant). The bound holds with equality if (and for $d = 4$ only if) $F$
is an Equiangular Tight Frame (ETF). Our results offer a novel perspective on
the superiority of ETFs over other frames in a variety of applications,
including spread spectrum communications, compressed sensing and analog coding.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04552</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Resource Allocation in NOMA Heterogeneous Networks</dc:title>
 <dc:creator>Zhang, Haijun</dc:creator>
 <dc:creator>Fang, Fang</dc:creator>
 <dc:creator>Cheng, Julian</dc:creator>
 <dc:creator>Long, Keping</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Leung, Victor C. M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Non-orthogonal multiple access (NOMA) has attracted much recent attention
owing to its capability for improving the system spectral efficiency in
wireless communications. Deploying NOMA in heterogeneous network can satisfy
users' explosive data traffic requirements, and NOMA will likely play an
important role in the fifth-generation (5G) mobile communication networks.
However, NOMA brings new technical challenges on resource allocation due to the
mutual cross-tier interference in heterogeneous networks. In this article, to
study the tradeoff between data rate performance and energy consumption in
NOMA, we examine the problem of energy-efficient user scheduling and power
optimization in 5G NOMA heterogeneous networks. The energy-efficient user
scheduling and power allocation schemes are introduced for the downlink 5G NOMA
heterogeneous network for perfect and imperfect channel state information (CSI)
respectively. Simulation results show that the resource allocation schemes can
significantly increase the energy efficiency of 5G NOMA heterogeneous network
for both cases of perfect CSI and imperfect CSI.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04553</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast computation of approximant bases in canonical form</dc:title>
 <dc:creator>Jeannerod, Claude-Pierre</dc:creator>
 <dc:creator>Neiger, Vincent</dc:creator>
 <dc:creator>Villard, Gilles</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  In this article, we design fast algorithms for the computation of approximant
bases in shifted Popov normal form. We first recall the algorithm known as
PM-Basis, which will be our second fundamental engine after polynomial matrix
multiplication: most other fast approximant basis algorithms basically aim at
efficiently reducing the input instance to instances for which PM-Basis is
fast. Such reductions usually involve partial linearization techniques due to
Storjohann, which have the effect of balancing the degrees and dimensions in
the manipulated matrices.
  Following these ideas, Zhou and Labahn gave two algorithms which are faster
than PM-Basis for important cases including Hermite-Pade approximation, yet
only for shifts whose values are concentrated around the minimum or the maximum
value. The three mentioned algorithms were designed for balanced orders and
compute approximant bases that are generally not normalized. Here, we show how
they can be modified to return the shifted Popov basis without impact on their
cost bound; besides, we extend Zhou and Labahn's algorithms to arbitrary
orders.
  Furthermore, we give an algorithm which handles arbitrary shifts with one
extra logarithmic factor in the cost bound compared to the above algorithms. To
the best of our knowledge, this improves upon previously known algorithms for
arbitrary shifts, including for particular cases such as Hermite-Pade
approximation. This algorithm is based on a recent divide and conquer approach
which reduces the general case to the case where information on the output
degree is available. As outlined above, we solve the latter case via partial
linearizations and PM-Basis.
</dc:description>
 <dc:description>Comment: 36 pages, 8 algorithms</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04554</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DCDistance: A Supervised Text Document Feature extraction based on class
  labels</dc:title>
 <dc:creator>Ferreira, Charles Henrique Porto</dc:creator>
 <dc:creator>de Medeiros, Debora Maria Rossi</dc:creator>
 <dc:creator>de Fran&#xe7;a, Fabricio Olivetti</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Text Mining is a field that aims at extracting information from textual data.
One of the challenges of such field of study comes from the pre-processing
stage in which a vector (and structured) representation should be extracted
from unstructured data. The common extraction creates large and sparse vectors
representing the importance of each term to a document. As such, this usually
leads to the curse-of-dimensionality that plagues most machine learning
algorithms. To cope with this issue, in this paper we propose a new supervised
feature extraction and reduction algorithm, named DCDistance, that creates
features based on the distance between a document to a representative of each
class label. As such, the proposed technique can reduce the features set in
more than 99% of the original set. Additionally, this algorithm was also
capable of improving the classification accuracy over a set of benchmark
datasets when compared to traditional and state-of-the-art features selection
algorithms.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04556</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Poisson Cox Point Processes for Vehicular Networks</dc:title>
 <dc:creator>Choi, Chang-Sik</dc:creator>
 <dc:creator>Baccelli, Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper analyzes statistical properties of the Poisson line Cox point
process useful in the modeling of vehicular networks. The point process is
created by a two-stage construction: a Poisson line process to model road
infrastructure and independent Poisson point processes, conditionally on the
Poisson lines, to model vehicles on the roads. We derive basic properties of
the point process, including the general quadratic position of the points, the
nearest distance distribution, the Laplace functional, the densities of facets
of the Cox-Voronoi tessellation, and the asymptotic behavior of the typical
Voronoi cell under vehicular densification. These properties are closely linked
to features that are important in vehicular networks.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04558</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the effect of blockage objects in dense MIMO SWIPT networks</dc:title>
 <dc:creator>Akin, Ayse Ipek</dc:creator>
 <dc:creator>Stupia, Ivan</dc:creator>
 <dc:creator>Vandendorpe, Luc</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Simultaneous information and power transfer (SWIPT) is characterised by the
ambiguous role of multi-user interference. In short, the beneficial effect of
multi-user interference on RF energy harvesting is obtained at the price of a
reduced link capacity, thus originating nontrivial trade-offs between the
achievable information rate and the harvestable energy. Arguably, in indoor
environments, this trade-off might be affected by the propagation loss due to
blockage objects like walls. Hence, a couple of fundamental questions arise.
How much must the network elements be densified to counteract the blockage
attenuation? Is blockage always detrimental on the achievable rate-energy
trade-off? In this paper, we analyse the performance of an indoor
multiple-input multiple-output (MIMO) SWIPT-enabled network in the attempt to
shed a light of those questions. The effects of the obstacles are examined with
the help of a stochastic approach in which energy transmitters (also referred
to as power heads) are located by using a Poisson Point Process and walls are
generated through a Manhattan Poisson Line Process. The stochastic behaviour of
the signal attenuation and the multi-user interference is studied to obtain the
Joint Complementary Cumulative Distribution Function (J-CCDF) of information
rate and harvested power. Theoretical results are validated through Monte Carlo
simulations. Eventually, the rate-energy trade-off is presented as a function
of the frequency of walls to emphasise the cross-dependences between the
deployment of the network elements and the topology of the venue.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04565</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shai: Enforcing Data-Specific Policies with Near-Zero Runtime Overhead</dc:title>
 <dc:creator>Elnikety, Eslam</dc:creator>
 <dc:creator>Garg, Deepak</dc:creator>
 <dc:creator>Druschel, Peter</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Data retrieval systems such as online search engines and online social
networks must comply with the privacy policies of personal and selectively
shared data items, regulatory policies regarding data retention and censorship,
and the provider's own policies regarding data use. Enforcing these policies is
difficult and error-prone. Systematic techniques to enforce policies are either
limited to type-based policies that apply uniformly to all data of the same
type, or incur significant runtime overhead.
  This paper presents Shai, the first system that systematically enforces
data-specific policies with near-zero overhead in the common case. Shai's key
idea is to push as many policy checks as possible to an offline, ahead-of-time
analysis phase, often relying on predicted values of runtime parameters such as
the state of access control lists or connected users' attributes. Runtime
interception is used sparingly, only to verify these predictions and to make
any remaining policy checks. Our prototype implementation relies on efficient,
modern OS primitives for sandboxing and isolation. We present the design of
Shai and quantify its overheads on an experimental data indexing and search
pipeline based on the popular search engine Apache Lucene.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04569</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Realistic Threat Modeling: Attack Commodification, Irrelevant
  Vulnerabilities, and Unrealistic Assumptions</dc:title>
 <dc:creator>Allodi, Luca</dc:creator>
 <dc:creator>Etalle, Sandro</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Current threat models typically consider all possible ways an attacker can
penetrate a system and assign probabilities to each path according to some
metric (e.g. time-to-compromise). In this paper we discuss how this view
hinders the realness of both technical (e.g. attack graphs) and strategic (e.g.
game theory) approaches of current threat modeling, and propose to steer away
by looking more carefully at attack characteristics and attacker environment.
We use a toy threat model for ICS attacks to show how a realistic view of
attack instances can emerge from a simple analysis of attack phases and
attacker limitations.
</dc:description>
 <dc:description>Comment: Proceedings of the 2017 Workshop on Automated Decision Making for
  Active Cyber Defense</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04569</dc:identifier>
 <dc:identifier>doi:10.1145/3140368.3140372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04572</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Quantum Arbitrarily Varying Channels: Random Coding Capacity and
  Capacity Dichotomy</dc:title>
 <dc:creator>Boche, Holger</dc:creator>
 <dc:creator>Deppe, Christian</dc:creator>
 <dc:creator>N&#xf6;tzel, Janis</dc:creator>
 <dc:creator>Winter, Andreas</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a model of communication via a fully quantum jammer channel with
quantum jammer, quantum sender and quantum receiver, which we dub quantum
arbitrarily varying channel (QAVC). Restricting to finite dimensional user and
jammer systems, we show, using permutation symmetry and a de Finetti reduction,
how the random coding capacity (classical and quantum) of the QAVC is reduced
to the capacity of a naturally associated compound channel, which is obtained
by restricting the jammer to i.i.d. input states.
  Furthermore, we demonstrate that the shared randomness required is at most
logarithmic in the block length, using a random matrix tail bound. This implies
a dichotomy theorem: either the classical capacity of the QAVC is zero, and
then also the quantum capacity is zero, or each capacity equals its random
coding variant.
</dc:description>
 <dc:description>Comment: 5 pages, ISIT format (IEEEtra.cls)</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04581</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voliro: An Omnidirectional Hexacopter With Tiltable Rotors</dc:title>
 <dc:creator>Kamel, Mina</dc:creator>
 <dc:creator>Verling, Sebastian</dc:creator>
 <dc:creator>Elkhatib, Omar</dc:creator>
 <dc:creator>Sprecher, Christian</dc:creator>
 <dc:creator>Wulkop, Paula</dc:creator>
 <dc:creator>Taylor, Zachary</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:creator>Gilitschenski, Igor</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Extending the maneuverability of unmanned areal vehicles promises to yield a
considerable increase in the areas in which these systems can be used. Some
such applications are the performance of more complicated inspection tasks and
the generation of complex uninterrupted movements of an attached camera. In
this paper we address this challenge by presenting Voliro, a novel aerial
platform that combines the advantages of existing multi-rotor systems with the
agility of omnidirectionally controllable platforms. We propose the use of a
hexacopter with tiltable rotors allowing the system to decouple the control of
position and orientation. The contributions of this work involve the mechanical
design as well as a controller with the corresponding allocation scheme. This
work also discusses the design challenges involved when turning the concept of
a hexacopter with tiltable rotors into an actual prototype. The agility of the
system is demonstrated and evaluated in real- world experiments.
</dc:description>
 <dc:description>Comment: Submitted to Robotics and Automation Magazine</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04582</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed dynamic load balancing for task parallel programming</dc:title>
 <dc:creator>Zafari, Afshin</dc:creator>
 <dc:creator>Larsson, Elisabeth</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  In this paper, we derive and investigate approaches to dynamically load
balance a distributed task parallel application software. The load balancing
strategy is based on task migration. Busy processes export parts of their ready
task queue to idle processes. Idle--busy pairs of processes find each other
through a random search process that succeeds within a few steps with high
probability. We evaluate the load balancing approach for a block Cholesky
factorization implementation and observe a reduction in execution time on the
order of 5\% in the selected test cases.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04589</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Fuzzing</dc:title>
 <dc:creator>B&#xf6;ttinger, Konstantin</dc:creator>
 <dc:creator>Godefroid, Patrice</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Fuzzing is the process of finding security vulnerabilities in
input-processing code by repeatedly testing the code with modified inputs. In
this paper, we formalize fuzzing as a reinforcement learning problem using the
concept of Markov decision processes. This in turn allows us to apply
state-of-the-art deep Q-learning algorithms that optimize rewards, which we
define from runtime properties of the program under test. By observing the
rewards caused by mutating with a specific set of actions performed on an
initial program input, the fuzzing agent learns a policy that can next generate
new higher-reward inputs. We have implemented this new approach, and
preliminary empirical evidence shows that reinforcement fuzzing can outperform
baseline random fuzzing.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04590</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frame-Recurrent Video Super-Resolution</dc:title>
 <dc:creator>Sajjadi, Mehdi S. M.</dc:creator>
 <dc:creator>Vemulapalli, Raviteja</dc:creator>
 <dc:creator>Brown, Matthew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent advances in video super-resolution have shown that convolutional
neural networks combined with motion compensation are able to merge information
from multiple low-resolution (LR) frames to generate high-quality images.
Current state-of-the-art methods process a batch of LR frames to generate a
single high-resolution (HR) frame and run this scheme in a sliding window
fashion over the entire video, effectively treating the problem as a large
number of separate multi-frame super-resolution tasks. This approach has two
main weaknesses: 1) Each input frame is processed and warped multiple times,
increasing the computational cost, and 2) each output frame is estimated
independently conditioned on the input frames, limiting the system's ability to
produce temporally consistent results.
  In this work, we propose an end-to-end trainable frame-recurrent video
super-resolution framework that uses the previously inferred HR estimate to
super-resolve the subsequent frame. This naturally encourages temporally
consistent results and reduces the computational cost by warping only one image
in each step. Furthermore, due to its recurrent nature, the proposed method has
the ability to assimilate a large number of previous frames without increased
computational demands. Extensive evaluations and comparisons with previous
methods validate the strengths of our approach and demonstrate that the
proposed framework is able to significantly outperform the current state of the
art.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04593</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Identifying a Massive Number of Distributions</dc:title>
 <dc:creator>Shahi, Sara</dc:creator>
 <dc:creator>Tuninetti, Daniela</dc:creator>
 <dc:creator>Devroye, Natasha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Finding the underlying probability distributions of a set of observed
sequences under the constraint that each sequence is generated i.i.d by a
distinct distribution is considered. The number of distributions, and hence the
number of observed sequences, are let to grow with the observation blocklength
$n$. Asymptotically matching upper and lower bounds on the probability of error
are derived.
</dc:description>
 <dc:description>Comment: Under Submission</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04598</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Perspectives on Multi-Prover Interactive Proofs</dc:title>
 <dc:creator>Cr&#xe9;peau, Claude</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The existing multi-prover interactive proof framework suffers from
incompleteness in terms of soundness and zero-knowledge that is not completely
addressed in the literature. The problem is that the existing definitions of
what is local, entangled and no-signalling are not rich enough to capture the
full generality of multi-prover interaction. In general, existing proofs do not
take into account possible changes in locality either during a protocol's
execution or when protocols are composed together. This is especially
problematic for zero-knowledge, as composing commitments is the only known way
of achieving zero-knowledge outside of some NP-intermediate languages.
  In this work, we introduce the locality hierarchy for multiparty
(multi-round) interaction, and for the first time a complete definition of
multi-round multiparty no-signalling distributions and strategies. Within this
framework, we define the locality of a protocol which involves the provers,
verifiers, simulators and distinguishers. We show that an existing protocol for
NEXP [BFL90] and a zero-knowledge variant we introduce are sound in a local
sense, but are zero-knowledge in a sense that is even stronger than usually
understood. All prior claims of zero-knowledge proofs in the multi-prover model
were actually incorrect. Finally, we present similar constructions for
entangled and no-signalling prover sets for NEXP and EXP based on [IV12] and
[KRR14] using new multi-prover commitment schemes.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures. Submitted to the STOC 2018 conference, Nov 2017</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04600</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning of Cell Movement in the Early Stage of C.
  elegans Embryogenesis</dc:title>
 <dc:creator>Wang, Zi</dc:creator>
 <dc:creator>Wang, Dali</dc:creator>
 <dc:creator>Li, Chengcheng</dc:creator>
 <dc:creator>Xu, Yichi</dc:creator>
 <dc:creator>Li, Husheng</dc:creator>
 <dc:creator>Bao, Zhirong</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Cell movement in the early phase of C. elegans development is regulated by a
highly complex process in which a set of rules and connections are formulated
at distinct scales. Previous efforts have demonstrated that agent-based,
multi-scale modeling systems can integrate physical and biological rules and
provide new avenues to study developmental systems. However, the application of
these systems to model cell movement is still challenging and requires a
comprehensive understanding of regulation networks at the right scales. Recent
developments in deep learning and reinforcement learning provide an
unprecedented opportunity to explore cell movement using 3D time-lapse
microscopy images. We presented a deep reinforcement learning approach within
an agent-based modeling system to characterize cell movement in the embryonic
development of C. elegans. We tested our model through two scenarios within
real developmental processes: the anterior movement of the Cpaaa cell via
intercalation and the restoration of the superficial left-right symmetry. Our
modeling system overcame the local optimization problems encountered by
traditional rule-based, agent-based modeling by using greedy algorithms. It
also overcame the computational challenges in the action selection which has
been plagued by the traditional tabular-based reinforcement learning approach.
Our system can automatically explore the cell movement path by using live
microscopy images and it can provide a unique capability to model cell movement
scenarios where regulatory mechanisms are not well studied. In addition, our
system can be used to explore potential paths of a cell under different
regulatory mechanisms or to facilitate new hypotheses for explaining certain
cell movement behaviors.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04601</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PACER: Peripheral Activity Completion Estimation and Recognition</dc:title>
 <dc:creator>Moore, Daniel</dc:creator>
 <dc:creator>Dean, Alexander</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Embedded peripheral devices such as memories, sensors and communications
interfaces are used to perform a function external to a host microcontroller.
The device manufacturer typically specifies worst-case current consumption and
latency estimates for each of these peripheral actions. Peripheral Activity
Completion, Estimation and Recognition (PACER) is introduced as a suite of
algorithms that can be applied to detect completed peripheral operations in
real-time. By detecting activity completion, PACER enables the host to exploit
slack between the worst-case estimate and the actual response time. These
methods were tested independently and in conjunction with IODVS on multiple
common peripheral devices. For the peripheral devices under test, the test
fixture confirmed decreases in energy expenditures of up to 80% and latency
reductions of up to 67%.
</dc:description>
 <dc:description>Comment: 8 pages, 12 figures, Presented at HIP3ES, 2018</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04607</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic Polynomials</dc:title>
 <dc:creator>Sherstov, Alexander A.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The approximate degree of a Boolean function $f(x_{1},x_{2},\ldots,x_{n})$ is
the minimum degree of a real polynomial that approximates $f$ pointwise within
$1/3$. Upper bounds on approximate degree have a variety of applications in
learning theory, differential privacy, and algorithm design in general. Nearly
all known upper bounds on approximate degree arise in an existential manner
from bounds on quantum query complexity. We develop a first-principles,
classical approach to the polynomial approximation of Boolean functions. We use
it to give the first constructive upper bounds on the approximate degree of
several fundamental problems:
  - $O\bigl(n^{\frac{3}{4}-\frac{1}{4(2^{k}-1)}}\bigr)$ for the $k$-element
distinctness problem;
  - $O(n^{1-\frac{1}{k+1}})$ for the $k$-subset sum problem;
  - $O(n^{1-\frac{1}{k+1}})$ for any $k$-DNF or $k$-CNF formula;
  - $O(n^{3/4})$ for the surjectivity problem.
  In all cases, we obtain explicit, closed-form approximating polynomials that
are unrelated to the quantum arguments from previous work. Our first three
results match the bounds from quantum query complexity. Our fourth result
improves polynomially on the $\Theta(n)$ quantum query complexity of the
problem and refutes the conjecture by several experts that surjectivity has
approximate degree $\Omega(n)$. In particular, we exhibit the first natural
problem with a polynomial gap between approximate degree and quantum query
complexity.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04609</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tyche: Risk-Based Permissions for Smart Home Platforms</dc:title>
 <dc:creator>Rahmati, Amir</dc:creator>
 <dc:creator>Fernandes, Earlence</dc:creator>
 <dc:creator>Eykholt, Kevin</dc:creator>
 <dc:creator>Prakash, Atul</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Emerging smart home platforms, which interface with a variety of physical
devices and support third-party application development, currently use
permission models inspired by smartphone operating systems-they group
functionally similar device operations into separate units, and require users
to grant apps access to devices at that granularity. Unfortunately, this leads
to two issues: (1) apps that do not require access to all of the granted device
operations have overprivileged access to them, (2) apps might pose a higher
risk to users than needed because physical device operations are fundamentally
risk- asymmetric-&quot;door.unlock&quot; provides access to burglars, and &quot;door.lock&quot; can
potentially lead to getting locked out. Overprivileged apps with access to
mixed-risk operations only increase the potential for damage. We present Tyche,
a system that leverages the risk-asymmetry in physical device operations to
limit the risk that apps pose to smart home users, without increasing the
user's decision overhead. Tyche introduces the notion of risk-based
permissions. When using risk-based permissions, device operations are grouped
into units of similar risk, and users grant apps access to devices at that
risk-based granularity. Starting from a set of permissions derived from the
popular Samsung SmartThings platform, we conduct a user study involving
domain-experts and Mechanical Turk users to compute a relative ranking of risks
associated with device operations. We find that user assessment of risk closely
matches that of domain experts. Using this ranking, we define risk-based
groupings of device operations, and apply it to existing SmartThings apps,
showing that risk-based permissions indeed limit risk if apps are malicious or
exploitable.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04613</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Defined Networks based Smart Grid Communication: A
  Comprehensive Survey</dc:title>
 <dc:creator>Rehmani, Mubashir Husain</dc:creator>
 <dc:creator>Davy, Alan</dc:creator>
 <dc:creator>Jennings, Brendan</dc:creator>
 <dc:creator>Assi, Chadi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Software defined networks (SDN) has been proposed to monitor and manage the
communication networks globally. SDN revolutionized the way the communication
network managed previously. By segregating the control plane from the data
plane, SDN helps the network operators to manage the network flexibly. Since
smart grid heavily relies on communication networks, therefore, SDN has also
paved its way into the smart grid. By applying SDN in SG systems, efficiency
and resiliency can potentially be improved. SDN, with its programmability,
protocol independence, and granularity features, can help the smart grid to
integrate different SG standards and protocols, to cope with diverse
communication systems, and to help SG to perform traffic flow orchestration and
to meet specific SG quality of service requirements. This article serves as a
comprehensive survey on SDN-based smart grid. In this article, we first discuss
taxonomy of advantages of SDN-based smart grid. We then discuss SDN-based smart
grid architectures, along with case studies. Our article provides an in-depth
discussion on multicasting and routing schemes for SDN-based smart grid. We
also provide detailed survey of security and privacy schemes applied to
SDN-based smart grid. We furthermore presents challenges, open issues, and
future research directions related to SDN-based smart grid.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04614</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Generalizations of Good Integers and Their Applications in the
  Study of Self-Dual Negacyclic Codes</dc:title>
 <dc:creator>Prugsapitak, Supawadee</dc:creator>
 <dc:creator>Jitman, Somphong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>11N25, 94B15, 94B60</dc:subject>
 <dc:description>  Good integers introduced in 1997 form an interesting family of integers that
has been continuously studied due to their rich number theoretical properties
and wide applications. In this paper, we have focused on classes of
$2^\beta$-good integers, $2^\beta$-oddly-good integers, and
$2^\beta$-evenly-good integers which are generalizations of good integers.
Properties of such integers have been given as well as their applications in
characterizing and enumerating self-dual negacyclic codes over finite fields.
An alternative proof for the characterization of the existence of a self-dual
negacyclic code over finite fields have been given in terms of such generalized
good integers. A general enumeration formula for the number of self-dual
negacyclic codes of length $n$ over finite fields has been established. For
some specific lengths, explicit formulas have been provided as well. Some known
results on self-dual negacyclic codes over finite fields can be formalized and
viewed as special cases of this work.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04618</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Memory Management for Mutable State</dc:title>
 <dc:creator>Guatto, Adrien</dc:creator>
 <dc:creator>Westrick, Sam</dc:creator>
 <dc:creator>Raghunathan, Ram</dc:creator>
 <dc:creator>Acar, Umut</dc:creator>
 <dc:creator>Fluet, Matthew</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  It is well known that modern functional programming languages are naturally
amenable to parallel programming. Achieving efficient parallelism using
functional languages, however, remains difficult. Perhaps the most important
reason for this is their lack of support for efficient in-place updates, i.e.,
mutation, which is important for the implementation of both parallel algorithms
and the run-time system services (e.g., schedulers and synchronization
primitives) used to execute them.
  In this paper, we propose techniques for efficient mutation in parallel
functional languages. To this end, we couple the memory manager with the thread
scheduler to make reading and updating data allocated by nested threads
efficient. We describe the key algorithms behind our technique, implement them
in the MLton Standard ML compiler, and present an empirical evaluation. Our
experiments show that the approach performs well, significantly improving
efficiency over existing functional language implementations.
</dc:description>
 <dc:description>Comment: 15 pages, 14 figures, PPoPP 2018</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04618</dc:identifier>
 <dc:identifier>doi:10.1145/3178487.3178494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04619</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Innovative Non-parametric Texture Synthesis via Patch Permutations</dc:title>
 <dc:creator>Webster, Ryan</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  In this work, we present a non-parametric texture synthesis algorithm capable
of producing plausible images without copying large tiles of the exemplar. We
focus on a simple synthesis algorithm, where we explore two patch match
heuristics; the well known Bidirectional Similarity (BS) measure and a
heuristic that finds near permutations using the solution of an entropy
regularized optimal transport (OT) problem. Innovative synthesis is achieved
with a small patch size, where global plausibility relies on the qualities of
the match. For OT, less entropic regularization also meant near permutations
and more plausible images. We examine the tile maps of the synthesized images,
showing that they are indeed novel superpositions of the input and contain few
or no verbatim copies. Synthesis results are compared to a statistical method,
namely a random convolutional network. We conclude by remarking simple
algorithms using only the input image can synthesize textures decently well and
call for more modest approaches in future algorithm design.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04622</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top k Memory Candidates in Memory Networks for Common Sense Reasoning</dc:title>
 <dc:creator>Mahajan, Vatsal</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Successful completion of reasoning task requires the agent to have relevant
prior knowledge or some given context of the world dynamics. Usually, the
information provided to the system for a reasoning task is just the query or
some supporting story, which is often not enough for common reasoning tasks.
The goal here is that, if the information provided along the question is not
sufficient to correctly answer the question, the model should choose k most
relevant documents that can aid its inference process. In this work, the model
dynamically selects top k most relevant memory candidates that can be used to
successfully solve reasoning tasks. Experiments were conducted on a subset of
Winograd Schema Challenge (WSC) problems to show that the proposed model has
the potential for commonsense reasoning. The WSC is a test of machine
intelligence, designed to be an improvement on the Turing test.
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04623</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sex differences in network controllability as a predictor of executive
  function in youth</dc:title>
 <dc:creator>Cornblath, Eli J.</dc:creator>
 <dc:creator>Tang, Evelyn</dc:creator>
 <dc:creator>Baum, Graham L.</dc:creator>
 <dc:creator>Moore, Tyler M.</dc:creator>
 <dc:creator>Roalf, David R.</dc:creator>
 <dc:creator>Gur, Ruben C.</dc:creator>
 <dc:creator>Gur, Raquel E.</dc:creator>
 <dc:creator>Pasqualetti, Fabio</dc:creator>
 <dc:creator>Satterthwaite, Theodore D.</dc:creator>
 <dc:creator>Bassett, Danielle S.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Executive function emerges late in development and displays different
developmental trends in males and females. Sex differences in executive
function in youth have been linked to vulnerability to psychopathology as well
as to behaviors that impinge on health. Yet, the neurobiological basis of these
differences is not well understood. Here we test the hypothesis that sex
differences in executive function in youth stem from sex differences in the
controllability of structural brain networks as they rewire over development.
Combining methods from network neuroscience and network control theory, we
characterize the network control properties of structural brain networks
estimated from diffusion imaging data acquired in males and females in a sample
of 882 youth aged 8-22 years. We summarize the control properties of these
networks by estimating average and modal controllability, two statistics that
probe the ease with which brain areas can drive the network towards easy-
versus difficult-to-reach states. We find that females have higher modal
controllability in frontal, parietal, and subcortical regions while males have
higher average controllability in frontal and subcortical regions. Furthermore,
average controllability values in the medial frontal cortex and subcortex, both
higher in males, are negatively related to executive function. Finally, we find
that average controllability predicts sex-dependent individual differences in
activation during an n-back working memory task. Taken together, our findings
support the notion that sex differences in the controllability of structural
brain networks can partially explain sex differences in executive function.
Controllability of structural brain networks also predicts features of
task-relevant activation, suggesting the potential for controllability to
represent context-specific constraints on network state more generally.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04624</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Stratified Graph Sampling Algorithms based on Approximate
  Degree Distribution</dc:title>
 <dc:creator>Zhu, Junpeng</dc:creator>
 <dc:creator>Li, Hui</dc:creator>
 <dc:creator>Chen, Mei</dc:creator>
 <dc:creator>Dai, Zhenyu</dc:creator>
 <dc:creator>Zhu, Ming</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>91D30</dc:subject>
 <dc:description>  Sampling technique has become one of the recent research focuses in the
graph-related fields. Most of the existing graph sampling algorithms tend to
sample the high degree or low degree nodes in the complex networks because of
the characteristic of scale-free. Scale-free means that degrees of different
nodes are subject to a power law distribution. So, there is a significant
difference in the degrees between the overall sampling nodes. In this paper, we
propose an idea of approximate degree distribution and devise a stratified
strategy using it in the complex networks. We also develop two graph sampling
algorithms combining the node selection method with the stratified strategy.
The experimental results show that our sampling algorithms preserve several
properties of different graphs and behave more accurately than other
algorithms. Further, we prove the proposed algorithms are superior to the
off-the-shelf algorithms in terms of the unbiasedness of the degrees and more
efficient than state-of-the-art FFS and ES-i algorithms.
</dc:description>
 <dc:description>Comment: 10 pages, 23 figures, master paper</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04638</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pointlike sets for varieties determined by groups</dc:title>
 <dc:creator>Gool, Samuel J. v.</dc:creator>
 <dc:creator>Steinberg, B.</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>20M07, 20M35</dc:subject>
 <dc:description>  For a variety of finite groups $\mathbf H$, let $\overline{\mathbf H}$ denote
the variety of finite semigroups all of whose subgroups lie in $\mathbf H$. We
give a characterization of the subsets of a finite semigroup that are pointlike
with respect to $\overline{\mathbf H}$. Our characterization is effective
whenever $\mathbf H$ has a decidable membership problem. In particular, the
separation problem for $\overline{\mathbf H}$-languages is decidable for any
decidable variety of finite groups $\mathbf H$. This generalizes Henckell's
theorem on decidability of aperiodic pointlikes.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04639</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Elementary Dyadic Riemann Hypothesis</dc:title>
 <dc:creator>Knill, Oliver</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:subject>05Exx, 58J50, 15A36</dc:subject>
 <dc:description>  The connection zeta function of a finite abstract simplicial complex G is
defined as zeta_L(s)=sum_x 1/lambda_x^s, where lambda_x are the eigenvalues of
the connection Laplacian L defined by L(x,y)=1 if x and y intersect and 0 else.
(I) As a consequence of the spectral formula chi(G)=sum_x (-1)^dim(x) =
p(G)-n(G), where p(G) is the number of positive eigenvalues and n(G) is the
number of negative eigenvalues of L, both the Euler characteristic
chi(G)=zeta(0)-2 i zeta'(0)/pi as well as determinant det(L)=e^zeta'(0)/pi can
be written in terms of zeta. (II) As a consequence of the generalized
Cauchy-Binet formula for the coefficients of the characteristic polynomials of
a product of matrices we show that for every one-dimensional simplicial complex
G, the functional equation zeta(s)=zeta(-s) holds, where zeta(s) is the Zeta
function of the positive definite squared connection operator L^2 of G.
Equivalently, the spectrum sigma of the integer matrix L^2 for a 1-dimensional
complex always satisfies the symmetry sigma = 1/sigma and the characteristic
polynomial of L^2 is palindromic. The functional equation extends to products
of one-dimensional complexes. (III) Explicit expressions for the spectrum of
circular connection Laplacian lead to an explicit entire zeta function in the
Barycentric limit. The situation is simpler than in the Hodge Laplacian H=D^2
case where no functional equation was available. In the connection Laplacian
case, the limiting zeta function is a generalized hypergeometric function which
for an integer s is given by an elliptic integral over the real elliptic curve
w^2=(1+z)(1-z)(z^2-4z-1), which has the analytic involutive symmetry (z,w) to
(1/z,w/z^2).
</dc:description>
 <dc:description>Comment: 37 pages, 12 figures</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04641</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategies for Stable Merge Sorting</dc:title>
 <dc:creator>Buss, Sam</dc:creator>
 <dc:creator>Knop, Alexander</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We introduce new stable, natural merge sort algorithms, called 2-merge sort
and $\alpha$-merge sort. We prove upper and lower bounds for several merge sort
algorithms, including Timsort, Shiver's sort, $\alpha$-stack sorts, and our new
2-merge and $\alpha$-merge sorts. The upper and lower bounds have the forms $c
\cdot n \log m$ and $c \cdot n \log n$ for inputs of length $n$ comprising $m$
runs. For Timsort, we prove a lower bound of $ (1.5 - o(1)) n \log n $. For
2-merge sort, we prove optimal upper and lower bounds of approximately $ (1.089
\pm o(1))n \log m $. We prove similar asymptotically matching upper and lower
bounds for $\alpha$-merge sort, when $\varphi &lt; \alpha &lt; 2$, where $\varphi$ is
the golden ratio. These merge strategies can be used for any stable merge sort,
not just natural merge sorts.
  The new 2-merge and $\alpha$-merge sorts have better worst-case merge cost
upper bounds and are slightly simpler to implement than the widely-used
Timsort; they also perform better in experiments.
</dc:description>
 <dc:description>Comment: 34 pages, 4 figures</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04642</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable and Efficient Structures for the Content Production and
  Consumption in Information Communities</dc:title>
 <dc:creator>Zhang, Larry Yueli</dc:creator>
 <dc:creator>Marbach, Peter</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Real-world information communities exhibit inherent structures that
characterize a system that is stable and efficient for content production and
consumption. In this paper, we study such structures through mathematical
modelling and analysis. We formulate a generic model of a community in which
each member decides how they allocate their time between content production and
consumption with the objective of maximizing their individual reward. We define
the community system as &quot;stable and efficient&quot; when a Nash equilibrium is
reached while the social welfare of the community is maximized. We investigate
the conditions for forming a stable and efficient community under two
variations of the model representing different internal relational structures
of the community. Our analysis results show that the structure with &quot;a small
core of celebrity producers&quot; is the optimally stable and efficient for a
community. These analysis results provide possible explanations to the
sociological observations such as &quot;the Law of the Few&quot; and also provide
insights into how to effectively build and maintain the structure of
information communities.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04644</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Method for Uncertainty Propagation in Robust Software
  Performance Estimation</dc:title>
 <dc:creator>Aleti, Aldeida</dc:creator>
 <dc:creator>Trubiani, Catia</dc:creator>
 <dc:creator>van Hoorn, Andr&#xe9;</dc:creator>
 <dc:creator>Jamshidi, Pooyan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software engineers often have to estimate the performance of a software
system before having full knowledge of the system parameters, such as workload
and operational profile. These uncertain parameters inevitably affect the
accuracy of quality evaluations, and the ability to judge if the system can
continue to fulfil performance requirements if parameter results are different
from expected. Previous work has addressed this problem by modelling the
potential values of uncertain parameters as probability distribution functions,
and estimating the robustness of the system using Monte Carlo-based methods.
These approaches require a large number of samples, which results in high
computational cost and long waiting times.
  To address the computational inefficiency of existing approaches, we employ
Polynomial Chaos Expansion (PCE) as a rigorous method for uncertainty
propagation and further extend its use to robust performance estimation. The
aim is to assess if the software system is robust, i.e., it can withstand
possible changes in parameter values, and continue to meet performance
requirements. PCE is a very efficient technique, and requires significantly
less computations to accurately estimate the distribution of performance
indices. Through three very different case studies from different phases of
software development and heterogeneous application domains, we show that PCE
can accurately (&gt;97\%) estimate the robustness of various performance indices,
and saves up to 225 hours of performance evaluation time when compared to Monte
Carlo Simulation.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04644</dc:identifier>
 <dc:identifier>doi:10.1016/j.jss.2018.01.010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04650</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Orthogonal Multiple Access For Cooperative Communications:
  Challenges, Opportunities, And Trends</dc:title>
 <dc:creator>Wan, Dehuan</dc:creator>
 <dc:creator>Wen, Miaowen</dc:creator>
 <dc:creator>Ji, Fei</dc:creator>
 <dc:creator>Yu, Hua</dc:creator>
 <dc:creator>Chen, Fangjiong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Non-orthogonal multiple access (NOMA) is a promising radio access technique
for next-generation wireless networks. In this article, we investigate the
NOMA-based cooperative relay network. We begin with an introduction of the
existing relay-assisted NOMA systems by classifying them into three categories:
uplink, downlink, and composite architectures. Then, we discuss their
principles and key features, and provide a comprehensive comparison from the
perspective of spectral efficiency, energy efficiency, and total transmit
power. A novel strategy termed hybrid power allocation is further discussed for
the composite architecture, which can reduce the computational complexity and
signaling overhead at the expense of marginal sum rate degradation. Finally,
major challenges, opportunities, and future research trends for the design of
NOMA-based cooperative relay systems with other techniques are also highlighted
to provide insights for researchers in this field.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04651</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Net Triage: Assessing the Criticality of Network Layers by
  Structural Compression</dc:title>
 <dc:creator>Nowak, Theodore S.</dc:creator>
 <dc:creator>Corso, Jason J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep network compression seeks to reduce the number of parameters in the
network while maintaining a certain level of performance. Deep network
distillation seeks to train a smaller network that matches soft-max performance
of a larger network. While both regimes have led to impressive performance for
their respective goals, neither provide insight into the importance of a given
layer in the original model, which is useful if we are to improve our
understanding of these highly parameterized models. In this paper, we present
the concept of deep net triage, which individually assesses small blocks of
convolution layers to understand their collective contribution to the overall
performance, which we call criticality. We call it triage because we assess
this criticality by answering the question: what is the impact to the health of
the overall network if we compress a block of layers into a single layer. We
propose a suite of triage methods and compare them on problem spaces of varying
complexity. We ultimately show that, across these problem spaces, deep net
triage is able to indicate the of relative importance of different layers.
Surprisingly, our local structural compression technique also leads to an
improvement in overall accuracy when the final model is fine-tuned globally.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04654</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperspectral recovery from RGB images using Gaussian Processes</dc:title>
 <dc:creator>Akhtar, Naveed</dc:creator>
 <dc:creator>Mian, Ajmal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hyperspectral cameras preserve the fine spectral details of scenes that are
generally lost in the traditional RGB cameras due to the gross quantization of
radiance. These details are desirable in numerous imaging applications,
nevertheless the high cost of hyperspectral hardware and the associated
physical constraints currently limit the pervasive use of hyperspectral
imaging. We take a computational approach to construct hyperspectral images
using the RGB cameras of known spectral response, and assuming a prior over the
imaged scene. Our approach first clusters training hyperspectral image patches
and infers a set of Gaussian Processes~(GPs) to represent the naturally smooth
reflectance spectra of materials in each cluster. The GPs and the clusters are
then transformed to match the spectral quantization of the RGB camera. A patch
from the test RGB image is assigned a matching cluster and it is represented by
the transformed GPs for that cluster. The computed representation codes are
combined with the original GPs to construct the desired hyperspectral
signatures. The approach infers the Gaussian Processes using a model inspired
by the Beta-Bernoulli Process and it encourages those to be non-negative to
better approximate the positive reflectance values. We present the analytical
expressions for the Bayesian inference over the proposed model. Thorough
evaluation using three hyperspectral datasets demonstrates the effectiveness of
the proposed technique.
</dc:description>
 <dc:description>Comment: submitted to a journal</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04655</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Control for Harmonic Utility in Non-Orthogonal Multiple Access
  based Visible Light Communications</dc:title>
 <dc:creator>Pham, Quoc-Viet</dc:creator>
 <dc:creator>Hon, Choong Seon</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Visible light communication is a promising technique in future networks due
to its advantages of high data rate and licensed-free spectrum. In addition,
non-orthogonal multiple access (NOMA) is considered as a candidate of multiple
access schemes in 5G networks and beyond. In this paper, we study the power
control problem in NOMA-based visible light communication. An optimization
problem is formulated, where the objective is the harmonic-rate utility
function. The optimal solution is achieved optimally by equivalently
transforming the underlying problem into a convex problem. Simulation result is
provided to validate performance of the proposed approach.
</dc:description>
 <dc:description>Comment: Presented at Korea Software Congress 2017</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04658</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Geometric Approach to Bayesian Lower Error Bounds</dc:title>
 <dc:creator>Kumar, M. Ashok</dc:creator>
 <dc:creator>Mishra, Kumar Vijay</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Information geometry describes a framework where probability densities can be
viewed as differential geometry structures. This approach has shown that the
geometry in the space of probability distributions that are parameterized by
their covariance matrix is linked to the fundamentals concepts of estimation
theory. In particular, prior work proposes a Riemannian metric - the distance
between the parameterized probability distributions - that is equivalent to the
Fisher Information Matrix, and helpful in obtaining the deterministic
Cram\'{e}r-Rao lower bound (CRLB). Recent work in this framework has led to
establishing links with several practical applications. However, classical CRLB
is useful only for unbiased estimators and inaccurately predicts the mean
square error in low signal-to-noise (SNR) scenarios. In this paper, we propose
a general Riemannian metric that, at once, is used to obtain both Bayesian CRLB
and deterministic CRLB along with their vector parameter extensions. We also
extend our results to the Barankin bound, thereby enhancing their applicability
to low SNR situations.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04662</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Trimmed Convolutional Arithmetic Encoding for Lossless Image
  Compression</dc:title>
 <dc:creator>Li, Mu</dc:creator>
 <dc:creator>Gu, Shuhang</dc:creator>
 <dc:creator>Zhang, David</dc:creator>
 <dc:creator>Zuo, Wangmeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Arithmetic encoding is an essential class of coding techniques which have
been widely used in various data compression systems and exhibited promising
performance. One key issue of arithmetic encoding method is to predict the
probability of the current symbol to be encoded from its context, i.e., the
preceding encoded symbols, which usually can be executed by building a look-up
table (LUT). However, the complexity of LUT increases exponentially with the
length of context. Thus, such solutions are limited in modeling large context,
which inevitably restricts the compression performance. Several recent
convolutional neural network (CNN) and recurrent neural network (RNN)-based
solutions have been developed to account for large context, but are still
costly in computation. The inefficiency of the existing methods are mainly
attributed to that probability prediction is performed independently for the
neighboring symbols, which actually can be efficiently conducted by shared
computation. To this end, we propose a trimmed convolutional network for
arithmetic encoding (TCAE) to model large context while maintaining
computational efficiency. As for trimmed convolution, the convolutional kernels
are specially trimmed to respect the compression order and context dependency
of the input symbols. Benefited from trimmed convolution, the probability
prediction of all symbols can be efficiently performed in one single forward
pass via a fully convolutional network. Experiments show that our TCAE attains
better compression ratio in lossless gray image compression, and can be adopted
in CNN-based lossy image compression to achieve state-of-the-art
rate-distortion performance with real-time encoding speed.
</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04668</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The decoding failure probability of MDPC codes</dc:title>
 <dc:creator>Tillich, Jean-Pierre</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Moderate Density Parity Check (MDPC) codes are defined here as codes which
have a parity-check matrix whose row weight is $O(\sqrt{n})$ where $n$ is the
length $n$ of the code. They can be decoded like LDPC codes but they decode
much less errors than LDPC codes: the number of errors they can decode in this
case is of order $\Theta(\sqrt{n})$. Despite this fact they have been proved
very useful in cryptography for devising key exchange mechanisms. They have
also been proposed in McEliece type cryptosystems. However in this case, the
parameters that have been proposed in \cite{MTSB13} were broken in
\cite{GJS16}. This attack exploits the fact that the decoding failure
probability is non-negligible. We show here that this attack can be thwarted by
choosing the parameters in a more conservative way. We first show that such
codes can decode with a simple bit-flipping decoder any pattern of
$O\left(\frac{\sqrt{n} \log \log n}{\log n}\right)$ errors. This avoids the
previous attack at the cost of significantly increasing the key size of the
scheme. We then show that under a very reasonable assumption the decoding
failure probability decays almost exponentially with the codelength with just
two iterations of bit-flipping. With an additional assumption it has even been
proved that it decays exponentially with an unbounded number of iterations and
we show that in this case the increase of the key size which is required for
resisting to the attack of \cite{GJS16} is only moderate.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04669</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fault-Tolerant Hotelling Games</dc:title>
 <dc:creator>Avin, Chen</dc:creator>
 <dc:creator>Cohen, Avi</dc:creator>
 <dc:creator>Lotker, Zvi</dc:creator>
 <dc:creator>Peleg, David</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The $n$-player Hotelling game calls for each player to choose a point on the
line segment, so as to maximize the size of his Voronoi cell. This paper
studies fault-tolerant versions of the Hotelling game. Two fault models are
studied: line faults and player faults. The first model assumes that the
environment is prone to failure: with some probability, a disconnection occurs
at a random point on the line, splitting it into two separate segments and
modifying each player's Voronoi cell accordingly. A complete characterization
of the Nash equilibria of this variant is provided for every $n$. Additionally,
a one to one correspondence is shown between equilibria of this variant and of
the Hotelling game with no faults. The second fault model assumes the players
are prone to failure: each player is removed from the game with i.i.d.
probability, changing the payoffs of the remaining players accordingly. It is
shown that for $n \geq 3$ this variant of the game has no Nash equilibria.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04678</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Bias Correction for Lidar-only Motion Estimation</dc:title>
 <dc:creator>Tang, Tim Y.</dc:creator>
 <dc:creator>Yoon, David J.</dc:creator>
 <dc:creator>Pomerleau, Fran&#xe7;ois</dc:creator>
 <dc:creator>Barfoot, Timothy D.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a novel technique to correct for bias in a classical
estimator using a learning approach. We apply a learned bias correction to a
lidar-only motion estimation pipeline. Our technique trains a Gaussian process
(GP) regression model using data with ground truth. The inputs to the model are
high-level features derived from the geometry of the point-clouds, and the
outputs are the predicted biases between poses computed by the estimator and
the ground truth. The predicted biases are applied as a correction to the poses
computed by the estimator.
  Our technique is evaluated on over 50km of lidar data, which includes the
KITTI odometry benchmark and lidar datasets collected around the University of
Toronto campus. After applying the learned bias correction, we obtained
significant improvements to lidar odometry in all datasets tested. We achieved
around 10% reduction in errors on all datasets from an already accurate lidar
odometry algorithm, at the expense of only less than 1% increase in
computational cost at run-time.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04686</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Coding for Distributed Computing</dc:title>
 <dc:creator>Park, Hyegyeong</dc:creator>
 <dc:creator>Lee, Kangwook</dc:creator>
 <dc:creator>Sohn, Jy-yong</dc:creator>
 <dc:creator>Suh, Changho</dc:creator>
 <dc:creator>Moon, Jaekyun</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Coding for distributed computing supports low-latency computation by
relieving the burden of straggling workers. While most existing works assume a
simple master-worker model, we consider a hierarchical computational structure
consisting of groups of workers, motivated by the need to reflect the
architectures of real-world distributed computing systems. In this work, we
propose a hierarchical coding scheme for this model, as well as analyze its
decoding cost and expected computation time. Specifically, we first provide
upper and lower bounds on the expected computing time of the proposed scheme.
We also show that our scheme enables efficient parallel decoding, thus reducing
decoding costs by orders of magnitude over non-hierarchical schemes. When
considering both decoding cost and computing time, the proposed hierarchical
coding is shown to outperform existing schemes in many practical scenarios.
</dc:description>
 <dc:description>Comment: 7 pages, part of the paper is submitted to ISIT2018</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04693</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Imperceptible and Robust Adversarial Example Attacks against
  Neural Networks</dc:title>
 <dc:creator>Luo, Bo</dc:creator>
 <dc:creator>Liu, Yannan</dc:creator>
 <dc:creator>Wei, Lingxiao</dc:creator>
 <dc:creator>Xu, Qiang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Machine learning systems based on deep neural networks, being able to produce
state-of-the-art results on various perception tasks, have gained mainstream
adoption in many applications. However, they are shown to be vulnerable to
adversarial example attack, which generates malicious output by adding slight
perturbations to the input. Previous adversarial example crafting methods,
however, use simple metrics to evaluate the distances between the original
examples and the adversarial ones, which could be easily detected by human
eyes. In addition, these attacks are often not robust due to the inevitable
noises and deviation in the physical world. In this work, we present a new
adversarial example attack crafting method, which takes the human perceptual
system into consideration and maximizes the noise tolerance of the crafted
adversarial example. Experimental results demonstrate the efficacy of the
proposed technique.
</dc:description>
 <dc:description>Comment: Adversarial example attacks, Robust and Imperceptible, Human
  perceptual system, Neural Networks</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04695</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparsity-based Defense against Adversarial Attacks on Linear Classifiers</dc:title>
 <dc:creator>Marzi, Zhinus</dc:creator>
 <dc:creator>Gopalakrishnan, Soorya</dc:creator>
 <dc:creator>Madhow, Upamanyu</dc:creator>
 <dc:creator>Pedarsani, Ramtin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks represent the state of the art in machine learning in a
growing number of fields, including vision, speech and natural language
processing. However, recent work raises important questions about the
robustness of such architectures, by showing that it is possible to induce
classification errors through tiny, almost imperceptible, perturbations.
Vulnerability to such &quot;adversarial attacks&quot;, or &quot;adversarial examples&quot;, has
been conjectured to be due to the excessive linearity of deep networks. In this
paper, we study this phenomenon in the setting of a linear classifier, and show
that it is possible to exploit sparsity in natural data to combat
$\ell_{\infty}$-bounded adversarial perturbations. Specifically, we demonstrate
the efficacy of a sparsifying front end via an ensemble averaged analysis, and
experimental results for the MNIST handwritten digit database. To the best of
our knowledge, this is the first work to provide a theoretically rigorous
framework for defense against adversarial attacks.
</dc:description>
 <dc:description>Comment: Submitted to IEEE International Symposium on Information Theory
  (ISIT) 2018. ZM and SG are joint first authors</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04696</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust capacitated trees and networks with uniform demands</dc:title>
 <dc:creator>Bentz, C&#xe9;dric</dc:creator>
 <dc:creator>Costa, Marie-Christine</dc:creator>
 <dc:creator>Poirion, Pierre-Louis</dc:creator>
 <dc:creator>Ridremont, Thomas</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We are interested in the design of robust (or resilient) capacitated rooted
Steiner networks in case of terminals with uniform demands. Formally, we are
given a graph, capacity and cost functions on the edges, a root, a subset of
nodes called terminals, and a bound k on the number of edge failures. We first
study the problem where k = 1 and the network that we want to design must be a
tree covering the root and the terminals: we give complexity results and
propose models to optimize both the cost of the tree and the number of
terminals disconnected from the root in the worst case of an edge failure,
while respecting the capacity constraints on the edges. Second, we consider the
problem of computing a minimum-cost survivable network, i.e., a network that
covers the root and terminals even after the removal of any k edges, while
still respecting the capacity constraints on the edges. We also consider the
possibility of protecting a given number of edges. We propose three different
formulations: a cut-set based formulation, a flow based one, and a bilevel one
(with an attacker and a defender). We propose algorithms to solve each
formulation and compare their efficiency.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04701</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>tau-FPL: Tolerance-Constrained Learning in Linear Time</dc:title>
 <dc:creator>Zhang, Ao</dc:creator>
 <dc:creator>Li, Nan</dc:creator>
 <dc:creator>Pu, Jian</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:creator>Yan, Junchi</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning a classifier with control on the false-positive rate plays a
critical role in many machine learning applications. Existing approaches either
introduce prior knowledge dependent label cost or tune parameters based on
traditional classifiers, which lack consistency in methodology because they do
not strictly adhere to the false-positive rate constraint. In this paper, we
propose a novel scoring-thresholding approach, tau-False Positive Learning
(tau-FPL) to address this problem. We show the scoring problem which takes the
false-positive rate tolerance into accounts can be efficiently solved in linear
time, also an out-of-bootstrap thresholding method can transform the learned
ranking function into a low false-positive classifier. Both theoretical
analysis and experimental results show superior performance of the proposed
tau-FPL over existing approaches.
</dc:description>
 <dc:description>Comment: 32 pages, 3 figures. This is an extended version of our paper
  published in AAAI-18</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04702</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Searching for Maximum Out-Degree Vertices in Tournaments</dc:title>
 <dc:creator>Gutin, Gregory</dc:creator>
 <dc:creator>Mertzios, George B.</dc:creator>
 <dc:creator>Reidl, Felix</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A vertex $x$ in a tournament $T$ is called a king if for every vertex $y$ of
$T$ there is a directed path from $x$ to $y$ of length at most 2. It is not
hard to show that every vertex of maximum out-degree in a tournament is a king.
However, tournaments may have kings which are not vertices of maximum
out-degree. A binary inquiry asks for the orientation of the edge between a
pair of vertices and receives the answer. The cost of finding a king in an
unknown tournament is the number of binary inquiries required to detect a king.
For the cost of finding a king in a tournament, in the worst case, Shen, Sheng
and Wu (SIAM J. Comput., 2003) proved a lower and upper bounds of
$\Omega(n^{4/3})$ and $O(n^{3/2})$, respectively. In contrast to their result,
we prove that the cost of finding a vertex of maximum out-degree is ${n \choose
2} -O(n)$ in the worst case.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04703</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attack Potential in Impact and Complexity</dc:title>
 <dc:creator>Allodi, Luca</dc:creator>
 <dc:creator>Massacci, Fabio</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Vulnerability exploitation is reportedly one of the main attack vectors
against computer systems. Yet, most vulnerabilities remain unexploited by
attackers. It is therefore of central importance to identify vulnerabilities
that carry a high `potential for attack'. In this paper we rely on Symantec
data on real attacks detected in the wild to identify a trade-off in the Impact
and Complexity of a vulnerability, in terms of attacks that it generates;
exploiting this effect, we devise a readily computable estimator of the
vulnerability's Attack Potential that reliably estimates the expected volume of
attacks against the vulnerability. We evaluate our estimator performance
against standard patching policies by measuring foiled attacks and demanded
workload expressed as the number of vulnerabilities entailed to patch. We show
that our estimator significantly improves over standard patching policies by
ruling out low-risk vulnerabilities, while maintaining invariant levels of
coverage against attacks in the wild. Our estimator can be used as a first aid
for vulnerability prioritisation to focus assessment efforts on high-potential
vulnerabilities.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04703</dc:identifier>
 <dc:identifier>Proceedings of the 12th International Conference on Availability,
  Reliability and Security (ARES 2017)</dc:identifier>
 <dc:identifier>doi:10.1145/3098954.3098965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04705</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distribution System Monitoring for Smart Power Grids with Distributed
  Generation Using Artificial Neural Networks</dc:title>
 <dc:creator>Menke, Jan-Hendrik</dc:creator>
 <dc:creator>Bornhorst, Nils</dc:creator>
 <dc:creator>Braun, Martin</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The increasing number of distributed generators connected to the distribution
system at the low and medium voltage level requires a reliable monitoring of
distribution grids. Economic considerations prevent a full observation of
distribution grids with direct measurements. First state-of-the-art approaches
using artificial neural networks (ANN) for monitoring distribution grids with a
limited amount of measurements exist. These approaches, however, have strong
limitations. We develop a new solution for distribution system monitoring
overcoming these limitations by 1. presenting a novel training procedure for
the ANN, enabling its use in distribution grids with a high amount of
distributed generation and a very limited amount of measurements, far less than
is traditionally required by the state-of-the-art Weighted Least Squares (WLS)
state estimation (SE), 2. using mutliple hidden layers in the ANN, increasing
the estimation accuracy, 3. including switch statuses as inputs to the ANN,
eliminating the need for individual ANN for each switching state, 4. estimating
line current magnitudes additionally to voltage magnitudes. Simulations
performed with an elaborate evaluation approach on a real and a benchmark grid
demonstrate that the proposed ANN scheme clearly outperforms state-of-the-art
ANN schemes and WLS SE under normal operating conditions and different
situations such as gross measurement errors.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, 4 tables, preprint</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04720</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Stereo Disparity and Optical Flow for Basic Scene Flow</dc:title>
 <dc:creator>Schuster, Ren&#xe9;</dc:creator>
 <dc:creator>Bailer, Christian</dc:creator>
 <dc:creator>Wasenm&#xfc;ller, Oliver</dc:creator>
 <dc:creator>Stricker, Didier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scene flow is a description of real world motion in 3D that contains more
information than optical flow. Because of its complexity there exists no
applicable variant for real-time scene flow estimation in an automotive or
commercial vehicle context that is sufficiently robust and accurate. Therefore,
many applications estimate the 2D optical flow instead. In this paper, we
examine the combination of top-performing state-of-the-art optical flow and
stereo disparity algorithms in order to achieve a basic scene flow. On the
public KITTI Scene Flow Benchmark we demonstrate the reasonable accuracy of the
combination approach and show its speed in computation.
</dc:description>
 <dc:description>Comment: Commercial Vehicle Technology Symposium (CVTS), 2018</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04723</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPIN: A Fast and Scalable Matrix Inversion Method in Apache Spark</dc:title>
 <dc:creator>Misra, Chandan</dc:creator>
 <dc:creator>Bhattacharya, Sourangshu</dc:creator>
 <dc:creator>Ghosh, Soumya K.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The growth of big data in domains such as Earth Sciences, Social Networks,
Physical Sciences, etc. has lead to an immense need for efficient and scalable
linear algebra operations, e.g. Matrix inversion. Existing methods for
efficient and distributed matrix inversion using big data platforms rely on LU
decomposition based block-recursive algorithms. However, these algorithms are
complex and require a lot of side calculations, e.g. matrix multiplication, at
various levels of recursion. In this paper, we propose a different scheme based
on Strassen's matrix inversion algorithm (mentioned in Strassen's original
paper in 1969), which uses far fewer operations at each level of recursion. We
implement the proposed algorithm, and through extensive experimentation, show
that it is more efficient than the state of the art methods. Furthermore, we
provide a detailed theoretical analysis of the proposed algorithm, and derive
theoretical running times which match closely with the empirically observed
wall clock running times, thus explaining the U-shaped behaviour w.r.t.
block-sizes.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04725</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure k-NN as a Service Over Encrypted Data in Multi-User Setting</dc:title>
 <dc:creator>Singh, Gagandeep</dc:creator>
 <dc:creator>Kaul, Akshar</dc:creator>
 <dc:creator>Mehta, Sameep</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  To securely leverage the advantages of Cloud Computing, recently a lot of
research has happened in the area of &quot;Secure Query Processing over Encrypted
Data&quot;. As a concrete use case, many encryption schemes have been proposed for
securely processing k Nearest Neighbors (SkNN) over encrypted data in the
outsourced setting. Recently Zhu et al[25]. proposed a SkNN solution which
claimed to satisfy following four properties: (1)Data Privacy, (2)Key
Confidentiality, (3)Query Privacy, and (4)Query Controllability. However, in
this paper, we present an attack which breaks the Query Controllability claim
of their scheme. Further, we propose a new SkNN solution which satisfies all
the four existing properties along with an additional essential property of
Query Check Verification. We analyze the security of our proposed scheme and
present the detailed experimental results to showcase the efficiency in real
world scenario.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04726</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Interpretable Reasoning Network for Multi-Relation Question Answering</dc:title>
 <dc:creator>Zhou, Mantong</dc:creator>
 <dc:creator>Huang, Minlie</dc:creator>
 <dc:creator>Zhu, Xiaoyan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Multi-relation Question Answering is a challenging task, due to the
requirement of elaborated analysis on questions and reasoning over multiple
fact triples in knowledge base. In this paper, we present a novel model called
Interpretable Reasoning Network that employs an interpretable, hop-by-hop
reasoning process for question answering. The model dynamically decides which
part of an input question should be analyzed at each hop; predicts a relation
that corresponds to the current parsed results; utilizes the predicted relation
to update the question representation and the state of the reasoning process;
and then drives the next-hop reasoning. Experiments show that our model yields
state-of-the-art results on two datasets. More interestingly, the model can
offer traceable and observable intermediate predictions for reasoning analysis
and failure diagnosis.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04728</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Communication-Hiding Conjugate Gradient Method with Deep Pipelines</dc:title>
 <dc:creator>Cornelis, Jeffrey</dc:creator>
 <dc:creator>Cools, Siegfried</dc:creator>
 <dc:creator>Vanroose, Wim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>65F10</dc:subject>
 <dc:description>  Krylov subspace methods are among the most efficient present-day solvers for
large scale linear algebra problems. Nevertheless, classic Krylov subspace
method algorithms do not scale well on massively parallel hardware due to the
synchronization bottlenecks induced by the computation of dot products
throughout the algorithms. Communication-hiding pipelined Krylov subspace
methods offer increased parallel scalability. One of the first published
methods in this class is the pipelined Conjugate Gradient method (p-CG), which
exhibits increased speedups on parallel machines. This is achieved by
overlapping the time-consuming global communication phase with useful
(independent) computations such as spmvs, hence reducing the impact of global
communication as a synchronization bottleneck and avoiding excessive processor
idling. However, on large numbers of processors the time spent in the global
communication phase can be much higher than the time required for computing a
single spmv. This work extends the pipelined CG method to deeper pipelines,
which allows further scaling when the global communication phase is the
dominant time-consuming factor. By overlapping the global all-to-all reduction
phase in each CG iteration with the next l spmvs (pipelining), the method is
able to hide communication latency behind computational work. The derivation of
the p(l)-CG algorithm is based on the existing p(l)-GMRES method. Moreover, a
number of theoretical and implementation properties of the p(l)-CG method are
presented, including a preconditioned version of the algorithm. Experimental
results are presented to demonstrate the possible performance gains of using
deeper pipelines for solving large scale symmetric linear systems with the new
CG method variant.
</dc:description>
 <dc:description>Comment: 25 pages, 8 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04734</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full Wafer Redistribution and Wafer Embedding as Key Technologies for a
  Multi-Scale Neuromorphic Hardware Cluster</dc:title>
 <dc:creator>Zoschke, Kai</dc:creator>
 <dc:creator>G&#xfc;ttler, Maurice</dc:creator>
 <dc:creator>B&#xf6;ttcher, Lars</dc:creator>
 <dc:creator>Gr&#xfc;bl, Andreas</dc:creator>
 <dc:creator>Husmann, Dan</dc:creator>
 <dc:creator>Schemmel, Johannes</dc:creator>
 <dc:creator>Meier, Karlheinz</dc:creator>
 <dc:creator>Ehrmann, Oswin</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Together with the Kirchhoff-Institute for Physics(KIP) the Fraunhofer IZM has
developed a full wafer redistribution and embedding technology as base for a
large-scale neuromorphic hardware system. The paper will give an overview of
the neuromorphic computing platform at the KIP and the associated hardware
requirements which drove the described technological developments. In the first
phase of the project standard redistribution technologies from wafer level
packaging were adapted to enable a high density reticle-to-reticle routing on
200mm CMOS wafers. Neighboring reticles were interconnected across the scribe
lines with an 8{\mu}m pitch routing based on semi-additive copper
metallization. Passivation by photo sensitive benzocyclobutene was used to
enable a second intra-reticle routing layer. Final IO pads with flash gold were
generated on top of each reticle. With that concept neuromorphic systems based
on full wafers could be assembled and tested. The fabricated high density
inter-reticle routing revealed a very high yield of larger than 99.9%. In order
to allow an upscaling of the system size to a large number of wafers with
feasible effort a full wafer embedding concept for printed circuit boards was
developed and proven in the second phase of the project. The wafers were
thinned to 250{\mu}m and laminated with additional prepreg layers and copper
foils into a core material. After lamination of the PCB panel the reticle IOs
of the embedded wafer were accessed by micro via drilling, copper
electroplating, lithography and subtractive etching of the PCB wiring
structure. The created wiring with 50um line width enabled an access of the
reticle IOs on the embedded wafer as well as a board level routing. The panels
with the embedded wafers were subsequently stressed with up to 1000 thermal
cycles between 0C and 100C and have shown no severe failure formation over the
cycle time.
</dc:description>
 <dc:description>Comment: Accepted at EPTC 2017</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04735</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Adaptive Group Testing</dc:title>
 <dc:creator>Cohen, Alejandro</dc:creator>
 <dc:creator>Cohen, Asaf</dc:creator>
 <dc:creator>Jaggi, Sidharth</dc:creator>
 <dc:creator>Gurewitz, Omer</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Group Testing (GT) addresses the problem of identifying a small subset of
defective items from a large population, by grouping items into as few test
pools as possible. In Adaptive GT (AGT), outcomes of previous tests can
influence the makeup of future tests. This scenario has been studied from an
information theoretic point of view. Aldridge $2012$ showed that in the regime
of a few defectives, adaptivity does not help much, as the number of tests
required for identification of the set of defectives is essentially the same as
for non-adaptive GT.
  Secure GT considers a scenario where there is an eavesdropper who may observe
a fraction $\delta$ of the outcomes, and should not be able to infer the status
of the items. In the non-adaptive scenario, the number of tests required is
$1/(1-\delta)$ times the number of tests without the secrecy constraint.
  In this paper, we consider Secure Adaptive GT. Specifically, when an adaptive
algorithm has access to a private feedback link of rate $R_f$, we prove that
the number of tests required for both correct reconstruction at the legitimate
user, with high probability, and negligible mutual information at the
eavesdropper is $1/min\{1,1-\delta+R_f\}$ times the number of tests required
with no secrecy constraint. Thus, unlike non-secure GT, where an adaptive
algorithm has only a mild impact, under a security constraint it can
significantly boost performance. A key insight is that not only the adaptive
link should disregard test results and send keys, these keys should be enhanced
through a &quot;secret sharing&quot; scheme before usage.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04739</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixing Time on the Kagome Lattice</dc:title>
 <dc:creator>Ugolnikova, Alexandra</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>37A25, 05B45</dc:subject>
 <dc:description>  We consider tilings of a closed region of the Kagome lattice (partition of
the plane into regular hexagons and equilateral triangles such that each edge
is shared by one triangle and one hexagon). We are interested in the rate of
convergence to the stationarity of a natural Markov chain defined on the set of
Kagome tilings. The rate of convergence can be represented by the mixing time
which mesures the amount of time it takes the chain to be close to its
stationary distribution. We obtain a $\mathcal{O}(N^4)$ upper bound on the
mixing time of a weighted version of the natural Markov chain. We also consider
Kagome tilings restrained to two prototiles, prove flip-connectivity and draw a
$\mathcal{O}(N^4)$ upper bound as well on the mixing time of the natural Markov
chain in a general (non weighted) case. Finally, we present simulations that
suggest existence of a long range phenomenon.
</dc:description>
 <dc:description>Comment: 23 pages, 18 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04744</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modified SI Epidemic Model for Combating Virus Spread in Spatially
  Correlated Wireless Sensor Networks</dc:title>
 <dc:creator>Shakya, Rajeev K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  In wireless sensor networks (WSNs), main task of each sensor node is to sense
the physical activity (i.e., targets or disaster conditions) and then to report
it to the control center for further process. For this, sensor nodes are
attached with many sensors having ability to measure the environmental
information. Spatial correlation between nodes exists in such wireless sensor
network based on common sensory coverage and then the redundant data
communication is observed. To study virus spreading dynamics in such scenario,
a modified SI epidemic model is derived mathematically by incorporating WSN
parameters such as spatial correlation, node density, sensing range,
transmission range, total sensor nodes etc. The solution for proposed SI model
is also determined to study the dynamics with time. Initially, a small number
of nodes are attacked by viruses and then virus infection propagates through
its neighboring nodes over normal data communication. Since redundant nodes
exists in correlated sensor field, virus spread process could be different with
different sensory coverage. The proposed SI model captures spatial and temporal
dynamics than existing ones which are global. The infection process leads to
network failure. By exploiting spatial correlation between nodes, spread
control scheme is developed to limit the further infection in the network.
Numerical result analysis is provided with comparison for validation.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04745</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributionally Robust Optimization for Sequential Decision Making</dc:title>
 <dc:creator>Chen, Zhi</dc:creator>
 <dc:creator>Yu, Pengqian</dc:creator>
 <dc:creator>Haskell, William B.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The distributionally robust Markov Decision Process approach has been
proposed in the literature, where the goal is to seek a distributionally robust
policy that achieves the maximal expected total reward under the most
adversarial joint distribution of uncertain parameters. In this paper, we study
distributionally robust MDP where ambiguity sets for uncertain parameters are
of a format that can easily incorporate in its description the uncertainty's
statistical information estimated from historical data. In this way, we
generalize existing works on distributionally robust Markov Decision Process
with generalized-moment-based ambiguity sets and statistical-distance-based
ambiguity sets to incorporate information from the former class such as moments
and dispersions to the latter class that critically depend on samples. We show
that, under this format of ambiguity sets, the resulting distributionally
robust Markov Decision Process remains tractable under mild technical
conditions. To be more specific, a distributionally robust policy can be
constructed by solving a collection of one-stage convex optimization
subproblems.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04747</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Reversible Data Hiding</dc:title>
 <dc:creator>Wu, Hanzhou</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Dong, Jing</dc:creator>
 <dc:creator>Wang, Hongxia</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The conventional reversible data hiding (RDH) algorithms often consider the
host as a whole to embed a payload. In order to achieve satisfactory
rate-distortion performance, the secret bits are embedded into the noise-like
component of the host such as prediction errors. From the rate-distortion view,
it may be not optimal since the data embedding units use the identical
parameters. This motivates us to present a segmented data embedding strategy
for RDH in this paper, in which the raw host could be partitioned into multiple
sub-hosts such that each one can freely optimize and use the embedding
parameters. Moreover, it enables us to apply different RDH algorithms within
different sub-hosts, which is defined as ensemble. Notice that, the ensemble
defined here is different from that in machine learning. Accordingly, the
conventional operation corresponds to a special case of our work. Since it is a
general strategy, we combine some state-of-the-art algorithms to construct a
new system using the proposed embedding strategy to evaluate the
rate-distortion performance. Experimental results have shown that, the ensemble
RDH system outperforms the original versions, which has shown the superiority
and applicability.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04751</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SAR Image Despeckling Using Quadratic-Linear Approximated L1-Norm</dc:title>
 <dc:creator>Nar, Fatih</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Speckle noise, inherent in synthetic aperture radar (SAR) images, degrades
the performance of the various SAR image analysis tasks. Thus, speckle noise
reduction is a critical preprocessing step for smoothing homogeneous regions
while preserving details. This letter proposes a variational despeckling
approach where L1-norm total variation regularization term is approximated in a
quadratic and linear manner to increase accuracy while decreasing the
computation time. Despeckling performance and computational efficiency of the
proposed method are shown using synthetic and real-world SAR images.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04752</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reversible Embedding to Covers Full of Boundaries</dc:title>
 <dc:creator>Wu, Hanzhou</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Dong, Jing</dc:creator>
 <dc:creator>Chen, Yanli</dc:creator>
 <dc:creator>Wang, Hongxia</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In reversible data embedding, to avoid overflow and underflow problem, before
data embedding, boundary pixels are recorded as side information, which may be
losslessly compressed. The existing algorithms often assume that a natural
image has little boundary pixels so that the size of side information is small.
Accordingly, a relatively high pure payload could be achieved. However, there
actually may exist a lot of boundary pixels in a natural image, implying that,
the size of side information could be very large. Therefore, when to directly
use the existing algorithms, the pure embedding capacity may be not sufficient.
In order to address this problem, in this paper, we present a new and efficient
framework to reversible data embedding in images that have lots of boundary
pixels. The core idea is to losslessly preprocess boundary pixels so that it
can significantly reduce the side information. Experimental results have shown
the superiority and applicability of our work.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04756</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semi-Parametric Binning Approach to Quickest Change Detection</dc:title>
 <dc:creator>Lau, Tze Siong</dc:creator>
 <dc:creator>Tay, Wee Peng</dc:creator>
 <dc:creator>Veeravalli, Venugopal V.</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of quickest detection of a change in distribution is considered
under the assumption that the pre-change distribution is known, and the
post-change distribution is only known to belong to a family of distributions
distinguishable from a discretized version of the pre-change distribution. A
sequential change detection procedure is proposed that partitions the sample
space into a finite number of bins, and monitors the number of samples falling
into each of these bins to detect the change. A test statistic that
approximates the generalized likelihood ratio test is developed. It is shown
that the proposed test statistic can be efficiently computed using a recursive
update scheme, and a procedure for choosing the number of bins in the scheme is
provided. Various asymptotic properties of the test statistic are derived to
offer insights into its performance trade-off between average detection delay
and average run length to a false alarm. Testing on synthetic and real data
demonstrates that our approach is comparable or better in performance to
existing non-parametric change detection methods.
</dc:description>
 <dc:description>Comment: Double-column 11-page version sent to IEEE. Transaction on Signal
  Processing. Supplementary material included</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04757</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Distribution of Random Geometric Graphs</dc:title>
 <dc:creator>Badiu, Mihai-Alin</dc:creator>
 <dc:creator>Coon, Justin P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Random geometric graphs (RGGs) are commonly used to model networked systems
that depend on the underlying spatial embedding. We concern ourselves with the
probability distribution of an RGG, which is crucial for studying its random
topology, properties (e.g., connectedness), or Shannon entropy as a measure of
the graph's topological uncertainty (or information content). Moreover, the
distribution is also relevant for determining average network performance or
designing protocols. However, a major impediment in deducing the graph
distribution is that it requires the joint probability distribution of the
$n(n-1)/2$ distances between $n$ nodes randomly distributed in a bounded
domain. As no such result exists in the literature, we make progress by
obtaining the joint distribution of the distances between three nodes confined
in a disk in $\mathbb{R}^2$. This enables the calculation of the probability
distribution and entropy of a three-node graph. For arbitrary $n$, we derive a
series of upper bounds on the graph entropy; in particular, the bound involving
the entropy of a three-node graph is tighter than the existing bound which
assumes distances are independent. Finally, we provide numerical results on
graph connectedness and the tightness of the derived entropy bounds.
</dc:description>
 <dc:description>Comment: submitted to the IEEE International Symposium on Information Theory
  2018</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04761</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tight Converse to the Spectral Resolution Limit via Convex Programming</dc:title>
 <dc:creator>Da Costa, Maxime Ferreira</dc:creator>
 <dc:creator>Dai, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  It is now well understood that convex programming can be used to estimate the
frequency components of a spectrally sparse signal from $m$ uniform temporal
measurements. It is conjectured that a phase transition on the success of the
total-variation regularization occurs when the distance between the spectral
components of the signal to estimate crosses $1/m$. We prove the necessity part
of this conjecture by demonstrating that this regularization can fail whenever
the spectral distance of the signal of interest is asymptotically equal to
$1/m$.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04774</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNA Molecular Storage System: Transferring Digitally Encoded Information
  through Bacterial Nanonetworks</dc:title>
 <dc:creator>Tavella, Federico</dc:creator>
 <dc:creator>Giaretta, Alberto</dc:creator>
 <dc:creator>Dooley-Cullinane, Triona Marie</dc:creator>
 <dc:creator>Conti, Mauro</dc:creator>
 <dc:creator>Coffey, Lee</dc:creator>
 <dc:creator>Balasubramaniam, Sasitharan</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Since the birth of computer and networks, fuelled by pervasive computing and
ubiquitous connectivity, the amount of data stored and transmitted has
exponentially grown through the years. Due to this demand, new solutions for
storing data are needed, and one promising media is the DNA. This storage
solution provides numerous advantages, which includes the ability to store
dense information while achieving long-term stability. However, the question as
how the data can be retrieved from a DNA-based archive, still remains. In this
paper, we aim to address this question by proposing a new storage solution that
relies upon molecular communication, and in particular bacterial nanonetworks.
Our solution allows digitally encoded information to be stored into non-motile
bacteria, which compose an archival architecture of clusters, and to be later
retrieved by engineered motile bacteria, whenever reading operations are
needed. We conducted extensive simulations, in order to determine the
reliability of data retrieval from non-motile storage clusters, placed at
different locations. Aiming to assess the feasibility of our solution, we have
also conducted wet lab experiments that show how bacteria nanonetworks can
effectively retrieve a simple message, such as &quot;Hello World&quot;, by conjugation
with non-motile bacteria, and finally mobilize towards a final point.
</dc:description>
 <dc:description>Comment: 22 pages, 13 figures; removed wrong venue references, reordered
  bibliography accordingly to ACM guidelines</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04775</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two High-performance Schemes of Transmit Antenna Selection for Secure
  Spatial Modulation</dc:title>
 <dc:creator>Shu, Feng</dc:creator>
 <dc:creator>Wang, Zhengwang</dc:creator>
 <dc:creator>Chen, Riqing</dc:creator>
 <dc:creator>Wu, Yongpeng</dc:creator>
 <dc:creator>Wang, Jiangzhou</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  In this paper, a secure spatial modulation (SM) system with artificial noise
(AN)-aided is investigated. To achieve higher secrecy rate (SR) in such a
system, two high-performance schemes of transmit antenna selection (TAS),
leakage-based and maximum secrecy rate (Max-SR), are proposed and a generalized
Euclidean distance-optimized antenna selection (EDAS) method is designed. From
simulation results and analysis, the four TAS schemes have an decreasing order:
Max-SR, leakage-based, generalized EDAS, and random (conventional), in terms of
SR performance. However, the proposed Max-SR method requires the exhaustive
search to achieve the optimal SR performance, thus its complexity is extremely
high as the number of antennas tends to medium and large scale. The proposed
leakage-based method approaches the Max-SR method with much lower complexity.
Thus, it achieves a good balance between complexity and SR performance. In
terms of bit error rate (BER), their performances are in an increasing order:
random, leakage-based, Max-SR, and generalized EDAS.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04783</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subpolynomial trace reconstruction for random strings and arbitrary
  deletion probability</dc:title>
 <dc:creator>Holden, Nina</dc:creator>
 <dc:creator>Pemantle, Robin</dc:creator>
 <dc:creator>Peres, Yuval</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The deletion-insertion channel takes as input a bit string ${\bf
x}\in\{0,1\}^n$, and outputs a string where bits have been deleted and inserted
independently at random. The trace reconstruction problem is to recover $\bf x$
from many independent outputs (called &quot;traces&quot;) of the deletion-insertion
channel applied to $\bf x$. We show that if $\bf x$ is chosen uniformly at
random, then $\exp(O(\log^{1/3}n))$ traces suffice to reconstruct $\bf x$ with
high probability. The earlier upper bounds were $\exp(O(\log^{1/2}n))$ for the
deletion channel with deletion probability less than $1/2$, and
$\exp(O(n^{1/3}))$ for the general case. A key ingredient in our proof is a
two-step alignment procedure where we estimate the location in each trace
corresponding to a given bit of $\bf x$. The alignment is done by viewing the
strings as random walks, and comparing the increments in the walk associated
with the input string and the trace, respectively.
</dc:description>
 <dc:description>Comment: 44 pages, 9 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04801</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating the Incremental Knapsack Problem</dc:title>
 <dc:creator>Della Croce, Federico</dc:creator>
 <dc:creator>Pferschy, Ulrich</dc:creator>
 <dc:creator>Scatamacchia, Rosario</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the 0-1 Incremental Knapsack Problem (IKP) where the capacity
grows over time periods and if an item is placed in the knapsack in a certain
period, it cannot be removed afterwards. The contribution of a packed item in
each time period depends on its profit as well as on a time factor which
reflects the importance of the period in the objective function. The problem
calls for maximizing the weighted sum of the profits over the whole time
horizon. In this work, we provide approximation results for IKP and its
restricted variants. In some results, we rely on Linear Programming (LP) to
derive approximation bounds and show how the proposed LP-based analysis can be
seen as a valid alternative to more formal proof systems. We first manage to
prove the tightness of some approximation ratios of a general purpose algorithm
currently available in the literature and originally applied to a
time-invariant version of the problem. We also devise a Polynomial Time
Approximation Scheme (PTAS) when the input value indicating the number of
periods is considered as a constant. Then, we add the mild and natural
assumption that each item can be packed in the first time period. For this
variant, we discuss different approximation algorithms suited for any number of
time periods and for the special case with two periods.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04803</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New LMRD bounds for constant dimension codes and improved constructions</dc:title>
 <dc:creator>Heinlein, Daniel</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>51E20, 94B65, 05B25</dc:subject>
 <dc:description>  We generalize upper bounds for constant dimension codes containing a lifted
maximum rank distance code first studied by Etzion and Silberstein. The proof
allows to construct several improved codes.
</dc:description>
 <dc:description>Comment: 18 pages, 1 figure, 2 tables, 1 algorithm</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04813</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Movie Genres Based on Plot Summaries</dc:title>
 <dc:creator>Hoang, Quan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This project explores several Machine Learning methods to predict movie
genres based on plot summaries. Naive Bayes, Word2Vec+XGBoost and Recurrent
Neural Networks are used for text classification, while K-binary
transformation, rank method and probabilistic classification with learned
probability threshold are employed for the multi-label problem involved in the
genre tagging task.Experiments with more than 250,000 movies show that
employing the Gated Recurrent Units (GRU) neural networks for the probabilistic
classification with learned probability threshold approach achieves the best
result on the test set. The model attains a Jaccard Index of 50.0%, a F-score
of 0.56, and a hit rate of 80.5%.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04815</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Metric Learning with BIER: Boosting Independent Embeddings Robustly</dc:title>
 <dc:creator>Opitz, Michael</dc:creator>
 <dc:creator>Waltner, Georg</dc:creator>
 <dc:creator>Possegger, Horst</dc:creator>
 <dc:creator>Bischof, Horst</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning similarity functions between image pairs with deep neural networks
yields highly correlated activations of embeddings. In this work, we show how
to improve the robustness of such embeddings by exploiting the independence
within ensembles. To this end, we divide the last embedding layer of a deep
network into an embedding ensemble and formulate training this ensemble as an
online gradient boosting problem. Each learner receives a reweighted training
sample from the previous learners. Further, we propose two loss functions which
increase the diversity in our ensemble. These loss functions can be applied
either for weight initialization or during training. Together, our
contributions leverage large embedding sizes more effectively by significantly
reducing correlation of the embedding and consequently increase retrieval
accuracy of the embedding. Our method works with any differentiable loss
function and does not introduce any additional parameters during test time. We
evaluate our metric learning method on image retrieval tasks and show that it
improves over state-of-the-art methods on the CUB 200-2011, Cars-196, Stanford
Online Products, In-Shop Clothes Retrieval and VehicleID datasets.
</dc:description>
 <dc:description>Comment: Extension to our paper BIER: Boosting Independent Embeddings Robustly
  (ICCV 2017 oral) - submitted to PAMI</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04816</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localizability-Constrained Deployment of Mobile Robotic Networks with
  Noisy Range Measurements</dc:title>
 <dc:creator>Ny, Jerome Le</dc:creator>
 <dc:creator>Chauvi&#xe8;re, Simon</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  When nodes in a mobile network use relative noisy measurements with respect
to their neighbors to estimate their positions, the overall connectivity and
geometry of the measurement network has a critical influence on the achievable
localization accuracy. This paper considers the problem of deploying a mobile
robotic network implementing a cooperative localization scheme based on range
measurements only, while attempting to maintain a network geometry that is
favorable to estimating the robots' positions with high accuracy. The quality
of the network geometry is measured by a &quot;localizability&quot; function serving as
potential field for robot motion planning. This function is built from the
Cram\'er-Rao bound, which provides for a given geometry a lower bound on the
covariance matrix achievable by any unbiased position estimator that the robots
might implement using their relative measurements. We describe gradient
descent-based motion planners for the robots that attempt to optimize or
constrain different variations of the network's localizability function, and
discuss ways of implementing these controllers in a distributed manner.
Finally, the paper also establishes formal connections between our statistical
point of view and maintaining a form of weighted rigidity for the graph
capturing the relative range measurements.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04819</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robots as Powerful Allies for the Study of Embodied Cognition from the
  Bottom Up</dc:title>
 <dc:creator>Hoffmann, Matej</dc:creator>
 <dc:creator>Pfeifer, Rolf</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  A large body of compelling evidence has been accumulated demonstrating that
embodiment - the agent's physical setup, including its shape, materials,
sensors and actuators - is constitutive for any form of cognition and as a
consequence, models of cognition need to be embodied. In contrast to methods
from empirical sciences to study cognition, robots can be freely manipulated
and virtually all key variables of their embodiment and control programs can be
systematically varied. As such, they provide an extremely powerful tool of
investigation. We present a robotic bottom-up or developmental approach,
focusing on three stages: (a) low-level behaviors like walking and reflexes,
(b) learning regularities in sensorimotor spaces, and (c) human-like cognition.
We also show that robotic based research is not only a productive path to
deepening our understanding of cognition, but that robots can strongly benefit
from human-like cognition in order to become more autonomous, robust,
resilient, and safe.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04819</dc:identifier>
 <dc:identifier>2018, The Oxford Handbook 4e Cognition; Albert Newen, Leon de
  Bruin, Shaun Gallagher (eds.)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04821</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Communication Patterns in Polyhedral Process Networks</dc:title>
 <dc:creator>Alias, Christophe</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Embedded system performances are bounded by power consumption. The trend is
to offload greedy computations on hardware accelerators as GPU, Xeon Phi or
FPGA. FPGA chips combine both flexibility of programmable chips and
energy-efficiency of specialized hardware and appear as a natural solution.
Hardware compilers from high-level languages (High-level synthesis, HLS) are
required to exploit all the capabilities of FPGA while satisfying tight
time-to-market constraints. Compiler optimizations for parallelism and data
locality restructure deeply the execution order of the processes, hence the
read/write patterns in communication channels. This breaks most FIFO channels,
which have to be implemented with addressable buffers. Expensive hardware is
required to enforce synchronizations, which often results in dramatic
performance loss. In this paper, we present an algorithm to partition the
communications so that most FIFO channels can be recovered after a loop tiling,
a key optimization for parallelism and data locality. Experimental results show
a drastic improvement of FIFO detection for regular kernels at the cost of a
few additional storage. As a bonus, the storage can even be reduced in some
cases.
</dc:description>
 <dc:description>Comment: Presented at HIP3ES, 2018</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04828</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncertainty Quantification For A Permanent Magnet Synchronous Machine
  With Dynamic Rotor Eccentricity</dc:title>
 <dc:creator>Bontinck, Zeger</dc:creator>
 <dc:creator>Lass, Oliver</dc:creator>
 <dc:creator>De Gersem, Herbert</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The influence of dynamic eccentricity on the harmonic spectrum of the torque
of a permanent magnet synchronous machine is studied. The spectrum is
calculated by an energy balance method. Uncertainty quantification is applied
by using generalized Polynomial Chaos and Monte Carlo. It is found that the
displacement of the rotor impacts the spectrum of the torque the most.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04829</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Quantitative Approach in Heuristic Evaluation of E-commerce Websites</dc:title>
 <dc:creator>Li, Xiaosong</dc:creator>
 <dc:creator>Liu, Ye</dc:creator>
 <dc:creator>Fan, Zizhou</dc:creator>
 <dc:creator>Li, Will</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This paper presents a pilot study on developing an instrument to predict the
quality of e-commerce websites. The 8C model was adopted as the reference model
of the heuristic evaluation. Each dimension of the 8C was mapped into a set of
quantitative website elements, selected websites were scraped to get the
quantitative website elements, and the score of each dimension was calculated.
A software was developed in PHP for the experiments. In the training process,
10 experiments were conducted and quantitative analysis was regressively
conducted between the experiments. The conversion rate was used to verify the
heuristic evaluation of an e-commerce website after each experiment. The
results showed that the mapping revisions between the experiments improved the
performance of the evaluation instrument, therefore the experiment process and
the quantitative mapping revision guideline proposed was on the right track.
The software resulted from the experiment 10 can serve as the aimed e-commerce
website evaluation instrument. The experiment results and the future work have
been discussed.
</dc:description>
 <dc:description>Comment: Extended paper for AIAA-2017, submitted for Journal publish, paper ID
  AIRCC-33, 13 pages</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04835</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixing Time for Square Tilings</dc:title>
 <dc:creator>Ugolnikova, Alexandra</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05B45, 37A25, 60J10, 52C20</dc:subject>
 <dc:description>  We consider tilings of $\mathbb{Z}^2$ by two types of squares. We are
interested in the rate of convergence to the stationarity of a natural Markov
chain defined for square tilings. The rate of convergence can be represented by
the mixing time which measures the amount of time it takes the chain to be
close to its stationary distribution. We prove polynomial mixing time for $n
\times \log n $ regions in the case of tilings by $1 \times 1$ and $s \times s$
squares. We also consider a weighted Markov chain with weights $\lambda$ being
put on big squares. We show rapid mixing of $O(n^4 \log n)$ with conditions on
$\lambda$. We provide simulations that suggest different conjectures, one of
which is the existence of frozen regions in random tilings by squares.
</dc:description>
 <dc:description>Comment: 25 pages, 15 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04837</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disseminacao de mensagens DTN com base em grupos de interesses</dc:title>
 <dc:creator>Neves, Eric V. das</dc:creator>
 <dc:creator>Martins, Ronaldo N.</dc:creator>
 <dc:creator>Carvalho, Celso B.</dc:creator>
 <dc:creator>Mota, Edjair</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Recent works explore social characteristics of nodes to improve message
delivery rate in Delay Tolerant Networks (DTN). This work uses machine learning
techniques to create node groups organized by common interests. Messages are
sent to target groups, and from there to the final destination. Simulation
results using The ONE simulator show that the larger the group size the higher
the message delivery rate, that reaches 100% in some cases. The paper also
presents results related to the groups of interest such as message delivery
rat, delivery delay and an average number of hops to deliver messages. The
overall results indicate that group-based routing is a promising research
filed.
</dc:description>
 <dc:description>Comment: IV Escola Regional de Informatica (ERIN 2017), in Portuguese</dc:description>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04837</dc:identifier>
 <dc:identifier>Eric V. Das Neves, Ronaldo Martins, Celso B. Carvalho and Edjair
  Mota. Disseminacao de mensagens DTN com base em grupos de interesses. IV
  Escola Regional de Informatica - ERIN, 2017</dc:identifier>
 <dc:language>pt</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04849</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Method of Finding a Lower Energy Solution to a QUBO/Ising Objective
  Function</dc:title>
 <dc:creator>Dorband, John E.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  A new method to find a lower energy solution to a QUBO/Ising objective
function will be presented in this paper. It is applied to samples returned
from the D-Wave for various example cases. This method, multi-qubit correction
(MQC), creates a sample with an equal-to or less-than energy than any of the
D-wave samples used to create it. The method will be detailed and the results
of 3 uses cases will be given to demonstrate its merit.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04853</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>System-Aware Compression</dc:title>
 <dc:creator>Dar, Yehuda</dc:creator>
 <dc:creator>Elad, Michael</dc:creator>
 <dc:creator>Bruckstein, Alfred M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Many information systems employ lossy compression as a crucial intermediate
stage among other processing components. While the important distortion is
defined by the system's input and output signals, the compression usually
ignores the system structure, therefore, leading to an overall sub-optimal
rate-distortion performance. In this paper we propose a compression methodology
for an operational rate-distortion optimization considering a known system
layout, modeled using linear operators and noise. Using the alternating
direction method of multipliers (ADMM) technique, we show that the design of
the new globally-optimized compression reduces to a standard compression of a
&quot;system adjusted&quot; signal. We further explain the main ideas of our method by
theoretically studying the case of a cyclo-stationary Gaussian signal. We
present experimental results for coding of one-dimensional signals and for
video compression using the HEVC standard, showing significant gains by the
adjustment to an acquisition-rendering system.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04856</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Orbit Prediction Accuracy through Supervised Machine Learning</dc:title>
 <dc:creator>Peng, Hao</dc:creator>
 <dc:creator>Bai, Xiaoli</dc:creator>
 <dc:subject>Astrophysics - Earth and Planetary Astrophysics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Due to the lack of information such as the space environment condition and
resident space objects' (RSOs') body characteristics, current orbit predictions
that are solely grounded on physics-based models may fail to achieve required
accuracy for collision avoidance and have led to satellite collisions already.
This paper presents a methodology to predict RSOs' trajectories with higher
accuracy than that of the current methods. Inspired by the machine learning
(ML) theory through which the models are learned based on large amounts of
observed data and the prediction is conducted without explicitly modeling space
objects and space environment, the proposed ML approach integrates
physics-based orbit prediction algorithms with a learning-based process that
focuses on reducing the prediction errors. Using a simulation-based space
catalog environment as the test bed, the paper demonstrates three types of
generalization capability for the proposed ML approach: 1) the ML model can be
used to improve the same RSO's orbit information that is not available during
the learning process but shares the same time interval as the training data; 2)
the ML model can be used to improve predictions of the same RSO at future
epochs; and 3) the ML model based on a RSO can be applied to other RSOs that
share some common features.
</dc:description>
 <dc:description>Comment: 30 pages, 21 figures, 4 tables, Preprint submitted to Advances in
  Space Research, on December 14, 2017</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04857</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Design Space of Social Robots</dc:title>
 <dc:creator>Skillicorn, D. B.</dc:creator>
 <dc:creator>Billingsley, R.</dc:creator>
 <dc:creator>Williams, M. -A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We consider the design space available for social robots in terms of a
hierarchy of functional definitions: the essential properties in terms of a
locus of interaction, autonomy, intelligence, awareness of humans as possessors
of mental state, and awareness of humans as social interactors. We also suggest
that the emphasis on physical embodiment in some segments of the social
robotics community has obscured commonalities with a class of agents that are
identical in all other respects. These definitions naturally suggest research
issues, directions, and possibilities which we explore. Social robotics also
lacks compelling 'killer apps' which we suggest would help focus the community
on a research agenda.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04871</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building a Conversational Agent Overnight with Dialogue Self-Play</dc:title>
 <dc:creator>Shah, Pararth</dc:creator>
 <dc:creator>Hakkani-T&#xfc;r, Dilek</dc:creator>
 <dc:creator>T&#xfc;r, Gokhan</dc:creator>
 <dc:creator>Rastogi, Abhinav</dc:creator>
 <dc:creator>Bapna, Ankur</dc:creator>
 <dc:creator>Nayak, Neha</dc:creator>
 <dc:creator>Heck, Larry</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose Machines Talking To Machines (M2M), a framework combining
automation and crowdsourcing to rapidly bootstrap end-to-end dialogue agents
for goal-oriented dialogues in arbitrary domains. M2M scales to new tasks with
just a task schema and an API client from the dialogue system developer, but it
is also customizable to cater to task-specific interactions. Compared to the
Wizard-of-Oz approach for data collection, M2M achieves greater diversity and
coverage of salient dialogue flows while maintaining the naturalness of
individual utterances. In the first phase, a simulated user bot and a
domain-agnostic system bot converse to exhaustively generate dialogue
&quot;outlines&quot;, i.e. sequences of template utterances and their semantic parses. In
the second phase, crowd workers provide contextual rewrites of the dialogues to
make the utterances more natural while preserving their meaning. The entire
process can finish within a few hours. We propose a new corpus of 3,000
dialogues spanning 2 domains collected with M2M, and present comparisons with
popular dialogue datasets on the quality and diversity of the surface forms and
dialogue flows.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04880</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification of histopathological breast cancer images using iterative
  VMD aided Zernike moments &amp; textural signatures</dc:title>
 <dc:creator>Chattoraj, Subhankar</dc:creator>
 <dc:creator>Vishwakarma, Karan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present a novel method for an automated diagnosis of breast
carcinoma through multilevel iterative variational mode decomposition (VMD) and
textural features encompassing Zernaike moments, fractal dimension and entropy
features namely, Kapoor entropy, Renyi entropy, Yager entropy features are
extracted from VMD components. The proposed method considers the
histopathological image as a set of multidimensional spatially-evolving
signals. ReliefF algorithm is used to select the discriminatory features and
statistically most significant features are fed to squares support vector
machine (SVM) for classification. We evaluate the efficiency of the proposed
methodology on publicly available Breakhis dataset containing 7,909 breast
cancer histological images, collected from 82 patients, of both benign and
malignant cases. Experimental results shows the efficacy of the proposed method
in outperforming the state of the art while achieving an average classification
rates of 89.61% and 88:23% using three-fold and ten-fold cross-validation
strategies, respectively. This system can aid the pathologist in accurate and
reliable diagnosis of biopsy samples. BreaKHis, a publicly dataset available at
http://web.inf.ufpr.br/vri/breast-cancer-database.
</dc:description>
 <dc:description>Comment: Working Paper</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04882</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coding over Sets for DNA Storage</dc:title>
 <dc:creator>Lenz, Andreas</dc:creator>
 <dc:creator>Siegel, Paul H.</dc:creator>
 <dc:creator>Wachter-Zeh, Antonia</dc:creator>
 <dc:creator>Yaakobi, Eitan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B60</dc:subject>
 <dc:description>  In this paper we study error-correcting codes for the storage of data in
synthetic DNA. We investigate a storage model where a data set is represented
by an unordered set of M sequences, each of length L. Errors within that model
are losses of whole sequences and point errors inside the sequences, such as
insertions, deletions and substitutions. We propose code constructions which
can correct errors in such a storage system that can be encoded and decoded
efficiently. By deriving upper bounds on the cardinalities of these codes using
sphere packing arguments, we show that many of our codes are close to optimal.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04883</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Cipher Cracking Using Discrete GANs</dc:title>
 <dc:creator>Gomez, Aidan N.</dc:creator>
 <dc:creator>Huang, Sicong</dc:creator>
 <dc:creator>Zhang, Ivan</dc:creator>
 <dc:creator>Li, Bryan M.</dc:creator>
 <dc:creator>Osama, Muhammad</dc:creator>
 <dc:creator>Kaiser, Lukasz</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This work details CipherGAN, an architecture inspired by CycleGAN used for
inferring the underlying cipher mapping given banks of unpaired ciphertext and
plaintext. We demonstrate that CipherGAN is capable of cracking language data
enciphered using shift and Vigenere ciphers to a high degree of fidelity and
for vocabularies much larger than previously achieved. We present how CycleGAN
can be made compatible with discrete data and train in a stable way. We then
prove that the technique used in CipherGAN avoids the common problem of
uninformative discrimination associated with GANs applied to discrete data.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04886</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Dependability Modeling and Optimization of Scrubbed-Partitioned
  TMR for SRAM-based FPGAs</dc:title>
 <dc:creator>Hoque, Khaza Anuarul</dc:creator>
 <dc:creator>Mohamed, Otmane Ait</dc:creator>
 <dc:creator>Savaria, Yvon</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  SRAM-based FPGAs are popular in the aerospace industry for their field
programmability and low cost. However, they suffer from cosmic
radiation-induced Single Event Upsets (SEUs). Triple Modular Redundancy (TMR)
is a well-known technique to mitigate SEUs in FPGAs that is often used with
another SEU mitigation technique known as configuration scrubbing. Traditional
TMR provides protection against a single fault at a time, while partitioned TMR
provides improved reliability and availability. In this paper, we present a
methodology to analyze TMR partitioning at early design stage using
probabilistic model checking. The proposed formal model can capture both single
and multiple-cell upset scenarios, regardless of any assumption of equal
partition sizes. Starting with a high-level description of a design, a Markov
model is constructed from the Data Flow Graph (DFG) using a specified number of
partitions, a component characterization library and a user defined scrub rate.
Such a model and exhaustive analysis captures all the considered failures and
repairs possible in the system within the radiation environment. Various
reliability and availability properties are then verified automatically using
the PRISM model checker exploring the relationship between the scrub frequency
and the number of TMR partitions required to meet the design requirements.
Also, the reported results show that based on a known voter failure rate, it is
possible to find an optimal number of partitions at early design stages using
our proposed method.
</dc:description>
 <dc:description>Comment: Submitted to a journal for review</dc:description>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04888</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Orthogonal Multiple Access for Mobile VLC Networks with Random
  Receiver Orientation</dc:title>
 <dc:creator>Yapici, Yavuz</dc:creator>
 <dc:creator>Guvenc, Ismail</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Visible light communications (VLC) is an emerging technology with a promise
of viable solution to spectrum crunch problem in conventional radio frequency
bands. In this work, we consider a VLC system where mobile users are randomly
changing their horizontal location and vertical orientation. The non-orthogonal
multiple access (NOMA) strategy with full channel state information (CSI)
feedback is adopted to serve these users with improved spectral efficiency. To
reduce computational burden and overhead due to tracking and feeding back the
full CSI, we consider various limited feedback schemes where users are ordered
based on their distance and vertical angle information instead of full CSI.
Comprehensive numerical results verify the superiority of NOMA as compared to
orthogonal multiple access while compensating the loss in user rates due to the
random receiver orientation. In addition, vertical angle information based
limited feedback schemes are observed to achieve satisfactory performance as
compared to full CSI feedback, while conventional distance feedback scheme
shows poor performance in this realistic VLC scenario.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04891</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cobra: A Framework for Cost Based Rewriting of Database Applications</dc:title>
 <dc:creator>Emani, K. Venkatesh</dc:creator>
 <dc:creator>Sudarshan, S.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Database applications are typically written using a mixture of imperative
languages and declarative frameworks for data processing. Application logic
gets distributed across the declarative and imperative parts of a program.
Often, there is more than one way to implement the same program, whose
efficiency may depend on a number of parameters. In this paper, we propose a
framework that automatically generates all equivalent alternatives of a given
program using a given set of program transformations, and chooses the least
cost alternative. We use the concept of program regions as an algebraic
abstraction of a program and extend the Volcano/Cascades framework for
optimization of algebraic expressions, to optimize programs. We illustrate the
use of our framework for optimizing database applications. We show through
experimental results, that our framework has wide applicability in real world
applications and provides significant performance benefits.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04894</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Debugging Static Analysis</dc:title>
 <dc:creator>Do, Lisa Nguyen Quang</dc:creator>
 <dc:creator>Kr&#xfc;ger, Stefan</dc:creator>
 <dc:creator>Hill, Patrick</dc:creator>
 <dc:creator>Ali, Karim</dc:creator>
 <dc:creator>Bodden, Eric</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  To detect and fix bugs and security vulnerabilities, software companies use
static analysis as part of the development process. However, static analysis
code itself is also prone to bugs. To ensure a consistent level of precision,
as analyzed programs grow more complex, a static analysis has to handle more
code constructs, frameworks, and libraries that the programs use. While more
complex analyses are written and used in production systems every day, the cost
of debugging and fixing them also increases tremendously.
  To better understand the difficulties of debugging static analyses, we
surveyed 115 static analysis writers. From their responses, we extracted the
core requirements to build a debugger for static analysis, which revolve around
two main issues: (1) abstracting from two code bases at the same time (the
analysis code and the analyzed code) and (2) tracking the analysis internal
state throughout both code bases. Most current debugging tools that our survey
participants use lack the capabilities to address both issues.
  Focusing on those requirements, we introduce VisuFlow, a debugging
environment for static data-flow analysis that is integrated in the Eclipse
development environment. VisuFlow features graph visualizations that enable
users to view the state of a data-flow analysis and its intermediate results at
any time. Special breakpoints in VisuFlow help users step through the analysis
code and the analyzed simultaneously. To evaluate the usefulness of VisuFlow,
we have conducted a user study on 20 static analysis writers. Using VisuFlow
helped our sample of analysis writers identify 25% and fix 50% more errors in
the analysis code compared to using the standard Eclipse debugging environment.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04898</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network assembly of scientific communities of varying size and
  specificity</dc:title>
 <dc:creator>Citron, Daniel T.</dc:creator>
 <dc:creator>Way, Samuel F.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  How does the collaboration network of researchers coalesce around a
scientific topic? What sort of social restructuring occurs as a new field
develops? Previous empirical explorations of these questions have examined the
evolution of co-authorship networks associated with several fields of science,
each noting a characteristic shift in network structure as fields develop.
Historically, however, such studies have tended to rely on manually annotated
datasets and therefore only consider a handful of disciplines, calling into
question the universality of the observed structural signature.To overcome this
limitation and test the robustness of this phenomenon, we use a comprehensive
dataset of over 189,000 scientific articles and develop a framework for
partitioning articles and their authors into coherent, semantically-related
groups representing scientific fields of varying size and specificity. We then
use the resulting population of fields to study the structure of evolving
co-authorship networks. Consistent with earlier findings, we observe a global
topological transition as the co-authorship networks coalesce from a disjointed
aggregate into a dense giant connected component that dominates the network. We
validate these results using a separate, complimentary corpus of scientific
articles, and, overall, we find that the previously reported characteristic
structural evolution of a scientific field's associated co-authorship network
is robust across a large number of scientific fields of varying size, scope,
and specificity. Additionally, the framework developed in this study may be
used in other scientometric contexts in order to extend studies to compare
across a larger range of scientific disciplines.
</dc:description>
 <dc:description>Comment: 22 pages, 13 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04898</dc:identifier>
 <dc:identifier>Journal of Informetrics, Volume 12, Issue 1, 2018, Pages 181-190</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2017.12.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04907</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sending Information Through Status Updates</dc:title>
 <dc:creator>Baknina, Abdulrahman</dc:creator>
 <dc:creator>Ozel, Omur</dc:creator>
 <dc:creator>Yang, Jing</dc:creator>
 <dc:creator>Ulukus, Sennur</dc:creator>
 <dc:creator>Yener, Aylin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  We consider an energy harvesting transmitter sending status updates regarding
a physical phenomenon it observes to a receiver. Different from the existing
literature, we consider a scenario where the status updates carry information
about an independent message. The transmitter encodes this message into the
timings of the status updates. The receiver needs to extract this encoded
information, as well as update the status of the observed phenomenon. The
timings of the status updates, therefore, determine both the age of information
(AoI) and the message rate (rate). We study the tradeoff between the achievable
message rate and the achievable average AoI. We propose several achievable
schemes and compare their rate-AoI performances.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04908</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing the power of advice strings: a notion of complexity for
  infinite words</dc:title>
 <dc:creator>Dou&#xe9;neau-Tabot, Ga&#xeb;tan</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68Q45</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  We investigate in this paper a certain notion of comparison between infinite
words. In a general way, if M is a model of computation (e.g. Turing machines)
and C a class of objects (e.g. languages), the complexity of an infinite word w
can be measured with respect to the objects from C that are presentable with
machines from M using w as an oracle.
  In our case, the model M is finite automata and the objects are either
recognized languages or presentable structures, known respectively as advice
regular languages and advice automatic structures. This leads to several
different classifications of infinite words that are studied in detail; logical
and computational characterizations are derived. Our main results explore the
connections between classes of advice automatic structures, MSO-transductions
and two-way transducers. They suggest a closer study of the resulting hierarchy
over infinite words.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04920</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secrecy Amplification for Distributed Encrypted Sources with Correlated
  Keys using Affine Encoders</dc:title>
 <dc:creator>Santoso, Bagus</dc:creator>
 <dc:creator>Oohama, Yasutada</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposed the application of post-encryption-compression (PEC) to
strengthen the secrecy in the case of distributed encryption where the
encryption keys are correlated to each other. We derive the universal code
construction for the compression and the rate region where codes with
achievability and secrecy are obtainable. Our main technique is to use affine
encoders which are constructed from certain linear encoders to encode the
ciphertexts before sending them to public communication channels. We show that
if the rates of linear codes are within a certain rate region:(1) information
leakage on the original sources from the encoded ciphertexts without the keys
is negligible, while (2) one who has legitimate keys is able to retrieve the
original source data with negligible error probability.
</dc:description>
 <dc:description>Comment: An extended abstract is submitted to ISIT 2018. This is the full
  version. arXiv admin note: text overlap with arXiv:1801.02563</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04923</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Capacity-Achieving PIR Protocol for Distributed Storage Using an
  Arbitrary Linear Code</dc:title>
 <dc:creator>Lin, Hsuan-Yin</dc:creator>
 <dc:creator>Kumar, Siddhartha</dc:creator>
 <dc:creator>Rosnes, Eirik</dc:creator>
 <dc:creator>Amat, Alexandre Graell i</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a private information retrieval (PIR) protocol for distributed
storage systems (DSSs) with noncolluding nodes where data is stored using an
arbitrary linear code. An expression for the PIR rate, i.e., the ratio of the
amount of retrieved stored data per unit of downloaded data, is derived, and a
necessary and a sufficient condition for codes to achieve the PIR capacity are
given. The necessary condition is based on the generalized Hamming weights of
the storage code, while the sufficient condition is based on code
automorphisms. We show that cyclic codes and Reed-Muller codes satisfy the
sufficient condition and are thus PIR capacity-achieving.
</dc:description>
 <dc:description>Comment: Submitted to 2018 IEEE International Symposium on Information
  Theory.arXiv admin note: substantial text overlap with arXiv:1712.03898</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04928</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leapfrogging for parallelism in deep neural networks</dc:title>
 <dc:creator>Saraiya, Yatin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present a technique, which we term leapfrogging, to parallelize back-
propagation in deep neural networks. We show that this technique yields a
savings of $1-1/k$ of a dominant term in backpropagation, where k is the number
of threads (or gpus).
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04929</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalizing, Decoding, and Optimizing Support Vector Machine
  Classification</dc:title>
 <dc:creator>Krell, Mario Michael</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The classification of complex data usually requires the composition of
processing steps. Here, a major challenge is the selection of optimal
algorithms for preprocessing and classification (including parameterizations).
Nowadays, parts of the optimization process are automized but expert knowledge
and manual work are still required. We present three steps to face this process
and ease the optimization. Namely, we take a theoretical view on classical
classifiers, provide an approach to interpret the classifier together with the
preprocessing, and integrate both into one framework which enables a
semiautomatic optimization of the processing chain and which interfaces
numerous algorithms.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04929</dc:identifier>
 <dc:identifier>PhD Thesis, University of Bremen, Bremen, 1-236, 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04953</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Uplink Grant for Machine Type Communications: Challenges and
  Opportunities</dc:title>
 <dc:creator>Ali, Samad</dc:creator>
 <dc:creator>Rajatheva, Nandana</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The notion of a fast uplink grant is emerging as a promising solution for
enabling massive machine type communications (MTCs) in the Internet of Things
over cellular networks. By using the fast uplink grant, machine type devices
(MTD) will no longer require random access (RA) channels to send scheduling
requests. Instead, uplink resources can be actively allocated to MTDs by the
base station. In this paper, the challenges and opportunities for adopting the
fast uplink grant to support MTCs are investigated. First, the fundamentals of
fast uplink grant and its advantages over conventional access schemes: i) fully
scheduled with RA process and ii) uncoordinated access, are presented. Then,
the key challenges that include the prediction of set of MTDs with data to
transmit, as well as the optimal scheduling of MTDs, are exposed. To overcome
these challenges, a two-stage approach that includes traffic prediction and
optimized scheduling is proposed. For this approach, various solutions for
source traffic prediction for periodic MTD traffic are reviewed and novel
methods for event-driven traffic prediction are proposed. For optimal
allocation of uplink grants, new solutions based on advanced machine learning
methods are presented. By using the proposed solutions, the fast uplink grant
has the potential to enable cellular networks to support massive MTCs and
effectively reduce the signaling overhead and overcome the delay and congestion
challenges of conventional RA schemes.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04958</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Modeling on Health Journals with Regularized Variational Inference</dc:title>
 <dc:creator>Giaquinto, Robert</dc:creator>
 <dc:creator>Banerjee, Arindam</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Topic modeling enables exploration and compact representation of a corpus.
The CaringBridge (CB) dataset is a massive collection of journals written by
patients and caregivers during a health crisis. Topic modeling on the CB
dataset, however, is challenging due to the asynchronous nature of multiple
authors writing about their health journeys. To overcome this challenge we
introduce the Dynamic Author-Persona topic model (DAP), a probabilistic
graphical model designed for temporal corpora with multiple authors. The
novelty of the DAP model lies in its representation of authors by a persona ---
where personas capture the propensity to write about certain topics over time.
Further, we present a regularized variational inference algorithm, which we use
to encourage the DAP model's personas to be distinct. Our results show
significant improvements over competing topic models --- particularly after
regularization, and highlight the DAP model's unique ability to capture common
journeys shared by different authors.
</dc:description>
 <dc:description>Comment: Published in Thirty-Second AAAI Conference on Artificial
  Intelligence, February 2018, New Orleans, Louisiana, USA</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04959</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic compensation and homeostasis: a feedback control perspective</dc:title>
 <dc:creator>Fliess, Michel</dc:creator>
 <dc:creator>Join, C&#xe9;dric</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>92B05, 93B52</dc:subject>
 <dc:description>  &quot;Dynamic compensation&quot; is a robustness property where a perturbed biological
circuit maintains a suitable output [Karin O., Swisa A., Glaser B., Dor Y.,
Alon U. (2016). Mol. Syst. Biol., 12: 886]. In spite of several attempts, no
fully convincing analysis seems now to be on hand. This communication suggests
an explanation via &quot;model-free control&quot; and the corresponding &quot;intelligent&quot;
controllers [Fliess M., Join C. (2013). Int. J. Contr., 86, 2228-2252], which
are already successfully applied in many concrete situations. As a byproduct
this setting provides also a slightly different presentation of homeostasis, or
&quot;exact adaptation,&quot; where the working conditions are assumed to be &quot;mild.&quot;
Several convincing, but academic, computer simulations are provided and
discussed.
</dc:description>
 <dc:description>Comment: Research Report, Ecole polytechnique, Palaiseau, France</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04961</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encrypt Flip-Flop: A Novel Logic Encryption Technique For Sequential
  Circuits</dc:title>
 <dc:creator>Karmakar, Rajit</dc:creator>
 <dc:creator>Chatopadhyay, Santanu</dc:creator>
 <dc:creator>Kapur, Rohit</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Logic Encryption is one of the most popular hardware security techniques
which can prevent IP piracy and illegal IC overproduction. It introduces
obfuscation by inserting some extra hardware into a design to hide its
functionality from unauthorized users. Correct functionality of an encrypted
design depends upon the application of correct keys, shared only with the
authorized users. In the recent past, extensive efforts have been devoted in
extracting the secret key of an encrypted design. At the same time, several
countermeasures have also been proposed by the research community to thwart
different state-of-the-art attacks on logic encryption. However, most of the
proposed countermeasures fail to prevent the powerful SAT attack. Although a
few researchers have proposed different solutions to withstand SAT attack,
those solutions suffer from several drawbacks such as high design overheads,
low output corruptibility, and vulnerability against removal attack. Almost all
the known logic encryption strategies are vulnerable to scan based attack. In
this paper, we propose a novel encryption technique called Encrypt Flip-Flop,
which encrypts the outputs of selected flip-flops by inserting multiplexers
(MUX). The proposed strategy can thwart all the known attacks including SAT and
scan based attacks. The scheme has low design overhead and implementation
complexity. Experimental results on several ISCAS'89 and ITC'99 benchmarks show
that our proposed method can produce reasonable output corruption for wrong
keys.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04962</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Level of Quality can Neural Machine Translation Attain on Literary
  Text?</dc:title>
 <dc:creator>Toral, Antonio</dc:creator>
 <dc:creator>Way, Andy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Given the rise of a new approach to MT, Neural MT (NMT), and its promising
performance on different text types, we assess the translation quality it can
attain on what is perceived to be the greatest challenge for MT: literary text.
Specifically, we target novels, arguably the most popular type of literary
text. We build a literary-adapted NMT system for the English-to-Catalan
translation direction and evaluate it against a system pertaining to the
previous dominant paradigm in MT: statistical phrase-based MT (PBSMT). To this
end, for the first time we train MT systems, both NMT and PBSMT, on large
amounts of literary text (over 100 million words) and evaluate them on a set of
twelve widely known novels spanning from the the 1920s to the present day.
According to the BLEU automatic evaluation metric, NMT is significantly better
than PBSMT (p &lt; 0.01) on all the novels considered. Overall, NMT results in a
11% relative improvement (3 points absolute) over PBSMT. A complementary human
evaluation on three of the books shows that between 17% and 34% of the
translations, depending on the book, produced by NMT (versus 8% and 20% with
PBSMT) are perceived by native speakers of the target language to be of
equivalent quality to translations produced by a professional human translator.
</dc:description>
 <dc:description>Comment: Chapter for the forthcoming book &quot;Translation Quality Assessment:
  From Principles to Practice&quot; (Springer)</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04964</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Future is Unlicensed: Coexistence in the Unlicensed Spectrum for 5G</dc:title>
 <dc:creator>Bayhan, Suzan</dc:creator>
 <dc:creator>G&#xfc;r, G&#xfc;rkan</dc:creator>
 <dc:creator>Zubow, Anatolij</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  5G has to fulfill the requirements of ultra-dense, scalable, and customizable
networks such as IoT while increasing spectrum and energy efficiency. Given the
diversity of envisaged applications and scenarios, one crucial property for 5G
New Radio (NR) is flexibility: flexible UL/DL allocation, bandwidths, or
scalable transmission time interval, and most importantly operation at
different frequency bands. In particular, 5G should exploit the spectral
opportunities in the unlicensed spectrum for expanding network capacity when
and where needed. However, unlicensed bands pose the challenge of &quot;coexisting
networks&quot;, which mostly lack the means of communication for negotiation and
coordination. This deficiency is further exacerbated by the heterogeneity,
massive connectivity, and ubiquity of IoT systems and applications. Therefore,
5G needs to provide mechanisms to coexist and even converge in the unlicensed
bands. In that regard, WiFi, as the most prominent wireless technology in the
unlicensed bands, is both a key enabler for boosting 5G capacity and competitor
of 5G cellular networks for the shared unlicensed spectrum. In this work, we
describe spectrum sharing in 5G and present key coexistence solutions, mostly
in the context of WiFi. We also highlight the role of machine learning which is
envisaged to be critical for reaching coexistence and convergence goals by
providing the necessary intelligence and adaptation mechanisms.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04966</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic Specifications of Wayfinding Using Cognitive Map</dc:title>
 <dc:creator>Ahmadi, Vahid</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper outlines the formal representation of the environment in which it
is assumed that a wayfinding process has been occurred through a street
network. Wayfinding is a process in which people navigate themselves from an
origin to a destination by their common sense geospatial knowledge. Na\&quot;ive
Geography is a field of study that investigates the body of knowledge that
people have about the surrounding geospatial world and it deals with common
sense knowledge of space. The image schemas which are needed for wayfinding
with boundary relations method have been extracted and represented formally
with algebraic specifications. These specifications are mentioned in the syntax
of a functional programming language, Haskell. It allows us to execute written
algebraic specifications and provide conditions for rapid prototyping and
formal checks on consistency. These formal specifications are implemented for
modeling street network of a part of Tehran, Capital city of Iran.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04971</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Data Retrieval Practices: A Social Informatics Perspective</dc:title>
 <dc:creator>Gregory, Kathleen</dc:creator>
 <dc:creator>Cousijn, Helena</dc:creator>
 <dc:creator>Groth, Paul</dc:creator>
 <dc:creator>Scharnhorst, Andrea</dc:creator>
 <dc:creator>Wyatt, Sally</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Open research data are heralded as having the potential to increase
effectiveness, productivity, and reproducibility in science, but little is
known about the actual practices involved in data search and retrieval. The
socio-technical problem of locating data for (re)use is often reduced to the
technological dimension of designing data search systems. In this article, we
explore how a social informatics perspective can help to better analyze the
current academic discourse about data retrieval as well as to study user
practices and behaviors. We employ two methods in our analysis - bibliometrics
and interviews with data seekers - and conclude with a discussion of the
implications of our findings for designing data discovery systems.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04973</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Stage LASSO ADMM Signal Detection Algorithm For Large Scale MIMO</dc:title>
 <dc:creator>Elgabli, Anis</dc:creator>
 <dc:creator>Elghariani, Ali</dc:creator>
 <dc:creator>Al-Abbasi, Abubakr O.</dc:creator>
 <dc:creator>Bell, Mark</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper explores the benefit of using some of the machine learning
techniques and Big data optimization tools in approximating maximum likelihood
(ML) detection of Large Scale MIMO systems. First, large scale MIMO detection
problem is formulated as a LASSO (Least Absolute Shrinkage and Selection
Operator) optimization problem. Then, Alternating Direction Method of
Multipliers (ADMM) is considered in solving this problem. The choice of ADMM is
motivated by its ability of solving convex optimization problems by breaking
them into smaller sub-problems, each of which are then easier to handle.
Further improvement is obtained using two stages of LASSO with interference
cancellation from the first stage. The proposed algorithm is investigated at
various modulation techniques with different number of antennas. It is also
compared with widely used algorithms in this field. Simulation results
demonstrate the efficacy of the proposed algorithm for both uncoded and coded
cases.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04979</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal specification of the FlexRay protocol using FocusST</dc:title>
 <dc:creator>Spichkova, Maria</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  FlexRay is a communication protocol developed by the FlexRay Consortium. The
core members of the Consortium are Freescale Semiconductor, Robert Bosch GmbH,
NXP Semiconductors, BMW, Volkswagen, Daimler, and General Motors, and the
protocol was respectively oriented towards embedded systems in the automotive
domain. This paper presents a formal specification of the FlexRay protocol
using the FocusST framework. This work extends our previous research of formal
specifications of this protocol using Focus formal language.
</dc:description>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04982</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing effectively stabilizing controllers for a class of $n$D
  systems</dc:title>
 <dc:creator>Bouzidi, Yacine</dc:creator>
 <dc:creator>Cluzeau, Thomas</dc:creator>
 <dc:creator>Moroz, Guillaume</dc:creator>
 <dc:creator>Quadrat, Alban</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  In this paper, we study the internal stabilizability and internal
stabilization problems for multidimensional (nD) systems. Within the fractional
representation approach, a multidimen-sional system can be studied by means of
matrices with entries in the integral domain of structurally stable rational
fractions, namely the ring of rational functions which have no poles in the
closed unit polydisc U n = {z = (z 1 ,. .. , z n) $\in$ C n | |z 1 | 1,. .. ,
|z n | 1}. It is known that the internal stabilizability of a multidimensional
system can be investigated by studying a certain polynomial ideal I = p 1 ,. ..
, p r that can be explicitly described in terms of the transfer matrix of the
plant. More precisely the system is stabilizable if and only if V (I) = {z
$\in$ C n | p 1 (z) = $\times$ $\times$ $\times$ = p r (z) = 0} $\cap$ U n =
$\emptyset$. In the present article, we consider the specific class of linear
nD systems (which includes the class of 2D systems) for which the ideal I is
zero-dimensional, i.e., the p i 's have only a finite number of common complex
zeros. We propose effective symbolic-numeric algorithms for testing if V (I)
$\cap$ U n = $\emptyset$, as well as for computing, if it exists, a stable
polynomial p $\in$ I which allows the effective computation of a stabilizing
controller. We illustrate our algorithms through an example and finally provide
running times of prototype implementations for 2D and 3D systems.
</dc:description>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04982</dc:identifier>
 <dc:identifier>IFAC-PapersOnLine, 2017, 50 (1), pp.1847 - 1852.
  \&amp;\#x3008;10.1016/j.ifacol.2017.08.200\&amp;\#x3009</dc:identifier>
 <dc:identifier>doi:10.1016/j.ifacol.2017.08.200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04984</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Time-Parallel Poroelasticity Simulation</dc:title>
 <dc:creator>K&#xf6;cher, Uwe</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  The accurate, reliable and efficient numerical approximation of multi-physics
processes in heterogeneous porous media with varying media coefficients that
include fluid flow and structure interactions is of fundamental importance in
energy, environmental, petroleum and biomedical engineering applications fields
for instance. Important applications include subsurface compaction drive,
carbon sequestration, hydraulic and thermal fracturing and oil recovery.
Biomedical applications include the simulation of vibration therapy for
osteoporosis processes of trabeculae bones, estimating stress levels induced by
tumour growth within the brain or next-generation spinal disc prostheses.
  Variational space-time methods offers some appreciable advantages such as the
flexibility of the triangulation for complex geometries in space and natural
local time stepping, the straightforward construction of higher-order
approximations and the application of efficient goal-oriented (duality-based)
adaptivity concepts. In addition to that, uniform space-time variational
methods appear to be advantageous for stability and a priori error analyses of
the discrete schemes. Especially (high-order) discontinuous in time approaches
appear to have favourable properties due to the weak application of the initial
conditions.
  The development of monolithic multi-physics schemes, instead of iterative
coupling methods between the physical problems, is a key component of the
research to reduce the modeling error. Special emphasis is on the development
of efficient multi-physics and multigrid preconditioning technologies and their
implementation.
  The simulation software DTM++ is a modularised framework written in C++11 and
builds on top of deal.II toolchains. The implementation allows parallel
simulations from notebooks up to cluster scale.
</dc:description>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04986</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation of thin film flows with a moving mesh mixed finite element
  method</dc:title>
 <dc:creator>Zhang, Hong</dc:creator>
 <dc:creator>Zegeling, Paul A</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We present an efficient mixed finite element method to solve the fourth-order
thin film flow equations using moving mesh refinement. The moving mesh strategy
is based on harmonic mappings developed by Li et al. [J. Comput. Phys., 170
(2001), pp. 562-588, and 177 (2002), pp. 365-393]. To achieve a high quality
mesh, we adopt an adaptive monitor function and smooth it based on a diffusive
mechanism. A variety of numerical tests are performed to demonstrate the
accuracy and efficiency of the method. The moving mesh refinement accurately
resolves the overshoot and downshoot structures and reduces the computational
cost in comparison to numerical simulations using a fixed mesh.
</dc:description>
 <dc:description>Comment: 18 pages, 10 figures</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04987</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of the Weighted Fussed Lasso</dc:title>
 <dc:creator>Bento, Jose</dc:creator>
 <dc:creator>Ray, Surjyendu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The solution path of the 1D fused lasso for an $n$-dimensional input is
piecewise linear with $\mathcal{O}(n)$ segments (Hoefling et al. 2010 and
Tibshirani et al 2011). However, existing proofs of this bound do not hold for
the weighted fused lasso. At the same time, results for the generalized lasso,
of which the weighted fused lasso is a special case, allow $\Omega(3^n)$
segments (Mairal et al. 2012). In this paper, we prove that the number of
segments in the solution path of the weighted fused lasso is
$\mathcal{O}(n^3)$, and for some instances $\Omega(n^2)$. We also give a new,
very simple, proof of the $\mathcal{O}(n)$ bound for the fused lasso.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04991</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicle Routing with Subtours</dc:title>
 <dc:creator>Held, Stephan</dc:creator>
 <dc:creator>K&#xf6;nemann, Jochen</dc:creator>
 <dc:creator>Vygen, Jens</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  When delivering items to a set of destinations, one can save time and cost by
passing a subset to a sub-contractor at any point en route. We consider a model
where a set of items are initially loaded in one vehicle and should be
distributed before a given deadline {\Delta}. In addition to travel time and
time for deliveries, we assume that there is a fixed delay for handing over an
item from one vehicle to another.
  We will show that it is easy to decide whether an instance is feasible, i.e.,
whether it is possible to deliver all items before the deadline {\Delta}. We
then consider computing a feasible tour of minimum cost, where we incur a cost
per unit distance traveled by the vehicles, and a setup cost for every used
vehicle. Our problem arises in practical applications and generalizes classical
problems such as shallow-light trees and the bounded-latency problem.
  Our main result is a polynomial-time algorithm that, for any given {\epsilon}
&gt; 0 and any feasible instance, computes a solution that delivers all items
before time (1+ {\epsilon}){\Delta} and has cost O(1 + 1 / {\epsilon}) OPT,
where OPT is the minimum cost of any feasible solution.
  We show that our result is best possible in the sense that any improvement
would lead to progress on 25-year-old questions on shallow-light trees.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04992</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data</dc:title>
 <dc:creator>Reich, Johannes</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In this article, the data notion is mathematically conceptualized as typed
information based on the two concepts of information and computable
functionality. A data type is defined as a pair of a set of distinguishable
characters (an alphabet) and a set of operations (surjective, computable
functions) that operate on this alphabet as domain and capture the intent of a
parameterizable concept. Two different ways to construct new data types from
existing ones are described: restriction and extension. They lead to two
different partial orders on types in the sense of subtyping as formulated by
Liskov and Wing. It is argued that the proposed data concept matches the
concept of characteristics (Merkmale) of the automation industry.
</dc:description>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05030</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting abnormal events in video using Narrowed Motion Clusters</dc:title>
 <dc:creator>Ionescu, Radu Tudor</dc:creator>
 <dc:creator>Smeureanu, Sorina</dc:creator>
 <dc:creator>Popescu, Marius</dc:creator>
 <dc:creator>Alexe, Bogdan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We formulate the abnormal event detection problem as an outlier detection
task and we propose a two-stage algorithm based on k-means clustering and
one-class Support Vector Machines (SVM) to eliminate outliers. After extracting
motion features from the training video containing only normal events, we apply
k-means clustering to find clusters representing different types of motion. In
the first stage, we consider that clusters with fewer samples (with respect to
a given threshold) contain only outliers and we eliminate these clusters
altogether. In the second stage, we shrink the borders of the remaining
clusters by training a one-class SVM model on each cluster. To detected
abnormal events in the test video, we analyze each test sample and consider its
maximum normality score provided by the trained one-class SVM models, based on
the intuition that a test sample can belong to only one cluster of normal
motion. If the test sample does not fit well in any narrowed cluster, than it
is labeled as abnormal. We also combine our approach based on motion features
with a recent approach based on deep appearance features extracted with
pre-trained convolutional neural networks (CNN). We combine our two-stage
algorithm with the deep framework using a late fusion strategy, keeping the
pipelines of the two approaches independent. We compare our method with several
state-of-the-art supervised and unsupervised methods on four benchmark data
sets. The empirical results indicate that our abnormal event detection
framework can achieve better results in most cases, while processing the test
video in real-time at 30 frames per second on CPU.
</dc:description>
 <dc:description>Comment: Submitted at a conference for review.arXiv admin note: text overlap
  with arXiv:1705.08182</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05032</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AliMe Assist: An Intelligent Assistant for Creating an Innovative
  E-commerce Experience</dc:title>
 <dc:creator>Li, Feng-Lin</dc:creator>
 <dc:creator>Qiu, Minghui</dc:creator>
 <dc:creator>Chen, Haiqing</dc:creator>
 <dc:creator>Wang, Xiongwei</dc:creator>
 <dc:creator>Gao, Xing</dc:creator>
 <dc:creator>Huang, Jun</dc:creator>
 <dc:creator>Ren, Juwei</dc:creator>
 <dc:creator>Zhao, Zhongzhou</dc:creator>
 <dc:creator>Zhao, Weipeng</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Jin, Guwei</dc:creator>
 <dc:creator>Chu, Wei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present AliMe Assist, an intelligent assistant designed for creating an
innovative online shopping experience in E-commerce. Based on question
answering (QA), AliMe Assist offers assistance service, customer service, and
chatting service. It is able to take voice and text input, incorporate context
to QA, and support multi-round interaction. Currently, it serves millions of
customer questions per day and is able to address 85% of them. In this paper,
we demonstrate the system, present the underlying techniques, and share our
experience in dealing with real-world QA in the E-commerce field.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05037</identifier>
 <datestamp>2018-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A fast new algorithm for weak graph regularity</dc:title>
 <dc:creator>Fox, Jacob</dc:creator>
 <dc:creator>Lov&#xe1;sz, L&#xe1;szl&#xf3; Mikl&#xf3;s</dc:creator>
 <dc:creator>Zhao, Yufei</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We provide a deterministic algorithm that finds, in $\epsilon^{-O(1)} n^2$
time, an $\epsilon$-regular Frieze-Kannan partition of a graph on $n$ vertices.
The algorithm outputs an approximation of a given graph as a weighted sum of
$\epsilon^{-O(1)}$ many complete bipartite graphs.
  As a corollary, we give a deterministic algorithm for estimating the number
of copies of $H$ in an $n$-vertex graph $G$ up to an additive error of at most
$\epsilon n^{v(H)}$, in time $\epsilon^{-O_H(1)}n^2$.
</dc:description>
 <dc:description>Comment: 12 pages, not including references. arXiv admin note: text overlap
  with arXiv:1604.00733</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05038</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An octree cells occupancy geometric dimensionality descriptor for
  massive on-server point cloud visualisation and classification</dc:title>
 <dc:creator>Cura, Remi</dc:creator>
 <dc:creator>Perret, Julien</dc:creator>
 <dc:creator>Paparoditis, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Lidar datasets are becoming more and more common. They are appreciated for
their precise 3D nature, and have a wide range of applications, such as surface
reconstruction, object detection, visualisation, etc. For all this
applications, having additional semantic information per point has potential of
increasing the quality and the efficiency of the application. In the last
decade the use of Machine Learning and more specifically classification methods
have proved to be successful to create this semantic information. In this
paradigm, the goal is to classify points into a set of given classes (for
instance tree, building, ground, other). Some of these methods use descriptors
(also called feature) of a point to learn and predict its class. Designing the
descriptors is then the heart of these methods. Descriptors can be based on
points geometry and attributes, use contextual information, etc. Furthermore,
descriptors can be used by humans for easier visual understanding and sometimes
filtering. In this work we propose a new simple geometric descriptor that gives
information about the implicit local dimensionality of the point cloud at
various scale. For instance a tree seen from afar is more volumetric in nature
(3D), yet locally each leaves is rather planar (2D). To do so we build an
octree centred on the point to consider, and compare the variation of the
occupancy of the cells across the levels of the octree. We compare this
descriptor with the state of the art dimensionality descriptor and show its
interest. We further test the descriptor for classification within the Point
Cloud Server, and demonstrate efficiency and correctness results.
</dc:description>
 <dc:description>Comment: extracted from article arXiv:1602.06920 ( arXiv:1602.06920 was split
  into 2 articles because it was to long and to hard to read)</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05039</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Convergence of Policy Gradient Methods for Linearized Control
  Problems</dc:title>
 <dc:creator>Fazel, Maryam</dc:creator>
 <dc:creator>Ge, Rong</dc:creator>
 <dc:creator>Kakade, Sham M.</dc:creator>
 <dc:creator>Mesbahi, Mehran</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Direct policy gradient methods for reinforcement learning and continuous
control problems are a popular approach for a variety of reasons: 1) they are
easy to implement without explicit knowledge of the underlying model 2) they
are an &quot;end-to-end&quot; approach, directly optimizing the performance metric of
interest 3) they inherently allow for richly parameterized policies. A notable
drawback is that even in the most basic continuous control problem (that of
linear quadratic regulators), these methods must solve a non-convex
optimization problem, where little is understood about their efficiency from
both computational and statistical perspectives. In contrast, system
identification and model based planning in optimal control theory have a much
more solid theoretical footing, where much is known with regards to their
computational and statistical properties. This work bridges this gap showing
that (model free) policy gradient methods globally converge to the optimal
solution and are efficient (polynomially so in relevant problem dependent
quantities) with regards to their sample and computational complexities.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05040</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Student Beats the Teacher: Deep Neural Networks for Lateral Ventricles
  Segmentation in Brain MR</dc:title>
 <dc:creator>Ghafoorian, Mohsen</dc:creator>
 <dc:creator>Teuwen, Jonas</dc:creator>
 <dc:creator>Manniesing, Rashindra</dc:creator>
 <dc:creator>de Leeuw, Frank-Erik</dc:creator>
 <dc:creator>van Ginneken, Bram</dc:creator>
 <dc:creator>Karssemeijer, Nico</dc:creator>
 <dc:creator>Platel, Bram</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Ventricular volume and its progression are known to be linked to several
brain diseases such as dementia and schizophrenia. Therefore accurate
measurement of ventricle volume is vital for longitudinal studies on these
disorders, making automated ventricle segmentation algorithms desirable. In the
past few years, deep neural networks have shown to outperform the classical
models in many imaging domains. However, the success of deep networks is
dependent on manually labeled data sets, which are expensive to acquire
especially for higher dimensional data in the medical domain. In this work, we
show that deep neural networks can be trained on much-cheaper-to-acquire
pseudo-labels (e.g., generated by other automated less accurate methods) and
still produce more accurate segmentations compared to the quality of the
labels. To show this, we use noisy segmentation labels generated by a
conventional region growing algorithm to train a deep network for lateral
ventricle segmentation. Then on a large manually annotated test set, we show
that the network significantly outperforms the conventional region growing
algorithm which was used to produce the training labels for the network. Our
experiments report a Dice Similarity Coefficient (DSC) of $0.874$ for the
trained network compared to $0.754$ for the conventional region growing
algorithm ($p &lt; 0.001$).
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, SPIE Medical Imaging 2018 Conference paper</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05042</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Centralized &quot;big science&quot; communities more likely generate
  non-replicable results</dc:title>
 <dc:creator>Danchev, Valentin</dc:creator>
 <dc:creator>Rzhetsky, Andrey</dc:creator>
 <dc:creator>Evans, James A.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Growing concern that most published results, including those widely agreed
upon, may be false are rarely examined against rapidly expanding research
production. Replications have only occurred on small scales due to prohibitive
expense and limited professional incentive. We introduce a novel,
high-throughput replication strategy aligning 51,292 published claims about
drug-gene interactions with high-throughput experiments performed through the
NIH LINCS L1000 program. We show (1) that unique claims replicate 19% more
frequently than at random, while those widely agreed upon replicate 45% more
frequently, manifesting collective correction mechanisms in science; but (2)
centralized scientific communities perpetuate claims that are less likely to
replicate even if widely agreed upon, demonstrating how centralized,
overlapping collaborations weaken collective understanding. Decentralized
research communities involve more independent teams and use more diverse
methodologies, generating the most robust, replicable results. Our findings
highlight the importance of science policies that foster decentralized
collaboration to promote robust scientific advance.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05047</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy attitudes and concerns in the digital lives of older adults:
  Westin's privacy attitude typology revisited</dc:title>
 <dc:creator>Elueze, Isioma</dc:creator>
 <dc:creator>Quan-Haase, Anabel</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  There is a growing literature on teenage and young adult users' attitudes
toward and concerns about online privacy, yet little is known about older
adults and their unique experiences. As older adults join the digital world in
growing numbers, we need to gain a better understanding of how they experience
and navigate online privacy. This paper fills this research gap by examining 40
in-depth interviews with older adults (65 and older) living in East York,
Toronto. We found Westin's typology to be a useful starting point for
understanding privacy attitudes and concerns in this demographic. We expand
Westin's typology and distinguish five categories: fundamentalist, intense
pragmatist, relaxed pragmatist, marginally concerned, and cynical expert. We
find that older adults are not a homogenous group composed of privacy
fundamentalists; rather, there is considerable variability in terms of their
privacy attitudes, with only 13 per cent being fundamentalists. We also
identify a group of cynical experts who believe that online privacy breaches
are inevitable. A large majority of older adults are marginally concerned, as
they see their online participation as limited and harmless. Older adults were
also grouped as either intense or relaxed pragmatists. We find that some
privacy concerns are shared by older adults across several categories, the most
common being spam, unauthorized access to personal information, and information
misuse. We discuss theoretical implications based on the findings for our
understanding of privacy in the context of older adults' digital lives and
discuss implications for offering training appropriate for enhancing privacy
literacy in this age group.
</dc:description>
 <dc:description>Comment: 39 pages, 2 tables, 2 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05052</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Java &amp; Lambda: a Featherweight Story</dc:title>
 <dc:creator>Bettini, Lorenzo</dc:creator>
 <dc:creator>Bono, Viviana</dc:creator>
 <dc:creator>Dezani-Ciancaglini, Mariangiola</dc:creator>
 <dc:creator>Venneri, Betti</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>03B70, 03B15, 68Q55</dc:subject>
 <dc:description>  We present FJ&amp;Lambda, a new core calculus that extends Featherweight Java
(FJ) with interfaces, supporting multiple inheritance, lambda-expressions, and
intersection types. Our main goal is to formalise how lambdas and intersection
types are grafted on Java 8, by studying their properties in a formal setting.
We show how intersection types play a significant role in several cases, in
particular in the typecast of a lambda-expression and in the typing of
conditional expressions. We also embody interface default methods in FJ&amp;Lambda,
since they increase the dynamism of lambda-expressions, by allowing these
methods to be called on lambda-expressions.
  The crucial point in Java 8 and in our calculus is that lambda-expressions
can have various types according to the context requirements (target types):
indeed, Java code is not correct when lambda-expressions come without target
types. In particular, in the operational semantics we must record target types
by decorating lambda-expressions, otherwise they would be lost in the runtime
expressions.
  We prove the subject reduction property and progress for the resulting
calculus, and we give a type inference algorithm that returns the type of a
given program if it is well typed. The design of FJ&amp;Lambda has been driven by
the aim of making it a subset of Java 8, while preserving the elegance and
compactness of FJ. Indeed, FJ&amp;Lambda programs are typed and behave the same as
Java programs.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05055</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Metric Indexes for Incremental Insertion and Querying</dc:title>
 <dc:creator>Raff, Edward</dc:creator>
 <dc:creator>Nicholas, Charles</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work we explore the use of metric index structures, which accelerate
nearest neighbor queries, in the scenario where we need to interleave
insertions and queries during deployment. This use-case is inspired by a
real-life need in malware analysis triage, and is surprisingly understudied.
Existing literature tends to either focus on only final query efficiency, often
does not support incremental insertion, or does not support arbitrary distance
metrics. We modify and improve three algorithms to support our scenario of
incremental insertion and querying with arbitrary metrics, and evaluate them on
multiple datasets and distance metrics while varying the value of $k$ for the
desired number of nearest neighbors. In doing so we determine that our improved
Vantage-Point tree of Minimum-Variance performs best for this scenario.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05062</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Label Learning from Medical Plain Text with Convolutional Residual
  Models</dc:title>
 <dc:creator>Zhang, Xinyuan</dc:creator>
 <dc:creator>Henao, Ricardo</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Li, Yitong</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Predicting diagnoses from Electronic Health Records (EHRs) is an important
medical application of multi-label learning. We propose a convolutional
residual model for multi-label classification from doctor notes in EHR data. A
given patient may have multiple diagnoses, and therefore multi-label learning
is required. We employ a Convolutional Neural Network (CNN) to encode plain
text into a fixed-length sentence embedding vector. Since diagnoses are
typically correlated, a deep residual network is employed on top of the CNN
encoder, to capture label (diagnosis) dependencies and incorporate information
directly from the encoded sentence vector. A real EHR dataset is considered,
and we compare the proposed model with several well-known baselines, to predict
diagnoses based on doctor notes. Experimental results demonstrate the
superiority of the proposed convolutional residual model.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05064</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DKVF: A Framework for Rapid Prototyping and Evaluating Distributed
  Key-value Stores</dc:title>
 <dc:creator>Roohitavaf, Mohammad</dc:creator>
 <dc:creator>Kulkarni, Sandeep</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We present our framework DKVF that enables one to quickly prototype and
evaluate new protocols for key-value stores and compare them with existing
protocols based on selected benchmarks. Due to limitations of CAP theorem, new
protocols must be developed that achieve the desired trade-off between
consistency and availability for the given application at hand. Hence, both
academic and industrial communities focus on developing new protocols that
identify a different (and hopefully better in one or more aspect) point on this
trade-off curve. While these protocols are often based on a simple intuition,
evaluating them to ensure that they indeed provide increased availability,
consistency, or performance is a tedious task. Our framework, DKVF, enables one
to quickly prototype a new protocol as well as identify how it performs
compared to existing protocols for pre-specified benchmarks. Our framework
relies on YCSB (Yahoo! Cloud Servicing Benchmark) for benchmarking. We
demonstrate DKVF by implementing four existing protocols --eventual
consistency, COPS, GentleRain and CausalSpartan-- with it. We compare the
performance of these protocols against different loading conditions. We find
that the performance is similar to our implementation of these protocols from
scratch. And, the comparison of these protocols is consistent with what has
been reported in the literature. Moreover, implementation of these protocols
was much more natural as we only needed to translate the pseudocode into Java
(and add the necessary error handling). Hence, it was possible to achieve this
in just 1-2 days per protocol. Finally, our framework is extensible. It is
possible to replace individual components in the framework (e.g., the storage
component).
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05068</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Circular Antenna Array Design for Breast Cancer Detection</dc:title>
 <dc:creator>Ouerghi, Kalthoum</dc:creator>
 <dc:creator>Fadlallah, Najib</dc:creator>
 <dc:creator>Smida, Amor</dc:creator>
 <dc:creator>Ghayoula, Ridha</dc:creator>
 <dc:creator>Fattahi, Jaouhar</dc:creator>
 <dc:creator>Boulejfen, Noureddine</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Microwave imaging for breast cancer detection is based on the contrast in the
electrical properties of healthy fatty breast tissues. This paper presents an
industrial, scientific and medical (ISM) bands comparative study of five
microstrip patch antennas for microwave imaging at a frequency of 2.45 GHz. The
choice of one antenna is made for an antenna array composed of 8 antennas for a
microwave breast imaging system. Each antenna element is arranged in a circular
configuration so that it can be directly faced to the breast phantom for better
tumor detection. This choice is made by putting each antenna alone on the
Breast skin to study the electric field, magnetic fields and current density in
the healthy tissue of the breast phantom designed and simulated in Ansoft High
Frequency Simulation Software (HFSS).
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05068</dc:identifier>
 <dc:identifier>Sensors Networks Smart and Emerging Technologies (SENSET), 2017,
  pp. 1-4</dc:identifier>
 <dc:identifier>doi:10.1109/SENSET.2017.8125016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05071</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Finite Block Length Achievability Bound for Low Probability of
  Detection Communication</dc:title>
 <dc:creator>Letzepis, Nick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Low probability of detection (or covert) communication refers to the scenario
where information must be sent reliably to a receiver, but with low probability
of detection by an adversary. Recent works on the fundamental limits of this
communication problem have established achievability and converse bounds that
are asymptotic in the block length of the code. This paper uses Gallager's
random coding bound to derive a new achievability bound that is applicable to
low probability of detection communication in the finite block length regime.
Further insights are unveiled that are otherwise hidden in previous asymptotic
analyses.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05075</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Human-Grounded Evaluation Benchmark for Local Explanations of Machine
  Learning</dc:title>
 <dc:creator>Mohseni, Sina</dc:creator>
 <dc:creator>Ragan, Eric D.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In order for people to be able to trust and take advantage of the results of
advanced machine learning and artificial intelligence solutions for real
decision making, people need to be able to understand the machine rationale for
given output. Research in explain artificial intelligence (XAI) addresses the
aim, but there is a need for evaluation of human relevance and
understandability of explanations. Our work contributes a novel methodology for
evaluating the quality or human interpretability of explanations for machine
learning models. We present an evaluation benchmark for instance explanations
from text and image classifiers. The explanation meta-data in this benchmark is
generated from user annotations of image and text samples. We describe the
benchmark and demonstrate its utility by a quantitative evaluation on
explanations generated from a recent machine learning algorithm. This research
demonstrates how human-grounded evaluation could be used as a measure to
qualify local machine-learning explanations.
</dc:description>
 <dc:description>Comment: Benchmark Available online at
  https://github.com/SinaMohseni/ML-Interpretability-Evaluation-Benchmark</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05076</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytic Provenance Datasets: A Data Repository of Human Analysis
  Activity and Interaction Logs</dc:title>
 <dc:creator>Mohseni, Sina</dc:creator>
 <dc:creator>Pachuilo, Andrew</dc:creator>
 <dc:creator>Nirjhar, Ehsanul Haque</dc:creator>
 <dc:creator>Linder, Rhema</dc:creator>
 <dc:creator>Pena, Alyssa</dc:creator>
 <dc:creator>Ragan, Eric D.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We present an analytic provenance data repository that can be used to study
human analysis activity, thought processes, and software interaction with
visual analysis tools during exploratory data analysis. We conducted a series
of user studies involving exploratory data analysis scenario with textual and
cyber security data. Interactions logs, think-alouds, videos and all coded data
in this study are available online for research purposes. Analysis sessions are
segmented in multiple sub-task steps based on user think-alouds, video and
audios captured during the studies. These analytic provenance datasets can be
used for research involving tools and techniques for analyzing interaction logs
and analysis history. By providing high-quality coded data along with
interaction logs, it is possible to compare algorithmic data processing
techniques to the ground-truth records of analysis history.
</dc:description>
 <dc:description>Comment: Datasets are available online at
  https://research.arch.tamu.edu/analytic-provenance/datasets/ for research
  purposes</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05078</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Don't Look Back: Robustifying Place Categorization for Viewpoint- and
  Condition-Invariant Place Recognition</dc:title>
 <dc:creator>Garg, Sourav</dc:creator>
 <dc:creator>Suenderhauf, Niko</dc:creator>
 <dc:creator>Milford, Michael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  When a human drives a car along a road for the first time, they later
recognize where they are on the return journey typically without needing to
look in their rear-view mirror or turn around to look back, despite significant
viewpoint and appearance change. Such navigation capabilities are typically
attributed to our semantic visual understanding of the environment [1] beyond
geometry to recognizing the types of places we are passing through such as
&quot;passing a shop on the left&quot; or &quot;moving through a forested area&quot;. Humans are in
effect using place categorization [2] to perform specific place recognition
even when the viewpoint is 180 degrees reversed. Recent advances in deep neural
networks have enabled high-performance semantic understanding of visual places
and scenes, opening up the possibility of emulating what humans do. In this
work, we develop a novel methodology for using the semantics-aware higher-order
layers of deep neural networks for recognizing specific places from within a
reference database. To further improve the robustness to appearance change, we
develop a descriptor normalization scheme that builds on the success of
normalization schemes for pure appearance-based techniques such as SeqSLAM [3].
Using two different datasets - one road-based, one pedestrian-based, we
evaluate the performance of the system in performing place recognition on
reverse traversals of a route with a limited field of view camera and no
turn-back-and-look behaviours, and compare to existing state-of-the-art
techniques and vanilla off-the-shelf features. The results demonstrate
significant improvements over the existing state of the art, especially for
extreme perceptual challenges that involve both great viewpoint change and
environmental appearance change. We also provide experimental analyses of the
contributions of the various system components.
</dc:description>
 <dc:description>Comment: 9 pages, 11 figures, ICRA 2018</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05079</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One Way Function Candidate based on the Collatz Problem</dc:title>
 <dc:creator>Vuckovac, Rade</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>00-XX</dc:subject>
 <dc:description>  The one way function based on Collatz problem is proposed. While Colatz
($3x+1$) problem is well known and undecided, the proposal is actually based on
the problem's underlying conditional branching structure. The analysis shows
why the $3x+1$ problem is so difficult and how the algorithm conditional
branching structure can be used to construct an one way function.
</dc:description>
 <dc:description>Comment: 8 pages 1 figure</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05085</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Excuse me! Perception of Abrupt Direction Changes Using Body Cues and
  Paths on Mixed Reality Avatars</dc:title>
 <dc:creator>Katzakis, Nicholas</dc:creator>
 <dc:creator>Steinicke, Frank</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We evaluate two methods of signalling abrupt direction changes of a robotic
platform using a Mixed Reality avatar. The &quot;Body&quot; method uses gaze, gesture and
torso direction to point to upcoming waypoints. The &quot;Path&quot; method visualises
the change in direction using an angled path on the ground. We compare these
two methods using a controlled user study and show that each method has its
strengths depending on the situation. Overall the &quot;Path&quot; method was slightly
more accurate in communicating the direction change of the robot but
participants overall preferred the &quot;Body&quot; method.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05086</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous UAV Navigation Using Reinforcement Learning</dc:title>
 <dc:creator>Pham, Huy X.</dc:creator>
 <dc:creator>La, Hung M.</dc:creator>
 <dc:creator>Feil-Seifer, David</dc:creator>
 <dc:creator>Nguyen, Luan V.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Unmanned aerial vehicles (UAV) are commonly used for missions in unknown
environments, where an exact mathematical model of the environment may not be
available. This paper provides a framework for using reinforcement learning to
allow the UAV to navigate successfully in such environments. We conducted our
simulation and real implementation to show how the UAVs can successfully learn
to navigate through an unknown environment. Technical aspects regarding to
applying reinforcement learning algorithm to a UAV system and UAV flight
control were also addressed. This will enable continuing research using a UAV
with learning capabilities in more important applications, such as wildfire
monitoring, or search and rescue missions.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05088</identifier>
 <datestamp>2018-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time Road Traffic Information Detection Through Social Media</dc:title>
 <dc:creator>Khatri, Chandra</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>97R40</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In current study, a mechanism to extract traffic related information such as
congestion and incidents from textual data from the internet is proposed. The
current source of data is Twitter. As the data being considered is extremely
large in size automated models are developed to stream, download, and mine the
data in real-time. Furthermore, if any tweet has traffic related information
then the models should be able to infer and extract this data.
  Currently, the data is collected only for United States and a total of
120,000 geo-tagged traffic related tweets are extracted, while six million
geo-tagged non-traffic related tweets are retrieved and classification models
are trained. Furthermore, this data is used for various kinds of spatial and
temporal analysis. A mechanism to calculate level of traffic congestion,
safety, and traffic perception for cities in U.S. is proposed. Traffic
congestion and safety rankings for the various urban areas are obtained and
then they are statistically validated with existing widely adopted rankings.
Traffic perception depicts the attitude and perception of people towards the
traffic.
  It is also seen that traffic related data when visualized spatially and
temporally provides the same pattern as the actual traffic flows for various
urban areas. When visualized at the city level, it is clearly visible that the
flow of tweets is similar to flow of vehicles and that the traffic related
tweets are representative of traffic within the cities. With all the findings
in current study, it is shown that significant amount of traffic related
information can be extracted from Twitter and other sources on internet.
Furthermore, Twitter and these data sources are freely available and are not
bound by spatial and temporal limitations. That is, wherever there is a user
there is a potential for data.
</dc:description>
 <dc:description>Comment: 138 Pages, 21 Figures, 15 Tables. Masters Thesis in Computational
  Science &amp; Engineering Group @ Georgia Tech.
  https://smartech.gatech.edu/bitstream/handle/1853/53889/KHATRI-THESIS-2015.pdf.
  arXiv admin note: text overlap with arXiv:1703.03921 by other author</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05089</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reed-Muller Sequences for 5G Grant-free Massive Access</dc:title>
 <dc:creator>Zhang, Huazi</dc:creator>
 <dc:creator>Li, Rong</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:creator>Chen, Yan</dc:creator>
 <dc:creator>Zhang, Zhaoyang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose to use second order Reed-Muller (RM) sequence for user
identification in 5G grant-free access. The benefits of RM sequences mainly lie
in two folds, (i) support of much larger user space, hence lower collision
probability and (ii) lower detection complexity. These two features are
essential to meet the massive connectivity ($10^7$ links/km$^2$),
ultra-reliable and low-latency requirements in 5G, e.g., one-shot transmission
($\leq 1$ms) with $\leq 10^{-4}$ packet error rate. However, the
non-orthogonality introduced during sequence space expansion leads to worse
detection performance. In this paper, we propose a noise-resilient detection
algorithm along with a layered sequence construction to meet the harsh
requirements. Link-level simulations in both narrow-band and OFDM-based
scenarios show that RM sequences are suitable for 5G.
</dc:description>
 <dc:description>Comment: The paper has been accepted by IEEE Globecom 2017</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05091</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis</dc:title>
 <dc:creator>Hong, Seunghoon</dc:creator>
 <dc:creator>Yang, Dingdong</dc:creator>
 <dc:creator>Choi, Jongwook</dc:creator>
 <dc:creator>Lee, Honglak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel hierarchical approach for text-to-image synthesis by
inferring semantic layout. Instead of learning a direct mapping from text to
image, our algorithm decomposes the generation process into multiple steps, in
which it first constructs a semantic layout from the text by the layout
generator and converts the layout to an image by the image generator. The
proposed layout generator progressively constructs a semantic layout in a
coarse-to-fine manner by generating object bounding boxes and refining each box
by estimating object shapes inside the box. The image generator synthesizes an
image conditioned on the inferred semantic layout, which provides a useful
semantic structure of an image matching with the text description. Our model
not only generates semantically more meaningful images, but also allows
automatic annotation of generated images and user-controlled generation process
by modifying the generated scene layout. We demonstrate the capability of the
proposed model on challenging MS-COCO dataset and show that the model can
substantially improve the image quality, interpretability of output and
semantic alignment to input text over existing approaches.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05095</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Analysis of Puncturing for Finite-Length Polar Codes: Boolean
  Function Approach</dc:title>
 <dc:creator>Hong, Song-Nam</dc:creator>
 <dc:creator>Hui, Dennis</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the impact of puncturing on finite-length polar codes
in which a puncturing pattern $\pv^{N}=(p_0,...,p_N)$ is applied to a
length-$N$ polar code.. We first introduce two virtual channels to
stochastically model the punctured (untransmitted) bits, which are respectively
called {\em useless channel model} (UCM) and {\em deterministic channel model}
(DCM). Under each model, we derive boolean functions in variables
$p_0,...,p_{N-1}$ that can indicate which polarized channels should carry
frozen bits. Based on this, we present an efficient method to jointly optimize
a puncturing pattern and an information set. Focusing on a fixed information
set, we show that there exist the so-called {\em catastrophic} puncturing
patterns that will surely lead to a block error and derive their weight
distributions recursively. We then propose the two construction methods of a
rate-compatible (RC) polar code which ensures that each puncturing pattern in
the family is non-catastrophic. Simulation results demonstrate that the
proposed RC polar code outperform the RC Turbo code adopted in LTE.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05096</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grounded Language Understanding for Manipulation Instructions Using
  GAN-Based Classification</dc:title>
 <dc:creator>Sugiura, Komei</dc:creator>
 <dc:creator>Kawai, Hisashi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The target task of this study is grounded language understanding for domestic
service robots (DSRs). In particular, we focus on instruction understanding for
short sentences where verbs are missing. This task is of critical importance to
build communicative DSRs because manipulation is essential for DSRs. Existing
instruction understanding methods usually estimate missing information only
from non-grounded knowledge; therefore, whether the predicted action is
physically executable or not was unclear.
  In this paper, we present a grounded instruction understanding method to
estimate appropriate objects given an instruction and situation. We extend the
Generative Adversarial Nets (GAN) and build a GAN-based classifier using latent
representations. To quantitatively evaluate the proposed method, we have
developed a data set based on the standard data set used for Visual QA.
Experimental results have shown that the proposed method gives the better
result than baseline methods.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, published at IEEE ASRU 2017</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05100</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plane-Casting: 3D Cursor Control with a SmartPhone</dc:title>
 <dc:creator>Katzakis, Nicholas</dc:creator>
 <dc:creator>Kiyokawa, Kiyoshi</dc:creator>
 <dc:creator>Hori, Masahiro</dc:creator>
 <dc:creator>Takemura, Haruo</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We present Plane-Casting, a novel technique for 3D object manipulation from a
distance that is especially suitable for smartphones. We describe two
variations of Plane-Casting, Pivot and Free Plane-Casting, and present results
from a pilot study. Results suggest that Pivot Plane-Casting is more suitable
for quick, coarse movements whereas Free Plane-Casting is more suited to
slower, precise motion. In a 3D movement task, Pivot Plane-Casting performed
better quantitatively, but subjects preferred Free Plane-Casting overall.
</dc:description>
 <dc:description>Comment: Proceedings of &quot;Touching the Third Dimension&quot; (3DCHI), Workshop at
  ACM SIGCHI Conference on Human Factors in Computing Systems</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05100</dc:identifier>
 <dc:identifier>Proceedings of &quot;The 3rd dimension of CHI (3DCHI): Touching and
  designing 3D user interfaces&quot; workshop at ACM SIGCHI Conference on Human
  Factors in Computing Systems 2012. Austin, TX. pp 13-21</dc:identifier>
 <dc:identifier>doi:10.1145/2212776.2212698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05101</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the I/O Costs of Some Repair Schemes for Full-Length Reed-Solomon
  Codes</dc:title>
 <dc:creator>Dau, Hoang</dc:creator>
 <dc:creator>Duursma, Iwan</dc:creator>
 <dc:creator>Chu, Hien</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Network transfer and disk read are the most time consuming operations in the
repair process for node failures in erasure-code-based distributed storage
systems. Recent developments on Reed-Solomon codes, the most widely used
erasure codes in practical storage systems, have shown that efficient repair
schemes specifically tailored to these codes can significantly reduce the
network bandwidth spent to recover single failures. However, the I/O cost, that
is, the number of disk reads performed in these repair schemes remains largely
unknown. We take the first step to address this gap in the literature by
investigating the I/O costs of some existing repair schemes for full-length
Reed-Solomon codes.
</dc:description>
 <dc:description>Comment: Submitted to the ISIT'18</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05104</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput Maximization in Cloud Radio Access Networks using Network
  Coding</dc:title>
 <dc:creator>Al-Abiad, Mohammed S.</dc:creator>
 <dc:creator>Douik, Ahmed</dc:creator>
 <dc:creator>Sorour, Sameh</dc:creator>
 <dc:creator>Hossain, MD Jahangir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper is interested in maximizing the total throughput of cloud radio
access networks (CRANs) in which multiple radio remote heads (RRHs) are
connected to a central computing unit known as the cloud. The transmit frame of
each RRH consists of multiple radio resources blocks (RRBs), and the cloud is
responsible for synchronizing these RRBS and scheduling them to users. Unlike
previous works that consider allocating each RRB to only a single user at each
time instance, this paper proposes to mix the flows of multiple users in each
RRB using instantly decodable network coding (IDNC). The proposed scheme is
thus designed to jointly schedule the users to different RRBs, choose the
encoded file sent in each of them, and the rate at which each of them is
transmitted. Hence, the paper maximizes the throughput which is defined as the
number of correctly received bits. To jointly fulfill this objective, we design
a graph in which each vertex represents a possible user-RRB association,
encoded file, and transmission rate. By appropriately choosing the weights of
vertices, the scheduling problem is shown to be equivalent to a maximum weight
clique problem over the newly introduced graph. Simulation results illustrate
the significant gains of the proposed scheme compared to classical coding and
uncoded solutions.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05112</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Error and Erasure Exponents for the Asymmetric Broadcast Channel</dc:title>
 <dc:creator>Cao, Daming</dc:creator>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We derive exact (ensemble-tight) error and erasure exponents for the
asymmetric broadcast channel given a random superposition codebook. We consider
Forney's optimal decoder for both messages and the message pair for the
receiver that decodes both messages. We prove that the optimal decoder designed
to decode the pair of messages achieves the optimal trade-off between the total
and undetected exponents associated with the optimal decoder for the private
message. We propose convex optimization-based procedures to evaluate the
exponents efficiently. Numerical examples are presented to illustrate the
results.
</dc:description>
 <dc:description>Comment: Abridged version submitted to ISIT 2018</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05114</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Reed-Muller codes over Galois rings</dc:title>
 <dc:creator>Andriatahiny, Harinaivo</dc:creator>
 <dc:creator>Ratahirinjatovo, Desir&#xe9; Ars&#xe8;ne</dc:creator>
 <dc:creator>Andrianalisefa, Sanni Jos&#xe9;</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B05, 94B15, 12E05</dc:subject>
 <dc:description>  Recently, Bhaintwal and Wasan studied the Generalized Reed-Muller codes over
the prime power integer residue ring. In this paper, we give a generalization
of these codes to Generalized Reed-Muller codes over Galois rings.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05117</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reblur2Deblur: Deblurring Videos via Self-Supervised Learning</dc:title>
 <dc:creator>Chen, Huaijin</dc:creator>
 <dc:creator>Gu, Jinwei</dc:creator>
 <dc:creator>Gallo, Orazio</dc:creator>
 <dc:creator>Liu, Ming-Yu</dc:creator>
 <dc:creator>Veeraraghavan, Ashok</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Motion blur is a fundamental problem in computer vision as it impacts image
quality and hinders inference. Traditional deblurring algorithms leverage the
physics of the image formation model and use hand-crafted priors: they usually
produce results that better reflect the underlying scene, but present
artifacts. Recent learning-based methods implicitly extract the distribution of
natural images directly from the data and use it to synthesize plausible
images. Their results are impressive, but they are not always faithful to the
content of the latent image. We present an approach that bridges the two. Our
method fine-tunes existing deblurring neural networks in a self-supervised
fashion by enforcing that the output, when blurred based on the optical flow
between subsequent frames, matches the input blurry image. We show that our
method significantly improves the performance of existing methods on several
datasets both visually and in terms of image quality metrics. The supplementary
material is https://goo.gl/nYPjEQ
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05119</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Recurrent Neural Machine Translation</dc:title>
 <dc:creator>Su, Jinsong</dc:creator>
 <dc:creator>Wu, Shan</dc:creator>
 <dc:creator>Xiong, Deyi</dc:creator>
 <dc:creator>Lu, Yaojie</dc:creator>
 <dc:creator>Han, Xianpei</dc:creator>
 <dc:creator>Zhang, Biao</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Partially inspired by successful applications of variational recurrent neural
networks, we propose a novel variational recurrent neural machine translation
(VRNMT) model in this paper. Different from the variational NMT, VRNMT
introduces a series of latent random variables to model the translation
procedure of a sentence in a generative way, instead of a single latent
variable. Specifically, the latent random variables are included into the
hidden states of the NMT decoder with elements from the variational
autoencoder. In this way, these variables are recurrently generated, which
enables them to further capture strong and complex dependencies among the
output translations at different timesteps. In order to deal with the
challenges in performing efficient posterior inference and large-scale training
during the incorporation of latent variables, we build a neural posterior
approximator, and equip it with a reparameterization technique to estimate the
variational lower bound. Experiments on Chinese-English and English-German
translation tasks demonstrate that the proposed model achieves significant
improvements over both the conventional and variational NMT models.
</dc:description>
 <dc:description>Comment: accepted by AAAI 18</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05122</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Bidirectional Decoding for Neural Machine Translation</dc:title>
 <dc:creator>Zhang, Xiangwen</dc:creator>
 <dc:creator>Su, Jinsong</dc:creator>
 <dc:creator>Qin, Yue</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Ji, Rongrong</dc:creator>
 <dc:creator>Wang, Hongji</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The dominant neural machine translation (NMT) models apply unified
attentional encoder-decoder neural networks for translation. Traditionally, the
NMT decoders adopt recurrent neural networks (RNNs) to perform translation in a
left-toright manner, leaving the target-side contexts generated from right to
left unexploited during translation. In this paper, we equip the conventional
attentional encoder-decoder NMT framework with a backward decoder, in order to
explore bidirectional decoding for NMT. Attending to the hidden state sequence
produced by the encoder, our backward decoder first learns to generate the
target-side hidden state sequence from right to left. Then, the forward decoder
performs translation in the forward direction, while in each translation
prediction timestep, it simultaneously applies two attention models to consider
the source-side and reverse target-side hidden states, respectively. With this
new architecture, our model is able to fully exploit source- and target-side
contexts to improve translation quality altogether. Experimental results on
NIST Chinese-English and WMT English-German translation tasks demonstrate that
our model achieves substantial improvements over the conventional NMT by 3.14
and 1.38 BLEU points, respectively. The source code of this work can be
obtained from https://github.com/DeepLearnXMU/ABDNMT.
</dc:description>
 <dc:description>Comment: accepted by AAAI 18</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05124</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization-Aware Active Learning for Object Detection</dc:title>
 <dc:creator>Kao, Chieh-Chi</dc:creator>
 <dc:creator>Lee, Teng-Yok</dc:creator>
 <dc:creator>Sen, Pradeep</dc:creator>
 <dc:creator>Liu, Ming-Yu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Active learning - a class of algorithms that iteratively searches for the
most informative samples to include in a training dataset - has been shown to
be effective at annotating data for image classification. However, the use of
active learning for object detection is still largely unexplored as determining
informativeness of an object-location hypothesis is more difficult. In this
paper, we address this issue and present two metrics for measuring the
informativeness of an object hypothesis, which allow us to leverage active
learning to reduce the amount of annotated data needed to achieve a target
object detection performance. Our first metric measures 'localization
tightness' of an object hypothesis, which is based on the overlapping ratio
between the region proposal and the final prediction. Our second metric
measures 'localization stability' of an object hypothesis, which is based on
the variation of predicted object locations when input images are corrupted by
noise. Our experimental results show that by augmenting a conventional
active-learning algorithm designed for classification with the proposed
metrics, the amount of labeled training data required can be reduced up to 25%.
Moreover, on PASCAL 2007 and 2012 datasets our localization-stability method
has an average relative improvement of 96.5% and 81.9% over the baseline method
using classification only.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05127</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Round- and Message-Optimal Distributed Part-Wise Aggregation</dc:title>
 <dc:creator>Haeupler, Bernhard</dc:creator>
 <dc:creator>Hershkowitz, D. Ellis</dc:creator>
 <dc:creator>Wajc, David</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Distributed graph algorithms that separately optimize for either the number
of rounds used or the total number of messages sent have been studied
extensively. However, algorithms simultaneously efficient with respect to both
measures have been elusive for a long time. For example, only very recently was
it shown that for Minimum Spanning Tree (MST), an optimal message and round
complexity is achievable (up to polylog terms) by a single algorithm in the
CONGEST model of communication.
  In this paper we provide algorithms that are simultaneously round-optimal
with near-linear message complexities for a number of well-studied distributed
optimization problems. Our algorithmic centerpiece is such a distributed
algorithm that solves what we dub Part-Wise Aggregation: computing simple
functions over each part of a graph partition. From this algorithm we derive
round-optimal algorithms for MST, Approximate Min-Cut and Approximate Single
Source Shortest Paths (SSSP), all with $\tilde{O}(m)$ message complexities. On
general graphs all of our algorithms achieve a worst-case optimal
$\tilde{O}(D+\sqrt n)$ round complexities and $\tilde{O}(m)$ message
complexities.
  Furthermore, our algorithms require even fewer rounds on many widely-studied
classes of graphs, namely planar, genus-bounded, treewidth-bounded and
pathwidth-bounded graphs. For these graphs our algorithms require an optimal
$\tilde{O}(D)$ rounds and $\tilde{O}(m)$ messages. Our results are the first
instance of distributed algorithms with $\tilde{O}(m)$ message complexities for
Approximate Min-Cut and Approximate SSSP. Moreover, our algorithms are the
first algorithms for any of these problems that beat the general graph round
lower bound of $\tilde{\Omega}(D + \sqrt{n})$ on graph families of interest and
simultaneously achieve an $\tilde{O}(m)$ message complexity.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05132</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Navigate: Exploiting Deep Networks to Inform Sample-Based
  Planning During Vision-Based Navigation</dc:title>
 <dc:creator>Smith, Justin S.</dc:creator>
 <dc:creator>Hwang, Jin-Ha</dc:creator>
 <dc:creator>Chu, Fu-Jen</dc:creator>
 <dc:creator>Vela, Patricio A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Recent applications of deep learning to navigation have generated end-to-end
navigation solutions whereby visual sensor input is mapped to control signals
or to motion primitives. The resulting visual navigation strategies work very
well at collision avoidance and have performance that matches traditional
reactive navigation algorithms while operating in real-time. It is accepted
that these solutions cannot provide the same level of performance as a global
planner. However, it is less clear how such end-to-end systems should be
integrated into a full navigation pipeline. We evaluate the typical end-to-end
solution within a full navigation pipeline in order to expose its weaknesses.
Doing so illuminates how to better integrate deep learning methods into the
navigation pipeline. In particular, we show that they are an efficient means to
provide informed samples for sample-based planners. Controlled simulations with
comparison against traditional planners show that the number of samples can be
reduced by an order of magnitude while preserving navigation performance.
Implementation on a mobile robot matches the simulated performance outcomes.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05134</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding the Disharmony between Dropout and Batch Normalization by
  Variance Shift</dc:title>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Chen, Shuo</dc:creator>
 <dc:creator>Hu, Xiaolin</dc:creator>
 <dc:creator>Yang, Jian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper first answers the question &quot;why do the two most powerful
techniques Dropout and Batch Normalization (BN) often lead to a worse
performance when they are combined together?&quot; in both theoretical and
statistical aspects. Theoretically, we find that Dropout would shift the
variance of a specific neural unit when we transfer the state of that network
from train to test. However, BN would maintain its statistical variance, which
is accumulated from the entire learning procedure, in the test phase. The
inconsistency of that variance (we name this scheme as &quot;variance shift&quot;) causes
the unstable numerical behavior in inference that leads to more erroneous
predictions finally, when applying Dropout before BN. Thorough experiments on
DenseNet, ResNet, ResNeXt and Wide ResNet confirm our findings. According to
the uncovered mechanism, we next explore several strategies that modifies
Dropout and try to overcome the limitations of their combination by avoiding
the variance shift risks.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05135</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stabilizing Unstable Periodic Orbits with Delayed Feedback Control in
  Act-and-Wait Fashion</dc:title>
 <dc:creator>Cetinkaya, Ahmet</dc:creator>
 <dc:creator>Hayakawa, Tomohisa</dc:creator>
 <dc:creator>Taib, Mohd Amir Fikri bin Mohd</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A delayed feedback control framework for stabilizing unstable periodic orbits
of linear periodic time-varying systems is proposed. In this framework,
act-and-wait approach is utilized for switching a delayed feedback controller
on and off alternately at every integer multiples of the period of the system.
By analyzing the monodromy matrix of the closed-loop system, we obtain
conditions under which the closed-loop system's state converges towards a
periodic solution under our proposed control law. We discuss the application of
our results in stabilization of unstable periodic orbits of nonlinear systems
and present numerical examples to illustrate the efficacy of our approach.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05141</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image denoising and restoration with CNN-LSTM Encoder Decoder with
  Direct Attention</dc:title>
 <dc:creator>Haque, Kazi Nazmul</dc:creator>
 <dc:creator>Yousuf, Mohammad Abu</dc:creator>
 <dc:creator>Rana, Rajib</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image denoising is always a challenging task in the field of computer vision
and image processing. In this paper, we have proposed an encoder-decoder model
with direct attention, which is capable of denoising and reconstruct highly
corrupted images. Our model consists of an encoder and a decoder, where the
encoder is a convolutional neural network and decoder is a multilayer Long
Short-Term memory network. In the proposed model, the encoder reads an image
and catches the abstraction of that image in a vector, where decoder takes that
vector as well as the corrupted image to reconstruct a clean image. We have
trained our model on MNIST handwritten digit database after making lower half
of every image as black as well as adding noise top of that. After a massive
destruction of the images where it is hard for a human to understand the
content of those images, our model can retrieve that image with minimal error.
Our proposed model has been compared with convolutional encoder-decoder, where
our model has performed better at generating missing part of the images than
convolutional autoencoder.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05143</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Accurate and Real-time Self-blast Glass Insulator Location Method
  Based On Faster R-CNN and U-net with Aerial Images</dc:title>
 <dc:creator>Ling, Zenan</dc:creator>
 <dc:creator>Qiu, Robert C.</dc:creator>
 <dc:creator>Jin, Zhijian</dc:creator>
 <dc:creator>Zhang, Yuhang</dc:creator>
 <dc:creator>He, Xing</dc:creator>
 <dc:creator>Liu, Haichun</dc:creator>
 <dc:creator>Chu, Lei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The location of broken insulators in aerial images is a challenging task.
This paper, focusing on the self-blast glass insulator, proposes a deep
learning solution. We address the broken insulators location problem as a low
signal-noise-ratio image location framework with two modules: 1) object
detection based on Fast R-CNN, and 2) classification of pixels based on U-net.
A diverse aerial image set of some grid in China is tested to validated the
proposed approach. Furthermore, a comparison is made among different methods
and the result shows that our approach is accurate and real-time.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05147</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Learning for Chinese NER from Crowd Annotations</dc:title>
 <dc:creator>Yang, YaoSheng</dc:creator>
 <dc:creator>Zhang, Meishan</dc:creator>
 <dc:creator>Chen, Wenliang</dc:creator>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Wang, Haofen</dc:creator>
 <dc:creator>Zhang, Min</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  To quickly obtain new labeled data, we can choose crowdsourcing as an
alternative way at lower cost in a short time. But as an exchange, crowd
annotations from non-experts may be of lower quality than those from experts.
In this paper, we propose an approach to performing crowd annotation learning
for Chinese Named Entity Recognition (NER) to make full use of the noisy
sequence labels from multiple annotators. Inspired by adversarial learning, our
approach uses a common Bi-LSTM and a private Bi-LSTM for representing
annotator-generic and -specific information. The annotator-generic information
is the common knowledge for entities easily mastered by the crowd. Finally, we
build our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we
create two data sets for Chinese NER tasks from two domains. The experimental
results show that our system achieves better scores than strong baseline
systems.
</dc:description>
 <dc:description>Comment: 8 pages, AAAI-2018</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05149</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OneNet: Joint Domain, Intent, Slot Prediction for Spoken Language
  Understanding</dc:title>
 <dc:creator>Kim, Young-Bum</dc:creator>
 <dc:creator>Lee, Sungjin</dc:creator>
 <dc:creator>Stratos, Karl</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In practice, most spoken language understanding systems process user input in
a pipelined manner; first domain is predicted, then intent and semantic slots
are inferred according to the semantic frames of the predicted domain. The
pipeline approach, however, has some disadvantages: error propagation and lack
of information sharing. To address these issues, we present a unified neural
network that jointly performs domain, intent, and slot predictions. Our
approach adopts a principled architecture for multitask learning to fold in the
state-of-the-art models for each task. With a few more ingredients, e.g.
orthography-sensitive input encoding and curriculum training, our model
delivered significant improvements in all three tasks across all domains over
strong baselines, including one using oracle prediction for domain detection,
on real user data of a commercial personal assistant.
</dc:description>
 <dc:description>Comment: 5 pages conference paper accepted to IEEE ASRU 2017. Will be
  published in December 2017</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05150</identifier>
 <datestamp>2018-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the characterization of models of H* : The operational aspect</dc:title>
 <dc:creator>Breuvart, Flavien</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We give a characterization, with respect to a large class of models of
untyped $\lambda$-calculus, of those models that are fully abstract for
head-normalization, i.e., whose equational theory is $\mathcal{H}^*$. An
extensional K-model $D$ is fully abstract if and only if it is hyperimmune,
i.e., non-well founded chains of elements of $D$ cannot be captured by any
recursive function.
  This article share its first title with its companion paper and a short
version. It is a standalone paper that present a purely syntactical proof of
the result as opposed to its companion paper that present an independent and
purely semantical proof of the exact same result.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1603.07259</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05151</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraint-free Natural Image Reconstruction from fMRI Signals Based on
  Convolutional Neural Network</dc:title>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:creator>Qiao, Kai</dc:creator>
 <dc:creator>Wang, Linyuan</dc:creator>
 <dc:creator>Tong, Li</dc:creator>
 <dc:creator>Zeng, Ying</dc:creator>
 <dc:creator>Yan, Bin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  In recent years, research on decoding brain activity based on functional
magnetic resonance imaging (fMRI) has made remarkable achievements. However,
constraint-free natural image reconstruction from brain activity is still a
challenge. The existing methods simplified the problem by using semantic prior
information or just reconstructing simple images such as letters and digitals.
Without semantic prior information, we present a novel method to reconstruct
nature images from fMRI signals of human visual cortex based on the computation
model of convolutional neural network (CNN). Firstly, we extracted the units
output of viewed natural images in each layer of a pre-trained CNN as CNN
features. Secondly, we transformed image reconstruction from fMRI signals into
the problem of CNN feature visualizations by training a sparse linear
regression to map from the fMRI patterns to CNN features. By iteratively
optimization to find the matched image, whose CNN unit features become most
similar to those predicted from the brain activity, we finally achieved the
promising results for the challenging constraint-free natural image
reconstruction. As there was no use of semantic prior information of the
stimuli when training decoding model, any category of images (not constraint by
the training set) could be reconstructed theoretically. We found that the
reconstructed images resembled the natural stimuli, especially in position and
shape. The experimental results suggest that hierarchical visual features can
effectively express the visual perception process of human brain.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05153</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refining Properties of Filter Models: Sensibility, Approximability and
  Reducibility</dc:title>
 <dc:creator>Breuvart, Flavien</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this paper, we study the tedious link between the properties of
sensibility and approximability of models of untyped {\lambda}-calculus.
Approximability is known to be a slightly, but strictly stronger property that
sensibility. However, we will see that so far, each and every (filter) model
that have been proven sensible are in fact approximable. We explain this result
as a weakness of the sole known approach of sensibility: the Tait reducibility
candidates and its realizability variants. In fact, we will reduce the
approximability of a filter model D for the {\lambda}-calculus to the
sensibility of D but for an extension of the {\lambda}-calculus that we call
{\lambda}-calculus with D-tests. Then we show that traditional proofs of
sensibility of D for the {\lambda}-calculus are smoothly extendable for this
{\lambda}-calculus with D-tests.
</dc:description>
 <dc:description>Comment: long version, draft</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05156</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical Explorations in Training Networks with Discrete Activations</dc:title>
 <dc:creator>Baluja, Shumeet</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present extensive experiments training and testing hidden units in deep
networks that emit only a predefined, static, number of discretized values.
These units provide benefits in real-world deployment in systems in which
memory and/or computation may be limited. Additionally, they are particularly
well suited for use in large recurrent network models that require the
maintenance of large amounts of internal state in memory. Surprisingly, we find
that despite reducing the number of values that can be represented in the
output activations from $2^{32}-2^{64}$ to between 64 and 256, there is little
to no degradation in network performance across a variety of different
settings. We investigate simple classification and regression tasks, as well as
memorization and compression problems. We compare the results with more
standard activations, such as tanh and relu. Unlike previous discretization
studies which often concentrate only on binary units, we examine the effects of
varying the number of allowed activation levels. Compared to existing
approaches for discretization, the approach presented here is both conceptually
and programatically simple, has no stochastic component, and allows the
training, testing, and usage phases to be treated in exactly the same manner.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05159</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GitGraph - Architecture Search Space Creation through Frequent
  Computational Subgraph Mining</dc:title>
 <dc:creator>Bennani-Smires, Kamil</dc:creator>
 <dc:creator>Musat, Claudiu</dc:creator>
 <dc:creator>Hossmann, Andreea</dc:creator>
 <dc:creator>Baeriswyl, Michael</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The dramatic success of deep neural networks across multiple application
areas often relies on experts painstakingly designing a network architecture
specific to each task. To simplify this process and make it more accessible, an
emerging research effort seeks to automate the design of neural network
architectures, using e.g. evolutionary algorithms or reinforcement learning or
simple search in a constrained space of neural modules.
  Considering the typical size of the search space (e.g. $10^{10}$ candidates
for a $10$-layer network) and the cost of evaluating a single candidate,
current architecture search methods are very restricted. They either rely on
static pre-built modules to be recombined for the task at hand, or they define
a static hand-crafted framework within which they can generate new
architectures from the simplest possible operations.
  In this paper, we relax these restrictions, by capitalizing on the collective
wisdom contained in the plethora of neural networks published in online code
repositories. Concretely, we (a) extract and publish GitGraph, a corpus of
neural architectures and their descriptions; (b) we create problem-specific
neural architecture search spaces, implemented as a textual search mechanism
over GitGraph; (c) we propose a method of identifying unique common subgraphs
within the architectures solving each problem (e.g., image processing,
reinforcement learning), that can then serve as modules in the newly created
problem specific neural search space.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05161</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Integration-Oriented Ontology to Govern Evolution in Big Data
  Ecosystems</dc:title>
 <dc:creator>Nadal, Sergi</dc:creator>
 <dc:creator>Romero, Oscar</dc:creator>
 <dc:creator>Abell&#xf3;, Alberto</dc:creator>
 <dc:creator>Vassiliadis, Panos</dc:creator>
 <dc:creator>Vansummeren, Stijn</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Big Data architectures allow to flexibly store and process heterogeneous
data, from multiple sources, in their original format. The structure of those
data, commonly supplied by means of REST APIs, is continuously evolving. Thus
data analysts need to adapt their analytical processes after each API release.
This gets more challenging when performing an integrated or historical
analysis. To cope with such complexity, in this paper, we present the Big Data
Integration ontology, the core construct to govern the data integration process
under schema evolution by systematically annotating it with information
regarding the schema of the sources. We present a query rewriting algorithm
that, using the annotated ontology, converts queries posed over the ontology to
queries over the sources. To cope with syntactic evolution in the sources, we
present an algorithm that semi-automatically adapts the ontology upon new
releases. This guarantees ontology-mediated queries to correctly retrieve data
from the most recent schema version as well as correctness in historical
queries. A functional and performance evaluation on real-world APIs is
performed to validate our approach.
</dc:description>
 <dc:description>Comment: Preprint submitted to Information Systems. 35 pages</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05164</identifier>
 <datestamp>2018-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedding a $\theta$-invariant code into a complete one</dc:title>
 <dc:creator>N&#xe9;raud, Jean</dc:creator>
 <dc:creator>Selmi, Carla</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Let A be a finite or countable alphabet and let $\theta$ be a literal
(anti)morphism onto A * (by definition, such a correspondence is determinated
by a permutation of the alphabet). This paper deals with sets which are
invariant under $\theta$ ($\theta$-invariant for short). We establish a formula
which allows to embed any non-complete $\theta$-invariant code into a complete
one: this brings a positive answer to the open question that was stated in
[[N{\'e}raud J. and Selmi C. Invariance: a theoretical approach for coding sets
of words modulo literal (anti)morphisms. In S. Brlek, F. Dolce, C. Reutenauer,
and E. Vandomme, editors, Combinatorics on Words, volume 10432, pages 214-227.
Lect. Notes in Comp. Sci., sept 2017].
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1705.05564</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05168</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A First Look at QUIC in the Wild</dc:title>
 <dc:creator>R&#xfc;th, Jan</dc:creator>
 <dc:creator>Poese, Ingmar</dc:creator>
 <dc:creator>Dietzel, Christoph</dc:creator>
 <dc:creator>Hohlfeld, Oliver</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  For the first time since the establishment of TCP and UDP, the Internet
transport layer is subject to a major change by the introduction of QUIC.
Initiated by Google in 2012, QUIC provides a reliable, connection-oriented
low-latency and fully encrypted transport. In this paper, we provide the first
broad assessment of QUIC usage in the wild. We monitor the entire IPv4 address
space since August 2016 and about 46% of the DNS namespace to detected
QUIC-capable infrastructures. Our scans show that the number of QUIC-capable
IPs has more than tripled since then to over 617.59 K. We find around 161K
domains hosted on QUIC-enabled infrastructure, but only 15K of them present
valid certificates over QUIC. Second, we analyze one year of traffic traces
provided by MAWI, one day of a major European tier-1 ISP and from a large IXP
to understand the dominance of QUIC in the Internet traffic mix. We find QUIC
to account for 2.6% to 9.1% of the current Internet traffic, depending on the
vantage point. This share is dominated by Google pushing up to 42.1% of its
traffic via QUIC.
</dc:description>
 <dc:description>Comment: Passive Active Measurements Conference (PAM) 2018</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05171</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Multi-Spectral Registration Using Invariant Descriptor Learning</dc:title>
 <dc:creator>Ofir, Nati</dc:creator>
 <dc:creator>Silberstein, Shai</dc:creator>
 <dc:creator>Rozenbaum, Dani</dc:creator>
 <dc:creator>Bar, Sharon Duvdevani</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we introduce a novel deep-learning method to align
cross-spectral images. Our approach relies on a learned descriptor which is
invariant to different spectra. Multi-modal images of the same scene capture
different signals and therefore their registration is challenging and it is not
solved by classic approaches. To that end, we developed a feature-based
approach that solves the visible (VIS) to Near-Infra-Red (NIR) registration
problem. Our algorithm detects corners by Harris and matches them by a
patch-metric learned on top of CIFAR-10 network descriptor. As our experiments
demonstrate we achieve a high-quality alignment of cross-spectral images with a
sub-pixel accuracy. Comparing to other existing methods, our approach is more
accurate in the task of VIS to NIR registration.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05173</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Convolutional Multi-scale Residual DenseNets for Cardiac
  Segmentation and Automated Cardiac Diagnosis using Ensemble of Classifiers</dc:title>
 <dc:creator>Khened, Mahendra</dc:creator>
 <dc:creator>Kollerathu, Varghese Alex</dc:creator>
 <dc:creator>Krishnamurthi, Ganapathy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep fully convolutional neural network (FCN) based architectures have shown
great potential in medical image segmentation. However, such architectures
usually have millions of parameters and inadequate number of training samples
leading to over-fitting and poor generalization. In this paper, we present a
novel highly parameter and memory efficient FCN based architecture for medical
image analysis. We propose a novel up-sampling path which incorporates long
skip and short-cut connections to overcome the feature map explosion in FCN
like architectures. In order to processes the input images at multiple scales
and view points simultaneously, we propose to incorporate Inception module's
parallel structures. We also propose a novel dual loss function whose weighting
scheme allows to combine advantages of cross-entropy and dice loss. We have
validated our proposed network architecture on two publicly available datasets,
namely: (i) Automated Cardiac Disease Diagnosis Challenge (ACDC-2017), (ii)
Left Ventricular Segmentation Challenge (LV-2011). Our approach in ACDC-2017
challenge stands second place for segmentation and first place in automated
cardiac disease diagnosis tasks with an accuracy of 100%. In the LV-2011
challenge our approach attained 0.74 Jaccard index, which is so far the highest
published result in fully automated algorithms. From the segmentation we
extracted clinically relevant cardiac parameters and hand-crafted features
which reflected the clinical diagnostic analysis to train an ensemble system
for cardiac disease classification. Our approach combined both cardiac
segmentation and disease diagnosis into a fully automated framework which is
computational efficient and hence has the potential to be incorporated in
computer-aided diagnosis (CAD) tools for clinical application.
</dc:description>
 <dc:description>Comment: 59 Pages, 21 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05178</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inter-thread Communication in Multithreaded, Reconfigurable Coarse-grain
  Arrays</dc:title>
 <dc:creator>Voitsechov, Dani</dc:creator>
 <dc:creator>Etsion, Yoav</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Traditional von Neumann GPGPUs only allow threads to communicate through
memory on a group-to-group basis. In this model, a group of producer threads
writes intermediate values to memory, which are read by a group of consumer
threads after a barrier synchronization. To alleviate the memory bandwidth
imposed by this method of communication, GPGPUs provide a small scratchpad
memory that prevents intermediate values from overloading DRAM bandwidth. In
this paper we introduce direct inter-thread communications for massively
multithreaded CGRAs, where intermediate values are communicated directly
through the compute fabric on a point-to-point basis. This method avoids the
need to write values to memory, eliminates the need for a dedicated scratchpad,
and avoids workgroup-global barriers. The paper introduces the programming
model (CUDA) and execution model extensions, as well as the hardware primitives
that facilitate the communication. Our simulations of Rodinia benchmarks
running on the new system show that direct inter-thread communication provides
an average speedup of 4.5x (13.5x max) and reduces system power by an average
of 7x (33x max), when compared to an equivalent Nvidia GPGPU.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05189</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Kernel of $\mathbb{Z}_{2^s}$-Linear Hadamard Codes</dc:title>
 <dc:creator>Fern&#xe1;ndez-C&#xf3;rdoba, Cristina</dc:creator>
 <dc:creator>Vela, Carlos</dc:creator>
 <dc:creator>Villanueva, Merc&#xe8;</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B25 and 94B60</dc:subject>
 <dc:description>  The $\mathbb{Z}_{2^s}$-additive codes are subgroups of $\mathbb{Z}^n_{2^s}$,
and can be seen as a generalization of linear codes over $\mathbb{Z}_2$ and
$\mathbb{Z}_4$. A $\mathbb{Z}_{2^s}$-linear Hadamard code is a binary Hadamard
code which is the Gray map image of a $\mathbb{Z}_{2^s}$-additive code. It is
known that the dimension of the kernel can be used to give a complete
classification of the $\mathbb{Z}_4$-linear Hadamard codes. In this paper, the
kernel of $\mathbb{Z}_{2^s}$-linear Hadamard codes and its dimension are
established for $s &gt; 2$. Moreover, we prove that this invariant only provides a
complete classification for some values of $t$ and $s$. The exact amount of
nonequivalent such codes are given up to $t=11$ for any $s\geq 2$, by using
also the rank and, in some cases, further computations.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05194</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparsity Preserving Optimal Control of Discretized PDE Systems</dc:title>
 <dc:creator>Haber, Aleksandar</dc:creator>
 <dc:creator>Verhaegen, Michel</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  We focus on the problem of optimal control of large-scale systems whose
models are obtained by discretization of partial differential equations using
the Finite Element (FE) or Finite Difference (FD) methods. The motivation for
studying this pressing problem originates from the fact that the classical
numerical tools used to solve low-dimensional optimal control problems are
computationally infeasible for large-scale systems. Furthermore, although the
matrices of large-scale FE or FD models are usually sparse banded or highly
structured, the optimal control solution computed using the classical methods
is dense and unstructured. Consequently, it is not suitable for efficient
centralized and distributed real-time implementations. We show that the a
priori sparsity patterns of the exact solutions of the generalized Lyapunov
equations for FE and FD models are banded matrices. The a priori sparsity
pattern predicts the structure (non-zero entries) of the exact solution. We
furthermore show that for well-conditioned problems, the a priori sparsity
patterns are not only banded but also sparse matrices. On the basis of these
results, we develop two computationally efficient methods for computing sparse
approximate solutions of generalized Lyapunov equations. Using these two
methods and the inexact Newton method, we show that the solution of the
generalized Riccati equation can be approximated by a banded matrix. This
enables us to develop a novel computationally efficient optimal control
approach that is able to preserve the sparsity of the control law. We perform
extensive numerical experiments that demonstrate the effectiveness of our
approach.
</dc:description>
 <dc:description>Comment: 32 pages, 8 figures, conditionally accepted in Computer Methods in
  Applied Mechanics and Engineering</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05198</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why and How Java Developers Break APIs</dc:title>
 <dc:creator>Brito, Aline</dc:creator>
 <dc:creator>Xavier, Laerte</dc:creator>
 <dc:creator>Hora, Andre</dc:creator>
 <dc:creator>Valente, Marco Tulio</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Modern software development depends on APIs to reuse code and increase
productivity. As most software systems, these libraries and frameworks also
evolve, which may break existing clients. However, the main reasons to
introduce breaking changes in APIs are unclear. Therefore, in this paper, we
report the results of an almost 4-month long field study with the developers of
400 popular Java libraries and frameworks. We configured an infrastructure to
observe all changes in these libraries and to detect breaking changes shortly
after their introduction in the code. After identifying breaking changes, we
asked the developers to explain the reasons behind their decision to change the
APIs. During the study, we identified 59 breaking changes, confirmed by the
developers of 19 projects. By analyzing the developers' answers, we report that
breaking changes are mostly motivated by the need to implement new features, by
the desire to make the APIs simpler and with fewer elements, and to improve
maintainability. We conclude by providing suggestions to language designers,
tool builders, software engineering researchers and API developers.
</dc:description>
 <dc:description>Comment: Accepted at International Conference on Software Analysis, Evolution
  and Reengineering, SANER 2018; 11 pages</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05202</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower bounds for Combinatorial Algorithms for Boolean Matrix
  Multiplication</dc:title>
 <dc:creator>Das, Debarati</dc:creator>
 <dc:creator>Kouck&#xfd;, Michal</dc:creator>
 <dc:creator>Saks, Michael</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  In this paper we propose models of combinatorial algorithms for the Boolean
Matrix Multiplication (BMM), and prove lower bounds on computing BMM in these
models. First, we give a relatively relaxed combinatorial model which is an
extension of the model by Angluin (1976), and we prove that the time required
by any algorithm for the BMM is at least $\Omega(n^3 / 2^{O( \sqrt{ \log n
})})$. Subsequently, we propose a more general model capable of simulating the
&quot;Four Russians Algorithm&quot;. We prove a lower bound of $\Omega(n^{7/3} /
2^{O(\sqrt{ \log n })})$ for the BMM under this model. We use a special class
of graphs, called $(r,t)$-graphs, originally discovered by Rusza and Szemeredi
(1978), along with randomization, to construct matrices that are hard instances
for our combinatorial models.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05204</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Agent Neural Network for Dynamic Frequency Reuse in LTE Networks</dc:title>
 <dc:creator>Marinescu, Andrei</dc:creator>
 <dc:creator>Macaluso, Irene</dc:creator>
 <dc:creator>DaSilva, Luiz A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Fractional Frequency Reuse techniques can be employed to address interference
in mobile networks, improving throughput for edge users. There is a tradeoff
between the coverage and overall throughput achievable, as interference
avoidance techniques lead to a loss in a cell's overall throughput, with
spectrum efficiency decreasing with the fencing off of orthogonal resources. In
this paper we propose MANN, a dynamic multiagent frequency reuse scheme, where
individual agents in charge of cells control their configurations based on
input from neural networks. The agents' decisions are partially influenced by a
coordinator agent, which attempts to maximise a global metric of the network
(e.g., cell-edge performance). Each agent uses a neural network to estimate the
best action (i.e., cell configuration) for its current environment setup, and
attempts to maximise in turn a local metric, subject to the constraint imposed
by the coordinator agent. Results show that our solution provides improved
performance for edge users, increasing the throughput of the bottom 5% of users
by 22%, while retaining 95% of a network's overall throughput from the full
frequency reuse case. Furthermore, we show how our method improves on static
fractional frequency reuse schemes.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05206</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequences, yet Functions: The Dual Nature of Data-Stream Processing</dc:title>
 <dc:creator>Herbst, Sebastian</dc:creator>
 <dc:creator>Tenschert, Johannes</dc:creator>
 <dc:creator>Wahl, Andreas M.</dc:creator>
 <dc:creator>Meyer-Wegener, Klaus</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Data-stream processing has continuously risen in importance as the amount of
available data has been steadily increas- ing over the last decade. Besides
traditional domains such as data-center monitoring and click analytics, there
is an increasing number of network-enabled production machines that generate
continuous streams of data. Due to their continuous nature, queries on
data-streams can be more complex, and distinctly harder to understand then
database queries. As users have to consider operational details, maintenance
and debugging become challenging. Current approaches model data-streams as
sequences, be- cause this is the way they are physically received. These models
result in an implementation-focused perspective. We explore an alternate way of
modeling data-streams by focusing on time-slicing semantics. This focus results
in a model based on functions, which is better suited for reasoning about query
semantics. By adapting the definitions of relevant concepts in stream
processing to our model, we illustrate the practical useful- ness of our
approach. Thereby, we link data-streams and query primitives to concepts in
functional programming and mathematics. Most noteworthy, we prove that
data-streams are monads, and show how to derive monad definitions for current
data-stream models. We provide an abstract, yet practical perspective on data-
stream related subjects based on a sound, consistent query model. Our work can
serve as solid foundation for future data-stream query-languages.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05208</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The dynamically changing publication universe as a reference point in
  national impact evaluation: A counterfactual case study on the Chinese
  publication growth</dc:title>
 <dc:creator>Stahlschmidt, Stephan</dc:creator>
 <dc:creator>Hinze, Sybille</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  National bibliometric performance is commonly measured via relative impact
indicators which appraise absolute national values through a global
environment. Consequenty the resulting impact values mirror changes in the
national performance as well as in its embedding. In order to assess the
importance of the environment in this ratio, we analyse the increase in Chinese
publications as an example for a structural change altering the whole database.
Via a counterfactual comparison we quantify how Chinese publications benefit a
large set of countries on their impact values, identify explanatory factors and
describe the underelying mechanism due to longer reference lists and a
non-uniform citation distribution among recipient countries. We argue that such
structural changes in the environment have to be taken into account for an
unbiased measurement of national bibliometric performance.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05210</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Quality-Driven Scalable Video Transmission over Multi-User NOMA
  System</dc:title>
 <dc:creator>Jiang, Xiaoda</dc:creator>
 <dc:creator>Lu, Hancheng</dc:creator>
 <dc:creator>Chen, Chang Wen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Recently, non-orthogonal multiple access (NOMA) has been proposed to achieve
higher spectral efficiency over conventional orthogonal multiple access.
Although it has the potential to meet increasing demands of video services, it
is still challenging to provide high performance video streaming. In this
research, we investigate, for the first time, a multi-user NOMA system design
for video transmission. Various NOMA systems have been proposed for data
transmission in terms of throughput or reliability. However, the perceived
quality, or the quality-of-experience of users, is more critical for video
transmission. Based on this observation, we design a quality-driven scalable
video transmission framework with cross-layer support for multi-user NOMA. To
enable low complexity multi-user NOMA operations, a novel user grouping
strategy is proposed. The key features in the proposed framework include the
integration of the quality model for encoded video with the physical layer
model for NOMA transmission, and the formulation of multi-user NOMA-based video
transmission as a quality-driven power allocation problem. As the problem is
non-concave, a global optimal algorithm based on the hidden monotonic property
and a suboptimal algorithm with polynomial time complexity are developed.
Simulation results show that the proposed multi-user NOMA system outperforms
existing schemes in various video delivery scenarios.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures. This paper has already been accepted by IEEE
  INFOCOM 2018</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05212</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Analytic Method for SINS Attitude and Parameters Online Estimation</dc:title>
 <dc:creator>Chang, Lubin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this note, the attitude and inertial sensors drift biases estimation for
Strapdown inertial navigation system is investigated. A semi-analytic method is
proposed, which contains two interlaced solution procedures. Specifically, the
attitude encoding the body frame changes and gyroscopes drift biases are
estimated through attitude estimation while the attitude encoding the constant
value at the very start and accelerometers drift biases are determined through
online optimization.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05215</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trends in Processor Architecture</dc:title>
 <dc:creator>Gonzalez, Antonio</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  This paper presents an overview of the main trends in processor architecture.
It starts with an analysis of the past evolution of processors and the main
driving forces behind it, and then it focuses on a description of the main
architectural features of current processors. Finally, it presents a discussion
on some promising directions for future evolution of processor architectures.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05216</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual vibration configuration interaction (DVCI). A novel factorisation
  of molecular Hamiltonian for high performance infrared spectrum computation</dc:title>
 <dc:creator>Garnier, Romain</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Here is presented an original program based on molecular Schrodinger
equations. It is dedicated to target specific states of infrared vibrational
spectrum in a very precise way with a minimal usage of memory. An eigensolver
combined with a new probing technique accumulate information along the
iterations so that desired eigenpairs rapidly tend towards the variational
limit. Basis set is augmented from the maximal components of residual vectors
that usually require the construction of a big matrix block that here is
bypassed with a new factorisation of the Hamiltonian. The latest borrows the
mathematical concept of duality and the second quantization formalism of
quantum theory.
</dc:description>
 <dc:description>Comment: Minor corrections: diag(Hs) added on equation (14) page 6, hat on
  operator (16) page 6. Remark: harmonic functions refer here to quantum
  harmonic oscillators</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05224</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Device-to-Device Aided Multicasting</dc:title>
 <dc:creator>Santana, Thomas Varela</dc:creator>
 <dc:creator>Combes, Richard</dc:creator>
 <dc:creator>Kobayashi, Mari</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a device-to-device (D2D) aided multicast channel, where a
transmitter wishes to convey a common message to many receivers and these
receivers cooperate with each other. We propose a simple computationally
efficient scheme requiring only statistical channel knowledge at transmitter.
Our analysis in general topologies reveals that, when the number of receivers
$K$ grows to infinity, the proposed scheme guarantees a multicast rate of ${1
\over 2} \log_2(1 + \beta \ln K )$ with high probability for any $\beta &lt;
\beta^\star$ where $\beta^\star$ depends on the network topology. This scheme
undergoes a phase transition at threshold $\beta^\star \ln K$ where
transmissions are successful/unsuccessful with high probability when the SNR is
above/below this threshold. We also analyze the outage rate of the proposed
scheme in the same setting.
</dc:description>
 <dc:description>Comment: Technical report version of a paper submitted to ISIT 2018</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05225</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Homogenization of the fluid-saturated piezoelectric porous media</dc:title>
 <dc:creator>Rohan, Eduard</dc:creator>
 <dc:creator>Luke&#x161;, Vladim&#xed;r</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>74F10, 74F15, 35Q74</dc:subject>
 <dc:description>  The paper is devoted to the homogenization of porous piezoelectric materials
saturated by electrically inert fluid. The solid part of a representative
volume element consists of the piezoelectric skeleton with embedded conductors.
The pore fluid in the periodic structure can constitute a single connected
domain, or an array of inclusions. Also the conducting parts are represented by
several mutually separated connected domains, or by inclusions. Two of four
possible arrangements are considered for upscaling by the homogenization
method. The macroscopic model of the first type involves coefficients
responsible for interactions between the electric field and the pore pressure,
or the pore volume. For the second type, the electrodes can be used for
controlling the electric field at the pore level, so that the deformation and
the pore volume can be influenced locally. Effective constitutive coefficients
are computed using characteristic responses of the microstructure. The
two-scale modelling procedure is implemented numerically using the finite
element method. The macroscopic strain and electric fields are used to
reconstruct the corresponding local responses at the pore level. For validation
of the models, these are compared with results obtained by direct numerical
simulations of the heterogeneous structure; a good agreement is demonstrated,
showing relevance of the two-scale numerical modelling approach.
</dc:description>
 <dc:description>Comment: This manuscript version is made available under the CC-BY-NC-ND 4.0
  license</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05227</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Physical Layer Security Techniques for 5G Wireless Networks
  and Challenges Ahead</dc:title>
 <dc:creator>Wu, Yongpeng</dc:creator>
 <dc:creator>Khisti, Ashish</dc:creator>
 <dc:creator>Xiao, Chengshan</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:creator>Wong, Kai-Kit</dc:creator>
 <dc:creator>Gao, Xiqi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Physical layer security which safeguards data confidentiality based on the
information-theoretic approaches has received significant research interest
recently. The key idea behind physical layer security is to utilize the
intrinsic randomness of the transmission channel to guarantee the security in
physical layer. The evolution towards 5G wireless communications poses new
challenges for physical layer security research. This paper provides a latest
survey of the physical layer security research on various promising 5G
technologies, including physical layer security coding, massive multiple-input
multiple-output, millimeter wave communications, heterogeneous networks,
non-orthogonal multiple access, full duplex technology, etc. Technical
challenges which remain unresolved at the time of writing are summarized and
the future trends of physical layer security in 5G and beyond are discussed.
</dc:description>
 <dc:description>Comment: To appear in IEEE Journal on Selected Areas in Communications</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05230</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time CPU-based large-scale 3D mesh reconstruction</dc:title>
 <dc:creator>Piazza, Enrico</dc:creator>
 <dc:creator>Romanoni, Andrea</dc:creator>
 <dc:creator>Matteucci, Matteo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In Robotics, especially in this era of autonomous driving, mapping is one key
ability of a robot to be able to navigate through an environment, localize on
it and analyze its traversability. To allow for real-time execution on
constrained hardware, the map usually estimated by feature-based or semi-dense
SLAM algorithms is a sparse point cloud; a richer and more complete
representation of the environment is desirable. Existing dense mapping
algorithms require extensive use of GPU computing and they hardly scale to
large environments; incremental algorithms from sparse points still represent
an effective solution when light computational effort is needed and big
sequences have to be processed in real-time. In this paper we improved and
extended the state of the art incremental manifold mesh algorithm proposed in
[1] and extended in [2]. While these algorithms do not achieve real-time and
they embed points from SLAM or Structure from Motion only when their position
is fixed, in this paper we propose the first incremental algorithm able to
reconstruct a manifold mesh in real-time through single core CPU processing
which is also able to modify the mesh according to 3D points updates from the
underlying SLAM algorithm. We tested our algorithm against two state of the art
incremental mesh mapping systems on the KITTI dataset, and we showed that,
while accuracy is comparable, our approach is able to reach real-time
performances thanks to an order of magnitude speed-up.
</dc:description>
 <dc:description>Comment: Accepted for ICRA2018/RA-L</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05236</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MORF: A Framework for MOOC Predictive Modeling and Replication At Scale</dc:title>
 <dc:creator>Gardner, Josh</dc:creator>
 <dc:creator>Brooks, Christopher</dc:creator>
 <dc:creator>Andres, Juan Miguel L.</dc:creator>
 <dc:creator>Baker, Ryan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The MOOC Replication Framework (MORF) is a novel software system for feature
extraction, model training/testing, and evaluation of predictive dropout models
in Massive Open Online Courses (MOOCs). MORF makes large-scale replication of
complex machine-learned models tractable and accessible for researchers, and
enables public research on privacy-protected data. It does so by focusing on
the high-level operations of an extract-train-test-evaluate workflow, and
enables researchers to encapsulate their implementations in portable, fully
reproducible software containers which are executed on data with a known
schema. MORF's workflow allows researchers to use data in analysis without
providing them access to the underlying data directly, preserving privacy and
data security. During execution, containers are sandboxed for security and data
leakage and parallelized for efficiency, allowing researchers to create and
test new models rapidly, on large-scale multi-institutional datasets that were
previously inaccessible to most researchers. MORF is provided both as a Python
API (the MORF Software), for institutions to use on their own MOOC data) or in
a platform-as-a-service (PaaS) model with a web API and a high-performance
computing environment (the MORF Platform).
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05240</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>de Finetti reductions for partially exchangeable probability
  distributions</dc:title>
 <dc:creator>Bardet, Ivan</dc:creator>
 <dc:creator>Lancien, C&#xe9;cilia</dc:creator>
 <dc:creator>Nechita, Ion</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We introduce a general framework for de Finetti reduction results, applicable
to various notions of partially exchangeable probability distributions.
Explicit statements are derived for the cases of exchangeability, Markov
exchangeability, and some generalizations of these. Our techniques are
combinatorial and rely on the &quot;BEST&quot; theorem, enumerating the Eulerian cycles
of a multigraph.
</dc:description>
 <dc:description>Comment: 22 pages, 1 figure</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05242</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Conjugate Gradient Method</dc:title>
 <dc:creator>Cockayne, Jon</dc:creator>
 <dc:creator>Oates, Chris</dc:creator>
 <dc:creator>Girolami, Mark</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  A fundamental task in numerical computation is the solution of large linear
systems. The conjugate gradient method is an iterative method which offers
rapid convergence to the solution, particularly when an effective
preconditioner is employed. However, for more challenging systems a substantial
error can be present even after many iterations have been performed. The
estimates obtained in this case are of little value unless further information
can be provided about the numerical error. In this paper we propose a novel
statistical model for this numerical error set in a Bayesian framework. Our
approach is a strict generalisation of the conjugate gradient method, which is
recovered as the posterior mean for a particular choice of prior. The estimates
obtained are analysed with Krylov subspace methods and a contraction result for
the posterior is presented. The method is then analysed in a simulation study
as well as being applied to a challenging problem in medical imaging.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05243</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rank Selection of CP-decomposed Convolutional Layers with Variational
  Bayesian Matrix Factorization</dc:title>
 <dc:creator>Astrid, Marcella</dc:creator>
 <dc:creator>Lee, Seung-Ik</dc:creator>
 <dc:creator>Seo, Beom-Su</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) is one of successful method in many
areas such as image classification tasks. However, the amount of memory and
computational cost needed for CNNs inference obstructs them to run efficiently
in mobile devices because of memory and computational ability limitation. One
of the method to compress CNNs is compressing the layers iteratively, i.e. by
layer-by-layer compression and fine-tuning, with CP-decomposition in
convolutional layers. To compress with CP-decomposition, rank selection is
important. In the previous approach rank selection that is based on sensitivity
of each layer, the average rank of the network was still arbitrarily selected.
Additionally, the rank of all layers were decided before whole process of
iterative compression, while the rank of a layer can be changed after
fine-tuning. Therefore, this paper proposes selecting rank of each layer using
Variational Bayesian Matrix Factorization (VBMF) which is more systematic than
arbitrary approach. Furthermore, to consider the change of each layer's rank
after fine-tuning of previous iteration, the method is applied just before
compressing the target layer, i.e. after fine-tuning of the previous iteration.
The results show better accuracy while also having more compression rate in
AlexNet's convolutional layers compression.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at ICACT 2018</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05264</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Reversible Watermarking Based on Linear Prediction for Medical
  Videos</dc:title>
 <dc:creator>Zarrabi, Hamidreza</dc:creator>
 <dc:creator>Emami, Ali</dc:creator>
 <dc:creator>Karimi, Nader</dc:creator>
 <dc:creator>Samavi, Shadrokh</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Reversible video watermarking can guarantee that the original watermark and
the original frame can be recovered from the watermarked frame without any
distortion. Although reversible video watermarking has successfully been
applied in multimedia, but its application has not been extensively explored in
medical videos. Reversible watermarking in medical videos is still a
challenging problem. The existing reversible video watermarking algorithms,
which are based on error prediction expansion, use motion vectors for
prediction. In this study, we propose an adaptive reversible watermarking
method for medical videos. We suggest to use temporal correlations for
improving the prediction accuracy. Hence, two temporal neighbor pixels in
upcoming frames are used alongside the four spatial rhombus neighboring pixels
to minimize the prediction error. To the best of our knowledge, this is the
first time this method is applied for medical videos. The method helps to
protect patients' personal and medical information by watermarking, i.e.
increase the security of Health Information Systems (HIS). Experimental results
demonstrate a high quality watermarking based on PSNR metric and a large
capacity for data hiding on medical videos.
</dc:description>
 <dc:description>Comment: 6 Pages, 6 figures, 1 table</dc:description>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05269</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long-term Visual Localization using Semantically Segmented Images</dc:title>
 <dc:creator>Stenborg, Erik</dc:creator>
 <dc:creator>Toft, Carl</dc:creator>
 <dc:creator>Hammarstrand, Lars</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Robust cross-seasonal localization is one of the major challenges in
long-term visual navigation of autonomous vehicles. In this paper, we exploit
recent advances in semantic segmentation of images, i.e., where each pixel is
assigned a label related to the type of object it represents, to solve the
problem of long-term visual localization. We show that semantically labeled 3D
point maps of the environment, together with semantically segmented images, can
be efficiently used for vehicle localization without the need for detailed
feature descriptors (SIFT, SURF, etc.). Thus, instead of depending on
hand-crafted feature descriptors, we rely on the training of an image
segmenter. The resulting map takes up much less storage space compared to a
traditional descriptor based map. A particle filter based semantic localization
solution is compared to one based on SIFT-features, and even with large
seasonal variations over the year we perform on par with the larger and more
descriptive SIFT-features, and are able to localize with an error below 1 m
most of the time.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05271</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Some Linear Codes</dc:title>
 <dc:creator>Darkunde, N. S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Linear code with complementary dual($LCD$) are those codes which meet their
duals trivially. In this paper we will give rather alternative proof of
Massey's theorem\cite{Massey2}, which is one of the most important
characterization of $LCD$ codes. Let $LCD[n,k]_3$ denote the maximum of
possible values of $d$ among $[n,k,d]$ ternary codes. We will give bound on
$LCD[n,k]_3$. We will also discuss the cases when this bound is attained.
</dc:description>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05278</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Representation Learning with Laplacian Pyramid
  Auto-encoders</dc:title>
 <dc:creator>Zhao, Qilu</dc:creator>
 <dc:creator>Li, Zongmin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scale-space representation has been popular in computer vision community due
to its theoretical foundation. The motivation for generating a scale-space
representation of a given data set originates from the basic observation that
real-world objects are composed of different structures at different scales.
Hence, it's reasonable to consider learning features with image pyramids
generated by smoothing and down-sampling operations. In this paper we propose
Laplacian pyramid auto-encoders, a straightforward modification of the deep
convolutional auto-encoder architecture, for unsupervised representation
learning. The method uses multiple encoding-decoding sub-networks within a
Laplacian pyramid framework to reconstruct the original image and the low pass
filtered images. The last layer of each encoding sub-network also connects to
an encoding layer of the sub-network in the next level, which aims to reverse
the process of Laplacian pyramid generation. Experimental results showed that
Laplacian pyramid benefited the classification and reconstruction performance
of deep auto-encoder approaches, and batch normalization is critical to get
deep auto-encoders approaches to begin learning.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05284</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint registration and synthesis using a probabilistic model for
  alignment of MRI and histological sections</dc:title>
 <dc:creator>Iglesias, Juan Eugenio</dc:creator>
 <dc:creator>Modat, Marc</dc:creator>
 <dc:creator>Peter, Loic</dc:creator>
 <dc:creator>Stevens, Allison</dc:creator>
 <dc:creator>Annunziata, Roberto</dc:creator>
 <dc:creator>Vercauteren, Tom</dc:creator>
 <dc:creator>Lein, Ed</dc:creator>
 <dc:creator>Fischl, Bruce</dc:creator>
 <dc:creator>Ourselin, Sebastien</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Nonlinear registration of 2D histological sections with corresponding slices
of MRI data is a critical step of 3D histology reconstruction. This task is
difficult due to the large differences in image contrast and resolution, as
well as the complex nonrigid distortions produced when sectioning the sample
and mounting it on the glass slide. It has been shown in brain MRI registration
that better spatial alignment across modalities can be obtained by synthesizing
one modality from the other and then using intra-modality registration metrics,
rather than by using mutual information (MI) as metric. However, such an
approach typically requires a database of aligned images from the two
modalities, which is very difficult to obtain for histology/MRI.
  Here, we overcome this limitation with a probabilistic method that
simultaneously solves for registration and synthesis directly on the target
images, without any training data. In our model, the MRI slice is assumed to be
a contrast-warped, spatially deformed version of the histological section. We
use approximate Bayesian inference to iteratively refine the probabilistic
estimate of the synthesis and the registration, while accounting for each
other's uncertainty. Moreover, manually placed landmarks can be seamlessly
integrated in the framework for increased performance.
  Experiments on a synthetic dataset show that, compared with MI, the proposed
method makes it possible to use a much more flexible deformation model in the
registration to improve its accuracy, without compromising robustness.
Moreover, our framework also exploits information in manually placed landmarks
more efficiently than MI, since landmarks inform both synthesis and
registration - as opposed to registration alone. Finally, we show qualitative
results on the public Allen atlas, in which the proposed method provides a
clear improvement over MI based registration.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05294</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds on the Effective-length of Optimal Codes for Interference Channel
  with Feedback</dc:title>
 <dc:creator>Heidari, Mohsen</dc:creator>
 <dc:creator>Shirani, Farhad</dc:creator>
 <dc:creator>Pradhan, S. Sandeep</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the necessity of finite blocklength codes in
distributed transmission of independent message sets over channels with
feedback. Previously, it was shown that finite effective length codes are
necessary in distributed transmission and compression of sources. We provide
two examples of three user interference channels with feedback where codes with
asymptotically large effective lengths are sub-optimal. As a result, we
conclude that coded transmission using finite effective length codes is
necessary to achieve optimality. We argue that the sub-optimal performance of
large effective length codes is due to their inefficiency in preserving the
correlation between the inputs to the distributed terminals in the
communication system. This correlation is made available by the presence of
feedback at the terminals and is used as a means for coordination between the
terminals when using finite effective length coding strategies.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05295</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Network based Short-Term Stock Trading System</dc:title>
 <dc:creator>Cremonesi, Paolo</dc:creator>
 <dc:creator>Francalanci, Chiara</dc:creator>
 <dc:creator>Poli, Alessandro</dc:creator>
 <dc:creator>Pagano, Roberto</dc:creator>
 <dc:creator>Mazzoni, Luca</dc:creator>
 <dc:creator>Maggioni, Alberto</dc:creator>
 <dc:creator>Elahi, Mehdi</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:description>  This paper proposes a novel adaptive algorithm for the automated short-term
trading of financial instrument. The algorithm adopts a semantic sentiment
analysis technique to inspect the Twitter posts and to use them to predict the
behaviour of the stock market. Indeed, the algorithm is specifically developed
to take advantage of both the sentiment and the past values of a certain
financial instrument in order to choose the best investment decision. This
allows the algorithm to ensure the maximization of the obtainable profits by
trading on the stock market. We have conducted an investment simulation and
compared the performance of our proposed with a well-known benchmark (DJTATO
index) and the optimal results, in which an investor knows in advance the
future price of a product. The result shows that our approach outperforms the
benchmark and achieves the performance score close to the optimal result.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05297</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evidential Occupancy Grid Map Augmentation using Deep Learning</dc:title>
 <dc:creator>Wirges, Sascha</dc:creator>
 <dc:creator>Hartenbach, Felix</dc:creator>
 <dc:creator>Stiller, Christoph</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A detailed environment representation is a crucial component of automated
vehicles. Using single range sensor scans, data is often too sparse and subject
to occlusions. Therefore, we present a method to augment occupancy grid maps
from single views to be similar to evidential occupancy maps acquired from
different views using Deep Learning. To accomplish this, we estimate motion
between subsequent range sensor measurements and create an evidential 3D voxel
map in an extensive post-processing step. Within this voxel map, we explicitly
model uncertainty using evidence theory and create a 2D projection using
combination rules. As input for our neural networks, we use a multi-layer grid
map consisting of the three features detections, transmissions and intensity,
each for ground and non-ground measurements. Finally, we perform a quantitative
and qualitative evaluation which shows that different network architectures
accurately infer evidential measures in real-time.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05299</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous Driving in Reality with Reinforcement Learning and Image
  Translation</dc:title>
 <dc:creator>Tan, Bowen</dc:creator>
 <dc:creator>Xu, Nayun</dc:creator>
 <dc:creator>Kong, Bingyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Supervised learning is widely used in training autonomous driving vehicle.
However, it is trained with large amount of supervised labeled data.
Reinforcement learning can be trained without abundant labeled data, but we
cannot train it in reality because it would involve many unpredictable
accidents. Nevertheless, training an agent with good performance in virtual
environment is relatively much easier. Because of the huge difference between
virtual and real, how to fill the gap between virtual and real is challenging.
In this paper, we proposed a novel framework of reinforcement learning with
image semantic segmentation network to make the whole model adaptable to
reality. The agent is trained in TORCS, a car racing simulator.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1704.03952 by other authors</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05301</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Efficiency Gap Does Not Satisfy the Efficiency Principle</dc:title>
 <dc:creator>Veomett, Ellen</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>97A40, 91F99</dc:subject>
 <dc:description>  We prove that the efficiency gap does not satisfy the efficiency principle.
We assume no mathematical background, with the intent that a law scholar can
read this short note.
</dc:description>
 <dc:description>Comment: gerrymandering, efficiency gap</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05302</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmark Visual Question Answer Models by using Focus Map</dc:title>
 <dc:creator>Qiu, Wenda</dc:creator>
 <dc:creator>Xianzang, Yueyang</dc:creator>
 <dc:creator>Zhang, Zhekai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Inferring and Executing Programs for Visual Reasoning proposes a model for
visual reasoning that consists of a program generator and an execution engine
to avoid end-to-end models. To show that the model actually learns which
objects to focus on to answer the questions, the authors give a visualization
of the norm of the gradient of the sum of the predicted answer scores with
respect to the final feature map. However, the authors do not evaluate the
efficiency of focus map. This paper purposed a method for evaluating it. We
generate several kinds of questions to test different keywords. We infer focus
maps from the model by asking these questions and evaluate them by comparing
with the segmentation graph. Furthermore, this method can be applied to any
model if focus maps can be inferred from it. By evaluating focus map of
different models on the CLEVR dataset, we will show that CLEVR-iep model has
learned where to focus more than end-to-end models.
</dc:description>
 <dc:description>Comment: A group project paper for course CS348. arXiv admin note: text
  overlap with arXiv:1705.03633 by other authors</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05306</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On strong homogeneity of a class of global optimization algorithms
  working with infinite and infinitesimal scales</dc:title>
 <dc:creator>Sergeyev, Yaroslav D.</dc:creator>
 <dc:creator>Kvasov, Dmitri E.</dc:creator>
 <dc:creator>Mukhametzhanov, Marat S.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>90C26, 65K10, 65Y99, 65G99</dc:subject>
 <dc:description>  The necessity to find the global optimum of multiextremal functions arises in
many applied problems where finding local solutions is insufficient. One of the
desirable properties of global optimization methods is \emph{strong
homogeneity} meaning that a method produces the same sequences of points where
the objective function is evaluated independently both of multiplication of the
function by a scaling constant and of adding a shifting constant. In this
paper, several aspects of global optimization using strongly homogeneous
methods are considered. First, it is shown that even if a method possesses this
property theoretically, numerically very small and large scaling constants can
lead to ill-conditioning of the scaled problem. Second, a new class of global
optimization problems where the objective function can have not only finite but
also infinite or infinitesimal Lipschitz constants is introduced. Third, the
strong homogeneity of several Lipschitz global optimization algorithms is
studied in the framework of the Infinity Computing paradigm allowing one to
work \emph{numerically} with a variety of infinities and infinitesimals.
Fourth, it is proved that a class of efficient univariate methods enjoys this
property for finite, infinite and infinitesimal scaling and shifting constants.
Finally, it is shown that in certain cases the usage of numerical infinities
and infinitesimals can avoid ill-conditioning produced by scaling. Numerical
experiments illustrating theoretical results are described.
</dc:description>
 <dc:description>Comment: 25 pages, 3 figures</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05306</dc:identifier>
 <dc:identifier>Communications in Nonlinear Science and Numerical Simulation,
  Volume 59, June 2018, Pages 319-330</dc:identifier>
 <dc:identifier>doi:10.1016/j.cnsns.2017.11.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05309</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Hybrid Method for Network Anomaly Detection Based on Traffic
  Prediction and Change Point Detection</dc:title>
 <dc:creator>Alkasassbeh, Mouhammd</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In recent years, computer networks have become more and more advanced in
terms of size, applications, complexity and level of heterogeneity. Moreover,
availability and performance are important issues for end users. New types of
cyber-attacks that can affect and damage network performance and availability
are constantly emerging and some threats, such as Distributed Denial of Service
(DDoS) attacks, can be very dangerous and cannot be easily prevented. In this
study, we present a novel hybrid approach to detecting a DDoS attack by means
of monitoring abnormal traffic in the network. This approach reads traffic data
and from that it is possible to build a model, by means of which future data
may be predicted and compared with observed data, in order to detect any
abnormal traffic. This approach combines two methods: traffic prediction and
changing detection. To the best of our knowledge, such a combination has never
been used in this area before. The approach achieved a highly significant
accuracy rate of 98.3% and sensitivity was 100%, which means that all potential
attacks are detected and prevented from penetrating the network system.
</dc:description>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05313</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Digital identity, personal data and privacy protection</dc:title>
 <dc:creator>Banerjee, Subhashis</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Privacy protection in digital databases does not demand that data should not
be collected, stored or used, but that there should be guarantees that the data
can only be used for pre-approved and legitimate purposes. We argue that a data
protection law based on traditional understanding of privacy protection and
detection of privacy infringements is unlikely to be successful, and that what
is required is a law based on an understanding of an architectural requirement
of authorisation, audit and access control in real-time.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05334</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical exponents of infinite balanced words</dc:title>
 <dc:creator>Rampersad, Narad</dc:creator>
 <dc:creator>Shallit, Jeffrey</dc:creator>
 <dc:creator>Vandomme, &#xc9;lise</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68R15</dc:subject>
 <dc:description>  Over an alphabet of size 3 we construct an infinite balanced word with
critical exponent 2+sqrt(2)/2. Over an alphabet of size 4 we construct an
infinite balanced word with critical exponent (5+sqrt(5))/4. Over larger
alphabets, we give some candidates for balanced words (found computationally)
having small critical exponents. We also explore a method for proving these
results using the automated theorem prover Walnut.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05338</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision-Feedback Detection Strategy for Nonlinear Frequency-Division
  Multiplexing</dc:title>
 <dc:creator>Civelli, Stella</dc:creator>
 <dc:creator>Forestieri, Enrico</dc:creator>
 <dc:creator>Secondini, Marco</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  By exploiting a causality property of the nonlinear Fourier transform, a
novel decision-feedback detection strategy for nonlinear frequency-division
multiplexing (NFDM) systems is introduced. The performance of the proposed
strategy is investigated both by simulations and by theoretical bounds and
approximations, showing that it achieves a considerable performance improvement
compared to previously adopted techniques in terms of Q-factor. The obtained
improvement demonstrates that, by tailoring the detection strategy to the
peculiar properties of the nonlinear Fourier transform, it is possible to boost
the performance of NFDM systems and overcome current limitations imposed by the
use of more conventional detection techniques suitable for the linear regime.
</dc:description>
 <dc:description>Comment: Submitted for publication to Optics Express</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05339</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Re-ID done right: towards good practices for person re-identification</dc:title>
 <dc:creator>Almazan, Jon</dc:creator>
 <dc:creator>Gajic, Bojana</dc:creator>
 <dc:creator>Murray, Naila</dc:creator>
 <dc:creator>Larlus, Diane</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Training a deep architecture using a ranking loss has become standard for the
person re-identification task. Increasingly, these deep architectures include
additional components that leverage part detections, attribute predictions,
pose estimators and other auxiliary information, in order to more effectively
localize and align discriminative image regions. In this paper we adopt a
different approach and carefully design each component of a simple deep
architecture and, critically, the strategy for training it effectively for
person re-identification. We extensively evaluate each design choice, leading
to a list of good practices for person re-identification. By following these
practices, our approach outperforms the state of the art, including more
complex methods with auxiliary components, by large margins on four benchmark
datasets. We also provide a qualitative analysis of our trained representation
which indicates that, while compact, it is able to capture information from
localized and discriminative regions, in a manner akin to an implicit attention
mechanism.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05349</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint CSI Estimation, Beamforming and Scheduling Design for Wideband
  Massive MIMO System</dc:title>
 <dc:creator>Bogale, Tadilo Endeshaw</dc:creator>
 <dc:creator>Le, Long Bao</dc:creator>
 <dc:creator>Wang, Xianbin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a novel approach for designing channel estimation,
beamforming and scheduling jointly for wideband massive multiple input multiple
output (MIMO) systems. With the proposed approach, we first quantify the
maximum number of user equipments (UEs) that can send pilots which may or may
not be orthogonal. Specifically, when the channel has a maximum of $L$
multipath taps, and we allocate $\tilde{M}$ sub-carriers for the channel state
information (CSI) estimation, a maximum of $\tilde{M}$ UEs CSI can be estimated
($L$ times compared to the conventional CSI estimation approach) in a massive
MIMO regime. Then, we propose to schedule a subset of these UEs using greedy
based scheduling to transmit their data on each sub-carrier with the proposed
joint beamforming and scheduling design. We employ the well known maximum ratio
combiner (MRC) beamforming approach in the uplink channel data transmission.
All the analytical expressions are validated via numerical results, and the
superiority of the proposed design over the conventional orthogonal frequency
division multiplexing (OFDM) transmission approach is demonstrated using
extensive numerical simulations in the long term evolution (LTE) channel
environment. The proposed channel estimation and beamforming design is linear
and simple to implement.
</dc:description>
 <dc:description>Comment: ICC 2018 (To appear)</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05353</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Power Loading for OFDM-based Cognitive Radio Systems
  with Channel Uncertainties</dc:title>
 <dc:creator>Bedeer, Ebrahim</dc:creator>
 <dc:creator>Amin, Osama</dc:creator>
 <dc:creator>Dobre, Octavia A.</dc:creator>
 <dc:creator>Ahmed, Mohamed H.</dc:creator>
 <dc:creator>Baddour, Kareem E.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a novel algorithm to optimize the energy-efficiency
(EE) of orthogonal frequency division multiplexing-based cognitive radio
systems under channel uncertainties. We formulate an optimization problem that
guarantees a minimum required rate and a specified power budget for the
secondary user (SU), while restricting the interference to primary users (PUs)
in a statistical manner. The optimization problem is non-convex and it is
transformed to an equivalent problem using the concept of fractional
programming. Unlike all related works in the literature, we consider the effect
of imperfect channel-stateinformation (CSI) on the links between the SU
transmitter and receiver pairs and we additionally consider the effect of
limited sensing capabilities of the SU. Since the interference constraints are
met statistically, the SU transmitter does not require perfect CSI feedback
from the PUs receivers. Simulation results sho w that the EE deteriorates as
the channel estimation error increases. Comparisons with relevant works from
the literature show that the interference thresholds at the PUs receivers can
be severely exceeded and the EE is slightly deteriorated if the SU does no t
account for spectrum sensing errors.
</dc:description>
 <dc:description>Comment: TVT</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05360</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-Pass Trajectory Simplification Using the Synchronous Euclidean
  Distance</dc:title>
 <dc:creator>Lin, Xuelian</dc:creator>
 <dc:creator>Jiang, Jiahao</dc:creator>
 <dc:creator>Ma, Shuai</dc:creator>
 <dc:creator>Zuo, Yimeng</dc:creator>
 <dc:creator>Hu, Chunming</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Various mobile devices have been used to collect, store and transmit
tremendous trajectory data, and it is known that raw trajectory data seriously
wastes the storage, network band and computing resource. To attack this issue,
one-pass line simplification (LS) algorithms have are been developed, by
compressing data points in a trajectory to a set of continuous line segments.
However, these algorithms adopt the perpendicular Euclidean distance, and none
of them uses the synchronous Euclidean distance (SED), and cannot support
spatio-temporal queries. To do this, we develop two one-pass error bounded
trajectory simplification algorithms (CISED-S and CISED-W) using SED, based on
a novel spatio-temporal cone intersection technique. Using four real-life
trajectory datasets, we experimentally show that our approaches are both
efficient and effective. In terms of running time, algorithms CISED-S and
CISED-W are on average 3 times faster than SQUISH-E (the most efficient
existing LS algorithm using SED). In terms of compression ratios, algorithms
CISED-S and CISED-W are comparable with and 19.6% better than DPSED (the most
effective existing LS algorithm using SED) on average, respectively, and are
21.1% and 42.4% better than SQUISH-E on average, respectively.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05362</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimax Optimal Additive Functional Estimation with Discrete
  Distribution: Slow Divergence Speed Case</dc:title>
 <dc:creator>Fukuchi, Kazuto</dc:creator>
 <dc:creator>Sakuma, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  This paper addresses an estimation problem of an additive functional of
$\phi$, which is defined as $\theta(P;\phi)=\sum_{i=1}^k\phi(p_i)$, given $n$
i.i.d. random samples drawn from a discrete distribution $P=(p_1,...,p_k)$ with
alphabet size $k$. We have revealed in the previous paper that the minimax
optimal rate of this problem is characterized by the divergence speed of the
fourth derivative of $\phi$ in a range of fast divergence speed. In this paper,
we prove this fact for a more general range of the divergence speed. As a
result, we show the minimax optimal rate of the additive functional estimation
for each range of the parameter $\alpha$ of the divergence speed. For $\alpha
\in (1,3/2)$, we show that the minimax rate is $\frac{1}{n}+\frac{k^2}{(n\ln
n)^{2\alpha}}$. Besides, we show that the minimax rate is $\frac{1}{n}$ for
$\alpha \in [3/2,2]$.
</dc:description>
 <dc:description>Comment: 35 pages. arXiv admin note: text overlap with arXiv:1701.06381</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05365</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Features for One-Class Classification</dc:title>
 <dc:creator>Perera, Pramuditha</dc:creator>
 <dc:creator>Patel, Vishal M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a deep learning-based solution for the problem of feature learning
in one-class classification. The proposed method operates on top of a
Convolutional Neural Network (CNN) of choice and produces descriptive features
while maintaining a low intra-class variance in the feature space for the given
class. For this purpose two loss functions, compactness loss and
descriptiveness loss are proposed along with a parallel CNN architecture. A
template matching-based framework is introduced to facilitate the testing
process. Extensive experiments on publicly available anomaly detection, novelty
detection and mobile active authentication datasets show that the proposed Deep
One-Class (DOC) classification method achieves significant improvements over
the state-of-the-art.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05366</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Debugging Framework Applications: Benefits and Challenges</dc:title>
 <dc:creator>Coker, Zack</dc:creator>
 <dc:creator>Widder, David Gray</dc:creator>
 <dc:creator>Goues, Claire Le</dc:creator>
 <dc:creator>Bogart, Christopher</dc:creator>
 <dc:creator>Sunshine, Joshua</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Aspects of frameworks, such as inversion of control and the structure of
framework applications, require developers to adjust their debugging strategies
as compared to debugging sequential programs. However, the benefits and
challenges of framework debugging are not fully understood, and gaining this
knowledge could provide guidance in debugging strategies and framework tool
design. To gain insight into the process developers use to fix problems in
framework applications, we performed two human studies investigating how
developers fix applications that use a framework API incorrectly. These studies
focused on the Android Fragment class and the ROS framework. We analyzed the
results of the studies using a mixed-methods approach, consisting of techniques
from grounded theory, qualitative content analysis, and case studies. From our
analysis, we produced a theory of the benefits and challenges of framework
debugging. This theory states that developers find inversion of control
challenging when debugging but find the structure of framework applications
helpful. This theory could be used to guide strategies for debugging framework
applications and framework tool designs.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05367</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TexT - Text Extractor Tool for Handwritten Document Transcription and
  Annotation</dc:title>
 <dc:creator>Hast, Anders</dc:creator>
 <dc:creator>Cullhed, Per</dc:creator>
 <dc:creator>Vats, Ekta</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a framework for semi-automatic transcription of
large-scale historical handwritten documents and proposes a simple
user-friendly text extractor tool, TexT for transcription. The proposed
approach provides a quick and easy transcription of text using computer
assisted interactive technique. The algorithm finds multiple occurrences of the
marked text on-the-fly using a word spotting system. TexT is also capable of
performing on-the-fly annotation of handwritten text with automatic generation
of ground truth labels, and dynamic adjustment and correction of user generated
bounding box annotations with the word being perfectly encapsulated. The user
can view the document and the found words in the original form or with
background noise removed for easier visualization of transcription results. The
effectiveness of TexT is demonstrated on an archival manuscript collection from
well-known publicly available dataset.
</dc:description>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05372</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Features For Relational Data</dc:title>
 <dc:creator>Lam, Hoang Thanh</dc:creator>
 <dc:creator>Minh, Tran Ngoc</dc:creator>
 <dc:creator>Sinn, Mathieu</dc:creator>
 <dc:creator>Buesser, Beat</dc:creator>
 <dc:creator>Wistuba, Martin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Feature engineering is one of the most important but tedious tasks in data
science projects. This work studies automation of feature learning for
relational data. We first theoretically proved that learning relevant features
from relational data for a given predictive analytics problem is NP-hard.
However, it is possible to empirically show that an efficient rule based
approach predefining transformations as a priori based on heuristics can
extract very useful features from relational data. Indeed, the proposed
approach outperformed the state of the art solutions with a significant margin.
We further introduce a deep neural network which automatically learns
appropriate transformations of relational data into a representation that
predicts the target variable well instead of being predefined as a priori by
users. In an extensive experiment with Kaggle competitions, the proposed
methods could win late medals. To the best of our knowledge, this is the first
time an automation system could win medals in Kaggle competitions with complex
relational data.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05376</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subword complexity and power avoidance</dc:title>
 <dc:creator>Shallit, Jeffrey</dc:creator>
 <dc:creator>Shur, Arseny M.</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68R15</dc:subject>
 <dc:description>  We begin a systematic study of the relations between subword complexity of
infinite words and their power avoidance. Among other things, we show that
  -- the Thue-Morse word has the minimum possible subword complexity over all
overlap-free binary words and all $(\frac 73)$-power-free binary words, but not
over all $(\frac 73)^+$-power-free binary words;
  -- the twisted Thue-Morse word has the maximum possible subword complexity
over all overlap-free binary words, but no word has the maximum subword
complexity over all $(\frac 73)$-power-free binary words;
  -- if some word attains the minimum possible subword complexity over all
square-free ternary words, then one such word is the ternary Thue word;
  -- the recently constructed 1-2-bonacci word has the minimum possible subword
complexity over all \textit{symmetric} square-free ternary words.
</dc:description>
 <dc:description>Comment: 29 pages. Submitted to TCS</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05387</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StressedNets: Efficient Feature Representations via Stress-induced
  Evolutionary Synthesis of Deep Neural Networks</dc:title>
 <dc:creator>Shafiee, Mohammad Javad</dc:creator>
 <dc:creator>Chwyl, Brendan</dc:creator>
 <dc:creator>Li, Francis</dc:creator>
 <dc:creator>Chen, Rongyan</dc:creator>
 <dc:creator>Karg, Michelle</dc:creator>
 <dc:creator>Scharfenberger, Christian</dc:creator>
 <dc:creator>Wong, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The computational complexity of leveraging deep neural networks for
extracting deep feature representations is a significant barrier to its
widespread adoption, particularly for use in embedded devices. One particularly
promising strategy to addressing the complexity issue is the notion of
evolutionary synthesis of deep neural networks, which was demonstrated to
successfully produce highly efficient deep neural networks while retaining
modeling performance. Here, we further extend upon the evolutionary synthesis
strategy for achieving efficient feature extraction via the introduction of a
stress-induced evolutionary synthesis framework, where stress signals are
imposed upon the synapses of a deep neural network during training to induce
stress and steer the synthesis process towards the production of more efficient
deep neural networks over successive generations and improved model fidelity at
a greater efficiency. The proposed stress-induced evolutionary synthesis
approach is evaluated on a variety of different deep neural network
architectures (LeNet5, AlexNet, and YOLOv2) on different tasks (object
classification and object detection) to synthesize efficient StressedNets over
multiple generations. Experimental results demonstrate the efficacy of the
proposed framework to synthesize StressedNets with significant improvement in
network architecture efficiency (e.g., 40x for AlexNet and 33x for YOLOv2) and
speed improvements (e.g., 5.5x inference speed-up for YOLOv2 on an Nvidia Tegra
X1 mobile processor).
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05388</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UAV Offloading: Spectrum Trading Contract Design for UAV Assisted
  Offloading in Cellular Networks</dc:title>
 <dc:creator>Hu, Zhiwen</dc:creator>
 <dc:creator>Zheng, Zijie</dc:creator>
 <dc:creator>Song, Lingyang</dc:creator>
 <dc:creator>Wang, Tao</dc:creator>
 <dc:creator>Li, Xiaoming</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Unmanned Aerial Vehicle (UAV) has been recognized as a promising way to
assist future wireless communications due to its high flexibility of deployment
and scheduling. In this paper, we focus on temporarily deployed UAVs that
provide downlink data offloading in some regions under a macro base station
(MBS). Since the manager of the MBS and the operators of the UAVs could be of
different interest groups, we formulate the corresponding spectrum trading
problem by means of contract theory, where the manager of the MBS has to design
an optimal contract to maximize its own revenue. Such contract comprises a set
of bandwidth options and corresponding prices, and each UAV operator only
chooses the most profitable one from all the options in the whole contract. We
analytically derive the optimal pricing strategy based on fixed bandwidth
assignment, and then propose a dynamic programming algorithm to calculate the
optimal bandwidth assignment in polynomial time. By simulations, we compare the
outcome of the MBS optimal contract with that of a social optimal one, and find
that a selfish MBS manager sells less bandwidth to the UAV operators.
</dc:description>
 <dc:description>Comment: 30 pages, 8 figures</dc:description>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05391</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Sat solvers for synchronization issues in non-deterministic
  automata</dc:title>
 <dc:creator>Shabana, Hanan</dc:creator>
 <dc:creator>Volkov, Mikhail V.</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68Q45</dc:subject>
 <dc:description>  We approach the problem of computing a $D_{3}$-synchronizing word of minimum
length for a given nondeterministic automaton via its encoding as an instance
of SAT and invoking a SAT solver. We also present some experimental results.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05393</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coexistence of 5G mmWave Users with Incumbent Fixed Stations over 70 and
  80 GHz</dc:title>
 <dc:creator>Hattab, Ghaith</dc:creator>
 <dc:creator>Visotsky, Eugene</dc:creator>
 <dc:creator>Cudak, Mark</dc:creator>
 <dc:creator>Ghosh, Amitava</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Millimeter wave spectrum access over the 70GHz and 80GHz is central to
unlocking gigabit connectivity and meeting the explosive growth of mobile
traffic. A pressing question, however, is whether fifth-generation (5G) systems
can harmoniously coexist with the incumbents of these bands, which are
primarily point-to-point fixed stations (FSs). To this end, we thoroughly
analyze the impact of 5G coexistence on FSs. Specifically, we first analyze the
geometry of existing FSs' deployment using actual databases of these stations.
Then, we present a case study on the interference generated from users towards
FSs in two populated areas in Chicago, where we use actual building databases
to accurately compute the aggregate interference. The analysis and simulation
results reveal that the deployment strategy of FSs and the high attenuation
losses at 70/80GHz significantly limit the 5G interference, with the majority
of FSs experiencing interference levels well below the noise floor.
</dc:description>
 <dc:description>Comment: to be published in 2017 IEEE Global Communications Workshops (GC
  Wkshps), Singapore, Dec. 2017</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05394</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time Series Segmentation through Automatic Feature Learning</dc:title>
 <dc:creator>Lee, Wei-Han</dc:creator>
 <dc:creator>Ortiz, Jorge</dc:creator>
 <dc:creator>Ko, Bongjun</dc:creator>
 <dc:creator>Lee, Ruby</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Internet of things (IoT) applications have become increasingly popular in
recent years, with applications ranging from building energy monitoring to
personal health tracking and activity recognition. In order to leverage these
data, automatic knowledge extraction - whereby we map from observations to
interpretable states and transitions - must be done at scale. As such, we have
seen many recent IoT data sets include annotations with a human expert
specifying states, recorded as a set of boundaries and associated labels in a
data sequence. These data can be used to build automatic labeling algorithms
that produce labels as an expert would. Here, we refer to human-specified
boundaries as breakpoints. Traditional changepoint detection methods only look
for statistically-detectable boundaries that are defined as abrupt variations
in the generative parameters of a data sequence. However, we observe that
breakpoints occur on more subtle boundaries that are non-trivial to detect with
these statistical methods. In this work, we propose a new unsupervised
approach, based on deep learning, that outperforms existing techniques and
learns the more subtle, breakpoint boundaries with a high accuracy. Through
extensive experiments on various real-world data sets - including
human-activity sensing data, speech signals, and electroencephalogram (EEG)
activity traces - we demonstrate the effectiveness of our algorithm for
practical applications. Furthermore, we show that our approach achieves
significantly better performance than previous methods.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05398</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Direction of Discrimination: An Information-Theoretic Analysis of
  Disparate Impact in Machine Learning</dc:title>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Ustun, Berk</dc:creator>
 <dc:creator>Calmon, Flavio P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In the context of machine learning, disparate impact refers to a form of
systematic discrimination whereby the output distribution of a model depends on
the value of a sensitive attribute (e.g., race or gender). In this paper, we
present an information-theoretic framework to analyze the disparate impact of a
binary classification model. We view the model as a fixed channel, and quantify
disparate impact as the divergence in output distributions over two groups. We
then aim to find a \textit{correction function} that can be used to perturb the
input distributions of each group in order to align their output distributions.
We present an optimization problem that can be solved to obtain a correction
function that will make the output distributions statistically
indistinguishable. We derive closed-form expression for the correction function
that can be used to compute it efficiently. We illustrate the use of the
correction function for a recidivism prediction application derived from the
ProPublica COMPAS dataset.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05399</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A networked voting rule for democratic representation</dc:title>
 <dc:creator>Hernandez, Alexis R.</dc:creator>
 <dc:creator>Gracia-Lazaro, Carlos</dc:creator>
 <dc:creator>Brigatti, Edgardo</dc:creator>
 <dc:creator>Moreno, Yamir</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We introduce a general framework for exploring the problem of selecting a
committee of representatives with the aim of studying a networked voting rule
based on a decentralized large-scale platform, which can assure a strong
accountability of the elected. The results of our simulations suggest that this
algorithm-based approach is able to obtain a high representativeness for
relatively small committees, performing even better than a classical voting
rule based on a closed list of candidates. We show that a general relation
between committee size and representatives exists in the form of an inverse
square root law and that the normalized committee size approximately scales
with the inverse of the community size, allowing the scalability to very large
populations. These findings are not strongly influenced by the different
networks used to describe the individuals interactions, except for the presence
of few individuals with very high connectivity which can have a marginally
negative effect in the committee selection process.
</dc:description>
 <dc:description>Comment: Submitted for publication</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05400</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure and Evolution of Indian Physics Co-authorship Networks</dc:title>
 <dc:creator>Singh, Chakresh Kumar</dc:creator>
 <dc:creator>Jolad, Shivakumar</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>05C82, 91D30</dc:subject>
 <dc:description>  We trace the evolution of Indian physics community from 1919 to 2013 by
analysing the coauthorship network constructed from papers published by authors
in India in American Physical Society journals. We make inferences on Indias
contribution to different branches of Physics and identify the most influential
Indian physicists at different time periods. The relative contribution of India
to global physics publication(research) and its variation across subfields of
Physics is assessed. We extract the changing collaboration pattern of authors
between Indian physicists through various network measures. We study the
evolution of Indian physics communities and trace the mean life and
stationarity of communities by size in different APS journals. We map the
transition of authors between communities of different sizes from 1970 to 2013,
capturing their birth, growth, merger and collapse. We find that Indian-Foreign
collaborations are increasing at a faster pace compared to the Indian-Indian.
We observe that the degree distribution of Indian collaboration networks
follows the power law, with distinct patterns between Physical Review A, B and
E, and high energy physics journals Physical Review C and D, and Physical
Review Letters. In almost every measure, we observe strong structural
differences between low-energy and high-energy physics journals.
</dc:description>
 <dc:description>Comment: 17 pages, 16 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05401</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Shot Learning from Imaginary Data</dc:title>
 <dc:creator>Wang, Yu-Xiong</dc:creator>
 <dc:creator>Girshick, Ross</dc:creator>
 <dc:creator>Hebert, Martial</dc:creator>
 <dc:creator>Hariharan, Bharath</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Humans can quickly learn new visual concepts, perhaps because they can easily
visualize or imagine what novel objects look like from different views.
Incorporating this ability to hallucinate novel instances of new concepts might
help machine vision systems perform better low-shot learning, i.e., learning
concepts from few examples. We present a novel approach to low-shot learning
that uses this idea. Our approach builds on recent progress in meta-learning
(&quot;learning to learn&quot;) by combining a meta-learner with a &quot;hallucinator&quot; that
produces additional training examples, and optimizing both models jointly. Our
hallucinator can be incorporated into a variety of meta-learners and provides
significant gains: up to a 6 point boost in classification accuracy when only a
single training example is available, yielding state-of-the-art performance on
the challenging ImageNet low-shot classification benchmark.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05405</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Mitigation Techniques for Coexistence of 5G mmWave Users
  with Incumbents at 70 and 80 GHz</dc:title>
 <dc:creator>Hattab, Ghaith</dc:creator>
 <dc:creator>Visotsky, Eugene</dc:creator>
 <dc:creator>Cudak, Mark</dc:creator>
 <dc:creator>Ghosh, Amitava</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  The millimeter wave spectra at 71-76GHz (70GHz) and 81-86GHz (80GHz) have the
potential to endow fifth-generation new radio (5G-NR) with mobile connectivity
at gigabit rates. However, a pressing issue is the presence of incumbent
systems in these bands, which are primarily point-to-point fixed stations
(FSs). In this paper, we first identify the key properties of incumbents by
parsing databases of existing stations in major cities to devise several
modeling guidelines and characterize their deployment geometry and antenna
specifications. Second, we develop a detailed interference framework to compute
the aggregate interference from outdoor 5G-NR users into FSs. We then present
several case studies in dense populated areas, using actual incumbent databases
and building layouts. Our simulation results demonstrate promising 5G
coexistence at 70GHz and 80GHz as the majority of FSs experience interference
well below the noise floor thanks to the propagation losses in these bands and
the deployment geometry of the incumbent and 5G systems. For the few FSs that
may incur higher interference, we propose several passive interference
mitigation techniques such as angular-based exclusion zones and spatial power
control. Simulations results show that the techniques can effectively protect
FSs, without tangible degradation of the 5G coverage.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05407</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Canonically Correlated LSTMs</dc:title>
 <dc:creator>Mallinar, Neil</dc:creator>
 <dc:creator>Rosset, Corbin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We examine Deep Canonically Correlated LSTMs as a way to learn nonlinear
transformations of variable length sequences and embed them into a correlated,
fixed dimensional space. We use LSTMs to transform multi-view time-series data
non-linearly while learning temporal relationships within the data. We then
perform correlation analysis on the outputs of these neural networks to find a
correlated subspace through which we get our final representation via
projection. This work follows from previous work done on Deep Canonical
Correlation (DCCA), in which deep feed-forward neural networks were used to
learn nonlinear transformations of data while maximizing correlation.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, accepted as the undergraduate honors thesis for
  Neil Mallinar by The Johns Hopkins University</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05411</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expectation Propagation for Approximate Inference: Free Probability
  Framework</dc:title>
 <dc:creator>&#xc7;akmak, Burak</dc:creator>
 <dc:creator>Opper, Manfred</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study asymptotic properties of expectation propagation (EP) - a method for
approximate inference originally developed in the field of machine learning.
Applied to generalized linear models, EP iteratively computes a multivariate
Gaussian approximation to the exact posterior distribution. The computational
complexity of the repeated update of covariance matrices severely limits the
application of EP to large problem sizes. In this paper, we present a rigorous
analysis by means of free probability theory that allows us to overcome this
computational bottleneck if specific data matrices in the problem fulfill a
certain property of asymptotic freeness. We demonstrate the relevance of our
approach on the gene selection problem of a microarray dataset.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05412</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Automated System for Epilepsy Detection using EEG Brain Signals based
  on Deep Learning Approach</dc:title>
 <dc:creator>Ullah, Ihsan</dc:creator>
 <dc:creator>Hussain, Muhammad</dc:creator>
 <dc:creator>Qazi, Emad-ul-Haq</dc:creator>
 <dc:creator>Aboalsamh, Hatim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Epilepsy is a neurological disorder and for its detection, encephalography
(EEG) is a commonly used clinical approach. Manual inspection of EEG brain
signals is a time-consuming and laborious process, which puts heavy burden on
neurologists and affects their performance. Several automatic techniques have
been proposed using traditional approaches to assist neurologists in detecting
binary epilepsy scenarios e.g. seizure vs. non-seizure or normal vs. ictal.
These methods do not perform well when classifying ternary case e.g. ictal vs.
normal vs. inter-ictal; the maximum accuracy for this case by the
state-of-the-art-methods is 97+-1%. To overcome this problem, we propose a
system based on deep learning, which is an ensemble of pyramidal
one-dimensional convolutional neural network (P-1D-CNN) models. In a CNN model,
the bottleneck is the large number of learnable parameters. P-1D-CNN works on
the concept of refinement approach and it results in 60% fewer parameters
compared to traditional CNN models. Further to overcome the limitations of
small amount of data, we proposed augmentation schemes for learning P-1D-CNN
model. In almost all the cases concerning epilepsy detection, the proposed
system gives an accuracy of 99.1+-0.9% on the University of Bonn dataset.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05413</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial Preconditioners for Proximal Algorithms on Graphs</dc:title>
 <dc:creator>M&#xf6;llenhoff, Thomas</dc:creator>
 <dc:creator>Ye, Zhenzhang</dc:creator>
 <dc:creator>Wu, Tao</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a novel preconditioning technique for proximal optimization
methods that relies on graph algorithms to construct effective preconditioners.
Such combinatorial preconditioners arise from partitioning the graph into
forests. We prove that certain decompositions lead to a theoretically optimal
condition number. We also show how ideal decompositions can be realized using
matroid partitioning and propose efficient greedy variants thereof for
large-scale problems. Coupled with specialized solvers for the resulting scaled
proximal subproblems, the preconditioned algorithm achieves competitive
performance in machine learning and vision applications.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05420</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of Rule Extraction for Different Recurrent Neural Network
  Models and Grammatical Complexity</dc:title>
 <dc:creator>Wang, Qinglong</dc:creator>
 <dc:creator>Zhang, Kaixuan</dc:creator>
 <dc:creator>Ororbia II, Alexander G.</dc:creator>
 <dc:creator>Xing, Xinyu</dc:creator>
 <dc:creator>Liu, Xue</dc:creator>
 <dc:creator>Giles, C. Lee</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  It has been shown that rules can be extracted from highly non-linear,
recursive models such as recurrent neural networks (RNNs). The RNN models
mostly investigated include both Elman networks and second-order recurrent
networks. Recently, new types of RNNs have demonstrated superior power in
handling many machine learning tasks, especially when structural data is
involved such as language modeling. Here, we empirically evaluate different
recurrent models on the task of learning deterministic finite automata (DFA),
the seven Tomita grammars. We are interested in the capability of recurrent
models with different architectures in learning and expressing regular
grammars, which can be the building blocks for many applications dealing with
structural data. Our experiments show that a second-order RNN provides the best
and stablest performance of extracting DFA over all Tomita grammars and that
other RNN models are greatly influenced by different Tomita grammars. To better
understand these results, we provide a theoretical analysis of the &quot;complexity&quot;
of different grammars, by introducing the entropy and the averaged edit
distance of regular grammars defined in this paper. Through our analysis, we
categorize all Tomita grammars into different classes, which explains the
inconsistency in the performance of extraction observed across all RNN models.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05423</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A random walk through experimental mathematics</dc:title>
 <dc:creator>Chan, Eunice Y. S.</dc:creator>
 <dc:creator>Corless, Robert M.</dc:creator>
 <dc:subject>Mathematics - History and Overview</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>68W30, 30B70, 37N30</dc:subject>
 <dc:description>  We describe our adventures in creating a new first-year course in
Experimental Mathematics that uses active learning. We used a state-of-the-art
facility, called The Western Active Learning Space, and got the students to
&quot;drive the spaceship&quot; (at least a little bit). This paper describes some of our
techniques for pedagogy, some of the vignettes of experimental mathematics that
we used, and some of the outcomes. EYSC was a student in the
simultaneously-taught senior sister course &quot;Open Problems in Experimental
Mathematics&quot; the first time it was taught and an unofficial co-instructor the
second time. Jon Borwein attended the Project Presentation Day (the second
time) and gave thoughtful feedback to each student. This paper is dedicated to
his memory.
</dc:description>
 <dc:description>Comment: 25 pages, 7 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05449</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ConvSRC: SmartPhone based Periocular Recognition using Deep
  Convolutional Neural Network and Sparsity Augmented Collaborative
  Representation</dc:title>
 <dc:creator>Alahmadi, Amani</dc:creator>
 <dc:creator>Hussain, Muhammad</dc:creator>
 <dc:creator>Aboalsamh, Hatim</dc:creator>
 <dc:creator>Zuair, Mansour</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Smartphone based periocular recognition has gained significant attention from
biometric research community because of the limitations of biometric modalities
like face, iris etc. Most of the existing methods for periocular recognition
employ hand-crafted features. Recently, learning based image representation
techniques like deep Convolutional Neural Network (CNN) have shown outstanding
performance in many visual recognition tasks. CNN needs a huge volume of data
for its learning, but for periocular recognition only limited amount of data is
available. The solution is to use CNN pre-trained on the dataset from the
related domain, in this case the challenge is to extract efficiently the
discriminative features. Using a pertained CNN model (VGG-Net), we propose a
simple, efficient and compact image representation technique that takes into
account the wealth of information and sparsity existing in the activations of
the convolutional layers and employs principle component analysis. For
recognition, we use an efficient and robust Sparse Augmented Collaborative
Representation based Classification (SA-CRC) technique. For thorough evaluation
of ConvSRC (the proposed system), experiments were carried out on the VISOB
challenging database which was presented for periocular recognition competition
in ICIP2016. The obtained results show the superiority of ConvSRC over the
state-of-the-art methods; it obtains a GMR of more than 99% at FMR = 10-3 and
outperforms the first winner of ICIP2016 challenge by 10%.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05453</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Word Importance: Contextual Decomposition to Extract Interactions
  from LSTMs</dc:title>
 <dc:creator>Murdoch, W. James</dc:creator>
 <dc:creator>Liu, Peter J.</dc:creator>
 <dc:creator>Yu, Bin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The driving force behind the recent success of LSTMs has been their ability
to learn complex and non-linear relationships. Consequently, our inability to
describe these relationships has led to LSTMs being characterized as black
boxes. To this end, we introduce contextual decomposition (CD), an
interpretation algorithm for analysing individual predictions made by standard
LSTMs, without any changes to the underlying model. By decomposing the output
of a LSTM, CD captures the contributions of combinations of words or variables
to the final prediction of an LSTM. On the task of sentiment analysis with the
Yelp and SST data sets, we show that CD is able to reliably identify words and
phrases of contrasting sentiment, and how they are combined to yield the LSTM's
final prediction. Using the phrase-level labels in SST, we also demonstrate
that CD is able to successfully extract positive and negative negations from an
LSTM, something which has not previously been done.
</dc:description>
 <dc:description>Comment: Under review at ICLR 2018</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05457</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solutions to problems with deep learning</dc:title>
 <dc:creator>Wolff, J Gerard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Despite the several successes of deep learning systems, there are concerns
about their limitations, discussed most recently by Gary Marcus. This paper
discusses Marcus's concerns and some others, together with solutions to several
of these problems provided by the &quot;P theory of intelligence&quot; and its
realisation in the &quot;SP computer model&quot;. The main advantages of the SP system
are: relatively small requirements for data and the ability to learn from a
single experience; the ability to model both hierarchical and non-hierarchical
structures; strengths in several kinds of reasoning, including `commonsense'
reasoning; transparency in the representation of knowledge, and the provision
of an audit trail for all processing; the likelihood that the SP system could
not be fooled into bizarre or eccentric recognition of stimuli, as deep
learning systems can be; the SP system provides a robust solution to the
problem of `catastrophic forgetting' in deep learning systems; the SP system
provides a theoretically-coherent solution to the problems of correcting over-
and under-generalisations in learning, and learning correct structures despite
errors in data; unlike most research on deep learning, the SP programme of
research draws extensively on research on human learning, perception, and
cognition; and the SP programme of research has an overarching theory,
supported by evidence, something that is largely missing from research on deep
learning. In general, the SP system provides a much firmer foundation than deep
learning for the development of artificial general intelligence.
</dc:description>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05458</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Network for Simultaneous Decomposition and Classification in
  UWB-SAR Imagery</dc:title>
 <dc:creator>Vu, Tiep</dc:creator>
 <dc:creator>Nguyen, Lam</dc:creator>
 <dc:creator>Guo, Tiantong</dc:creator>
 <dc:creator>Monga, Vishal</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Classifying buried and obscured targets of interest from other natural and
manmade clutter objects in the scene is an important problem for the U.S. Army.
Targets of interest are often represented by signals captured using
low-frequency (UHF to L-band) ultra-wideband (UWB) synthetic aperture radar
(SAR) technology. This technology has been used in various applications,
including ground penetration and sensing-through-the-wall. However, the
technology still faces a significant issues regarding low-resolution SAR
imagery in this particular frequency band, low radar cross sections (RCS),
small objects compared to radar signal wavelengths, and heavy interference. The
classification problem has been firstly, and partially, addressed by sparse
representation-based classification (SRC) method which can extract noise from
signals and exploit the cross-channel information. Despite providing potential
results, SRC-related methods have drawbacks in representing nonlinear relations
and dealing with larger training sets. In this paper, we propose a Simultaneous
Decomposition and Classification Network (SDCN) to alleviate noise inferences
and enhance classification accuracy. The network contains two jointly trained
sub-networks: the decomposition sub-network handles denoising, while the
classification sub-network discriminates targets from confusers. Experimental
results show significant improvements over a network without decomposition and
SRC-related methods.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05459</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Considerations regarding security issues impact on systems availability</dc:title>
 <dc:creator>Pricop, Emil</dc:creator>
 <dc:creator>Mihalache, Sanda Florentina</dc:creator>
 <dc:creator>Paraschiv, Nicolae</dc:creator>
 <dc:creator>Fattahi, Jaouhar</dc:creator>
 <dc:creator>Zamfir, Florin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Control systems behavior can be analyzed taking into account a large number
of parameters: performances, reliability, availability, security. Each control
system presents various security vulnerabilities that affect in lower or higher
measure its functioning. In this paper the authors present a method to assess
the impact of security issues on the systems availability. A fuzzy model for
estimating the availability of the system based on the security level and
achieved availability coefficient (depending on MTBF and MTR) is developed and
described. The results of the fuzzy inference system (FIS) are presented in the
last section of the paper.
</dc:description>
 <dc:description>Comment: Paper accepted for 2016 8th International Conference on Electronics,
  Computers and Artificial Intelligence (ECAI 2016) Proceedings, Ploiesti,
  Romania</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05462</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Role of Conditional Independence in the Evolution of Intelligent
  Systems</dc:title>
 <dc:creator>Schossau, Jory</dc:creator>
 <dc:creator>Albantakis, Larissa</dc:creator>
 <dc:creator>Hintze, Arend</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Systems are typically made from simple components regardless of their
complexity. While the function of each part is easily understood, higher order
functions are emergent properties and are notoriously difficult to explain. In
networked systems, both digital and biological, each component receives inputs,
performs a simple computation, and creates an output. When these components
have multiple outputs, we intuitively assume that the outputs are causally
dependent on the inputs but are themselves independent of each other given the
state of their shared input. However, this intuition can be violated for
components with probabilistic logic, as these typically cannot be decomposed
into separate logic gates with one output each. This violation of conditional
independence on the past system state is equivalent to instantaneous
interaction --- the idea is that some information between the outputs is not
coming from the inputs and thus must have been created instantaneously. Here we
compare evolved artificial neural systems with and without instantaneous
interaction across several task environments. We show that systems without
instantaneous interactions evolve faster, to higher final levels of
performance, and require fewer logic components to create a densely connected
cognitive machinery.
</dc:description>
 <dc:description>Comment: Original Abstract submitted to the GECCO conference 2017 Berlin</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05463</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep learning for topology optimization design</dc:title>
 <dc:creator>Yu, Yonggyun</dc:creator>
 <dc:creator>Hur, Taeil</dc:creator>
 <dc:creator>Jung, Jaeho</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Generative modeling techniques are being rapidly developed in the field of
deep learning, and they have been applied to topology optimization. The
variational autoencoder (VAE) is a generative modeling technology that extends
the autoencoder to generate new images with a limited latent space. We modified
the basic VAE structure to encode optimization conditions and decode latent
variables for topology optimization design. The modified VAE could efficiently
predict the optimized structure after topology optimization. However, it was
difficult to train the neural network to predict a very detailed structure. The
generative adversarial network (GAN) is another generative modeling technique
for generating images and is implemented by a system of two neural networks
competing with each other to make realistic synthetic data. We applied GAN to
obtain more detailed optimized results from the original design. The proposed
methodology of using two generative modeling techniques for deep learning is
expected to significantly increase the efficiency of topology optimization.
</dc:description>
 <dc:description>Comment: 21 page, 12 figures, The paper is under review to be published in the
  Structural and Multidisciplinary Optimization journal, Springer</dc:description>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05469</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ProvThreads: Analytic Provenance Visualization and Segmentation</dc:title>
 <dc:creator>Mohseni, Sina</dc:creator>
 <dc:creator>Pena, Alyssa</dc:creator>
 <dc:creator>Ragan, Eric D.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Our work aims to generate visualizations to enable meta-analysis of analytic
provenance and aid better understanding of analysts' strategies during
exploratory text analysis. We introduce ProvThreads, a visual analytics
approach that incorporates interactive topic modeling outcomes to illustrate
relationships between user interactions and the data topics under
investigation. ProvThreads uses a series of continuous analysis paths called
topic threads to demonstrate both topic coverage and the progression of an
investigation over time. As an analyst interacts with different pieces of data
during the analysis, interactions are logged and used to track user interests
in topics over time. A line chart shows different amounts of interest in
multiple topics over the duration of the analysis. We discuss how different
configurations of ProvThreads can be used to reveal changes in focus throughout
an analysis.
</dc:description>
 <dc:description>Comment: Presented at IEEE VIS 2017 Poster Session</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05479</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Belief Control Strategies for Interactions over Weak Graphs</dc:title>
 <dc:creator>Salami, Hawraa</dc:creator>
 <dc:creator>Ying, Bicheng</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In diffusion social learning over weakly-connected graphs, it has been shown
recently that influential agents end up shaping the beliefs of non-influential
agents. This paper analyzes this control mechanism more closely and addresses
two main questions. First, the article examines how much freedom influential
agents have in controlling the beliefs of the receiving agents. That is, the
derivations clarify whether receiving agents can be driven to arbitrary beliefs
and whether the network structure limits the scope of control by the
influential agents. Second, even if there is a limit to what influential agents
can accomplish, this article develops mechanisms by which these agents can lead
receiving agents to adopt certain beliefs. These questions raise interesting
possibilities about belief control over networked agents. Once addressed, one
ends up with design procedures that allow influential agents to drive other
agents to endorse particular beliefs regardless of their local observations or
convictions. The theoretical findings are illustrated by means of several
examples.
</dc:description>
 <dc:description>Comment: Submitted for publication</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05483</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pilot Contamination Mitigation with Reduced RF Chains</dc:title>
 <dc:creator>Ioushua, Shahar S.</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive multiple-input multiple-output (MIMO) communication is a promising
technology for increasing spectral efficiency in wireless networks. Two of the
main challenges massive MIMO systems face are degraded channel estimation
accuracy due to pilot contamination and increase in computational load and
hardware complexity due to the massive amount of antennas. In this paper, we
focus on the problem of channel estimation in massive MIMO systems, while
addressing these two challenges: We jointly design the pilot sequences to
mitigate the effect of pilot contamination and propose an analog combiner which
maps the high number of sensors to a low number of RF chains, thus reducing the
computational and hardware cost. We consider a statistical model in which the
channel covariance obeys a Kronecker structure. In particular, we treat two
such cases, corresponding to fully- and partially-separable correlations. We
prove that with these models, the analog combiner design can be done
independently of the pilot sequences. Given the resulting combiner, we derive a
closed-form expression for the optimal pilot sequences in the fully-separable
case and suggest a greedy sum of ratio traces maximization (GSRTM) method for
designing sub-optimal pilots in the partially-separable scenario. We
demonstrate via simulations that our pilot design framework achieves lower mean
squared error than the common pilot allocation framework previously considered
for pilot contamination mitigation.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures, submitted to IEEE Transactions on Signal
  Processing</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05489</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Longest Processing Time rule for identical parallel machines revisited</dc:title>
 <dc:creator>Della Croce, Federico</dc:creator>
 <dc:creator>Scatamacchia, Rosario</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the Pm || Cmax scheduling problem where the goal is to schedule n
jobs on m identical parallel machines to minimize makespan. We revisit the
famous Longest Processing Time (LPT) rule proposed by Graham in 1969. LPT
requires to sort jobs in non-ascending order of processing times and then to
assign one job at a time to the machine whose load is smallest so far. We
provide new insights on LPT and discuss the approximation ratio of a
modification of LPT that improves Graham's bound from 4/3 - 1/(3m) to 4/3 -
1/(3(m-1)) for m &gt;= 3 and from 7/6 to 9/8 for m = 2. We use Linear Programming
(LP) to analyze the approximation ratio of our approach. This performance
analysis can be seen as a valid alternative to formal proofs based on
analytical derivation. Also, we derive from the proposed approach an O(n log n)
heuristic. The heuristic splits the sorted jobset in tuples of m consecutive
jobs (1,...,m; m+1,...,2m; etc.) and sorts the tuples in non-increasing order
of the difference (slack) between largest job and smallest job in the tuple.
Then, List Scheduling is applied to the set of sorted tuples. This approach
strongly outperforms LPT on benchmark literature instances.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05496</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic aspects of graph-indexed random walks</dc:title>
 <dc:creator>Bok, Jan</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We study three problems regarding the so called graph-indexed random walks
(or equivalently Lipschitz mappings of graphs). Computing the average range of
graph-indexed random walk of a graph. Computing the maximum range of
graph-indexed random walk for a given graph. Deciding if we can extend partial
GI random walk into full GI random walk for a given graph. We show that while
the first problem is $\#$P-complete, the other two problems can be solved in
polynomial time.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05498</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-indexed random walks on special classes of graphs</dc:title>
 <dc:creator>Bok, Jan</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We investigate the paramater of the average range of $M$-Lipschitz mapping of
a given graph. We focus on well-known classes such as paths, complete graphs,
complete bipartite graphs and cycles and show closed formulas for computing
this parameter and also we conclude asymptotics of this parameter on these
aforementioned classes.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05500</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cellular-Connected UAVs over 5G: Deep Reinforcement Learning for
  Interference Management</dc:title>
 <dc:creator>Challita, Ursula</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bettstetter, Christian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper, an interference-aware path planning scheme for a network of
cellular-connected unmanned aerial vehicles (UAVs) is proposed. In particular,
each UAV aims at achieving a tradeoff between maximizing energy efficiency and
minimizing both wireless latency and the interference level caused on the
ground network along its path. The problem is cast as a dynamic game among
UAVs. To solve this game, a deep reinforcement learning algorithm, based on
echo state network (ESN) cells, is proposed. The introduced deep ESN
architecture is trained to allow each UAV to map each observation of the
network state to an action, with the goal of minimizing a sequence of
time-dependent utility functions. Each UAV uses ESN to learn its optimal path,
transmission power level, and cell association vector at different locations
along its path. The proposed algorithm is shown to reach a subgame perfect Nash
equilibrium (SPNE) upon convergence. Moreover, an upper and lower bound for the
altitude of the UAVs is derived thus reducing the computational complexity of
the proposed algorithm. Simulation results show that the proposed scheme
achieves better wireless latency per UAV and rate per ground user (UE) while
requiring a number of steps that is comparable to a heuristic baseline that
considers moving via the shortest distance towards the corresponding
destinations. The results also show that the optimal altitude of the UAVs
varies based on the ground network density and the UE data rate requirements
and plays a vital role in minimizing the interference level on the ground UEs
as well as the wireless transmission delay of the UAV.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05504</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Classification of Music Genre using Masked Conditional Neural
  Networks</dc:title>
 <dc:creator>Medhat, Fady</dc:creator>
 <dc:creator>Chesmore, David</dc:creator>
 <dc:creator>Robinson, John</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural network based architectures used for sound recognition are usually
adapted from other application domains such as image recognition, which may not
harness the time-frequency representation of a signal. The ConditionaL Neural
Networks (CLNN) and its extension the Masked ConditionaL Neural Networks
(MCLNN) are designed for multidimensional temporal signal recognition. The CLNN
is trained over a window of frames to preserve the inter-frame relation, and
the MCLNN enforces a systematic sparseness over the network's links that mimics
a filterbank-like behavior. The masking operation induces the network to learn
in frequency bands, which decreases the network susceptibility to
frequency-shifts in time-frequency representations. Additionally, the mask
allows an exploration of a range of feature combinations concurrently analogous
to the manual handcrafting of the optimum collection of features for a
recognition task. MCLNN have achieved competitive performance on the Ballroom
music dataset compared to several hand-crafted attempts and outperformed models
based on state-of-the-art Convolutional Neural Networks.
</dc:description>
 <dc:description>Comment: Restricted Boltzmann Machine; RBM; Conditional RBM; CRBM; Deep Belief
  Net; DBN; Conditional Neural Network; CLNN; Masked Conditional Neural
  Network; MCLNN; Music Information Retrieval; MIR. IEEE International
  Conference on Data Mining (ICDM), 2017</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05504</dc:identifier>
 <dc:identifier>IEEE International Conference on Data Mining (ICDM) Year: 2017
  Pages: 979 - 984</dc:identifier>
 <dc:identifier>doi:10.1109/ICDM.2017.125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05507</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gazelle: A Low Latency Framework for Secure Neural Network Inference</dc:title>
 <dc:creator>Juvekar, Chiraag</dc:creator>
 <dc:creator>Vaikuntanathan, Vinod</dc:creator>
 <dc:creator>Chandrakasan, Anantha</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The growing popularity of cloud-based machine learning raises a natural
question about the privacy guarantees that can be provided in such a setting.
Our work tackles this problem in the context where a client wishes to classify
private images using a convolutional neural network (CNN) trained by a server.
Our goal is to build efficient protocols whereby the client can acquire the
classification result without revealing their input to the server, while
guaranteeing the privacy of the server's neural network.
  To this end, we design Gazelle, a scalable and low-latency system for secure
neural network inference, using an intricate combination of homomorphic
encryption and traditional two-party computation techniques (such as garbled
circuits). Gazelle makes three contributions. First, we design the Gazelle
homomorphic encryption library which provides fast algorithms for basic
homomorphic operations such as SIMD (single instruction multiple data)
addition, SIMD multiplication and ciphertext permutation. Second, we implement
the Gazelle homomorphic linear algebra kernels which map neural network layers
to optimized homomorphic matrix-vector multiplication and convolution routines.
Third, we design optimized encryption switching protocols which seamlessly
convert between homomorphic and garbled circuit encodings to enable
implementation of complete neural network inference.
  We evaluate our protocols on benchmark neural networks trained on the MNIST
and CIFAR-10 datasets and show that Gazelle outperforms the best existing
systems such as MiniONN (ACM CCS 2017) by 20 times and Chameleon (Crypto Eprint
2017/1164) by 30 times in online runtime. Similarly when compared with fully
homomorphic approaches like CryptoNets (ICML 2016) we demonstrate three orders
of magnitude faster online run-time.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05512</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Networks for Survival Analysis Based on a Multi-Task
  Framework</dc:title>
 <dc:creator>Fotso, Stephane</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Survival analysis/time-to-event models are extremely useful as they can help
companies predict when a customer will buy a product, churn or default on a
loan, and therefore help them improve their ROI. In this paper, we introduce a
new method to calculate survival functions using the Multi-Task Logistic
Regression (MTLR) model as its base and a deep learning architecture as its
core. Based on the Concordance index (C-index) and Brier score, this method
outperforms the MTLR in all the experiments disclosed in this paper as well as
the Cox Proportional Hazard (CoxPH) model when nonlinear dependencies are
found.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05521</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event-triggered Control of Infinite-dimensional Systems</dc:title>
 <dc:creator>Wakaiki, Masashi</dc:creator>
 <dc:creator>Sano, Hideki</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider the event-triggered control of continuous-time linear
infinite-dimensional systems. We show that an event trigger that measures the
difference of a control input leads to the positive minimum inter-event time if
a feedback operator is compact. Moreover, under certain natural assumptions on
the infinite-dimensional system, we show that there exists an event trigger
such that the closed-loop system is exponentially stable.
</dc:description>
 <dc:description>Comment: 24 pages, 2 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05522</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coded Computing for Distributed Graph Analytics</dc:title>
 <dc:creator>Prakash, Saurav</dc:creator>
 <dc:creator>Reisizadeh, Amirhossein</dc:creator>
 <dc:creator>Pedarsani, Ramtin</dc:creator>
 <dc:creator>Avestimehr, Salman</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Many distributed graph computing systems have been developed recently for
efficient processing of massive graphs. These systems require many messages to
be exchanged among computing machines at each step of the computation, making
communication bandwidth a major performance bottleneck. We present a coded
computing framework that systematically injects redundancy in the computation
phase to enable coding opportunities in the communication phase thus reducing
the communication load substantially. Specifically, we propose coded schemes
that enable an inverse-linear trade-off (asymptotically) between computation
load and average communication load for three popular random graphs --
Erd\&quot;os-R\'enyi (ER), random bi-partite (RB), stochastic block model (SBM). The
proposed scheme for ER graph is shown to be optimal asymptotically as the graph
size $n\rightarrow \infty$. For finite $n$, we demonstrate via numerical
analysis that for a given computation load $r$, i.e. when each graph node is
carefully stored at $r$ servers, the proposed scheme slashes the average
communication load by (nearly) $r$.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05525</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification of Seed Cells in Multispectral Images for GrowCut
  Segmentation</dc:title>
 <dc:creator>Torres, Wuilan</dc:creator>
 <dc:creator>Rueda-Toicen, Antonio</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The segmentation of satellite images is a necessary step to perform
object-oriented image classification, which has become relevant due to its
applicability on images with a high spatial resolution. To perform
object-oriented image classification, the studied image must first be segmented
in uniform regions. This segmentation requires manual work by an expert user,
who must exhaustively explore the image to establish thresholds that generate
useful and representative segments without oversegmenting and without
discarding representative segments. We propose a technique that automatically
segments the multispectral image while facing these issues. We identify in the
image homogenous zones according to their spectral signatures through the use
of morphological filters. These homogenous zones are representatives of
different types of land coverings in the image and are used as seeds for the
GrowCut multispectral segmentation algorithm. GrowCut is a cellular automaton
with competitive region growth, its cells are linked to every pixel in the
image through three parameters: the pixel's spectral signature, a label, and a
strength factor that represents the strength with which a cell defends its
label. The seed cells possess maximum strength and maintain their state
throughout the automaton's evolution. Starting from seed cells, each cell in
the image is iteratively attacked by its neighboring cells. When the automaton
stops updating its states, we obtain a segmented image where each pixel has
taken the label of one of its cells. In this paper the algorithm was applied in
an image acquired by Landsat8 on agricultural land of Calabozo, Guarico,
Venezuela where there are different types of land coverings: agriculture, urban
regions, water bodies, and savannas with different degrees of human
intervention. The segmentation obtained is presented as irregular polygons
enclosing geographical objects.
</dc:description>
 <dc:description>Comment: 10 pages, in Spanish, originally presented at CIMENICS 2016, accepted
  to the Journal of the Faculty of Engineering UCV</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05525</dc:identifier>
 <dc:language>es</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05527</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cahn--Hilliard inpainting with the double obstacle potential</dc:title>
 <dc:creator>Garcke, Harald</dc:creator>
 <dc:creator>Lam, Kei Fong</dc:creator>
 <dc:creator>Styles, Vanessa</dc:creator>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>49J40, 94A08, 68U10, 35K55</dc:subject>
 <dc:description>  The inpainting of damaged images has a wide range of applications and many
different mathematical methods have been proposed to solve this problem.
Inpainting witht the help of Cahn--Hilliard models has been particularly
successful, and it turns out that Cahn--Hilliard inpainting with the double
obstacle potential can lead to better results compared to inpainting with a
smooth double well potential. However, a mathematical analysis of this approach
is missing so far. In this paper we give first analytical results for a
Cahn--Hilliard double obstacle model and in particular we can show existence of
stationary solutions without constraints on the parameters involved. With the
help of numerical results we show the effectiveness of the approach for binary
and grayscale images.
</dc:description>
 <dc:description>Comment: 24 pages, 7 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05532</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning based Recommender System using Biclustering
  Technique</dc:title>
 <dc:creator>Choi, Sungwoon</dc:creator>
 <dc:creator>Ha, Heonseok</dc:creator>
 <dc:creator>Hwang, Uiwon</dc:creator>
 <dc:creator>Kim, Chanju</dc:creator>
 <dc:creator>Ha, Jung-Woo</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A recommender system aims to recommend items that a user is interested in
among many items. The need for the recommender system has been expanded by the
information explosion. Various approaches have been suggested for providing
meaningful recommendations to users. One of the proposed approaches is to
consider a recommender system as a Markov decision process (MDP) problem and
try to solve it using reinforcement learning (RL). However, existing RL-based
methods have an obvious drawback. To solve an MDP in a recommender system, they
encountered a problem with the large number of discrete actions that bring RL
to a larger class of problems. In this paper, we propose a novel RL-based
recommender system. We formulate a recommender system as a gridworld game by
using a biclustering technique that can reduce the state and action space
significantly. Using biclustering not only reduces space but also improves the
recommendation quality effectively handling the cold-start problem. In
addition, our approach can provide users with some explanation why the system
recommends certain items. Lastly, we examine the proposed algorithm on a
real-world dataset and achieve a better performance than the widely used
recommendation algorithm.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, IFUP2018(WSDM 2018 workshop)</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05534</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind De-anonymization Attacks using Social Networks</dc:title>
 <dc:creator>Lee, Wei-Han</dc:creator>
 <dc:creator>Liu, Changchang</dc:creator>
 <dc:creator>Ji, Shouling</dc:creator>
 <dc:creator>Mittal, Prateek</dc:creator>
 <dc:creator>Lee, Ruby</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  It is important to study the risks of publishing privacy-sensitive data. Even
if sensitive identities (e.g., name, social security number) were removed and
advanced data perturbation techniques were applied, several de-anonymization
attacks have been proposed to re-identify individuals. However, existing
attacks have some limitations: 1) they are limited in de-anonymization
accuracy; 2) they require prior seed knowledge and suffer from the imprecision
of such seed information.
  We propose a novel structure-based de-anonymization attack, which does not
require the attacker to have prior information (e.g., seeds). Our attack is
based on two key insights: using multi-hop neighborhood information, and
optimizing the process of de-anonymization by exploiting enhanced machine
learning techniques. The experimental results demonstrate that our method is
robust to data perturbations and significantly outperforms the state-of-the-art
de-anonymization techniques by up to $10\times$ improvement.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05535</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ALE: Additive Latent Effect Models for Grade Prediction</dc:title>
 <dc:creator>Ren, Zhiyun</dc:creator>
 <dc:creator>Ning, Xia</dc:creator>
 <dc:creator>Rangwala, Huzefa</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The past decade has seen a growth in the development and deployment of
educational technologies for assisting college-going students in choosing
majors, selecting courses and acquiring feedback based on past academic
performance. Grade prediction methods seek to estimate a grade that a student
may achieve in a course that she may take in the future (e.g., next term).
Accurate and timely prediction of students' academic grades is important for
developing effective degree planners and early warning systems, and ultimately
improving educational outcomes. Existing grade pre- diction methods mostly
focus on modeling the knowledge components associated with each course and
student, and often overlook other factors such as the difficulty of each
knowledge component, course instructors, student interest, capabilities and
effort. In this paper, we propose additive latent effect models that
incorporate these factors to predict the student next-term grades.
Specifically, the proposed models take into account four factors: (i) student's
academic level, (ii) course instructors, (iii) student global latent factor,
and (iv) latent knowledge factors. We compared the new models with several
state-of-the-art methods on students of various characteristics (e.g., whether
a student transferred in or not). The experimental results demonstrate that the
proposed methods significantly outperform the baselines on grade prediction
problem. Moreover, we perform a thorough analysis on the importance of
different factors and how these factors can practically assist students in
course selection, and finally improve their academic performance.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05535</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05537</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual-Mobile-Core Placement for Metro Network</dc:title>
 <dc:creator>Gupta, Abhishek</dc:creator>
 <dc:creator>Tornatore, Massimo</dc:creator>
 <dc:creator>Jaumard, Brigitte</dc:creator>
 <dc:creator>Mukherjee, Biswanath</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Traditional highly-centralized mobile core networks (e.g., Evolved Packet
Core (EPC)) need to be constantly upgraded both in their network functions and
backhaul links, to meet increasing traffic demands. Network Function
Virtualization (NFV) is being investigated as a potential cost-effective
solution for this upgrade. A virtual mobile core (here, virtual EPC, vEPC)
provides deployment flexibility and scalability while reducing costs,
network-resource consumption and application delay. Moreover, a distributed
deployment of vEPC is essential for emerging paradigms like Multi-Access Edge
Computing (MEC). In this work, we show that significant reduction in
networkresource consumption can be achieved as a result of optimal placement of
vEPC functions in metro area. Further, we show that not all vEPC functions need
to be distributed. In our study, for the first time, we account for vEPC
interactions in both data and control planes (Non-Access Stratum (NAS)
signaling procedure Service Chains (SCs) with application latency requirements)
using a detailed mathematical model.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05538</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable Phaseless Sampling and Reconstruction of Real-Valued Signals with
  Finite Rate of Innovations</dc:title>
 <dc:creator>Cheng, Cheng</dc:creator>
 <dc:creator>Sun, Qiyu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A12, 94A20, 42C15</dc:subject>
 <dc:description>  A spatial signal is defined by its evaluations on the whole domain. In this
paper, we consider stable reconstruction of real-valued signals with finite
rate of innovations (FRI), up to a sign, from their magnitude measurements on
the whole domain or their phaseless samples on a discrete subset. FRI signals
appear in many engineering applications such as magnetic resonance spectrum,
ultra wide-band communication and electrocardiogram. For an FRI signal, we
introduce an undirected graph to describe its topological structure. We
establish the equivalence between the graph connectivity and phase
retrievability of FRI signals, and we apply the graph connected component
decomposition to find all FRI signals that have the same magnitude measurements
as the original FRI signal has. We construct discrete sets with finite density
explicitly so that magnitude measurements of FRI signals on the whole domain
are determined by their samples taken on those discrete subsets. In this paper,
we also propose a stable algorithm with linear complexity to reconstruct FRI
signals from their phaseless samples on the above phaseless sampling set. The
proposed algorithm is demonstrated theoretically and numerically to provide a
suboptimal approximation to the original FRI signal in magnitude measurements.
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05541</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Over-the-Air Implementation of Uplink NOMA</dc:title>
 <dc:creator>Abeywickrama, Samith</dc:creator>
 <dc:creator>Liu, Lei</dc:creator>
 <dc:creator>Chi, Yuhao</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Though the concept of non-orthogonal multiple access (NOMA) was proposed
several years ago, the performance of uplink NOMA has only been verified in
theory, but not in practice. This paper presents an over-the-air implementation
of a uplink NOMA system, while providing solutions to most common practical
problems, i.e., carrier frequency offset (CFO) synchronization, time
synchronization, and channel estimation. The implemented CFO synchronization
method adopts the primary synchronization signal (PSS) of LTE. Also, we design
a novel preamble for each uplink user, and it is appended to every frame before
it is transmitted through the air. This preamble will be used for time
synchronization and channel estimation at the BS. Also, a low-complexity,
iterative linear minimum mean squared error (LMMSE) detector has been
implemented for multi-user decoding. The paper also validates the proposed
architecture numerically, as well as experimentally.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures, in Proc. IEEE Global Communications Conference
  (GLOBECOM), 2017</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05541</dc:identifier>
 <dc:identifier>doi:10.1109/GLOCOM.2017.8254920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05544</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NELS - Never-Ending Learner of Sounds</dc:title>
 <dc:creator>Elizalde, Benjamin</dc:creator>
 <dc:creator>Badlani, Rohan</dc:creator>
 <dc:creator>Shah, Ankit</dc:creator>
 <dc:creator>Kumar, Anurag</dc:creator>
 <dc:creator>Raj, Bhiksha</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Sounds are essential to how humans perceive and interact with the world and
are captured in recordings and shared on the Internet on a minute-by-minute
basis. These recordings, which are predominantly videos, constitute the largest
archive of sounds we know. However, most of these recordings have undescribed
content making necessary methods for automatic sound analysis, indexing and
retrieval. These methods have to address multiple challenges, such as the
relation between sounds and language, numerous and diverse sound classes, and
large-scale evaluation. We propose a system that continuously learns from the
web relations between sounds and language, improves sound recognition models
over time and evaluates its learning competency in the large-scale without
references. We introduce the Never-Ending Learner of Sounds (NELS), a project
for continuously learning of sounds and their associated knowledge, available
on line in nels.cs.cmu.edu
</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05551</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised FusedGAN for Conditional Image Generation</dc:title>
 <dc:creator>Bodla, Navaneeth</dc:creator>
 <dc:creator>Hua, Gang</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present FusedGAN, a deep network for conditional image synthesis with
controllable sampling of diverse images. Fidelity, diversity and controllable
sampling are the main quality measures of a good image generation model. Most
existing models are insufficient in all three aspects. The FusedGAN can perform
controllable sampling of diverse images with very high fidelity. We argue that
controllability can be achieved by disentangling the generation process into
various stages. In contrast to stacked GANs, where multiple stages of GANs are
trained separately with full supervision of labeled intermediate images, the
FusedGAN has a single stage pipeline with a built-in stacking of GANs. Unlike
existing methods, which requires full supervision with paired conditions and
images, the FusedGAN can effectively leverage more abundant images without
corresponding conditions in training, to produce more diverse samples with high
fidelity. We achieve this by fusing two generators: one for unconditional image
generation, and the other for conditional image generation, where the two
partly share a common latent space thereby disentangling the generation. We
demonstrate the efficacy of the FusedGAN in fine grained image generation tasks
such as text-to-image, and attribute-to-face generation.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05554</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>rlsm: R package for least squares Monte Carlo</dc:title>
 <dc:creator>Yee, Jeremy</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  This short paper briefly describes the implementation of the least squares
Monte Carlo method in the rlsm package. This package provides users with an
easy manner to experiment with the large amount of R regression tools on any
regression basis and reward functions. This package also computes lower and
upper bounds for the true value function via duality methods.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05558</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-Learning with Adaptive Layerwise Metric and Subspace</dc:title>
 <dc:creator>Lee, Yoonho</dc:creator>
 <dc:creator>Choi, Seungjin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent advances in meta-learning demonstrate that deep representations
combined with the gradient descent method have sufficient capacity to
approximate any learning algorithm. A promising approach is the model-agnostic
meta-learning (MAML) which embeds gradient descent into the meta-learner. It
optimizes for the initial parameters of the learner to warm-start the gradient
descent updates, such that new tasks can be solved using a small number of
examples. In this paper we elaborate the gradient-based meta-learning,
developing two new schemes. First, we present a feedforward neural network,
referred to as T-net, where the linear transformation between two adjacent
layers is decomposed as T W such that W is learned by task-specific learners
and the transformation T, which is shared across tasks, is meta-learned to
speed up the convergence of gradient updates for task-specific learners.
Second, we present MT-net where gradient updates in the T-net are guided by a
binary mask M that is meta-learned, restricting the updates to be performed in
a subspace. Empirical results demonstrate that our method is less sensitive to
the choice of initial learning rates than existing meta-learning methods, and
achieves the state-of-the-art or comparable performance on few-shot
classification and regression tasks.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05560</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fruit Quantity and Quality Estimation using a Robotic Vision System</dc:title>
 <dc:creator>Halstead, M.</dc:creator>
 <dc:creator>McCool, C.</dc:creator>
 <dc:creator>Denman, S.</dc:creator>
 <dc:creator>Perez, T.</dc:creator>
 <dc:creator>Fookes, C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accurate localisation of crop remains highly challenging in unstructured
environments such as farms. Many of the developed systems still rely on the use
of hand selected features for crop identification and often neglect the
estimation of crop quantity and quality, which is key to assigning labor during
farming processes. To alleviate these limitations we present a robotic vision
system that can accurately estimate the quantity and quality of sweet pepper
(Capsicum annuum L), a key horticultural crop. This system consists of three
parts: detection, quality estimation, and tracking. Efficient detection is
achieved using the FasterRCNN framework. Quality is then estimated in the same
framework by learning a parallel layer which we show experimentally results in
superior performance than treating quality as extra classes in the traditional
Faster-RCNN framework. Evaluation of these two techniques outlines the improved
performance of the parallel layer, where we achieve an F1 score of 77.3 for the
parallel technique yet only 72.5 for the best scoring (red) of the multi-class
implementation. To track the crop we present a tracking via detection approach,
which uses the FasterRCNN with parallel layers, that is also a vision-only
solution. This approach is cheap to implement as it only requires a camera and
in experiments across 2 days we show that our proposed system can accurately
estimate the number of sweet pepper present, within 4.1% of the ground truth.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05564</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Socialbots whitewashing contested elections; a case study from Honduras</dc:title>
 <dc:creator>Gallagher, E.</dc:creator>
 <dc:creator>Su&#xe1;rez-Serrato, P.</dc:creator>
 <dc:creator>Richards, E. I. Velazquez</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We analyze socialbots active tweeting in relation to Juan Orlando
Hern\'andez, the recently re-elected president of Honduras. We find a clear
bimodal separation between humans and bots, using Botometer and its
classifiers. Around one hundred separate communities of socialbots are
identified and visualized, detected through the analysis of temporally
coordinated retweets.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05566</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Analysis of Proximal Policy Optimization with
  Kronecker-factored Natural Gradients</dc:title>
 <dc:creator>Song, Jiaming</dc:creator>
 <dc:creator>Wu, Yuhuai</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this technical report, we consider an approach that combines the PPO
objective and K-FAC natural gradient optimization, for which we call PPOKFAC.
We perform a range of empirical analysis on various aspects of the algorithm,
such as sample complexity, training speed, and sensitivity to batch size and
training epochs. We observe that PPOKFAC is able to outperform PPO in terms of
sample complexity and speed in a range of MuJoCo environments, while being
scalable in terms of batch size. In spite of this, it seems that adding more
epochs is not necessarily helpful for sample efficiency, and PPOKFAC seems to
be worse than its A2C counterpart, ACKTR.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05567</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Diversity in Molecular Timing Channels via Order Statistics</dc:title>
 <dc:creator>Murin, Yonathan</dc:creator>
 <dc:creator>Farsad, Nariman</dc:creator>
 <dc:creator>Chowdhury, Mainak</dc:creator>
 <dc:creator>Goldsmith, Andrea</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study diversity in one-shot communication over molecular timing channels.
We consider a channel model where the transmitter simultaneously releases a
large number of information particles, while the information is encoded in the
time of release. The receiver decodes the information based on the random time
of arrival of the information particles. The random propagation is
characterized by the general class of right-sided unimodal densities. We
characterize the asymptotic exponential decrease rate of the probability of
error as a function of the number of released particles, and denote this
quantity as the system diversity gain. Four types of detectors are considered:
the maximum-likelihood (ML) detector, a linear detector, a detector that is
based on the first arrival (FA) among all the transmitted particles, and a
detector based on the last arrival (LA). When the density characterizing the
random propagation is supported over a large interval, we show that the simple
FA detector achieves a diversity gain very close to that of the ML detector. On
the other hand, when the density characterizing the random propagation is
supported over a small interval, we show that the simple LA detector achieves a
diversity gain very close to that of the ML detector.
</dc:description>
 <dc:description>Comment: Submitted for publication; 10 pages; 5 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05568</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Captioning using Deep Neural Architectures</dc:title>
 <dc:creator>Shah, Parth</dc:creator>
 <dc:creator>Bakarola, Vishvajit</dc:creator>
 <dc:creator>Pati, Supriya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatically creating the description of an image using any natural
languages sentence like English is a very challenging task. It requires
expertise of both image processing as well as natural language processing. This
paper discuss about different available models for image captioning task. We
have also discussed about how the advancement in the task of object recognition
and machine translation has greatly improved the performance of image
captioning model in recent years. In addition to that we have discussed how
this model can be implemented. In the end, we have also evaluated the
performance of model using standard evaluation matrices.
</dc:description>
 <dc:description>Comment: Pre-print version of paper accepted at 2017 International Conference
  on Innovations in information Embedded and Communication Systems (ICIIECS)</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05574</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brenier approach for optimal transportation between a quasi-discrete
  measure and a discrete measure</dc:title>
 <dc:creator>Lu, Ying</dc:creator>
 <dc:creator>Chen, Liming</dc:creator>
 <dc:creator>Saidi, Alexandre</dc:creator>
 <dc:creator>Gu, Xianfeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Correctly estimating the discrepancy between two data distributions has
always been an important task in Machine Learning. Recently, Cuturi proposed
the Sinkhorn distance which makes use of an approximate Optimal Transport cost
between two distributions as a distance to describe distribution discrepancy.
Although it has been successfully adopted in various machine learning
applications (e.g. in Natural Language Processing and Computer Vision) since
then, the Sinkhorn distance also suffers from two unnegligible limitations. The
first one is that the Sinkhorn distance only gives an approximation of the real
Wasserstein distance, the second one is the `divide by zero' problem which
often occurs during matrix scaling when setting the entropy regularization
coefficient to a small value. In this paper, we introduce a new Brenier
approach for calculating a more accurate Wasserstein distance between two
discrete distributions, this approach successfully avoids the two limitations
shown above for Sinkhorn distance and gives an alternative way for estimating
distribution discrepancy.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05583</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Know Your Enemy: Characteristics of Cyber-Attacks on Medical Imaging
  Devices</dc:title>
 <dc:creator>Nissim, Nir</dc:creator>
 <dc:creator>Mahler, Tom</dc:creator>
 <dc:creator>Shalom, Erez</dc:creator>
 <dc:creator>Goldenberg, Israel</dc:creator>
 <dc:creator>Hasman, Guy</dc:creator>
 <dc:creator>Makori, Arnon</dc:creator>
 <dc:creator>Kochav, Itzik</dc:creator>
 <dc:creator>Elovici, Yuval</dc:creator>
 <dc:creator>Shahar, Yuval</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Purpose: Used extensively in the diagnosis, treatment, and prevention of
disease, Medical Imaging Devices (MIDs), such as Magnetic Resonance Imaging
(MRI) or Computed Tomography (CT) machines, play an important role in medicine
today. MIDs are increasingly connected to hospital networks, making them
vulnerable to sophisticated cyber-attacks targeting the devices' infrastructure
and components, which can disrupt digital patient records, and potentially
jeopardize patients' health. Attacks on MIDs are likely to increase, as
attackers' skills improve and the number of unpatched devices with known
vulnerabilities that can be easily exploited grows. Attackers may also block
access to MIDs or disable them, as part of ransomware attacks, which have been
shown to be successful against hospitals. Method and Materials: We conducted a
comprehensive risk analysis survey at the Malware-Lab, based on the
Confidentiality, Integrity, and Availability (CIA) model, in collaboration with
our country's largest health maintenance organization, to define the
characteristics of cyber-attacks on MIDs. The survey includes a range of
vulnerabilities and potential attacks aimed at MIDs, medical and imaging
information systems, and medical protocols and standards such as DICOM and HL7.
Results: Based on our survey, we found that CT devices face the greatest risk
of cyber-attack, due to their pivotal role in acute care imaging. Thus, we
identified several possible attack vectors that target the infrastructure and
functionality of CT devices, which can cause: 1. Disruption of the parameters'
values used in the scanning protocols within the CT devices (e.g., tampering
with the radiation exposure levels); 2. Mechanical disruption of the CT device
(e.g., changing the pitch); 3. Disruption of the tomography scan signals
constructing the digital images; and 4. Denial-of-Service attacks against the
CT device.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05585</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Light-weight pixel context encoders for image inpainting</dc:title>
 <dc:creator>van Noord, Nanne</dc:creator>
 <dc:creator>Postma, Eric</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we propose Pixel Content Encoders (PCE), a light-weight image
inpainting model, capable of generating novel con-tent for large missing
regions in images. Unlike previously presented convolutional neural network
based models, our PCE model has an order of magnitude fewer trainable
parameters. Moreover, by incorporating dilated convolutions we are able to
preserve fine grained spatial information, achieving state-of-the-art
performance on benchmark datasets of natural images and paintings. Besides
image inpainting, we show that without changing the architecture, PCE can be
used for image extrapolation, generating novel content beyond existing image
boundaries.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05588</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>White or Blue, the Whale gets its Vengeance: A Social Media Analysis of
  the Blue Whale Challenge</dc:title>
 <dc:creator>Khattar, Abhinav</dc:creator>
 <dc:creator>Dabas, Karan</dc:creator>
 <dc:creator>Gupta, Kshitij</dc:creator>
 <dc:creator>Chopra, Shaan</dc:creator>
 <dc:creator>Kumaraguru, Ponnurangam</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The Blue Whale Challenge is a series of self-harm causing tasks that are
propagated via online social media under the disguise of a &quot;game.&quot; The list of
tasks must be completed in a duration of 50 days and they cause both physical
and mental harm to the player. The final task is to commit suicide. The game is
supposed to be administered by people called &quot;curators&quot; who incite others to
cause self-mutilation and commit suicide. The curators and potential players
are known to contact each other on social networking websites and the
conversations between them are suspected to take place mainly via direct
messages which are difficult to track. Though, in order to find curators, the
players make public posts containing certain hashtags/keywords to catch their
attention. Even though a lot of these social networks have moderated posts
talking about the game, yet some posts manage to pass their filters. Our
research focuses on (1) understanding the social media spread of the challenge,
(2) spotting the behaviour of the people taking interest in Blue Whale
challenge and, (3) analysing demographics of the users who may be involved in
playing the game.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05599</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Additive Margin Softmax for Face Verification</dc:title>
 <dc:creator>Wang, Feng</dc:creator>
 <dc:creator>Liu, Weiyang</dc:creator>
 <dc:creator>Liu, Haijun</dc:creator>
 <dc:creator>Cheng, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a conceptually simple and geometrically
interpretable objective function, i.e. additive margin Softmax (AM-Softmax),
for deep face verification. In general, the face verification task can be
viewed as a metric learning problem, so learning large-margin face features
whose intra-class variation is small and inter-class difference is large is of
great importance in order to achieve good performance. Recently, Large-margin
Softmax and Angular Softmax have been proposed to incorporate the angular
margin in a multiplicative manner. In this work, we introduce a novel additive
angular margin for the Softmax loss, which is intuitively appealing and more
interpretable than the existing works. We also emphasize and discuss the
importance of feature normalization in the paper. Most importantly, our
experiments on LFW BLUFR and MegaFace show that our additive margin softmax
loss consistently performs better than the current state-of-the-art methods
using the same network architecture and training dataset. Our code has also
been made available at https://github.com/happynear/AMSoftmax
</dc:description>
 <dc:description>Comment: technical report</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05604</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Packet Routing in 3D Nanonetworks: A Lightweight, Linear-path Scheme</dc:title>
 <dc:creator>Tsioliaridou, A.</dc:creator>
 <dc:creator>Liaskos, C.</dc:creator>
 <dc:creator>Dedu, E.</dc:creator>
 <dc:creator>Ioannidis, S.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Packet routing in nanonetworks requires novel approaches, which can cope with
the extreme limitations posed by the nano-scale. Highly lossy wireless
channels, extremely limited hardware capabilities and non-unique node
identifiers are among the restrictions. The present work offers an addressing
and routing solution for static 3D nanonetworks that find applications in
material monitoring and programmatic property tuning. The addressing process
relies on virtual coordinates from multiple, alternative anchor point sets that
act as \emph{viewports}. Each viewport offers different address granularity
within the network space, and its selection is optimized by a packet sending
node using a novel heuristic. Regarding routing, each node can deduce whether
it is located on the linear segment connecting the sender to the recipient
node. This deduction is made using integer calculations, node-local information
and in a stateless manner, minimizing the computational and storage overhead of
the proposed scheme. Most importantly, the nodes can regulate the width of the
linear path, thus trading energy efficiency (redundant transmissions) for
increased path diversity. This trait can enable future adaptive routing
schemes. Extensive evaluation via simulations highlights the advantages of the
novel scheme over related approaches.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05604</dc:identifier>
 <dc:identifier>Volume 12, June 2017, Pages 63-71</dc:identifier>
 <dc:identifier>doi:10.1016/j.nancom.2017.01.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05605</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Test Collection Construction via Active Learning</dc:title>
 <dc:creator>Rahman, Md Mustafizur</dc:creator>
 <dc:creator>Kutlu, Mucahid</dc:creator>
 <dc:creator>Elsayed, Tamer</dc:creator>
 <dc:creator>Lease, Matthew</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  To create a new IR test collection at minimal cost, we must carefully select
which documents merit human relevance judgments. Shared task campaigns such as
NIST TREC determine this by pooling search results from many participating
systems (and often interactive runs as well), thereby identifying the most
likely relevant documents in a given collection. While effective, it would be
preferable to be able to build a new test collection without needing to run an
entire shared task. Toward this end, we investigate multiple active learning
(AL) strategies which, without reliance on system rankings: 1) select which
documents human assessors should judge; and 2) automatically classify the
relevance of remaining unjudged documents. Because scarcity of relevant
documents tends to yield highly imbalanced training data for model estimation,
we investigate sampling strategies to mitigate class imbalance. We report
experiments on four TREC collections with varying scarcity of relevant
documents, reporting labeling accuracy achieved, as well as rank correlation
when evaluating participant systems using these labels vs. NIST judgments.
Results demonstrate the effectiveness of our approach, coupled with further
analysis showing how varying relevance scarcity, within and across collections,
impacts findings.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05606</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-View Stereo 3D Edge Reconstruction</dc:title>
 <dc:creator>Bignoli, Andrea</dc:creator>
 <dc:creator>Romanoni, Andrea</dc:creator>
 <dc:creator>Matteucci, Matteo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel method for the reconstruction of 3D edges in
multi-view stereo scenarios. Previous research in the field typically relied on
video sequences and limited the reconstruction process to either straight
line-segments, or edge-points, i.e., 3D points that correspond to image edges.
We instead propose a system, denoted as EdgeGraph3D, able to recover both
straight and curved 3D edges from an unordered image sequence. A second
contribution of this work is a graph-based representation for 2D edges that
allows the identification of the most structurally significant edges detected
in an image. We integrate EdgeGraph3D in a multi-view stereo reconstruction
pipeline and analyze the benefits provided by 3D edges to the accuracy of the
recovered surfaces. We evaluate the effectiveness of our approach on multiple
datasets from two different collections in the multi-view stereo literature.
Experimental results demonstrate the ability of EdgeGraph3D to work in presence
of strong illumination changes and reflections, which are usually detrimental
to the effectiveness of classical photometric reconstruction systems.
</dc:description>
 <dc:description>Comment: Accepted for WACV 2018</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05607</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Data Market: Policies for Decentralised Visual Localisation</dc:title>
 <dc:creator>Gadd, Matthew</dc:creator>
 <dc:creator>Newman, Paul</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a mercantile framework for the decentralised sharing of
navigation expertise amongst a fleet of robots which perform regular missions
into a common but variable environment. We build on our earlier work and allow
individual agents to intermittently initiate trades based on a real-time
assessment of the nature of their missions or demand for localisation
capability, and to choose trading partners with discrimination based on an
internally evolving set of beliefs in the expected value of trading with each
other member of the team. To this end, we suggest some obligatory properties
that a formalisation of the distributed versioning of experience maps should
exhibit, to ensure the eventual convergence in the state of each agent's map
under a sequence of pairwise exchanges, as well as the uninterrupted integrity
of the representation under versioning operations. To mitigate limitations in
hardware and network resources, the &quot;data market&quot; is catalogued by distinct
sections of the world, which the agents treat as &quot;products&quot; for appraisal and
purchase. To this end, we demonstrate and evaluate our system using the
publicly available Oxford RobotCar Dataset, the hand-labelled data market
catalogue (approaching 446km of fully indexed sections-of-interest) for which
we plan to release alongside the existing raw stereo imagery. We show that, by
refining market policies over time, agents achieve improved localisation in a
directed and accelerated manner.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05609</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unseen Class Discovery in Open-world Classification</dc:title>
 <dc:creator>Shu, Lei</dc:creator>
 <dc:creator>Xu, Hu</dc:creator>
 <dc:creator>Liu, Bing</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper concerns open-world classification, where the classifier not only
needs to classify test examples into seen classes that have appeared in
training but also reject examples from unseen or novel classes that have not
appeared in training. Specifically, this paper focuses on discovering the
hidden unseen classes of the rejected examples. Clearly, without prior
knowledge this is difficult. However, we do have the data from the seen
training classes, which can tell us what kind of similarity/difference is
expected for examples from the same class or from different classes. It is
reasonable to assume that this knowledge can be transferred to the rejected
examples and used to discover the hidden unseen classes in them. This paper
aims to solve this problem. It first proposes a joint open classification model
with a sub-model for classifying whether a pair of examples belongs to the same
or different classes. This sub-model can serve as a distance function for
clustering to discover the hidden classes of the rejected examples.
Experimental results show that the proposed model is highly promising.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05610</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Taxonomy for Management and Optimization of Multiple Resources in Edge
  Computing</dc:title>
 <dc:creator>Tocz&#xe9;, Klervie</dc:creator>
 <dc:creator>Nadjm-Tehrani, Simin</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Edge computing is promoted to meet increasing performance needs of
data-driven services using computational and storage resources close to the end
devices, at the edge of the current network. To achieve higher performance in
this new paradigm one has to consider how to combine the efficiency of resource
usage at all three layers of architecture: end devices, edge devices, and the
cloud. While cloud capacity is elastically extendable, end devices and edge
devices are to various degrees resource-constrained. Hence, an efficient
resource management is essential to make edge computing a reality. In this
work, we first present terminology and architectures used within the field of
edge computing. Then, we review recent literature, consisting of a wide range
of papers and categorise them using 4 perspectives, namely resource type,
resource management objective, resource location, and resource use. This
taxonomy and the ensuing analysis is used to identify some gaps in the research
currently conducted. While the combination of dynamic load changes and mobility
would seem to require novel edge-based resource estimation and discovery
methods, we found these areas less studied. As for resource types, we observe
that energy and data as a resource are not as well-studied as computation and
communication resources. Finally, we find that few works are dedicated to the
study of the footprint of resource management techniques.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05611</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Socket Store: An App Model for the Application-Network Interaction</dc:title>
 <dc:creator>Liaskos, Christos</dc:creator>
 <dc:creator>Tsioliaridou, Ageliki</dc:creator>
 <dc:creator>Ioannidis, Sotiris</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  A developer of mobile or desktop applications is responsible for implementing
the network logic of his software. Nonetheless: i) Developers are not network
specialists, while pressure for emphasis on the visible application parts
places the network logic out of the coding focus. Moreover, computer networks
undergo evolution at paces that developers may not follow. ii) From the network
resource provider point of view, marketing novel services and involving a broad
audience is also challenge for the same reason. Moreover, the objectives of
end-user networking logic are neither clear nor uniform. This constitutes the
central optimization of network resources an additional challenge. As a
solution to these problems, we propose the Socket Store. The Store is a
marketplace containing end-user network logic in modular form. The Store
modules act as intelligent mediators between the end-user and the network
resources. Each module has a clear, specialized objective, such as connecting
two clients over the Internet while avoiding transit networks suspicious for
eavesdropping. The Store is populated and peer-reviewed by network specialists,
whose motive is the visibility, practical applicability and monetization
potential of their work. A developer first purchases access to a given socket
module. Subsequently, he incorporates it to his applications under development,
obtaining state-of-the-art performance with trivial coding burden. A full Store
prototype is implemented and a critical data streaming module is evaluated as a
driving case.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05611</dc:identifier>
 <dc:identifier>doi:10.1109/ISCC.2017.8024557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05613</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query2Vec: NLP Meets Databases for Generalized Workload Analytics</dc:title>
 <dc:creator>Jain, Shrainik</dc:creator>
 <dc:creator>Howe, Bill</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose methods for learning vector representations of SQL workloads to
support a variety of administration tasks and application features, including
query recommendation, workload summarization, index selection, identifying
expensive queries, and predicting query reuse. We consider vector
representations of both raw SQL text and optimized query plans under various
assumptions and pre-processing strategies, and evaluate these methods on
multiple real SQL workloads by comparing with results of task and application
feature metrics in the literature. We find that simple algorithms based on
these generic vector representations compete favorably with previous approaches
that require a number of assumptions and task-specific heuristics. We then
present a new embedding strategy specialized for queries based on
tree-structured Long Short Term Memory (LSTM) network architectures that
improves on the text-oriented embeddings for some tasks. We find that the
general approach, when trained on a large corpus of SQL queries, provides a
robust foundation for a variety of workload analysis tasks. We conclude by
considering how workload embeddings can be deployed as a core database system
feature to support database maintenance and novel applications.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05615</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Protocol for Network-Controlled Metasurfaces</dc:title>
 <dc:creator>Tsioliaridou, Angeliki</dc:creator>
 <dc:creator>Liaskos, Christos</dc:creator>
 <dc:creator>Pitsillides, Andreas</dc:creator>
 <dc:creator>Ioannidis, Sotiris</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  A recently proposed class of materials, called software-defined
metamaterials, can change their electromagnetic behavior on demand, utilizing a
nanonetwork embedded in their structure. The present work focuses on 2D
metamaterials, known as metasurfaces, and their electromagnetically
programmable counterparts, the HyperSurfaces. The particular focus of the study
is to propose a nanonetworking protocol that can support the intended
macroscopic functionality of a HyperSurface, such as sensing and reacting to
impinging waves in a customizable manner. The novel protocol is derived
analytically, using the Lyapunov drift minimization approach, taking into
account nano-node energy, communication latency and complexity concerns. The
proposed scheme is evaluated via simulations, covering both the macroscopic
HyperSurface functionality and the microscopic, nanonetwork behavior.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05615</dc:identifier>
 <dc:identifier>doi:10.1145/3109453.3109469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05617</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Detection of Cyberbullying in Social Media Text</dc:title>
 <dc:creator>Van Hee, Cynthia</dc:creator>
 <dc:creator>Jacobs, Gilles</dc:creator>
 <dc:creator>Emmery, Chris</dc:creator>
 <dc:creator>Desmet, Bart</dc:creator>
 <dc:creator>Lefever, Els</dc:creator>
 <dc:creator>Verhoeven, Ben</dc:creator>
 <dc:creator>De Pauw, Guy</dc:creator>
 <dc:creator>Daelemans, Walter</dc:creator>
 <dc:creator>Hoste, V&#xe9;ronique</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  While social media offer great communication opportunities, they also
increase the vulnerability of young people to threatening situations online.
Recent studies report that cyberbullying constitutes a growing problem among
youngsters. Successful prevention depends on the adequate detection of
potentially harmful messages and the information overload on the Web requires
intelligent systems to identify potential risks automatically. The focus of
this paper is on automatic cyberbullying detection in social media text by
modelling posts written by bullies, victims, and bystanders of online bullying.
We describe the collection and fine-grained annotation of a training corpus for
English and Dutch and perform a series of binary classification experiments to
determine the feasibility of automatic cyberbullying detection. We make use of
linear support vector machines exploiting a rich feature set and investigate
which information sources contribute the most for this particular task.
Experiments on a holdout test set reveal promising results for the detection of
cyberbullying-related posts. After optimisation of the hyperparameters, the
classifier yields an F1-score of 64% and 61% for English and Dutch
respectively, and considerably outperforms baseline systems based on keywords
and word unigrams.
</dc:description>
 <dc:description>Comment: 21 pages, 9 tables, under review</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05620</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revealing In-Block Nestedness: detection and benchmarking</dc:title>
 <dc:creator>Sol&#xe9;-Ribalta, Albert</dc:creator>
 <dc:creator>Tessone, Claudio J.</dc:creator>
 <dc:creator>Mariani, Manuel S.</dc:creator>
 <dc:creator>Borge-Holthoefer, Javier</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  As new instances of nested organization --beyond ecological networks-- are
discovered, scholars are debating around the co-existence of two apparently
incompatible macroscale architectures: nestedness and modularity. The
discussion is far from being solved, mainly for two reasons. First, nestedness
and modularity appear to emerge from two contradictory dynamics, cooperation
and competition. Second, existing methods to assess the presence of nestedness
and modularity are flawed when it comes to the evaluation of concurrently
nested and modular structures. In this work, we tackle the latter problem,
presenting the concept of \textit{in-block nestedness}, a structural property
determining to what extent a network is composed of blocks whose internal
connectivity exhibits nestedness. We then put forward a set of optimization
methods that allow us to identify such organization successfully, both in
synthetic and in a large number of real networks. These findings challenge our
understanding of the topology of ecological and social systems, calling for new
models to explain how such patterns emerge.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures, 1 Table</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05627</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Reduction of Biases in Big Data Sets for the Detection of
  Irregular Power Usage</dc:title>
 <dc:creator>Glauner, Patrick</dc:creator>
 <dc:creator>State, Radu</dc:creator>
 <dc:creator>Valtchev, Petko</dc:creator>
 <dc:creator>Duarte, Diogo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In machine learning, a bias occurs whenever training sets are not
representative for the test data, which results in unreliable models. The most
common biases in data are arguably class imbalance and covariate shift. In this
work, we aim to shed light on this topic in order to increase the overall
attention to this issue in the field of machine learning. We propose a scalable
novel framework for reducing multiple biases in high-dimensional data sets in
order to train more reliable predictors. We apply our methodology to the
detection of irregular power usage from real, noisy industrial data. In
emerging markets, irregular power usage, and electricity theft in particular,
may range up to 40% of the total electricity distributed. Biased data sets are
of particular issue in this domain. We show that reducing these biases
increases the accuracy of the trained predictors. Our models have the potential
to generate significant economic value in a real world application, as they are
being deployed in a commercial software for the detection of irregular power
usage.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05629</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game-Theoretical Strategy of Robot in the Area with Dynamical Obstacles</dc:title>
 <dc:creator>Malafeyev, Oleg</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The effectiveness of a robot manipulation to a large extent is determined by
the speed of making this or that movement needed for carrying out the task.
Accordingly to this the problem of optimal robot control is often subdivided
into two subproblems solved separately. In an autonomous regime the trajectory
planning is fulfilled for providing the robot movement time close to the
minimal.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05637</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Elevating commodity storage with the SALSA host translation layer</dc:title>
 <dc:creator>Ioannou, Nikolas</dc:creator>
 <dc:creator>Kourtis, Kornilios</dc:creator>
 <dc:creator>Koltsidas, Ioannis</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  To satisfy increasing storage demands in both capacity and performance,
industry has turned to multiple storage technologies, including Flash SSDs and
SMR disks. These devices employ a translation layer that conceals the
idiosyncrasies of their mediums and enables random access. Device translation
layers are, however, inherently constrained: resources on the drive are scarce,
they cannot be adapted to application requirements, and lack visibility across
multiple devices. As a result, performance and durability of many storage
devices is severely degraded.
  In this paper, we present SALSA: a translation layer that executes on the
host and allows unmodified applications to better utilize commodity storage.
SALSA supports a wide range of single- and multi-device optimizations and,
because is implemented in software, can adapt to specific workloads. We
describe SALSA's design, and demonstrate its significant benefits using
microbenchmarks and case studies based on three applications: MySQL, the Swift
object store, and a video server.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05643</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Case for Automatic Database Administration using Deep Reinforcement
  Learning</dc:title>
 <dc:creator>Sharma, Ankur</dc:creator>
 <dc:creator>Schuhknecht, Felix Martin</dc:creator>
 <dc:creator>Dittrich, Jens</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Like any large software system, a full-fledged DBMS offers an overwhelming
amount of configuration knobs. These range from static initialisation
parameters like buffer sizes, degree of concurrency, or level of replication to
complex runtime decisions like creating a secondary index on a particular
column or reorganising the physical layout of the store. To simplify the
configuration, industry grade DBMSs are usually shipped with various advisory
tools, that provide recommendations for given workloads and machines. However,
reality shows that the actual configuration, tuning, and maintenance is usually
still done by a human administrator, relying on intuition and experience.
Recent work on deep reinforcement learning has shown very promising results in
solving problems, that require such a sense of intuition. For instance, it has
been applied very successfully in learning how to play complicated games with
enormous search spaces. Motivated by these achievements, in this work we
explore how deep reinforcement learning can be used to administer a DBMS.
First, we will describe how deep reinforcement learning can be used to
automatically tune an arbitrary software system like a DBMS by defining a
problem environment. Second, we showcase our concept of NoDBA at the concrete
example of index selection and evaluate how well it recommends indexes for
given workloads.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05643</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05644</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A formal framework for deliberated judgment</dc:title>
 <dc:creator>Cailloux, Olivier</dc:creator>
 <dc:creator>Meinard, Yves</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  While the philosophical literature has extensively studied how decisions
relate to arguments, reasons and justifications, decision theory almost
entirely ignores the latter notions and rather focuses on preference and
belief. In this article, we argue that decision theory can largely benefit from
explicitly taking into account the stance that decision-makers take towards
arguments and counter-arguments. To that end, we elaborate a formal framework
aiming to integrate the role of arguments and argumentation in decision theory
and decision aid. We start from a decision situation, where an individual
requests decision support. In this context, we formally define, as a
commendable basis for decision-aid, this individual's deliberated judgment,
popularized by Rawls. We explain how models of deliberated judgment can be
validated empirically. We then identify conditions upon which the existence of
a valid model can be taken for granted, and analyze how these conditions can be
relaxed. We then explore the significance of our proposed framework for
decision aiding practice. We argue that our concept of deliberated judgment
owes its normative credentials both to its normative foundations (the idea of
rationality based on arguments) and to its reference to empirical reality (the
stance that real, empirical individuals hold towards arguments and
counter-arguments, on due reflection). We then highlight that our framework
opens promising avenues for future research involving both philosophical and
decision theoretic approaches, as well as empirical implementations.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05649</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eigenvector localization in real networks and its implications for
  epidemic spreading</dc:title>
 <dc:creator>Pastor-Satorras, Romualdo</dc:creator>
 <dc:creator>Castellano, Claudio</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The spectral properties of the adjacency matrix, in particular its largest
eigenvalue and the associated principal eigenvector, dominate many structural
and dynamical properties of complex networks. Here we focus on the localization
properties of the principal eigenvector in real networks. We show that in most
cases it is either localized on the star defined by the node with largest
degree (hub) and its nearest neighbors, or on the densely connected subgraph
defined by the maximum $K$-core in a $K$-core decomposition. The localization
of the principal eigenvector is often strongly correlated with the value of the
largest eigenvalue, which is given by the local eigenvalue of the corresponding
localization subgraph, but different scenarios sometimes occur. We additionally
show that simple targeted immunization strategies for epidemic spreading are
extremely sensitive to the actual localization set.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05655</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-Distortion Performance of Sequential Massive Random Access to
  Gaussian Sources with Memory</dc:title>
 <dc:creator>Dupraz, Elsa</dc:creator>
 <dc:creator>Maugey, Thomas</dc:creator>
 <dc:creator>Roumy, Aline</dc:creator>
 <dc:creator>Kieffer, Michel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In Sequential Massive Random Access (SMRA), a set of correlated sources is
jointly encoded and stored on a server, and clients want to access to only a
subset of the sources. Since the number of simultaneous clients can be huge,
the server is only authorized to extract a bitstream from the stored data: no
re-encoding can be performed before the transmission of a request. In this
paper, we investigate the SMRA performance of lossy source coding of Gaussian
sources with memory. In practical applications such as Free Viewpoint
Television, this model permits to take into account not only inter but also
intra correlation between sources. For this model, we provide the storage and
transmission rates that are achievable for SMRA under some distortion
constraint, and we consider two particular examples of Gaussian sources with
memory.
</dc:description>
 <dc:description>Comment: Long version of a paper accepted at DCC 2018</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05659</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Decoding Schemes for the MDPC-McEliece Cryptosystem</dc:title>
 <dc:creator>Bartz, Hannes</dc:creator>
 <dc:creator>Liva, Gianluigi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Recently, it has been shown how McEliece public-key cryptosystems based on
moderate-density parity-check (MDPC) codes allow for very compact keys compared
to variants based on other code families. In this paper, classical (iterative)
decoding schemes for MPDC codes are considered. The algorithms are analyzed
with respect to their error-correction capability as well as their resilience
against a recently proposed reaction-based key-recovery attack on a variant of
the MDPC-McEliece cryptosystem by Guo, Johansson and Stankovski (GJS). New
message-passing decoding algorithms are presented and analyzed. Two proposed
decoding algorithms have an improved error-correction performance compared to
existing hard-decision decoding schemes and are resilient against the GJS
reaction-based attack for an appropriate choice of the algorithm's parameters.
Finally, a modified belief propagation decoding algorithm that is resilient
against the GJS reaction-based attack is presented.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05667</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Innateness, AlphaZero, and Artificial Intelligence</dc:title>
 <dc:creator>Marcus, Gary</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>97R40</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  The concept of innateness is rarely discussed in the context of artificial
intelligence. When it is discussed, or hinted at, it is often the context of
trying to reduce the amount of innate machinery in a given system. In this
paper, I consider as a test case a recent series of papers by Silver et al
(Silver et al., 2017a) on AlphaGo and its successors that have been presented
as an argument that a &quot;even in the most challenging of domains: it is possible
to train to superhuman level, without human examples or guidance&quot;, &quot;starting
tabula rasa.&quot;
  I argue that these claims are overstated, for multiple reasons. I close by
arguing that artificial intelligence needs greater attention to innateness, and
I point to some proposals about what that innateness might look like.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05671</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact Real-time avoidance on a Humanoid Robot for Human-robot
  Interaction</dc:title>
 <dc:creator>Nguyen, Dong Hai Phuong</dc:creator>
 <dc:creator>Hoffmann, Matej</dc:creator>
 <dc:creator>Roncone, Alessandro</dc:creator>
 <dc:creator>Pattacini, Ugo</dc:creator>
 <dc:creator>Metta, Giorgio</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  With robots leaving factories and entering less controlled domains, possibly
sharing the space with humans, safety is paramount and multimodal awareness of
the body surface and the surrounding environment is fundamental. Taking
inspiration from peripersonal space representations in humans, we present a
framework on a humanoid robot that dynamically maintains such a protective
safety zone, composed of the following main components: (i) a human 2D
keypoints estimation pipeline employing a deep learning based algorithm,
extended here into 3D using disparity; (ii) a distributed peripersonal space
representation around the robot's body parts; (iii) a reaching controller that
incorporates all obstacles entering the robot's safety zone on the fly into the
task. Pilot experiments demonstrate that an effective safety margin between the
robot's and the human's body parts is kept. The proposed solution is flexible
and versatile since the safety zone around individual robot and human body
parts can be selectively modulated---here we demonstrate stronger avoidance of
the human head compared to rest of the body. Our system works in real time and
is self-contained, with no external sensory equipment and use of onboard
cameras only.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05671</dc:identifier>
 <dc:identifier>HRI '18: 2018 ACM/IEEE International Conference on Human-Robot
  Interaction, March 5--8, 2018, Chicago, IL, USA</dc:identifier>
 <dc:identifier>doi:10.1145/3171221.3171245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05678</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Recognition via Centralized Coordinate Learning</dc:title>
 <dc:creator>Qi, Xianbiao</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Owe to the rapid development of deep neural network (DNN) techniques and the
emergence of large scale face databases, face recognition has achieved a great
success in recent years. During the training process of DNN, the face features
and classification vectors to be learned will interact with each other, while
the distribution of face features will largely affect the convergence status of
network and the face similarity computing in test stage. In this work, we
formulate jointly the learning of face features and classification vectors, and
propose a simple yet effective centralized coordinate learning (CCL) method,
which enforces the features to be dispersedly spanned in the coordinate space
while ensuring the classification vectors to lie on a hypersphere. An adaptive
angular margin is further proposed to enhance the discrimination capability of
face features. Extensive experiments are conducted on six face benchmarks,
including those have large age gap and hard negative samples. Trained only on
the small-scale CASIA Webface dataset with 460K face images from about 10K
subjects, our CCL model demonstrates high effectiveness and generality, showing
consistently competitive performance across all the six benchmark databases.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05681</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixed Delay Constraints in Wyner's Soft-Handoff Network</dc:title>
 <dc:creator>Nikbakht, Homa</dc:creator>
 <dc:creator>Wigger, Mich&#xe8;le</dc:creator>
 <dc:creator>Shamai, Shlomo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Wyner's soft-handoff network with mixed delay constraints is considered when
neighbouring receivers can cooperate over rate-limited links. Each source
message is a combination of independent &quot;fast&quot; and &quot;slow&quot; bits, where the
former are subject to a stringent decoding delay. Inner and outer bounds on the
capacity region are derived, and the multiplexing gain region is characterized
when only transmitters or only receivers cooperate.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05694</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A modified fuzzy C means algorithm for shading correction in
  craniofacial CBCT images</dc:title>
 <dc:creator>Ashfaq, Awais</dc:creator>
 <dc:creator>Adler, Jonas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  CBCT images suffer from acute shading artifacts primarily due to scatter.
Numerous image-domain correction algorithms have been proposed in the
literature that use patient-specific planning CT images to estimate shading
contributions in CBCT images. However, in the context of radiosurgery
applications such as gamma knife, planning images are often acquired through
MRI which impedes the use of polynomial fitting approaches for shading
correction. We present a new shading correction approach that is independent of
planning CT images. Our algorithm is based on the assumption that true CBCT
images follow a uniform volumetric intensity distribution per material, and
scatter perturbs this uniform texture by contributing cupping and shading
artifacts in the image domain. The framework is a combination of fuzzy C-means
coupled with a neighborhood regularization term and Otsu's method. Experimental
results on artificially simulated craniofacial CBCT images are provided to
demonstrate the effectiveness of our algorithm. Spatial non-uniformity is
reduced from 16% to 7% in soft tissue and from 44% to 8% in bone regions. With
shading-correction, thresholding based segmentation accuracy for bone pixels is
improved from 85% to 91% when compared to thresholding without
shading-correction. The proposed algorithm is thus practical and qualifies as a
plug and play extension into any CBCT reconstruction software for shading
correction.
</dc:description>
 <dc:description>Comment: 15 pages, published in CMBEBIH 2017</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05694</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Medical and
  Biological Engineering 2017</dc:identifier>
 <dc:identifier>doi:10.1007/978-981-10-4166-2_81</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05700</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Imprecise Markov Models for Scalable and Robust Performance Evaluation
  of Flexi-Grid Spectrum Allocation Policies</dc:title>
 <dc:creator>Erreygers, Alexander</dc:creator>
 <dc:creator>Rottondi, Cristina</dc:creator>
 <dc:creator>Verticale, Giacomo</dc:creator>
 <dc:creator>De Bock, Jasper</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  The possibility of flexibly assigning spectrum resources with channels of
different sizes greatly improves the spectral efficiency of optical networks,
but can also lead to unwanted spectrum fragmentation.We study this problem in a
scenario where traffic demands are categorised in two types (low or high
bit-rate) by assessing the performance of three allocation policies. Our first
contribution consists of exact Markov chain models for these allocation
policies, which allow us to numerically compute the relevant performance
measures. However, these exact models do not scale to large systems, in the
sense that the computations required to determine the blocking
probabilities---which measure the performance of the allocation
policies---become intractable. In order to address this, we first extend an
approximate reduced-state Markov chain model that is available in the
literature to the three considered allocation policies. These reduced-state
Markov chain models allow us to tractably compute approximations of the
blocking probabilities, but the accuracy of these approximations cannot be
easily verified. Our main contribution then is the introduction of
reduced-state imprecise Markov chain models that allow us to derive guaranteed
lower and upper bounds on blocking probabilities, for the three allocation
policies separately or for all possible allocation policies simultaneously.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures, 3 tables</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05707</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalized Dempster--Shafer Evidence Theory</dc:title>
 <dc:creator>Xiao, Fuyuan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Dempster-Shafer evidence theory has been widely used in various fields of
applications. Besides, it has been proven that the quantum theory has powerful
capabilities of solving the decision making problems. However, due to the
inconsistency of the expression, the classical Dempster-Shafer evidence theory
modelled by real numbers can not be integrated directly with the quantum theory
modelled by complex numbers. The main contribution in this study is that,
unlike the existing evidence theory, a mass function in the generalized
Dempster-Shafer evidence theory is modelled by a complex number, called as a
complex mass function. When the complex mass function is degenerated from
complex numbers to real numbers, the generalized Dempster's combination rule
degenerates to the classical evidence theory. This generalized Dempster-Shafer
evidence theory provides a promising way to model and handle more uncertain
information. Numerical examples are illustrated to show the efficiency of the
generalized Dempster-Shafer evidence theory.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05717</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact quantum query complexity of weight decision problems</dc:title>
 <dc:creator>He, Xiaoyu</dc:creator>
 <dc:creator>Sun, Xiaoming</dc:creator>
 <dc:creator>Yang, Guang</dc:creator>
 <dc:creator>Yuan, Pei</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The weight decision problem, which requires to determine the Hamming weight
of a given binary string, is a natural and important problem, with applications
in cryptanalysis, coding theory, fault-tolerant circuit design and so on. In
particular, both Deutsch-Jozsa problem and Grover search problem can be
interpreted as special cases of weight decision problems. In this work, we
investigate the exact quantum query complexity of weight decision problems,
where the quantum algorithm must always output the correct answer. More
specifically we consider a partial Boolean function which distinguishes whether
the Hamming weight of the length-$n$ input is $k$ or it is $l$. Our
contribution includes both upper bounds and lower bounds for the precise number
of queries. Furthermore, for most choices of $(\frac{k}{n},\frac{l}{n})$ and
sufficiently large $n$, the gap between our upper and lower bounds is no more
than one. To get the results, we first build the connection between Chebyshev
polynomials and our problem, then determine all the boundary cases of
$(\frac{k}{n},\frac{l}{n})$ with matching upper and lower bounds, and finally
we generalize to other cases via a new \emph{quantum padding} technique. This
quantum padding technique can be of independent interest in designing other
quantum algorithms.
</dc:description>
 <dc:description>Comment: 17 pages, 3 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05721</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A compressed classical description of quantum states</dc:title>
 <dc:creator>Gosset, David</dc:creator>
 <dc:creator>Smolin, John</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We show how to approximately represent a quantum state using the square root
of the usual amount of classical memory. The classical representation of an
n-qubit state $\psi$ consists of its inner products with $O(\sqrt{2^n})$
stabilizer states. A quantum state initially specified by its $2^n$ entries in
the computational basis can be compressed to this form in time $O(2^n
\mathrm{poly}(n))$, and, subsequently, the compressed description can be used
to additively approximate the expectation value of an arbitrary observable. Our
compression scheme directly gives a new protocol for the vector in subspace
problem with randomized one-way communication complexity that matches (up to
polylogarithmic factors) the best known upper bound, due to Raz. We obtain an
exponential improvement over Raz's protocol in terms of computational
efficiency.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05731</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In-network Neural Networks</dc:title>
 <dc:creator>Siracusano, Giuseppe</dc:creator>
 <dc:creator>Bifulco, Roberto</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present N2Net, a system that implements binary neural networks using
commodity switching chips deployed in network switches and routers. Our system
shows that these devices can run simple neural network models, whose input is
encoded in the network packets' header, at packet processing speeds (billions
of packets per second). Furthermore, our experience highlights that switching
chips could support even more complex models, provided that some minor and
cheap modifications to the chip's design are applied. We believe N2Net provides
an interesting building block for future end-to-end networked systems.
</dc:description>
 <dc:description>Comment: Accepted at SysML 2018</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05734</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eliminating the effect of rating bias on reputation systems</dc:title>
 <dc:creator>Wu, Leilei</dc:creator>
 <dc:creator>Ren, Zhuoming</dc:creator>
 <dc:creator>Ren, Xiao-Long</dc:creator>
 <dc:creator>Zhang, Jianlin</dc:creator>
 <dc:creator>L&#xfc;, Linyuan</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The ongoing rapid development of the e-commercial and interest-base websites
make it more pressing to evaluate objects' accurate quality before
recommendation by employing an effective reputation system. The objects'
quality are often calculated based on their historical information, such as
selected records or rating scores, to help visitors to make decisions before
watching, reading or buying. Usually high quality products obtain a higher
average ratings than low quality products regardless of rating biases or
errors. However many empirical cases demonstrate that consumers may be misled
by rating scores added by unreliable users or deliberate tampering. In this
case, users' reputation, i.e., the ability to rating trustily and precisely,
make a big difference during the evaluating process. Thus, one of the main
challenges in designing reputation systems is eliminating the effects of users'
rating bias on the evaluation results. To give an objective evaluation of each
user's reputation and uncover an object's intrinsic quality, we propose an
iterative balance (IB) method to correct users' rating biases. Experiments on
two online video-provided Web sites, namely MovieLens and Netflix datasets,
show that the IB method is a highly self-consistent and robust algorithm and it
can accurately quantify movies' actual quality and users' stability of rating.
Compared with existing methods, the IB method has higher ability to find the
&quot;dark horses&quot;, i.e., not so popular yet good movies, in the Academy Awards.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures. All the authors contributed equally to this work</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05741</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StreetGen : In base city scale procedural generation of streets: road
  network, road surface and street objects</dc:title>
 <dc:creator>Cura, R&#xe9;mi</dc:creator>
 <dc:creator>Perret, Julien</dc:creator>
 <dc:creator>Paparoditis, Nicolas</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Streets are large, diverse, and used for several (and possibly conflicting)
transport modalities as well as social and cultural activities. Proper planning
is essential and requires data. Manually fabricating data that represent
streets (street reconstruction) is error-prone and time consuming. Automatising
street reconstruction is a challenge because of the diversity, size, and scale
of the details (few centimetres for cornerstone) required. The state-of-the-art
focuses on roads (no context, no urban features) and is strongly determined by
each application (simulation, visualisation, planning). We propose a unified
framework that works on real Geographic Information System (GIS) data and uses
a strong, yet simple modelling hypothesis when possible to robustly model
streets at the city level or street level. Our method produces a coherent
street-network model containing topological traffic information, road surface
and street objects. We demonstrate the robustness and genericity of our method
by reconstructing the entire city of Paris streets and exploring other similar
reconstruction (airport driveway).
</dc:description>
 <dc:description>Comment: Paper extracted from thesis manuscript, is also an extension of
  doi:10.5194/isprsannals-II-3-W5-409-201</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05746</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image
  Segmentation</dc:title>
 <dc:creator>Iglovikov, Vladimir</dc:creator>
 <dc:creator>Shvets, Alexey</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pixel-wise image segmentation is demanding task in computer vision. Classical
U-Net architectures composed of encoders and decoders are very popular for
segmentation of medical images, satellite images etc. Typically, neural network
initialized with weights from a network pre-trained on a large data set like
ImageNet shows better performance than those trained from scratch on a small
dataset. In some practical applications, particularly in medicine and traffic
safety, the accuracy of the models is of utmost importance. In this paper, we
demonstrate how the U-Net type architecture can be improved by the use of the
pre-trained encoder. Our code and corresponding pre-trained weights are
publicly available at https://github.com/ternaus/TernausNet. We compare three
weight initialization schemes: LeCun uniform, the encoder with weights from
VGG11 and full network trained on the Carvana dataset. This network
architecture was a part of the winning solution (1st out of 735) in the Kaggle:
Carvana Image Masking Challenge.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05756</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Content Placement in Cache-Enabled Sub-6 GHz and Millimeter-Wave
  Multi-antenna Dense Small Cell Networks</dc:title>
 <dc:creator>Zhu, Yongxu</dc:creator>
 <dc:creator>Zheng, Gan</dc:creator>
 <dc:creator>Wang, Lifeng</dc:creator>
 <dc:creator>Wong, Kai-Kit</dc:creator>
 <dc:creator>Zhao, Liqiang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper studies the performance of cache-enabled dense small cell networks
consisting of multi-antenna sub-6 GHz and millimeter-wave base stations.
Different from the existing works which only consider a single antenna at each
base station, the optimal content placement is unknown when the base stations
have multiple antennas. We first derive the successful content delivery
probability by accounting for the key channel features at sub-6 GHz and mmWave
frequencies. The maximization of the successful content delivery probability is
a challenging problem. To tackle it, we first propose a constrained
cross-entropy algorithm which achieves the near-optimal solution with moderate
complexity. We then develop another simple yet effective heuristic
probabilistic content placement scheme, termed two-stair algorithm, which
strikes a balance between caching the most popular contents and achieving
content diversity. Numerical results demonstrate the superior performance of
the constrained cross-entropy method and that the two-stair algorithm yields
significantly better performance than only caching the most popular contents.
The comparisons between the sub-6 GHz and mmWave systems reveal an interesting
tradeoff between caching capacity and density for the mmWave system to achieve
similar performance as the sub-6 GHz system.
</dc:description>
 <dc:description>Comment: 14 pages; Accepted to appear in IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05757</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experience-driven Networking: A Deep Reinforcement Learning based
  Approach</dc:title>
 <dc:creator>Xu, Zhiyuan</dc:creator>
 <dc:creator>Tang, Jian</dc:creator>
 <dc:creator>Meng, Jingsong</dc:creator>
 <dc:creator>Zhang, Weiyi</dc:creator>
 <dc:creator>Wang, Yanzhi</dc:creator>
 <dc:creator>Liu, Chi Harold</dc:creator>
 <dc:creator>Yang, Dejun</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Modern communication networks have become very complicated and highly
dynamic, which makes them hard to model, predict and control. In this paper, we
develop a novel experience-driven approach that can learn to well control a
communication network from its own experience rather than an accurate
mathematical model, just as a human learns a new skill (such as driving,
swimming, etc). Specifically, we, for the first time, propose to leverage
emerging Deep Reinforcement Learning (DRL) for enabling model-free control in
communication networks; and present a novel and highly effective DRL-based
control framework, DRL-TE, for a fundamental networking problem: Traffic
Engineering (TE). The proposed framework maximizes a widely-used utility
function by jointly learning network environment and its dynamics, and making
decisions under the guidance of powerful Deep Neural Networks (DNNs). We
propose two new techniques, TE-aware exploration and actor-critic-based
prioritized experience replay, to optimize the general DRL framework
particularly for TE. To validate and evaluate the proposed framework, we
implemented it in ns-3, and tested it comprehensively with both representative
and randomly generated network topologies. Extensive packet-level simulation
results show that 1) compared to several widely-used baseline methods, DRL-TE
significantly reduces end-to-end delay and consistently improves the network
utility, while offering better or comparable throughput; 2) DRL-TE is robust to
network changes; and 3) DRL-TE consistently outperforms a state-ofthe-art DRL
method (for continuous control), Deep Deterministic Policy Gradient (DDPG),
which, however, does not offer satisfying performance.
</dc:description>
 <dc:description>Comment: 9 pages, 12 figures, paper is accepted as a conference paper at IEEE
  Infocom 2018</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05764</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>M-STAR: A Modular, Evidence-based Software Trustworthiness Framework</dc:title>
 <dc:creator>Alexopoulos, Nikolaos</dc:creator>
 <dc:creator>Habib, Sheikh Mahbub</dc:creator>
 <dc:creator>Schulz, Steffen</dc:creator>
 <dc:creator>M&#xfc;hlh&#xe4;user, Max</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Despite years of intensive research in the field of software vulnerabilities
discovery, exploits are becoming ever more common. Consequently, it is more
necessary than ever to choose software configurations that minimize systems'
exposure surface to these threats. In order to support users in assessing the
security risks induced by their software configurations and in making informed
decisions, we introduce M-STAR, a Modular Software Trustworthiness ARchitecture
and framework for probabilistically assessing the trustworthiness of software
systems, based on evidence, such as their vulnerability history and source code
properties.
  Integral to M-STAR is a software trustworthiness model, consistent with the
concept of computational trust. Computational trust models are rooted in
Bayesian probability and Dempster-Shafer Belief theory, offering mathematical
soundness and expressiveness to our framework. To evaluate our framework, we
instantiate M-STAR for Debian Linux packages, and investigate real-world
deployment scenarios. In our experiments with real-world data, M-STAR could
assess the relative trustworthiness of complete software configurations with an
error of less than 10%. Due to its modular design, our proposed framework is
agile, as it can incorporate future advances in the field of code analysis and
vulnerability prediction. Our results point out that M-STAR can be a valuable
tool for system administrators, regular users and developers, helping them
assess and manage risks associated with their software configurations.
</dc:description>
 <dc:description>Comment: 18 pages, 13 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05768</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Asymptotic Capacity of Private Search</dc:title>
 <dc:creator>Chen, Zhen</dc:creator>
 <dc:creator>Wang, Zhiying</dc:creator>
 <dc:creator>Jafar, Syed</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The private search problem is introduced, where a dataset comprised of $L$
i.i.d. records is replicated across $N$ non-colluding servers, each record
takes values uniformly from an alphabet of size $K$, and a user wishes to
search for all records that match a privately chosen value, without revealing
any information about the chosen value to any individual server. The capacity
of private search is the maximum number of bits of desired information that can
be retrieved per bit of download. The asymptotic (large $K$) capacity of
private search is shown to be $1-1/N$, even as the scope of private search is
further generalized to allow approximate (OR) search over a number of
realizations that grows with $K$. The results are based on the asymptotic
behavior of a new converse bound for private information retrieval with
arbitrarily dependent messages.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05787</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster gaze prediction with dense networks and Fisher pruning</dc:title>
 <dc:creator>Theis, Lucas</dc:creator>
 <dc:creator>Korshunova, Iryna</dc:creator>
 <dc:creator>Tejani, Alykhan</dc:creator>
 <dc:creator>Husz&#xe1;r, Ferenc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Predicting human fixations from images has recently seen large improvements
by leveraging deep representations which were pretrained for object
recognition. However, as we show in this paper, these networks are highly
overparameterized for the task of fixation prediction. We first present a
simple yet principled greedy pruning method which we call Fisher pruning.
Through a combination of knowledge distillation and Fisher pruning, we obtain
much more runtime-efficient architectures for saliency prediction, achieving a
10x speedup for the same AUC performance as a state of the art network on the
CAT2000 dataset. Speeding up single-image gaze prediction is important for many
real-world applications, but it is also a crucial step in the development of
video saliency models, where the amount of data to be processed is
substantially larger.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05795</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shortest Path and Maximum Flow Problems Under Service Function Chaining
  Constraints</dc:title>
 <dc:creator>Sallam, Gamal</dc:creator>
 <dc:creator>Gupta, Gagan R.</dc:creator>
 <dc:creator>Li, Bin</dc:creator>
 <dc:creator>Ji, Bo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the advent of Network Function Virtualization (NFV), Physical Network
Functions (PNFs) are gradually being replaced by Virtual Network Functions
(VNFs) that are hosted on general purpose servers. Depending on the call flows
for specific services, the packets need to pass through an ordered set of
network functions (physical or virtual) called Service Function Chains (SFC)
before reaching the destination. Conceivably for the next few years during this
transition, these networks would have a mix of PNFs and VNFs, which brings an
interesting mix of network problems that are studied in this paper: (1) How to
find an SFC-constrained shortest path between any pair of nodes? (2) What is
the achievable SFC-constrained maximum flow? (3) How to place the VNFs such
that the cost (the number of nodes to be virtualized) is minimized, while the
maximum flow of the original network can still be achieved even under the SFC
constraint? In this work, we will try to address such emerging questions.
First, for the SFC-constrained shortest path problem, we propose a
transformation of the network graph to minimize the computational complexity of
subsequent applications of any shortest path algorithm. Second, we formulate
the SFC-constrained maximum flow problem as a fractional multicommodity flow
problem, and develop a combinatorial algorithm for a special case of practical
interest. Third, we prove that the VNFs placement problem is NP-hard and
present an alternative Integer Linear Programming (ILP) formulation. Finally,
we conduct simulations to elucidate our theoretical results.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05796</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a computational model of social norms</dc:title>
 <dc:creator>B&#xf6;l&#xf6;ni, Ladislau</dc:creator>
 <dc:creator>Bhatia, Taranjeet Singh</dc:creator>
 <dc:creator>Khan, Saad Ahmad</dc:creator>
 <dc:creator>Streater, Jonathan</dc:creator>
 <dc:creator>Fiore, Stephen M.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We describe a computational model of social norms based on identifying values
that a certain culture finds desirable such as dignity, generosity and
politeness. The model quantifies these values in the form of Culture-Sanctioned
Social Metrics (CSSMs) and treats social norms as the requirement to maximize
these metrics from the perspective of the self, peers and public. This model
can be used to create realistic social simulations, to explain or predict human
behavior in specific scenarios, or as a component of robots or agents that need
to interact with humans in specific social-cultural settings. We validate the
model by using it to represent a complex deception scenario and showing that it
can yield non-trivial insights such as the explanation of apparently irrational
human behavior.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05797</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real Time Impact Control on Charging Energy Storage For Shipboard Power
  Systems</dc:title>
 <dc:creator>Luo, Yusheng</dc:creator>
 <dc:creator>Srivastava, Sanjeev</dc:creator>
 <dc:creator>Mohanpurkar, Manish</dc:creator>
 <dc:creator>Stevic, Svetomir</dc:creator>
 <dc:creator>Hovsapian, Rob</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Medium voltage direct-current based integrated power system is projected as
one of the solutions for powering the all-electric ship. It faces significant
challenges for accurately energizing advanced loads, especially the pulsed
power load, which can be rail gun, high power radar, and other state of art
equipment. Energy storage based on supercapacitors is proposed as a technique
for buffering the direct impact of pulsed power load on the power systems.
However, the high magnitude of charging current of the energy storage can pose
as a disturbance to both distribution and generation systems. This paper
presents a fast switching device based real time control system that can
achieve a desired balance between maintaining the required power quality and
fast charging the energy storage in required time. Test results are shown to
verify the performance of the proposed control algorithm.
</dc:description>
 <dc:description>Comment: This paper has 20 page and 5 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05800</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interactive in-base street model edit: how common GIS software and a
  database can serve as a custom Graphical User Interface</dc:title>
 <dc:creator>Cura, Remi</dc:creator>
 <dc:creator>Perret, Julien</dc:creator>
 <dc:creator>Paparoditis, Nicolas</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Our modern world produces an increasing quantity of data, and especially
geospatial data, with advance of sensing technologies, and growing complexity
and organisation of vector data. Tools are needed to efficiently create and
edit those vector geospatial data. Procedural generation has been a tool of
choice to generate strongly organised data, yet it may be hard to control.
Because those data may be involved to take consequence-full real life
decisions, user interactions are required to check data and edit it. The
classical process to do so would be to build an adhoc Graphical User Interface
(GUI) tool adapted for the model and method being used. This task is difficult,
takes a large amount of resources, and is very specific to one model, making it
hard to share and re-use.
  Besides, many common generic GUI already exists to edit vector data, each
having its specialities. We propose a change of paradigm; instead of building a
specific tool for one task, we use common GIS software as GUIs, and deport the
specific interactions from the software to within the database. In this
paradigm, GIS software simply modify geometry and attributes of database
layers, and those changes are used by the database to perform automated task.
  This new paradigm has many advantages. The first one is genericity. With
in-base interaction, any GIS software can be used to perform edition, whatever
the software is a Desktop sofware or a web application. The second is
concurrency and coherency. Because interaction is in-base, use of database
features allows seamless multi-user work, and can guarantee that the data is in
a coherent state. Last we propose tools to facilitate multi-user edits, both
during the edit phase (each user knows what areas are edited by other users),
and before and after edit (planning of edit, analyse of edited areas).
</dc:description>
 <dc:description>Comment: this article is an extract from PhD thesis</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05802</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring, Understanding, and Classifying News Media Sympathy on Twitter
  after Crisis Events</dc:title>
 <dc:creator>Ali, Abdallah El</dc:creator>
 <dc:creator>Stratmann, Tim C</dc:creator>
 <dc:creator>Park, Souneil</dc:creator>
 <dc:creator>Sch&#xf6;ning, Johannes</dc:creator>
 <dc:creator>Heuten, Wilko</dc:creator>
 <dc:creator>Boll, Susanne CJ</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  This paper investigates bias in coverage between Western and Arab media on
Twitter after the November 2015 Beirut and Paris terror attacks. Using two
Twitter datasets covering each attack, we investigate how Western and Arab
media differed in coverage bias, sympathy bias, and resulting information
propagation. We crowdsourced sympathy and sentiment labels for 2,390 tweets
across four languages (English, Arabic, French, German), built a regression
model to characterize sympathy, and thereafter trained a deep convolutional
neural network to predict sympathy. Key findings show: (a) both events were
disproportionately covered (b) Western media exhibited less sympathy, where
each media coverage was more sympathetic towards the country affected in their
respective region (c) Sympathy predictions supported ground truth analysis that
Western media was less sympathetic than Arab media (d) Sympathetic tweets do
not spread any further. We discuss our results in light of global news flow,
Twitter affordances, and public perception impact.
</dc:description>
 <dc:description>Comment: Conditionally accepted for inclusion in the 2018 ACM Conference on
  Human Factors in Computing Systems (CHI'18) Papers program</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05823</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Device Caching for Network Offloading: Delay Minimization with Presence
  of User Mobility</dc:title>
 <dc:creator>Deng, Tao</dc:creator>
 <dc:creator>You, Lei</dc:creator>
 <dc:creator>Fan, Pingzhi</dc:creator>
 <dc:creator>Yuan, Di</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A delay-optimal caching problem (DOCP) in deviceto- device (D2D) networks
with moblity is modelled. The problem arises in the context of achieving
offloading using device caching, and the offloading effect is represented by
the expected network load ratio (NLR) which is the percentage of data that has
to be downloaded from the network. Compared with the related studies, this work
considers minimizing delay with NLR guarantee in mobility scenarios. A lower
bound of global optimum is derived, thus enabling performance benchmarking of
any sub-optimal algorithm. For problem-solving, an effective search algorithm
(ESA) is proposed based on the bound. Simulations are conducted to evaluate the
effectiveness of the ESA algorithm.
</dc:description>
 <dc:description>Comment: To appear in IEEE Wireless Communication Letters</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05831</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Experimental Study of Cryptocurrency Market Dynamics</dc:title>
 <dc:creator>Krafft, Peter M</dc:creator>
 <dc:creator>Della Penna, Nicol&#xe1;s</dc:creator>
 <dc:creator>Pentland, Alex</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>K.4.2</dc:subject>
 <dc:subject>H.5.m</dc:subject>
 <dc:description>  As cryptocurrencies gain popularity and credibility, marketplaces for
cryptocurrencies are growing in importance. Understanding the dynamics of these
markets can help to assess how viable the cryptocurrnency ecosystem is and how
design choices affect market behavior. One existential threat to
cryptocurrencies is dramatic fluctuations in traders' willingness to buy or
sell. Using a novel experimental methodology, we conducted an online experiment
to study how susceptible traders in these markets are to peer influence from
trading behavior. We created bots that executed over one hundred thousand
trades costing less than a penny each in 217 cryptocurrencies over the course
of six months. We find that individual &quot;buy&quot; actions led to short-term
increases in subsequent buy-side activity hundreds of times the size of our
interventions. From a design perspective, we note that the design choices of
the exchange we study may have promoted this and other peer influence effects,
which highlights the potential social and economic impact of HCI in the design
of digital institutions.
</dc:description>
 <dc:description>Comment: To appear in CHI 2018</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05831</dc:identifier>
 <dc:identifier>Peter Krafft, Nicol\'as Della Penna, Alex Pentland. (2018). An
  Experimental Study of Cryptocurrency Market Dynamics. ACM CHI Conference on
  Human Factors in Computing Systems (CHI)</dc:identifier>
 <dc:identifier>doi:10.1145/3173574.3174179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05832</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Computation of the 8-point DCT via Summation by Parts</dc:title>
 <dc:creator>Coelho, D. F. G.</dc:creator>
 <dc:creator>Cintra, R. J.</dc:creator>
 <dc:creator>Dimitrov, V. S.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  This paper introduces a new fast algorithm for the 8-point discrete cosine
transform (DCT) based on the summation-by-parts formula. The proposed method
converts the DCT matrix into an alternative transformation matrix that can be
decomposed into sparse matrices of low multiplicative complexity. The method is
capable of scaled and exact DCT computation and its associated fast algorithm
achieves the theoretical minimal multiplicative complexity for the 8-point DCT.
Depending on the nature of the input signal simplifications can be introduced
and the overall complexity of the proposed algorithm can be further reduced.
Several types of input signal are analyzed: arbitrary, null mean, accumulated,
and null mean/accumulated signal. The proposed tool has potential application
in harmonic detection, image enhancement, and feature extraction, where input
signal DC level is discarded and/or the signal is required to be integrated.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05832</dc:identifier>
 <dc:identifier>J Sign Process Syst (2017)</dc:identifier>
 <dc:identifier>doi:10.1007/s11265-017-1270-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05844</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Joint Pairing and Mode Selection in D2D
  Communications with FD Radios</dc:title>
 <dc:creator>Badri, Simin</dc:creator>
 <dc:creator>Naslcheraghi, Mansour</dc:creator>
 <dc:creator>Rasti, Mehdi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In cellular-D2D networks, users can select the communication mode either
direct and form D2D links or indirect and communicate with BS. In former case,
users should perform pairing selection and choose their pairs. The main focus
in this paper is proposing an analytical framework by using tools from
stochastic geometry to address these two issues, i.e. i) mode selection for the
user devices to be established in either cellular or D2D mode, which is done
based on received power from BS influenced by a bias factor, and ii)
investigation of choosing nth-nearest neighbor as the serving node for the
receiver of interest, by considering full-duplex (FD) radios as well as half-
duplex (HD) in the D2D links. The analytic and simulation results demonstrate
that even though the bias factor determines the throughput of each mode, it
does not have any influence on the system sum throughput. Furthermore, we
demonstrate that despite of suffering from self-interference, FD-D2D results in
higher system sum throughput as well as higher coverage probability in
comparison to its counterpart, namely purely HD- D2D network.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, accepted in WCNC 2018</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05848</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Construction of Partial MDS Codes</dc:title>
 <dc:creator>Neri, Alessandro</dc:creator>
 <dc:creator>Horlemann-Trautmann, Anna-Lena</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work deals with partial MDS (PMDS) codes, a special class of locally
repairable codes, used for distributed storage system. We first show that a
known construction of these codes, using Gabidulin codes, can be extended to
use any maximum rank distance code. Then we define a standard form for the
generator matrices of PMDS codes and use this form to give an algebraic
description of PMDS generator matrices. This implies that over a sufficiently
large finite field a randomly chosen generator matrix in PMDS standard form
generates a PMDS code with high probability. This also provides sufficient
conditions on the field size for the existence of PMDS codes.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05849</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Limited Communication Analysis and Design for Decentralized
  Estimation</dc:title>
 <dc:creator>Alexandru, Andreea B.</dc:creator>
 <dc:creator>Pequito, Sergio</dc:creator>
 <dc:creator>Jadbabaie, Ali</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This paper pertains to the analysis and design of decentralized estimation
schemes that make use of limited communication. Briefly, these schemes equip
the sensors with scalar states that iteratively merge the measurements and the
state of other sensors to be used for state estimation. Contrarily to commonly
used distributed estimation schemes, the only information being exchanged are
scalars, there is only one common time-scale for communication and estimation,
and the retrieval of the state of the system and sensors is achieved in
finite-time. We extend previous work to a more general setup and provide
necessary and sufficient conditions required for the communication between the
sensors that enable the use of limited communication decentralized
estimation~schemes. Additionally, we discuss the cases where the sensors are
memoryless, and where the sensors might not have the capacity to discern the
contributions of other sensors. Based on these conditions and the fact that
communication channels incur a cost, we cast the problem of finding the minimum
cost communication graph that enables limited communication decentralized
estimation schemes as an integer programming problem.
</dc:description>
 <dc:description>Comment: Updates on the paper in CDC 2017</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05852</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Representation Learning: A Survey</dc:title>
 <dc:creator>Zhang, Daokun</dc:creator>
 <dc:creator>Yin, Jie</dc:creator>
 <dc:creator>Zhu, Xingquan</dc:creator>
 <dc:creator>Zhang, Chengqi</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  With the widespread use of information technologies, information networks
have increasingly become popular to capture complex relationships across
various disciplines, such as social networks, citation networks,
telecommunication networks, and biological networks. Analyzing these networks
sheds light on different aspects of social life such as the structure of
society, information diffusion, and different patterns of communication.
However, the large scale of information networks often makes network analytic
tasks computationally expensive and intractable. Recently, network
representation learning has been proposed as a new learning paradigm that
embeds network vertices into a low-dimensional vector space, by preserving
network topology structure, vertex content, and other side information. This
facilitates the original network to be easily handled in the new vector space
for further analysis. In this survey, we perform a thorough review of the
current literature on network representation learning in the field of data
mining and machine learning. We propose a new categorization to analyze and
summarize state-of-the-art network representation learning techniques according
to the methodology they employ and the network information they preserve.
Finally, to facilitate research on this topic, we summarize benchmark datasets
and evaluation methodologies, and discuss open issues and future research
directions in this field.
</dc:description>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05853</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time Matters: Multi-scale Temporalization of Social Media Popularity</dc:title>
 <dc:creator>Wu, Bo</dc:creator>
 <dc:creator>Cheng, Wen-Huang</dc:creator>
 <dc:creator>Zhang, Yongdong</dc:creator>
 <dc:creator>Mei, Tao</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The evolution of social media popularity exhibits rich temporality, i.e.,
popularities change over time at various levels of temporal granularity. This
is influenced by temporal variations of public attentions or user activities.
For example, popularity patterns of street snap on Flickr are observed to
depict distinctive fashion styles at specific time scales, such as season-based
periodic fluctuations for Trench Coat or one-off peak in days for Evening
Dress. However, this fact is often overlooked by existing research of
popularity modeling. We present the first study to incorporate multiple
time-scale dynamics into predicting online popularity. We propose a novel
computational framework in the paper, named Multi-scale Temporalization, for
estimating popularity based on multi-scale decomposition and structural
reconstruction in a tensor space of user, post, and time by joint low-rank
constraints. By considering the noise caused by context inconsistency, we
design a data rearrangement step based on context aggregation as preprocessing
to enhance contextual relevance of neighboring data in the tensor space. As a
result, our approach can leverage multiple levels of temporal characteristics
and reduce the noise of data decomposition to improve modeling effectiveness.
We evaluate our approach on two large-scale Flickr image datasets with over 1.8
million photos in total, for the task of popularity prediction. The results
show that our approach significantly outperforms state-of-the-art popularity
prediction techniques, with a relative improvement of 10.9%-47.5% in terms of
prediction accuracy.
</dc:description>
 <dc:description>Comment: accepted in ACM Multimedia 2016</dc:description>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05854</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NDlib: a Python Library to Model and Analyze Diffusion Processes Over
  Complex Networks</dc:title>
 <dc:creator>Rossetti, Giulio</dc:creator>
 <dc:creator>Milli, Letizia</dc:creator>
 <dc:creator>Rinzivillo, Salvatore</dc:creator>
 <dc:creator>Sirbu, Alina</dc:creator>
 <dc:creator>Giannotti, Fosca</dc:creator>
 <dc:creator>Pedreschi, Dino</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>05C85, 60J60, 90C35</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:description>  Nowadays the analysis of dynamics of and on networks represents a hot topic
in the Social Network Analysis playground. To support students, teachers,
developers and researchers in this work we introduce a novel framework, namely
NDlib, an environment designed to describe diffusion simulations. NDlib is
designed to be a multi-level ecosystem that can be fruitfully used by different
user segments. For this reason, upon NDlib, we designed a simulation server
that allows remote execution of experiments as well as an online visualization
tool that abstracts its programmatic interface and makes available the
simulation platform to non-technicians.
</dc:description>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05854</dc:identifier>
 <dc:identifier>International Journal of Data Science and Analytics, 2018</dc:identifier>
 <dc:identifier>doi:10.1007/s41060-017-0086-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05855</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Spectral Graph Embedding: A Non-Backtracking Perspective and Graph
  Approximation</dc:title>
 <dc:creator>Jiang, Fei</dc:creator>
 <dc:creator>He, Lifang</dc:creator>
 <dc:creator>Zheng, Yi</dc:creator>
 <dc:creator>Zhu, Enqiang</dc:creator>
 <dc:creator>Xu, Jin</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Graph embedding has been proven to be efficient and effective in facilitating
graph analysis. In this paper, we present a novel spectral framework called
NOn-Backtracking Embedding (NOBE), which offers a new perspective that
organizes graph data at a deep level by tracking the flow traversing on the
edges with backtracking prohibited. Further, by analyzing the non-backtracking
process, a technique called graph approximation is devised, which provides a
channel to transform the spectral decomposition on an edge-to-edge matrix to
that on a node-to-node matrix. Theoretical guarantees are provided by bounding
the difference between the corresponding eigenvalues of the original graph and
its graph approximation. Extensive experiments conducted on various real-world
networks demonstrate the efficacy of our methods on both macroscopic and
microscopic levels, including clustering and structural hole spanner detection.
</dc:description>
 <dc:description>Comment: SDM 2018 (Full version including all proofs)</dc:description>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05856</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Community Detection: A Maximum Likelihood Approach</dc:title>
 <dc:creator>Mirabelli, Benjamin</dc:creator>
 <dc:creator>Kushnir, Dan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose novel semi-supervised and active learning algorithms for the
problem of community detection on networks. The algorithms are based on
optimizing the likelihood function of the community assignments given a graph
and an estimate of the statistical model that generated it. The optimization
framework is inspired by prior work on the unsupervised community detection
problem in Stochastic Block Models (SBM) using Semi-Definite Programming (SDP).
In this paper we provide the next steps in the evolution of learning
communities in this context which involves a constrained semi-definite
programming algorithm, and a newly presented active learning algorithm. The
active learner intelligently queries nodes that are expected to maximize the
change in the model likelihood. Experimental results show that this active
learning algorithm outperforms the random-selection semi-supervised version of
the same algorithm as well as other state-of-the-art active learning
algorithms. Our algorithms significantly improved performance is demonstrated
on both real-world and SBM-generated networks even when the SBM has a signal to
noise ratio (SNR) below the known unsupervised detectability threshold.
</dc:description>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05857</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Scalability of the GPUexplore Explicit-State Model Checker</dc:title>
 <dc:creator>Cassee, Nathan</dc:creator>
 <dc:creator>Neele, Thomas</dc:creator>
 <dc:creator>Wijs, Anton</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The use of graphics processors (GPUs) is a promising approach to speed up
model checking to such an extent that it becomes feasible to instantly verify
software systems during development. GPUexplore is an explicit-state model
checker that runs all its computations on the GPU. Over the years it has been
extended with various techniques, and the possibilities to further improve its
performance have been continuously investigated. In this paper, we discuss how
the hash table of the tool works, which is at the heart of its functionality.
We propose an alteration of the hash table that in isolated experiments seems
promising, and analyse its effect when integrated in the tool. Furthermore, we
investigate the current scalability of GPUexplore, by experimenting both with
input models of varying sizes and running the tool on one of the latest GPUs of
NVIDIA.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2017, arXiv:1712.08345</dc:description>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05857</dc:identifier>
 <dc:identifier>EPTCS 263, 2017, pp. 38-52</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.263.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05863</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Remote Attestation with Transport Layer Security</dc:title>
 <dc:creator>Knauth, Thomas</dc:creator>
 <dc:creator>Steiner, Michael</dc:creator>
 <dc:creator>Chakrabarti, Somnath</dc:creator>
 <dc:creator>Lei, Li</dc:creator>
 <dc:creator>Xing, Cedric</dc:creator>
 <dc:creator>Vij, Mona</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Intel(R) Software Guard Extensions (Intel(R) SGX) is a promising technology
to securely process information in otherwise untrusted environments. An
important aspect of Intel SGX is the ability to perform remote attestation to
assess the endpoint's trustworthiness. Ultimately, remote attestation will
result in an attested secure channel to provision secrets to the enclave.
  We seamlessly combine Intel SGX remote attestation with the establishment of
a standard Transport Layer Security (TLS) connection. Remote attestation is
performed during the connection setup. To achieve this, we neither change the
TLS protocol, nor do we modify existing protocol implementations.
  We have prototype implementations for three widely used open-source TLS
libraries: OpenSSL, wolfSSL and mbedTLS. We describe the requirements, design
and implementation details to seamlessly bind attested TLS endpoints to Intel
SGX enclaves.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05864</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Subdivision for Diameter-Distance Tests</dc:title>
 <dc:creator>Burr, Michael</dc:creator>
 <dc:creator>Gao, Shuhong</dc:creator>
 <dc:creator>Tsigaridas, Elias</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>68W30, 65Y20</dc:subject>
 <dc:description>  We present a general framework for analyzing the complexity of
subdivision-based algorithms whose tests are based on the sizes of regions and
their distance to certain sets (often varieties) intrinsic to the problem under
study. We call such tests diameter-distance tests. We illustrate that
diameter-distance tests are common in the literature by proving that many
interval arithmetic-based tests are, in fact, diameter-distance tests. For this
class of algorithms, we provide both non-adaptive bounds for the complexity,
based on separation bounds, as well as adaptive bounds, by applying the
framework of continuous amortization.
  Using this structure, we provide the first complexity analysis for the
algorithm by Plantinga and Vegeter for approximating real implicit curves and
surfaces. We present both adaptive and non-adaptive a priori worst-case bounds
on the complexity of this algorithm both in terms of the number of subregions
constructed and in terms of the bit complexity for the construction. Finally,
we construct families of hypersurfaces to prove that our bounds are tight.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05868</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Service Caching and Task Offloading for Mobile Edge Computing in
  Dense Networks</dc:title>
 <dc:creator>Xu, Jie</dc:creator>
 <dc:creator>Chen, Lixing</dc:creator>
 <dc:creator>Zhou, Pan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Mobile Edge Computing (MEC) pushes computing functionalities away from the
centralized cloud to the network edge, thereby meeting the latency requirements
of many emerging mobile applications and saving backhaul network bandwidth.
Although many existing works have studied computation offloading policies,
service caching is an equally, if not more important, design topic of MEC, yet
receives much less attention. Service caching refers to caching application
services and their related databases/libraries in the edge server (e.g.
MEC-enabled BS), thereby enabling corresponding computation tasks to be
executed. Because only a small number of application services can be cached in
resource-limited edge server at the same time, which services to cache has to
be judiciously decided to maximize the edge computing performance. In this
paper, we investigate the extremely compelling but much less studied problem of
dynamic service caching in MEC-enabled dense cellular networks. We propose an
efficient online algorithm, called OREO, which jointly optimizes dynamic
service caching and task offloading to address a number of key challenges in
MEC systems, including service heterogeneity, unknown system dynamics, spatial
demand coupling and decentralized coordination. Our algorithm is developed
based on Lyapunov optimization and Gibbs sampling, works online without
requiring future information, and achieves provable close-to-optimal
performance. Simulation results show that our algorithm can effectively reduce
computation latency for end users while keeping energy consumption low.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05870</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantized Compressive Sensing with RIP Matrices: The Benefit of
  Dithering</dc:title>
 <dc:creator>Xu, Chunlei</dc:creator>
 <dc:creator>Jacques, Laurent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In Compressive Sensing theory and its applications, quantization of signal
measurements, as integrated into any realistic sensing model, impacts the
quality of signal reconstruction. In fact, there even exist incompatible
combinations of quantization functions (e.g., the 1-bit sign function) and
sensing matrices (e.g., Bernoulli) that cannot lead to an arbitrarily low
reconstruction error when the number of observations increases.
  This work shows that, for a scalar and uniform quantization, provided that a
uniform random vector, or &quot;random dithering&quot;, is added to the compressive
measurements of a low-complexity signal (e.g., a sparse or compressible signal,
or a low-rank matrix) before quantization, a large class of random matrix
constructions known to respect the restricted isometry property (RIP) are made
&quot;compatible&quot; with this quantizer. This compatibility is demonstrated by the
existence of (at least) one signal reconstruction method, the &quot;projected back
projection&quot; (PBP), whose reconstruction error is proved to decay when the
number of quantized measurements increases.
  Despite the simplicity of PBP, which amounts to projecting the back
projection of the compressive observations (obtained from their multiplication
by the adjoint sensing matrix) onto the low-complexity set containing the
observed signal, we also prove that given a RIP matrix and for a single
realization of the dithering, this reconstruction error decay is also
achievable uniformly for the sensing of all signals in the considered
low-complexity set.
  We finally confirm empirically these observations in several sensing contexts
involving sparse signals, low-rank matrices, and compressible signals, with
various RIP matrix constructions such as sub-Gaussian random matrices and
random partial Discrete Cosine Transform (DCT) matrices.
</dc:description>
 <dc:description>Comment: 40 pages, 9 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05873</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Activity Detection for Massive Connectivity</dc:title>
 <dc:creator>Chen, Zhilin</dc:creator>
 <dc:creator>Sohrabi, Foad</dc:creator>
 <dc:creator>Yu, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the massive connectivity application in which a large
number of potential devices communicate with a base-station (BS) in a sporadic
fashion. The detection of device activity pattern together with the estimation
of the channel are central problems in such a scenario. Due to the large number
of potential devices in the network, the devices need to be assigned
non-orthogonal signature sequences. The main objective of this paper is to show
that by using random signature sequences and by exploiting sparsity in the user
activity pattern, the joint user detection and channel estimation problem can
be formulated as a compressed sensing single measurement vector (SMV) problem
or multiple measurement vector (MMV) problem, depending on whether the BS has a
single antenna or multiple antennas, and be efficiently solved using an
approximate message passing (AMP) algorithm. This paper proposes an AMP
algorithm design that exploits the statistics of the wireless channel and
provides an analytical characterization of the probabilities of false alarm and
missed detection by using the state evolution. We consider two cases depending
on whether the large-scale component of the channel fading is known at the BS
and design the minimum mean squared error (MMSE) denoiser for AMP according to
the channel statistics. Simulation results demonstrate the substantial
advantage of exploiting the statistical channel information in AMP design;
however, knowing the large-scale fading component does not offer tangible
benefits. For the multiple-antenna case, we employ two different AMP
algorithms, namely the AMP with vector denoiser and the parallel AMP-MMV, and
quantify the benefit of deploying multiple antennas at the BS.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures; accepted at TSP</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05881</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Pipeline for Post-Crisis Twitter Data Acquisition</dc:title>
 <dc:creator>Kejriwal, Mayank</dc:creator>
 <dc:creator>Gu, Yao</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Due to instant availability of data on social media platforms like Twitter,
and advances in machine learning and data management technology, real-time
crisis informatics has emerged as a prolific research area in the last decade.
Although several benchmarks are now available, especially on portals like
CrisisLex, an important, practical problem that has not been addressed thus far
is the rapid acquisition and benchmarking of data from free, publicly available
streams like the Twitter API. In this paper, we present ongoing work on a
pipeline for facilitating immediate post-crisis data collection, curation and
relevance filtering from the Twitter API. The pipeline is minimally supervised,
alleviating the need for feature engineering by including a judicious mix of
data preprocessing and fast text embeddings, along with an active learning
framework. We illustrate the utility of the pipeline by describing a recent
case study wherein it was used to collect and analyze millions of tweets in the
immediate aftermath of the Las Vegas shootings.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, Workshop on Social Web in Emergency and Disaster
  Management 2018 at the ACM WSDM Conference</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05882</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonuniform Reductions and NP-Completeness</dc:title>
 <dc:creator>Hitchcock, John M.</dc:creator>
 <dc:creator>Shafei, Hadi</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Nonuniformity is a central concept in computational complexity with powerful
connections to circuit complexity and randomness. Nonuniform reductions have
been used to study the isomorphism conjecture for NP and completeness for
larger complexity classes. We study the power of nonuniform reductions for
NP-completeness, obtaining both separations and upper bounds for nonuniform
completeness vs uniform completeness in NP.
  Under various hypotheses, we obtain the following separations:
  1. There is a set complete for NP under nonuniform many-one reductions, but
not under uniform many-one reductions. This is true even with a single bit of
nonuniform advice.
  2. There is a set complete for NP under nonuniform many-one reductions with
polynomial-size advice, but not under uniform Turing reductions. That is,
polynomial nonuniformity is stronger than a polynomial number of queries.
  3. For any fixed polynomial p(n), there is a set complete for NP under
uniform 2-truth-table reductions, but not under nonuniform many-one reductions
that use p(n) advice. That is, giving a uniform reduction a second query makes
it more powerful than a nonuniform reduction with fixed polynomial advice.
  4. There is a set complete for NP under nonuniform many-one reductions with
polynomial advice, but not under nonuniform many-one reductions with
logarithmic advice. This hierarchy theorem also holds for other reducibilities,
such as truth-table and Turing.
  We also consider uniform upper bounds on nonuniform completeness. Hirahara
(2015) showed that unconditionally every set that is complete for NP under
nonuniform truth-table reductions that use logarithmic advice is also uniformly
Turing-complete. We show that under a derandomization hypothesis, the same
statement for truth-table reductions and truth-table completeness also holds.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05884</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nondeterminisic Sublinear Time Has Measure 0 in P</dc:title>
 <dc:creator>Hitchcock, John M.</dc:creator>
 <dc:creator>Sekoni, Adewale</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The measure hypothesis is a quantitative strengthening of the P != NP
conjecture which asserts that NP is a nonnegligible subset of EXP. Cai,
Sivakumar, and Strauss (1997) showed that the analogue of this hypothesis in P
is false. In particular, they showed that NTIME[n^{1/11}] has measure 0 in P.
We improve on their result to show that the class of all languages decidable in
nondeterministic sublinear time has measure 0 in P. Our result is based on DNF
width and holds for all four major notions of measure on P.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05889</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perceived Audiovisual Quality Modelling based on Decison Trees, Genetic
  Programming and Neural Networks</dc:title>
 <dc:creator>Demirbilek, Edip</dc:creator>
 <dc:creator>Gr&#xe9;goire, Jean-Charles</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Our objective is to build machine learning based models that predict
audiovisual quality directly from a set of correlated parameters that are
extracted from a target quality dataset. We have used the bitstream version of
the INRS audiovisual quality dataset that reflects contemporary real-time
configurations for video frame rate, video quantization, noise reduction
parameters and network packet loss rate. We have utilized this dataset to build
bitstream perceived quality estimation models based on the Random Forests,
Bagging, Deep Learning and Genetic Programming methods.
  We have taken an empirical approach and have generated models varying from
very simple to the most complex depending on the number of features used from
the quality dataset. Random Forests and Bagging models have overall generated
the most accurate results in terms of RMSE and Pearson correlation coefficient
values. Deep Learning and Genetic Programming based bitstream models have also
achieved good results but that high performance was observed only with a
limited range of features. We have also obtained the epsilon-insensitive RMSE
values for each model and have computed the significance of the difference
between the correlation coefficients.
  Overall we conclude that computing the bitstream information is worth the
effort it takes to generate and helps to build more accurate models for
real-time communications. However, it is useful only for the deployment of the
right algorithms with the carefully selected subset of the features. The
dataset and tools that have been developed during this research are publicly
available for research and development purposes.
</dc:description>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05894</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning: An Introduction for Applied Mathematicians</dc:title>
 <dc:creator>Higham, Catherine F.</dc:creator>
 <dc:creator>Higham, Desmond J.</dc:creator>
 <dc:subject>Mathematics - History and Overview</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>97R40, 68T01, 65K10, 62M45</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Multilayered artificial neural networks are becoming a pervasive tool in a
host of application fields. At the heart of this deep learning revolution are
familiar concepts from applied and computational mathematics; notably, in
calculus, approximation theory, optimization and linear algebra. This article
provides a very brief introduction to the basic ideas that underlie deep
learning from an applied mathematics perspective. Our target audience includes
postgraduate and final year undergraduate students in mathematics who are keen
to learn about the area. The article may also be useful for instructors in
mathematics who wish to enliven their classes with references to the
application of deep learning techniques. We focus on three fundamental
questions: what is a deep neural network? how is a network trained? what is the
stochastic gradient method? We illustrate the ideas with a short MATLAB code
that sets up and trains a network. We also show the use of state-of-the art
software on a large scale image classification problem. We finish with
references to the current literature.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05895</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparsely Connected Convolutional Networks</dc:title>
 <dc:creator>Zhu, Ligeng</dc:creator>
 <dc:creator>Deng, Ruizhi</dc:creator>
 <dc:creator>Deng, Zhiwei</dc:creator>
 <dc:creator>Mori, Greg</dc:creator>
 <dc:creator>Tan, Ping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Residual learning with skip connections permits training ultra-deep neural
networks and obtains superb performance. Building in this direction, DenseNets
proposed a dense connection structure where each layer is directly connected to
all of its predecessors. The densely connected structure leads to better
information flow and feature reuse. However, the overly dense skip connections
also bring about the problems of potential risk of overfitting, parameter
redundancy and large memory consumption. In this work, we analyze the feature
aggregation patterns of ResNets and DenseNets under a uniform aggregation view
framework. We show that both structures densely gather features from previous
layers in the network but combine them in their respective ways: summation
(ResNets) or concatenation (DenseNets). We compare the strengths and drawbacks
of these two aggregation methods and analyze their potential effects on the
networks' performance. Based on our analysis, we propose a new structure named
SparseNets which achieves better performance with fewer parameters than
DenseNets and ResNets.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05896</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Batch Auction Design For Cloud Container Services</dc:title>
 <dc:creator>Ma, Lin</dc:creator>
 <dc:creator>Zhou, Ruiting</dc:creator>
 <dc:creator>Li, Zongpeng</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Cloud containers represent a new, light-weight alternative to virtual
machines in cloud computing. A user job may be described by a container graph
that specifies the resource profile of each container and container dependence
relations. This work is the first in the cloud computing literature that
designs efficient market mechanisms for container based cloud jobs. Our design
targets simultaneously incentive compatibility, computational efficiency, and
economic efficiency. It further adapts the idea of batch online optimization
into the paradigm of mechanism design, leveraging agile creation of cloud
containers and exploiting delay tolerance of elastic cloud jobs. The new and
classic techniques we employ include: (i) compact exponential optimization for
expressing and handling non-traditional constraints that arise from container
dependence and job deadlines; (ii) the primal-dual schema for designing
efficient approximation algorithms for social welfare maximization; and (iii)
posted price mechanisms for batch decision making and truthful payment design.
Theoretical analysis and trace-driven empirical evaluation verify the efficacy
of our container auction algorithms.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05906</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Hashtag Retrieval and Visualization for Crisis Informatics</dc:title>
 <dc:creator>Gu, Yao</dc:creator>
 <dc:creator>Kejriwal, Mayank</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In social media like Twitter, hashtags carry a lot of semantic information
and can be easily distinguished from the main text. Exploring and visualizing
the space of hashtags in a meaningful way can offer important insights into a
dataset, especially in crisis situations. In this demonstration paper, we
present a functioning prototype, HashViz, that ingests a corpus of tweets
collected in the aftermath of a crisis situation (such as the Las Vegas
shootings) and uses the fastText bag-of-tricks semantic embedding algorithm
(from Facebook Research) to embed words and hashtags into a vector space.
Hashtag vectors obtained in this way can be visualized using the t-SNE
dimensionality reduction algorithm in 2D. Although multiple Twitter
visualization platforms exist, HashViz is distinguished by being simple,
scalable, interactive and portable enough to be deployed on a server for
million-tweet corpora collected in the aftermath of arbitrary disasters,
without special-purpose installation, technical expertise, manual supervision
or costly software or infrastructure investment. Although simple, we show that
HashViz offers an intuitive way to summarize, and gain insight into, a
developing crisis situation. HashViz is also completely unsupervised, requiring
no manual inputs to go from a raw corpus to a visualization and search
interface. Using the recent Las Vegas mass shooting massacre as a case study,
we illustrate the potential of HashViz using only a web browser on the client
side.
</dc:description>
 <dc:description>Comment: 2 pages, 3 figures, Workshop on Social Web in Emergency and Disaster
  Management at ACM WSDM 2018</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05909</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling and Tiling Reductions on Realistic Machines</dc:title>
 <dc:creator>Prajapati, Nirmal</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Computations, where the number of results is much smaller than the input data
and are produced through some sort of accumulation, are called Reductions.
Reductions appear in many scientific applications. Usually, reductions admit an
associative and commutative binary operator over accumulation. Reductions are
therefore highly parallel. Given unbounded fan-in, one can execute a reduction
in constant/linear time provided that the data is available. However, due to
the fact that real machines have bounded fan-in, accumulations cannot be
performed in one time step and have to be broken into parts. Thus, a (partial)
serialization of reductions becomes necessary. This makes scheduling reductions
a difficult and interesting problem.
  There have been a number of research works in the context of scheduling
reductions. We focus on the scheduling techniques presented in Gupta et al.,
identify a potential issue in their scheduling algorithm and provide a
solution. In addition, we demonstrate how these scheduling techniques can be
extended to &quot;tile&quot; reductions and briefly survey other studies that address the
problem of scheduling reductions.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05911</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How can social planners prevent disappointment in an election?</dc:title>
 <dc:creator>Ramezanian, Rasoul</dc:creator>
 <dc:creator>Javidian, Mohammad ali</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Mechanism design is concerned with settings where a policy maker (or social
planner) faces the problem of aggregating the announced preferences of multiple
agents into a collective (or social), system-wide decision. One of the most
important ways for aggregation preference used in a multi agent system is using
election. In an election, the aim is to select the candidate who reects the
common will of the whole society. Despite the importance of this subject, in
the real world situations, sometimes under special circumstances, the result of
the election is completely an antithesis of the purpose of those who execute it
or the election leads to the dissatisfaction of a large amount of people. For
analyzing these situations, a notion is discussed in the present paper called
social disappointment and then new protocols are proposed to prevent social
disappointment. A version of the impossibility theorem is stated and proved
regarding social disappointment in elections. In the end, the numerical results
obtained by simulating the voting protocols of plurality and Hare system are
given, to show that Hare system is a little more seccessful than plurality to
prevent social disappointment.
</dc:description>
 <dc:description>Comment: 19 pages, 1 figure, and 2 tables</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05912</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the influence of Dice loss function in multi-class organ segmentation
  of abdominal CT using 3D fully convolutional networks</dc:title>
 <dc:creator>Shen, Chen</dc:creator>
 <dc:creator>Roth, Holger R.</dc:creator>
 <dc:creator>Oda, Hirohisa</dc:creator>
 <dc:creator>Oda, Masahiro</dc:creator>
 <dc:creator>Hayashi, Yuichiro</dc:creator>
 <dc:creator>Misawa, Kazunari</dc:creator>
 <dc:creator>Mori, Kensaku</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning-based methods achieved impressive results for the segmentation
of medical images. With the development of 3D fully convolutional networks
(FCNs), it has become feasible to produce improved results for multi-organ
segmentation of 3D computed tomography (CT) images. The results of multi-organ
segmentation using deep learning-based methods not only depend on the choice of
networks architecture, but also strongly rely on the choice of loss function.
In this paper, we present a discussion on the influence of Dice-based loss
functions for multi-class organ segmentation using a dataset of abdominal CT
volumes. We investigated three different types of weighting the Dice loss
functions based on class label frequencies (uniform, simple and square) and
evaluate their influence on segmentation accuracies. Furthermore, we compared
the influence of different initial learning rates. We achieved average Dice
scores of 81.3%, 59.5% and 31.7% for uniform, simple and square types of
weighting when the learning rate is 0.001, and 78.2%, 81.0% and 58.5% for each
weighting when the learning rate is 0.01. Our experiments indicated a strong
relationship between class balancing weights and initial learning rate in
training.
</dc:description>
 <dc:description>Comment: presented at MI-ken, November 2017, Takamatsu, Japan
  (http://www.ieice.org/iss/mi/)</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05915</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security in Mobile Edge Caching with Reinforcement Learning</dc:title>
 <dc:creator>Xiao, Liang</dc:creator>
 <dc:creator>Wan, Xiaoyue</dc:creator>
 <dc:creator>Dai, Canhuang</dc:creator>
 <dc:creator>Du, Xiaojiang</dc:creator>
 <dc:creator>Chen, Xiang</dc:creator>
 <dc:creator>Guizani, Mohsen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Mobile edge computing usually uses cache to support multimedia contents in 5G
mobile Internet to reduce the computing overhead and latency. Mobile edge
caching (MEC) systems are vulnerable to various attacks such as denial of
service attacks and rogue edge attacks. This article investigates the attack
models in MEC systems, focusing on both the mobile offloading and the caching
procedures. In this paper, we propose security solutions that apply
reinforcement learning (RL) techniques to provide secure offloading to the edge
nodes against jamming attacks. We also present light-weight authentication and
secure collaborative caching schemes to protect data privacy. We evaluate the
performance of the RL-based security solution for mobile edge caching and
discuss the challenges that need to be addressed in the future.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05916</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Citation Analysis of Innovative ICT and Advances of Governance
  (2008-2017)</dc:title>
 <dc:creator>Liu, Shuhua Monica</dc:creator>
 <dc:creator>Pan, Liting</dc:creator>
 <dc:creator>Chen, Xiaowei</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This paper opens by introducing the Internet Plus Government (IPG), a new
government initiative emerging in the last decade. To understand benefits and
challenges associated with this initiative worldwide, we conducted analyses on
research articles published in the e-governance area between 2008 and 2017.
Content analysis and citation analysis were performed on 2105 articles to
address three questions: (1) What types of new ICT have been adopted in the IPG
initiative in the past decade? (2) How did scholars investigate interactions
between the new ICTs and governance core to IPG? (3) How did the new ICTs
interact and shape while also being shaped by the evolution of governance in
the past decade? Our analysis suggests that IPG initiative has enriched the
government information infrastructure. It presented opportunities to accumulate
and use huge volume of data for better decision making and proactive
government-citizen interaction. At the same time, the advance of open data, the
widespread use of social media and the potential of data analytics also
generated great pressure to address challenging questions and issues in the
domain of e-democracy.
</dc:description>
 <dc:description>Comment: Corrected first author's name spelling and added authors' affiliation
  in the metadata</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05917</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Large-Scale Empirical Comparison of Static and Dynamic Test Case
  Prioritization Techniques</dc:title>
 <dc:creator>Luo, Qi</dc:creator>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:creator>Poshyvanyk, Denys</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The large body of existing research in Test Case Prioritization (TCP)
techniques, can be broadly classified into two categories: dynamic techniques
(that rely on run-time execution information) and static techniques (that
operate directly on source and test code). Absent from this current body of
work is a comprehensive study aimed at understanding and evaluating the static
approaches and comparing them to dynamic approaches on a large set of projects.
  In this work, we perform the first extensive study aimed at empirically
evaluating four static TCP techniques comparing them with state-of-research
dynamic TCP techniques at different test-case granularities (e.g., method and
class-level) in terms of effectiveness, efficiency and similarity of faults
detected. This study was performed on 30 real-word Java programs encompassing
431 KLoC. In terms of effectiveness, we find that the static call-graph-based
technique outperforms the other static techniques at test-class level, but the
topic-model-based technique performs better at test-method level. In terms of
efficiency, the static call-graph-based technique is also the most efficient
when compared to other static techniques. When examining the similarity of
faults detected for the four static techniques compared to the four dynamic
ones, we find that on average, the faults uncovered by these two groups of
techniques are quite dissimilar, with the top 10% of test cases agreeing on
only 25% - 30% of detected faults. This prompts further research into the
severity/importance of faults uncovered by these techniques, and into the
potential for combining static and dynamic information for more effective
approaches.
</dc:description>
 <dc:description>Comment: 12 pages, Accepted in the proceedings of the 2016 24th ACM SIGSOFT
  International Symposium on Foundations of Software Engineering (FSE'16)</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05917</dc:identifier>
 <dc:identifier>doi:10.1145/2950290.2950344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05918</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extend the shallow part of Single Shot MultiBox Detector via
  Convolutional Neural Network</dc:title>
 <dc:creator>Zheng, Liwen</dc:creator>
 <dc:creator>Fu, Canmiao</dc:creator>
 <dc:creator>Zhao, Yong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Single Shot MultiBox Detector (SSD) is one of the fastest algorithms in the
current object detection field, which uses fully convolutional neural network
to detect all scaled objects in an image. Deconvolutional Single Shot Detector
(DSSD) is an approach which introduces more context information by adding the
deconvolution module to SSD. And the mean Average Precision (mAP) of DSSD on
PASCAL VOC2007 is improved from SSD's 77.5% to 78.6%. Although DSSD obtains
higher mAP than SSD by 1.1%, the frames per second (FPS) decreases from 46 to
11.8. In this paper, we propose a single stage end-to-end image detection model
called ESSD to overcome this dilemma. Our solution to this problem is to
cleverly extend better context information for the shallow layers of the best
single stage (e.g. SSD) detectors. Experimental results show that our model can
reach 79.4% mAP, which is higher than DSSD and SSD by 0.8 and 1.9 points
respectively. Meanwhile, our testing speed is 25 FPS in Titan X GPU which is
more than double the original DSSD.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, 3 tables</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05919</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-Optimal Streaming Codes for Channels with Burst and Isolated
  Erasures</dc:title>
 <dc:creator>Krishnan, M. Nikhil</dc:creator>
 <dc:creator>Kumar, P. Vijay</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recovery of data packets from packet erasures in a timely manner is critical
for many streaming applications. An early paper by Martinian and Sundberg
introduced a framework for streaming codes and designed rate-optimal codes that
permit delay-constrained recovery from an erasure burst of length up to $B$. A
recent work by Badr et al. extended this result and introduced a sliding-window
channel model $\mathcal{C}(N,B,W)$. Under this model, in a sliding-window of
width $W$, one of the following erasure patterns are possible (i) a burst of
length at most $B$ or (ii) at most $N$ (possibly non-contiguous) arbitrary
erasures. Badr et al. obtained a rate upper bound for streaming codes that can
recover with a time delay $T$, from any erasure patterns permissible under the
$\mathcal{C}(N,B,W)$ model. However, constructions matching the bound were
absent, except for a few parameter sets. In this paper, we present an explicit
family of codes that achieves the rate upper bound for all feasible parameters
$N$, $B$, $W$ and $T$.
</dc:description>
 <dc:description>Comment: shorter version submitted to ISIT 2018</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05924</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-Device Bug Reporting for Android Applications</dc:title>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:creator>Bonett, Richard</dc:creator>
 <dc:creator>Bernal-Cardenas, Carlos</dc:creator>
 <dc:creator>Otten, Brendan</dc:creator>
 <dc:creator>Park, Daniel</dc:creator>
 <dc:creator>Poshyvanyk, Denys</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Bugs that surface in mobile applications can be difficult to reproduce and
fix due to several confounding factors including the highly GUI-driven nature
of mobile apps, varying contextual states, differing platform versions and
device fragmentation. It is clear that developers need support in the form of
automated tools that allow for more precise reporting of application defects in
order to facilitate more efficient and effective bug fixes. In this paper, we
present a tool aimed at supporting application testers and developers in the
process of On-Device Bug Reporting. Our tool, called ODBR, leverages the
uiautomator framework and low-level event stream capture to offer support for
recording and replaying a series of input gesture and sensor events that
describe a bug in an Android application.
</dc:description>
 <dc:description>Comment: 2 pages, Accepted in the Proceedings of 4th IEEE/ACM International
  Conference on Mobile Software Engineering and Systems (MOBILESoft'17)</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05926</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Utility Cost of Robust Privacy Guarantees</dc:title>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Diaz, Mario</dc:creator>
 <dc:creator>Calmon, Flavio P.</dc:creator>
 <dc:creator>Sankar, Lalitha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Consider a data publishing setting for a data set with public and private
features. The objective of the publisher is to maximize the amount of
information about the public features in a revealed data set, while keeping the
information leaked about the private features bounded. The goal of this paper
is to analyze the performance of privacy mechanisms that are constructed to
match the distribution learned from the data set. Two distinct scenarios are
considered: (i) mechanisms are designed to provide a privacy guarantee for the
learned distribution; and (ii) mechanisms are designed to provide a privacy
guarantee for every distribution in a given neighborhood of the learned
distribution. For the first scenario, given any privacy mechanism, upper bounds
on the difference between the privacy-utility guarantees for the learned and
true distributions are presented. In the second scenario, upper bounds on the
reduction in utility incurred by providing a uniform privacy guarantee are
developed.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05927</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview of Machine Teaching</dc:title>
 <dc:creator>Zhu, Xiaojin</dc:creator>
 <dc:creator>Singla, Adish</dc:creator>
 <dc:creator>Zilles, Sandra</dc:creator>
 <dc:creator>Rafferty, Anna N.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we try to organize machine teaching as a coherent set of ideas.
Each idea is presented as varying along a dimension. The collection of
dimensions then form the problem space of machine teaching, such that existing
teaching problems can be characterized in this space. We hope this organization
allows us to gain deeper understanding of individual teaching problems,
discover connections among them, and identify gaps in the field.
</dc:description>
 <dc:description>Comment: A tutorial document grown out of NIPS 2017 Workshop on Teaching
  Machines, Robots, and Humans</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05928</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On partitions into squares of distinct integers whose reciprocals sum to
  1</dc:title>
 <dc:creator>Alekseyev, Max A.</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In 1963, Graham proved that all integers greater than 77 (but not 77 itself)
can be partitioned into distinct positive integers whose reciprocals sum to 1.
He further conjectured that for any sufficiently large integer, it can be
partitioned into squares of distinct positive integers whose reciprocals sum to
1. In this study, we establish the exact bound for existence of such
representations by proving that 8542 is the largest integer with no such
partition.
</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05931</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Algorithms for Large-scale Machine Learning using Simple Sampling
  Techniques</dc:title>
 <dc:creator>Chauhan, Vinod Kumar</dc:creator>
 <dc:creator>Dahiya, Kalpana</dc:creator>
 <dc:creator>Sharma, Anuj</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Now a days, the major challenge in machine learning is the `Big~Data'
challenge. The big data problems due to large number of data points or large
number of features in each data point, or both, the training of models have
become very slow. The training time has two major components: Time to access
the data and time to process the data. In this paper, we have proposed one
possible solution to handle the big data problems in machine learning. The
focus is on reducing the training time through reducing data access time by
proposing systematic sampling and cyclic/sequential sampling to select
mini-batches from the dataset. To prove the effectiveness of proposed sampling
techniques, we have used Empirical Risk Minimization, which is commonly used
machine learning problem, for strongly convex and smooth case. The problem has
been solved using SAG, SAGA, SVRG, SAAG-II and MBSGD (Mini-batched SGD), each
using two step determination techniques, namely, constant step size and
backtracking line search method. Theoretical results prove the same convergence
for systematic sampling, cyclic sampling and the widely used random sampling
technique, in expectation. Experimental results with bench marked datasets
prove the efficacy of the proposed sampling techniques.
</dc:description>
 <dc:description>Comment: 80 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05932</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Bug Reports for Mobile Apps</dc:title>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The modern software development landscape has seen a shift in focus toward
mobile applications as &quot;smart&quot; devices near ubiquitous adoption. Due to this
trend, the complexity of mobile applications has been increasing, making
development and maintenance particularly challenging. However, it is clear that
current bug tracking systems are not able effectively support construction of
reports with actionable information that will directly lead to a bug's
resolution. To address the need for an improved reporting system, we introduce
a novel solution, called FUSION, that helps users auto-complete reproduction
steps in bug reports for mobile apps. FUSION links information, that users
provide, to program artifacts extracted through static and dynamic analysis
performed before testing or release. The approach that FUSION employs is
generalizable to other current mobile software platforms, and constitutes a new
method by which off-device bug reporting can be conducted for mobile software
projects. We evaluate FUSION by conducting a study that quantitatively and
qualitatively measures the user experience of the system for both reporting and
reproducing bugs, as well as the quality of the bug reports it produces. In a
study involving 28 participants we apply FUSION to support the maintenance
tasks of reporting and reproducing defects on 15 real-world bugs found in 14
open source Android apps. Our results demonstrate that FUSION allows for more
reliable reproduction of bugs from reports by aiding users in reporting more
detailed application-specific information compared to traditional bug tracking
systems.
</dc:description>
 <dc:description>Comment: 77 pages, MS Thesis presented to the faculty @ the College of William
  &amp; Mary</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05937</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixing Bug Reporting for Mobile and GUI-Based Applications</dc:title>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Smartphones and tablets have established themselves as mainstays in the
modern computing landscape. It is conceivable that in the near future such
devices may supplant laptops and desktops, becoming many users primary means of
carrying out typical computer assisted tasks. In turn, this means that mobile
applications will continue on a trajectory to becoming more complex, and the
primary focus of millions of developers worldwide. In order to properly create
and maintain these apps developers will need support, especially with regard to
the prompt confirmation and resolution of bug reports. Unfortunately, current
issue tracking systems typically only implement collection of coarse grained
natural language descriptions, and lack features to facilitate reporters
including important information in their reports. This illustrates the lexical
information gap that exists in current bug reporting systems for mobile and
GUI-based apps. This paper outlines promising preliminary work towards
addressing this problem and proposes a comprehensive research program which
aims to implement new bug reporting mechanisms and examine the impact that they
might have on related software maintenance tasks.
</dc:description>
 <dc:description>Comment: 4 pages, accepted to the Doctoral Symposium at the 38th ACM/IEEE
  International Conference on Software Engineering (ICSE'16)</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05938</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WiLAD: Wireless Localisation through Anomaly Detection</dc:title>
 <dc:creator>Nguyen, Cam Ly</dc:creator>
 <dc:creator>Khan, Aftab</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We propose a new approach towards RSS (Received Signal Strength) based
wireless localisation for scenarios where, instead of absolute positioning of
an object, only the information whether an object is inside or outside of a
specific area is required. This is motivated through a number of applications
including, but not limited to, a) security: detecting whether an object is
removed from a secure location, b) wireless sensor networks: detecting sensor
movements outside of a network area, and c) computational behaviour analytics:
detecting customers leaving a retail store. The result of such detection
systems can naturally be utilised in building a higher level contextual
understanding of a system or user behaviours. We use a supervised learning
method to overcome issues related to RSS based localisation systems including
multipath fading, shadowing, and incorrect model parameters (as in unsupervised
methods). Moreover, to reduce the cost of collecting training data, we employ a
detection method called One-Class SVM (OC-SVM) which requires only one class of
data (positive data, or target class data) for training. We derive a
mathematical approximation of accuracy which utilises the characteristics of
wireless signals as well as OC-SVM. Based on this we then propose a novel
mathematical formula to find optimal placement of devices. This enables us to
optimize the placement without performing any costly experiments or
simulations. We validate our proposed mathematical framework based on simulated
and real experiments.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05938</dc:identifier>
 <dc:identifier>IEEE GLOBECOM 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05940</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FUSION: A Tool for Facilitating and Augmenting Android Bug Reporting</dc:title>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:creator>Linares-Vasquez, Mario</dc:creator>
 <dc:creator>Bernal-Cardenas, Carlos</dc:creator>
 <dc:creator>Poshyvanyk, Denys</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  As the popularity of mobile smart devices continues to climb the complexity
of &quot;apps&quot; continues to increase, making the development and maintenance process
challenging. Current bug tracking systems lack key features to effectively
support construction of reports with actionable information that directly lead
to a bug's resolution. In this demo we present the implementation of a novel
bug reporting system, called Fusion, that facilitates users including
reproduction steps in bug reports for mobile apps. Fusion links user-provided
information to program artifacts extracted through static and dynamic analysis
performed before testing or release. Results of preliminary studies demonstrate
that Fusion both effectively facilitates reporting and allows for more reliable
reproduction of bugs from reports compared to traditional issue tracking
systems by presenting more detailed contextual app information. Tool website:
www.fusion-android. com Video url: https://youtu.be/AND9h0ElxRg
</dc:description>
 <dc:description>Comment: 4 pages, Accepted in the Proceedings of 38thACM/IEEE International
  Conference on Software Engineering (ICSE'16)</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05944</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PTB-TIR: A Thermal Infrared Pedestrian Tracking Benchmark</dc:title>
 <dc:creator>Liu, Qiao</dc:creator>
 <dc:creator>He, Zhenyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Thermal infrared (TIR) pedestrian tracking is one of the most important
components in numerous applications of computer vision, which has a major
advantage: it can track the pedestrians in total darkness. How to evaluate the
TIR pedestrian tracker fairly on a benchmark dataset is significant for the
development of this field. However, there is no a benchmark dataset. In this
paper, we develop a TIR pedestrian tracking dataset for the TIR pedestrian
tracker evaluation. The dataset includes 60 thermal sequences with manual
annotations. Each sequence has nine attribute labels for the attribute based
evaluation. In addition to the dataset, we carry out the large-scale evaluation
experiments on our benchmark dataset using nine public available trackers. The
experimental results help us to understand the strength and weakness of these
trackers. What's more, in order to get insight into the TIR pedestrian tracker
more sufficiently, we divide a tracker into three components: feature
extractor, motion model, and observation model. Then, we conduct three
comparison experiments on our benchmark dataset to validate how each component
affects the tracker's performance. The findings of these experiments provide
some guidelines for future research.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05946</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Efficiently Detecting Overlapping Communities over Distributed
  Dynamic Graphs</dc:title>
 <dc:creator>Jian, Xun</dc:creator>
 <dc:creator>Lian, Xiang</dc:creator>
 <dc:creator>Chen, Lei</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Modern networks are of huge sizes as well as high dynamics, which challenges
the efficiency of community detection algorithms. In this paper, we study the
problem of overlapping community detection on distributed and dynamic graphs.
Given a distributed, undirected and unweighted graph, the goal is to detect
overlapping communities incrementally as the graph is dynamically changing. We
propose an efficient algorithm, called \textit{randomized Speaker-Listener
Label Propagation Algorithm} (rSLPA), based on the \textit{Speaker-Listener
Label Propagation Algorithm} (SLPA) by relaxing the probability distribution of
label propagation. Besides detecting high-quality communities, rSLPA can
incrementally update the detected communities after a batch of edge insertion
and deletion operations. To the best of our knowledge, rSLPA is the first
algorithm that can incrementally capture the same communities as those obtained
by applying the detection algorithm from the scratch on the updated graph.
Extensive experiments are conducted on both synthetic and real-world datasets,
and the results show that our algorithm can achieve high accuracy and
efficiency at the same time.
</dc:description>
 <dc:description>Comment: A short version of this paper will be published as ICDE'2018 poster</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05948</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uplink Coverage Performance of an Underlay Drone Cell for Temporary
  Events</dc:title>
 <dc:creator>Zhou, Xiaohui</dc:creator>
 <dc:creator>Guo, Jing</dc:creator>
 <dc:creator>Durrani, Salman</dc:creator>
 <dc:creator>Yanikomeroglu, Halim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Using a drone as an aerial base station (ABS) to provide coverage to users on
the ground is envisaged as a promising solution for beyond fifth generation
(beyond-5G) wireless networks. While the literature to date has examined
downlink cellular networks with ABSs, we consider an uplink cellular network
with an ABS. Specifically, we analyze the use of an underlay ABS to provide
coverage for a temporary event, such as a sporting event or a concert in a
stadium. Using stochastic geometry, we derive the analytical expressions for
the uplink coverage probability of the terrestrial base station (TBS) and the
ABS. The results are expressed in terms of (i) the Laplace transforms of the
interference power distribution at the TBS and the ABS and (ii) the distance
distribution between the ABS and an independently and uniformly distributed
(i.u.d.) ABS-supported user equipment and between the ABS and an i.u.d.
TBS-supported user equipment. The accuracy of the analytical results is
verified by Monte Carlo simulations. Our results show that varying the ABS
height leads to a trade-off between the uplink coverage probability of the TBS
and the ABS. In addition, assuming a quality of service of 90% at the TBS, an
uplink coverage probability of the ABS of over 85% can be achieved, with the
ABS deployed at or below its optimal height of typically between 250-500 m for
the considered setup.
</dc:description>
 <dc:description>Comment: This work has been submitted to 2018 IEEE International Conference on
  Communications Workshops (ICC Workshops): Integrating UAVs into 5G</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05950</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Scalable Verification for Safety-Critical Deep Networks</dc:title>
 <dc:creator>Kuper, Lindsey</dc:creator>
 <dc:creator>Katz, Guy</dc:creator>
 <dc:creator>Gottschlich, Justin</dc:creator>
 <dc:creator>Julian, Kyle</dc:creator>
 <dc:creator>Barrett, Clark</dc:creator>
 <dc:creator>Kochenderfer, Mykel</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The increasing use of deep neural networks for safety-critical applications,
such as autonomous driving and flight control, raises concerns about their
safety and reliability. Formal verification can address these concerns by
guaranteeing that a deep learning system operates as intended, but the
state-of-the-art is limited to small systems. In this work-in-progress report
we give an overview of our work on mitigating this difficulty, by pursuing two
complementary directions: devising scalable verification techniques, and
identifying design choices that result in deep learning systems that are more
amenable to verification.
</dc:description>
 <dc:description>Comment: Accepted for presentation at SysML 2018</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05951</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quadratically Constrained Myopic Adversarial Channels</dc:title>
 <dc:creator>Zhang, Yihan</dc:creator>
 <dc:creator>Vatedka, Shashank</dc:creator>
 <dc:creator>Jaggi, Sidharth</dc:creator>
 <dc:creator>Sarwate, Anand</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study communication in the presence of a jamming adversary where quadratic
power constraints are imposed on the transmitter and the jammer. The jamming
signal is assumed to be a function of the codebook, and a noncausal but noisy
observation of the transmitted codeword. For a certain range of the
noise-to-signal ratios (NSRs) of the transmitter and the jammer, we are able to
characterize the capacity of this channel under deterministic encoding. For the
remaining NSR regimes, we determine the capacity under the assumption of a
small amount of common randomness (at most $\mathcal O(\log(n))$ bits in one
sub-regime, and at most $\mathcal O(n^2)$ bits in the other sub-regime)
available to the encoder-decoder pair. Our proof techniques involve a novel
myopic list-decoding result for achievability and a Plotkin-type push attack
for the converse in a subregion of the NSRs, which may be of independent
interest.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05958</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a Generic Security Game Model</dc:title>
 <dc:creator>Shandilya, Vivek</dc:creator>
 <dc:creator>Shiva, Sajjan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  To protect the systems exposed to the Internet against attacks, a security
system with the capability to engage with the attacker is needed. There have
been attempts to model the engagement/interactions between users, both benign
and malicious, and network administrators as games. Building on such works, we
present a game model which is generic enough to capture various modes of such
interactions. The model facilitates stochastic games with imperfect
information. The information is imperfect due to erroneous sensors leading to
incorrect perception of the current state by the players. To model this error
in perception distributed over other multiple states, we use Euclidean
distances between the outputs of the sensors. We build a 5-state game to
represent the interaction of the administrator with the user. The states
correspond to 1) the user being out of the system in the Internet, and after
logging in to the system; 2) having low privileges; 3) having high privileges;
4) when he successfully attacks and 5) gets trapped in a honeypot by the
administrator. Each state has its own action set. We present the game with a
distinct perceived action set corresponding to each distinct information set of
these states. The model facilitates stochastic games with imperfect
information. The imperfect information is due to erroneous sensors leading to
incorrect perception of the current state by the players. To model this error
in perception distributed over the states, we use Euclidean distances between
outputs of the sensors. A numerical simulation of an example game is presented
to show the evaluation of rewards to the players and the preferred strategies.
We also present the conditions for formulating the strategies when dealing with
more than one attacker and making collaborations.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05958</dc:identifier>
 <dc:identifier>Shandilya, V. and Shiva, S. (2017) On a Generic Security Game
  Model. Int. J. Communications , Network and System Sciences , 10, 142-172</dc:identifier>
 <dc:identifier>doi:10.4236/ijcns.2017.107008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05965</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity of Combinations of Qualitative Constraint Satisfaction
  Problems</dc:title>
 <dc:creator>Bodirsky, Manuel</dc:creator>
 <dc:creator>Greiner, Johannes</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>03C35, 03C98, 03D15, 08A70</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  The CSP of a first-order theory $T$ is the problem of deciding for a given
finite set $S$ of atomic formulas whether $T \cup S$ is satisfiable. Let $T_1$
and $T_2$ be two theories with countably infinite models and disjoint
signatures. Nelson and Oppen presented conditions that imply decidability (or
polynomial-time decidability) of $\mathrm{CSP}(T_1 \cup T_2)$ under the
assumption that $\mathrm{CSP}(T_1)$ and $\mathrm{CSP}(T_2)$ are decidable (or
polynomial-time decidable). We show that for a large class of
$\omega$-categorical theories $T_1, T_2$ the Nelson-Oppen conditions are not
only sufficient, but also necessary for polynomial-time tractability of
$\mathrm{CSP}(T_1 \cup T_2)$ (unless P=NP).
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05968</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D CNN-based classification using sMRI and MD-DTI images for Alzheimer
  disease studies</dc:title>
 <dc:creator>Khvostikov, Alexander</dc:creator>
 <dc:creator>Aderghal, Karim</dc:creator>
 <dc:creator>Benois-Pineau, Jenny</dc:creator>
 <dc:creator>Krylov, Andrey</dc:creator>
 <dc:creator>Catheline, Gwenaelle</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68U10</dc:subject>
 <dc:description>  Computer-aided early diagnosis of Alzheimers Disease (AD) and its prodromal
form, Mild Cognitive Impairment (MCI), has been the subject of extensive
research in recent years. Some recent studies have shown promising results in
the AD and MCI determination using structural and functional Magnetic Resonance
Imaging (sMRI, fMRI), Positron Emission Tomography (PET) and Diffusion Tensor
Imaging (DTI) modalities. Furthermore, fusion of imaging modalities in a
supervised machine learning framework has shown promising direction of
research.
  In this paper we first review major trends in automatic classification
methods such as feature extraction based methods as well as deep learning
approaches in medical image analysis applied to the field of Alzheimer's
Disease diagnostics. Then we propose our own algorithm for Alzheimer's Disease
diagnostics based on a convolutional neural network and sMRI and DTI modalities
fusion on hippocampal ROI using data from the Alzheimers Disease Neuroimaging
Initiative (ADNI) database (http://adni.loni.usc.edu). Comparison with a single
modality approach shows promising results. We also propose our own method of
data augmentation for balancing classes of different size and analyze the
impact of the ROI size on the classification results as well.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05972</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WYFIWYG: Investigating Effective User Support in Aerial Videography</dc:title>
 <dc:creator>Gebhardt, Christoph</dc:creator>
 <dc:creator>Hilliges, Otmar</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  Tools for quadrotor trajectory design have enabled single videographers to
create complex aerial video shots that previously required dedicated hardware
and several operators. We build on this prior work by studying film-maker's
working practices which informed a system design that brings expert workflows
closer to end-users. For this purpose, we propose WYFIWYG, a new quadrotor
camera tool which (i) allows to design a video solely via specifying its
frames, (ii) encourages the exploration of the scene prior to filming and (iii)
allows to continuously frame a camera target according to compositional
intentions. Furthermore, we propose extensions to an existing algorithm,
generating more intuitive angular camera motions and producing spatially and
temporally smooth trajectories. Finally, we conduct a user study where we
evaluate how end-users work with current videography tools. We conclude by
summarizing the findings of work as implications for the design of UIs and
algorithms of quadrotor camera tools.
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05974</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-preserving Data Splitting: A Combinatorial Approach</dc:title>
 <dc:creator>Farr&#xe0;s, Oriol</dc:creator>
 <dc:creator>Ribes-Gonz&#xe1;lez, Jordi</dc:creator>
 <dc:creator>Ricci, Sara</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>05C90, 94A99, 68P99, 05C15, 13P25</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  Privacy-preserving data splitting is a technique that aims to protect data
privacy by storing different fragments of data in different locations. In this
work we give a new combinatorial formulation to the data splitting problem. We
see the data splitting problem as a purely combinatorial problem, in which we
have to split data attributes into different fragments in a way that satisfies
certain combinatorial properties derived from processing and privacy
constraints. Using this formulation, we develop new combinatorial and algebraic
techniques to obtain solutions to the data splitting problem. We present an
algebraic method which builds an optimal data splitting solution by using
Gr\&quot;{o}bner bases. Since this method is not efficient in general, we also
develop a greedy algorithm for finding solutions that are not necessarily
minimal sized.
</dc:description>
 <dc:description>Comment: 22 pages, 5 tables, 1 figure</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05984</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of the Optimal Threshold Value in DF Relay Selection Schemes
  Based on Artificial Neural Networks</dc:title>
 <dc:creator>Kara, Ferdi</dc:creator>
 <dc:creator>Kaya, Hakan</dc:creator>
 <dc:creator>Erkaymaz, Okan</dc:creator>
 <dc:creator>Ozturk, Ertan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In wireless communications, the cooperative communication (CC) technology
promises performance gains compared to traditional Single-Input Single Output
(SISO) techniques. Therefore, the CC technique is one of the nominees for 5G
networks. In the Decode-and-Forward (DF) relaying scheme which is one of the CC
techniques, determination of the threshold value at the relay has a key role
for the system performance and power usage. In this paper, we propose
prediction of the optimal threshold values for the best relay selection scheme
in cooperative communications, based on Artificial Neural Networks (ANNs) for
the first time in literature. The average link qualities and number of relays
have been used as inputs in the prediction of optimal threshold values using
Artificial Neural Networks (ANNs): Multi-Layer Perceptron (MLP) and Radial
Basis Function (RBF) networks. The MLP network has better performance from the
RBF network on the prediction of optimal threshold value when the same number
of neurons is used at the hidden layer for both networks. Besides, the optimal
threshold values obtained using ANNs are verified by the optimal threshold
values obtained numerically using the closed form expression derived for the
system. The results show that the optimal threshold values obtained by ANNs on
the best relay selection scheme provide a minimum Bit-Error-Rate (BER) because
of the reduction of the probability that error propagation may occur. Also, for
the same BER performance goal, prediction of optimal threshold values provides
2dB less power usage, which is great gain in terms of green communicationBER
performance goal, prediction of optimal threshold values provides 2dB less
power usage, which is great gain in terms of green communication.
</dc:description>
 <dc:description>Comment: 6 pages,IEEE INnovations in Intelligent SysTems and Applications
  (INISTA), 2016 International Symposium on</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05984</dc:identifier>
 <dc:identifier>doi:10.1109/INISTA.2016.7571823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05989</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Code Constructions for Distributed Storage With Low Repair Bandwidth and
  Low Repair Complexity</dc:title>
 <dc:creator>Kumar, Siddhartha</dc:creator>
 <dc:creator>Amat, Alexandre Graell i</dc:creator>
 <dc:creator>Andriyanova, Iryna</dc:creator>
 <dc:creator>Br&#xe4;nnstr&#xf6;m, Fredrik</dc:creator>
 <dc:creator>Rosnes, Eirik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present the construction of a family of erasure correcting codes for
distributed storage systems that achieve low repair bandwidth and low repair
complexity. The construction is based on two classes of codes, where the
primary goal of the first class of codes is to achieve a good fault tolerance,
while the second class of codes aims at reducing the repair bandwidth and the
repair complexity. The repair procedure is a two-step procedure where parts of
the failed node are repaired in the first step using the first code. The
downloaded symbols during the first step are cached in the memory and used to
repair the remaining erased data symbols at no additional read cost during the
second step of the repair process. The first class of codes is based on maximum
distance separable (MDS) codes modified using piggybacks, while the second
class of codes is designed to reduce the number of additional symbols that need
to be downloaded to repair the remaining erased symbols. We show that the
proposed codes achieve better repair bandwidth compared to MDS, Piggyback, and
local reconstruction codes, while a better repair complexity is achieved when
compared to MDS, Zigzag, and Piggyback codes.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05992</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A universality theorem for allowable sequences with applications</dc:title>
 <dc:creator>Hoffmann, Udo</dc:creator>
 <dc:creator>Merckx, Keno</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Order types are a well known abstraction of combinatorial properties of a
point set. By Mn\&quot;ev's universality theorem for each semi-algebraic set $V$
there is an order type with a realization space that is \emph{stably
equivalent} to $V$. We consider realization spaces of \emph{allowable
sequences}, a refinement of order types. We show that the realization spaces of
allowable sequences are \emph{universal} and consequently deciding the
realizability is complete in the \emph{existential theory of the reals} (\ER).
This result holds even if the realization space of the order type induced by
the allowable sequence is non-empty. Furthermore, we argue that our result is a
useful tool for further geometric reductions. We support this by giving
\ER-hardness proofs for the realizability of abstract convex geometries and for
the recognition problem of visibility graphs of polygons with holes using the
hardness result for allowable sequences. This solves two longstanding open
problems.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05994</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some model theory for the modal $\mu$-calculus: syntactic
  characterisations of semantic properties</dc:title>
 <dc:creator>Fontaine, Ga&#xeb;lle</dc:creator>
 <dc:creator>Venema, Yde</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This paper contributes to the theory of the modal $\mu$-calculus by proving
some model-theoretic results. More in particular, we discuss a number of
semantic properties pertaining to formulas of the modal $\mu$-calculus. For
each of these properties we provide a corresponding syntactic fragment,in the
sense that a $\mu$-formula $\xi$ has the given property iff it is equivalent to
a formula $\xi'$ in the corresponding fragment. Since this formula $\xi'$ will
always be effectively obtainable from $\xi$, as a corollary, for each of the
properties under discussion, we prove that it is decidable in elementary time
whether a given $\mu$-calculus formula has the property or not.
  The properties that we study all concern the way in which the meaning of a
formula $\xi$ in a model depends on the meaning of a single, fixed proposition
letter $p$. For example, consider a formula $\xi$ which is monotone in $p$;
such a formula a formula $\xi$ is called continuous (respectively, fully
additive), if in addition it satisfies the property that, if $\xi$ is true at a
state $s$ then there is a finite set (respectively, a singleton set) $U$ such
that $\xi$ remains true at $s$ if we restrict the interpretation of $p$ to the
set $U$. Each of the properties that we consider is, in a similar way,
associated with one of the following special kinds of subset of a tree model:
singletons, finite sets, finitely branching subtrees, noetherian subtrees
(i.e., without infinite paths), and branches.
  Our proofs for these characterization results will be automata-theoretic in
nature; we will see that the effectively defined maps on formulas are in fact
induced by rather simple transformations on modal automata. Thus our results
can also be seen as a contribution to the model theory of modal automata.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05997</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-Chip CNN Accelerator for Image Super-Resolution</dc:title>
 <dc:creator>Chang, Jung-Woo</dc:creator>
 <dc:creator>Kang, Suk-Ju</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>68U10</dc:subject>
 <dc:description>  To implement convolutional neural networks (CNN) in hardware, the
state-of-the-art CNN accelerators pipeline computation and data transfer stages
using an off-chip memory and simultaneously execute them on the same timeline.
However, since a large amount of feature maps generated during the operation
should be transmitted to the off-chip memory, the pipeline stage length is
determined by the off-chip data transfer stage. Fusion architectures that can
fuse multiple layers have been proposed to solve this problem, but applications
such as super-resolution (SR) require a large amount of an on-chip memory
because of the high resolution of the feature maps. In this paper, we propose a
novel on-chip CNN accelerator for SR to optimize the CNN dataflow in the
on-chip memory. First, the convolution loop optimization technique is proposed
to prevent using a frame buffer. Second, we develop a combined convolutional
layer processor to reduce the buffer size used to store the feature maps.
Third, we explore how to perform low-cost multiply-and-accumulate operations in
the deconvolutional layer used in SR. Finally, we propose a two-stage
quantization algorithm to select the optimized hardware size for the limited
number of DSPs to implement the on-chip CNN accelerator. We evaluate our
proposed accelerator with FSRCNN, which is most popular as the CNN-based SR
algorithm. Experimental results show that the proposed accelerator requires
9.21ms to achieve an output image with the 2560x1440 pixel resolution, which is
36 times faster than the conventional method. In addition, we reduce the
on-chip memory usage and DSP usage by 4 times and 1.44 times, respectively,
compared to the conventional methods.
</dc:description>
 <dc:description>Comment: 7 pages, submitted to a conference for review</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.05997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06007</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Layered TPOT: Speeding up Tree-based Pipeline Optimization</dc:title>
 <dc:creator>Gijsbers, Pieter</dc:creator>
 <dc:creator>Vanschoren, Joaquin</dc:creator>
 <dc:creator>Olson, Randal S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  With the demand for machine learning increasing, so does the demand for tools
which make it easier to use. Automated machine learning (AutoML) tools have
been developed to address this need, such as the Tree-Based Pipeline
Optimization Tool (TPOT) which uses genetic programming to build optimal
pipelines. We introduce Layered TPOT, a modification to TPOT which aims to
create pipelines equally good as the original, but in significantly less time.
This approach evaluates candidate pipelines on increasingly large subsets of
the data according to their fitness, using a modified evolutionary algorithm to
allow for separate competition between pipelines trained on different sample
sizes. Empirical evaluation shows that, on sufficiently large datasets, Layered
TPOT indeed finds better models faster.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06011</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forecasting User Attention During Everyday Mobile Interactions Using
  Device-Integrated and Wearable Sensors</dc:title>
 <dc:creator>Steil, Julian</dc:creator>
 <dc:creator>M&#xfc;ller, Philipp</dc:creator>
 <dc:creator>Sugano, Yusuke</dc:creator>
 <dc:creator>Bulling, Andreas</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Users' visual attention is highly fragmented during mobile interactions but
the erratic nature of these attention shifts currently limits attentive user
interfaces to adapt after the fact, i.e. after shifts have already happened,
thereby severely limiting the adaptation capabilities and user experience. To
address these limitations, we study attention forecasting -- the challenging
task of predicting whether users' overt visual attention (gaze) will shift
between a mobile device and environment in the near future or how long users'
attention will stay in a given location. To facilitate the development and
evaluation of methods for attention forecasting, we present a novel long-term
dataset of everyday mobile phone interactions, continuously recorded from 20
participants engaged in common activities on a university campus over 4.5 hours
each (more than 90 hours in total). As a first step towards a fully-fledged
attention forecasting interface, we further propose a proof-of-concept method
that uses device-integrated sensors and body-worn cameras to encode rich
information on device usage and users' visual scene. We demonstrate the
feasibility of forecasting bidirectional attention shifts between the device
and the environment as well as for predicting the first and total attention
span on the device and environment using our method. We further study the
impact of different sensors and feature sets on performance and discuss the
significant potential but also remaining challenges of forecasting user
attention during mobile interactions.
</dc:description>
 <dc:description>Comment: 24 pages, 12 figures</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06014</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Enhancement and Noise Reduction Using Modified
  Delay-Multiply-and-Sum Beamformer: Application to Medical Photoacoustic
  Imaging</dc:title>
 <dc:creator>Mozaffarzadeh, Moein</dc:creator>
 <dc:creator>Mahloojifar, Ali</dc:creator>
 <dc:creator>Orooji, Mahdi</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Photoacoustic imaging (PAI) is an emerging biomedical imaging modality
capable of providing both high contrast and high resolution of optical and
UltraSound (US) imaging. When a short duration laser pulse illuminates the
tissue as a target of imaging, tissue induces US waves and detected waves can
be used to reconstruct optical absorption distribution. Since receiving part of
PA consists of US waves, a large number of beamforming algorithms in US imaging
can be applied on PA imaging. Delay-and-Sum (DAS) is the most common
beamforming algorithm in US imaging. However, make use of DAS beamformer leads
to low resolution images and large scale of off-axis signals contribution. To
address these problems a new paradigm namely Delay-Multiply-and-Sum (DMAS),
which was used as a reconstruction algorithm in confocal microwave imaging for
breast cancer detection, was introduced for US imaging. Consequently, DMAS was
used in PA imaging systems and it was shown this algorithm results in
resolution enhancement and sidelobe degrading. However, in presence of high
level of noise the reconstructed image still suffers from high contribution of
noise. In this paper, a modified version of DMAS beamforming algorithm is
proposed based on DAS inside DMAS formula expansion. The quantitative and
qualitative results show that proposed method results in more noise reduction
and resolution enhancement in expense of contrast degrading. For the
simulation, two-point target, along with lateral variation in two depths of
imaging are employed and it is evaluated under high level of noise in imaging
medium. Proposed algorithm in compare to DMAS, results in reduction of lateral
valley for about 19 dB followed by more distinguished two-point target.
Moreover, levels of sidelobe are reduced for about 25 dB.
</dc:description>
 <dc:description>Comment: This paper was accepted and presented at Iranian Conference on
  Electrical Engineering (ICEE) 2017</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06014</dc:identifier>
 <dc:identifier>Iranian Conference on Electrical Engineering, 2-4 May 2017</dc:identifier>
 <dc:identifier>doi:10.1109/IranianCEE.2017.7985131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06018</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Slotted Scheduling Schemes for Multi-hop Concurrent Transmission in
  WPANs with Directional Antenna</dc:title>
 <dc:creator>Bilal, Muhammad</dc:creator>
 <dc:creator>Kang, Moonsoo</dc:creator>
 <dc:creator>Shah, Sayed Chhattan</dc:creator>
 <dc:creator>Kang, Shin-Gak</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>68M10, 68M12, 68M20</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:subject>C.2.5</dc:subject>
 <dc:subject>D.4.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  To achieve high-speed (giga-bit) connectivity for short-range wireless
multimedia applications, the millimeter-wave (mmWave) wireless personal area
networks with directional antennas are gaining increased interest. Due to the
use of directional antennas and mmWave communications, the probability of
non-interfering transmissions increases in a localized region. Network
throughput can be increased immensely by the concurrent time allocation of
non-interfering transmissions. The problem of finding optimum time allocation
for concurrent transmissions is an NP-hard problem. In this paper, we propose
two enhanced versions of previously proposed multi-hop concurrent transmission
(MHCT) schemes. To increase network capacity, the proposed schemes efficiently
make use of the free holes in the time-allocation map of the MHCT scheme; thus,
making it more compact.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures, published in ETRI Journal, Volume 36, Number 3,
  pp. 374-384, June 2014</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06018</dc:identifier>
 <dc:identifier>ETRI Journal, vol. 36, no. 3, pp. 374-384, 2014</dc:identifier>
 <dc:identifier>doi:10.4218/etrij.14.0113.0703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06022</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconstruction Codes for DNA Sequences with Uniform Tandem-Duplication
  Errors</dc:title>
 <dc:creator>Yehezkeally, Yonatan</dc:creator>
 <dc:creator>Schwartz, Moshe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  DNA as a data storage medium has several advantages, including far greater
data density compared to electronic media. We propose that schemes for data
storage in the DNA of living organisms may benefit from studying the
reconstruction problem, which is applicable whenever multiple reads of noisy
data are available. This strategy is uniquely suited to the medium, which
inherently replicates stored data in multiple distinct ways, caused by
mutations. We consider noise introduced solely by uniform tandem-duplication,
and utilize the relation to constant-weight integer codes in the Manhattan
metric. By bounding the intersection of the cross-polytope with hyperplanes, we
prove the existence of reconstruction codes with greater capacity than known
error-correcting codes, which we can determine analytically for any set of
parameters.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06024</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural Language Multitasking: Analyzing and Improving Syntactic
  Saliency of Hidden Representations</dc:title>
 <dc:creator>Brunner, Gino</dc:creator>
 <dc:creator>Wang, Yuyi</dc:creator>
 <dc:creator>Wattenhofer, Roger</dc:creator>
 <dc:creator>Weigelt, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We train multi-task autoencoders on linguistic tasks and analyze the learned
hidden sentence representations. The representations change significantly when
translation and part-of-speech decoders are added. The more decoders a model
employs, the better it clusters sentences according to their syntactic
similarity, as the representation space becomes less entangled. We explore the
structure of the representation space by interpolating between sentences, which
yields interesting pseudo-English sentences, many of which have recognizable
syntactic structure. Lastly, we point out an interesting property of our
models: The difference-vector between two sentences can be added to change a
third sentence with similar features in a meaningful way.
</dc:description>
 <dc:description>Comment: The 31st Annual Conference on Neural Information Processing (NIPS) -
  Workshop on Learning Disentangled Features: from Perception to Control, Long
  Beach, CA, December 2017</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06027</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In-RDBMS Hardware Acceleration of Advanced Analytics</dc:title>
 <dc:creator>Mahajan, Divya</dc:creator>
 <dc:creator>Kim, Joon Kyung</dc:creator>
 <dc:creator>Sacks, Jacob</dc:creator>
 <dc:creator>Ardalan, Adel</dc:creator>
 <dc:creator>Kumar, Arun</dc:creator>
 <dc:creator>Esmaeilzadeh, Hadi</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The data revolution is fueled by advances in several areas, including
databases, high-performance computer architecture, and machine learning.
Although timely, there is a void of solutions that brings these disjoint
directions together. This paper sets out to be the initial step towards such a
union. The aim is to devise a solution for the in-Database Acceleration of
Advanced Analytics (DAnA). DAnA empowers database users to leap beyond
traditional data summarization techniques and seamlessly utilize
hardware-accelerated machine learning. Deploying specialized hardware, such as
FPGAs, for in-database analytics currently requires hand-designing the hardware
and manually routing the data. Instead, DAnA automatically maps a high-level
specification of in-database analytics queries to the FPGA accelerator. The
accelerator implementation is generated from a User Defined Function (UDF),
expressed as part of a SQL query in a Python-embedded Domain Specific Language
(DSL). To realize efficient in-database integration, DAnA accelerators contain
a novel hardware structure, Striders, that directly interface with the buffer
pool of the database. DAnA obtains the schema and page layout information from
the database catalog to configure the Striders. In turn, Striders extract,
cleanse, and process the training data tuples, which are consumed by a
multi-threaded FPGA engine that executes the analytics algorithm. We integrated
DAnA with PostgreSQL to generate hardware accelerators for a range of
real-world and synthetic datasets running diverse ML algorithms. Results show
that DAnA-enhanced PostgreSQL provides, on average, 11.3x end-to-end speedup
than MADLib and 5.4x faster than multi-threaded MADLib running on Greenplum.
DAnA provides these benefits while hiding the complexity of hardware design
from data scientists and allowing them to express the algorithm in 30-60 lines
of Python.
</dc:description>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06029</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>rcss: Subgradient and duality approach for dynamic programming</dc:title>
 <dc:creator>Hinz, Juri</dc:creator>
 <dc:creator>Yee, Jeremy</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  This short paper gives an introduction to the \emph{rcss} package. The R
package \emph{rcss} provides users with a tool to approximate the value
functions in the Bellman recursion using convex piecewise linear functions
formed using operations on tangents. A pathwise method is then used to gauge
the quality of the numerical results.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06030</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-measures fusion based on multi-objective genetic programming for
  full-reference image quality assessment</dc:title>
 <dc:creator>Merzougui, Naima</dc:creator>
 <dc:creator>Merzougui, Naima</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In this paper, we exploit the flexibility of multi-objective fitness
functions, and the efficiency of the model structure selection ability of a
standard genetic programming (GP) with the parameter estimation power of
classical regression via multi-gene genetic programming (MGGP), to propose a
new fusion technique for image quality assessment (IQA) that is called
Multi-measures Fusion based on Multi-Objective Genetic Programming (MFMOGP).
This technique can automatically select the most significant suitable measures,
from 16 full-reference IQA measures, used in aggregation and finds weights in a
weighted sum of their outputs while simultaneously optimizing for both accuracy
and complexity. The obtained well-performing fusion of IQA measures are
evaluated on four largest publicly available image databases and compared
against state-of-the-art full-reference IQA approaches. Results of comparison
reveal that the proposed approach outperforms other state-of-the-art recently
developed fusion approaches.
</dc:description>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06041</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained locating arrays for combinatorial interaction testing</dc:title>
 <dc:creator>Jin, Hao</dc:creator>
 <dc:creator>Tsuchiya, Tatsuhiro</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>94C12, 05B30, 68R05</dc:subject>
 <dc:description>  This paper introduces the notion of Constrained Locating Arrays (CLAs),
mathematical objects which can be used for fault localization in a testing
process for information systems. CLAs extend ordinary locating arrays to make
them applicable to testing of systems that have constraints on test parameters.
Such constraints are common in real-world systems; thus CLA enhances the
applicability of locating arrays to practical testing problems.
</dc:description>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06043</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Weighting for Exam Composition</dc:title>
 <dc:creator>Ganzfried, Sam</dc:creator>
 <dc:creator>Yusuf, Farzana</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A problem faced by many instructors is that of designing exams that
accurately assess the abilities of the students. Typically these exams are
prepared several days in advance, and generic question scores are used based on
rough approximation of the question difficulty and length. For example, for a
recent class taught by the author, there were 30 multiple choice questions
worth 3 points, 15 true/false with explanation questions worth 4 points, and 5
analytical exercises worth 10 points. We describe a novel framework where
algorithms from machine learning are used to modify the exam question weights
in order to optimize the exam scores, using the overall class grade as a proxy
for a student's true ability. We show that significant error reduction can be
obtained by our approach over standard weighting schemes, and we make several
new observations regarding the properties of the &quot;good&quot; and &quot;bad&quot; exam
questions that can have impact on the design of improved future evaluation
methods.
</dc:description>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06044</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of the Relation between Artificial Intelligence and the
  Internet from the Perspective of Brain Science</dc:title>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Shi, Yong</dc:creator>
 <dc:creator>Lia, Peijia</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Artificial intelligence (AI) like deep learning, cloud AI computation has
been advancing at a rapid pace since 2014. There is no doubt that the
prosperity of AI is inseparable with the development of the Internet. However,
there has been little attention to the link between AI and the internet. This
paper explores them with brain insights mainly from four views:1) How is the
general relation between artificial intelligence and Internet of Things, cloud
computing, big data and Industrial Internet from the perspective of brain
science. 2) Construction of a new AI system model with the Internet and brain
science.
</dc:description>
 <dc:description>Comment: 6 pages,3 figures</dc:description>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06044</dc:identifier>
 <dc:identifier>doi:10.1016/j.procs.2017.11.383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06047</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Engagement in Foundational Computer Science Courses Through
  Supplementary Content for Algorithms</dc:title>
 <dc:creator>Birster, Christopher A.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Engaging students in teaching foundational Computer Science concepts is vital
for the student's continual success in more advanced topics in the field. An
idea of a series of Jupyter notebooks was conceived as a way of using Bloom's
Taxonomy to reinforce concepts taught in an introductory algorithms class. The
idea of the notebook is to keep the student's engaged in the lesson and in turn
motivate them to persevere through the end of the course.
</dc:description>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06048</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Fatigue Estimation on the Basis of Multimodal
  Human-Machine Interactions</dc:title>
 <dc:creator>Gordienko, Yuri</dc:creator>
 <dc:creator>Stirenko, Sergii</dc:creator>
 <dc:creator>Kochura, Yuriy</dc:creator>
 <dc:creator>Alienin, Oleg</dc:creator>
 <dc:creator>Novotarskiy, Michail</dc:creator>
 <dc:creator>Gordienko, Nikita</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The new method is proposed to monitor the level of current physical load and
accumulated fatigue by several objective and subjective characteristics. It was
applied to the dataset targeted to estimate the physical load and fatigue by
several statistical and machine learning methods. The data from peripheral
sensors (accelerometer, GPS, gyroscope, magnetometer) and brain-computing
interface (electroencephalography) were collected, integrated, and analyzed by
several statistical and machine learning methods (moment analysis, cluster
analysis, principal component analysis, etc.). The hypothesis 1 was presented
and proved that physical activity can be classified not only by objective
parameters, but by subjective parameters also. The hypothesis 2 (experienced
physical load and subsequent restoration as fatigue level can be estimated
quantitatively and distinctive patterns can be recognized) was presented and
some ways to prove it were demonstrated. Several &quot;physical load&quot; and &quot;fatigue&quot;
metrics were proposed. The results presented allow to extend application of the
machine learning methods for characterization of complex human activity
patterns (for example, to estimate their actual physical load and fatigue, and
give cautions and advice).
</dc:description>
 <dc:description>Comment: 12 pages, 10 figures, 1 table; presented at XXIX IUPAP Conference in
  Computational Physics (CCP2017) July 9-13, 2017, Paris, University Pierre et
  Marie Curie - Sorbonne (https://ccp2017.sciencesconf.org/program)</dc:description>
 <dc:date>2017-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06049</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effects of Home Resources and School Environment on Eighth-Grade
  Mathematics Achievement in Taiwan</dc:title>
 <dc:creator>Cai, Jiaqi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics Education</dc:subject>
 <dc:description>  Over the past decades, researchers have explored the relationship among home
resources, school environment, and students' mathematics achievement in a large
amount of studies. Many of them suggested that rich home resources for learning
were related to higher average academic achievement. Some also suggested that
the home background was closely associated with the learning environment, and
therefore, influenced students' achievements. Thus, this study hypothesized
that students who own more home resources would perform better than students
who possess fewer resources and that schools that have more socioeconomically
advantaged students, located in high-income neighborhoods, and possess more
instructional resources would have better mathematics performance. The study
focuses on eighth graders in Taiwan and explores the variance in mathematics
achievement of students as a function of student and school level differences.
</dc:description>
 <dc:date>2017-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06050</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A taxonomy of video lecture styles</dc:title>
 <dc:creator>Chorianopoulos, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Many educational organizations are employing instructional video in their
pedagogy, but there is limited understanding of the possible presentation
styles. In practice, the presentation style of video lectures ranges from a
direct recording of classroom teaching with a stationary camera and screencasts
with voice-over, up to highly elaborate video post-production. Previous work
evaluated the effectiveness of several presentation styles, but there has not
been any consistent taxonomy, which would have made comparisons and
meta-analyses possible. In this article, we surveyed the research literature
and we examined contemporary video-based courses, which have been produced by
diverse educational organizations and teachers across various academic
disciplines. We organized video lectures in two dimensions according to the
level of human presence and according to the type of instructional media. In
addition to organizing existing video lectures in a comprehensive way, the
proposed taxonomy offers a design space that facilitates the choice of a
suitable presentation style, as well as the preparation of new ones.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures</dc:description>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06052</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Big Data and Learning Analytics in Higher Education: Demystifying
  Variety, Acquisition, Storage, NLP and Analytics</dc:title>
 <dc:creator>Alblawi, Amal S.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Different sectors have sought to take advantage of opportunities to invest in
big data analytics and Natural language processing, in order to improve their
productivity and competitiveness. Current challenges facing the higher
education sector include a rapidly changing and evolving environment, which
necessitates the development of new ways of thinking. Interest has therefore
increased in analytics as part of the solution to many issues in higher
education, including the rate of student attrition and learner support. This
study provides a comprehensive discussion of big data, learning analytics and
use of NLP in higher education. In addition, it introduces an integrated
learning analytics solution leveraging a distributed technology system capable
of supporting academic authorities and advisors at educational institutions in
making decisions concerning individual students.
</dc:description>
 <dc:description>Comment: 6 pages , 2017 IEEE Conference on Big Data and Analytics (ICBDA)</dc:description>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06053</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lab Based Curriculum for CIS and Related Technology</dc:title>
 <dc:creator>Movafaghi, Shahriar</dc:creator>
 <dc:creator>Pournaghshband, Hassan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The Computer Information System (CIS) is information and communication
technology in support of business processes. In this paper, we present a
typical undergraduate computer information system curriculum examining the
degree of lab intensity and its effect on the course efficacy. A CIS program is
usually part of the school of business as it is in support of business
processes. We also explore the differences between a CIS curriculum and other
computer related technology courses, such as Information Technology (IT),
Computer Science (CS), and Software Engineering (SE). The curriculum is
composed of several elements such as content and sequence of subjects,
classrooms equipped with computer projection, internet, and local network
access, and appropriate computing and software infrastructure. We will focus on
the importance and adequacy of labs for the CIS curriculum. The proposed CIS
curriculum works for a 4-year as well as a 3-year program. This paper provides
a recommendation for local and Federal Accreditation agencies and curriculum
committees.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06055</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Low Rapport During Natural Interactions in Small Groups from
  Non-Verbal Behaviour</dc:title>
 <dc:creator>M&#xfc;ller, Philipp</dc:creator>
 <dc:creator>Huang, Michael Xuelin</dc:creator>
 <dc:creator>Bulling, Andreas</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.5.m</dc:subject>
 <dc:description>  Rapport, the close and harmonious relationship in which interaction partners
are &quot;in sync&quot; with each other, was shown to result in smoother social
interactions, improved collaboration, and improved interpersonal outcomes. In
this work, we are first to investigate automatic prediction of low rapport
during natural interactions within small groups. This task is challenging given
that rapport only manifests in subtle non-verbal signals that are, in addition,
subject to influences of group dynamics as well as inter-personal
idiosyncrasies. We record videos of unscripted discussions of three to four
people using a multi-view camera system and microphones. We analyse a rich set
of non-verbal signals for rapport detection, namely facial expressions, hand
motion, gaze, speaker turns, and speech prosody. Using facial features, we can
detect low rapport with an average precision of 0.7 (chance level at 0.25),
while incorporating prior knowledge of participants' personalities can even
achieve early prediction without a drop in performance. We further provide a
detailed analysis of different feature sets and the amount of information
contained in different temporal segments of the interactions.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures</dc:description>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06055</dc:identifier>
 <dc:identifier>doi:10.1145/3172944.3172969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06059</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tamil Open-Source Landscape - Opportunities and Challenges</dc:title>
 <dc:creator>Annamalai, Muthiah</dc:creator>
 <dc:creator>Shrinivasan, T</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We report in this paper, Tamil open-source software community is a vibrant
place with software developers, font designers, translators, voice-over
artists, and general user testers, who come together for love of their
language, and promotion of critical thinking, and modern language usage in
Tamil. We identify a need for institutional support at various stages from
grooming software developers in Tamil, to marketing platform for Tamil
software. There is bright future for tamil software if we will meet challenges
it brings with it.
</dc:description>
 <dc:description>Comment: Tamil Internet Conference (INFITT) 2017, Toronto, Canada</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06066</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RED-Net: A Recurrent Encoder-Decoder Network for Video-based Face
  Alignment</dc:title>
 <dc:creator>Peng, Xi</dc:creator>
 <dc:creator>Feris, Rogerio S.</dc:creator>
 <dc:creator>Wang, Xiaoyu</dc:creator>
 <dc:creator>Metaxas, Dimitris N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel method for real-time face alignment in videos based on a
recurrent encoder-decoder network model. Our proposed model predicts 2D facial
point heat maps regularized by both detection and regression loss, while
uniquely exploiting recurrent learning at both spatial and temporal dimensions.
At the spatial level, we add a feedback loop connection between the combined
output response map and the input, in order to enable iterative coarse-to-fine
face alignment using a single network model, instead of relying on traditional
cascaded model ensembles. At the temporal level, we first decouple the features
in the bottleneck of the network into temporal-variant factors, such as pose
and expression, and temporal-invariant factors, such as identity information.
Temporal recurrent learning is then applied to the decoupled temporal-variant
features. We show that such feature disentangling yields better generalization
and significantly more accurate results at test time. We perform a
comprehensive experimental analysis, showing the importance of each component
of our proposed model, as well as superior results over the state of the art
and several variations of our method in standard datasets.
</dc:description>
 <dc:description>Comment: International Journal of Computer Vision. arXiv admin note: text
  overlap with arXiv:1608.05477</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06070</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Early Output Asynchronous Adders Based on Dual-Rail Data
  Encoding and 4-Phase Return-to-Zero and Return-to-One Handshaking</dc:title>
 <dc:creator>Balasubramanian, P</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Approximate computing is emerging as an alternative to accurate computing due
to its potential for realizing digital circuits and systems with low power
dissipation, less critical path delay, and less area occupancy for an
acceptable trade-off in the accuracy of results. In the domain of computer
arithmetic, several approximate adders and multipliers have been designed and
their potential have been showcased versus accurate adders and multipliers for
practical digital signal processing applications. Nevertheless, in the existing
literature, almost all the approximate adders and multipliers reported
correspond to the synchronous design method. In this work, we consider robust
asynchronous i.e. quasi-delay-insensitive realizations of approximate adders by
employing delay-insensitive codes for data representation and processing, and
the 4-phase handshake protocols for data communication. The 4-phase handshake
protocols used are the return-to-zero and the return-to-one protocols.
Specifically, we consider the implementations of 32-bit approximate adders
based on the return-to-zero and return-to-one handshake protocols by adopting
the delay-insensitive dual-rail code for data encoding. We consider a range of
approximations varying from 4-bits to 20-bits for the least significant
positions of the accurate 32-bit asynchronous adder. The asynchronous adders
correspond to early output (i.e. early reset) type, which are based on the
well-known ripple carry adder architecture. The experimental results show that
approximate asynchronous adders achieve reductions in the design metrics such
as latency, cycle time, average power dissipation, and silicon area compared to
the accurate asynchronous adders. Further, the reductions in the design metrics
are greater for the return-to-one protocol compared to the return-to-zero
protocol. The design metrics were estimated using a 32/28nm CMOS technology.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1711.02333</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06070</dc:identifier>
 <dc:identifier>Intl. Jour. of Ckts., Sys. and Signal Processing, vol. 11, pp.
  445-453, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06077</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The QLBS Q-Learner Goes NuQLear: Fitted Q Iteration, Inverse RL, and
  Option Portfolios</dc:title>
 <dc:creator>Halperin, Igor</dc:creator>
 <dc:subject>Quantitative Finance - Computational Finance</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The QLBS model is a discrete-time option hedging and pricing model that is
based on Dynamic Programming (DP) and Reinforcement Learning (RL). It combines
the famous Q-Learning method for RL with the Black-Scholes (-Merton) model's
idea of reducing the problem of option pricing and hedging to the problem of
optimal rebalancing of a dynamic replicating portfolio for the option, which is
made of a stock and cash. Here we expand on several NuQLear (Numerical
Q-Learning) topics with the QLBS model. First, we investigate the performance
of Fitted Q Iteration for a RL (data-driven) solution to the model, and
benchmark it versus a DP (model-based) solution, as well as versus the BSM
model. Second, we develop an Inverse Reinforcement Learning (IRL) setting for
the model, where we only observe prices and actions (re-hedges) taken by a
trader, but not rewards. Third, we outline how the QLBS model can be used for
pricing portfolios of options, rather than a single option in isolation, thus
providing its own, data-driven and model independent solution to the (in)famous
volatility smile problem of the Black-Scholes model.
</dc:description>
 <dc:description>Comment: 18 pages, 5 figures</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06082</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Stronger Robustness of Network Controllability: A Snapback
  Network Model</dc:title>
 <dc:creator>Lou, Yang</dc:creator>
 <dc:creator>Wang, Lin</dc:creator>
 <dc:creator>Chen, Guanrong</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A new complex network model, called q-snapback network, is introduced. Basic
topological characteristics of the network, such as degree distribution,
average path length, clustering coefficient and Pearson correlation
coefficient, are evaluated. The typical 4-motifs of the network are simulated.
The robustness of both state and structural controllabilities of the network
against targeted and random node- and edge-removal attacks, with comparisons to
the multiplex congruence network and the generic scale-free network, are
presented. It is shown that the q-snapback network has the strongest robustness
of controllabilities due to its advantageous inherent structure with many
chain- and loop-motifs.
</dc:description>
 <dc:description>Comment: 15 pages, 11 figures</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06104</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invariants of multidimensional time series based on their
  iterated-integral signature</dc:title>
 <dc:creator>Diehl, Joscha</dc:creator>
 <dc:creator>Reizenstein, Jeremy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:description>  We introduce a novel class of features for multidimensional time series, that
are invariant with respect to transformations of the ambient space. The general
linear group, the group of rotations and the group of permutations of the axes
are considered. The starting point for their construction is Chen's
iterated-integral signature.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06105</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overcoming the vanishing gradient problem in plain recurrent networks</dc:title>
 <dc:creator>Hu, Yuhuang</dc:creator>
 <dc:creator>Huber, Adrian</dc:creator>
 <dc:creator>Anumula, Jithendar</dc:creator>
 <dc:creator>Liu, Shih-Chii</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Plain recurrent networks greatly suffer from the vanishing gradient problem
while Gated Neural Networks (GNNs) such as Long-short Term Memory (LSTM) and
Gated Recurrent Unit (GRU) deliver promising results in many sequence learning
tasks through sophisticated network designs. This paper shows how we can
address this problem in a plain recurrent network by analyzing the gating
mechanisms in GNNs. We propose a novel network called the Recurrent Identity
Network (RIN) which allows a plain recurrent network to overcome the vanishing
gradient problem while training very deep models without the use of gates. We
compare this model with IRNNs and LSTMs on multiple sequence modeling
benchmarks. The RINs demonstrate competitive performance and converge faster in
all tasks. Notably, small RIN models produce 12%--67% higher accuracy on the
Sequential and Permuted MNIST datasets and reach state-of-the-art performance
on the bAbI question answering dataset.
</dc:description>
 <dc:description>Comment: 20 pages, 12 figures</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06107</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges of the Dynamic Detection of Functionally Similar Code
  Fragments</dc:title>
 <dc:creator>Deissenboeck, Florian</dc:creator>
 <dc:creator>Heinemann, Lars</dc:creator>
 <dc:creator>Hummel, Benjamin</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Classic clone detection approaches are hardly capable of finding redundant
code that has been developed independently, i.e., is not the result of
copy&amp;paste. To automatically detect such functionally similar code of
independent origin, we experimented with a dynamic detection approach that
applies random testing to selected chunks of code similar to Jiang&amp;Su's
approach. We found that such an approach faces several limitations in its
application to diverse Java systems. This paper details on our insights
regarding these challenges of dynamic detection of functionally similar code
fragments. Our findings support a substantiated discussion on detection
approaches and serve as a starting point for future research.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06107</dc:identifier>
 <dc:identifier>Proceedings of the 16th European Conference on Software
  Maintenance and Reengineering (CSMR), IEEE, 2012</dc:identifier>
 <dc:identifier>doi:10.1109/CSMR.2012.38</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06122</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anatomy of an online misinformation network</dc:title>
 <dc:creator>Shao, Chengcheng</dc:creator>
 <dc:creator>Hui, Pik-Mai</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Jiang, Xinwen</dc:creator>
 <dc:creator>Flammini, Alessandro</dc:creator>
 <dc:creator>Menczer, Filippo</dc:creator>
 <dc:creator>Ciampaglia, Giovanni Luca</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Massive amounts of fake news and conspiratorial content have spread over
social media before and after the 2016 US Presidential Elections despite
intense fact-checking efforts. How do the spread of misinformation and
fact-checking compete? What are the structural and dynamic characteristics of
the core of the misinformation diffusion network, and who are its main
purveyors? How to reduce the overall amount of misinformation? To explore these
questions we built Hoaxy, an open platform that enables large-scale, systematic
studies of how misinformation and fact-checking spread and compete on Twitter.
Hoaxy filters public tweets that include links to unverified claims or
fact-checking articles. We perform k-core decomposition on a diffusion network
obtained from two million retweets produced by several hundred thousand
accounts over the six months before the election. As we move from the periphery
to the core of the network, fact-checking nearly disappears, while social bots
proliferate. The number of users in the main core reaches equilibrium around
the time of the election, with limited churn and increasingly dense
connections. We conclude by quantifying how effectively the network can be
disrupted by penalizing the most central nodes. These findings provide a first
look at the anatomy of a massive online misinformation diffusion network.
</dc:description>
 <dc:description>Comment: 28 pages, 11 figures, submitted to PLOS ONE</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06126</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Iterative Closest Point Method for Unsupervised Word Translation</dc:title>
 <dc:creator>Hoshen, Yedid</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Unsupervised word translation from non-parallel inter-lingual corpora has
attracted much research interest. Very recently, neural network methods trained
with adversarial loss functions achieved high accuracy on this task. Despite
the impressive success of the recent techniques, they suffer from the typical
drawbacks of generative adversarial models: sensitivity to hyper-parameters,
long training time and lack of interpretability. In this paper, we make the
observation that two sufficiently similar distributions can be aligned
correctly with iterative matching methods. We present a novel method that first
aligns the second moment of the word distributions of the two languages and
then iteratively refines the alignment. Our simple linear method is able to
achieve better or equal performance to recent state-of-the-art deep adversarial
approaches and typically does a little better than the supervised baseline. Our
method is also efficient, easy to parallelize and interpretable.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06136</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latitude: A Model for Mixed Linear-Tropical Matrix Factorization</dc:title>
 <dc:creator>Karaev, Sanjar</dc:creator>
 <dc:creator>Hook, James</dc:creator>
 <dc:creator>Miettinen, Pauli</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Nonnegative matrix factorization (NMF) is one of the most frequently-used
matrix factorization models in data analysis. A significant reason to the
popularity of NMF is its interpretability and the `parts of whole'
interpretation of its components. Recently, max-times, or subtropical, matrix
factorization (SMF) has been introduced as an alternative model with equally
interpretable `winner takes it all' interpretation. In this paper we propose a
new mixed linear--tropical model, and a new algorithm, called Latitude, that
combines NMF and SMF, being able to smoothly alternate between the two. In our
model, the data is modeled using the latent factors and latent parameters that
control whether the factors are interpreted as NMF or SMF features, or their
mixtures. We present an algorithm for our novel matrix factorization. Our
experiments show that our algorithm improves over both baselines, and can yield
interpretable results that reveal more of the latent structure than either NMF
or SMF alone.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures. To appear in 2018 SIAM International Conference
  on Data Mining (SDM '18). For the source code, see
  https://people.mpi-inf.mpg.de/~pmiettin/linear-tropical/</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06144</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formalization for Specifying and Implementing Correct Pull-Stream
  Modules</dc:title>
 <dc:creator>Lavoie, Erick</dc:creator>
 <dc:creator>Hendren, Laurie</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.m</dc:subject>
 <dc:description>  Pull-stream is a JavaScript demand-driven functional design pattern based on
callback functions that enables the creation and easy composition of
independent modules that are used to create streaming applications. It is used
in popular open source projects and the community around it has created over a
hundred compatible modules. While the description of the pull-stream design
pattern may seem simple, it does exhibit complicated termination cases. Despite
the popularity and large uptake of the pull-stream design pattern, there was no
existing formal specification that could help programmers reason about the
correctness of their implementations.
  Thus, the main contribution of this paper is to provide a formalization for
specifying and implementing correct pull-stream modules based on the following:
(1) we show the pull-stream design pattern is a form of declarative concurrent
programming; (2) we present an event-based protocol language that supports our
formalization, independently of JavaScript; (3) we provide the first precise
and explicit definition of the expected sequences of events that happen at the
interface of two modules, which we call the pull-stream protocol; (4) we
specify reference modules that exhibit the full range of behaviors of the
pull-stream protocol; (5) we validate our definitions against the community
expectations by testing the existing core pull-stream modules against them and
identify unspecified behaviors in existing modules.
  Our approach helps to better understand the pull-stream protocol, to ensure
interoperability of community modules, and to concisely and precisely specify
new pull-stream abstractions in papers and documentation.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06146</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-tuned Language Models for Text Classification</dc:title>
 <dc:creator>Howard, Jeremy</dc:creator>
 <dc:creator>Ruder, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Transfer learning has revolutionized computer vision, but existing approaches
in NLP still require task-specific modifications and training from scratch. We
propose Fine-tuned Language Models (FitLaM), an effective transfer learning
method that can be applied to any task in NLP, and introduce techniques that
are key for fine-tuning a state-of-the-art language model. Our method
significantly outperforms the state-of-the-art on five text classification
tasks, reducing the error by 18-24% on the majority of datasets. We open-source
our pretrained models and code to enable adoption by the community.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06153</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LCD: Low Latency Command Dissemination for A Platoon of Vehicles</dc:title>
 <dc:creator>Li, Kai</dc:creator>
 <dc:creator>Ni, Wei</dc:creator>
 <dc:creator>Tovar, Eduardo</dc:creator>
 <dc:creator>Guizani, Mohsen</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In a vehicular platoon, a lead vehicle that is responsible for managing the
platoon's moving directions and velocity periodically disseminates control
commands to following vehicles based on vehicle-to-vehicle communications.
However, reducing command dissemination latency with multiple vehicles while
ensuring successful message delivery to the tail vehicle is challenging. We
propose a new linear dynamic programming algorithm using backward induction and
interchange arguments to minimize the dissemination latency of the vehicles.
Furthermore, a closed form of dissemination latency in vehicular platoon is
obtained by utilizing Markov chain with M/M/1 queuing model. Simulation results
confirm that the proposed dynamic programming algorithm improves the
dissemination rate by at least 50.9%, compared to similar algorithms in the
literature. Moreover, it also approximates the best performance with the
maximum gap of up to 0.2 second in terms of latency.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, accepted in IEEE International Conference on
  Communications (ICC), 2018</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06159</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Does Stochastic Gradient Algorithm Work Well?</dc:title>
 <dc:creator>Nguyen, Lam M.</dc:creator>
 <dc:creator>Nguyen, Nam H.</dc:creator>
 <dc:creator>Phan, Dzung T.</dc:creator>
 <dc:creator>Kalagnanam, Jayant R.</dc:creator>
 <dc:creator>Scheinberg, Katya</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we consider a general stochastic optimization problem which is
often at the core of supervised learning, such as deep learning and linear
classification. We consider a standard stochastic gradient descent (SGD) method
with a fixed, large step size and propose a novel assumption on the objective
function, under which this method has the improved convergence rates (to a
neighborhood of the optimal solutions). We then empirically demonstrate that
these assumptions hold for logistic regression and standard deep neural
networks on classical data sets. Thus our analysis helps to explain when
efficient behavior can be expected from the SGD method in training
classification models and deep neural networks.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06161</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Lifecycle on Social Networks: Analyzing the Effects of Semantic
  Continuity and Social Communities</dc:title>
 <dc:creator>Dey, Kuntal</dc:creator>
 <dc:creator>Kaushik, Saroj</dc:creator>
 <dc:creator>Garg, Kritika</dc:creator>
 <dc:creator>Shrivastava, Ritvik</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Topic lifecycle analysis on Twitter, a branch of study that investigates
Twitter topics from their birth through lifecycle to death, has gained immense
mainstream research popularity. In the literature, topics are often treated as
one of (a) hashtags (independent from other hashtags), (b) a burst of keywords
in a short time span or (c) a latent concept space captured by advanced text
analysis methodologies, such as Latent Dirichlet Allocation (LDA). The first
two approaches are not capable of recognizing topics where different users use
different hashtags to express the same concept (semantically related), while
the third approach misses out the user's explicit intent expressed via
hashtags. In our work, we use a word embedding based approach to cluster
different hashtags together, and the temporal concurrency of the hashtag
usages, thus forming topics (a semantically and temporally related group of
hashtags).We present a novel analysis of topic lifecycles with respect to
communities. We characterize the participation of social communities in the
topic clusters, and analyze the lifecycle of topic clusters with respect to
such participation. We derive first-of-its-kind novel insights with respect to
the complex evolution of topics over communities and time: temporal morphing of
topics over hashtags within communities, how the hashtags die in some
communities but morph into some other hashtags in some other communities (that,
it is a community-level phenomenon), and how specific communities adopt to
specific hashtags. Our work is fundamental in the space of topic lifecycle
modeling and understanding in communities: it redefines our understanding of
topic lifecycles and shows that the social boundaries of topic lifecycles are
deeply ingrained with community behavior.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures (13 figures if sub-figures are counted
  separately), To Appear in ECIR 2018</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06171</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Information Retrieval Through Wiretap Channel II: Privacy Meets
  Security</dc:title>
 <dc:creator>Banawan, Karim</dc:creator>
 <dc:creator>Ulukus, Sennur</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We consider the problem of private information retrieval through wiretap
channel II (PIR-WTC-II). In PIR-WTC-II, a user wants to retrieve a single
message (file) privately out of $M$ messages, which are stored in $N$
replicated and non-communicating databases. An external eavesdropper observes a
fraction $\mu_n$ (of its choice) of the traffic exchanged between the $n$th
database and the user. In addition to the privacy constraint, the databases
should encode the returned answer strings such that the eavesdropper learns
absolutely nothing about the \emph{contents} of the databases. We aim at
characterizing the capacity of the PIR-WTC-II under the combined privacy and
security constraints. We obtain a general upper bound for the problem in the
form of a max-min optimization problem, which extends the converse proof of the
PIR problem under asymmetric traffic constraints. We propose an achievability
scheme that satisfies the security constraint by encoding a secret key, which
is generated securely at each database, into an artificial noise vector using
an MDS code. The user and the databases operate at one of the corner points of
the achievable scheme for the PIR under asymmetric traffic constraints such
that the retrieval rate is maximized under the imposed security constraint. The
upper bound and the lower bound match for the case of $M=2$ and $M=3$ messages,
for any $N$, and any $\boldsymbol{\mu}=(\mu_1, \cdots, \mu_N)$.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Information Theory, January 2018</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06172</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextual and Position-Aware Factorization Machines for Sentiment
  Classification</dc:title>
 <dc:creator>Wang, Shuai</dc:creator>
 <dc:creator>Zhou, Mianwei</dc:creator>
 <dc:creator>Fei, Geli</dc:creator>
 <dc:creator>Chang, Yi</dc:creator>
 <dc:creator>Liu, Bing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  While existing machine learning models have achieved great success for
sentiment classification, they typically do not explicitly capture
sentiment-oriented word interaction, which can lead to poor results for
fine-grained analysis at the snippet level (a phrase or sentence).
Factorization Machine provides a possible approach to learning element-wise
interaction for recommender systems, but they are not directly applicable to
our task due to the inability to model contexts and word sequences. In this
work, we develop two Position-aware Factorization Machines which consider word
interaction, context and position information. Such information is jointly
encoded in a set of sentiment-oriented word interaction vectors. Compared to
traditional word embeddings, SWI vectors explicitly capture sentiment-oriented
word interaction and simplify the parameter learning. Experimental results show
that while they have comparable performance with state-of-the-art methods for
document-level classification, they benefit the snippet/sentence-level
sentiment analysis.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06176</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating planning for task-completion dialogue policy learning</dc:title>
 <dc:creator>Peng, Baolin</dc:creator>
 <dc:creator>Li, Xiujun</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Liu, Jingjing</dc:creator>
 <dc:creator>Wong, Kam-Fai</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Training a task-completion dialogue agent with real users via reinforcement
learning (RL) could be prohibitively expensive, because it requires many
interactions with users. One alternative is to resort to a user simulator,
while the discrepancy of between simulated and real users makes the learned
policy unreliable in practice. This paper addresses these challenges by
integrating planning into the dialogue policy learning based on Dyna-Q
framework, and provides a more sample-efficient approach to learn the dialogue
polices. The proposed agent consists of a planner trained on-line with limited
real user experience that can generate large amounts of simulated experience to
supplement with limited real user experience, and a policy model trained on
these hybrid experiences. The effectiveness of our approach is validated on a
movie-booking task in both a simulation setting and a human-in-the-loop
setting.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06208</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Parametric Detection of Network Communities; The Natural Way; A
  Cascaded Stackelberg Game</dc:title>
 <dc:creator>Keni, Nishant Deepak</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Real-World networks have an inherently dynamic structure and are often
composed of communities that are constantly changing in membership. Identifying
these communities is of great importance when analyzing structural properties
of networks. Hence, recent years have witnessed intense research in of solving
the challenging problem of detecting such evolving communities. The mainstream
approach towards community detection involves optimization of a global
partition quality metric (e.g. modularity) over the network. Another technique,
Spectral Clustering, involves mapping of original data points in a lower
dimensional space, where the clustering properties of a graph are much more
evident, and then applying standard clustering techniques for identifying
communities. However, the traditional spectral clustering techniques cannot
naturally learn the number of communities in networks. These techniques are
based on external community connectivity properties, and often fail to identify
smaller community structures in dense networks. In this article, we propose an
algorithm, namely, the Cascaded Stackelberg Community Detection Algorithm
(CASCODE) inspired by the Stackelberg Duopoly Game. This algorithm uses the
notion of a leader-follower relationship between the nodes to influence the
actions of either. The intuition of the algorithm is based on the natural
expected internal structure in evolving communities in networks. Thus, the
algorithm is able to naturally learn the number of communities in a network in
contrast with other techniques such as Spectral Clustering, which require the
expected number of communities as an input. Because this Stackelberg
Model-based Community Detection algorithm detects communities through their
internal structure, we are able to obtain a finer community structure
resolution in dense networks.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06216</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Degree-constrained 2-partitions of graphs</dc:title>
 <dc:creator>Bang-Jensen, Joergen</dc:creator>
 <dc:creator>Bessy, St&#xe9;phane</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A $(\delta\geq k_1,\delta\geq k_2)$-partition of a graph $G$ is a
vertex-partition $(V_1,V_2)$ of $G$ satisfying that $\delta(G[V_i])\geq k_i$
for $i=1,2$. We determine, for all positive integers $k_1,k_2$, the complexity
of deciding whether a given graph has a $(\delta\geq k_1,\delta\geq
k_2)$-partition.
  We also address the problem of finding a function $g(k_1,k_2)$ such that the
$(\delta\geq k_1,\delta\geq k_2)$-partition problem is ${\cal
  NP}$-complete for the class of graphs of minimum degree less than
$g(k_1,k_2)$ and polynomial for all graphs with minimum degree at least
$g(k_1,k_2)$. We prove that $g(1,k)=k$ for $k\ge 3$, that $g(2,2)=3$ and that
$g(2,3)$, if it exists, has value 4 or 5.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06228</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In-memory computing on a photonic platform</dc:title>
 <dc:creator>R&#xed;os, Carlos</dc:creator>
 <dc:creator>Youngblood, Nathan</dc:creator>
 <dc:creator>Cheng, Zengguang</dc:creator>
 <dc:creator>Gallo, Manuel Le</dc:creator>
 <dc:creator>Pernice, Wolfram H. P.</dc:creator>
 <dc:creator>Wright, C David</dc:creator>
 <dc:creator>Sebastian, Abu</dc:creator>
 <dc:creator>Bhaskaran, Harish</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Physics - Applied Physics</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  Collocated data processing and storage are the norm in biological systems.
Indeed, the von Neumann computing architecture, that physically and temporally
separates processing and memory, was born more of pragmatism based on available
technology. As our ability to create better hardware improves, new
computational paradigms are being explored. Integrated photonic circuits are
regarded as an attractive solution for on-chip computing using only light,
leveraging the increased speed and bandwidth potential of working in the
optical domain, and importantly, removing the need for time and energy sapping
electro-optical conversions. Here we show that we can combine the emerging area
of integrated optics with collocated data storage and processing to enable
all-photonic in-memory computations. By employing non-volatile photonic
elements based on the phase-change material, Ge2Sb2Te5, we are able to achieve
direct scalar multiplication on single devices. Featuring a novel single-shot
Write/Erase and a drift-free process, such elements can multiply two scalar
numbers by mapping their values to the energy of an input pulse and to the
transmittance of the device, codified in the crystallographic state of the
element. The output pulse, carrying the information of the light-matter
interaction, is the result of the computation. Our all-optical approach is
novel, easy to fabricate and operate, and sets the stage for development of
entirely photonic computers.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06232</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NAE-SAT-based probabilistic membership filters</dc:title>
 <dc:creator>Fang, Chao</dc:creator>
 <dc:creator>Zhu, Zheng</dc:creator>
 <dc:creator>Katzgraber, Helmut G.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Probabilistic membership filters are a type of data structure designed to
quickly verify whether an element of a large data set belongs to a subset of
the data. While false negatives are not possible, false positives are.
Therefore, the main goal of any good probabilistic membership filter is to have
a small false-positive rate while being memory efficient and fast to query.
Although Bloom filters are fast to construct, their memory efficiency is
bounded by a strict theoretical upper bound. Weaver et al. introduced random
satisfiability-based filters that significantly improved the efficiency of the
probabilistic filters, however, at the cost of solving a complex random
satisfiability (SAT) formula when constructing the filter. Here we present an
improved SAT filter approach with a focus on reducing the filter building
times, as well as query times. Our approach is based on using not-all-equal
(NAE) SAT formulas to build the filters, solving these via a mapping to random
SAT using traditionally-fast random SAT solvers, as well as bit packing and the
reduction of the number of hash functions. Paired with fast hardware, NAE-SAT
filters could result in enterprise-size applications.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, 3 pages</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06237</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minor Excluded Network Families Admit Fast Distributed Algorithms</dc:title>
 <dc:creator>Haeupler, Bernhard</dc:creator>
 <dc:creator>Li, Jason</dc:creator>
 <dc:creator>Zuzic, Goran</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C83, 68Q85</dc:subject>
 <dc:description>  Distributed network optimization algorithms, such as minimum spanning tree,
minimum cut, and shortest path, are an active research area in distributed
computing. This paper presents a fast distributed algorithm for such problems
in the CONGEST model, on networks that exclude a fixed minor.
  On general graphs, many optimization problems, including the ones mentioned
above, require $\tilde\Omega(\sqrt n)$ rounds of communication in the CONGEST
model, even if the network graph has a much smaller diameter. Naturally, the
next step in algorithm design is to design efficient algorithms which bypass
this lower bound on a restricted class of graphs. Currently, the only known
method of doing so uses the low-congestion shortcut framework of Ghaffari and
Haeupler [SODA'16]. Building off of their work, this paper proves that excluded
minor graphs admit high-quality shortcuts, leading to an $\tilde O(D^2)$ round
algorithm for the aforementioned problems, where $D$ is the diameter of the
network graph. To work with excluded minor graph families, we utilize the Graph
Structure Theorem of Robertson and Seymour. To the best of our knowledge, this
is the first time the Graph Structure Theorem has been used for an algorithmic
result in the distributed setting.
  Even though the proof is involved, merely showing the existence of good
shortcuts is sufficient to obtain simple, efficient distributed algorithms. In
particular, the shortcut framework can efficiently construct near-optimal
shortcuts and then use them to solve the optimization problems. This, combined
with the very general family of excluded minor graphs, which includes most
other important graph classes, makes this result of significant interest.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06255</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Contractivity of Privacy Mechanisms</dc:title>
 <dc:creator>Diaz, Mario</dc:creator>
 <dc:creator>Sankar, Lalitha</dc:creator>
 <dc:creator>Kairouz, Peter</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present a novel way to compare the statistical cost of privacy mechanisms
using their Dobrushin coefficient. Specifically, we provide upper and lower
bounds for the Dobrushin coefficient of a privacy mechanism in terms of its
maximal leakage and local differential privacy guarantees. Given the geometric
nature of the Dobrushin coefficient, this approach provides some insights into
the general statistical cost of these privacy guarantees. We highlight the
strength of this method by applying our results to develop new bounds on the
$\ell_2$-minimax risk in a distribution estimation setting under maximal
leakage constraints. Specifically, we find its order with respect to the sample
size and privacy level, allowing a quantitative comparison with the
corresponding local differential privacy $\ell_2$-minimax risk.
</dc:description>
 <dc:description>Comment: Submitted to the International Symposium on Information Theory (ISIT)
  2018</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06258</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Theory of Data-Diff: Optimal Synthesis of Succinct Data
  Modification Scripts</dc:title>
 <dc:creator>Wattanawaroon, Tana</dc:creator>
 <dc:creator>Macke, Stephen</dc:creator>
 <dc:creator>Parameswaran, Aditya</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  This paper addresses the Data-Diff problem: given a dataset and a subsequent
version of the dataset, find the shortest sequence of operations that
transforms the dataset to the subsequent version, under a restricted family of
operations. We consider operations similar to SQL UPDATE, each with a condition
(WHERE) that matches a subset of tuples and a modifier (SET) that makes changes
to those matched tuples. We characterize the problem based on different
constraints on the attributes and the allowed conditions and modifiers,
providing complexity classification and algorithms in each case.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06261</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating the Working of Text Classifiers</dc:title>
 <dc:creator>Sachan, Devendra Singh</dc:creator>
 <dc:creator>Zaheer, Manzil</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Text classification is one of the most widely studied task in natural
language processing. Recently, larger and larger multilayer neural network
models are employed for the task motivated by the principle of
compositionality. Almost all of the methods reported use discriminative
approaches for the task. Discriminative approaches come with a caveat that if
there is no proper capacity control, it might latch on to any signal even
though it might not generalize. With use of various state-of-the-art approaches
for text classifiers, we want to explore if the models actually learn to
compose meaning of the sentences or still just use some key lexicons. To test
our hypothesis, we construct datasets where the train and test split have no
direct overlap of such lexicons. We study various text classifiers and observe
that there is a big performance drop on these datasets. Finally, we show that
even simple regularization techniques can improve performance on these
datasets.
</dc:description>
 <dc:description>Comment: NIPS 2017 Workshop on Deep Learning: Bridging Theory and Practice</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06267</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous, Evolutionary and Large-Scale: A New Perspective for
  Automated Mobile App Testing</dc:title>
 <dc:creator>Vasquez, Mario Linares</dc:creator>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:creator>Poshyvanyk, Denys</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Mobile app development involves a unique set of challenges including device
fragmentation and rapidly evolving platforms, making testing a difficult task.
The design space for a comprehensive mobile testing strategy includes features,
inputs, potential contextual app states, and large combinations of devices and
underlying platforms. Therefore, automated testing is an essential activity of
the development process. However, current state of the art of automated testing
tools for mobile apps poses limitations that has driven a preference for manual
testing in practice. As of today, there is no comprehensive automated solution
for mobile testing that overcomes fundamental issues such as automated oracles,
history awareness in test cases, or automated evolution of test cases.
  In this perspective paper we survey the current state of the art in terms of
the frameworks, tools, and services available to developers to aid in mobile
testing, highlighting present shortcomings. Next, we provide commentary on
current key challenges that restrict the possibility of a comprehensive,
effective, and practical automated testing solution. Finally, we offer our
vision of a comprehensive mobile app testing framework, complete with research
agenda, that is succinctly summarized along three principles: Continuous,
Evolutionary and Large-scale (CEL).
</dc:description>
 <dc:description>Comment: 12 pages, accepted to the Proceedings of 33rd IEEE International
  Conference on Software Maintenance and Evolution (ICSME'17)</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06268</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How do Developers Test Android Applications?</dc:title>
 <dc:creator>Vasquez, Mario Linares</dc:creator>
 <dc:creator>Bernal-Cardenas, Carlos</dc:creator>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:creator>Poshyvanyk, Denys</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Enabling fully automated testing of mobile applications has recently become
an important topic of study for both researchers and practitioners. A plethora
of tools and approaches have been proposed to aid mobile developers both by
augmenting manual testing practices and by automating various parts of the
testing process. However, current approaches for automated testing fall short
in convincing developers about their benefits, leading to a majority of mobile
testing being performed manually. With the goal of helping researchers and
practitioners - who design approaches supporting mobile testing - to understand
developer's needs, we analyzed survey responses from 102 open source
contributors to Android projects about their practices when performing testing.
The survey focused on questions regarding practices and preferences of
developers/testers in-the-wild for (i) designing and generating test cases,
(ii) automated testing practices, and (iii) perceptions of quality metrics such
as code coverage for determining test quality. Analyzing the information
gleaned from this survey, we compile a body of knowledge to help guide
researchers and professionals toward tailoring new automated testing approaches
to the need of a diverse set of open source developers.
</dc:description>
 <dc:description>Comment: 11 pages, accepted to the Proceedings of the 33rd IEEE International
  Conference on Software Maintenance and Evolution (ICSME'17)</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06270</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Defense Against Advanced Persistent Threats in Dynamic Cloud Storage: A
  Colonel Blotto Game Approach</dc:title>
 <dc:creator>Min, Minghui</dc:creator>
 <dc:creator>Xiao, Liang</dc:creator>
 <dc:creator>Xie, Caixia</dc:creator>
 <dc:creator>Hajimirsadeghi, Mohammad</dc:creator>
 <dc:creator>Mandayam, Narayan B.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Advanced Persistent Threat (APT) attackers apply multiple sophisticated
methods to continuously and stealthily steal information from the targeted
cloud storage systems and can even induce the storage system to apply a
specific defense strategy and attack it accordingly. In this paper, the
interactions between an APT attacker and a defender allocating their Central
Processing Units (CPUs) over multiple storage devices in a cloud storage system
are formulated as a Colonel Blotto game. The Nash equilibria (NEs) of the CPU
allocation game are derived for both symmetric and asymmetric CPUs between the
APT attacker and the defender to evaluate how the limited CPU resources, the
date storage size and the number of storage devices impact the expected data
protection level and the utility of the cloud storage system. A CPU allocation
scheme based on &quot;hotbooting&quot; policy hill-climbing (PHC) that exploits the
experiences in similar scenarios to initialize the quality values to accelerate
the learning speed is proposed for the defender to achieve the optimal APT
defense performance in the dynamic game without being aware of the APT attack
model and the data storage model. A hotbooting deep Q-network (DQN)-based CPU
allocation scheme further improves the APT detection performance for the case
with a large number of CPUs and storage devices. Simulation results show that
our proposed reinforcement learning based CPU allocation can improve both the
data protection level and the utility of the cloud storage system compared with
the Q-learning based CPU allocation against APTs.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06271</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Android App Usages for Generating Actionable GUI-based Execution
  Scenarios</dc:title>
 <dc:creator>Linares-Vasquez, Mario</dc:creator>
 <dc:creator>White, Martin</dc:creator>
 <dc:creator>Bernal-Cardenas, Carlos</dc:creator>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:creator>Poshyvanyk, Denys</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  GUI-based models extracted from Android app execution traces, events, or
source code can be extremely useful for challenging tasks such as the
generation of scenarios or test cases. However, extracting effective models can
be an expensive process. Moreover, existing approaches for automatically
deriving GUI-based models are not able to generate scenarios that include
events which were not observed in execution (nor event) traces. In this paper,
we address these and other major challenges in our novel hybrid approach,
coined as MonkeyLab. Our approach is based on the Record-Mine-Generate-Validate
framework, which relies on recording app usages that yield execution (event)
traces, mining those event traces and generating execution scenarios using
statistical language modeling, static and dynamic analyses, and validating the
resulting scenarios using an interactive execution of the app on a real device.
The framework aims at mining models capable of generating feasible and fully
replayable (i.e., actionable) scenarios reflecting either natural user behavior
or uncommon usages (e.g., corner cases) for a given app. We evaluated MONKEYLAB
in a case study involving several medium-to-large open-source Android apps. Our
results demonstrate that MonkeyLab is able to mine GUI-based models that can be
used to generate actionable execution scenarios for both natural and unnatural
sequences of events on Google Nexus 7 tablets.
</dc:description>
 <dc:description>Comment: 12 pages, accepted to the Proceedings of the 12th IEEE Working
  Conference on Mining Software Repositories (MSR'15)</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06274</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Machine Learning Hardware at ARM: A Systems-on-Chip (SoC)
  Perspective</dc:title>
 <dc:creator>Zhu, Yuhao</dc:creator>
 <dc:creator>Mattina, Matthew</dc:creator>
 <dc:creator>Whatmough, Paul</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Machine learning is playing an increasingly significant role in emerging
mobile application domains such as AR/VR, ADAS, etc. Accordingly, hardware
architects have designed customized hardware for machine learning algorithms,
especially neural networks, to improve compute efficiency. However, machine
learning is typically just one processing stage in complex end-to-end
applications, which involve multiple components in a mobile Systems-on-a-chip
(SoC). Focusing on just ML accelerators loses bigger optimization opportunity
at the system (SoC) level. This paper argues that hardware architects should
expand the optimization scope to the entire SoC. We demonstrate one particular
case-study in the domain of continuous computer vision where camera sensor,
image signal processor (ISP), memory, and NN accelerator are synergistically
co-designed to achieve optimal system-level efficiency.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06275</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IoT Security Techniques Based on Machine Learning</dc:title>
 <dc:creator>Xiao, Liang</dc:creator>
 <dc:creator>Wan, Xiaoyue</dc:creator>
 <dc:creator>Lu, Xiaozhen</dc:creator>
 <dc:creator>Zhang, Yanyong</dc:creator>
 <dc:creator>Wu, Di</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Internet of things (IoT) that integrate a variety of devices into networks to
provide advanced and intelligent services have to protect user privacy and
address attacks such as spoofing attacks, denial of service attacks, jamming
and eavesdropping. In this article, we investigate the attack model for IoT
systems, and review the IoT security solutions based on machine learning
techniques including supervised learning, unsupervised learning and
reinforcement learning. We focus on the machine learning based IoT
authentication, access control, secure offloading and malware detection schemes
to protect data privacy. In this article, we discuss the challenges that need
to be addressed to implement these machine learning based security schemes in
practical IoT systems.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06277</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Chain HDRI: Reconstructing a High Dynamic Range Image from a Single
  Low Dynamic Range Image</dc:title>
 <dc:creator>Lee, Siyeong</dc:creator>
 <dc:creator>An, Gwon Hwan</dc:creator>
 <dc:creator>Kang, Suk-Ju</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  In this paper, we propose a novel deep neural network model that reconstructs
a high dynamic range (HDR) image from a single low dynamic range (LDR) image.
The proposed model is based on a convolutional neural network composed of
dilated convolutional layers, and infers LDR images with various exposures and
illumination from a single LDR image of the same scene. Then, the final HDR
image can be formed by merging these inference results. It is relatively easy
for the proposed method to find the mapping between the LDR and an HDR with a
different bit depth because of the chaining structure inferring the
relationship between the LDR images with brighter (or darker) exposures from a
given LDR image. The method not only extends the range, but also has the
advantage of restoring the light information of the actual physical world. For
the HDR images obtained by the proposed method, the HDR-VDP2 Q score, which is
the most popular evaluation metric for HDR images, was 56.36 for a display with
a 1920$\times$1200 resolution, which is an improvement of 6 compared with the
scores of conventional algorithms. In addition, when comparing the peak
signal-to-noise ratio values for tone mapped HDR images generated by the
proposed and conventional algorithms, the average value obtained by the
proposed algorithm is 30.86 dB, which is 10 dB higher than those obtained by
the conventional algorithms.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06278</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discontinuous energy shaping control of the Chaplygin sleigh</dc:title>
 <dc:creator>Ferguson, Joel</dc:creator>
 <dc:creator>Donaire, Alejandro</dc:creator>
 <dc:creator>Middleton, Richard H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we present an energy shaping control law for set-point
regulation of the Chaplygin sleigh. It is well known that nonholonomic
mechanical systems cannot be asymptotically stabilised using smooth control
laws as they do no satisfy Brockett's necessary condition for smooth
stabilisation. Here, we propose a discontinuous control law that can be seen as
a potential energy shaping and damping injection controller. The proposed
controller is shown to be robust against the parameters of both the inertia
matrix and the damping structure of the open-loop system.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, To be presented at 6th IFAC Workshop on
  Lagrangian and Hamiltonian Methods for Nonlinear Control (LHMNC 2018)</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06279</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust integral action of port-Hamiltonian systems</dc:title>
 <dc:creator>Ferguson, Joel</dc:creator>
 <dc:creator>Donaire, Alejandro</dc:creator>
 <dc:creator>Ortega, Romeo</dc:creator>
 <dc:creator>Middleton, Richard H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Interconnection and damping assignment, passivity-based control (IDA-PBC) has
proven to be a successful control technique for the stabilisation of many
nonlinear systems. In this paper, we propose a method to robustify a system
which has been stabilised using IDA-PBC with respect to constant, matched
disturbances via the addition of integral action. The proposed controller
extends previous work on the topic by being robust against the damping of the
system, a quantity which may not be known in many applications.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, accepted to LHMNLC2018</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06285</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning-based Energy Trading for Microgrids</dc:title>
 <dc:creator>Xiao, Liang</dc:creator>
 <dc:creator>Xiao, Xingyu</dc:creator>
 <dc:creator>Dai, Canhuang</dc:creator>
 <dc:creator>Pengy, Mugen</dc:creator>
 <dc:creator>Wang, Lichun</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  With the time-varying renewable energy generation and power demand,
microgrids (MGs) exchange energy in smart grids to reduce their dependence on
power plants. In this paper, we formulate an MG energy trading game, in which
each MG trades energy according to the predicted renewable energy generation
and local energy demand, the current battery level, and the energy trading
history. The Nash quilibrium (NE) of the game is provided, revealing the
conditions under which the local energy generation satisfies the energy demand
of the MG and providing the performance bound of the energy trading scheme. We
propose a reinforcement learning based MG energy trading scheme that applies
the deep Q-network (DQN) to improve the utility of the MG for the case with a
large number of the connected MGs. Simulations are performed for the MGs with
wind generation that are aware of the electricity prices and the historic
energy trading, showing that this scheme significantly reduces the average
power plant schedules and improves the utility of the MG compared with the
benchmark strategy.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06287</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Does a TextCNN Learn?</dc:title>
 <dc:creator>Gong, Linyuan</dc:creator>
 <dc:creator>Ji, Ruyi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  TextCNN, the convolutional neural network for text, is a useful deep learning
algorithm for sentence classification tasks such as sentiment analysis and
question classification. However, neural networks have long been known as black
boxes because interpreting them is a challenging task. Researchers have
developed several tools to understand a CNN for image classification by deep
visualization, but research about deep TextCNNs is still insufficient. In this
paper, we are trying to understand what a TextCNN learns on two classical NLP
datasets. Our work focuses on functions of different convolutional kernels and
correlations between convolutional kernels.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06288</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An End-to-End Deep Learning Histochemical Scoring System for Breast
  Cancer Tissue Microarray</dc:title>
 <dc:creator>Liu, Jingxin</dc:creator>
 <dc:creator>Xu, Bolei</dc:creator>
 <dc:creator>Zheng, Chi</dc:creator>
 <dc:creator>Gong, Yuanhao</dc:creator>
 <dc:creator>Garibaldi, Jon</dc:creator>
 <dc:creator>Soria, Daniele</dc:creator>
 <dc:creator>Green, Andew</dc:creator>
 <dc:creator>Ellis, Ian O.</dc:creator>
 <dc:creator>Zou, Wenbin</dc:creator>
 <dc:creator>Qiu, Guoping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One of the methods for stratifying different molecular classes of breast
cancer is the Nottingham Prognostic Index Plus (NPI+) which uses breast cancer
relevant biomarkers to stain tumour tissues prepared on tissue microarray
(TMA). To determine the molecular class of the tumour, pathologists will have
to manually mark the nuclei activity biomarkers through a microscope and use a
semi-quantitative assessment method to assign a histochemical score (H-Score)
to each TMA core. Manually marking positively stained nuclei is a time
consuming, imprecise and subjective process which will lead to inter-observer
and intra-observer discrepancies. In this paper, we present an end-to-end deep
learning system which directly predicts the H-Score automatically. Our system
imitates the pathologists' decision process and uses one fully convolutional
network (FCN) to extract all nuclei region (tumour and non-tumour), a second
FCN to extract tumour nuclei region, and a multi-column convolutional neural
network which takes the outputs of the first two FCNs and the stain intensity
description image as input and acts as the high-level decision making mechanism
to directly output the H-Score of the input TMA image. To the best of our
knowledge, this is the first end-to-end system that takes a TMA image as input
and directly outputs a clinical score. We will present experimental results
which demonstrate that the H-Scores predicted by our model have very high and
statistically significant correlation with experienced pathologists' scores and
that the H-Score discrepancy between our algorithm and the pathologists is on
par with the inter-subject discrepancy between the pathologists.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06290</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Angle-Monotone Graphs: Construction and Local Routing</dc:title>
 <dc:creator>Lubiw, Anna</dc:creator>
 <dc:creator>Mondal, Debajyoti</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>68Q25, 65D18</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  A geometric graph in the plane is angle-monotone of width $\gamma$ if every
pair of vertices is connected by an angle-monotone path of width $\gamma$, a
path such that the angles of any two edges in the path differ by at most
$\gamma$. Angle-monotone graphs have good spanning properties.
  We prove that every point set in the plane admits an angle-monotone graph of
width $90^\circ$, hence with spanning ratio $\sqrt 2$, and a subquadratic
number of edges. This answers an open question posed by Dehkordi, Frati and
Gudmundsson.
  We show how to construct, for any point set of size $n$ and any angle
$\alpha$, $0 &lt; \alpha &lt; 45^\circ$, an angle-monotone graph of width
$(90^\circ+\alpha)$ with $O(\frac{n}{\alpha})$ edges. Furthermore, we give a
local routing algorithm to find angle-monotone paths of width
$(90^\circ+\alpha)$ in these graphs. The routing ratio, which is the ratio of
path length to Euclidean distance, is at most $1/\cos(45^\circ +
\frac{\alpha}{2})$, i.e., ranging from $\sqrt 2 \approx 1.414$ to $2.613$. For
the special case $\alpha = 30^\circ$, we obtain the $\Theta_6$-graph and our
routing algorithm achieves the known routing ratio 2 while finding
angle-monotone paths of width $120^\circ$.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06294</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Task Pharmacovigilance Mining from Social Media Posts</dc:title>
 <dc:creator>Chowdhury, Shaika</dc:creator>
 <dc:creator>Zhang, Chenwei</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Social media has grown to be a crucial information source for
pharmacovigilance studies where an increasing number of people post adverse
reactions to medical drugs that are previously unreported. Aiming to
effectively monitor various aspects of Adverse Drug Reactions (ADRs) from
diversely expressed social medical posts, we propose a multi-task neural
network framework that learns several tasks associated with ADR monitoring with
different levels of supervisions collectively. Besides being able to correctly
classify ADR posts and accurately extract ADR mentions from online posts, the
proposed framework is also able to further understand reasons for which the
drug is being taken, known as 'indication', from the given social media post. A
coverage-based attention mechanism is adopted in our framework to help the
model properly identify 'phrasal' ADRs and Indications that are attentive to
multiple words in a post. Our framework is applicable in situations where
limited parallel data for different pharmacovigilance tasks are available.We
evaluate the proposed framework on real-world Twitter datasets, where the
proposed model outperforms the state-of-the-art alternatives of each individual
task consistently.
</dc:description>
 <dc:description>Comment: Accepted in The Web Conference(WWW) 2018</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06302</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Point-wise Convolutional Neural Network for Modeling Statistical
  Regularities in Natural Images</dc:title>
 <dc:creator>Zhang, Jing</dc:creator>
 <dc:creator>Cao, Yang</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Zha, Zheng-Jun</dc:creator>
 <dc:creator>Wen, Chenglin</dc:creator>
 <dc:creator>Chen, Chang Wen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Modeling statistical regularities is the problem of representing the pixel
distributions in natural images, and usually applied to solve the ill-posed
image processing problems. In this paper, we present an extremely efficient CNN
architecture for modeling statistical regularities. Our method is based on the
observation that, by random sampling the pixels in natural images, we can
obtain a set of pixel ensembles in which the pixel value is independent
identically distributed. This leads to the idea of using 1*1 (point-wise)
convolution kernel instead of k*k convolution kernel to learn the feature
representation efficiently. Accordingly, we design a novel architecture with
fully point-wise convolutions to greatly reduce the model complexity while
maintaining the representation ability. Experiments on three applications:
color constancy, image dehazing and underwater image enhancement demonstrate
the superior performance of our proposed network over the existing
architectures, i.e., using 1/10-1/100 network parameters and computational cost
over the state-of-the-art networks while achieving comparable accuracy. Codes
and models will be made publicly available.
</dc:description>
 <dc:description>Comment: 10 pages. submitted to CVPR'2018</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06309</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composite Functional Gradient Learning of Generative Adversarial Models</dc:title>
 <dc:creator>Johnson, Rie</dc:creator>
 <dc:creator>Zhang, Tong</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative adversarial networks (GAN) have become popular for generating data
that mimic observations by learning a suitable variable transformation from a
random variable. However, empirically, GAN is known to suffer from instability.
Also, the theory provided based on the minimax optimization formulation of GAN
cannot explain the widely-used practical procedure that uses the so-called logd
trick. This paper provides a different theoretical foundation for generative
adversarial methods which does not rely on the minimax formulation. We show
that with a strong discriminator, it is possible to learn a good variable
transformation via functional gradient learning, which updates the functional
definition of a generator model, instead of updating only the model parameters
as in GAN. The theory guarantees that the learned generator improves the
KL-divergence between the probability distributions of real data and generated
data after each functional gradient step, until the KL-divergence converges to
zero. This new point of view leads to enhanced stable procedures for training
generative models that can utilize arbitrary learning algorithms. It also gives
a new theoretical insight into the original GAN procedure both with and without
the logd trick. Empirical results are shown on image generation to illustrate
the effectiveness of our new method.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06313</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BinaryRelax: A Relaxation Approach For Training Deep Neural Networks
  With Quantized Weights</dc:title>
 <dc:creator>Yin, Penghang</dc:creator>
 <dc:creator>Zhang, Shuai</dc:creator>
 <dc:creator>Lyu, Jiancheng</dc:creator>
 <dc:creator>Osher, Stanley</dc:creator>
 <dc:creator>Qi, Yingyong</dc:creator>
 <dc:creator>Xin, Jack</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We propose BinaryRelax, a simple two-phase algorithm, for training deep
neural networks with quantized weights. The set constraint that characterizes
the quantization of weights is not imposed until the late stage of training,
and a sequence of pseudo quantized weights is maintained. Specifically, we
relax the hard constraint into a continuous regularizer via Moreau envelope,
which turns out to be the squared Euclidean distance to the set of quantized
weights. The pseudo quantized weights are obtained by linearly interpolating
between the float weights and their quantizations. A continuation strategy is
adopted to push the weights towards the quantized state by gradually increasing
the regularization parameter. In the second phase, exact quantization scheme
with a small learning rate is invoked to guarantee fully quantized weights. We
test BinaryRelax on the benchmark CIFAR-10 and CIFAR-100 color image datasets
to demonstrate the superiority of the relaxed quantization approach and the
improved accuracy over the state-of-the-art training methods. Finally, we prove
the convergence of BinaryRelax under an approximate orthogonality condition.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06315</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chained Successive Cancellation Decoding of the Extended Golay code</dc:title>
 <dc:creator>Trifonov, Peter</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The extended Golay code is shown to be representable as a chained polar
subcode. This enables its decoding with the successive cancellation algorithm
and its stack generalization. The decoder can be further simplified by
employing fast Hadamard transform. The complexity of the obtained algorithm is
comparable with that of the Vardy algorithm.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06316</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demonstration of Topological Data Analysis on a Quantum Processor</dc:title>
 <dc:creator>Huang, He-Liang</dc:creator>
 <dc:creator>Wang, Xi-Lin</dc:creator>
 <dc:creator>Rohde, Peter P.</dc:creator>
 <dc:creator>Luo, Yi-Han</dc:creator>
 <dc:creator>Zhao, You-Wei</dc:creator>
 <dc:creator>Liu, Chang</dc:creator>
 <dc:creator>Li, Li</dc:creator>
 <dc:creator>Liu, Nai-Le</dc:creator>
 <dc:creator>Lu, Chao-Yang</dc:creator>
 <dc:creator>Pan, Jian-Wei</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Topological data analysis offers a robust way to extract useful information
from noisy, unstructured data by identifying its underlying structure.
Recently, an efficient quantum algorithm was proposed [Lloyd, Garnerone,
Zanardi, Nat. Commun. 7, 10138 (2016)] for calculating Betti numbers of data
points -- topological features that count the number of topological holes of
various dimensions in a scatterplot. Here, we implement a proof-of-principle
demonstration of this quantum algorithm by employing a six-photon quantum
processor to successfully analyze the topological features of Betti numbers of
a network including three data points, providing new insights into data
analysis in the era of quantum computing.
</dc:description>
 <dc:description>Comment: Accepted by Optica</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06323</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plagiarism: Taxonomy, Tools and Detection Techniques</dc:title>
 <dc:creator>Chowdhury, Hussain A</dc:creator>
 <dc:creator>Bhattacharyya, Dhruba K</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  To detect plagiarism of any form, it is essential to have broad knowledge of
its possible forms and classes, and existence of various tools and systems for
its detection. Based on impact or severity of damages, plagiarism may occur in
an article or in any production in a number of ways. This survey presents a
taxonomy of various plagiarism forms and include discussion on each of these
forms. Over the years, a good number tools and techniques have been introduced
to detect plagiarism. This paper highlights few promising methods for
plagiarism detection based on machine learning techniques. We analyse the pros
and cons of these methods and finally we highlight a list of issues and
research challenges related to this evolving research problem.
</dc:description>
 <dc:description>Comment: Paper of the 19th National Convention on Knowledge, Library and
  Information Networking (NACLIN 2016) held at Tezpur University, Assam, India
  from October 26-28, 2016</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06323</dc:identifier>
 <dc:identifier>Knowledge, Library and Information Networking, NACLIN 2016, ISBN:
  978-93-82735-08-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06326</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some aspects of physical prototyping in Pervasive Computing</dc:title>
 <dc:creator>Sigg, Stephan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This document summarises the results of several research campaigns over the
past seven years. The main connecting theme is the physical layer of widely
deployed sensors in Pervasive Computing domains. In particular, we have focused
on the RF-channel or on ambient audio.
  The initial problem from which we started this work was that of distributed
adaptive transmit beamforming. We have been looking for a simple method to
align the phases of jointly transmitting nodes (e.g. sensor or IoT nodes). The
algorithmic solution to this problem was to implement a distributed random
optimisation method on the participating nodes in which the transmitters and
the receiver follow an iterative question-and-answer scheme. We have been able
to derive sharp asymptotic bounds on the expected optimisation time of an
evolutionary random optimiser and presented an asymptotically optimal approach.
  One thing that we have learned from the work on these physical layer
algorithms was that the signals we work on are fragile and perceptive to
physical environmental changes. These could be obstacles such as furniture,
opened or closed windows or doors as well as movement of individuals. This
observation motivated us to view the wireless interface as a sensor for
environmental changes in Pervasive Computing environments.
  Another use of physical layer RF-signals is for security applications.
  We are currently working to further push these mentioned directions and novel
fields of physical prototyping. In particular, the calculation of mathematical
operations on the wireless channel at the time of transmission appears to
contain good potential for gains in efficiency for communication and
computation in Pervasive Computing domains.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06328</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Analysis on Spatial Coupling Coding for Two-Way Relay
  Channels</dc:title>
 <dc:creator>Takabe, Satoshi</dc:creator>
 <dc:creator>Ishimatsu, Yuta</dc:creator>
 <dc:creator>Wadayama, Tadashi</dc:creator>
 <dc:creator>Hayashi, Masahito</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Compute-and-forward relaying is effective to increase bandwidth efficiency of
wireless two-way relay channels. In a compute-and-forward scheme, a relay tries
to decode a linear combination composed of transmitted messages from other
terminals or relays. Design for error correcting codes and its decoding
algorithms suitable for compute-and-forward relaying schemes are still
important issue to be studied. In this paper, we will present an asymptotic
performance analysis on LDPC codes over two-way relay channels based on density
evolution (DE). Because of the asymmetric nature of the channel, we employ the
population dynamics DE combined with DE formulas for asymmetric channels to
obtain BP thresholds. In addition, we also evaluate the asymptotic performance
of spatially coupled LDPC codes for two-way relay channels. The results
indicate that the spatial coupling codes yield improvements in the BP threshold
compared with corresponding uncoupled codes for two-way relay channels.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06333</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Power Allocation Limits for Downlink Multi-user NOMA with QoS</dc:title>
 <dc:creator>Oviedo, Jose Armando</dc:creator>
 <dc:creator>Sadjadpour, Hamid R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A05</dc:subject>
 <dc:description>  The fundamental power allocation requirements for NOMA systems with minimum
quality of service (QoS) requirements are investigated. For any minimum QoS
rate $R_0$, the limits on the power allocation coefficients for each user are
derived, such that any power allocation coefficient outside of these limits
creates an outage with probability equal to 1. The power allocation
coefficients that facilitate each user's success of performing successive
interference cancellation (SIC) and decoding its own signal are derived, and
are found to depend only on the target rate $R_0$ and the number of total users
$K$. It is then proven that using these power allocation coefficients create
the same outage event as if using orthogonal multiple access (OMA), which
proves that the outage performance of NOMA with a fixed-power scheme can
matched that of OMA for all users simultaneously. Simulations confirm the
theoretical results, and also demonstrate that a power allocation strategy
exists that can improve the outage performance of NOMA over OMA, even with a
fixed-power strategy.
</dc:description>
 <dc:description>Comment: Accepted in Internation Conference on Communications (ICC) 2018
  Wireless Communication Symposium, 5 pages long, 2 figures</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06338</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boolean constant degree functions on the slice are juntas</dc:title>
 <dc:creator>Filmus, Yuval</dc:creator>
 <dc:creator>Ihringer, Ferdinand</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05B25, 05E30, 06E30</dc:subject>
 <dc:description>  We show that a Boolean degree $d$ function on the slice $\binom{[n]}{k} = \{
(x_1,\ldots,x_n) \in \{0,1\} : \sum_{i=1}^n x_i = k \}$ is a junta, assuming
that $k,n-k$ are large enough. This generalizes a classical result of Nisan and
Szegedy on the hypercube. Moreover, we show that the maximum number of
coordinates that a Boolean degree $d$ function can depend on is the same on the
slice and the hypercube.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06340</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Just-Right Consistency: reconciling availability and safety</dc:title>
 <dc:creator>Shapiro, Marc</dc:creator>
 <dc:creator>Bieniusa, Annette</dc:creator>
 <dc:creator>Pregui&#xe7;a, Nuno</dc:creator>
 <dc:creator>Balegas, Valter</dc:creator>
 <dc:creator>Meiklejohn, Christopher</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  By the CAP Theorem, a distributed data storage system can ensure either
Consistency under Partition (CP) or Availability under Partition (AP), but not
both. This has led to a split between CP databases, in which updates are
synchronous, and AP databases, where they are asynchronous. However, there is
no inherent reason to treat all updates identically: simply, the system should
be as available as possible, and synchronised just enough for the application
to be correct. We offer a principled Just-Right Consistency approach to
designing such applications, reconciling correctness with availability and
performance, based on the following insights:(i) The Conflict-Free Replicated
Data Type (CRDTs) data model supports asynchronous updates in an intuitive and
principled way.(ii) Invariants involving joint or mutually-ordered updates are
compatible with AP and can be guaranteed by Transactional Causal Consistency,
the strongest consistency model that does not compromise availability.
Regarding the remaining, &quot;CAP-sensitive&quot; invariants:(iii) For the common
pattern of Bounded Counters, we provide encapsulated data type that is proven
correct and is efficient; (iv) in the general case, static analysis can
identify when synchronisation is not necessary for correctness.Our Antidote
cloud database system supports CRDTs, Transactional Causal Consistency and the
Bounded Counter data type. Support tools help design applications by static
analysis and proof of CAP-sensitive invariants. This system supports
industrial-grade applications and has been tested experimentally with hundreds
of servers across several geo-distributed data centres.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06345</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCUT-FBP5500: A Diverse Benchmark Dataset for Multi-Paradigm Facial
  Beauty Prediction</dc:title>
 <dc:creator>Liang, Lingyu</dc:creator>
 <dc:creator>Lin, Luojun</dc:creator>
 <dc:creator>Jin, Lianwen</dc:creator>
 <dc:creator>Xie, Duorui</dc:creator>
 <dc:creator>Li, Mengru</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Facial beauty prediction (FBP) is a significant visual recognition problem to
make assessment of facial attractiveness that is consistent to human
perception. To tackle this problem, various data-driven models, especially
state-of-the-art deep learning techniques, were introduced, and benchmark
dataset become one of the essential elements to achieve FBP. Previous works
have formulated the recognition of facial beauty as a specific supervised
learning problem of classification, regression or ranking, which indicates that
FBP is intrinsically a computation problem with multiple paradigms. However,
most of FBP benchmark datasets were built under specific computation
constrains, which limits the performance and flexibility of the computational
model trained on the dataset. In this paper, we argue that FBP is a
multi-paradigm computation problem, and propose a new diverse benchmark
dataset, called SCUT-FBP5500, to achieve multi-paradigm facial beauty
prediction. The SCUT-FBP5500 dataset has totally 5500 frontal faces with
diverse properties (male/female, Asian/Caucasian, ages) and diverse labels
(face landmarks, beauty scores within [1,~5], beauty score distribution), which
allows different computational models with different FBP paradigms, such as
appearance-based/shape-based facial beauty classification/regression model for
male/female of Asian/Caucasian. We evaluated the SCUT-FBP5500 dataset for FBP
using different combinations of feature and predictor, and various deep
learning methods. The results indicates the improvement of FBP and the
potential applications based on the SCUT-FBP5500.
</dc:description>
 <dc:description>Comment: 6 pages, 14 figures, conference paper</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06349</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of eNTERFACE 2015 Workshop on Intelligent Interfaces</dc:title>
 <dc:creator>Mancas, Matei</dc:creator>
 <dc:creator>Frisson, Christian</dc:creator>
 <dc:creator>Tilmanne, Jo&#xeb;lle</dc:creator>
 <dc:creator>d'Alessandro, Nicolas</dc:creator>
 <dc:creator>Barborka, Petr</dc:creator>
 <dc:creator>Bayansar, Furkan</dc:creator>
 <dc:creator>Bernard, Francisco</dc:creator>
 <dc:creator>Fiebrink, Rebecca</dc:creator>
 <dc:creator>Heloir, Alexis</dc:creator>
 <dc:creator>Hemery, Edgar</dc:creator>
 <dc:creator>Laraba, Sohaib</dc:creator>
 <dc:creator>Moinet, Alexis</dc:creator>
 <dc:creator>Nunnari, Fabrizio</dc:creator>
 <dc:creator>Ravet, Thierry</dc:creator>
 <dc:creator>Reboursi&#xe8;re, Lo&#xef;c</dc:creator>
 <dc:creator>Sarasua, Alvaro</dc:creator>
 <dc:creator>Tits, Micka&#xeb;l</dc:creator>
 <dc:creator>Tits, No&#xe9;</dc:creator>
 <dc:creator>Zaj&#xe9;ga, Fran&#xe7;ois</dc:creator>
 <dc:creator>Alborno, Paolo</dc:creator>
 <dc:creator>Kolykhalova, Ksenia</dc:creator>
 <dc:creator>Frid, Emma</dc:creator>
 <dc:creator>Malafronte, Damiano</dc:creator>
 <dc:creator>Veld, Lisanne Huis in't</dc:creator>
 <dc:creator>Cakmak, H&#xfc;seyin</dc:creator>
 <dc:creator>Haddad, Kevin El</dc:creator>
 <dc:creator>Riche, Nicolas</dc:creator>
 <dc:creator>Leroy, Julien</dc:creator>
 <dc:creator>Marighetto, Pierre</dc:creator>
 <dc:creator>T&#xfc;rker, Bekir Berker</dc:creator>
 <dc:creator>Khaki, Hossein</dc:creator>
 <dc:creator>Pulisci, Roberto</dc:creator>
 <dc:creator>Gilmartin, Emer</dc:creator>
 <dc:creator>Haider, Fasih</dc:creator>
 <dc:creator>Cengiz, K&#xfc;bra</dc:creator>
 <dc:creator>Sulir, Martin</dc:creator>
 <dc:creator>Torre, Ilaria</dc:creator>
 <dc:creator>Marzban, Shabbir</dc:creator>
 <dc:creator>Yaz&#x131;c&#x131;, Ramazan</dc:creator>
 <dc:creator>B&#xe2;gc&#x131;, Furkan Burak</dc:creator>
 <dc:creator>K&#x131;l&#x131;, Vedat Gazi</dc:creator>
 <dc:creator>Sezer, Hilal</dc:creator>
 <dc:creator>Yenge, Sena B&#xfc;sra</dc:creator>
 <dc:creator>Delestage, Charles-Alexandre</dc:creator>
 <dc:creator>Leleu-Merviel, Sylvie</dc:creator>
 <dc:creator>Meyer-Chemenska, Muriel</dc:creator>
 <dc:creator>Schmitt, Daniel</dc:creator>
 <dc:creator>Yvart, Willy</dc:creator>
 <dc:creator>Dupont, St&#xe9;phane</dc:creator>
 <dc:creator>Altiok, Ozan Can</dc:creator>
 <dc:creator>Bumin, Ayseg&#xfc;l</dc:creator>
 <dc:creator>Dikmen, Ceren</dc:creator>
 <dc:creator>Giangreco, Ivan</dc:creator>
 <dc:creator>Heller, Silvan</dc:creator>
 <dc:creator>K&#xfc;lah, Emre</dc:creator>
 <dc:creator>Pironkov, Gueorgui</dc:creator>
 <dc:creator>Rossetto, Luca</dc:creator>
 <dc:creator>Sahillioglu, Yusuf</dc:creator>
 <dc:creator>Schuldt, Heiko</dc:creator>
 <dc:creator>Seddati, Omar</dc:creator>
 <dc:creator>Setinkaya, Yusuf</dc:creator>
 <dc:creator>Sezgin, Metin</dc:creator>
 <dc:creator>Tanase, Claudiu</dc:creator>
 <dc:creator>Toyan, Emre</dc:creator>
 <dc:creator>Wood, Sean</dc:creator>
 <dc:creator>Yeke, Doguhan</dc:creator>
 <dc:creator>Rocca, Fran&#xe7;cois</dc:creator>
 <dc:creator>De Deken, Pierre-Henri</dc:creator>
 <dc:creator>Bandrabur, Alessandra</dc:creator>
 <dc:creator>Grisard, Fabien</dc:creator>
 <dc:creator>Jean-Caurant, Axel</dc:creator>
 <dc:creator>Courboulay, Vincent</dc:creator>
 <dc:creator>Madhkour, Radhwan Ben</dc:creator>
 <dc:creator>Moreau, Ambroise</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The 11th Summer Workshop on Multimodal Interfaces eNTERFACE 2015 was hosted
by the Numediart Institute of Creative Technologies of the University of Mons
from August 10th to September 2015. During the four weeks, students and
researchers from all over the world came together in the Numediart Institute of
the University of Mons to work on eight selected projects structured around
intelligent interfaces. Eight projects were selected and their reports are
shown here.
</dc:description>
 <dc:description>Comment: 159 pages</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06352</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fostering Bilateral Patient-Clinician Engagement in Active Self-Tracking
  of Subjective Experience</dc:title>
 <dc:creator>Larsen, Jakob Eg</dc:creator>
 <dc:creator>Christiansen, Thomas Blomseth</dc:creator>
 <dc:creator>Eskelund, Kasper</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this position paper we describe select aspects of our experience with
health-related self-tracking, the data generated, and processes surrounding
those. In particular we focus on how bilateral patient-clinician engagement may
be fostered by the combination of technology and method. We exemplify with a
case study where a PTSD-suffering veteran has been self-tracking a specific
symptom precursor. The availability of high-resolution self-tracking data on
the occurrences of even a single symptom created new opportunities in the
therapeutic process for identifying underlying triggers of symptoms. The
patient was highly engaged in self-tracking and sharing the collected data. We
suggest a key reason was the collaborative effort in defining the data
collection protocol and discussion of the data. The therapist also engaged
highly in the self-tracking data, as it supported the existing therapeutic
process in reaching insights otherwise unobtainable.
</dc:description>
 <dc:description>Comment: In Proc. of the Pervasive Health 2017 conference workshop on
  Leveraging Patient-Generated Data for Collaborative Decision Making in
  Healthcare</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06352</dc:identifier>
 <dc:identifier>doi:10.1145/3154862.3154918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06353</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross Corpus Speech Emotion Classification- An Effective Transfer
  Learning Technique</dc:title>
 <dc:creator>Latif, Siddique</dc:creator>
 <dc:creator>Rana, Rajib</dc:creator>
 <dc:creator>Younis, Shahzad</dc:creator>
 <dc:creator>Qadir, Junaid</dc:creator>
 <dc:creator>Epps, Julien</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Cross-corpus speech emotion recognition can be a useful transfer learning
technique to build a robust speech emotion recognition system by leveraging
information from various speech datasets - cross-language and cross-corpus.
However, more research needs to be carried out to understand the effective
operating scenarios of cross-corpus speech emotion recognition, especially with
the utilization of the powerful deep learning techniques. In this paper, we use
five different corpora of three different languages to investigate the
cross-corpus and cross-language emotion recognition using Deep Belief Networks
(DBNs). Experimental results demonstrate that DBNs with generalization power
offers better accuracy than a discriminative method based on Sparse Auto
Encoder and SVM. Results also suggest that using a large number of languages
for training and using a small fraction of target data in training can
significantly boost accuracy compared to using the same language for training
and testing.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06357</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Modeling and Performance Assessment of Random Access with SIC</dc:title>
 <dc:creator>Mengali, Alberto</dc:creator>
 <dc:creator>De Gaudenzi, Riccardo</dc:creator>
 <dc:creator>Stefanovic, Cedomir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we review the key figures of merit to assess the performance
of advanced random access (RA) schemes exploiting physical layer coding,
repetitions and collision resolution techniques. We then investigate RA
modeling aspects and their impact on the figures of merit for the exemplary
advanced RA schemes: Contention Resolution Diversity Slotted ALOHA (CRDSA),
Irregular Repetition Slotted ALOHA (IRSA), Coded Slotted ALOHA (CSA) and
Enhanced Spread-Spectrum ALOHA (E-SSA). We show that typical simplifications of
the reception model when used to optimize RA schemes lead to inaccurate
findings, both in terms of parameter optimization and figures of merit, such as
the packet loss ratio (PLR) and throughput. We also derive a generic RA energy
efficiency model able to compare the schemes in terms of the energy required to
transmit a packet. The combination of achievable RA throughput at the target
PLR and energy efficiency, for the same average user power investment per frame
and occupied bandwidth, shows that E-SSA, which is an unslotted scheme,
provides the best overall performance, while, in terms of the slotted schemes,
CRDSA outperforms the more elaborated IRSA and CSA. This surprising results is
due to the fact that the IRSA and CSA optimization has so far been performed
using RA channel models that are not accurately reflecting the physical layer
receiver behavior. We conclude by providing insights on how to include more
accurate reception models in the IRSA and CSA design and optimization.
</dc:description>
 <dc:description>Comment: To appear in IEEE Journal on Selected Areas in Communications -
  Special Issue on Advances in Satellite Communications</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06358</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse recovery based on q-ratio constrained minimal singular values</dc:title>
 <dc:creator>Zhou, Zhiyong</dc:creator>
 <dc:creator>Yu, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study verifiable sufficient conditions and computable performance bounds
for sparse recovery algorithms such as the Basis Pursuit, the Dantzig selector
and the Lasso estimator, in terms of a newly defined family of quality measures
for the measurement matrices. With high probability, the developed measures for
subgaussian random matrices are bounded away from zero as long as the number of
measurements is reasonably large. Comparing to the restricted isotropic
constant based performance analysis, the arguments in this paper are much more
concise and the obtained bounds are tighter. Numerical experiments are
presented to illustrate our theoretical results.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06368</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>No Silk Road for Online Gamers!: Using Social Network Analysis to Unveil
  Black Markets in Online Games</dc:title>
 <dc:creator>Lee, Eunjo</dc:creator>
 <dc:creator>Woo, Jiyoung</dc:creator>
 <dc:creator>Kim, Hyoungshick</dc:creator>
 <dc:creator>Kim, Huy Kang</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online game involves a very large number of users who are interconnected and
interact with each other via the Internet. We studied the characteristics of
exchanging virtual goods with real money through processes called &quot;real money
trading (RMT).&quot; This exchange might influence online game user behaviors and
cause damage to the reputation of game companies. We examined in-game
transactions to reveal RMT by constructing a social graph of virtual goods
exchanges in an online game and identifying network communities of users.
  We analyzed approximately 6,000,000 transactions in a popular online game and
inferred RMT transactions by comparing the RMT transactions crawled from an
out-game market. Our findings are summarized as follows: (1) the size of the
RMT market could be approximately estimated; (2) professional RMT providers
typically form a specific network structure (either star-shape or chain) in the
trading network, which can be used as a clue for tracing RMT transactions; and
(3) the observed RMT market has evolved over time into a monopolized market
with a small number of large-sized virtual goods providers.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures, In Proceedings of the 27th International World
  Wide Web Conference (WWW) 2018</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06374</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient SWIPT in IoT Distributed Antenna Systems</dc:title>
 <dc:creator>Huang, Yuwen</dc:creator>
 <dc:creator>Liu, Mengyu</dc:creator>
 <dc:creator>Liu, Yuan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The rapid growth of Internet of Things (IoT) dramatically increases power
consumption of wireless devices. Simultaneous wireless information and power
transfer (SWIPT) is a promising solution for sustainable operation of IoT
devices. In this paper, we study energy efficiency (EE) in SWIPT-based
distributed antenna system (DAS), where power splitting (PS) is applied at IoT
devices to coordinate the energy harvesting (EH) and information decoding (ID)
processes by varying transmit power of distributed antenna (DA) ports and PS
ratios of IoT devices. In the case of single IoT device, we find the optimal
closed-form solution by deriving some useful properties based on
Karush-Kuhn-Tucker (KKT) conditions and the solution is no need for numerical
iterations. For the case of multiple IoT devices, we propose an efficient
suboptimal algorithm to solve the EE maximization problem. Simulation results
show that the proposed schemes achieve better EE performance compared with
other benchmark schemes in both single and multiple IoT devices cases.
</dc:description>
 <dc:description>Comment: accepted by the IEEE Internet of Things Journal</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06378</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introducing ReQuEST: an Open Platform for Reproducible and
  Quality-Efficient Systems-ML Tournaments</dc:title>
 <dc:creator>Moreau, Thierry</dc:creator>
 <dc:creator>Lokhmotov, Anton</dc:creator>
 <dc:creator>Fursin, Grigori</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Co-designing efficient machine learning based systems across the whole
hardware/software stack to trade off speed, accuracy, energy and costs is
becoming extremely complex and time consuming. Researchers often struggle to
evaluate and compare different published works across rapidly evolving software
frameworks, heterogeneous hardware platforms, compilers, libraries, algorithms,
data sets, models, and environments.
  We present our community effort to develop an open co-design tournament
platform with an online public scoreboard. It will gradually incorporate best
research practices while providing a common way for multidisciplinary
researchers to optimize and compare the quality vs. efficiency Pareto
optimality of various workloads on diverse and complete hardware/software
systems. We want to leverage the open-source Collective Knowledge framework and
the ACM artifact evaluation methodology to validate and share the complete
machine learning system implementations in a standardized, portable, and
reproducible fashion. We plan to hold regular multi-objective optimization and
co-design tournaments for emerging workloads such as deep learning, starting
with ASPLOS'18 (ACM conference on Architectural Support for Programming
Languages and Operating Systems - the premier forum for multidisciplinary
systems research spanning computer architecture and hardware, programming
languages and compilers, operating systems and networking) to build a public
repository of the most efficient machine learning algorithms and systems which
can be easily customized, reused and built upon.
</dc:description>
 <dc:description>Comment: ReQuEST tournament website: http://cKnowledge.org/request</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06391</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoupling schemes for predicting compressible fluid flows</dc:title>
 <dc:creator>Vabishchevich, Petr N.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Numerical simulation of compressible fluid flows is performed using the Euler
equations. They include the scalar advection equation for the density, the
vector advection equation for the velocity and a given pressure dependence on
the density. An approximate solution of an initial--boundary value problem is
calculated using the finite element approximation in space. The fully implicit
two-level scheme is used for discretization in time. Numerical implementation
is based on Newton's method. The main attention is paid to fulfilling
conservation laws for the mass and total mechanical energy for the discrete
formulation. Two-level schemes of splitting by physical processes are employed
for numerical solving problems of barotropic fluid flows. For a transition from
one time level to the next one, an iterative process is used, where at each
iteration the linearized scheme is implemented via solving individual problems
for the density and velocity. Possibilities of the proposed schemes are
illustrated by numerical results for a two--dimensional model problem with
density perturbations.
</dc:description>
 <dc:description>Comment: 20 pages, 11 figures,</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06393</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dissection of a Bug Dataset: Anatomy of 395 Patches from Defects4J</dc:title>
 <dc:creator>Sobreira, Victor</dc:creator>
 <dc:creator>Durieux, Thomas</dc:creator>
 <dc:creator>Madeiral, Fernanda</dc:creator>
 <dc:creator>Monperrus, Martin</dc:creator>
 <dc:creator>Maia, Marcelo A.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Well-designed and publicly available datasets of bugs are an invaluable asset
to advance research fields such as fault localization and program repair. They
allow directly and fairly comparison between competing techniques and also the
replication of experiments. These datasets need to be deeply understood by
researchers: the answer for questions like &quot;which bugs can my technique
handle?&quot; and &quot;for which bugs is my technique effective?&quot; depends on the
comprehension of properties related to bugs and their patches. However, such
properties are usually not included in the datasets, and there is still no
widely adopted methodology for characterizing bugs and patches. In this work,
we deeply study 395 patches of the Defects4J dataset. Quantitative properties
(patch size and spreading) were automatically extracted, whereas qualitative
ones (repair actions and patterns) were manually extracted using a thematic
analysis-based approach. We found that 1) the median size of Defects4J patches
is four lines, and almost 30% of the patches contain only addition of lines; 2)
92% of the patches change only one file, and 38% has no spreading at all; 3)
the top-3 most applied repair actions are addition of method calls,
conditionals, and assignments, occurring in 77% of the patches; and 4) nine
repair patterns were found for 95% of the patches, where the most prevalent,
appearing in 43% of the patches, is on conditional blocks. These results are
useful for researchers to perform advanced analysis on their techniques'
results based on Defects4J. Moreover, our set of properties can be used to
characterize and compare different bug datasets.
</dc:description>
 <dc:description>Comment: Accepted for SANER'18 (25th edition of IEEE International Conference
  on Software Analysis, Evolution and Reengineering), Campobasso, Italy</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06396</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Possible and Certain Answers over Order-Incomplete Data</dc:title>
 <dc:creator>Amarilli, Antoine</dc:creator>
 <dc:creator>Ba, Mouhamadou Lamine</dc:creator>
 <dc:creator>Deutch, Daniel</dc:creator>
 <dc:creator>Senellart, Pierre</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  This paper studies the complexity of query evaluation for databases whose
relations are partially ordered; the problem commonly arises when combining
ordered data from multiple sources. We focus on queries in a useful fragment of
SQL, namely positive relational algebra with aggregates, whose bag semantics we
extend to the partially ordered setting. Our semantics leads to the study of
two main computational problems, namely the possibility and certainty of query
answers. We show that these problems are respectively NP-complete and
coNP-complete, but identify tractable cases depending on the query operators or
input partial orders. We further introduce a duplicate elimination operator and
study its effect on the complexity results.
</dc:description>
 <dc:description>Comment: 63 pages, 48 references. Submitted. Extended journal version of
  arXiv:1707.07222</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06397</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Makes Good Synthetic Training Data for Learning Disparity and
  Optical Flow Estimation?</dc:title>
 <dc:creator>Mayer, Nikolaus</dc:creator>
 <dc:creator>Ilg, Eddy</dc:creator>
 <dc:creator>Fischer, Philipp</dc:creator>
 <dc:creator>Hazirbas, Caner</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:creator>Dosovitskiy, Alexey</dc:creator>
 <dc:creator>Brox, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The finding that very large networks can be trained efficiently and reliably
has led to a paradigm shift in computer vision from engineered solutions to
learning formulations. As a result, the research challenge shifts from devising
algorithms to creating suitable and abundant training data for supervised
learning. How to efficiently create such training data? The dominant data
acquisition method in visual recognition is based on web data and manual
annotation. Yet, for many computer vision problems, such as stereo or optical
flow estimation, this approach is not feasible because humans cannot manually
enter a pixel-accurate flow field. In this paper, we promote the use of
synthetically generated data for the purpose of training deep networks on such
tasks.We suggest multiple ways to generate such data and evaluate the influence
of dataset properties on the performance and generalization properties of the
resulting networks. We also demonstrate the benefit of learning schedules that
use different types of data at selected stages of the training process.
</dc:description>
 <dc:description>Comment: added references (UCL dataset)</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06400</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hikester - the event management application</dc:title>
 <dc:creator>Khatipov, Rinat</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Negimatzhanov, Aydar</dc:creator>
 <dc:creator>Rivera, Victor</dc:creator>
 <dc:creator>Zakirov, Anvar</dc:creator>
 <dc:creator>Zamaleev, Ilgiz</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Today social networks and services are one of the most important part of our
everyday life. Most of the daily activities, such as communicating with
friends, reading news or dating is usually done using social networks. However,
there are activities for which social networks do not yet provide adequate
support. This paper focuses on event management and introduces &quot;Hikester&quot;. The
main objective of this service is to provide users with the possibility to
create any event they desire and to invite other users. &quot;Hikester&quot; supports the
creation and management of events like attendance of football matches, quest
rooms, shared train rides or visit of museums in foreign countries. Here we
discuss the project architecture as well as the detailed implementation of the
system components: the recommender system, the spam recognition service and the
parameters optimizer.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06402</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CGQ: Relationship-Aware Contextual Graph Querying in Large Networks</dc:title>
 <dc:creator>Vachery, Jithin</dc:creator>
 <dc:creator>Arora, Akhil</dc:creator>
 <dc:creator>Ranu, Sayan</dc:creator>
 <dc:creator>Bhattacharya, Arnab</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The phenomenal growth of graph data from a wide-variety of real-world
applications has rendered graph querying to be a problem of paramount
importance. Traditional techniques use structural as well as node similarities
to find matches of a given query graph in a (large) target graph. However,
almost all previous research has tacitly ignored the presence of relationships
and context (usually manifested in the form of node/edge label distributions)
in the query. In this paper, we propose CGQ -- Relationship-Aware Contextual
Graph Querying} for real-world graphs. Given a query graph and a target graph,
CGQ identifies the (top-k) maximal common subgraphs between the query and the
target graphs with the highest contextual similarity. We prove that the problem
is NP-hard and APX-Hard. To overcome this computational bottleneck, we propose
a hierarchical index, CGQ-Tree, with its associated CGQ search algorithm.
Empirically, the CGQ search algorithm is capable of achieving speed-ups of up
to three orders of magnitude over a baseline strategy. Our experiments show
that CGQ is effective, efficient and scalable.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06407</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Size vs. Structure in Training Corpora for Word Embedding Models:
  Araneum Russicum Maximum and Russian National Corpus</dc:title>
 <dc:creator>Kutuzov, Andrey</dc:creator>
 <dc:creator>Kunilovskaya, Maria</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we present a distributional word embedding model trained on
one of the largest available Russian corpora: Araneum Russicum Maximum (over 10
billion words crawled from the web). We compare this model to the model trained
on the Russian National Corpus (RNC). The two corpora are much different in
their size and compilation procedures. We test these differences by evaluating
the trained models against the Russian part of the Multilingual SimLex999
semantic similarity dataset. We detect and describe numerous issues in this
dataset and publish a new corrected version. Aside from the already known fact
that the RNC is generally a better training corpus than web corpora, we
enumerate and explain fine differences in how the models process semantic
similarity task, what parts of the evaluation set are difficult for particular
models and why. Additionally, the learning curves for both models are
described, showing that the RNC is generally more robust as training material
for this task.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06407</dc:identifier>
 <dc:identifier>In: van der Aalst W. et al. (eds) Analysis of Images, Social
  Networks and Texts. AIST 2017. Lecture Notes in Computer Science, vol 10716.
  Springer, Cham</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-73013-4_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06408</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PRESTO: Probabilistic Cardinality Estimation for RDF Queries Based on
  Subgraph Overlapping</dc:title>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Siow, Eugene</dc:creator>
 <dc:creator>Madaan, Aastha</dc:creator>
 <dc:creator>Tiropanis, Thanassis</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In query optimisation accurate cardinality estimation is essential for
finding optimal query plans. It is especially challenging for RDF due to the
lack of explicit schema and the excessive occurrence of joins in RDF queries.
Existing approaches typically collect statistics based on the counts of triples
and estimate the cardinality of a query as the product of its join components,
where errors can accumulate even when the estimation of each component is
accurate. As opposed to existing methods, we propose PRESTO, a cardinality
estimation method that is based on the counts of subgraphs instead of triples
and uses a probabilistic method to estimate cardinalities of RDF queries as a
whole. PRESTO avoids some major issues of existing approaches and is able to
accurately estimate arbitrary queries under a bound memory constraint. We
evaluate PRESTO with YAGO and show that PRESTO is more accurate for both simple
and complex queries.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06421</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medical Photoacoustic Beamforming Using Minimum Variance-Based Delay
  Multiply and Sum</dc:title>
 <dc:creator>Mozaffarzadeh, Moein</dc:creator>
 <dc:creator>Mahloojifar, Ali</dc:creator>
 <dc:creator>Orooji, Mahdi</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Delay-and-Sum (DAS) beamformer is the most common beamforming algorithm in
Photoacoustic imaging (PAI) due to its simple implementation and real time
imaging. However, it provides poor resolution and high levels of sidelobe. A
new algorithm named Delay-Multiply-and-Sum (DMAS) was introduced. Using DMAS
leads to lower levels of sidelobe compared to DAS, but resolution is not
satisfying yet. In this paper, a novel beamformer is introduced based on the
combination of Minimum Variance (MV) adaptive beamforming and DMAS, so-called
Minimum Variance-Based DMAS (MVB-DMAS). It is shown that expanding the DMAS
equation leads to some terms which contain a DAS equation. It is proposed to
use MV adaptive beamformer instead of existing DAS inside the DMAS algebra
expansion. MVB-DMAS is evaluated numerically compared to DAS, DMAS and MV and
Signal-to-noise ratio (SNR) metric is presented. It is shown that MVB-DMAS
leads to higher image quality and SNR for about 13 dB, 3 dB and 2 dB in
comparison with DAS, DMAS and MV, respectively.
</dc:description>
 <dc:description>Comment: SPIE Digital Optical Technologies, 2017, Munich, Germany. arXiv admin
  note: substantial text overlap with arXiv:1709.07965</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06421</dc:identifier>
 <dc:identifier>Proceedings Volume 10335, Digital Optical Technologies 2017;
  1033522 (2017)</dc:identifier>
 <dc:identifier>doi:10.1117/12.2269608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06422</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating neural network explanation methods using hybrid documents and
  morphological prediction</dc:title>
 <dc:creator>Poerner, Nina</dc:creator>
 <dc:creator>Sch&#xfc;tze, Hinrich</dc:creator>
 <dc:creator>Roth, Benjamin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose two novel paradigms for evaluating neural network explanations in
NLP. The first paradigm works on hybrid documents, the second exploits
morphosyntactic agreements. Neither paradigm requires manual annotations;
instead, a relevance ground truth is generated automatically. In our
experiments, successful explanations for Long Short Term Memory networks
(LSTMs) were produced by a decomposition of memory cells (Murdoch &amp; Szlam,
2017), while for convolutional neural networks, a gradient-based method by
(Denil et al., 2014) works well. We also introduce LIMSSE, a substring-based
extension of LIME (Ribeiro et al., 2016) that produces the most successful
explanations in the hybrid document experiment.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06423</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum spanning tree release under differential privacy constraints</dc:title>
 <dc:creator>Pinot, Rafael</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We investigate the problem of nodes clustering under privacy constraints when
representing a dataset as a graph. Our contribution is threefold. First we
formally define the concept of differential privacy for structured databases
such as graphs, and give an alternative definition based on a new neighborhood
notion between graphs. This definition is adapted to particular frameworks that
can be met in various application fields such as genomics, world wide web,
population survey, etc. Second, we introduce a new algorithm to tackle the
issue of privately releasing an approximated minimum spanning tree topology for
a simple-undirected-weighted graph. It provides a simple way of producing the
topology of a private almost minimum spanning tree which outperforms, in most
cases, the state of the art &quot;Laplace mechanism&quot; in terms of
weight-approximation error.
  Finally, we propose a theoretically motivated method combining a sanitizing
mechanism (such as Laplace or our new algorithm) with a Minimum Spanning Tree
(MST)-based clustering algorithm. It provides an accurate method for nodes
clustering in a graph while keeping the sensitive information contained in the
edges weights of the private graph. We provide some theoretical results on the
robustness of an almost minimum spanning tree construction for Laplace
sanitizing mechanisms. These results exhibit which conditions the graph weights
should respect in order to consider that the nodes form well separated clusters
both for Laplace and our algorithm as sanitizing mechanism. The method has been
experimentally evaluated on simulated data, and preliminary results show the
good behavior of the algorithm while identifying well separated clusters.
</dc:description>
 <dc:description>Comment: Thesis of Master Degree of Statistics, Universit\'e Paris 6 Pierre et
  Marie Curie</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06428</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CrashScope: A Practical Tool for Automated Testing of Android
  Applications</dc:title>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:creator>Linares-Vasquez, Mario</dc:creator>
 <dc:creator>Bernal-Cardenas, Carlos</dc:creator>
 <dc:creator>Vendome, Christopher</dc:creator>
 <dc:creator>Poshyvanyk, Denys</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Unique challenges arise when testing mobile applications due to their
prevailing event-driven nature and complex contextual features (e.g. sensors,
notifications). Current automated input generation approaches for Android apps
are typically not practical for developers to use due to required
instrumentation or platform dependence and generally do not effectively
exercise contextual features. To better support developers in mobile testing
tasks, in this demo we present a novel, automated tool called CrashScope. This
tool explores a given Android app using systematic input generation, according
to several strategies informed by static and dynamic analyses, with the
intrinsic goal of triggering crashes. When a crash is detected, CrashScope
generates an augmented crash report containing screenshots, detailed crash
reproduction steps, the captured exception stack trace, and a fully replayable
script that automatically reproduces the crash on a target device(s). Results
of preliminary studies show that CrashScope is able to uncover about as many
crashes as other state of the art tools, while providing detailed useful crash
reports and test scripts to developers. Website:
www.crashscope-android.com/crashscope-home Video url:
https://youtu.be/ii6S1JF6xDw
</dc:description>
 <dc:description>Comment: 4 pages, Accepted in the Proceedings of 39th IEEE/ACM International
  Conference on Software Engineering (ICSE'17). arXiv admin note: text overlap
  with arXiv:1706.01130</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06428</dc:identifier>
 <dc:identifier>doi:10.1109/ICSE-C.2017.16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06430</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Analysis of Belief Propagation on Gaussian Graphical Models</dc:title>
 <dc:creator>Du, Jian</dc:creator>
 <dc:creator>Ma, Shaodan</dc:creator>
 <dc:creator>Wu, Yik-Chung</dc:creator>
 <dc:creator>Kar, Soummya</dc:creator>
 <dc:creator>Moura, Jos&#xe9; M. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Gaussian belief propagation (GBP) is a recursive computation method that is
widely used in inference for computing marginal distributions efficiently.
Depending on how the factorization of the underlying joint Gaussian
distribution is performed, GBP may exhibit different convergence properties as
different factorizations may lead to fundamentally different recursive update
structures. In this paper, we study the convergence of GBP derived from the
factorization based on the distributed linear Gaussian model. The motivation is
twofold. From the factorization viewpoint, i.e., by specifically employing a
factorization based on the linear Gaussian model, in some cases, we are able to
bypass difficulties that exist in other convergence analysis methods that use a
different (Gaussian Markov random field) factorization. From the distributed
inference viewpoint, the linear Gaussian model readily conforms to the physical
network topology arising in large-scale networks, and, is practically useful.
For the distributed linear Gaussian model, under mild assumptions, we show
analytically three main results: the GBP message inverse variance converges
exponentially fast to a unique positive limit for arbitrary nonnegative
initialization; we provide a necessary and sufficient convergence condition for
the belief mean to converge to the optimal value; and, when the underlying
factor graph is given by the union of a forest and a single loop, we show that
GBP always converges.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1611.02010</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06432</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Kronecker Component Analysis</dc:title>
 <dc:creator>Bahri, Mehdi</dc:creator>
 <dc:creator>Panagakis, Yannis</dc:creator>
 <dc:creator>Zafeiriou, Stefanos</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Dictionary learning and component analysis models are fundamental in learning
compact representations that are relevant to a given task (feature extraction,
dimensionality reduction, denoising, etc.). The model complexity is encoded by
means of specific structure, such as sparsity, low-rankness, or nonnegativity.
Unfortunately, approaches like K-SVD - that learn dictionaries for sparse
coding via Singular Value Decomposition (SVD) - are hard to scale to
high-volume and high-dimensional visual data, and fragile in the presence of
outliers. Conversely, robust component analysis methods such as the Robust
Principle Component Analysis (RPCA) are able to recover low-complexity (e.g.,
low-rank) representations from data corrupted with noise of unknown magnitude
and support, but do not provide a dictionary that respects the structure of the
data (e.g., images), and also involve expensive computations. In this paper, we
propose a novel Kronecker-decomposable component analysis model, coined as
Robust Kronecker Component Analysis (RKCA), that combines ideas from sparse
dictionary learning and robust component analysis. RKCA has several appealing
properties, including robustness to gross corruption; it can be used for
low-rank modeling, and leverages separability to solve significantly smaller
problems. We design an efficient learning algorithm by drawing links with a
restricted form of tensor factorization, and analyze its optimality and
low-rankness properties. The effectiveness of the proposed approach is
demonstrated on real-world applications, namely background subtraction and
image denoising and completion, by performing a thorough comparison with the
current state of the art.
</dc:description>
 <dc:description>Comment: In review for IEEE Transactions on Pattern Analysis and Machine
  Intelligence, Special Issue on Compact and Efficient Feature Representation
  and Learning in Computer Vision. Contains appendices. arXiv admin note: text
  overlap with arXiv:1703.07886</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06434</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EffNet: An Efficient Structure for Convolutional Neural Networks</dc:title>
 <dc:creator>Freeman, Ido</dc:creator>
 <dc:creator>Roese-Koerner, Lutz</dc:creator>
 <dc:creator>Kummert, Anton</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  With the ever increasing application of Convolutional Neural Networks to
costumer products the need emerges for models which can efficiently run on
embedded, mobile hardware. Slimmer models have therefore become a hot research
topic with multiple different approaches which vary from binary networks to
revised convolution layers. We offer our contribution to the latter and propose
a novel convolution block which significantly reduces the computational burden
while surpassing the current state-of-the-art. Our model, dubbed EffNet, is
optimised for models which are slim to begin with and is created to tackle
issues in existing models such as MobileNet and ShuffleNet.
</dc:description>
 <dc:description>Comment: Under Review for ICIP 2018</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06436</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Resource-Light Method for Cross-Lingual Semantic Textual Similarity</dc:title>
 <dc:creator>Glava&#x161;, Goran</dc:creator>
 <dc:creator>Franco-Salvador, Marc</dc:creator>
 <dc:creator>Ponzetto, Simone Paolo</dc:creator>
 <dc:creator>Rosso, Paolo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recognizing semantically similar sentences or paragraphs across languages is
beneficial for many tasks, ranging from cross-lingual information retrieval and
plagiarism detection to machine translation. Recently proposed methods for
predicting cross-lingual semantic similarity of short texts, however, make use
of tools and resources (e.g., machine translation systems, syntactic parsers or
named entity recognition) that for many languages (or language pairs) do not
exist. In contrast, we propose an unsupervised and a very resource-light
approach for measuring semantic similarity between texts in different
languages. To operate in the bilingual (or multilingual) space, we project
continuous word vectors (i.e., word embeddings) from one language to the vector
space of the other language via the linear translation model. We then align
words according to the similarity of their vectors in the bilingual embedding
space and investigate different unsupervised measures of semantic similarity
exploiting bilingual embeddings and word alignments. Requiring only a
limited-size set of word translation pairs between the languages, the proposed
approach is applicable to virtually any pair of languages for which there
exists a sufficiently large corpus, required to learn monolingual word
embeddings. Experimental results on three different datasets for measuring
semantic textual similarity show that our simple resource-light approach
reaches performance close to that of supervised and resource intensive methods,
displaying stability across different language pairs. Furthermore, we evaluate
the proposed method on two extrinsic tasks, namely extraction of parallel
sentences from comparable corpora and cross lingual plagiarism detection, and
show that it yields performance comparable to those of complex
resource-intensive state-of-the-art models for the respective tasks.
</dc:description>
 <dc:description>Comment: Accepted for publication in Knowledge-Based Systems journal</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06445</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quality Classified Image Analysis with Application to Face Detection and
  Recognition</dc:title>
 <dc:creator>Yang, Fei</dc:creator>
 <dc:creator>Zhang, Qian</dc:creator>
 <dc:creator>Wang, Miaohui</dc:creator>
 <dc:creator>Qiu, Guoping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Motion blur, out of focus, insufficient spatial resolution, lossy compression
and many other factors can all cause an image to have poor quality. However,
image quality is a largely ignored issue in traditional pattern recognition
literature. In this paper, we use face detection and recognition as case
studies to show that image quality is an essential factor which will affect the
performances of traditional algorithms. We demonstrated that it is not the
image quality itself that is the most important, but rather the quality of the
images in the training set should have similar quality as those in the testing
set. To handle real-world application scenarios where images with different
kinds and severities of degradation can be presented to the system, we have
developed a quality classified image analysis framework to deal with images of
mixed qualities adaptively. We use deep neural networks first to classify
images based on their quality classes and then design a separate face detector
and recognizer for images in each quality class. We will present experimental
results to show that our quality classified framework can accurately classify
images based on the type and severity of image degradations and can
significantly boost the performances of state-of-the-art face detector and
recognizer in dealing with image datasets containing mixed quality images.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06447</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Environment-Aware Minimum-Cost Wireless Backhaul Network Planning with
  Full-Duplex Links</dc:title>
 <dc:creator>Taghizadeh, Omid</dc:creator>
 <dc:creator>Sirvi, Praveen</dc:creator>
 <dc:creator>Narasimha, Santosh</dc:creator>
 <dc:creator>Calvo, Jose Angel Leon</dc:creator>
 <dc:creator>Mathar, Rudolf</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this work, we address the joint design of the wireless backhauling network
topology as well as the frequency/power allocation on the wireless links, where
nodes are capable of full-duplex (FD) operation. The proposed joint design
enables the coexistence of multiple wireless links at the same channel,
resulting in an enhanced spectral efficiency. Moreover, it enables the usage of
FD capability when/where it is gainful. In this regard, a
mixed-integer-linear-program (MILP) is proposed, aiming at a minimum cost
design for the wireless backhaul network, considering the required rate demand
at each base station. Moreover, a re-tunning algorithm is proposed which reacts
to the slight changes in the network condition, e.g., channel attenuation or
rate demand, by adjusting the transmit power at the wireless links. In this
regard, a successive inner approximation (SIA)- based design is proposed, where
in each step a convex subproblem is solved. Numerical simulations show a
reduction in the overall network cost via the utilization of the proposed
designs, thanks to the coexistence of multiple wireless links on the same
channel due to the FD capability.
</dc:description>
 <dc:description>Comment: Submuitted to IEEE for publication</dc:description>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06448</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Congestion Control System Based on VANET for Small Length Roads</dc:title>
 <dc:creator>Jain, Ruchin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  As vehicle population has been increasing on a daily basis, this leads
towards increased number of accidents. To overcome this issue, Vehicular Ad Hoc
Network (VANET) has come up with lot of novel ideas such as vehicular
communication, navigation and traffic controlling. In this study, the main
focus is on congestion control at the intersections which result from unclear
ahead. For this purpose, a city lane and intersection model has been proposed
to manage vehicle mobility. It shows the actual vehicle to vehicle and vehicle
to traffic infrastructure communication. The experiment was conducted using
Network Simulator 2 (NS 2). The implementation required modelling the road side
unit, traffic control unit, and on-board unit along the roadside. In the
simulation, including traffic volume, the distance between two signals,
end-to-end delay, packet delivery ratio, throughput and packet lost were taken
into consideration. These parameters ensure efficient communication between the
traffic signals. This results in improved congestion control and road safety,
since the vehicles will be signalled not to enter the junction box and
information about other vehicles.
</dc:description>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06448</dc:identifier>
 <dc:identifier>Annals of Emerging Technologies in Computing (AETiC), Print ISSN:
  2516-0281, Online ISSN: 2516-029X, pp. 17-21, Vol. 2, No. 1, 1st January
  2018, Published by International Association of Educators and Researchers
  (IAER)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06449</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Preference Learning Based Edge Caching for Fog-RAN</dc:title>
 <dc:creator>Jiang, Yanxiang</dc:creator>
 <dc:creator>Ma, Miaoli</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Zheng, Fuchun</dc:creator>
 <dc:creator>You, Xiaohu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the edge caching problem in fog radio access networks (F-RAN)
is investigated. By maximizing the overall cache hit rate, the edge caching
optimization problem is formulated to find the optimal edge caching policy. We
consider content popularity in terms of time and space from the perspective of
regional users. Taking into account that users request the contents they are
interested in, we propose an online content popularity prediction algorithm by
leveraging the content features and user preferences, and an offline user
preference learning algorithm by using the &quot;Online Gradient Descent&quot; (OGD)
method and the &quot;Follow The (Proximally) Regularized Leader&quot; (FTRL-Proximal)
method. Our proposed edge caching policy not only can promptly predict the
future content popularity in an online fashion with low computational
complexity, but it also can track the content popularity with spatial and
temporal popularity dynamics in time without delay. We theoretically derive the
upper bound of the popularity prediction error, the lower bound of the cache
hit rate, and the regret bound of the overall cache hit rate of our proposed
edge caching policy. Furthermore, to implement our proposed edge caching
policy, we design two learning based edge caching architectures for F-RAN,
which have the capability of flexibly setting the monitoring cycle and is
effective in various edge caching scenarios. Simulation results show that the
overall cache hit rate of our proposed policy is superior to those of the
traditional policies and asymptotically approaches the optimal performance.
</dc:description>
 <dc:description>Comment: 31 pages, 9 figures. This work has been accepted by IEEE GLOBECOM
  2017 and submitted to IEEE J. Sel. Areas Commun</dc:description>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06450</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Green Cell-less Design for RF-Wireless Power Transfer Networks</dc:title>
 <dc:creator>Tran, Ha-Vu</dc:creator>
 <dc:creator>Kaddoum, Georges</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper studies a new concept so-called green cell-less radio frequency
(RF) wireless power transfer (WPT) networks. We consider a scenario in which
multiple indoor access points (APs) equipped with outdoor energy harvesters are
connected with a central control unit via backhaul links. Further, such APs
exploit the harnessed green energy to recharge wirelessly indoor devices under
the coordination of the control unit. Considering the network, we focus on AP
selection and beamforming optimization to maximize the total energy harvesting
(EH) rate. The resulting mathematical problem has the form of mixed-integer
optimization that is intractable to solve. Thus, we propose an algorithm to
tackle this difficulty. Through numerical results, we show the advantages of
the cell-less design over the conventional small-cell one to validate our
ideas. In particular, the issue on safety requirements of human exposure to RF
radiation is discussed. Finally, potential future research is provided.
</dc:description>
 <dc:description>Comment: 7 pages, 8 figures, accepted for publication in IEEE Wireless
  Communications and Networking Conference, 15-18 April 2018, Barcelona, Spain</dc:description>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06451</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predictive Pre-allocation for Low-latency Uplink Access in Industrial
  Wireless Networks</dc:title>
 <dc:creator>Li, Mingyan</dc:creator>
 <dc:creator>Guan, Xinping</dc:creator>
 <dc:creator>Hua, Cunqing</dc:creator>
 <dc:creator>Chen, Cailian</dc:creator>
 <dc:creator>Lyu, Ling</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Driven by mission-critical applications in modern industrial systems, the 5th
generation (5G) communication system is expected to provide ultra-reliable
low-latency communications (URLLC) services to meet the quality of service
(QoS) demands of industrial applications. However, these stringent requirements
cannot be guaranteed by its conventional dynamic access scheme due to the
complex signaling procedure. A promising solution to reduce the access delay is
the pre-allocation scheme based on the semi-persistent scheduling (SPS)
technique, which however may lead to low spectrum utilization if the allocated
resource blocks (RBs) are not used. In this paper, we aim to address this issue
by developing DPre, a predictive pre-allocation framework for uplink access
scheduling of delay-sensitive applications in industrial process automation.
The basic idea of DPre is to explore and exploit the correlation of data
acquisition and access behavior between nodes through static and dynamic
learning mechanisms in order to make judicious resource per-allocation
decisions. We evaluate the effectiveness of DPre based on several monitoring
applications in a steel rolling production process. Simulation results
demonstrate that DPre achieves better performance in terms of the prediction
accuracy, which can effectively increase the rewards of those reserved
resources.
</dc:description>
 <dc:description>Comment: Full version (accepted by INFOCOM 2018)</dc:description>
 <dc:date>2018-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06452</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collision Selective Visual Neural Network Inspired by LGMD2 Neurons in
  Juvenile Locusts</dc:title>
 <dc:creator>Fu, Qinbing</dc:creator>
 <dc:creator>Hu, Cheng</dc:creator>
 <dc:creator>Yue, Shigang</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  For autonomous robots in dynamic environments mixed with human, it is vital
to detect impending collision quickly and robustly. The biological visual
systems evolved over millions of years may provide us efficient solutions for
collision detection in complex environments. In the cockpit of locusts, two
Lobula Giant Movement Detectors, i.e. LGMD1 and LGMD2, have been identified
which respond to looming objects rigorously with high firing rates. Compared to
LGMD1, LGMD2 matures early in the juvenile locusts with specific selectivity to
dark moving objects against bright background in depth while not responding to
light objects embedded in dark background - a similar situation which ground
vehicles and robots are facing with. However, little work has been done on
modeling LGMD2, let alone its potential in robotics and other vision-based
applications. In this article, we propose a novel way of modeling LGMD2 neuron,
with biased ON and OFF pathways splitting visual streams into parallel channels
encoding brightness increments and decrements separately to fulfill its
selectivity. Moreover, we apply a biophysical mechanism of spike frequency
adaptation to shape the looming selectivity in such a collision-detecting
neuron model. The proposed visual neural network has been tested with
systematic experiments, challenged against synthetic and real physical stimuli,
as well as image streams from the sensor of a miniature robot. The results
demonstrated this framework is able to detect looming dark objects embedded in
bright backgrounds selectively, which make it ideal for ground mobile
platforms. The robotic experiments also showed its robustness in collision
detection - it performed well for near range navigation in an arena with many
obstacles. Its enhanced collision selectivity to dark approaching objects
versus receding and translating ones has also been verified via systematic
experiments.
</dc:description>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06457</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative analysis of patch-based fully convolutional neural networks
  for tissue segmentation on brain magnetic resonance imaging</dc:title>
 <dc:creator>Bernal, Jose</dc:creator>
 <dc:creator>Kushibar, Kaisar</dc:creator>
 <dc:creator>Cabezas, Mariano</dc:creator>
 <dc:creator>Valverde, Sergi</dc:creator>
 <dc:creator>Oliver, Arnau</dc:creator>
 <dc:creator>Llad&#xf3;, Xavier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accurate brain tissue segmentation in Magnetic Resonance Imaging (MRI) has
attracted the attention of medical doctors and researchers since variations in
tissue volume help in diagnosing and monitoring neurological diseases. Several
proposals have been designed throughout the years comprising conventional
machine learning strategies as well as convolutional neural networks (CNN)
approaches. In particular, in this paper, we analyse a sub-group of deep
learning methods producing dense predictions. This branch, referred in the
literature as Fully CNN (FCNN), is of interest as these architectures can
process an input volume in less time than CNNs and local spatial dependencies
may be encoded since several voxels are classified at once. Our study focuses
on understanding architectural strengths and weaknesses of literature-like
approaches. Hence, we implement eight FCNN architectures inspired by robust
state-of-the-art methods on brain segmentation related tasks. We evaluate them
using the IBSR18, MICCAI2012 and iSeg2017 datasets as they contain infant and
adult data and exhibit varied voxel spacing, image quality, number of scans and
available imaging modalities. The discussion is driven in three directions:
comparison between 2D and 3D approaches, the importance of multiple modalities
and overlapping as a sampling strategy for training and testing models. To
encourage other researchers to explore the evaluation framework, a public
version is accessible to download from our research website.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06460</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empowering the Configuration-IP - New PTAS Results for Scheduling with
  Setups Times</dc:title>
 <dc:creator>Jansen, Klaus</dc:creator>
 <dc:creator>Klein, Kim-Manuel</dc:creator>
 <dc:creator>Maack, Marten</dc:creator>
 <dc:creator>Rau, Malin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Integer linear programs of configurations, or configuration IPs, are a
classical tool in the design of algorithms for scheduling and packing problems,
where a set of items has to be placed in multiple target locations. Herein a
configuration describes a possible placement on one of the target locations,
and the IP is used to chose suitable configurations covering the items. We give
an augmented IP formulation, which we call the module configuration IP. It can
be described within the framework of $n$-fold integer programming and therefore
be solved efficiently using the algorithm by Hemmecke, Onn, and Romanchuk.
Furthermore, we investigate how structural properties can be applied to reduce
the description of the IP and thereby speed up the resulting algorithms. As an
application, we consider scheduling problems with setup times, in which a set
of jobs has to be scheduled on a set of identical machines, with the objective
of minimizing the makespan. For instance, we investigate the case that jobs can
be split and scheduled on multiple machines. However, before a part of a job
can be processed an uninterrupted setup depending on the job has to be paid.
For both of the variants that jobs can be executed in parallel or not, we
obtain an efficient polynomial time approximation scheme (EPTAS) of running
time $f(1/\varepsilon)\times \mathrm{poly}(|I|)$ with a single exponential term
in $f$ for the first and a double exponential one for the second case.
Previously only constant factor approximations of $5/3$ and $4/3 + \varepsilon$
respectively were known. Furthermore, we present an EPTAS for a problem where
classes of (non-splittable) jobs are given, and a setup has to be paid for each
class of jobs being executed on one machine.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06475</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systematic Review of Productivity Factors in Software Development</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Ruhe, Melanie</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Analysing and improving productivity has been one of the main goals of
software engineering research since its beginnings. A plethora of studies has
been conducted on various factors that resulted in several models for analysis
and prediction of productivity. However, productivity is still an issue in
current software development and not all factors and their relationships are
known. This paper reviews the large body of available literature in order to
distill a list of the main factors influencing productivity investigated so
far. The measure for importance here is the number of articles a factor is
mentioned in. Special consideration is given to soft or human-related factors
in software engineering that are often not analysed with equal detail as more
technical factors. The resulting list can be used to guide further analysis and
as basis for building productivity models.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06475</dc:identifier>
 <dc:identifier>Proc. 2nd International Workshop on Software Productivity Analysis
  and Cost Estimation (SPACE 2008). Technical Report ISCAS-SKLCS-08-08, State
  Key Laboratory of Computer Science, Institute of Software, Chinese Academy of
  Sciences</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06480</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Practitioners' Guide to Transfer Learning for Text Classification
  using Convolutional Neural Networks</dc:title>
 <dc:creator>Semwal, Tushar</dc:creator>
 <dc:creator>Mathur, Gaurav</dc:creator>
 <dc:creator>Yenigalla, Promod</dc:creator>
 <dc:creator>Nair, Shivashankar B.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Transfer Learning (TL) plays a crucial role when a given dataset has
insufficient labeled examples to train an accurate model. In such scenarios,
the knowledge accumulated within a model pre-trained on a source dataset can be
transferred to a target dataset, resulting in the improvement of the target
model. Though TL is found to be successful in the realm of image-based
applications, its impact and practical use in Natural Language Processing (NLP)
applications is still a subject of research. Due to their hierarchical
architecture, Deep Neural Networks (DNN) provide flexibility and customization
in adjusting their parameters and depth of layers, thereby forming an apt area
for exploiting the use of TL. In this paper, we report the results and
conclusions obtained from extensive empirical experiments using a Convolutional
Neural Network (CNN) and try to uncover thumb rules to ensure a successful
positive transfer. In addition, we also highlight the flawed means that could
lead to a negative transfer. We explore the transferability of various layers
and describe the effect of varying hyper-parameters on the transfer
performance. Also, we present a comparison of accuracy value and model size
against state-of-the-art methods. Finally, we derive inferences from the
empirical results and provide best practices to achieve a successful positive
transfer.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures, accepted in SDM 2018</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06481</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Learning of Strict Partial Orders: A Case Study on Concept
  Prerequisite Relations</dc:title>
 <dc:creator>Liang, Chen</dc:creator>
 <dc:creator>Ye, Jianbo</dc:creator>
 <dc:creator>Zhao, Han</dc:creator>
 <dc:creator>Pursel, Bart</dc:creator>
 <dc:creator>Giles, C. Lee</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Strict partial order is a mathematical structure commonly seen in relational
data. One obstacle to extracting such type of relations at scale is the lack of
large-scale labels for building effective data-driven solutions. We develop an
active learning framework for mining such relations subject to a strict order.
Our approach incorporates relational reasoning not only in finding new
unlabeled pairs whose labels can be deduced from an existing label set, but
also in devising new query strategies that consider the relational structure of
labels. Our experiments on concept prerequisite relations show our proposed
framework can substantially improve the classification performance with the
same query budget compared to other baseline approaches.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06482</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Detecting Cyberbullying Across Multiple Social Media
  Platforms</dc:title>
 <dc:creator>Agrawal, Sweta</dc:creator>
 <dc:creator>Awekar, Amit</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Harassment by cyberbullies is a significant phenomenon on the social media.
Existing works for cyberbullying detection have at least one of the following
three bottlenecks. First, they target only one particular social media platform
(SMP). Second, they address just one topic of cyberbullying. Third, they rely
on carefully handcrafted features of the data. We show that deep learning based
models can overcome all three bottlenecks. Knowledge learned by these models on
one dataset can be transferred to other datasets. We performed extensive
experiments using three real-world datasets: Formspring (12k posts), Twitter
(16k posts), and Wikipedia(100k posts). Our experiments provide several useful
insights about cyberbullying detection. To the best of our knowledge, this is
the first work that systematically analyzes cyberbullying detection on various
topics across multiple SMPs using deep learning based models and transfer
learning.
</dc:description>
 <dc:description>Comment: Accepted for ECIR 2018</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06484</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Scalable Architecture using L1 Adaptive Controllers for
  Primary Voltage Control of DC Microgrids</dc:title>
 <dc:creator>O'Keeffe, Daniel</dc:creator>
 <dc:creator>Riverso, Stefano</dc:creator>
 <dc:creator>Albiol-Tendillo, Laura</dc:creator>
 <dc:creator>Lightbody, Gordon</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes a new distributed control architecture for distributed
generation units in heterogeneous DC islanded microgrids. Each unit is equipped
with state-feedback baseline and augmenting $\mathcal{L}_1$ adaptive voltage
controllers at the primary level of the microgrid control hierarchy. Local
controller synthesis is scalable as it only requires information about
corresponding units, couplings, and at most, the addition of state-predictor
measurements of neighbouring controllers. Global asymptotic stability of the
microgrid is guaranteed in a plug-and-play fashion by exploiting Lyapunov
functions and algebraic Riccati equations. The performance of the proposed
architecture is evaluated using a heterogeneous DC islanded microgrid that
consists of 6 DC-DC boost converters configured in a radial and meshed
topology. The use of $\mathcal{L}_1$ adaptive controllers achieves fast and
robust microgrid voltage stability in the presence of plug-and-play operations,
topology changes and unknown load changes. Finally, the distributed
architecture is tested on a bus-connected islanded-microgrid consisting of
linear resistive load and non-linear DC motor.
</dc:description>
 <dc:description>Comment: 21 pages, 26 figures, Journal paper pre-print. arXiv admin note:
  substantial text overlap with arXiv:1801.04508</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06490</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Worst-case Optimal Submodular Extensions for Marginal Estimation</dc:title>
 <dc:creator>Pansari, Pankaj</dc:creator>
 <dc:creator>Russell, Chris</dc:creator>
 <dc:creator>Kumar, M. Pawan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Submodular extensions of an energy function can be used to efficiently
compute approximate marginals via variational inference. The accuracy of the
marginals depends crucially on the quality of the submodular extension. To
identify the best possible extension, we show an equivalence between the
submodular extensions of the energy and the objective functions of linear
programming (LP) relaxations for the corresponding MAP estimation problem. This
allows us to (i) establish the worst-case optimality of the submodular
extension for Potts model used in the literature; (ii) identify the worst-case
optimal submodular extension for the more general class of metric labeling; and
(iii) efficiently compute the marginals for the widely used dense CRF model
with the help of a recently proposed Gaussian filtering method. Using synthetic
and real data, we show that our approach provides comparable upper bounds on
the log-partition function to those obtained using tree-reweighted message
passing (TRW) in cases where the latter is computationally feasible.
Importantly, unlike TRW, our approach provides the first practical algorithm to
compute an upper bound on the dense CRF model.
</dc:description>
 <dc:description>Comment: Accepted to AISTATS 2018</dc:description>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06492</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Epoch-Synchronous Overlap-Add (ESOLA) for Time- and Pitch-Scale
  Modification of Speech Signals</dc:title>
 <dc:creator>Rudresh, Sunil</dc:creator>
 <dc:creator>Vasisht, Aditya</dc:creator>
 <dc:creator>Vijayan, Karthika</dc:creator>
 <dc:creator>Seelamantula, Chandra Sekhar</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Time- and pitch-scale modifications of speech signals find important
applications in speech synthesis, playback systems, voice conversion,
learning/hearing aids, etc.. There is a requirement for computationally
efficient and real-time implementable algorithms. In this paper, we propose a
high quality and computationally efficient time- and pitch-scaling methodology
based on the glottal closure instants (GCIs) or epochs in speech signals. The
proposed algorithm, termed as epoch-synchronous overlap-add time/pitch-scaling
(ESOLA-TS/PS), segments speech signals into overlapping short-time frames and
then the adjacent frames are aligned with respect to the epochs and the frames
are overlap-added to synthesize time-scale modified speech. Pitch scaling is
achieved by resampling the time-scaled speech by a desired sampling factor. We
also propose a concept of epoch embedding into speech signals, which
facilitates the identification and time-stamping of samples corresponding to
epochs and using them for time/pitch-scaling to multiple scaling factors
whenever desired, thereby contributing to faster and efficient implementation.
The results of perceptual evaluation tests reported in this paper indicate the
superiority of ESOLA over state-of-the-art techniques. ESOLA significantly
outperforms the conventional pitch synchronous overlap-add (PSOLA) techniques
in terms of perceptual quality and intelligibility of the modified speech.
Unlike the waveform similarity overlap-add (WSOLA) or synchronous overlap-add
(SOLA) techniques, the ESOLA technique has the capability to do exact
time-scaling of speech with high quality to any desired modification factor
within a range of 0.5 to 2. Compared to synchronous overlap-add with fixed
synthesis (SOLAFS), the ESOLA is computationally advantageous and at least
three times faster.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06494</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasimonotone graphs</dc:title>
 <dc:creator>Dyer, Martin</dc:creator>
 <dc:creator>M&#xfc;ller, Haiko</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C81 05C75</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  For any class C of bipartite graphs, we define quasi-C to be the class of all
graphs G such that every bipartition of G belongs to C. This definition is
motivated by a generalisation of the switch Markov chain on perfect matchings
from bipartite graphs to nonbipartite graphs. The monotone graphs, also known
as bipartite permutation graphs and proper interval bigraphs, are such a class
of bipartite graphs. We investigate the structure of quasi-monotone graphs and
hence construct a polynomial time recognition algorithm for graphs in this
class.
</dc:description>
 <dc:description>Comment: 35 pages, 55 figures</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06495</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dimensionality Reduction in Deep Learning for Chest X-Ray Analysis of
  Lung Cancer</dc:title>
 <dc:creator>Gordienko, Yu.</dc:creator>
 <dc:creator>Kochura, Yu.</dc:creator>
 <dc:creator>Alienin, O.</dc:creator>
 <dc:creator>Rokovyi, O.</dc:creator>
 <dc:creator>Stirenko, S.</dc:creator>
 <dc:creator>Gang, Peng</dc:creator>
 <dc:creator>Hui, Jiang</dc:creator>
 <dc:creator>Zeng, Wei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Efficiency of some dimensionality reduction techniques, like lung
segmentation, bone shadow exclusion, and t-distributed stochastic neighbor
embedding (t-SNE) for exclusion of outliers, is estimated for analysis of chest
X-ray (CXR) 2D images by deep learning approach to help radiologists identify
marks of lung cancer in CXR. Training and validation of the simple
convolutional neural network (CNN) was performed on the open JSRT dataset
(dataset #01), the JSRT after bone shadow exclusion - BSE-JSRT (dataset #02),
JSRT after lung segmentation (dataset #03), BSE-JSRT after lung segmentation
(dataset #04), and segmented BSE-JSRT after exclusion of outliers by t-SNE
method (dataset #05). The results demonstrate that the pre-processed dataset
obtained after lung segmentation, bone shadow exclusion, and filtering out the
outliers by t-SNE (dataset #05) demonstrates the highest training rate and best
accuracy in comparison to the other pre-processed datasets.
</dc:description>
 <dc:description>Comment: 6 pages, 14 figures</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06498</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Active Social Network De-anonymization Using Information
  Thresholds</dc:title>
 <dc:creator>Shirani, F.</dc:creator>
 <dc:creator>Garg, S.</dc:creator>
 <dc:creator>Erkip, E.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, de-anonymizing internet users by actively querying their group
memberships in social networks is considered. In this problem, an anonymous
victim visits the attacker's website, and the attacker uses the victim's
browser history to query her social media activity for the purpose of
de-anonymization using the minimum number of queries. A stochastic model of the
problem is considered where the attacker has partial prior knowledge of the
group membership graph and receives noisy responses to its real-time queries.
The victim's identity is assumed to be chosen randomly based on a given
distribution which models the users' risk of visiting the malicious website. A
de-anonymization algorithm is proposed which operates based on information
thresholds and its performance both in the finite and asymptotically large
social network regimes is analyzed. Furthermore, a converse result is provided
which proves the optimality of the proposed attack strategy.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06502</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobility Based Routing Protocol with MAC Collision Improvement in
  Vehicular Ad Hoc Networks</dc:title>
 <dc:creator>Ding, Zhihao</dc:creator>
 <dc:creator>Ren, Pinyi</dc:creator>
 <dc:creator>Du, Qinghe</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Intelligent transportation system attracts a great deal of research attention
because it helps enhance traffic safety, improve driving experiences, and
transportation efficiency. Vehicular Ad Hoc Network (VANET) supports wireless
connections among vehicles and offers information exchange, thus significantly
facilitating intelligent transportation systems. Since the vehicles move fast
and often change lanes unpredictably, the network topology evolves rapidly in a
random fashion, which imposes diverse challenges in routing protocol design
over VANET. When it comes to the 5G era, the fulfilment of ultra low end-to-end
delay and ultra high reliability becomes more crucial than ever. In this paper,
we propose a novel routing protocol that incorporates mobility status and MAC
layer channel contention information. The proposed routing protocol determines
next hop by applying mobility information and MAC contention information which
differs from existing greedy perimeter stateless routing (GPSR) protocol.
Simulation results of the proposed routing protocol show its performance
superiority over the existing approach.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06503</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global overview of Imitation Learning</dc:title>
 <dc:creator>Attia, Alexandre</dc:creator>
 <dc:creator>Dayan, Sharone</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Imitation Learning is a sequential task where the learner tries to mimic an
expert's action in order to achieve the best performance. Several algorithms
have been proposed recently for this task. In this project, we aim at proposing
a wide review of these algorithms, presenting their main features and comparing
them on their performance and their regret bounds.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures, 5 appendix pages</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06504</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting and counting tiny faces</dc:title>
 <dc:creator>Attia, Alexandre</dc:creator>
 <dc:creator>Dayan, Sharone</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Finding Tiny Faces (by Hu and Ramanan) proposes a novel approach to find
small objects in an image. Our contribution consists in deeply understanding
the choices of the paper together with applying and extending a similar method
to a real world subject which is the counting of people in a public
demonstration.
</dc:description>
 <dc:description>Comment: 4 pages, 10 figures, 2 appendix page</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06505</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperation risk and Nash equilibrium: quantitative description for
  realistic players</dc:title>
 <dc:creator>Nakamura, G. M.</dc:creator>
 <dc:creator>Contesini, G. S.</dc:creator>
 <dc:creator>Martinez, A. S.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The emergence of cooperation figures among the main goal of game theory in
competitive-cooperative environments. Potential games have long been hinted as
viable alternatives to study realistic player behavior. Here, we expand the
potential games approach by taking into account the inherent risks of
cooperation. We show the Public Goods game reduce to a Hamiltonian with
one-body operators, with the correct Nash Equilibrium as the ground state. The
inclusion of punishments to the Public Goods game reduces the cooperation risk,
creating two-body interaction with a rich phase diagram, where phase
transitions segregates the cooperative from competitive regimes.
</dc:description>
 <dc:description>Comment: 5 pages and 5 figures</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06510</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Provenance Analysis at Scale</dc:title>
 <dc:creator>Moreira, Daniel</dc:creator>
 <dc:creator>Bharati, Aparna</dc:creator>
 <dc:creator>Brogan, Joel</dc:creator>
 <dc:creator>Pinto, Allan</dc:creator>
 <dc:creator>Parowski, Michael</dc:creator>
 <dc:creator>Bowyer, Kevin W.</dc:creator>
 <dc:creator>Flynn, Patrick J.</dc:creator>
 <dc:creator>Rocha, Anderson</dc:creator>
 <dc:creator>Scheirer, Walter J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Prior art has shown it is possible to estimate, through image processing and
computer vision techniques, the types and parameters of transformations that
have been applied to the content of individual images to obtain new images.
Given a large corpus of images and a query image, an interesting further step
is to retrieve the set of original images whose content is present in the query
image, as well as the detailed sequences of transformations that yield the
query image given the original images. This is a problem that recently has
received the name of image provenance analysis. In these times of public media
manipulation ( e.g., fake news and meme sharing), obtaining the history of
image transformations is relevant for fact checking and authorship
verification, among many other applications. This article presents an
end-to-end processing pipeline for image provenance analysis, which works at
real-world scale. It employs a cutting-edge image filtering solution that is
custom-tailored for the problem at hand, as well as novel techniques for
obtaining the provenance graph that expresses how the images, as nodes, are
ancestrally connected. A comprehensive set of experiments for each stage of the
pipeline is provided, comparing the proposed solution with state-of-the-art
results, employing previously published datasets. In addition, this work
introduces a new dataset of real-world provenance cases from the social media
site Reddit, along with baseline results.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06519</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Piggyback: Adding Multiple Tasks to a Single, Fixed Network by Learning
  to Mask</dc:title>
 <dc:creator>Mallya, Arun</dc:creator>
 <dc:creator>Lazebnik, Svetlana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work presents a method for adding multiple tasks to a single, fixed deep
neural network without affecting performance on already learned tasks. By
building upon concepts from network quantization and sparsification, we learn
binary masks that &quot;piggyback&quot;, or are applied to an existing network to provide
good performance on a new task. These masks are learned in an end-to-end
differentiable fashion, and incur a low overhead of 1 bit per network
parameter, per task. Even though the underlying network is fixed, the ability
to mask certain weights allows for the learning of a large number of filters.
We show improved performance on a variety of classification tasks, including
those with large domain shifts from the natural images of ImageNet. Unlike
prior work, we can augment the capabilities of a network without suffering from
catastrophic forgetting or competition between tasks, while incurring the least
overhead per added task. We demonstrate the applicability of our method to
multiple architectures, and obtain accuracies comparable with individual
networks trained per task.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06523</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How would surround vehicles move? A Unified Framework for Maneuver
  Classification and Motion Prediction</dc:title>
 <dc:creator>Deo, Nachiket</dc:creator>
 <dc:creator>Rangesh, Akshay</dc:creator>
 <dc:creator>Trivedi, Mohan M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reliable prediction of surround vehicle motion is a critical requirement for
path planning for autonomous vehicles. In this paper we propose a unified
framework for surround vehicle maneuver classification and motion prediction
that exploits multiple cues, namely, the estimated motion of vehicles, an
understanding of typical motion patterns of freeway traffic and inter-vehicle
interaction. We report our results in terms of maneuver classification accuracy
and mean and median absolute error of predicted trajectories against the ground
truth for real traffic data collected using vehicle mounted sensors on
freeways. An ablative analysis is performed to analyze the relative importance
of each cue for trajectory prediction. Additionally, an analysis of execution
time for the components of the framework is presented. Finally, we present
multiple case studies analyzing the outputs of our model for complex traffic
scenarios
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE transactions on Intelligent Vehicles</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06540</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What is the right addressing scheme for India?</dc:title>
 <dc:creator>Rustogi, Kabir</dc:creator>
 <dc:creator>Bhattacharya, Santanu</dc:creator>
 <dc:creator>Church, Margaret</dc:creator>
 <dc:creator>Raskar, Ramesh</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Computer generated addresses are coming to your neighborhood because most
places in the world do not have an assigned meaningful street address. In
India, 80% of the addresses are written with respect to a landmark which
typically lies between 50-1500 meters of the actual address; such addresses
make geolocating very challenging. Accuracy in geolocation is critical for
emergency services to navigate quickly to reach you and for logistics
industries to improve on-time performance and efficient routing of the package
coming to your house. In this paper, we explore suggested addressing schemes
for India, to determine what use cases and potential technologies will have the
best adoption and therefore, greatest impact. Currently, there is a rush to use
machine generated codes such as 4ZXR3B (eLoc) or CAFE0098 (Zippr). These
methods have proven to work in a few ways, but such systems can be confusing
for the adoptee and there are technical drawbacks as well. It is critical that
India adopts the most effective scheme and not the scheme that is most readily
available or has the largest company behind it. We ask: What are the
requirements for machine codes so that they are easy for a layman, easy for a
service company (eCommerce, taxi etc) and suitable for computer systems? Here
we review the desired features, compare various solutions, and suggest a path
for widespread adoption of machine codes in India.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures and 3 tables. Published in the MIT Emerging
  Worlds Site</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06541</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HGum: Messaging Framework for Hardware Accelerators</dc:title>
 <dc:creator>Zhang, Sizhuo</dc:creator>
 <dc:creator>Angepat, Hari</dc:creator>
 <dc:creator>Chiou, Derek</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Software messaging frameworks help avoid errors and reduce engineering
efforts in building distributed systems by (1) providing an interface
definition language (IDL) to specify precisely the structure of the message
(i.e., the message schema), and (2) automatically generating the serialization
and deserialization functions that transform user data structures into binary
data for sending across the network and vice versa. Similarly, a
hardware-accelerated system, which consists of host software and multiple
FPGAs, could also benefit from a messaging framework to handle messages both
between software and FPGA and also between different FPGAs. The key challenge
for a hardware messaging framework is that it must be able to support large
messages with complex schema while meeting critical constraints such as clock
frequency, area, and throughput.
  In this paper, we present HGum, a messaging framework for hardware
accelerators that meets all the above requirements. HGum is able to generate
high-performance and low-cost hardware logic by employing a novel design that
algorithmically parses the message schema to perform serialization and
deserialization. Our evaluation of HGum shows that it not only significantly
reduces engineering efforts but also generates hardware with comparable quality
to manual implementation.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06542</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Further study on the maximum number of bent components of vectorial
  functions</dc:title>
 <dc:creator>Mesnager, Sihem</dc:creator>
 <dc:creator>Zhang, Fengrong</dc:creator>
 <dc:creator>Tang, Chunming</dc:creator>
 <dc:creator>Zhou, Yong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In 2018, Pott, at al. have studied in [IEEE Transactions on Information
Theory. Volume: 64, Issue: 1, 2018] the maximum number of bent components of
vectorial function. They have presented serval nice results and suggested
several open problems in this context. This paper is in the continuation of
their study in which we solve two open problems raised by Pott et al. and
partially solve an open problem raised by the same authors. Firstly, we prove
that for a vectorial function, the property of having the maximum number of
bent components is invariant under the so-called CCZ equivalence. Secondly, we
prove the non-existence of APN plateaued having the maximum number of bent
components. In particular, quadratic APN functions cannot have the maximum
number of bent components. Finally, we present some sufficient conditions that
the vectorial function defined from $\mathbb{F}_{2^{2k}}$ to
$\mathbb{F}_{2^{2k}}$ by its univariate representation:
  $$ \alpha
x^{2^i}\left(x+x^{2^k}+\sum\limits_{j=1}^{\rho}\gamma^{(j)}x^{2^{t_j}}
  +\sum\limits_{j=1}^{\rho}\gamma^{(j)}x^{2^{t_j+k}}\right)$$ has the maximum
number of {components bent functions, where $\rho\leq k$}. Further, we show
that the differential spectrum of the function $
x^{2^i}(x+x^{2^k}+x^{2^{t_1}}+x^{2^{t_1+k}}+x^{2^{t_2}}+x^{2^{t_2+k}})$ (where
$i,t_1,t_2$ satisfy some conditions) is different from the binomial function
$F^i(x)= x^{2^i}(x+x^{2^k})$ presented in the article of Pott et al.
  Finally, we provide sufficient and necessary conditions so that the functions
$$Tr_1^{2k}\left(\alpha
x^{2^i}\left(Tr^{2k}_{e}(x)+\sum\limits_{j=1}^{\rho}\gamma^{(j)}(Tr^{2k}_{e}(x))^{2^j}
  \right)\right) $$ are bent.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06552</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information &amp; Environment: IoT-Powered Recommender Systems</dc:title>
 <dc:creator>Hahn, Jim</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Internet of Things (IoT) infrastructure within the physical library
environment is the basis for an integrative, hybrid approach to digital
resource recommenders. The IoT infrastructure provides mobile, dynamic
wayfinding support for items in the collection, which includes features for
location-based recommendations. The evaluation and analysis herein clarified
the nature of users' requests for recommendations based on their location, and
describes subject areas of the library for which users request recommendations.
The results indicated that users of IoT-based recommendations are interested in
a broad distribution of subjects, with a short-head distribution from this
collection in American and English Literature. A long-tail finding showed a
diversity of topics that are recommended to users in the library book stacks
with IoT-powered recommendations.
</dc:description>
 <dc:description>Comment: 21 pages, 9 figures</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06558</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Passive Reaction Analysis for Grasp Stability</dc:title>
 <dc:creator>Haas-Heger, Maximilian</dc:creator>
 <dc:creator>Iyengar, Garud</dc:creator>
 <dc:creator>Ciocarlie, Matei</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper we focus on the following problem in multi-fingered robotic
grasping: assuming that an external wrench is being applied to a grasped
object, will the contact forces between the hand and the object, as well as the
hand joints, respond in such a way as to preserve quasi-static equilibrium? In
particular, we assume that there is no change in the joint torques being
actively exerted by the motors; any change in contact forces and joint torques
is due exclusively to passive effects arising in response to the external
disturbance. Such passive effects include for example joints that are driven by
highly geared motors (a common occurence in practice) and thus do not back
drive in response to external torques. To account for non- linear phenomena
encountered in such cases, and which existing methods do not consider, we
formulate the problem as a mixed integer program used in the inner loop of an
iterative solver. We present evidence showing that this formulation captures
important effects for assessing the stability of a grasp employing some of the
most commonly used actuation mechanisms.
</dc:description>
 <dc:description>Comment: In press for IEEE Transactions on Automation Science and Engineering
  Special Issue 12 pages, 9 figures, 1 table</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06590</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persistent Homology of Morse Decompositions in Combinatorial Dynamics</dc:title>
 <dc:creator>Dey, Tamal K.</dc:creator>
 <dc:creator>Juda, Mateusz</dc:creator>
 <dc:creator>Kapela, Tomasz</dc:creator>
 <dc:creator>Kubica, Jacek</dc:creator>
 <dc:creator>Lipinski, Michal</dc:creator>
 <dc:creator>Mrozek, Marian</dc:creator>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  We investigate combinatorial dynamical systems on simplicial complexes
considered as {\em finite topological spaces}. Such systems arise in a natural
way from sampling dynamics and may be used to reconstruct some features of the
dynamics directly from the sample. We study the homological persistence of {\em
Morse decompositions} of such systems, an important descriptor of the dynamics,
as a tool for validating the reconstruction. Our framework can be viewed as a
step toward extending the classical persistence theory to &quot;vector cloud&quot; data.
We present experimental results on two numerical examples.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06593</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Foreground Inference Network for Video Surveillance Using Multi-View
  Receptive Field</dc:title>
 <dc:creator>Akilan, Thangarajah</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Foreground (FG) pixel labelling plays a vital role in video surveillance.
Recent engineering solutions have attempted to exploit the efficacy of deep
learning (DL) models initially targeted for image classification to deal with
FG pixel labelling. One major drawback of such strategy is the lacking
delineation of visual objects when training samples are limited. To grapple
with this issue, we introduce a multi-view receptive field fully convolutional
neural network (MV-FCN) that harness recent seminal ideas, such as, fully
convolutional structure, inception modules, and residual networking. Therefrom,
we implement a system in an encoder-decoder fashion that subsumes a core and
two complementary feature flow paths. The model exploits inception modules at
early and late stages with three different sizes of receptive fields to capture
invariance at various scales. The features learned in the encoding phase are
fused with appropriate feature maps in the decoding phase through residual
connections for achieving enhanced spatial representation. These multi-view
receptive fields and residual feature connections are expected to yield highly
generalized features for an accurate pixel-wise FG region identification. It
is, then, trained with database specific exemplary segmentations to predict
desired FG objects.
  The comparative experimental results on eleven benchmark datasets validate
that the proposed model achieves very competitive performance with the prior-
and state-of-the-art algorithms. We also report that how well a transfer
learning approach can be useful to enhance the performance of our proposed
MV-FCN.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06597</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>mvn2vec: Preservation and Collaboration in Multi-View Network Embedding</dc:title>
 <dc:creator>Shi, Yu</dc:creator>
 <dc:creator>Han, Fangqiu</dc:creator>
 <dc:creator>He, Xinran</dc:creator>
 <dc:creator>Yang, Carl</dc:creator>
 <dc:creator>Luo, Jie</dc:creator>
 <dc:creator>Han, Jiawei</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Multi-view networks are ubiquitous in real-world applications. In order to
extract knowledge or business value, it is of interest to transform such
networks into representations that are easily machine-actionable. Meanwhile,
network embedding has emerged as an effective approach to generate distributed
network representations. Therefore, we are motivated to study the problem of
multi-view network embedding, with a focus on the characteristics that are
specific and important in embedding this type of networks. In our practice of
embedding real-world multi-view networks, we identify two such characteristics,
which we refer to as preservation and collaboration. We then explore the
feasibility of achieving better embedding quality by simultaneously modeling
preservation and collaboration, and propose the mvn2vec algorithms. With
experiments on a series of synthetic datasets, an internal Snapchat dataset,
and two public datasets, we further confirm the presence and importance of
preservation and collaboration. These experiments also demonstrate that better
embedding can be obtained by simultaneously modeling the two characteristics,
while not over-complicating the model or requiring additional supervision.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06601</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs</dc:title>
 <dc:creator>Lai, Liangzhen</dc:creator>
 <dc:creator>Suda, Naveen</dc:creator>
 <dc:creator>Chandra, Vikas</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Deep Neural Networks are becoming increasingly popular in always-on IoT edge
devices performing data analytics right at the source, reducing latency as well
as energy consumption for data communication. This paper presents CMSIS-NN,
efficient kernels developed to maximize the performance and minimize the memory
footprint of neural network (NN) applications on Arm Cortex-M processors
targeted for intelligent IoT edge devices. Neural network inference based on
CMSIS-NN kernels achieves 4.6X improvement in runtime/throughput and 4.9X
improvement in energy efficiency.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06605</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Collaborative Filtering Recommender System for Test Case
  Prioritization in Web Applications</dc:title>
 <dc:creator>Azizi, Maral</dc:creator>
 <dc:creator>Do, Hyunsook</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The use of relevant metrics of software systems could improve various
software engineering tasks, but identifying relationships among metrics is not
simple and can be very time consuming. Recommender systems can help with this
decision-making process, many applications have utilized these systems to
improve the performance of their applications. To investigate the potential
benefits of recommender systems in regression testing, we implemented an
item-based collaborative filtering recommender system that uses user
interaction data and application change history information to develop a test
case prioritization technique. To evaluate our approach, we performed an
empirical study using three web applications with multiple versions and
compared four control techniques. Our results indicate that our recommender
system can help improve the effectiveness of test prioritization.
</dc:description>
 <dc:description>Comment: In Proceedings of SAC 2018: Symposium on Applied Computing</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06605</dc:identifier>
 <dc:identifier>doi:10.1145/3167132.3167299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06607</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Text Classification Using Tree-structured Multi-linear
  Principle Component Analysis</dc:title>
 <dc:creator>Su, Yuanhang</dc:creator>
 <dc:creator>Huang, Yuzhong</dc:creator>
 <dc:creator>Kuo, C. -C. Jay</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A novel text data dimension reduction technique, called the tree-structured
multi-linear principle component anal- ysis (TMPCA), is proposed in this work.
Being different from traditional text dimension reduction methods that deal
with the word-level representation, the TMPCA technique reduces the dimension
of input sequences and sentences to simplify the following text classification
tasks. It is shown mathematically and experimentally that the TMPCA tool
demands much lower complexity (and, hence, less computing power) than the
ordinary principle component analysis (PCA). Furthermore, it is demon- strated
by experimental results that the support vector machine (SVM) method applied to
the TMPCA-processed data achieves commensurable or better performance than the
state-of-the-art recurrent neural network (RNN) approach.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06609</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Precise Analysis of PhaseMax in Phase Retrieval</dc:title>
 <dc:creator>Salehi, Fariborz</dc:creator>
 <dc:creator>Abbasi, Ehsan</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Recovering an unknown complex signal from the magnitude of linear
combinations of the signal is referred to as phase retrieval. We present an
exact performance analysis of a recently proposed
convex-optimization-formulation for this problem, known as PhaseMax. Standard
convex-relaxation-based methods in phase retrieval resort to the idea of
&quot;lifting&quot; which makes them computationally inefficient, since the number of
unknowns is effectively squared. In contrast, PhaseMax is a novel convex
relaxation that does not increase the number of unknowns. Instead it relies on
an initial estimate of the true signal which must be externally provided. In
this paper, we investigate the required number of measurements for exact
recovery of the signal in the large system limit and when the linear
measurement matrix is random with iid standard normal entries. If $n$ denotes
the dimension of the unknown complex signal and $m$ the number of phaseless
measurements, then in the large system limit, $\frac{m}{n} &gt;
\frac{4}{\cos^2(\theta)}$ measurements is necessary and sufficient to recover
the signal with high probability, where $\theta$ is the angle between the
initial estimate and the true signal. Our result indicates a sharp phase
transition in the asymptotic regime which matches the empirical result in
numerical simulations.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06611</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Description Convolutional Neural Networks for Image Compression</dc:title>
 <dc:creator>Zhao, Lijun</dc:creator>
 <dc:creator>Bai, Huihui</dc:creator>
 <dc:creator>Wang, Anhong</dc:creator>
 <dc:creator>Zhao, Yao</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multiple description coding (MDC) is able to stably transmit the signal in
the un-reliable and non-prioritized networks, which has been broadly studied
for several decades. However, the traditional MDC doesn't well leverage image's
context features to generate multiple descriptions. In this paper, we propose a
novel standard-compliant convolutional neural network-based MDC framework in
term of image's context features. Firstly, multiple description generator
network (MDGN) is designed to produce appearance-similar yet feature-different
multiple descriptions automatically according to image's content, which are
compressed by standard codec. Secondly, we present multiple description
reconstruction network (MDRN) including side reconstruction network (SRN) and
central reconstruction network (CRN). When any one of two lossy descriptions is
received at the decoder, SRN network is used to improve the quality of this
decoded lossy description by removing the compression artifact and up-sampling
simultaneously. Meanwhile, we utilize CRN network with two decoded descriptions
as inputs for better reconstruction, if both of lossy descriptions are
available. Thirdly, multiple description virtual codec network (MDVCN) is
proposed to bridge the gap between MDGN network and MDRN network in order to
train an end-to-end MDC framework. Here, two learning algorithms are provided
to train our whole framework. In addition to structural similarity loss
function, the produced descriptions are used as opposing labels with multiple
description distance loss function to regularize the training of MDGN network.
These losses guarantee that the generated description images are structurally
similar yet finely diverse. Experimental results show a great deal of objective
and subjective quality measurements to validate the efficiency of the proposed
method.
</dc:description>
 <dc:description>Comment: 13 pages, 3 tables, and 6 figures</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06613</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building an Ellipsis-aware Chinese Dependency Treebank for Web Text</dc:title>
 <dc:creator>Ren, Xuancheng</dc:creator>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:creator>Wen, Ji</dc:creator>
 <dc:creator>Wei, Bingzhen</dc:creator>
 <dc:creator>Zhan, Weidong</dc:creator>
 <dc:creator>Zhang, Zhiyuan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Web 2.0 has brought with it numerous user-produced data revealing one's
thoughts, experiences, and knowledge, which are a great source for many tasks,
such as information extraction, and knowledge base construction. However, the
colloquial nature of the texts poses new challenges for current natural
language processing techniques, which are more adapt to the formal form of the
language. Ellipsis is a common linguistic phenomenon that some words are left
out as they are understood from the context, especially in oral utterance,
hindering the improvement of dependency parsing, which is of great importance
for tasks relied on the meaning of the sentence. In order to promote research
in this area, we are releasing a Chinese dependency treebank of 319 weibos,
containing 572 sentences with omissions restored and contexts reserved.
</dc:description>
 <dc:description>Comment: The treebank is available at
  https://github.com/lancopku/Chinese-Dependency-Treebank-with-Ellipsis</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06619</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning Methods for User Positioning With Uplink RSS in
  Distributed Massive MIMO</dc:title>
 <dc:creator>Prasad, K. N. R. Surya Vara</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:creator>Bhargava, Vijay K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider a machine learning approach based on Gaussian process regression
(GP) to position users in a distributed massive multiple-input multiple-output
(MIMO) system with the uplink received signal strength (RSS) data. We focus on
the scenario where noise-free RSS is available for training, but only noisy RSS
is available for testing purposes. To estimate the test user locations and
their 2{\sigma} error-bars, we adopt two state-of-the-art GP methods, namely,
the conventional GP (CGP) and the numerical approximation GP (NaGP) methods. We
find that the CGP method, which treats the noisy test RSS vectors as
noise-free, provides unrealistically small 2{\sigma} error-bars on the
estimated locations. To alleviate this concern, we derive the true predictive
distribution for the test user locations and then employ the NaGP method to
numerically approximate it as a Gaussian with the same first and second order
moments. We also derive a Bayesian Cramer-Rao lower bound (BCRLB) on the
achievable root- mean-squared-error (RMSE) performance of the two GP methods.
Simulation studies reveal that: (i) the NaGP method indeed provides realistic
2{\sigma} error-bars on the estimated locations, (ii) operation in massive MIMO
regime improves the RMSE performance, and (iii) the achieved RMSE performances
are very close to the derived BCRLB.
</dc:description>
 <dc:description>Comment: submitted to IEEE Trans. Wireless Commun., Jan 2018</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06620</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A high-performance analog Max-SAT solver and its application to Ramsey
  numbers</dc:title>
 <dc:creator>Moln&#xe1;r, Botond</dc:creator>
 <dc:creator>Varga, Melinda</dc:creator>
 <dc:creator>Toroczkai, Zoltan</dc:creator>
 <dc:creator>Ercsey-Ravasz, M&#xe1;ria</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>05D10, 37N99, 68W99</dc:subject>
 <dc:description>  We introduce a continuous-time analog solver for MaxSAT, a quintessential
class of NP-hard discrete optimization problems, where the task is to find a
truth assignment for a set of Boolean variables satisfying the maximum number
of given logical constraints. We show that the scaling of an invariant of the
solver's dynamics, the escape rate, as function of the number of unsatisfied
clauses can predict the global optimum value, often well before reaching the
corresponding state. We demonstrate the performance of the solver on hard
MaxSAT competition problems. We then consider the two-color Ramsey number
$R(m,m)$ problem, translate it to SAT, and apply our algorithm to the still
unknown $R(5,5)$. We find edge colorings without monochromatic 5-cliques for
complete graphs up to 42 vertices, while on 43 vertices we find colorings with
only two monochromatic 5-cliques, the best coloring found so far, supporting
the conjecture that $R(5,5) = 43$.
</dc:description>
 <dc:description>Comment: 33 pages, 13 figures</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06623</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Promises and Caveats of Uplink IoT Ultra-Dense Networks</dc:title>
 <dc:creator>Ding, Ming</dc:creator>
 <dc:creator>Perez, David Lopez</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, by means of simulations, we evaluate the uplink (UL)
performance of an Internet of Things (IoT) capable ultra-dense network (UDN) in
terms of the coverage probability and the density of reliably working user
equipments (UEs). From our study, we show the benefits and challenges that UL
IoT UDNs will bring about in the future. In more detail, for a low-reliability
criterion, such as achieving a UL signal-to-interference-plus-noise ratio
(SINR) above 0 dB, the density of reliably working UEs grows quickly with the
network densification, showing the potential of UL IoT UDNs. In contrast, for a
high-reliability criterion, such as achieving a UL SINR above 10 dB, the
density of reliably working UEs remains to be low in UDNs due to excessive
inter-cell interference, which should be considered when operating UL IoT UDNs.
Moreover, considering the existence of a non-zero antenna height difference
between base stations (BSs) and UEs, the density of reliably working UEs could
even decrease as we deploy more BSs. This calls for the usage of sophisticated
interference management schemes and/or beam steering/shaping technologies in UL
IoT UDNs.
</dc:description>
 <dc:description>Comment: to appear in IEEE WCNC2018</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06624</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Double circulant self-dual and LCD codes over Galois rings</dc:title>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Huang, Daitao</dc:creator>
 <dc:creator>Sok, Lin</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the existence, enumeration and asymptotic performance
of self-dual and LCD double circulant codes over Galois rings of characteristic
$p^2$ and order $p^4$ with $p$ and odd prime. When $p \equiv 3 \pmod{4},$ we
give an algorithm to construct a duality preserving bijective Gray map from
such a Galois ring to $\mathbb{Z}_{p^2}^2.$ Using random coding, we obtain
families of asymptotically good self-dual and LCD codes over
$\mathbb{Z}_{p^2},$ for the metric induced by the standard
$\mathbb{F}_p$-valued Gray maps.
</dc:description>
 <dc:description>Comment: Sbumitted on 4, December, 20 pages</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06635</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualization of Hyperspectral Images Using Moving Least Squares</dc:title>
 <dc:creator>Liao, Danping</dc:creator>
 <dc:creator>Chen, Siyu</dc:creator>
 <dc:creator>Qian, Yuntao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Displaying the large number of bands in a hyper spectral image on a
trichromatic monitor has been an active research topic. The visualized image
shall convey as much information as possible form the original data and
facilitate image interpretation. Most existing methods display HSIs in false
colors which contradict with human's experience and expectation. In this paper,
we propose a nonlinear approach to visualize an input HSI with natural colors
by taking advantage of a corresponding RGB image. Our approach is based on
Moving Least Squares, an interpolation scheme for reconstructing a surface from
a set of control points, which in our case is a set of matching pixels between
the HSI and the corresponding RGB image. Based on MLS, the proposed method
solves for each spectral signature a unique transformation so that the non
linear structure of the HSI can be preserved. The matching pixels between a
pair of HSI and RGB image can be reused to display other HSIs captured b the
same imaging sensor with natural colors. Experiments show that the output image
of the proposed method no only have natural colors but also maintain the visual
information necessary for human analysis.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1712.01657</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06636</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the geometrical properties of the coherent matching distance in 2D
  persistent homology</dc:title>
 <dc:creator>Cerri, Andrea</dc:creator>
 <dc:creator>Ethier, Marc</dc:creator>
 <dc:creator>Frosini, Patrizio</dc:creator>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Primary 55N99, Secondary 68U05 65D18</dc:subject>
 <dc:description>  In this paper we study a new metric for comparing Betti numbers functions in
bidimensional persistent homology, based on coherent matchings, i.e. families
of matchings that vary in a continuous way. We prove some new results about
this metric, including its stability. In particular, we show that the
computation of this distance is strongly related to suitable filtering
functions associated with lines of slope 1, so underlining the key role of
these lines in the study of bidimensional persistence. In order to prove these
results, we introduce and study the concepts of extended Pareto grid for a
normal filtering function as well as of transport of a matching. As a
by-product, we obtain a theoretical framework for managing the phenomenon of
monodromy in 2D persistent homology.
</dc:description>
 <dc:description>Comment: 35 pages, 13 figures</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06637</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Hidden Physics Models: Deep Learning of Nonlinear Partial
  Differential Equations</dc:title>
 <dc:creator>Raissi, Maziar</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:description>  A long-standing problem at the interface of artificial intelligence and
applied mathematics is to devise an algorithm capable of achieving human level
or even superhuman proficiency in transforming observed data into predictive
mathematical models of the physical world. In the current era of abundance of
data and advanced machine learning capabilities, the natural question arises:
How can we automatically uncover the underlying laws of physics from
high-dimensional data generated from experiments? In this work, we put forth a
deep learning approach for discovering nonlinear partial differential equations
from scattered and potentially noisy observations in space and time.
Specifically, we approximate the unknown solution as well as the nonlinear
dynamics by two deep neural networks. The first network acts as a prior on the
unknown solution and essentially enables us to avoid numerical differentiations
which are inherently ill-conditioned and unstable. The second network
represents the nonlinear dynamics and helps us distill the mechanisms that
govern the evolution of a given spatiotemporal data-set. We test the
effectiveness of our approach for several benchmark problems spanning a number
of scientific domains and demonstrate how the proposed framework can help us
accurately learn the underlying dynamics and forecast future states of the
system. In particular, we study the Burgers', Korteweg-de Vries (KdV),
Kuramoto-Sivashinsky, nonlinear Schr\&quot;{o}dinger, and Navier-Stokes equations.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06642</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Inhomogeneous Density Map Learning for Crowd Counting</dc:title>
 <dc:creator>Li, Hanhui</dc:creator>
 <dc:creator>He, Xiangjian</dc:creator>
 <dc:creator>Wu, Hefeng</dc:creator>
 <dc:creator>Kasmani, Saeed Amirgholipour</dc:creator>
 <dc:creator>Wang, Ruomei</dc:creator>
 <dc:creator>Luo, Xiaonan</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we aim at tackling the problem of crowd counting in extremely
high-density scenes, which contain hundreds, or even thousands of people. We
begin by a comprehensive analysis of the most widely used density map-based
methods, and demonstrate how easily existing methods are affected by the
inhomogeneous density distribution problem, e.g., causing them to be sensitive
to outliers, or be hard to optimized. We then present an extremely simple
solution to the inhomogeneous density distribution problem, which can be
intuitively summarized as extending the density map from 2D to 3D, with the
extra dimension implicitly indicating the density level. Such solution can be
implemented by a single Density-Aware Network, which is not only easy to train,
but also can achieve the state-of-art performance on various challenging
datasets.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06657</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gender-dependent emotion recognition based on HMMs and SPHMMs</dc:title>
 <dc:creator>Shahin, Ismail</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  It is well known that emotion recognition performance is not ideal. The work
of this research is devoted to improving emotion recognition performance by
employing a two-stage recognizer that combines and integrates gender recognizer
and emotion recognizer into one system. Hidden Markov Models (HMMs) and
Suprasegmental Hidden Markov Models (SPHMMs) have been used as classifiers in
the two-stage recognizer. This recognizer has been tested on two distinct and
separate emotional speech databases. The first database is our collected
database and the second one is the Emotional Prosody Speech and Transcripts
database. Six basic emotions including the neutral state have been used in each
database. Our results show that emotion recognition performance based on the
two-stage approach (gender-dependent emotion recognizer) has been significantly
improved compared to that based on emotion recognizer without gender
information and emotion recognizer with correct gender information by an
average of 11% and 5%, respectively. This work shows that the highest emotion
identification performance takes place when the classifiers are completely
biased towards suprasegmental models and no impact of acoustic models. The
results achieved based on the two-stage framework fall within 2.28% of those
obtained in subjective assessment by human judges.
</dc:description>
 <dc:description>Comment: 9 pages. arXiv admin note: text overlap with arXiv:1706.09760,
  arXiv:1707.00137</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06657</dc:identifier>
 <dc:identifier>International Journal of Speech Technology, Vol. 16, issue 2, June
  2013, pp. 133-141</dc:identifier>
 <dc:identifier>doi:10.1007/s10772-012-9170-4.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06664</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ontology-based Adaptive e-Textbook Platform for Student and Machine
  Co-Learning</dc:title>
 <dc:creator>Tay, Noel Nuo Wi</dc:creator>
 <dc:creator>Yang, Sheng-Chi</dc:creator>
 <dc:creator>Lee, Chang-Shing</dc:creator>
 <dc:creator>Kubota, Naoyuki</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The use of electronic textbooks (e-book) has been heavily studied over the
years due to their flexibility, accessibility, interactivity and extensibility.
Yet current shortcomings of e-book, which is often just a digitized version of
the original book, does not encourage adoption. Consequently, this leads to a
rethinking of e-book that should incorporate current technologies to augment
its capabilities, where inclusion of information search and organization tools
have shown to be favorable. This paper is on a preliminary work to add
intelligence into such tools in terms of information retrieval. Construction of
knowledge graph for e-book material with little overhead is first introduced.
Information retrieval through typed similarity query is then performed via
random walk. Case study demonstrate the applicability of the e-book platform,
with promising application and advancement in the area of electronic textbooks.
</dc:description>
 <dc:description>Comment: This paper is submitted to IEEE WCCI 2018 Conference for review</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06665</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Data Augmentation through Learning</dc:title>
 <dc:creator>Chrysos, Grigorios G.</dc:creator>
 <dc:creator>Panagakis, Yannis</dc:creator>
 <dc:creator>Zafeiriou, Stefanos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The rapid progress in machine learning methods has been empowered by i) huge
datasets that have been collected and annotated, ii) improved engineering (e.g.
data pre-processing/normalization). The existing datasets typically include
several million samples, which constitutes their extension a colossal task. In
addition, the state-of-the-art data-driven methods demand a vast amount of
data, hence a standard engineering trick employed is artificial data
augmentation for instance by adding into the data cropped and (affinely)
transformed images. However, this approach does not correspond to any change in
the natural 3D scene.
  We propose instead to perform data augmentation through learning realistic
local transformations. We learn a forward and an inverse transformation that
maps an image from the high-dimensional space of pixel intensities to a latent
space which varies (approximately) linearly with the latent space of a
realistically transformed version of the image. Such transformed images can be
considered two successive frames in a video. Next, we utilize these
transformations to learn a linear model that modifies the latent spaces and
then use the inverse transformation to synthesize a new image. We argue that
the this procedure produces powerful invariant representations. We perform both
qualitative and quantitative experiments that demonstrate our proposed method
creates new realistic images.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06679</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Riding on the Primary: A New Spectrum Sharing Paradigm for
  Wireless-Powered IoT Devices</dc:title>
 <dc:creator>Kang, Xin</dc:creator>
 <dc:creator>Liang, Ying-Chang</dc:creator>
 <dc:creator>Yang, Jing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a new spectrum sharing model referred to as riding on the
primary (ROP) is proposed for wireless-powered IoT devices with ambient
backscatter communication capabilities. The key idea of ROP is that the
secondary transmitter harvests energy from the primary signal, then modulates
its information bits to the primary signal, and reflects the modulated signal
to the secondary receiver without violating the primary system's interference
requirement. Compared with the conventional spectrum sharing model, the
secondary system in the proposed ROP not only utilizes the spectrum of the
primary system but also takes advantage of the primary signal to harvest energy
and to carry its information. In this paper, we investigate the performance of
such a spectrum sharing system under fading channels. To be specific, we
maximize the ergodic capacity of the secondary system by jointly optimizing the
transmit power of the primary signal and the reflection coefficient of the
secondary ambient backscatter. Different (ideal/practical) energy consumption
models, different (peak/average) transmit power constraints, different types
(fixed/dynamically adjustable) reflection coefficient, different primary
system's interference requirements (rate/outage) are considered. Optimal power
allocation and reflection coefficient are obtained for each scenario.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Trans. Wireless Communications</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06682</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Securing UAV Communications via Joint Trajectory and Power Control</dc:title>
 <dc:creator>Zhang, Guangchi</dc:creator>
 <dc:creator>Wu, Qingqing</dc:creator>
 <dc:creator>Cui, Miao</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Unmanned aerial vehicle (UAV) communication is anticipated to be widely
applied in the forthcoming fifth-generation (5G) wireless networks, due to its
many advantages such as low cost, high mobility, and on-demand deployment.
However, the broadcast and line-of-sight (LoS) nature of air-to-ground wireless
channels gives rise to a new challenge on how to realize secure UAV
communications with the destined nodes on the ground. This paper aims to tackle
this challenge by applying the physical (PHY) layer security technique. We
consider both the downlink and uplink UAV communications with a ground node,
namely UAV-to-ground (U2G) and ground-to-UAV (G2U) communication, respectively,
subject to a potential eavesdropper on the ground. In contrast to the existing
literature on wireless PHY layer security only with ground nodes at fixed or
quasi-static locations, we exploit the high mobility of the UAV to proactively
establish favorable and degraded channels for the legitimate and eavesdropping
links, respectively, via its trajectory design. We formulate new problems to
maximize the average secrecy rates of the U2G and G2U transmissions,
respectively, by jointly optimizing the UAV's trajectory and the transmit power
of the legitimate transmitter over a given flight period of the UAV. Although
the formulated problems are non-convex, we propose iterative algorithms to
solve them efficiently by applying the block coordinate descent and successive
convex optimization methods. Specifically, the transmit power and UAV
trajectory are each optimized with the other being fixed in an alternating
manner, until they converge. Simulation results show that the proposed
algorithms can improve the secrecy rates for both U2G and G2U communications,
as compared to other benchmark schemes without power control and/or trajectory
optimization.
</dc:description>
 <dc:description>Comment: Submitted for possible journal publication</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06687</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Directionally Selective Small Target Motion Detecting Visual Neural
  Network in Cluttered Backgrounds</dc:title>
 <dc:creator>Wang, Hongxin</dc:creator>
 <dc:creator>Peng, Jigen</dc:creator>
 <dc:creator>Yue, Shigang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Discriminating targets moving against a cluttered background is a huge
challenge, let alone detecting a target as small as one or a few pixels and
tracking it in flight. In the fly's visual system, a class of specific neurons,
called small target motion detectors (STMDs), have been identified as showing
exquisite selectivity for small target motion. Some of the STMDs have also
demonstrated directional selectivity which means these STMDs respond strongly
only to their preferred motion direction. Directional selectivity is an
important property of these STMD neurons which could contribute to tracking
small targets such as mates in flight. However, little has been done on
systematically modeling these directional selective STMD neurons. In this
paper, we propose a directional selective STMD-based neural network (DSTMD) for
small target detection in a cluttered background. In the proposed neural
network, a new correlation mechanism is introduced for direction selectivity
via correlating signals relayed from two pixels. Then, a lateral inhibition
mechanism is implemented on the spatial field for size selectivity of STMD
neurons. Extensive experiments showed that the proposed neural network not only
is in accord with current biological findings, i.e. showing directional
preferences, but also worked reliably in detecting small targets against
cluttered backgrounds.
</dc:description>
 <dc:description>Comment: 14 pages, 24 figures</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06689</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning model-based strategies in simple environments with hierarchical
  q-networks</dc:title>
 <dc:creator>Muyesser, Necati Alp</dc:creator>
 <dc:creator>Dunovan, Kyle</dc:creator>
 <dc:creator>Verstynen, Timothy</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Recent advances in deep learning have allowed artificial agents to rival
human-level performance on a wide range of complex tasks; however, the ability
of these networks to learn generalizable strategies remains a pressing
challenge. This critical limitation is due in part to two factors: the opaque
information representation in deep neural networks and the complexity of the
task environments in which they are typically deployed. Here we propose a novel
Hierarchical Q-Network (HQN) motivated by theories of the hierarchical
organization of the human prefrontal cortex, that attempts to identify lower
dimensional patterns in the value landscape that can be exploited to construct
an internal model of rules in simple environments. We draw on combinatorial
games, where there exists a single optimal strategy for winning that
generalizes across other features of the game, to probe the strategy
generalization of the HQN and other reinforcement learning (RL) agents using
variations of Wythoff's game. Traditional RL approaches failed to reach
satisfactory performance on variants of Wythoff's Game; however, the HQN
learned heuristic-like strategies that generalized across changes in board
configuration. More importantly, the HQN allowed for transparent inspection of
the agent's internal model of the game following training. Our results show how
a biologically inspired hierarchical learner can facilitate learning abstract
rules to promote robust and flexible action policies in simplified training
environments with clearly delineated optimal strategies.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06694</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determination of Digital Straight Segments Using the Slope</dc:title>
 <dc:creator>Cartas, Alejandro</dc:creator>
 <dc:creator>Algorri, Mar&#xed;a Elena</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We present a new method for the recognition of digital straight lines based
on the slope. This method combines the Freeman's chain coding scheme and new
discovered properties of the digital slope introduced in this paper. We also
present the efficiency of our method from a testbed.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06700</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Reinforcement Learning Chatbot (Short Version)</dc:title>
 <dc:creator>Serban, Iulian V.</dc:creator>
 <dc:creator>Sankar, Chinnadhurai</dc:creator>
 <dc:creator>Germain, Mathieu</dc:creator>
 <dc:creator>Zhang, Saizheng</dc:creator>
 <dc:creator>Lin, Zhouhan</dc:creator>
 <dc:creator>Subramanian, Sandeep</dc:creator>
 <dc:creator>Kim, Taesup</dc:creator>
 <dc:creator>Pieper, Michael</dc:creator>
 <dc:creator>Chandar, Sarath</dc:creator>
 <dc:creator>Ke, Nan Rosemary</dc:creator>
 <dc:creator>Rajeswar, Sai</dc:creator>
 <dc:creator>de Brebisson, Alexandre</dc:creator>
 <dc:creator>Sotelo, Jose M. R.</dc:creator>
 <dc:creator>Suhubdy, Dendi</dc:creator>
 <dc:creator>Michalski, Vincent</dc:creator>
 <dc:creator>Nguyen, Alexandre</dc:creator>
 <dc:creator>Pineau, Joelle</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present MILABOT: a deep reinforcement learning chatbot developed by the
Montreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize
competition. MILABOT is capable of conversing with humans on popular small talk
topics through both speech and text. The system consists of an ensemble of
natural language generation and retrieval models, including neural network and
template-based models. By applying reinforcement learning to crowdsourced data
and real-world user interactions, the system has been trained to select an
appropriate response from the models in its ensemble. The system has been
evaluated through A/B testing with real-world users, where it performed
significantly better than other systems. The results highlight the potential of
coupling ensemble systems with deep reinforcement learning as a fruitful path
for developing real-world, open-domain conversational agents.
</dc:description>
 <dc:description>Comment: 9 pages, 1 figure, 2 tables; presented at NIPS 2017, Conversational
  AI: &quot;Today's Practice and Tomorrow's Potential&quot; Workshop</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06702</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secrecy Capacity of Colored Gaussian Noise Channels with Feedback</dc:title>
 <dc:creator>Li, Chong</dc:creator>
 <dc:creator>Liang, Yingbin</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:creator>Shamai, Shlomo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the k-th order autoregressive moving average (ARMA(k))
Gaussian wiretap channel with noiseless causal feedback is considered, in which
an eavesdropper receives noisy observations of the signals in both forward and
feedback channels. It is shown that a variant of the generalized
Schalkwijk-Kailath scheme, a capacity-achieving coding scheme for the feedback
Gaussian channel, achieves the same maximum rate for the same channel with the
presence of an eavesdropper. Therefore, the secrecy capacity is equal to the
feedback capacity without the presence of an eavesdropper for the feedback
channel. Furthermore, the results are extended to the additive white Gaussian
noise (AWGN) channel with quantized feedback. It is shown that the proposed
coding scheme achieves a positive secrecy rate. As the amplitude of the
quantization noise decreases to zero, the secrecy rate converges to the
capacity of the AWGN channel.
</dc:description>
 <dc:description>Comment: 23 pages, 4 figures</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06703</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision Rules for Robotic Mobile Fulfillment Systems</dc:title>
 <dc:creator>Merschformann, Marius</dc:creator>
 <dc:creator>Lamballais, Tim</dc:creator>
 <dc:creator>de Koster, Ren&#xe9;</dc:creator>
 <dc:creator>Suhl, Leena</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The Robotic Mobile Fulfillment Systems (RMFS) is a new type of robotized,
parts-to-picker material handling system, designed especially for e-commerce
warehouses. Robots bring movable shelves, called pods, to workstations where
inventory is put on or removed from the pods. This paper simulates both the
pick and replenishment process and studies the order assignment, pod selection
and pod storage assignment problems by evaluating multiple decision rules per
problem. The discrete event simulation uses realistic robot movements and keeps
track of every unit of inventory on every pod. We analyze seven performance
measures, e.g. throughput capacity and order due time, and find that the unit
throughput is strongly correlated with the other performance measures. We vary
the number of robots, the number of pick stations, the number of SKUs (stock
keeping units), the order size and whether returns need processing or not. The
decision rules for pick order assignment have a strong impact on the unit
throughput rate. This is not the case for replenishment order assignment, pod
selection and pod storage. Furthermore, for warehouses with a large number of
SKUs, more robots are needed for a high unit throughput rate, even if the
number of pods and the dimensions of the storage area remain the same. Lastly,
processing return orders only affects the unit throughput rate for warehouse
with a large number of SKUs and large pick orders.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06704</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A more reasonable proof of Cobham's theorem</dc:title>
 <dc:creator>Krebs, Thijmen J. P.</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>11B85 (Primary), 68Q45 (Secondary)</dc:subject>
 <dc:description>  We present a short new proof of Cobham's theorem without using Kronecker's
approximation theorem, making it suitable for generalization beyond automatic
sequences.
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06710</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Light Field Reconstruction from a Single Coded Image</dc:title>
 <dc:creator>Vadathya, Anil Kumar</dc:creator>
 <dc:creator>Cholleti, Saikiran</dc:creator>
 <dc:creator>Ramajayam, Gautham</dc:creator>
 <dc:creator>Kanchana, Vijayalakshmi</dc:creator>
 <dc:creator>Mitra, Kaushik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Light field imaging is a rich way of representing the 3D world around us.
However, due to limited sensor resolution capturing light field data inherently
poses spatio-angular resolution trade-off. In this paper, we propose a deep
learning based solution to tackle the resolution trade-off. Specifically, we
reconstruct full sensor resolution light field from a single coded image. We
propose to do this in three stages 1) reconstruction of center view from the
coded image 2) estimating disparity map from the coded image and center view 3)
warping center view using the disparity to generate light field. We propose
three neural networks for these stages. Our disparity estimation network is
trained in an unsupervised manner alleviating the need for ground truth
disparity. Our results demonstrate better recovery of parallax from the coded
image. Also, we get better results than dictionary learning approaches on
simulated data.
</dc:description>
 <dc:description>Comment: accepted at ACPR 2017</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06716</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mitigation of Human Exposure to RF Fields in Downlink of Millimeter-Wave
  Cellular Systems</dc:title>
 <dc:creator>Nasim, Imtiaz</dc:creator>
 <dc:creator>Kim, Seungmo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Out of the very few studies that paid proper attention to the harmful health
impacts in millimeter-wave (mmW) communications, most of them are concerned
about uplink cases due to closer contact with the human body. Our recent study
revealed that even the human exposure to radio frequency (RF) fields in
downlink mmW technology is not very minimum to be ignored. There were a few RF
exposure mitigation techniques for uplinks, but the downlink scenario is hardly
paid any attention. However, this paper proposes a downlink protocol for mmW
cellular communications that achieves the maximum data rate while keeping the
impacts on human health minimized. Our results show that the proposed technique
lowers both power density (PD) and specific absorption rate (SAR) compared to
the typical protocol, with only slight sacrifice in data rates.
</dc:description>
 <dc:description>Comment: Submitted to IEEE INFOCOM 2018. arXiv admin note: text overlap with
  arXiv:1711.03683</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06717</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Deep Learning For Title-Based Semantic Subject Indexing To Reach
  Competitive Performance to Full-Text</dc:title>
 <dc:creator>Mai, Florian</dc:creator>
 <dc:creator>Galke, Lukas</dc:creator>
 <dc:creator>Scherp, Ansgar</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  For (semi-)automated subject indexing systems in digital libraries, it is
often more practical to use metadata such as the title of a publication instead
of the full-text or the abstract. Therefore, it is desirable to have good text
mining and text classification algorithms that operate well already on the
title of a publication. So far, the classification performance on titles is not
competitive with the performance on the full-texts if the same number of
training samples is used for training. However, it is much easier to obtain
title data in large quantities and to use it for training than full-text data.
In this paper, we investigate the question how models obtained from training on
increasing amounts of title training data compare to models from training on a
constant number of full-texts. We evaluate this question on a large-scale
dataset from the medical domain (PubMed) and from economics (EconBiz). In these
datasets, the titles and annotations of millions of publications are available,
and they outnumber the available full-texts by a factor of 20 and 15,
respectively. To exploit these large amounts of data to their full potential,
we develop three strong deep learning classifiers and evaluate their
performance on the two datasets. The results are promising. On the EconBiz
dataset, all three classifiers outperform their full-text counterparts by a
large margin. The best title-based classifier outperforms the best full-text
method by 9.9%. On the PubMed dataset, the best title-based method almost
reaches the performance of the best full-text classifier, with a difference of
only 2.9%.
</dc:description>
 <dc:description>Comment: Under review at JCDL 2018, 11 pages</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06718</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analog-to-Digital Compression: A New Paradigm for Converting Signals to
  Bits</dc:title>
 <dc:creator>Kipnis, Alon</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:creator>Goldsmith, Andrea J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Processing, storing and communicating information that originates as an
analog signal involves conversion of this information to bits. This conversion
can be described by the combined effect of sampling and quantization, as
illustrated in Fig. 1. The digital representation is achieved by first sampling
the analog signal so as to represent it by a set of discrete-time samples and
then quantizing these samples to a finite number of bits. Traditionally, these
two operations are considered separately. The sampler is designed to minimize
information loss due to sampling based on characteristics of the
continuous-time input. The quantizer is designed to represent the samples as
accurately as possible, subject to a constraint on the number of bits that can
be used in the representation. The goal of this article is to revisit this
paradigm by illuminating the dependency between these two operations. In
particular, we explore the requirements on the sampling system subject to
constraints on the available number of bits for storing, communicating or
processing the analog information.
</dc:description>
 <dc:description>Comment: to appear in &quot;Signal Processing Magazine&quot;</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06719</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tutorial on Modeling and Analysis of Dynamic Social Networks. Part II</dc:title>
 <dc:creator>Proskurnikov, Anton</dc:creator>
 <dc:creator>Tempo, Roberto</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Recent years have witnessed a significant trend towards filling the gap
between Social Network Analysis (SNA) and control theory. This trend was
enabled by the introduction of new mathematical models describing dynamics of
social groups, the development of algorithms and software for data analysis and
the tremendous progress in understanding complex networks and multi-agent
systems (MAS) dynamics. The aim of this tutorial is to highlight a novel
chapter of control theory, dealing with dynamic models of social networks and
processes over them, to the attention of the broad research community. In its
first part [1], we have considered the most classical models of social
dynamics, which have anticipated and to a great extent inspired the recent
extensive studies on MAS and complex networks. This paper is the second part of
the tutorial, and it is focused on more recent models of social processes that
have been developed concurrently with MAS theory. Future perspectives of
control in social and techno-social systems are also discussed.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06720</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Rates for Spectral-regularized Algorithms with Least-Squares
  Regression over Hilbert Spaces</dc:title>
 <dc:creator>Lin, Junhong</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  In this paper, we study regression problems over a separable Hilbert space
with the square loss, covering non-parametric regression over a reproducing
kernel Hilbert space. We investigate a class of spectral-regularized
algorithms, including ridge regression, principal component analysis, and
gradient methods. We prove optimal, high-probability convergence results in
terms of variants of norms for the studied algorithms, considering a capacity
assumption on the hypothesis space and a general source condition on the target
function. Consequently, we obtain almost sure convergence results with optimal
rates. Our results improve and generalize previous results, filling a
theoretical gap for the non-attainable cases.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06724</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepISP: Learning End-to-End Image Processing Pipeline</dc:title>
 <dc:creator>Schwartz, Eli</dc:creator>
 <dc:creator>Giryes, Raja</dc:creator>
 <dc:creator>Bronstein, Alex M.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present DeepISP, a full end-to-end deep neural model of the camera image
signal processing (ISP) pipeline. Our model learns a mapping from the raw
low-light mosaiced image to the final visually compelling image and encompasses
low-level tasks such as demosaicing and denoising as well as higher-level tasks
such as color correction and image adjustment. The training and evaluation of
the pipeline was performed on a dedicated dataset containing pairs of low-light
and well-lit images captured by a Samsung S7 smartphone camera in both raw and
processed JPEG formats. The proposed solution achieves state-of-the-art
performance in objective evaluation of PSNR on the subtask of joint denoising
and demosaicing. For the full end-to-end pipeline, it achieves better visual
quality compared to the manufacturer ISP, in both a subjective human assessment
and when rated by a deep model trained for assessing image quality.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06726</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Storage-Class Memory Hierarchies for Scale-Out Servers</dc:title>
 <dc:creator>Ustiugov, Dmitrii</dc:creator>
 <dc:creator>Daglis, Alexandros</dc:creator>
 <dc:creator>Picorel, Javier</dc:creator>
 <dc:creator>Sutherland, Mark</dc:creator>
 <dc:creator>Bugnion, Edouard</dc:creator>
 <dc:creator>Falsafi, Babak</dc:creator>
 <dc:creator>Pnevmatikatos, Dionisios</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  With emerging storage-class memory (SCM) nearing commercialization, there is
evidence that it will deliver the much-anticipated high density and access
latencies within only a few factors of DRAM. Nevertheless, the
latency-sensitive nature of in-memory services makes seamless integration of
SCM in servers questionable. In this paper, we ask the question of how best to
introduce SCM for such servers to help improve overall performance per cost
over existing DRAM-only architectures. We first show that even with the best
latency projections for SCM, the higher memory access latency results in
prohibitive performance degradation. However, we find that deploying a modestly
sized high-bandwidth stacked DRAM cache makes SCM-based memory competitive. The
high degree of spatial locality in-memory services exhibit not only simplifies
the DRAM cache's design as page-based, but also enables the amortization of
increased SCM access latencies and mitigation of SCM's read/write latency
disparity. We finally perform a case study with PCM, and show that a 2
bits/cell technology hits the performance/cost sweet spot, reducing the memory
subsystem cost by 40% while keeping performance within 5% of the best
performing DRAM-only system, whereas single-level and triple-level cell
organizations are impractical for use as memory replacements.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06729</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EnKCF: Ensemble of Kernelized Correlation Filters for High-Speed Object
  Tracking</dc:title>
 <dc:creator>Uzkent, Burak</dc:creator>
 <dc:creator>Seo, YoungWoo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computer vision technologies are very attractive for practical applications
running on embedded systems. For such an application, it is desirable for the
deployed algorithms to run in high-speed and require no offline training. To
develop a single-target tracking algorithm with these properties, we propose an
ensemble of the kernelized correlation filters (KCF), we call it EnKCF. A
committee of KCFs is specifically designed to address the variations in scale
and translation of moving objects. To guarantee a high-speed run-time
performance, we deploy each of KCFs in turn, instead of applying multiple KCFs
to each frame. To minimize any potential drifts between individual KCFs
transition, we developed a particle filter. Experimental results showed that
the performance of ours is, on average, 70.10% for precision at 20 pixels,
53.00% for success rate for the OTB100 data, and 54.50% and 40.2% for the
UAV123 data. Experimental results showed that our method is better than other
high-speed trackers over 5% on precision on 20 pixels and 10-20% on AUC on
average. Moreover, our implementation ran at 340 fps for the OTB100 and at 416
fps for the UAV123 dataset that is faster than DCF (292 fps) for the OTB100 and
KCF (292 fps) for the UAV123. To increase flexibility of the proposed EnKCF
running on various platforms, we also explored different levels of deep
convolutional features.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06730</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Web password recovery --- a necessary evil?</dc:title>
 <dc:creator>Maqbali, Fatma Al</dc:creator>
 <dc:creator>Mitchell, Chris J</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Web password recovery, enabling a user who forgets their password to
re-establish a shared secret with a website, is very widely implemented.
However, use of such a fall-back system brings with it additional
vulnerabilities to user authentication. This paper provides a framework within
which such systems can be analysed systematically, and uses this to help gain a
better understanding of how such systems are best implemented. To this end, a
model for web password recovery is given, and existing techniques are
documented and analysed within the context of this model. This leads naturally
to a set of recommendations governing how such systems should be implemented to
maximise security. A range of issues for further research are also highlighted.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06732</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boundary-based Image Forgery Detection by Fast Shallow CNN</dc:title>
 <dc:creator>Zhang, Zhongping</dc:creator>
 <dc:creator>Zhang, Yixuan</dc:creator>
 <dc:creator>Zhou, Zheng</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image forgery detection is the task of detecting and localizing forged parts
in tampered images. Previous works mostly focus on high resolution images using
traces of resampling features, demosaicing features or sharpness of edges.
However, a good detection method should also be applicable to low resolution
images because compressed or resized images are common these days. To this end,
we propose a Shallow Convolutional Neural Network(SCNN), capable of
distinguishing the boundaries of forged regions from original edges in low
resolution images. SCNN is designed to utilize the information of chroma and
saturation. Based on SCNN, two approaches that are named Sliding Windows
Detection (SWD) and Fast SCNN, respectively, are developed to detect and
localize image forgery region. In this paper, we substantiate that Fast SCNN
can detect drastic change of chroma and saturation. In image forgery detection
experiments Our model is evaluated on the CASIA 2.0 dataset. The results show
that Fast SCNN performs well on low resolution images and achieves significant
improvements over the state-of-the-art.
</dc:description>
 <dc:description>Comment: Submitted to ICPR 2018. 6 pages</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06733</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Tools for the Analysis of Randomized Optimization
  Heuristics</dc:title>
 <dc:creator>Doerr, Benjamin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  This chapter collects several probabilistic tools that proved to be useful in
the analysis of randomized search heuristics. This includes classic material
like Markov, Chebyshev and Chernoff inequalities, but also lesser known topics
like stochastic domination and coupling or Chernoff bounds for geometrically
distributed random variables and for negatively correlated random variables.
Almost all of the results presented here have appeared previously, some,
however, only in recent conference publications. While the focus is on
collecting tools for the analysis of randomized search heuristics, many of
these may be useful as well in the analysis of classic randomized algorithms or
discrete random structures.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06734</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Multi-Modal Multi-Task Vehicle Control for Self-Driving Cars
  with Visual Perception</dc:title>
 <dc:creator>Yang, Zhengyuan</dc:creator>
 <dc:creator>Zhang, Yixuan</dc:creator>
 <dc:creator>Yu, Jerry</dc:creator>
 <dc:creator>Cai, Junjie</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNN) have been successfully applied to
autonomous driving tasks, many in an end-to-end manner. Previous end-to-end
steering control methods take an image or an image sequence as the input and
directly predict the steering angle with CNN. Although single task learning on
steering angles has reported good performances, the steering angle alone is not
sufficient for vehicle control. In this work, we propose a multi-task learning
framework to predict the steering angle and speed control simultaneously in an
end-to-end manner. Since it is nontrivial to predict accurate speed values with
only visual inputs, we first propose a network to predict discrete speed
commands and steering angles with image sequences. Moreover, we propose a
multi-modal multi-task network to predict speed values and steering angles by
taking previous feedback speeds and visual recordings as inputs. Experiments
are conducted on the public Udacity dataset and a newly collected SAIC dataset.
Results show that the proposed model predicts steering angles and speed values
accurately. Furthermore, we improve the failure data synthesis methods to solve
the problem of error accumulation in real road tests.
</dc:description>
 <dc:description>Comment: Submitted to ICPR 2018. 6 pages</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06736</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Construction of Quasi-Binary and Quasi-Orthogonal Matrices over
  Finite Fields</dc:title>
 <dc:creator>Gligoroski, Danilo</dc:creator>
 <dc:creator>Gjosteen, Kristian</dc:creator>
 <dc:creator>Kralevska, Katina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Orthogonal and quasi-orthogonal matrices have a long history of use in
digital image processing, digital and wireless communications, cryptography and
many other areas of computer science and coding theory. The practical benefits
of using orthogonal matrices come from the fact that the computation of inverse
matrices is avoided, by simply using the transpose of the orthogonal matrix. In
this paper, we introduce a new family of matrices over finite fields that we
call \emph{Quasi-Binary and Quasi-Orthogonal Matrices}. We call the matrices
quasi-binary due to the fact that matrices have only two elements $a, b \in
\mathbb{F}_q$, but those elements are not $0$ and $1$. In addition, the reason
why we call them quasi-orthogonal is due to the fact that their inverses are
obtained not just by a simple transposition, but there is a need for an
additional operation: a replacement of $a$ and $b$ by two other values $c$ and
$d$. We give a simple relation between the values $a, b, c$ and $d$ for any
finite field and especially for finite fields with characteristic 2. Our
construction is based on incident matrices from cyclic Latin Rectangles and the
efficiency of the proposed algorithm comes from the avoidance of matrix-matrix
or matrix-vector multiplications.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06740</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Representation for High-Level Norms and Violation Inference in
  Logic Programming</dc:title>
 <dc:creator>Akinkunmi, Babatunde Opeoluwa</dc:creator>
 <dc:creator>Babalola, Moyin Florence</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68Txx</dc:subject>
 <dc:description>  Most of the knowledge Representation formalisms developed for representing
prescriptive norms can be categorized as either suitable for representing
either low level or high level norms.We argue that low level norm
representations do not advance the cause of autonomy in agents in the sense
that it is not the agent itself that determines the normative position it
should be at a particular time, on the account of a more general rule. In other
words an agent on some external system for a nitty gritty prescriptions of its
obligations and prohibitions. On the other hand, high level norms which have an
explicit description of a norm's precondition and have some form of
implication, do not as they exist in the literature do not support generalized
inferences about violation like low level norm representations do. This paper
presents a logical formalism for the representation of high level norms in open
societies that enable violation inferences that detail the situation in which
the norm violation took place and the identity of the norm violation. Norms are
formalized as logic programs whose heads specify what an agent is obliged or
permitted to do when a situation arises and within what time constraint of the
situation.Each norm is also assigned an identity using some reification scheme.
The body of each logic program describes the nature of the situation in which
the agent is expected to act or desist from acting. This kind of violation is
novel in the literature.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06742</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-pseudo Regularized Label for Generated Samples in Person
  Re-Identification</dc:title>
 <dc:creator>Huang, Yan</dc:creator>
 <dc:creator>Xu, Jinsong</dc:creator>
 <dc:creator>Wu, Qiang</dc:creator>
 <dc:creator>Zheng, Zhedong</dc:creator>
 <dc:creator>Zhang, Zhaoxiang</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sufficient training data is normally required to train deeply learned models.
However, the number of pedestrian images per ID in person re-identification
(re-ID) datasets is usually limited, since manually annotations are required
for multiple camera views. To produce more data for training deeply learned
models, generative adversarial network (GAN) can be leveraged to generate
samples for person re-ID. However, the samples generated by vanilla GAN usually
do not have labels. So in this paper, we propose a virtual label called
Multi-pseudo Regularized Label (MpRL) and assign it to the generated images.
With MpRL, the generated samples will be used as supplementary of real training
data to train a deep model in a semi-supervised learning fashion. Considering
data bias between generated and real samples, MpRL utilizes different
contributions from pre-defined training classes. The contribution-based virtual
labels are automatically assigned to generated samples to reduce ambiguous
prediction in training. Meanwhile, MpRL only relies on pre-defined training
classes without using extra classes. Furthermore, to reduce over-fitting, a
regularized manner is applied to MpRL to regularize the learning process.
  To verify the effectiveness of MpRL, two state-of-the-art convolutional
neural networks (CNNs) are adopted in our experiments. Experiments demonstrate
that by assigning MpRL to generated samples, we can further improve the person
re-ID performance on three datasets i.e., Market-1501, DukeMTMC-reID, and
CUHK03. The proposed method obtains +6.29%, +6.30% and +5.58% improvements in
rank-1 accuracy over a strong CNN baseline respectively, and outperforms the
state-of-the-art methods.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06750</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formal Framework For Probabilistic Unclean Databases</dc:title>
 <dc:creator>De Sa, Christopher</dc:creator>
 <dc:creator>Ilyas, Ihab F.</dc:creator>
 <dc:creator>Kimelfeld, Benny</dc:creator>
 <dc:creator>Re, Christopher</dc:creator>
 <dc:creator>Rekatsinas, Theodoros</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Traditional modeling of inconsistency in database theory casts all possible
&quot;repairs&quot; equally likely. Yet, effective data cleaning needs to incorporate
statistical reasoning. For example, yearly salary of \$100k and age of 22 are
more likely than \$100k and 122 and two people with same address are likely to
share their last name (i.e., a functional dependency tends to hold but may
occasionally be violated). We propose a formal framework for unclean databases,
where two types of statistical knowledge are incorporated. The first represents
a belief of how intended (clean) data is generated, and the second represents a
belief of how the actual database is realized through the introduction of
noise.
  Formally, a Probabilistic Unclean Database (PUD) is a triple that consists of
a probabilistic database that we call the &quot;intention&quot;, a probabilistic data
transformator that we call the &quot;realization&quot;, and a dirty database that we call
the &quot;observation&quot;. We define three computational problems in this framework:
cleaning (find the most likely intention), probabilistic query answering
(compute the probability of an answer tuple), and learning (find the most
likely parameters given examples of clean and dirty databases). We illustrate
the framework on concrete representations of PUDs, show that they generalize
traditional concepts of repairs such as cardinality and value repairs, draw
connection to consistent query answering, and prove tractability results. We
further show that parameters can be learned in practical instantiations, and in
fact, prove that under certain conditions we can learn directly from a single
dirty database without any need for clean examples.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06756</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denoising Prior Driven Deep Neural Network for Image Restoration</dc:title>
 <dc:creator>Dong, Weisheng</dc:creator>
 <dc:creator>Wang, Peiyao</dc:creator>
 <dc:creator>Yin, Wotao</dc:creator>
 <dc:creator>Shi, Guangming</dc:creator>
 <dc:creator>Wu, Fangfang</dc:creator>
 <dc:creator>Lu, Xiaotong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep neural networks (DNNs) have shown very promising results for various
image restoration (IR) tasks. However, the design of network architectures
remains a major challenging for achieving further improvements. While most
existing DNN-based methods solve the IR problems by directly mapping low
quality images to desirable high-quality images, the observation models
characterizing the image degradation processes have been largely ignored. In
this paper, we first propose a denoising-based IR algorithm, whose iterative
steps can be computed efficiently. Then, the iterative process is unfolded into
a deep neural network, which is composed of multiple denoisers modules
interleaved with back-projection (BP) modules that ensure the observation
consistencies. A convolutional neural network (CNN) based denoiser that can
exploit the multi-scale redundancies of natural images is proposed. As such,
the proposed network not only exploits the powerful denoising ability of DNNs,
but also leverages the prior of the observation model. Through end-to-end
training, both the denoisers and the BP modules can be jointly optimized.
Experimental results on several IR tasks, e.g., image denoising,
super-resolution and deblurring show that the proposed method can lead to very
competitive and often state-of-the-art results on several IR tasks, including
image denoising, deblurring and super-resolution.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06761</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PU-Net: Point Cloud Upsampling Network</dc:title>
 <dc:creator>Yu, Lequan</dc:creator>
 <dc:creator>Li, Xianzhi</dc:creator>
 <dc:creator>Fu, Chi-Wing</dc:creator>
 <dc:creator>Cohen-Or, Daniel</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Learning and analyzing 3D point cloud with deep networks is challenging due
to the sparseness and irregularity of the data. In this paper, we present a
data-driven point cloud upsampling technique. The key idea is to learn
multi-level features per point, and then expanding them via a multi-branch
convolution unit, to implicitly expand the point set in feature space. The
expanded feature is then split to a multitude of features, which are then
reconstructed to an upsampled point set. Our network is applied at a
patch-level, with a joint loss function that encourages the upsampled points to
remain on the underlying surface with a uniform distribution. We conduct
various experiments using synthesis and scan data to evaluate our method and
demonstrate its superiority over some baseline methods and an
optimization-based method. The results show that our upsampled results have
better uniformity, and sampled closer to the underlying surface.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06766</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Speed Up Query Planning in Graph Databases</dc:title>
 <dc:creator>Namaki, Mohammad Hossain</dc:creator>
 <dc:creator>Chowdhury, F A Rezaur Rahman</dc:creator>
 <dc:creator>Islam, Md Rakibul</dc:creator>
 <dc:creator>Doppa, Janardhan Rao</dc:creator>
 <dc:creator>Wu, Yinghui</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Querying graph structured data is a fundamental operation that enables
important applications including knowledge graph search, social network
analysis, and cyber-network security. However, the growing size of real-world
data graphs poses severe challenges for graph databases to meet the
response-time requirements of the applications. Planning the computational
steps of query processing - Query Planning - is central to address these
challenges. In this paper, we study the problem of learning to speedup query
planning in graph databases towards the goal of improving the
computational-efficiency of query processing via training queries.We present a
Learning to Plan (L2P) framework that is applicable to a large class of query
reasoners that follow the Threshold Algorithm (TA) approach. First, we define a
generic search space over candidate query plans, and identify target search
trajectories (query plans) corresponding to the training queries by performing
an expensive search. Subsequently, we learn greedy search control knowledge to
imitate the search behavior of the target query plans. We provide a concrete
instantiation of our L2P framework for STAR, a state-of-the-art graph query
reasoner. Our experiments on benchmark knowledge graphs including DBpedia,
YAGO, and Freebase show that using the query plans generated by the learned
search control knowledge, we can significantly improve the speed of STAR with
negligible loss in accuracy.
</dc:description>
 <dc:description>Comment: Published in the Proceedings of the 27th International Conference on
  Automated Planning and Scheduling (ICAPS), 2017</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06769</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep joint rain and haze removal from single images</dc:title>
 <dc:creator>Shen, Liang</dc:creator>
 <dc:creator>Yue, Zihan</dc:creator>
 <dc:creator>Chen, Quan</dc:creator>
 <dc:creator>Feng, Fan</dc:creator>
 <dc:creator>Ma, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Rain removal from a single image is a challenge which has been studied for a
long time. In this paper, a novel convolutional neural network based on wavelet
and dark channel is proposed. On one hand, we think that rain streaks
correspond to high frequency component of the image. Therefore, haar wavelet
transform is a good choice to separate the rain streaks and background to some
extent. More specifically, the LL subband of a rain image is more inclined to
express the background information, while LH, HL, HH subband tend to represent
the rain streaks and the edges. On the other hand, the accumulation of rain
streaks from long distance makes the rain image look like haze veil. We extract
dark channel of rain image as a feature map in network. By increasing this
mapping between the dark channel of input and output images, we achieve haze
removal in an indirect way. All of the parameters are optimized by
back-propagation. Experiments on both synthetic and real- world datasets reveal
that our method outperforms other state-of- the-art methods from a qualitative
and quantitative perspective.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06771</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Make a Digital Currency on a Blockchain Stable</dc:title>
 <dc:creator>Saito, Kenji</dc:creator>
 <dc:creator>Iwamura, Mitsuru</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Bitcoin and other similar digital currencies on blockchains are not ideal
means for payment, because their prices tend to go up in the long term (thus
people are incentivized to hoard those currencies), and to fluctuate widely in
the short term (thus people would want to avoid risks of losing values).
  The reason why those blockchain currencies based on proof of work are
unstable may be found in their designs that the supplies of currencies do not
respond to their positive and negative demand shocks, as the authors have
formulated in our past work.
  Continuing from our past work, this paper proposes minimal changes to the
design of blockchain currencies so that their market prices are automatically
stabilized, absorbing both positive and negative demand shocks of the
currencies by autonomously controlling their supplies. Those changes are: 1)
limiting re-adjustment of proof-of-work targets, 2) making mining rewards
variable according to the observed over-threshold changes of block intervals,
and 3) enforcing negative interests to remove old coins in circulation. We have
made basic design checks of these measures through simple simulations.
  In addition to stabilization of prices, the proposed measures may have
effects of making those currencies preferred means for payment by
disincentivizing hoarding, and improving sustainability of the currency systems
by making rewards to miners perpetual.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06776</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Hybrid Analog and Digital Receive Beamforming Schemes for
  Efficient Interference Reduction</dc:title>
 <dc:creator>Qin, Yaolu</dc:creator>
 <dc:creator>Yang, Shuping</dc:creator>
 <dc:creator>Zhou, Xiaobo</dc:creator>
 <dc:creator>Lu, Jinhui</dc:creator>
 <dc:creator>Zhang, Yijin</dc:creator>
 <dc:creator>Wang, Jiangzhou</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In spatial spectrum estimation field, medium-scale or large-scale receive
antenna array with digital beamforming can be employed at receiver to achieve a
high-resolution direction of arrival (DOA) estimation and make a significant
interference suppression, but leads to an expensive RF-chain circuit cost.
Thus, a robust hybrid analog-and-digital beamforming (ADB) structure is
proposed to greatly reduces the number of RF-chains so that the cost of
RF-chains is lowered significantly. This ADB structure at receiver is to
attenuate the jamming signals from undesired directions and boost the receive
quality of the desired signal for the purpose of secure receiving. In this
paper, we first propose a hybrid ADB scheme with analytic expression, which
consists of null space projection in analog beamforming part and diagonal
loading method in digital beamforming part. Then, by exploiting DOA estimation
errors, we construct a robust hybrid beamforming algorithm using the
conditional expectation of DOA instead of making direct use of the estimated
DOA. Simulation result shows that the proposed robust beamforming scheme
performs more robust and makes a more efficient reduction in jamming
interference to improve the receive signal to interference and noise ratio
compared to non-burst ADB scheme proposed by us.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06782</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How can we naturally order and organize graph Laplacian eigenvectors?</dc:title>
 <dc:creator>Saito, Naoki</dc:creator>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>05C50, 06B75, 42C40, 58C40, 68R10, 90C08, 90C35</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:description>  When attempting to develop wavelet transforms for graphs and networks, some
researchers have used graph Laplacian eigenvalues and eigenvectors in place of
the frequencies and complex exponentials in the Fourier theory for regular
lattices in the Euclidean domains. This viewpoint, however, has a fundamental
flaw: on a general graph, the Laplacian eigenvalues cannot be interpreted as
the frequencies of the corresponding eigenvectors. In this paper, we discuss
this important problem further and propose a new method to organize those
eigenvectors by defining and measuring &quot;natural&quot; distances between eigenvectors
using the Ramified Optimal Transport Theory followed by embedding the resulting
distance matrix into a low-dimensional Euclidean domain for further grouping
and organization of such eigenvectors. We demonstrate its effectiveness using a
synthetic graph as well as a dendritic tree of a retinal ganglion cell of a
mouse.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06790</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoupled Learning for Conditional Adversarial Networks</dc:title>
 <dc:creator>Zhang, Zhifei</dc:creator>
 <dc:creator>Song, Yang</dc:creator>
 <dc:creator>Qi, Hairong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Incorporating encoding-decoding nets with adversarial nets has been widely
adopted in image generation tasks. We observe that the state-of-the-art
achievements were obtained by carefully balancing the reconstruction loss and
adversarial loss, and such balance shifts with different network structures,
datasets, and training strategies. Empirical studies have demonstrated that an
inappropriate weight between the two losses may cause instability, and it is
tricky to search for the optimal setting, especially when lacking prior
knowledge on the data and network.
  This paper gives the first attempt to relax the need of manual balancing by
proposing the concept of \textit{decoupled learning}, where a novel network
structure is designed that explicitly disentangles the backpropagation paths of
the two losses.
  Experimental results demonstrate the effectiveness, robustness, and
generality of the proposed method. The other contribution of the paper is the
design of a new evaluation metric to measure the image quality of generative
models. We propose the so-called \textit{normalized relative discriminative
score} (NRDS), which introduces the idea of relative comparison, rather than
providing absolute estimates like existing metrics.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06792</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attentive Recurrent Tensor Model for Community Question Answering</dc:title>
 <dc:creator>Bhatt, Gaurav</dc:creator>
 <dc:creator>Sharma, Shivam</dc:creator>
 <dc:creator>Raman, Balasubramanian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A major challenge to the problem of community question answering is the
lexical and semantic gap between the sentence representations. Some solutions
to minimize this gap includes the introduction of extra parameters to deep
models or augmenting the external handcrafted features. In this paper, we
propose a novel attentive recurrent tensor network for solving the lexical and
semantic gap in community question answering. We introduce token-level and
phrase-level attention strategy that maps input sequences to the output using
trainable parameters. Further, we use the tensor parameters to introduce a
3-way interaction between question, answer and external features in vector
space. We introduce simplified tensor matrices with L2 regularization that
results in smooth optimization during training. The proposed model achieves
state-of-the-art performance on the task of answer sentence selection (TrecQA
and WikiQA datasets) while outperforming the current state-of-the-art on the
tasks of best answer selection (Yahoo! L4) and answer triggering task (WikiQA).
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06793</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NOOP: A Domain-Theoretic Model of Nominally-Typed OOP</dc:title>
 <dc:creator>AbdelGawad, Moez</dc:creator>
 <dc:creator>Cartwright, Robert</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The majority of industrial-strength object-oriented (OO) software is written
using nominally-typed OO programming languages. Extant domain-theoretic models
of OOP developed to analyze OO type systems miss, however, a crucial feature of
these mainstream OO languages: nominality. This paper presents the construction
of NOOP as the first domain-theoretic model of OOP that includes full
class/type names information found in nominally-typed OOP. Inclusion of nominal
information in objects of NOOP and asserting that type inheritance in
statically-typed OO programming languages is an inherently nominal notion allow
readily proving that type inheritance and subtyping are completely identified
in these languages. This conclusion is in full agreement with intuitions of
developers and language designers of these OO languages, and contrary to the
belief that &quot;inheritance is not subtyping,&quot; which came from assuming
non-nominal (a.k.a., structural) models of OOP.
  To motivate the construction of NOOP, this paper briefly presents the
benefits of nominal-typing to mainstream OO developers and OO language
designers, as compared to structural-typing. After presenting NOOP, the paper
further briefly compares NOOP to the most widely known domain-theoretic models
of OOP. Leveraging the development of NOOP, the comparisons presented in this
paper provide clear, brief and precise technical and mathematical accounts for
the relation between nominal and structural OO type systems. NOOP, thus,
provides a firmer semantic foundation for analyzing and progressing
nominally-typed OO programming languages.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06794</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Rate-Optimal Construction of Codes with Sequential Recovery with Low
  Block Length</dc:title>
 <dc:creator>Babu, Balaji Srinivasan</dc:creator>
 <dc:creator>Kini, Ganesh R.</dc:creator>
 <dc:creator>Kumar, P. Vijay</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An erasure code is said to be a code with sequential recovery with parameters
$r$ and $t$, if for any $s \leq t$ erased code symbols, there is an $s$-step
recovery process in which at each step we recover exactly one erased code
symbol by contacting at most $r$ other code symbols. In earlier work by the
same authors, presented at ISIT 2017, we had given a construction for binary
codes with sequential recovery from $t$ erasures, with locality parameter $r$,
which were optimal in terms of code rate for given $r,t$, but where the block
length was large, on the order of $r^{c^t}$, for some constant $c &gt;1$. In the
present paper, we present an alternative construction of a rate-optimal code
for any value of $t$ and any $r\geq3$, where the block length is significantly
smaller, on the order of $r^{\frac{5t}{4}+\frac{7}{4}}$ (in some instances of
order $r^{\frac{3t}{2}+2}$). Our construction is based on the construction of
certain kind of tree-like graphs with girth $t+1$. We construct these graphs
and hence the codes recursively.
</dc:description>
 <dc:description>Comment: Accepted for publication in NCC 2018</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06797</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth CNNs for RGB-D scene recognition: learning from scratch better
  than transferring from RGB-CNNs</dc:title>
 <dc:creator>Song, Xinhang</dc:creator>
 <dc:creator>Herranz, Luis</dc:creator>
 <dc:creator>Jiang, Shuqiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Scene recognition with RGB images has been extensively studied and has
reached very remarkable recognition levels, thanks to convolutional neural
networks (CNN) and large scene datasets. In contrast, current RGB-D scene data
is much more limited, so often leverages RGB large datasets, by transferring
pretrained RGB CNN models and fine-tuning with the target RGB-D dataset.
However, we show that this approach has the limitation of hardly reaching
bottom layers, which is key to learn modality-specific features. In contrast,
we focus on the bottom layers, and propose an alternative strategy to learn
depth features combining local weakly supervised training from patches followed
by global fine tuning with images. This strategy is capable of learning very
discriminative depth-specific features with limited depth images, without
resorting to Places-CNN. In addition we propose a modified CNN architecture to
further match the complexity of the model and the amount of data available. For
RGB-D scene recognition, depth and RGB features are combined by projecting them
in a common space and further leaning a multilayer classifier, which is jointly
optimized in an end-to-end network. Our framework achieves state-of-the-art
accuracy on NYU2 and SUN RGB-D in both depth only and combined RGB-D data.
</dc:description>
 <dc:description>Comment: AAAI Conference on Artificial Intelligence 2017</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06797</dc:identifier>
 <dc:identifier>AAAI Conference on Artificial Intelligence 2017, 4271-4277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06801</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Curvature-based Comparison of Two Neural Networks</dc:title>
 <dc:creator>Yu, Tao</dc:creator>
 <dc:creator>Long, Huan</dc:creator>
 <dc:creator>Hopcroft, John E.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we show the similarities and differences of two deep neural
networks by comparing the manifolds composed of activation vectors in each
fully connected layer of them. The main contribution of this paper includes 1)
a new data generating algorithm which is crucial for determining the dimension
of manifolds; 2) a systematic strategy to compare manifolds. Especially, we
take Riemann curvature and sectional curvature as part of criterion, which can
reflect the intrinsic geometric properties of manifolds. Some interesting
results and phenomenon are given, which help in specifying the similarities and
differences between the features extracted by two networks and demystifying the
intrinsic mechanism of deep neural networks.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06805</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoupled Learning for Factorial Marked Temporal Point Processes</dc:title>
 <dc:creator>Wu, Weichang</dc:creator>
 <dc:creator>Yan, Junchi</dc:creator>
 <dc:creator>Yang, Xiaokang</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper introduces the factorial marked temporal point process model and
presents efficient learning methods. In conventional (multi-dimensional) marked
temporal point process models, event is often encoded by a single discrete
variable i.e. a marker. In this paper, we describe the factorial marked point
processes whereby time-stamped event is factored into multiple markers.
Accordingly the size of the infectivity matrix modeling the effect between
pairwise markers is in power order w.r.t. the number of the discrete marker
space. We propose a decoupled learning method with two learning procedures: i)
directly solving the model based on two techniques: Alternating Direction
Method of Multipliers and Fast Iterative Shrinkage-Thresholding Algorithm; ii)
involving a reformulation that transforms the original problem into a Logistic
Regression model for more efficient learning. Moreover, a sparse group
regularizer is added to identify the key profile features and event labels.
Empirical results on real world datasets demonstrate the efficiency of our
decoupled and reformulated method. The source code is available online.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures, submitted to TNNLS, 21 Jan, 2018</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06807</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Universal Semantic Space</dc:title>
 <dc:creator>Dufter, Philipp</dc:creator>
 <dc:creator>Sch&#xfc;tze, Hinrich</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Multilingual embeddings build on the success of monolingual embeddings and
have applications in crosslingual transfer, in machine translation and in the
digital humanities. We present the first multilingual embedding space for
thousands of languages, a much larger number of languages than in prior work.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06810</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guidelines for Systematic Mapping Studies in Security Engineering</dc:title>
 <dc:creator>Felderer, Michael</dc:creator>
 <dc:creator>Carver, Jeffrey C.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Security engineering in the software lifecycle aims at protecting information
and systems to guarantee confidentiality, integrity, and availability. As
security engineering matures and the number of research papers grows, there is
an increasing need for papers that summarize results and provide an overview of
the area. A systematic mapping study &quot;maps&quot; a research area by classifying
papers to identify which topics are well-studied and which need additional
study. Therefore, systematic mapping studies are becoming increasingly
important in security engineering. This chapter provides methodological support
for systematic mapping studies in security engineering based on examples from
published security engineering papers. Because security engineering is similar
to software engineering in that it bridges research and practice, researchers
can use the same basic systematic mapping process, as follows: (1) study
planning, (2) searching for studies, (3) study selection, (4) study quality
assessment, (5) data extraction, (6) data classification, (7) data analysis,
and (8) reporting of results. We use published mapping studies to describe the
tailoring of this process for security engineering. In addition to guidance on
how to perform systematic mapping studies in security engineering, this chapter
should increase awareness in the security engineering community of the need for
additional mapping studies.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06812</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recent Results on Classifying Risk-Based Testing Approaches</dc:title>
 <dc:creator>Felderer, Michael</dc:creator>
 <dc:creator>Grossmann, Juergen</dc:creator>
 <dc:creator>Schieferdecker, Ina</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In order to optimize the usage of testing efforts and to assess risks of
software-based systems, risk-based testing uses risk (re-)assessments to steer
all phases in a test process. Several risk-based testing approaches have been
proposed in academia and/or applied in industry, so that the determination of
principal concepts and methods in risk-based testing is needed to enable a
comparison of the weaknesses and strengths of different risk-based testing
approaches. In this chapter we provide an (updated) taxonomy of risk-based
testing aligned with risk considerations in all phases of a test process. It
consists of three top-level classes, i.e., contextual setup, risk assessment,
and risk-based test strategy. This taxonomy provides a framework to understand,
categorize, assess and compare risk-based testing approaches to support their
selection and tailoring for specific purposes. Furthermore, we position four
recent risk-based testing approaches into the taxonomy in order to demonstrate
its application and alignment with available risk-based testing approaches.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06818</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recovering a Hidden Community in a Preferential Attachment Graph</dc:title>
 <dc:creator>Hajek, Bruce</dc:creator>
 <dc:creator>Sankagiri, Suryanarayana</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  A message passing algorithm (MP) is derived for recovering a dense subgraph
within a graph generated by a variation of the Barab\'{a}si-Albert preferential
attachment model. The estimator is assumed to know the arrival times, or order
of attachment, of the vertices. The derivation of the algorithm is based on
belief propagation under an independence assumption. Two precursors to the
message passing algorithm are analyzed: the first is a degree thresholding (DT)
algorithm and the second is an algorithm based on the arrival times of the
children (C) of a given vertex, where the children of a given vertex are the
vertices that attached to it. C significantly outperforms DT, showing it is
beneficial to know the arrival times of the children, beyond simply knowing the
number of them. It is shown that for a fixed fraction of vertices in the
community $\rho$, fixed number of new edges per arriving vertex $m$, and fixed
affinity between vertices in the community $\beta$, the fraction of label
errors for either of the algorithms DT or C, or converges as $T\to\infty.$
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06819</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Next-Best-Smell Approach for Remote Gas Detection with a Mobile Robot</dc:title>
 <dc:creator>Polvara, Riccardo</dc:creator>
 <dc:creator>Trabattoni, Marco</dc:creator>
 <dc:creator>Kucner, Tomasz Piotr</dc:creator>
 <dc:creator>Schaffernicht, Erik</dc:creator>
 <dc:creator>Amigoni, Francesco</dc:creator>
 <dc:creator>Lilienthal, Achim J.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The problem of gas detection is relevant to many real-world applications,
such as leak detection in industrial settings and landfill monitoring. Using
mobile robots for gas detection has several advantages and can reduce danger
for humans. In our work, we address the problem of planning a path for a mobile
robotic platform equipped with a remote gas sensor, which minimizes the time to
detect all gas sources in a given environment. We cast this problem as a
coverage planning problem by defining a basic sensing operation -- a scan with
the remote gas sensor -- as the field of &quot;view&quot; of the sensor. Given the
computing effort required by previously proposed offline approaches, in this
paper we suggest a online coverage algorithm, called Next-Best-Smell, adapted
from the Next-Best-View class of exploration algorithms. Our algorithm
evaluates candidate locations with a global utility function, which combines
utility values for travel distance, information gain, and sensing time, using
Multi-Criteria Decision Making. In our experiments, conducted both in
simulation and with a real robot, we found the performance of the
Next-Best-Smell approach to be comparable with that of the state-of-the-art
offline algorithm, at much lower computational cost.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06822</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ERIM: Secure and Efficient In-process Isolation with Memory Protection
  Keys</dc:title>
 <dc:creator>Vahldiek-Oberwagner, Anjo</dc:creator>
 <dc:creator>Elnikety, Eslam</dc:creator>
 <dc:creator>Garg, Deepak</dc:creator>
 <dc:creator>Druschel, Peter</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Many applications can benefit from isolating sensitive data in a secure
library. Examples include protecting cryptographic keys behind a narrow
cryptography API to defend against vulnerabilities like OpenSSL's Heartbleed
bug. When such a library is called relatively infrequently, page-based hardware
isolation can be used, because the cost of kernel-mediated domain switching is
tolerable. However, some applications require very frequent domain switching,
such as isolating code pointers to prevent control flow hijack attacks in
code-pointer integrity (CPI). These applications have relied on weaker
isolation techniques like address-space layout randomization (ASLR), which
allow efficient switching but have proved vulnerable to attack.
  In this paper, we present ERIM, a novel technique that combines the security
of hardware-enforced isolation with a switching performance near that of ASRL.
ERIM can support sensitive data access up to a million times per CPU core a
second with low overhead. The key idea is to combine memory protection keys
(MPKs), a feature recently added to Intel CPUs, with binary rewriting to
prevent circumvention. ERIM provides three primitives: isolation, call gates,
and syscall mediation. We show how to apply ERIM to isolate frequently accessed
session keys (not just the long-term keys) in nginx, a high performance web
server, and how to isolate sensitive data in CPI. Our measurements indicate a
negligible degradation in performance, even with very high rates of switching
between the untrusted application and the secure library.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06825</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composite Behavioral Modeling for Identity Theft Detection in Online
  Social Networks</dc:title>
 <dc:creator>Wang, Cheng</dc:creator>
 <dc:creator>Yang, Bo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this work, we aim at building a bridge from poor behavioral data to an
effective, quick-response, and robust behavior model for online identity theft
detection. We concentrate on this issue in online social networks (OSNs) where
users usually have composite behavioral records, consisting of
multi-dimensional low-quality data, e.g., offline check-ins and online user
generated content (UGC). As an insightful result, we find that there is a
complementary effect among different dimensions of records for modeling users'
behavioral patterns. To deeply exploit such a complementary effect, we propose
a joint model to capture both online and offline features of a user's composite
behavior. We evaluate the proposed joint model by comparing with some typical
models on two real-world datasets: Foursquare and Yelp. In the widely-used
setting of theft simulation (simulating thefts via behavioral replacement), the
experimental results show that our model outperforms the existing ones, with
the AUC values $0.956$ in Foursquare and $0.947$ in Yelp, respectively.
Particularly, the recall (True Positive Rate) can reach up to $65.3\%$ in
Foursquare and $72.2\%$ in Yelp with the corresponding disturbance rate (False
Positive Rate) below $1\%$. It is worth mentioning that these performances can
be achieved by examining only one composite behavior (visiting a place and
posting a tip online simultaneously) per authentication, which guarantees the
low response latency of our method. This study would give the cybersecurity
community new insights into whether and how a real-time online identity
authentication can be improved via modeling users' composite behavioral
patterns.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06827</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Impostors for Location Privacy Preservation</dc:title>
 <dc:creator>Wang, Cheng</dc:creator>
 <dc:creator>Xie, Zhiyang</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The progress of location-based services has led to serious concerns on
location privacy leakage. For effective and efficient location privacy
preservation (LPP), existing methods are still not fully competent. They are
often vulnerable under the identification attack with side information, or hard
to be implemented due to the high computational complexity. In this paper, we
pursue the high protection efficacy and low computational complexity
simultaneously. We propose a \emph{scalable} LPP method based on the paradigm
of counterfeiting locations. To make fake locations extremely plausible, we
forge them through synthesizing \emph{artificial impostors} (AIs). The AIs
refer to the synthesized traces which have similar semantic features to the
actual traces, and do \emph{not} contain any target location. Two dedicated
techniques are devised: the \emph{sampling-based synthesis method} and
\emph{population-level semantic model}. They play significant roles in two
critical steps of synthesizing AIs. We conduct experiments on real datasets in
two cities (Shanghai, China and Asturias, Spain) to validate the high efficacy
and scalability of the proposed method. In these two datasets, the experimental
results show that our method achieves the preservation efficacy of $97.65\%$
and $96.12\%$, and its run time of building the generators is only $230.47$ and
$215.92$ seconds, respectively. This study would give the research community
new insights into improving the practicality of the state-of-the-art LPP
paradigm via counterfeiting locations.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06828</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Input Adaptation via Natural Type Selection</dc:title>
 <dc:creator>Tridenski, Sergey</dc:creator>
 <dc:creator>Zamir, Ram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For the model of communication through a discrete memoryless channel using
i.i.d. random block codes, where the channel is changing slowly from block to
block, we propose a stochastic algorithm for adaptation of the generating
distribution of the code in the process of continuous reliable communication.
The purpose of the algorithm is to match the generating distribution $Q(x)$ to
the changing channel $P(y\,|\,x)$, so that reliable communication is maintained
at some constant rate $R$. This is achieved by a feedback of one bit per
transmitted block. The feedback bit is determined by the joint type of the last
transmitted codeword and the received block, a constant threshold $T&gt;R$, and
some conditional distribution $\Phi(x\,|\,y)$. Depending on the value of the
feedback bit, the system parameters $Q(x)$ and $\Phi(x\,|\,y)$ are both updated
according to the joint type of the last transmitted and received blocks, or
remain unchanged.
  We show that, under certain technical conditions, the iterations of the
algorithm lead to a distribution $Q(x)$, which guarantees reliable
communication for all rates below the threshold $T$, provided that the discrete
memoryless channel capacity of $P(y\,|\,x)$ stays above $T$.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, submitted to ISIT-2018</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06830</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Multi-task Learning in Automated Assessment</dc:title>
 <dc:creator>Cummins, Ronan</dc:creator>
 <dc:creator>Rei, Marek</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Grammatical error detection and automated essay scoring are two tasks in the
area of automated assessment. Traditionally these tasks have been treated
independently with different machine learning models and features used for each
task. In this paper, we develop a multi-task neural network model that jointly
optimises for both tasks, and in particular we show that neural automated essay
scoring can be significantly improved. We show that while the essay score
provides little evidence to inform grammatical error detection, the essay score
is highly influenced by error detection.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06831</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dense Recurrent Neural Networks for Scene Labeling</dc:title>
 <dc:creator>Fan, Heng</dc:creator>
 <dc:creator>Ling, Haibin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently recurrent neural networks (RNNs) have demonstrated the ability to
improve scene labeling through capturing long-range dependencies among image
units. In this paper, we propose dense RNNs for scene labeling by exploring
various long-range semantic dependencies among image units. In comparison with
existing RNN based approaches, our dense RNNs are able to capture richer
contextual dependencies for each image unit via dense connections between each
pair of image units, which significantly enhances their discriminative power.
Besides, to select relevant and meanwhile restrain irrelevant dependencies for
each unit from dense connections, we introduce an attention model into dense
RNNs. The attention model enables automatically assigning more importance to
helpful dependencies while less weight to unconcerned dependencies. Integrating
with convolutional neural networks (CNNs), our method achieves state-of-the-art
performances on the PASCAL Context, MIT ADE20K and SiftFlow benchmarks.
</dc:description>
 <dc:description>Comment: Tech. Report</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06835</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Multi-User Wireless Charging Power Allocation</dc:title>
 <dc:creator>Gu, Yanju</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Wireless power charging enables portable devices to be permanently unplugged.
Due to its low transmission power and low transmission efficiency, it requires
much longer time slot to charge users compared with that for data transmission
in wireless communication networks. Besides, each user's demand urgency needs
to be taken into consideration for power allocation. Therefore, new algorithms
are essential for wireless power allocation in multi-user wireless charging
networks. In this paper, this problem is formulated as a static noncooperative
game. It is shown that there exists a unique Nash equilibrium, which is the
static state of the wireless power charging network. A distributed power
allocation algorithm is proposed to compute the Nash equilibrium of the game.
The main result of the paper consists of rigorous analysis of the distributed
algorithm for power allocation. The algorithm is shown to converge to Nash
equilibrium of the game with exponentially convergence rate for arbitrary
initial value with synchronous scheduling. Moreover, the distributed algorithm
is also convergence guaranteed with asynchronous scheduling under communication
delay and packet drops. Numerical simulations prove the correctness of the
analysis and demonstrate the fast convergence of the algorithm and the
robustness to synchronous scheduling.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06837</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>System-of-Systems Viewpoint for System Architecture Documentation</dc:title>
 <dc:creator>Klein, John</dc:creator>
 <dc:creator>van Vliet, Hans</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Context: The systems comprising a system of systems (SoS) are inde- pendently
acquired, operated, and managed. Frequently, the architecture documentation of
these existing systems addresses only a stand-alone perspective, and must be
augmented to address concerns that arise in the integrated SoS. Objective: We
evaluated an architecture documentation viewpoint to address the concerns of a
SoS architect about a constituent system, to support SoS design and analysis
involving that constituent system. Method: We performed an expert review of
documentation produced by applying the viewpoint to a system, using the active
review method. Results: The expert panel was able to used a view constructed
using the baseline version of the viewpoint to answer questions related to all
SoS architect concerns about a constituent system, except for questions
concerning the interaction of the constituent system with the platform and
network infrastructure. Conclusions: We found that the expert panel was unable
to answer certain questions because the baseline version of the viewpoint had a
gap in coverage related to relationship of software units of execution (e.g.,
processes or services) to computers and networks. The viewpoint was revised to
add a Deployment Model to address these concerns, and is included in an
appendix.
</dc:description>
 <dc:description>Comment: 49 pages</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06841</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UAV-Enabled Cooperative Jamming for Improving Secrecy of Ground Wiretap
  Channel</dc:title>
 <dc:creator>An, Li</dc:creator>
 <dc:creator>Qingqing, Wu</dc:creator>
 <dc:creator>Rui, Zhang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  This letter proposes a novel UAV-enabled mobile jamming scheme to improve the
secrecy rate of ground wiretap channel. Specifically, a UAV is employed to
transmit jamming signals to combat against eavesdropping. Such a mobile jamming
scheme is particularly appealing since the UAV-enabled jammer can fly close to
the eavesdropper and opportunistically jam it by leveraging the UAV's mobility.
We aim to maximize the average secrecy rate by jointly optimizing the UAV's
trajectory and jamming power over a given flight period. To make the problem
more tractable, we drive a closed-form lower bound for the achievable secrecy
rate, based on which the UAV's trajectory and transmit power are optimized
alternately by an efficient iterative algorithm applying the block coordinate
descent and successive convex optimization techniques. Simulation results
demonstrate that the proposed joint design can significantly enhance the
secrecy rate of the considered wiretap system as compared to benchmark schemes.
</dc:description>
 <dc:description>Comment: Keywords: UAV communication, physical layer security, mobile jammer,
  trajectory design, power control.
  http://ieeexplore.ieee.org/document/8247211/</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06845</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time series kernel similarities for predicting Paroxysmal Atrial
  Fibrillation from ECGs</dc:title>
 <dc:creator>Bianchi, Filippo Maria</dc:creator>
 <dc:creator>Livi, Lorenzo</dc:creator>
 <dc:creator>Ferrante, Alberto</dc:creator>
 <dc:creator>Milosevic, Jelena</dc:creator>
 <dc:creator>Malek, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We tackle the problem of classifying Electrocardiography (ECG) signals with
the aim of predicting the onset of Paroxysmal Atrial Fibrillation (PAF). Atrial
fibrillation is the most common type of arrhythmia, but in many cases PAF
episodes are asymptomatic. Therefore, in order to help diagnosing PAF, it is
important to be design a suitable procedure for detecting and, more
importantly, predicting PAF episodes. We propose a method for predicting PAF
events whose first step consists of a feature extraction procedure that
represents each ECG as a multi-variate time series. Successively, we design a
classification framework based on kernel similarities for multi-variate time
series, capable of handling missing data. We consider different approaches to
perform classification in the original space of the multi-variate time series
and in an embedding space, defined by the kernel similarity measure. Our
classification results show state-of-the-art performance in terms of accuracy.
Furthermore, we demonstrate the ability to predict, with high accuracy, the PAF
onset up to 15 minutes in advance.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06846</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linking and Cutting Spanning Trees</dc:title>
 <dc:creator>Russo, Lu&#xed;s M. S.</dc:creator>
 <dc:creator>Teixeira, Andreia Sofia</dc:creator>
 <dc:creator>Francisco, Alexandre P</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We consider the problem of uniformly generating a spanning tree, of a
connected undirected graph. This process is useful to compute statistics,
namely for phylogenetic trees. We describe a Markov chain for producing these
trees. For cycle graphs we prove that this approach significantly outperforms
existing algorithms. For general graphs we obtain no analytical bounds, but
experimental results show that the chain still converges quickly. This yields
an efficient algorithm, also due to the use of proper fast data structures. To
bound the mixing time of the chain we describe a coupling, which we analyse for
cycle graphs and simulate for other graphs.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06847</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monocular Imaging-based Autonomous Tracking for Low-cost Quad-rotor
  Design - TraQuad</dc:title>
 <dc:creator>Shrinivasan, Lakshmi</dc:creator>
 <dc:creator>R, Prasad N</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  TraQuad is an autonomous tracking quadcopter capable of tracking any moving
(or static) object like cars, humans, other drones or any other object
on-the-go. This article describes the applications and advantages of TraQuad
and the reduction in cost (to about 250$) that has been achieved so far using
the hardware and software capabilities and our custom algorithms wherever
needed. This description is backed by strong data and the research analyses
which have been drawn out of extant information or conducted on own when
necessary. This also describes the development of completely autonomous (even
GPS is optional) low-cost drone which can act as a major platform for further
developments in automation, transportation, reconnaissance and more. We
describe our ROS Gazebo simulator and our STATUS algorithms which form the core
of our development of our object tracking drone for generic purposes.
</dc:description>
 <dc:description>Comment: 19 pages, pre-print, 23 figures (ignoring nested figure count),
  Journal, robotics, drone, double column, Keywords: drone, image processing,
  quadcopter, control, machine learning, communication. This is our genuine and
  humble effort to publish our research on our innovation for which we have
  spent one and a half years to get the hardware and the custom software right</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06854</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outage Analysis of Energy Harvesting based Opportunistic Cooperative
  Communication Systems</dc:title>
 <dc:creator>Gu, Yanju</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Wireless energy harvesting constitutes an effective way to prolong the
lifetime of wireless networks. In this paper, an opportunistic
decode-and-forward cooperative communication system is investigated, where the
energy-constrained relays harvest energy from the received information signal
and the co-channel interference (CCI) signals and then use that harvested
energy to forward the correctly decoded signal to the destination. Different
from conventional relaying system with constant energy supplier, the
transmission power of the energy-constrained relay depends on the available
energy that harvested, which is a random process. Best relay selection that
takes into account all the impacting ingredients on the received signal quality
at the destination is deployed. The exact closed-form expression of the outage
probability is derived, and the optimal value of the energy harvesting ratio
for achieving minimum outage is numerically investigated. In addition, the
impacts of the CCI signals on the system's outage and diversity performances
are analyzed. It is shown that the proposed relaying scheme can achieve full
diversity order equal to the number of relays without the need of fixed power
supplier.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06856</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Delay Origins of Fundamental Tradeoffs Between Risk of Large
  Fluctuations and Network Connectivity</dc:title>
 <dc:creator>Somarakis, Christoforos</dc:creator>
 <dc:creator>Ghaedsharaf, Yaser</dc:creator>
 <dc:creator>Motee, Nader</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  For the class of noisy time-delay linear consensus networks, we obtain
explicit formulae for risk of large fluctuations of a scalar observable as a
function of Laplacian spectrum and its eigenvectors. It is shown that there is
an intrinsic tradeoff between risk of large fluctuations and effective
resistance of the underlying coupling graph of the network. The main
implication is that increasing network connectivity makes network riskier to
large fluctuations. For vector-valued observables, we obtain computationally
tractable lower and upper bounds for joint risk measures. Then, we study
behavior of risk measures for networks with specific graph topologies and show
how risk of large fluctuations scales with network size.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06861</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geolocating social media posts for emergency mapping</dc:title>
 <dc:creator>Pernici, Barbara</dc:creator>
 <dc:creator>Francalanci, Chiara</dc:creator>
 <dc:creator>Scalia, Gabriele</dc:creator>
 <dc:creator>Corsi, Marco</dc:creator>
 <dc:creator>Grandoni, Domenico</dc:creator>
 <dc:creator>Biscardi, Mariano Alfonso</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The demo will illustrate the features of a webGIS interface to support the
rapid mapping activities after a natural disaster, with the goal of providing
additional information from social media to the mapping operators. This demo
shows the first results of the E2mC H2020 European project, where the goal is
to extract precisely located information from available social media sources,
providing accurate geolocating functionalities and, starting from posts
searched in Twitter, extending the social media exploration to Flickr, YouTube,
and Instagram.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06863</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Bots for Policy and Research: Challenges, Methods, and
  Solutions</dc:title>
 <dc:creator>Gorwa, Robert</dc:creator>
 <dc:creator>Guilbeault, Douglas</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Amidst widespread reports of digital influence operations during major
elections, policymakers, scholars, and journalists have become increasingly
interested in the political impact of social media 'bots.' Most recently,
platform companies like Facebook and Twitter have been summoned to testify
about bots as part of investigations into digitally-enabled foreign
manipulation during the 2016 US Presidential election. Facing mounting pressure
from both the public and from legislators, these companies have been instructed
to crack down on apparently malicious bot accounts. But as this article
demonstrates, since the earliest writings on bots in the 1990s, there has been
substantial confusion as to exactly what a 'bot' is and what exactly a bot
does. We argue that multiple forms of ambiguity are responsible for much of the
complexity underlying contemporary bot-related policy, and that before
successful policy interventions can be formulated, a more comprehensive
understanding of bots --- especially how they are defined and measured --- will
be needed. In this article, we provide a history and typology of different
types of bots, provide clear guidelines to better categorize political
automation and unpack the impact that it can have on contemporary technology
policy, and outline the main challenges and ambiguities that will face both
researchers and legislators concerned with bots in the future.
</dc:description>
 <dc:description>Comment: Submitted to Policy and Internet. This draft to be presented at the
  2018 conference of the International Communication Association (ICA)</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06864</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Convex Optimization Framework for Constrained Concurrent Motion
  Control of a Hybrid Redundant Surgical System</dc:title>
 <dc:creator>Alambeigi, Farshid</dc:creator>
 <dc:creator>Sefati, Shahriar</dc:creator>
 <dc:creator>Armand, Mehran</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a constrained motion control framework for a redundant surgical
system designed for minimally invasive treatment of pelvic osteolysis. The
framework comprises a kinematics model of a six Degrees-of-Freedom (DoF)
robotic arm integrated with a one DoF continuum manipulator as well as a novel
convex optimization redundancy resolution controller. To resolve the redundancy
resolution problem, formulated as a constrained l2-regularized quadratic
minimization, we study and evaluate the potential use of an optimally tuned
alternating direction method of multipliers (ADMM) algorithm. To this end, we
prove global convergence of the algorithm at linear rate and propose
expressions for the involved parameters resulting in a fast convergence.
Simulations on the robotic system verified our analytical derivations and
showed the capability and robustness of the ADMM algorithm in constrained
motion control of our redundant surgical system.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures, To be appeared in IEEE American Control
  Conference (ACC) 2018</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06866</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sector-Based Radio Resource Allocation (SBRRA) Algorithm for Better
  Quality of Service and Experience in Device-to-Device (D2D) Communication</dc:title>
 <dc:creator>Gandotra, Pimmy</dc:creator>
 <dc:creator>Jha, Rakesh Kumar</dc:creator>
 <dc:creator>Jain, Sanjeev</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The mounting content sharing among users has resulted in a considerable rise
in wireless data traffic, pressurizing the cellular networks to undergo a
suitable upheaval. A competent technology of the fifth-generation networks (5G)
for efficiently supporting proximity-based applications is Device-to-Device
(D2D) communication, underlaying cellular networks. Significant advances have
been made till date, for allocating resources to D2D users in cellular
networks, such that sharing of spectral resources between cellular and D2D
users is carried out in a coordinated manner. In this paper, a sector-based
radio resource allocation (SBRRA) algorithm for resource block allocation to
D2D pairs has been proposed, where the number of resource blocks (RBs) is
allocated to each D2D pair in an adaptive manner, based on the demanded
application by each pair. Different applications demand a varying number of
RBs, in accordance with their priority. This algorithm focusses on the use of
sectored antennas at the base station, for a better performance and low
complexity. Extensive simulations are carried out, considering real-time
scenario, for ensuring satisfactory Quality of Service (QoS) and Quality of
Experience (QoE) by the users. The efficiency of the proposed scheme is proved
by comparing it with the RB allocation using Hidden Markov Model (HMM).
</dc:description>
 <dc:description>Comment: IEEE Transactions</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06866</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2017.2787767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06867</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene recognition with CNNs: objects, scales and dataset bias</dc:title>
 <dc:creator>Herranz, Luis</dc:creator>
 <dc:creator>Jiang, Shuqiang</dc:creator>
 <dc:creator>Li, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Since scenes are composed in part of objects, accurate recognition of scenes
requires knowledge about both scenes and objects. In this paper we address two
related problems: 1) scale induced dataset bias in multi-scale convolutional
neural network (CNN) architectures, and 2) how to combine effectively
scene-centric and object-centric knowledge (i.e. Places and ImageNet) in CNNs.
An earlier attempt, Hybrid-CNN, showed that incorporating ImageNet did not help
much. Here we propose an alternative method taking the scale into account,
resulting in significant recognition gains. By analyzing the response of
ImageNet-CNNs and Places-CNNs at different scales we find that both operate in
different scale ranges, so using the same network for all the scales induces
dataset bias resulting in limited performance. Thus, adapting the feature
extractor to each particular scale (i.e. scale-specific CNNs) is crucial to
improve recognition, since the objects in the scenes have their specific range
of scales. Experimental results show that the recognition accuracy highly
depends on the scale, and that simple yet carefully chosen multi-scale
combinations of ImageNet-CNNs and Places-CNNs, can push the state-of-the-art
recognition accuracy in SUN397 up to 66.26% (and even 70.17% with deeper
architectures, comparable to human performance).
</dc:description>
 <dc:description>Comment: CVPR 2016</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06867</dc:identifier>
 <dc:identifier>L. Herranz, S. Jiang, X. Li, &quot;Scene recognition with CNNs:
  objects, scales and dataset bias&quot;, Proc. International Conference on Computer
  Vision and Pattern Recognition (CVPR16), Las Vegas, Nevada, USA, June 2016</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2016.68</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06876</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-composition to Prove Relational Properties in Annotated C Program</dc:title>
 <dc:creator>Blatter, Lionel</dc:creator>
 <dc:creator>Kosmatov, Nikolai</dc:creator>
 <dc:creator>Gall, Pascale Le</dc:creator>
 <dc:creator>Prevosto, Virgile</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Deductive verification provides a powerful tool to show functional properties
of a given program. However, in practice, many properties of interest link
several program calls. This is for instance the case for non-interference,
continuity and monotony. Other examples relate sequences of function calls, for
instance to show that decrypting an encrypted message with the appropriate key
gives back the original one message. Such properties cannot be expressed
directly in the traditional setting used by modular deductive verification, but
are amenable to verification through self-composition. This paper presents a
verification tool dedicated to relational properties, in the form of a Frama-C
plug-in called RPP and based on self-composition. It supports functions with
side effects and recursive functions. Our initial experiments on existing
benchmarks confirm that RPP is useful to prove relational properties.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06879</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Deep Convolutional Encoder-Decoder Networks for Surrogate
  Modeling and Uncertainty Quantification</dc:title>
 <dc:creator>Zhu, Yinhao</dc:creator>
 <dc:creator>Zabaras, Nicholas</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We are interested in the development of surrogate models for uncertainty
quantification and propagation in problems governed by stochastic PDEs using a
deep convolutional encoder-decoder network in a similar fashion to approaches
considered in deep learning for image-to-image regression tasks. Since normal
neural networks are data intensive and cannot provide predictive uncertainty,
we propose a Bayesian approach to convolutional neural nets. A recently
introduced variational gradient descent algorithm based on Stein's method is
scaled to deep convolutional networks to perform approximate Bayesian inference
on millions of uncertain network parameters. This approach achieves state of
the art performance in terms of predictive accuracy and uncertainty
quantification in comparison to other approaches in Bayesian neural networks as
well as techniques that include Gaussian processes and ensemble methods even
when the training data size is relatively small. To evaluate the performance of
this approach, we consider standard uncertainty quantification benchmark
problems including flow in heterogeneous media defined in terms of limited
data-driven permeability realizations. The performance of the surrogate model
developed is very good even though there is no underlying structure shared
between the input (permeability) and output (flow/pressure) fields as is often
the case in the image-to-image regression models used in computer vision
problems. Studies are performed with an underlying stochastic input
dimensionality up to $4,225$ where most other uncertainty quantification
methods fail. Uncertainty propagation tasks are considered and the predictive
output Bayesian statistics are compared to those obtained with Monte Carlo
estimates.
</dc:description>
 <dc:description>Comment: 52 pages, 28 figures, submitted to Journal of Computational Physics</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06883</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dialectica Categories for the Lambek Calculus</dc:title>
 <dc:creator>de Paiva, Valeria</dc:creator>
 <dc:creator>Eades III, Harley</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We revisit the old work of de Paiva on the models of the Lambek Calculus in
dialectica models making sure that the syntactic details that were sketchy on
the first version got completed and verified. We extend the Lambek Calculus
with a \kappa modality, inspired by Yetter's work, which makes the calculus
commutative. Then we add the of-course modality !, as Girard did, to
re-introduce weakening and contraction for all formulas and get back the full
power of intuitionistic and classical logic. We also present the categorical
semantics, proved sound and complete. Finally we show the traditional
properties of type systems, like subject reduction, the Church-Rosser theorem
and normalization for the calculi of extended modalities, which we did not have
before.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06883</dc:identifier>
 <dc:identifier>In: Artemov S., Nerode A. (eds) Logical Foundations of Computer
  Science. LFCS 2018. Lecture Notes in Computer Science, vol 10703, . Springer,
  Cham</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-72056-2_16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06886</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Intuitionistic Linear Logical Semantics of SAND Attack Trees</dc:title>
 <dc:creator>Eades III, Harley</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this paper we introduce a new logical foundation of SAND attack trees in
intuitionistic linear logic. This new foundation is based on a new logic called
the Attack Tree Linear Logic (ATLL). Before introducing ATLL we given several
new logical models of attack trees, the first, is a very basic model based in
truth tables. Then we lift this semantics into a semantics of attack trees
based on lineales which introduces implication, but this can be further lifted
into a dialectica model which ATLL is based. One important feature of ATLL is
that it supports full distributivity of sequential conjunction over choice.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06889</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Analytics in Deep Learning: An Interrogative Survey for the Next
  Frontiers</dc:title>
 <dc:creator>Hohman, Fred</dc:creator>
 <dc:creator>Kahng, Minsuk</dc:creator>
 <dc:creator>Pienta, Robert</dc:creator>
 <dc:creator>Chau, Duen Horng</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>I.5.1.d</dc:subject>
 <dc:subject>I.6.9.c</dc:subject>
 <dc:subject>I.6.9.f</dc:subject>
 <dc:subject>I.2.6.g</dc:subject>
 <dc:description>  Deep learning has recently seen rapid development and significant attention
due to its state-of-the-art performance on previously-thought hard problems.
However, because of the innate complexity and nonlinear structure of deep
neural networks, the underlying decision making processes for why these models
are achieving such high performance are challenging and sometimes mystifying to
interpret. As deep learning spreads across domains, it is of paramount
importance that we equip users of deep learning with tools for understanding
when a model works correctly, when it fails, and ultimately how to improve its
performance. Standardized toolkits for building neural networks have helped
democratize deep learning; visual analytics systems have now been developed to
support model explanation, interpretation, debugging, and improvement. We
present a survey of the role of visual analytics in deep learning research,
noting its short yet impactful history and summarize the state-of-the-art using
a human-centered interrogative framework, focusing on the Five W's and How
(Why, Who, What, How, When, and Where), to thoroughly summarize deep learning
visual analytics research. We conclude by highlighting research directions and
open research problems. This survey helps new researchers and practitioners in
both visual analytics and deep learning to quickly learn key aspects of this
young and rapidly growing body of research, whose impact spans a diverse range
of domains.
</dc:description>
 <dc:description>Comment: Under review for IEEE Transactions on Visualization and Computer
  Graphics (TVCG)</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06897</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Optimal Majority Threshold as a Function of the Variation
  Coefficient of the Environment</dc:title>
 <dc:creator>Chebotarev, P. Yu.</dc:creator>
 <dc:creator>Malyshev, V. A.</dc:creator>
 <dc:creator>Tsodikova, Ya. Yu.</dc:creator>
 <dc:creator>Loginov, A. K.</dc:creator>
 <dc:creator>Lezina, Z. M.</dc:creator>
 <dc:creator>Afonkin, V. A.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>91B12, 91B70</dc:subject>
 <dc:description>  Within the model of social dynamics determined by collective decisions in a
stochastic environment (ViSE model), we consider the case of a homogeneous
society consisting of classically rational economic agents (or homines
economici, or egoists). We present expressions for the optimal majority
threshold and the maximum expected capital increment as functions of the
parameters of the environment. An estimate of the rate of change of the optimal
threshold at zero is given, which is an absolute constant:
$(\sqrt{2/\pi}-\sqrt{\pi/2})/2$.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06900</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Learning of Optimal Markov Network Topology with k-Tree
  Modeling</dc:title>
 <dc:creator>Ding, Liang</dc:creator>
 <dc:creator>Chang, Di</dc:creator>
 <dc:creator>Malmberg, Russell</dc:creator>
 <dc:creator>Martinez, Aaron</dc:creator>
 <dc:creator>Robinson, David</dc:creator>
 <dc:creator>Wicker, Matthew</dc:creator>
 <dc:creator>Yan, Hongfei</dc:creator>
 <dc:creator>Cai, Liming</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The seminal work of Chow and Liu (1968) shows that approximation of a finite
probabilistic system by Markov trees can achieve the minimum information loss
with the topology of a maximum spanning tree. Our current paper generalizes the
result to Markov networks of tree width $\leq k$, for every fixed $k\geq 2$. In
particular, we prove that approximation of a finite probabilistic system with
such Markov networks has the minimum information loss when the network topology
is achieved with a maximum spanning $k$-tree. While constructing a maximum
spanning $k$-tree is intractable for even $k=2$, we show that polynomial
algorithms can be ensured by a sufficient condition accommodated by many
meaningful applications. In particular, we prove an efficient algorithm for
learning the optimal topology of higher order correlations among random
variables that belong to an underlying linear structure.
</dc:description>
 <dc:description>Comment: 18 pages main text, 2 pages appendix</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06920</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-Domain Transfer in Reinforcement Learning using Target Apprentice</dc:title>
 <dc:creator>Joshi, Girish</dc:creator>
 <dc:creator>Chowdhary, Girish</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we present a new approach to Transfer Learning (TL) in
Reinforcement Learning (RL) for cross-domain tasks. Many of the available
techniques approach the transfer architecture as a method of speeding up the
target task learning. We propose to adapt and reuse the mapped source task
optimal-policy directly in related domains. We show the optimal policy from a
related source task can be near optimal in target domain provided an adaptive
policy accounts for the model error between target and source. The main benefit
of this policy augmentation is generalizing policies across multiple related
domains without having to re-learn the new tasks. Our results show that this
architecture leads to better sample efficiency in the transfer, reducing sample
complexity of target task learning to target apprentice learning.
</dc:description>
 <dc:description>Comment: To appear as conference paper in ICRA 2018</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06928</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge-Preserving Piecewise Linear Image Smoothing Using Piecewise
  Constant Filters</dc:title>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:creator>Chen, Xiaogang</dc:creator>
 <dc:creator>Huang, Xiaolin</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Yang, Jie</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Most image smoothing filters in the literature assume a piecewise constant
model of smoothed output images. However, the piecewise constant model
assumption can cause artifacts such as gradient reversals in applications such
as image detail enhancement, HDR tone mapping, etc. In these applications, a
piecewise linear model assumption is more preferred. In this paper, we propose
a simple yet very effective framework to smooth images of piecewise linear
model assumption using classical filters with the piecewise constant model
assumption. Our method is capable of handling with gradient reversal artifacts
caused by the piecewise constant model assumption. In addition, our method can
further help accelerated methods, which need to quantize image intensity values
into different bins, to achieve similar results that need a large number of
bins using a much smaller number of bins. This can greatly reduce the
computational cost. We apply our method to various classical filters with the
piecewise constant model assumption. Experimental results of several
applications show the effectiveness of the proposed method.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06934</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Iteration Complexity Analysis of Stochastic Primal-Dual Hybrid
  Gradient Approach with High Probability</dc:title>
 <dc:creator>Qiao, Linbo</dc:creator>
 <dc:creator>Lin, Tianyi</dc:creator>
 <dc:creator>Qin, Qi</dc:creator>
 <dc:creator>Lu, Xicheng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose a stochastic Primal-Dual Hybrid Gradient (PDHG)
approach for solving a wide spectrum of regularized stochastic minimization
problems, where the regularization term is composite with a linear function. It
has been recognized that solving this kind of problem is challenging since the
closed-form solution of the proximal mapping associated with the regularization
term is not available due to the imposed linear composition, and the
per-iteration cost of computing the full gradient of the expected objective
function is extremely high when the number of input data samples is
considerably large.
  Our new approach overcomes these issues by exploring the special structure of
the regularization term and sampling a few data points at each iteration.
Rather than analyzing the convergence in expectation, we provide the detailed
iteration complexity analysis for the cases of both uniformly and non-uniformly
averaged iterates with high probability. This strongly supports the good
practical performance of the proposed approach. Numerical experiments
demonstrate that the efficiency of stochastic PDHG, which outperforms other
competing algorithms, as expected by the high-probability convergence analysis.
</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06940</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MRI Image-to-Image Translation for Cross-Modality Image Registration and
  Segmentation</dc:title>
 <dc:creator>Yang, Qianye</dc:creator>
 <dc:creator>Li, Nannan</dc:creator>
 <dc:creator>Zhao, Zixu</dc:creator>
 <dc:creator>Fan, Xingyu</dc:creator>
 <dc:creator>Chang, Eric I-Chao</dc:creator>
 <dc:creator>Xu, Yan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We develop a novel cross-modality generation framework that learns to
generate predicted modalities from given modalities in MR images without real
acquisition. Our proposed method performs image-to-image translation by means
of a deep learning model that leverages conditional generative adversarial
networks (cGANs). Our framework jointly exploits the low-level features
(pixel-wise information) and high-level representations (e.g. brain tumors,
brain structure like gray matter, etc.) between cross modalities which are
important for resolving the challenging complexity in brain structures. Based
on our proposed framework, we first propose a method for cross-modality
registration by fusing the deformation fields to adopt the cross-modality
information from predicted modalities. Second, we propose an approach for MRI
segmentation, translated multichannel segmentation (TMS), where given
modalities, along with predicted modalities, are segmented by fully
convolutional networks (FCN) in a multi-channel manner. Both these two methods
successfully adopt the cross-modality information to improve the performance
without adding any extra data. Experiments demonstrate that our proposed
framework advances the state-of-the-art on five MRI datasets. We also observe
encouraging results in cross-modality registration and segmentation on some
widely adopted datasets. Overall, our work can serve as an auxiliary method in
clinical diagnosis and be applied to various tasks in medical fields.
  Keywords: Image-to-image, cross-modality, registration, segmentation, MRI
</dc:description>
 <dc:description>Comment: 39 pages, 11 figures</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06953</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Effect of Vibration on Shape Sensing of Continuum Manipulators
  Using Fiber Bragg Gratings</dc:title>
 <dc:creator>Sefati, Shahriar</dc:creator>
 <dc:creator>Alambeigi, Farshid</dc:creator>
 <dc:creator>Iordachita, Iulian</dc:creator>
 <dc:creator>Taylor, Russell</dc:creator>
 <dc:creator>Armand, Mehran</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Fiber Bragg Grating (FBG) has shown great potential in shape and force
sensing of continuum manipulators (CM) and biopsy needles. In the recent years,
many researchers have studied different manufacturing and modeling techniques
of FBG-based force and shape sensors for medical applications. These studies
mainly focus on obtaining shape and force information in a static (or
quasi-static) environment. In this paper, however, we study and evaluate
dynamic environments where the FBG data is affected by vibration caused by a
harmonic force e.g. a rotational debriding tool harmonically exciting the CM
and the FBG-based shape sensor. In such situations, appropriate pre-processing
of the FBG signal is necessary in order to infer correct information from the
raw signal. We look at an example of such dynamic environments in the less
invasive treatment of osteolysis by studying the FBG data both in time- and
frequency-domain in presence of vibration due to a debriding tool rotating
inside the lumen of the CM.
</dc:description>
 <dc:description>Comment: Accepted for International Symposium on Medical Robotics 2018</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06954</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A port-Hamiltonian approach to the control of nonholonomic systems</dc:title>
 <dc:creator>Ferguson, Joel</dc:creator>
 <dc:creator>Donaire, Alejandro</dc:creator>
 <dc:creator>Renton, Christopher</dc:creator>
 <dc:creator>Middleton, Richard H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper a method of controlling nonholonomic systems within the
port-Hamiltonian (pH) framework is presented. It is well known that
nonholonomic systems can be represented as pH systems without Lagrange
multipliers by considering a reduced momentum space. Here, we revisit the
modelling of these systems for the purpose of identifying the role that
physical damping plays. Using this representation, a geometric structure
generalising the well known chained form is identified as \textit{chained
structure}. A discontinuous control law is then proposed for pH systems with
chained structure such that the configuration of the system asymptotically
approaches the origin. The proposed control law is robust against the damping
and inertial of the open-loop system. The results are then demonstrated
numerically on a car-like vehicle.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06956</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Capacity of Degraded Cognitive Interference Channel with
  Unidirectional Destination Cooperation</dc:title>
 <dc:creator>Kazemi, Mohammad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Previous works established the capacity region for some special cases of
discrete memoryless degraded cognitive interference channel (CIC) with
unidirectional destination cooperation (UDC). In this letter, we characterize
the capacity region of the general discrete memoryless degraded CIC-UDC. The
obtained results imply that the capacity region is achieved by the
Gel'fand-Pinsker coding at the cognitive transmitter, superposition coding at
the primary transmitter and decode-and-forward at the relay. Furthermore, using
this general result and a novel converse analysis, we establish the capacity of
the Gaussian degraded CIC-UDC, which had been open until this work.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06964</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opportunism in Dynamic Spectrum Access for 5G: A Concept and Its
  Application to Duplexing</dc:title>
 <dc:creator>Kim, Jeemin</dc:creator>
 <dc:creator>Kim, Soo-Min</dc:creator>
 <dc:creator>Cha, Han</dc:creator>
 <dc:creator>Choi, Jinho</dc:creator>
 <dc:creator>Ko, Seung-Woo</dc:creator>
 <dc:creator>Chae, Chan-Byoung</dc:creator>
 <dc:creator>Kim, Seong-Lyun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the envisioned massive Internet-of-Things (IoT) era, one of the
challenges for 5G wireless systems will be handling the unprecedented spectrum
crunch. A potential solution has emerged in the form of spectrum sharing, which
deviates from a monopolistic spectrum usage system. This article investigates
the medium access control (MAC) as a means of increasing the viability of the
spectrum sharing technique. We first quantify the opportunity of spectrum
access in a probabilistic manner, a method referred to as opportunity
probability (OP). Based on the OP framework, we propose a random MAC algorithm
in which the access of a node is randomly determined with its own OP value. As
a possible application of our OP based random MAC, we propose a hybrid half
duplex (HD)/full duplex (FD) communication where each pair decides the
duplexing mode according to the OP values of the two pair nodes. This approach
fits well with the spectrum sharing system since it enables a flexible
operation for the spectrum access according to the spectrum usage level. From
the numerical analysis, we validate the feasibility and verify the performance
enhancements by implementing an FPGA based real-time prototype. Measurements
and numerical results confirm that the proposed architecture can achieve up to
4 times higher system throughput than conventional LTE-TDD (time division
duplex) systems.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures, real-time demonstration at IEEE Globecom,
  Singapore in Dec. 2017, and full demonstration video is available at
  http://www.cbchae.org/</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06965</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Density-based Clustering Algorithm for Higher-Dimensional
  Data</dc:title>
 <dc:creator>Boonchoo, Thapana</dc:creator>
 <dc:creator>Ao, Xiang</dc:creator>
 <dc:creator>He, Qing</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  DBSCAN is a typically used clustering algorithm due to its clustering ability
for arbitrarily-shaped clusters and its robustness to outliers. Generally, the
complexity of DBSCAN is O(n^2) in the worst case, and it practically becomes
more severe in higher dimension. Grid-based DBSCAN is one of the recent
improved algorithms aiming at facilitating efficiency. However, the performance
of grid-based DBSCAN still suffers from two problems: neighbour explosion and
redundancies in merging, which make the algorithms infeasible in
high-dimensional space. In this paper, we propose a novel algorithm named GDPAM
attempting to extend Grid-based DBSCAN to higher data dimension. In GDPAM, a
bitmap indexing is utilized to manage non-empty grids so that the neighbour
grid queries can be performed efficiently. Furthermore, we adopt an efficient
union-find algorithm to maintain the clustering information in order to reduce
redundancies in the merging. The experimental results on both real-world and
synthetic datasets demonstrate that the proposed algorithm outperforms the
state-of-the-art exact/approximate DBSCAN and suggests a good scalability.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06968</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convexity of mutual information along the heat flow</dc:title>
 <dc:creator>Wibisono, Andre</dc:creator>
 <dc:creator>Jog, Varun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the convexity of mutual information along the evolution of the heat
equation. We prove that if the initial distribution is log-concave, then mutual
information is always a convex function of time. We also prove that if the
initial distribution is either bounded, or has finite fourth moment and Fisher
information, then mutual information is eventually convex, i.e., convex for all
large time. Finally, we provide counterexamples to show that mutual information
can be nonconvex at small time.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06975</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extreme Learning Machine with Local Connections</dc:title>
 <dc:creator>Li, Feng</dc:creator>
 <dc:creator>Yang, Sibo</dc:creator>
 <dc:creator>Huang, Huanhuan</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper is concerned with the sparsification of the input-hidden weights
of ELM (Extreme Learning Machine). For ordinary feedforward neural networks,
the sparsification is usually done by introducing certain regularization
technique into the learning process of the network. But this strategy can not
be applied for ELM, since the input-hidden weights of ELM are supposed to be
randomly chosen rather than to be learned. To this end, we propose a modified
ELM, called ELM-LC (ELM with local connections), which is designed for the
sparsification of the input-hidden weights as follows: The hidden nodes and the
input nodes are divided respectively into several corresponding groups, and an
input node group is fully connected with its corresponding hidden node group,
but is not connected with any other hidden node group. As in the usual ELM, the
hidden-input weights are randomly given, and the hidden-output weights are
obtained through a least square learning. In the numerical simulations on some
benchmark problems, the new ELM-CL behaves better than the traditional ELM.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06976</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Improved LPTC Neural Model for Background Motion Direction Estimation</dc:title>
 <dc:creator>Wang, Hongxin</dc:creator>
 <dc:creator>Peng, Jigen</dc:creator>
 <dc:creator>Yue, Shigang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A class of specialized neurons, called lobula plate tangential cells (LPTCs)
has been shown to respond strongly to wide-field motion. The classic model,
elementary motion detector (EMD) and its improved model, two-quadrant detector
(TQD) have been proposed to simulate LPTCs. Although EMD and TQD can percept
background motion, their outputs are so cluttered that it is difficult to
discriminate actual motion direction of the background. In this paper, we
propose a max operation mechanism to model a newly-found transmedullary neuron
Tm9 whose physiological properties do not map onto EMD and TQD. This proposed
max operation mechanism is able to improve the detection performance of TQD in
cluttered background by filtering out irrelevant motion signals. We will
demonstrate the functionality of this proposed mechanism in wide-field motion
perception.
</dc:description>
 <dc:description>Comment: 6 pages, 11 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06989</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prioritizing Technical Debt in Database Normalization Using Portfolio
  Theory and Data Quality Metrics</dc:title>
 <dc:creator>Albarak, Mashel</dc:creator>
 <dc:creator>Bahsoon, Rami</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Database normalization is the one of main principles for designing relational
databases. The benefits of normalization can be observed through improving data
quality and performance, among the other qualities. We explore a new context of
technical debt manifestation, which is linked to ill-normalized databases. This
debt can have long-term impact causing systematic degradation of database
qualities. Such degradation can be liken to accumulated interest on a debt. We
claim that debts are likely to materialize for tables below the fourth normal
form. Practically, achieving fourth normal form for all the tables in the
database is a costly and idealistic exercise. Therefore, we propose a pragmatic
approach to prioritize tables that should be normalized to the fourth normal
form based on the metaphoric debt and interest of the ill-normalized tables,
observed on data quality and performance. For data quality, tables are
prioritized using the risk of data inconsistency metric. Unlike data quality, a
suitable metric to estimate the impact of weakly or un-normalized tables on
performance is not available. We estimate performance degradation and its costs
using Input\Output (I\O) cost of the operations performed on the tables and we
propose a model to estimate this cost for each table. We make use of Modern
Portfolio Theory to prioritize tables that should be normalized based on the
estimated I\O cost and the likely risk of cost accumulation in the future. To
evaluate our methods, we use a case study from Microsoft, AdventureWorks. The
results show that our methods can be effective in reducing normalization debt
and improving the quality of the database.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07003</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Properties of Twisted Reed-Solomon Codes with Applications to
  Cryptography</dc:title>
 <dc:creator>Beelen, Peter</dc:creator>
 <dc:creator>Bossert, Martin</dc:creator>
 <dc:creator>Puchinger, Sven</dc:creator>
 <dc:creator>Rosenkilde, Johan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present a generalisation of Twisted Reed-Solomon codes containing a new
large class of MDS codes. We prove that the code class contains a large
subfamily that is closed under duality. Furthermore, we study the Schur squares
of the new codes and show that their dimension is often large. Using these
structural properties, we single out a subfamily of the new codes which could
be considered for code-based cryptography: we show that these codes resist
existing structural attacks for Reed-Solomon-like codes, i.e. methods for
retrieving the code parameters from an obfuscated generator matrix.
</dc:description>
 <dc:description>Comment: 5 pages, submitted to: IEEE International Symposium on Information
  Theory 2018</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07004</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Public Sentiment and Demand for Used Cars after A Large-Scale Disaster:
  Social Media Sentiment Analysis with Facebook Pages</dc:title>
 <dc:creator>Shibuya, Yuya</dc:creator>
 <dc:creator>Tanaka, Hideyuki</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  There have been various studies analyzing public sentiment after a
large-scale disaster. However, few studies have focused on the relationship
between public sentiment on social media and its results on people's activities
in the real world. In this paper, we conduct a long-term sentiment analysis
after the Great East Japan Earthquake and Tsunami of 2011 using Facebook Pages
with the aim of investigating the correlation between public sentiment and
people's actual needs in areas damaged by water disasters. In addition, we try
to analyze whether different types of disaster-related communication created
different kinds of relationships on people's activities in the physical world.
Our analysis reveals that sentiment of geo-info-related communication, which
might be affected by sentiment inside a damaged area, had a positive
correlation with the prices of used cars in the damaged area. On the other
hand, the sentiment of disaster-interest-based-communication, which might be
affected more by people who were interested in the disaster, but were outside
the damaged area, had a negative correlation with the prices of used cars. The
result could be interpreted to mean that when people begin to recover, used-car
prices rise because they become more positive in their sentiment. This study
suggests that, for long-term disaster-recovery analysis, we need to consider
the different characteristics of online communication posted by locals directly
affected by the disaster and non-locals not directly affected by the disaster.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07005</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ACGreGate: A Framework for Practical Access Control for Applications
  using Weakly Consistent Databases</dc:title>
 <dc:creator>Weber, Mathias</dc:creator>
 <dc:creator>Bieniusa, Annette</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Scalable and highly available systems often require data stores that offer
weaker consistency guarantees than traditional relational databases systems.
The correctness of these applications highly depends on the resilience of the
application model against data inconsistencies. In particular regarding
application security, it is difficult to determine which inconsistencies can be
tolerated and which might lead to security breaches.
  In this paper, we discuss the problem of how to develop an access control
layer for applications using weakly consistent data stores without loosing the
performance benefits gained by using weaker consistency models. We present
ACGreGate, a Java framework for implementing correct access control layers for
applications using weakly consistent data stores. Under certain requirements on
the data store, ACGreGate ensures that the access control layer operates
correctly with respect to dynamically adaptable security policies. We used
ACGreGate to implement the access control layer of a student management system.
This case study shows that practically useful security policies can be
implemented with the framework incurring little overhead. A comparison with a
setup using a centralized server shows the benefits of using ACGreGate for
scalability of the service to geo-scale.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07006</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Power Decoding of Interleaved One-Point Hermitian Codes</dc:title>
 <dc:creator>Puchinger, Sven</dc:creator>
 <dc:creator>Rosenkilde, Johan</dc:creator>
 <dc:creator>Bouw, Irene</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a new partial decoding algorithm for $h$-interleaved one-point
Hermitian codes that can decode-under certain assumptions-an error of relative
weight up to $1-(\tfrac{k+g}{n})^{\frac{h}{h+1}}$, where $k$ is the dimension,
$n$ the length, and $g$ the genus of the code. Simulation results for various
parameters indicate that the new decoder achieves this maximal decoding radius
with high probability. The algorithm is based on a recent generalization of
Rosenkilde's improved power decoder to interleaved Reed-Solomon codes, does not
require an expensive root-finding step, and improves upon the previous best
decoding radius by Kampf at all rates. In the special case $h=1$, we obtain an
adaption of the improved power decoding algorithm to one-point Hermitian codes,
which for all simulated parameters achieves a similar observed failure
probability as the Guruswami-Sudan decoder above the latter's guaranteed
decoding radius.
</dc:description>
 <dc:description>Comment: 18 pages, submitted to Designs, Codes and Cryptography</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07008</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>INKA: An Ink-based Model of Graph Visualization</dc:title>
 <dc:creator>Nguyen, Quan Hoang</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Common quality metrics of graph drawing have been about the readability
criteria, such as small number of edge crossings, small drawing area and small
total edge length. Bold graph drawing considers more realistic drawings
consisting of vertices as disks of some radius and edges as rectangles of some
width. However, the relationship that links these readability criteria with the
rendering criteria in node-link diagrams has still not been well-established.
  This paper introduces a model, so-called INKA (Ink-Active), that encapsulates
mathematically the relationship between all common drawing factors.
Consequently, we investigate our INKA model on several common drawing
algorithms and real-world graphs.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07009</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Analysis of Framework-Specific Exceptions in Android Apps</dc:title>
 <dc:creator>Fan, Lingling</dc:creator>
 <dc:creator>Su, Ting</dc:creator>
 <dc:creator>Chen, Sen</dc:creator>
 <dc:creator>Meng, Guozhu</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Xu, Lihua</dc:creator>
 <dc:creator>Pu, Geguang</dc:creator>
 <dc:creator>Su, Zhendong</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Mobile apps have become ubiquitous. For app developers, it is a key priority
to ensure their apps' correctness and reliability. However, many apps still
suffer from occasional to frequent crashes, weakening their competitive edge.
Large-scale, deep analyses of the characteristics of real-world app crashes can
provide useful insights to guide developers, or help improve testing and
analysis tools. However, such studies do not exist -- this paper fills this
gap. Over a four-month long effort, we have collected 16,245 unique exception
traces from 2,486 open-source Android apps, and observed that
framework-specific exceptions account for the majority of these crashes. We
then extensively investigated the 8,243 framework-specific exceptions (which
took six person-months): (1) identifying their characteristics (e.g.,
manifestation locations, common fault categories), (2) evaluating their
manifestation via state-of-the-art bug detection techniques, and (3) reviewing
their fixes. Besides the insights they provide, these findings motivate and
enable follow-up research on mobile apps, such as bug detection, fault
localization and patch generation. In addition, to demonstrate the utility of
our findings, we have optimized Stoat, a dynamic testing tool, and implemented
ExLocator, an exception localization tool, for Android apps. Stoat is able to
quickly uncover three previously-unknown, confirmed/fixed crashes in Gmail and
Google+; ExLocator is capable of precisely locating the root causes of
identified exceptions in real-world apps. Our substantial dataset is made
publicly available to share with and benefit the community.
</dc:description>
 <dc:description>Comment: ICSE'18: the 40th International Conference on Software Engineering</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07009</dc:identifier>
 <dc:identifier>doi:10.1145/3180155.3180222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07011</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ongoing Events in Wikipedia: A Cross-lingual Case Study</dc:title>
 <dc:creator>Gottschalk, Simon</dc:creator>
 <dc:creator>Demidova, Elena</dc:creator>
 <dc:creator>Bernacchi, Viola</dc:creator>
 <dc:creator>Rogers, Richard</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In order to effectively analyze information regarding ongoing events that
impact local communities across language and country borders, researchers often
need to perform multilingual data analysis. This analysis can be particularly
challenging due to the rapidly evolving event-centric data and the language
barrier. In this abstract we present preliminary results of a case study with
the goal to better understand how researchers interact with multilingual
event-centric information in the context of cross-cultural studies and which
methods and features they use.
</dc:description>
 <dc:description>Comment: Proceedings of the 2017 ACM on Web Science Conference</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07011</dc:identifier>
 <dc:identifier>doi:10.1145/3091478.3098879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07013</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence Covering Similarity for Symbolic Sequence Comparison</dc:title>
 <dc:creator>Marteau, Pierre-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper introduces the sequence covering similarity, that we have formally
define for evaluating the similarity between a symbolic sequence and a set of
symbolic sequences. From this covering similarity we derive a pair-wise
distance to compare two symbolic sequences. We show that this covering distance
is a metric.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1712.02084</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07022</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capturability-based Analysis, Optimization and Control of 3D Bipedal
  Walking</dc:title>
 <dc:creator>Caron, St&#xe9;phane</dc:creator>
 <dc:creator>Escande, Adrien</dc:creator>
 <dc:creator>Lanari, Leonardo</dc:creator>
 <dc:creator>Mallein, Bastien</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Capturability analysis of the linear inverted pendulum model (LIPM) enabled
walking over even terrains based on the capture point. We generalize this
analysis to the inverted pendulum model (IPM) and show how it enables 3D
walking over uneven terrains based on capture inputs. Thanks to a tailored
optimization scheme, we can compute these inputs fast enough for a real-time
control loop. We implement this approach as open-source software and
demonstrate it in simulations.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07026</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do Mobile Developers Ask on Q&amp;A Sites About Error Codes Thrown by a
  Cross-Platform App Development Framework? An Empirical Study</dc:title>
 <dc:creator>Martinez, Matias</dc:creator>
 <dc:creator>Lecomte, Sylvain</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  During last years development frameworks have emerged to make easier the
development and maintenance of cross-platform mobile applications. Xamarin
framework is one of them: it takes as input an app written in C# and produces
native code for Android, iOS and Windows Mobile platforms. When using Xamarin,
developers can meet errors, identified with codes, thrown by the
framework.Unfortunately, the Xamarin official documentation does not provide a
complete description, solution or workaround for all those codes.In this paper,
we analyze two sites of questions and answers related to Xamarin for finding
questions that mention those error codes. We found in both sites that there are
questions written by developers asking about Xamarin errors, and the majority
of them have at least one answer. Our intuition is this discovered information
could be useful for giving support to Xamarin developers.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07029</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Scheduling of Periodic Messages for Cloud RAN</dc:title>
 <dc:creator>Dominique, Barth</dc:creator>
 <dc:creator>Ma&#xeb;l, Guiraud</dc:creator>
 <dc:creator>Yann, Strozecki</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A recent trend in mobile networks is to centralize in distant data-centers
the processing units which were attached to antennas until now. The main
challenge is to guarantee that the latency of the periodic messages sent from
the antennas to their processing units and back, fulfills protocol time
constraints. We show that traditional statistical multiplexing does not allow
such a low latency, due to collisions and buffering at nodes. Hence, we propose
in this article to use a deterministic scheme for sending periodic messages
without collisions in the network thus saving the latency incurred by
buffering.
  We give several algorithms to compute such schemes for a common topology
where one link is shared by all antennas. We show that there is always a
solution when the routes are short or the load is small. When the parameters
are unconstrained, and some buffering is allowed in the processing units, we
propose an algorithm (PMLS) adapted from a classical scheduling method. The
experimental results show that even under full load, most of the time PMLS
finds a deterministic sending scheme with no latency.
</dc:description>
 <dc:description>Comment: 14 pages, 13 Figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07030</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Offline A/B testing for Recommender Systems</dc:title>
 <dc:creator>Gilotte, Alexandre</dc:creator>
 <dc:creator>Calauz&#xe8;nes, Cl&#xe9;ment</dc:creator>
 <dc:creator>Nedelec, Thomas</dc:creator>
 <dc:creator>Abraham, Alexandre</dc:creator>
 <dc:creator>Doll&#xe9;, Simon</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Before A/B testing online a new version of a recommender system, it is usual
to perform some offline evaluations on historical data. We focus on evaluation
methods that compute an estimator of the potential uplift in revenue that could
generate this new technology. It helps to iterate faster and to avoid losing
money by detecting poor policies. These estimators are known as counterfactual
or off-policy estimators. We show that traditional counterfactual estimators
such as capped importance sampling and normalised importance sampling are
experimentally not having satisfying bias-variance compromises in the context
of personalised product recommendation for online advertising. We propose two
variants of counterfactual estimates with different modelling of the bias that
prove to be accurate in real-world conditions. We provide a benchmark of these
estimators by showing their correlation with business metrics observed by
running online A/B tests on a commercial recommender system.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07030</dc:identifier>
 <dc:identifier>doi:10.1145/3159652.3159687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07033</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the List Decodability of Self-orthogonal Rank Metric Codes</dc:title>
 <dc:creator>Liu, Shu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  V. Guruswami and N. Resch prove that the list decodability of
$\mathbb{F}_q$-linear rank metric codes is as good as that of random rank
metric codes in~\cite{venkat2017}. Due to the potential applications of
self-orthogonal rank metric codes, we focus on list decoding of them. In this
paper, we prove that with high probability, an $\F_q$-linear self-orthogonal
rank metric code over $\mathbb{F}_q^{n\times m}$ of rate
$R=(1-\tau)(1-\frac{n}{m}\tau)-\epsilon$ is shown to be list decodable up to
fractional radius $\tau\in(0,1)$ and small $\epsilon\in(0,1)$ with list size
depending on $\tau$ and $q$ at most $O_{\tau, q}(\frac{1}{\epsilon})$. In
addition, we show that an $\mathbb{F}_{q^m}$-linear self-orthogonal rank metric
code of rate up to the Gilbert-Varshamov bound is $(\tau n, \exp(O_{\tau,
q}(\frac{1}{\epsilon})))$-list decodable.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07054</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying Speakers Using Their Emotion Cues</dc:title>
 <dc:creator>Shahin, Ismail</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper addresses the formulation of a new speaker identification approach
which employs knowledge of emotional content of speaker information. Our
proposed approach in this work is based on a two-stage recognizer that combines
and integrates both emotion recognizer and speaker recognizer into one
recognizer. The proposed approach employs both Hidden Markov Models (HMMs) and
Suprasegmental Hidden Markov Models (SPHMMs) as classifiers. In the
experiments, six emotions are considered including neutral, angry, sad, happy,
disgust and fear. Our results show that average speaker identification
performance based on the proposed two-stage recognizer is 79.92% with a
significant improvement over a one-stage recognizer with an identification
performance of 71.58%. The results obtained based on the proposed approach are
close to those achieved in subjective evaluation by human listeners.
</dc:description>
 <dc:description>Comment: 10 pages. arXiv admin note: text overlap with arXiv:1707.00137</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07054</dc:identifier>
 <dc:identifier>Identifying speakers using their emotion cues, International
  Journal of Speech Technology, Vol. 14, No. 2, June 2011</dc:identifier>
 <dc:identifier>doi:10.1007/s10772-011-9089-1.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07055</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Source Social Feedback of Online News Feeds</dc:title>
 <dc:creator>Moniz, Nuno</dc:creator>
 <dc:creator>Torgo, Lu&#xed;s</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The profusion of user generated content caused by the rise of social media
platforms has enabled a surge in research relating to fields such as
information retrieval, recommender systems, data mining and machine learning.
However, the lack of comprehensive baseline data sets to allow a thorough
evaluative comparison has become an important issue. In this paper we present a
large data set of news items from well-known aggregators such as Google News
and Yahoo! News, and their respective social feedback on multiple platforms:
Facebook, Google+ and LinkedIn. The data collected relates to a period of 8
months, between November 2015 and July 2016, accounting for about 100,000 news
items on four different topics: economy, microsoft, obama and palestine. This
data set is tailored for evaluative comparisons in predictive analytics tasks,
although allowing for tasks in other research areas such as topic detection and
tracking, sentiment analysis in short text, first story detection or news
recommendation.
</dc:description>
 <dc:description>Comment: Dataset available in http://www.dcc.fc.up.pt/~nmoniz/MultiSourceNews</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07073</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BiographyNet: Extracting Relations Between People and Events</dc:title>
 <dc:creator>Fokkens, Antske</dc:creator>
 <dc:creator>ter Braake, Serge</dc:creator>
 <dc:creator>Ockeloen, Niels</dc:creator>
 <dc:creator>Vossen, Piek</dc:creator>
 <dc:creator>Leg&#xea;ne, Susan</dc:creator>
 <dc:creator>Schreiber, Guus</dc:creator>
 <dc:creator>de Boer, Victor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes BiographyNet, a digital humanities project (2012-2016)
that brings together researchers from history, computational linguistics and
computer science. The project uses data from the Biography Portal of the
Netherlands (BPN), which contains approximately 125,000 biographies from a
variety of Dutch biographical dictionaries from the eighteenth century until
now, describing around 76,000 individuals. BiographyNet's aim is to strengthen
the value of the portal and comparable biographical datasets for historical
research, by improving the search options and the presentation of its outcome,
with a historically justified NLP pipeline that works through a user evaluated
demonstrator. The project's main target group are professional historians. The
project therefore worked with two key concepts: ``provenance'' -understood as a
term allowing for both historical source criticism and for references to
data-management and programming interventions in digitized sources; and
``perspective'' interpreted as inherent uncertainty concerning the
interpretation of historical results.
</dc:description>
 <dc:description>Comment: 32 pages, 5 figures, \'A. Z. Bern\'ad, C. Gruber, M. Kaiser
  (editors). Europa baut auf Biographien: Aspekte, Bausteine, Normen und
  Standards f\&quot;ur eine europ\&quot;aische Biographik (2017)</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07076</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Aided Secure Massive MIMO Transmission with Active Eavesdropping</dc:title>
 <dc:creator>Wu, Yongpeng</dc:creator>
 <dc:creator>Wen, Chao-Kai</dc:creator>
 <dc:creator>Chen, Wen</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the design of secure communication for time division
duplexing multi-cell multi-user massive multiple-input multiple-output (MIMO)
systems with active eavesdropping. We assume that the eavesdropper actively
attacks the uplink pilot transmission and the uplink data transmission before
eavesdropping the downlink data transmission phase of the desired users. We
exploit both the received pilots and data signals for uplink channel
estimation. We show analytically that when the number of transmit antennas and
the length of the data vector both tend to infinity, the signals of the desired
user and the eavesdropper lie in different eigenspaces of the received signal
matrix at the base station if their signal powers are different. This finding
reveals that decreasing (instead of increasing) the desire user's signal power
might be an effective approach to combat a strong active attack from an
eavesdropper. Inspired by this result, we propose a data-aided secure downlink
transmission scheme and derive an asymptotic achievable secrecy sum-rate
expression for the proposed design. Numerical results indicate that under
strong active attacks, the proposed design achieves significant secrecy rate
gains compared to the conventional design employing matched filter precoding
and artificial noise generation.
</dc:description>
 <dc:description>Comment: Accepted by ICC'18</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07080</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Automated Tuberculosis detection using Deep Learning</dc:title>
 <dc:creator>Kant, Sonaal</dc:creator>
 <dc:creator>Srivastava, Muktabh Mayank</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Tuberculosis(TB) in India is the world's largest TB epidemic. TB leads to
480,000 deaths every year. Between the years 2006 and 2014, Indian economy lost
US$340 Billion due to TB. This combined with the emergence of drug resistant
bacteria in India makes the problem worse. The government of India has hence
come up with a new strategy which requires a high-sensitivity microscopy based
TB diagnosis mechanism. We propose a new Deep Neural Network based drug
sensitive TB detection methodology with recall and precision of 83.78% and
67.55% respectively for bacillus detection. This method takes a microscopy
image with proper zoom level as input and returns location of suspected TB
germs as output. The high accuracy of our method gives it the potential to
evolve into a high sensitivity system to diagnose TB when trained at scale.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07083</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential Message Importance Measure: A New Approach to the Required
  Sampling Number in Big Data Structure Characterization</dc:title>
 <dc:creator>Liu, Shanyun</dc:creator>
 <dc:creator>She, Rui</dc:creator>
 <dc:creator>Fan, Pingyi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Data collection is a fundamental problem in the scenario of big data, where
the size of sampling sets plays a very important role, especially in the
characterization of data structure. This paper considers the information
collection process by taking message importance into account, and gives a
distribution-free criterion to determine how many samples are required in big
data structure characterization. Similar to differential entropy, we define
differential message importance measure (DMIM) as a measure of message
importance for continuous random variable. The DMIM for many common densities
is discussed, and high-precision approximate values for normal distribution are
given. Moreover, it is proved that the change of DMIM can describe the gap
between the distribution of a set of sample values and a theoretical
distribution. In fact, the deviation of DMIM is equivalent to
Kolmogorov-Smirnov statistic, but it offers a new way to characterize the
distribution goodness-of-fit. Numerical results show some basic properties of
DMIM and the accuracy of the proposed approximate values. Furthermore, it is
also obtained that the empirical distribution approaches the real distribution
with decreasing of the DMIM deviation, which contributes to the selection of
suitable sampling points in actual system.
</dc:description>
 <dc:description>Comment: 11pages, 6 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07090</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview of Wireless IoT Protocol Security in the Smart Home Domain</dc:title>
 <dc:creator>Marksteiner, Stefan</dc:creator>
 <dc:creator>Jim&#xe9;nez, V&#xed;ctor Juan Exp&#xf3;sito</dc:creator>
 <dc:creator>Vallant, Heribert</dc:creator>
 <dc:creator>Zeiner, Herwig</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  While the application of IoT in smart technologies becomes more and more
proliferated, the pandemonium of its protocols becomes increasingly confusing.
More seriously, severe security deficiencies of these protocols become evident,
as time-to- market is a key factor, which satisfaction comes at the price of a
less thorough security design and testing. This applies especially to the smart
home domain, where the consumer-driven market demands quick and cheap
solutions. This paper presents an overview of IoT application domains and
discusses the most important wireless IoT protocols for smart home, which are
KNX-RF, EnOcean, Zigbee, Z-Wave and Thread. Finally, it describes the security
features of said protocols and compares them with each other, giving advice on
whose protocols are more suitable for a secure smart home.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07090</dc:identifier>
 <dc:identifier>Proceedings of the Joint 13th CTTE and 10th CMI Conference on
  Internet of Things Business Models, Users, and Networks, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/CTTE.2017.8260940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07092</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtualization-based Evaluation of Backhaul Performance in Vehicular
  Applications</dc:title>
 <dc:creator>Malandrino, Francesco</dc:creator>
 <dc:creator>Chiasserini, Carla-Fabiana</dc:creator>
 <dc:creator>Casetti, Claudio</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Next-generation networks, based on SDN and NFV, are expected to support a
wide array of services, including vehicular safety applications. These services
come with strict delay constraints, and our goal in this paper is to ascertain
to which extent SDN/NFV-based networks are able to meet them. To this end, we
build and emulate a vehicular collision detection system, using the popular
Mininet and Docker tools, on a real-world topology with mobility information.
Using different core network topologies and open-source SDN controllers, we
measure (i) the delay with which vehicle beacons are processed and (ii) the
associated overhead and energy consumption. We find that we can indeed meet the
latency constraints associated with vehicular safety applications, and that SDN
controllers represent a moderate contribution to the overall energy consumption
but a significant source of additional delay.
</dc:description>
 <dc:description>Comment: Accepted for publication in Elsevier Communication Networks</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07096</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized HARQ Protocols with Delayed Channel State Information and
  Average Latency Constraints</dc:title>
 <dc:creator>Trillingsgaard, Kasper Fl&#xf8;e</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In many wireless systems, the signal-to-interference-and-noise ratio that is
applicable to a certain transmission, referred to as channel state information
(CSI), can only be learned after the transmission has taken place and is
thereby delayed (outdated). In such systems, hybrid automatic repeat request
(HARQ) protocols are often used to achieve high throughput with low latency.
This paper put forth the family of expandable message space (EMS) protocols
that generalize the HARQ protocol and allow for rate adaptation based on
delayed CSI at the transmitter (CSIT). Assuming a block-fading channel, the
proposed EMS protocols are analyzed using dynamic programming. When full
delayed CSIT is available and there is a constraint on the average decoding
time, it is shown that the optimal zero outage EMS protocol has a particularly
simple operational interpretation and that the throughput is identical to that
of the backtrack retransmission request (BRQ) protocol. We also devise EMS
protocols for the case in which CSIT is only available through a finite number
of feedback messages. The numerical results demonstrate that the throughput of
BRQ approaches the ergodic capacity quickly compared to HARQ, while EMS
protocols with only three and four feedback messages achieve throughputs that
are only slightly worse than that of BRQ.
</dc:description>
 <dc:description>Comment: 19 pages, 5 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07102</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User assisted and automatic inverse procedural road modelling at the
  city scale</dc:title>
 <dc:creator>Cura, Remi</dc:creator>
 <dc:creator>Perret, Julien</dc:creator>
 <dc:creator>Paparoditis, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Cities are structured by roads. Having up to date and detailed maps of these
is thus an important challenge for urban planing, civil engineering and
transportation. Those maps are traditionally created manually, which represents
a massive amount of work, and may discard recent or temporary changes. For
these reasons, automated map building has been a long time goal, either for
road network reconstruction or for local road surface reconstruction from low
level observations. In this work, we navigate between these two goals. Starting
from an approximate road axis (+ width) network as a simple road modelling, we
propose to use observations of street features and optimisation to improve the
coarse model. Observations are generic, and as such, can be derived from
various data, such as aerial images, street images and street Lidar, other GIS
data, and complementary user input.
  Starting from an initial road modelling which is at a median distance of 1.5
metre from the sidewalk ground-truth, our method has the potential to robustly
optimise the road modelling so the median distance reaches 0.45 metre fully
automatically, with better results possible using user inputs and/or more
precise observations. The robust non linear least square optimisation used is
extremely fast, with computing time from few minutes (whole Paris) to less than
a second for a few blocks.
  The proposed approach is simple, very fast and produces a credible road
model. These promising results open the way to various applications, such as
integration in an interactive framework, or integration in a more powerful
optimisation method, which would be able to further segment road network and
use more complex road model.
</dc:description>
 <dc:description>Comment: Article extracted form PhD (chap5)</dc:description>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07108</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invitation to Real Complexity Theory: Algorithmic Foundations to
  Reliable Numerics with Bit-Costs</dc:title>
 <dc:creator>Kawamura, Akitoshi</dc:creator>
 <dc:creator>Ziegler, Martin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>68Q17, 65Y20</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:description>  While concepts and tools from Theoretical Computer Science are regularly
applied to, and significantly support, software development for discrete
problems, Numerical Engineering largely employs recipes and methods whose
correctness and efficiency is demonstrated empirically.
  We advertise REAL COMPLEXITY THEORY: a resource-oriented foundation to
rigorous computations over continuous universes such as real numbers, vectors,
sequences, continuous functions, and Euclidean subsets: in the bit-model by
approximation up to given absolute error. It offers sound semantics (e.g. of
comparisons/tests), closure under composition, realistic runtime predictions,
and proofs of algorithmic optimality by relating to known classes like NP, #P,
PSPACE.
</dc:description>
 <dc:description>Comment: Proc. WAAC 2015, http://waac-15.appspot.com/program.html</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07110</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Networks in Visual Environments</dc:title>
 <dc:creator>Betti, Alessandro</dc:creator>
 <dc:creator>Gori, Marco</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The puzzle of computer vision might find new challenging solutions when we
realize that most successful methods are working at image level, which is
remarkably more difficult than processing directly visual streams. In this
paper, we claim that their processing naturally leads to formulate the motion
invariance principle, which enables the construction of a new theory of
learning with convolutional networks. The theory addresses a number of
intriguing questions that arise in natural vision, and offers a well-posed
computational scheme for the discovery of convolutional filters over the
retina. They are driven by differential equations derived from the principle of
least cognitive action. Unlike traditional convolutional networks, which need
massive supervision, the proposed theory offers a truly new scenario in which
feature learning takes place by unsupervised processing of video signals. It is
pointed out that an opportune blurring of the video, along the interleaving of
segments of null signal, make it possible to conceive a novel learning
mechanism that yields the minimum of the cognitive action. Basically, while the
theory enables the implementation of novel computer vision systems, it is also
provides an intriguing explanation of the solution that evolution has
discovered for humans, where it looks like that the video blurring in newborns
and the day-night rhythm seem to emerge in a general computational framework,
regardless of biology.
</dc:description>
 <dc:description>Comment: 49 pages, 2 figures</dc:description>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07121</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reflexion in mathematical models of decision-making</dc:title>
 <dc:creator>Novikov, Dmitry</dc:creator>
 <dc:creator>Korepanov, Vsevolod</dc:creator>
 <dc:creator>Chkhartishvili, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The paper is devoted to a generalization of static and dynamic mathematical
models of behavior with explicitly stated reflexive models of agents'
decision-making. Reflexion is considered as agent's beliefs about nature,
opponents' beliefs and opponents' decision-making principles in the framework
of game theory, collective behavior theory and learning models.
</dc:description>
 <dc:description>Comment: This is an Accepted Manuscript of an article published by Taylor &amp;
  Francis Group in the International Journal of Parallel, Emergent &amp;
  Distributed Systems on 01/12/2017, available online:
  http://www.tandfonline.com/10.1080/17445760.2017.1413189</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07121</dc:identifier>
 <dc:identifier>doi:10.1080/17445760.2017.1413189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07132</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SecSens: Secure State Estimation with Application to Localization and
  Time Synchronization</dc:title>
 <dc:creator>Alanwar, Amr</dc:creator>
 <dc:creator>Etzlinger, Bernhard</dc:creator>
 <dc:creator>Ferraz, Henrique</dc:creator>
 <dc:creator>Hespanha, Joao</dc:creator>
 <dc:creator>Srivastava, Mani</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Research evidence in Cyber-Physical Systems (CPS) shows that the introduced
tight coupling of information technology with physical sensing and actuation
leads to more vulnerability and security weaknesses. But, the traditional
security protection mechanisms of CPS focus on data encryption while neglecting
the sensors which are vulnerable to attacks in the physical domain.
Accordingly, researchers attach utmost importance to the problem of state
estimation in the presence of sensor attacks. In this work, we present SecSens,
a novel approach for secure nonlinear state estimation in the presence of
modeling and measurement noise. SecSens consists of two independent algorithms,
namely, SecEKF and SecOPT, which are based on Extended Kalman Filter and
Maximum Likelihood Estimation, respectively. We adopt a holistic approach to
introduce security awareness among state estimation algorithms without
requiring specialized hardware, or cryptographic techniques. We apply SecSens
to securely localize and time synchronize networked mobile devices. SecSens
provides good performance at run-time several order of magnitude faster than
the state of art solutions under the presence of powerful attacks. Our
algorithms are evaluated on a testbed with static nodes and a mobile quadrotor
all equipped with commercial ultra-wide band wireless devices.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07138</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wikipedia in academia as a teaching tool: from averse to proactive
  faculty profiles</dc:title>
 <dc:creator>Minguill&#xf3;n, Juli&#xe0;</dc:creator>
 <dc:creator>Aibar, Eduard</dc:creator>
 <dc:creator>Lerga, Maura</dc:creator>
 <dc:creator>Llad&#xf3;s, Josep</dc:creator>
 <dc:creator>Meseguer-Artola, Antoni</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.3.1</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:description>  This study concerned the active use of Wikipedia as a teaching tool in the
classroom in higher education, trying to identify different usage profiles and
their characterization. A questionnaire survey was administrated to all
full-time and part-time teachers at the Universitat Oberta de Catalunya and the
Universitat Pompeu Fabra, both in Barcelona, Spain. The questionnaire was
designed using the Technology Acceptance Model as a reference, including items
about teachers web 2.0 profile, Wikipedia usage, expertise, perceived
usefulness, easiness of use, visibility and quality, as well as Wikipedia
status among colleagues and incentives to use it more actively. Clustering and
statistical analysis were carried out using the k-medoids algorithm and
differences between clusters were assessed by means of contingency tables and
generalized linear models (logit). The respondents were classified in four
clusters, from less to more likely to adopt and use Wikipedia in the classroom,
namely averse (25.4%), reluctant (17.9%), open (29.5%) and proactive (27.2%).
Proactive faculty are mostly men teaching part-time in STEM fields, mainly
engineering, while averse faculty are mostly women teaching full-time in
non-STEM fields. Nevertheless, questionnaire items related to visibility,
quality, image, usefulness and expertise determine the main differences between
clusters, rather than age, gender or domain. Clusters involving a positive view
of Wikipedia and at least some frequency of use clearly outnumber those with a
strictly negative stance. This goes against the common view that faculty
members are mostly sceptical about Wikipedia. Environmental factors such as
academic culture and colleagues opinion are more important than faculty
personal characteristics, especially with respect to what they think about
Wikipedia quality.
</dc:description>
 <dc:description>Comment: 16 pages, 1 figure, 8 tables</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07140</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Courteous Learning Rule for Ad-hoc Anti-coordination</dc:title>
 <dc:creator>Danassis, Panayiotis</dc:creator>
 <dc:creator>Faltings, Boi</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In this paper, we investigate the problem of anti-coordination under
rationality constraints in ad-hoc resource allocation settings. Inspired by
human behavior, we propose a framework (CA3NONY) that enables fast convergence
to efficient and fair allocations based on a simple convention of courtesy. We
prove that following such convention induces a strategy which constitutes an
approximate subgame-perfect equilibrium of the repeated resource allocation
game with discounting. Simulation results highlight the effectiveness of
CA3NONY as compared to state-of-the-art bandit algorithms, since it achieves
more than two orders of magnitude faster convergence, higher efficiency,
fairness, and average payoff for the agents.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07140</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07141</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Staff line Removal using Generative Adversarial Networks</dc:title>
 <dc:creator>Konwer, Aishik</dc:creator>
 <dc:creator>Bhunia, Ayan Kumar</dc:creator>
 <dc:creator>Bhowmick, Abir</dc:creator>
 <dc:creator>Bhunia, Ankan Kumar</dc:creator>
 <dc:creator>Banerjee, Prithaj</dc:creator>
 <dc:creator>Roy, Partha Pratim</dc:creator>
 <dc:creator>Pal, Umapada</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Staff line removal is a crucial pre-processing step in Optical Music
Recognition. It is a challenging task to simultaneously reduce the noise and
also retain the quality of music symbol context in ancient degraded music score
images. In this paper we propose a novel approach for staff line removal, based
on Generative Adversarial Networks. We convert staff line images into patches
and feed them into a U-Net, used as Generator. The Generator intends to produce
staff-less images at the output. Then the Discriminator does binary
classification and differentiates between the generated fake staff-less image
and real ground truth staff less image. For training, we use a Loss function
which is a weighted combination of L2 loss and Adversarial loss. L2 loss
minimizes the difference between real and fake staff-less image. Adversarial
loss helps to retrieve more high quality textures in generated images. Thus our
architecture supports solutions which are closer to ground truth and it
reflects in our results. For evaluation we consider the ICDAR/GREC 2013 staff
removal database. Our method achieves superior performance in comparison to
other conventional approaches.
</dc:description>
 <dc:description>Comment: Submitted in ICPR 2018</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07145</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>E-swish: Adjusting Activations to Different Network Depths</dc:title>
 <dc:creator>Alcaide, Eric</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Activation functions have a notorious impact on neural networks on both
training and testing the models against the desired problem. Currently, the
most used activation function is the Rectified Linear Unit (ReLU). This paper
introduces a new and novel activation function, closely related with the new
activation $Swish = x * sigmoid(x)$ (Ramachandran et al., 2017) which
generalizes it. We call the new activation $E-swish = \beta x * sigmoid(x)$. We
show that E-swish outperforms many other well-known activations including both
ReLU and Swish. For example, using E-swish provided 1.5% and 4.6% accuracy
improvements on Cifar10 and Cifar100 respectively for the WRN 10-2 when
compared to ReLU and 0.35% and 0.6% respectively when compared to Swish. The
code to reproduce all our experiments can be found at
https://github.com/EricAlcaide/E-swish
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07150</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Weighted Distance Measure for Multi-Attributed Graph</dc:title>
 <dc:creator>Abulaish, Muhammad</dc:creator>
 <dc:creator>Jahiruddin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Due to exponential growth of complex data, graph structure has become
increasingly important to model various entities and their interactions, with
many interesting applications including, bioinformatics, social network
analysis, etc. Depending on the complexity of the data, the underlying graph
model can be a simple directed/undirected and/or weighted/un-weighted graph to
a complex graph (aka multi-attributed graph) where vertices and edges are
labelled with multi-dimensional vectors. In this paper, we present a novel
weighted distance measure based on weighted Euclidean norm which is defined as
a function of both vertex and edge attributes, and it can be used for various
graph analysis tasks including classification and cluster analysis. The
proposed distance measure has flexibility to increase/decrease the weightage of
edge labels while calculating the distance between vertex-pairs. We have also
proposed a MAGDist algorithm, which reads multi-attributed graph stored in CSV
files containing the list of vertex vectors and edge vectors, and calculates
the distance between each vertex-pair using the proposed weighted distance
measure. Finally, we have proposed a multi-attributed similarity graph
generation algorithm, MAGSim, which reads the output of MAGDist algorithm and
generates a similarity graph that can be analysed using classification and
clustering algorithms. The significance and accuracy of the proposed distance
measure and algorithms is evaluated on Iris and Twitter data sets, and it is
found that the similarity graph generated by our proposed method yields better
clustering results than the existing similarity graph generation methods.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07150</dc:identifier>
 <dc:identifier>Muhammad Abulaish and Jahiruddin, A Novel Weighted Distance
  Measure for Multi-Attributed Graph, In Proceedings of the 10th Annual ACM
  India Conference (COMPUTE), Bhopal, India, Nov. 16-18, 2017, pp. 1-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07156</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word Level Font-to-Font Image Translation using Convolutional Recurrent
  Generative Adversarial Networks</dc:title>
 <dc:creator>Bhunia, Ankan Kumar</dc:creator>
 <dc:creator>Bhunia, Ayan Kumar</dc:creator>
 <dc:creator>Banerjee, Prithaj</dc:creator>
 <dc:creator>Konwer, Aishik</dc:creator>
 <dc:creator>Bhowmick, Abir</dc:creator>
 <dc:creator>Roy, Partha Pratim</dc:creator>
 <dc:creator>Pal, Umapada</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Conversion of one font to another font is very useful in real life
applications. In this paper, we propose a Convolutional Recurrent Generative
model to solve the word level font transfer problem. Our network is able to
convert the font style of any printed text images from its current font to the
required font. The network is trained end-to-end for the complete word images.
Thus it eliminates the necessary pre-processing steps, like character
segmentations. We extend our model to conditional setting that helps to learn
one-to-many mapping function. We employ a novel convolutional recurrent model
architecture in the Generator that efficiently deals with the word images of
arbitrary width. It also helps to maintain the consistency of the final images
after concatenating the generated image patches of target font. Besides, the
Generator and the Discriminator network, we employ a Classification network to
classify the generated word images of converted font style to their subsequent
font categories. Most of the earlier works related to image translation are
performed on square images. Our proposed architecture is the first work which
can handle images of varying widths. Word images generally have varying width
depending on the number of characters present. Hence, we test our model on a
synthetically generated font dataset. We compare our method with some of the
state-of-the-art methods for image translation. The superior performance of our
network on the same dataset proves the ability of our model to learn the font
distributions.
</dc:description>
 <dc:description>Comment: Submitted in ICPR 2018</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07161</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reasoning about multiple aspects in DLs: Semantics and Closure
  Construction</dc:title>
 <dc:creator>Giordano, Laura</dc:creator>
 <dc:creator>Gliozzi, Valentina</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Starting from the observation that rational closure has the undesirable
property of being an &quot;all or nothing&quot; mechanism, we here propose a
multipreferential semantics, which enriches the preferential semantics
underlying rational closure in order to separately deal with the inheritance of
different properties in an ontology with exceptions. We provide a
multipreference closure mechanism which is sound with respect to the
multipreference semantics.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1604.00301</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07168</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demonstrably Doing Accountability in the Internet of Things</dc:title>
 <dc:creator>Urquhart, Lachlan</dc:creator>
 <dc:creator>Lodge, Tom</dc:creator>
 <dc:creator>Crabtree, Andy</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper explores the importance of accountability to data protection, and
how it can be built into the Internet of Things (IoT). The need to build
accountability into the IoT is motivated by the opaque nature of distributed
data flows, inadequate consent mechanisms, and lack of interfaces enabling
end-user control over the behaviours of internet-enabled devices. The lack of
accountability precludes meaningful engagement by end-users with their personal
data and poses a key challenge to creating user trust in the IoT and the
reciprocal development of the digital economy. The EU General Data Protection
Regulation 2016 (GDPR) seeks to remedy this particular problem by mandating
that a rapidly developing technological ecosystem be made accountable. In doing
so it foregrounds new responsibilities for data controllers, including data
protection by design and default, and new data subject rights such as the right
to data portability. While GDPR is technologically neutral, it is nevertheless
anticipated that realising the vision will turn upon effective technological
development. Accordingly, this paper examines the notion of accountability, how
it has been translated into systems design recommendations for the IoT, and how
the IoT Databox puts key data protection principles into practice.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07172</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scale-invariant Feature Extraction of Neural Network and Renormalization
  Group Flow</dc:title>
 <dc:creator>Iso, Satoshi</dc:creator>
 <dc:creator>Shiba, Shotaro</dc:creator>
 <dc:creator>Yokoo, Sumito</dc:creator>
 <dc:subject>High Energy Physics - Theory</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Theoretical understanding of how deep neural network (DNN) extracts features
from input images is still unclear, but it is widely believed that the
extraction is performed hierarchically through a process of coarse-graining. It
reminds us of the basic concept of renormalization group (RG) in statistical
physics. In order to explore possible relations between DNN and RG, we use the
Restricted Boltzmann machine (RBM) applied to Ising model and construct a flow
of model parameters (in particular, temperature) generated by the RBM. We show
that the unsupervised RBM trained by spin configurations at various
temperatures from $T=0$ to $T=6$ generates a flow along which the temperature
approaches the critical value $T_c=2.27$. This behavior is opposite to the
typical RG flow of the Ising model. By analyzing various properties of the
weight matrices of the trained RBM, we discuss why it flows towards $T_c$ and
how the RBM learns to extract features of spin configurations.
</dc:description>
 <dc:description>Comment: 32 pages, 17 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07174</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Open Relation Extraction</dc:title>
 <dc:creator>Elsahar, Hady</dc:creator>
 <dc:creator>Demidova, Elena</dc:creator>
 <dc:creator>Gottschalk, Simon</dc:creator>
 <dc:creator>Gravier, Christophe</dc:creator>
 <dc:creator>Laforest, Frederique</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We explore methods to extract relations between named entities from free text
in an unsupervised setting. In addition to standard feature extraction, we
develop a novel method to re-weight word embeddings. We alleviate the problem
of features sparsity using an individual feature reduction. Our approach
exhibits a significant improvement by 5.8% over the state-of-the-art relation
clustering scoring a F1-score of 0.416 on the NYT-FB dataset.
</dc:description>
 <dc:description>Comment: 4 pages, published in ESWC 2017</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07174</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-70407-4_3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07175</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Texts with Gradient Methods</dc:title>
 <dc:creator>Gong, Zhitao</dc:creator>
 <dc:creator>Wang, Wenlu</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:creator>Ku, Wei-Shinn</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Adversarial samples for images have been extensively studied in the
literature. Among many of the attacking methods, gradient-based methods are
both effective and easy to compute. In this work, we propose a framework to
adapt the gradient attacking methods on images to text domain. The main
difficulties for generating adversarial texts with gradient methods are i) the
input space is discrete, which makes it difficult to accumulate small noise
directly in the inputs, and ii) the measurement of the quality of the
adversarial texts is difficult. We tackle the first problem by searching for
adversarials in the embedding space and then reconstruct the adversarial texts
via nearest neighbor search. For the latter problem, we employ the Word Mover's
Distance (WMD) to quantify the quality of adversarial texts. Through extensive
experiments on three datasets, IMDB movie reviews, Reuters-2 and Reuters-5
newswires, we show that our framework can leverage gradient attacking methods
to generate very high-quality adversarial texts that are only a few words
different from the original texts. There are many cases where we can change one
word to alter the label of the whole piece of text. We successfully incorporate
FGM and DeepFool into our framework. In addition, we empirically show that WMD
is closely related to the quality of adversarial texts.
</dc:description>
 <dc:description>Comment: This work lacks some crucial details. After careful discussion, we
  decided to withdraw it temporarily and resubmit a full version afterward</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07183</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-objective Optimal Sizing and Energy Management of Hybrid Energy
  Storage System for Electric Vehicles</dc:title>
 <dc:creator>Yu, Huilong</dc:creator>
 <dc:creator>Cheli, Federico</dc:creator>
 <dc:creator>Castelli-Dezza, Francesco</dc:creator>
 <dc:creator>Cao, Dongpu</dc:creator>
 <dc:creator>Wang, Fei-Yue</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Hybrid energy storage system (HESS) composed of lithium-ion battery and
supercapacitors has been recognized as one of the most promising solutions to
face against the high cost, low power density and short cycle life of the
battery-only energy storage system, which is the major headache hindering the
further penetration of electric vehicles. In this work, the HESS sizing and
energy management problem of an electric race car is investigated as a case
study to improve the driving mileage and battery cycle life performance.
Compared with the existing research, the distinctive features of this work are:
(1) A dynamic model and a degradation model of the battery are employed to
describe the dynamic behavior and to predict the cycle life of the battery more
precisely; (2) Considering the fact that the design and control problems are
coupled in most cases, in order to achieve a global optimal design solution and
an implementable real-time energy management system, a Bi-level multi-objective
sizing and control framework based on non-dominated sorting genetic
algorithm-II and fuzzy logic control (FLC) is proposed to size the HESS and to
optimize the membership functions of a FLC based EMS at the same time; (3) In
order to improve the optimization efficiency, a vectorized fuzzy inference
system which allows large scale of fuzzy logic controllers operating in
parallel is devised. At last, the Pareto optimal solutions of different HESSs
are obtained and compared to show the achieved enhancements of the proposed
Bi-level optimal sizing and energy management framework.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07184</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive parallelism with RMI: Idle high-performance computing resources
  can be completely avoided</dc:title>
 <dc:creator>Spenke, Florian</dc:creator>
 <dc:creator>Balzer, Karsten</dc:creator>
 <dc:creator>Frick, Sascha</dc:creator>
 <dc:creator>Hartke, Bernd</dc:creator>
 <dc:creator>Dieterich, Johannes M.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>65Y05, 68Q10, 68W10, 68W15</dc:subject>
 <dc:description>  In practice, standard scheduling of parallel computing jobs almost always
leaves significant portions of the available hardware unused, even with many
jobs still waiting in the queue. The simple reason is that the resource
requests of these waiting jobs are fixed and do not match the available, unused
resources. However, with alternative but existing and well-established
techniques it is possible to achieve a fully automated, adaptive parallelism
that does not need pre-set, fixed resources. Here, we demonstrate that such an
adaptively parallel program can indeed fill in all such scheduling gaps, even
in real-life situations on large supercomputers.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07185</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>White Noise from the White Goods? Conceptual and Empirical Perspectives
  on Ambient Domestic Computing</dc:title>
 <dc:creator>Urquhart, Lachlan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Within this chapter we consider the emergence of ambient domestic computing
systems, both conceptually and empirically. We critically assess visions of
post-desktop computing, paying particular attention to one contemporary trend:
the internet of things (IoT). We examine the contested nature of this term,
looking at the historical trajectory of similar technologies, and the
regulatory issues they can pose, particularly in the home. We also look to the
emerging regulatory solution of privacy by design, unpacking practical
challenges it faces. The novelty of our contribution stems from a turn to
practice through a set of empirical perspectives. We present findings that
document the practical experiences and viewpoints of leading experts in
technology law and design.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07188</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation for Solar Powered UAV Communication Systems</dc:title>
 <dc:creator>Sun, Yan</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Xu, Dongfang</dc:creator>
 <dc:creator>Dai, Linglong</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the resource allocation design for multicarrier
(MC) systems employing a solar powered unmanned aerial vehicle (UAV) for
providing communication services to multiple downlink users. We study the joint
design of the three-dimensional positioning of the UAV and the power and
subcarrier allocation for maximization of the system sum throughput. The
algorithm design is formulated as a mixed-integer non-convex optimization
problem, which requires a prohibitive computational complexity for obtaining
the globally optimal solution. Therefore, a low-complexity suboptimal iterative
solution based on successive convex approximation is proposed. Simulation
results confirm that the proposed suboptimal algorithm achieves a substantially
higher system sum throughput compared to several baseline schemes.
</dc:description>
 <dc:description>Comment: Invited paper for Special Session: UAV Communications and Networks,
  in SPAWC 2018, Greece</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07189</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realising the Right to Data Portability for the Domestic Internet of
  Things</dc:title>
 <dc:creator>Urquhart, Lachlan</dc:creator>
 <dc:creator>Sailaja, Neelima</dc:creator>
 <dc:creator>McAuley, Derek</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  There is an increasing role for the IT design community to play in regulation
of emerging IT. Article 25 of the EU General Data Protection Regulation (GDPR)
2016 puts this on a strict legal basis by establishing the need for information
privacy by design and default (PbD) for personal data-driven technologies.
Against this backdrop, we examine legal, commercial and technical perspectives
around the newly created legal right to data portability (RTDP) in GDPR. We are
motivated by a pressing need to address regulatory challenges stemming from the
Internet of Things (IoT). We need to find channels to support the protection of
these new legal rights for users in practice. In Part I we introduce the
internet of things and information PbD in more detail. We briefly consider
regulatory challenges posed by the IoT and the nature and practical challenges
surrounding the regulatory response of information privacy by design. In Part
II, we look in depth at the legal nature of the RTDP, determining what it
requires from IT designers in practice but also limitations on the right and
how it relates to IoT. In Part III we focus on technical approaches that can
support the realisation of the right. We consider the state of the art in data
management architectures, tools and platforms that can provide portability,
increased transparency and user control over the data flows. In Part IV, we
bring our perspectives together to reflect on the technical, legal and business
barriers and opportunities that will shape the implementation of the RTDP in
practice, and how the relationships may shape emerging IoT innovation and
business models. We finish with brief conclusions about the future for the RTDP
and PbD in the IoT.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07189</dc:identifier>
 <dc:identifier>Personal and Ubiquitous Computing, Springer, 2017</dc:identifier>
 <dc:identifier>doi:10.1007/s00779-017-1069-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07193</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Even flying cops should think ahead</dc:title>
 <dc:creator>Martinsson, Anders</dc:creator>
 <dc:creator>Meier, Florian</dc:creator>
 <dc:creator>Schnider, Patrick</dc:creator>
 <dc:creator>Steger, Angelika</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We study the entanglement game, which is a version of cops and robbers, on
sparse graphs. While the minimum degree of a graph G is a lower bound for the
number of cops needed to catch a robber in G, we show that the required number
of cops can be much larger, even for graphs with small maximum degree. In
particular, we show that there are 3-regular graphs where a linear number of
cops are needed.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07194</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Prediction Intervals by Tuning Random Forest via
  Meta-Validation</dc:title>
 <dc:creator>Bayley, Sean</dc:creator>
 <dc:creator>Falessi, Davide</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent studies have shown that tuning prediction models increases prediction
accuracy and that Random Forest can be used to construct prediction intervals.
However, to our best knowledge, no study has investigated the need to, and the
manner in which one can, tune Random Forest for optimizing prediction intervals
{ this paper aims to fill this gap. We explore a tuning approach that combines
an effectively exhaustive search with a validation technique on a single Random
Forest parameter. This paper investigates which, out of eight validation
techniques, are beneficial for tuning, i.e., which automatically choose a
Random Forest configuration constructing prediction intervals that are reliable
and with a smaller width than the default configuration. Additionally, we
present and validate three meta-validation techniques to determine which are
beneficial, i.e., those which automatically chose a beneficial validation
technique. This study uses data from our industrial partner (Keymind Inc.) and
the Tukutuku Research Project, related to post-release defect prediction and
Web application effort estimation, respectively. Results from our study
indicate that: i) the default configuration is frequently unreliable, ii) most
of the validation techniques, including previously successfully adopted ones
such as 50/50 holdout and bootstrap, are counterproductive in most of the
cases, and iii) the 75/25 holdout meta-validation technique is always
beneficial; i.e., it avoids the likely counterproductive effects of validation
techniques.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07198</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fluorescence Microscopy Image Segmentation Using Convolutional Neural
  Network With Generative Adversarial Networks</dc:title>
 <dc:creator>Fu, Chichen</dc:creator>
 <dc:creator>Lee, Soonam</dc:creator>
 <dc:creator>Ho, David Joon</dc:creator>
 <dc:creator>Han, Shuo</dc:creator>
 <dc:creator>Salama, Paul</dc:creator>
 <dc:creator>Dunn, Kenneth W.</dc:creator>
 <dc:creator>Delp, Edward J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent advance in fluorescence microscopy enables acquisition of 3D image
volumes with better quality and deeper penetration into tissue. Segmentation is
a required step to characterize and analyze biological structures in the
images. 3D segmentation using deep learning has achieved promising results in
microscopy images. One issue is that deep learning techniques require a large
set of groundtruth data which is impractical to annotate manually for
microscopy volumes. This paper describes a 3D nuclei segmentation method using
3D convolutional neural networks. A set of synthetic volumes and the
corresponding groundtruth volumes are generated automatically using a
generative adversarial network. Segmentation results demonstrate that our
proposed method is capable of segmenting nuclei successfully in 3D for various
data sets.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07207</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Avoiding the Internet of Insecure Industrial Things</dc:title>
 <dc:creator>Urquhart, Lachlan</dc:creator>
 <dc:creator>McAuley, Derek</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Security incidents such as targeted distributed denial of service (DDoS)
attacks on power grids and hacking of factory industrial control systems (ICS)
are on the increase. This paper unpacks where emerging security risks lie for
the industrial internet of things, drawing on both technical and regulatory
perspectives. Legal changes are being ushered by the European Union (EU)
Network and Information Security (NIS) Directive 2016 and the General Data
Protection Regulation 2016 (GDPR) (both to be enforced from May 2018). We use
the case study of the emergent smart energy supply chain to frame, scope out
and consolidate the breadth of security concerns at play, and the regulatory
responses. We argue the industrial IoT brings four security concerns to the
fore, namely: appreciating the shift from offline to online infrastructure;
managing temporal dimensions of security; addressing the implementation gap for
best practice; and engaging with infrastructural complexity. Our goal is to
surface risks and foster dialogue to avoid the emergence of an Internet of
Insecure Industrial Things
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07207</dc:identifier>
 <dc:identifier>Computer Law and Security Review, 2018</dc:identifier>
 <dc:identifier>doi:10.1016/j.clsr.2017.12.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07209</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIMO Underlay Cognitive Radio: Optimized Power Allocation, Effective
  Number of Transmit Antennas and Harvest-Transmit Tradeoff</dc:title>
 <dc:creator>Miridakis, Nikolaos I.</dc:creator>
 <dc:creator>Tsiftsis, Theodoros A.</dc:creator>
 <dc:creator>Alexandropoulos, George C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the performance of an underlay multiple-input multiple-output
(MIMO) cognitive radio system is analytically studied. In particular, the
secondary transmitter operates in a spatial multiplexing transmission mode,
while a zero-forcing detector is employed at the secondary receiver.
Additionally, the secondary system is interfered by single-antenna primary
users (PUs). To enhance the performance of secondary transmission, optimal
power allocation is performed at the secondary transmitter with a constraint on
the maximum allowable outage threshold specified by the PUs. Further, the
effective number of secondary transmit antennas is specified based on the
optimal power allocation for an arbitrary MIMO scale. Also, a lower bound on
the ergodic channel capacity of the secondary system is derived in a
closed-form expression. Afterwards, the scenario of a massive MIMO secondary
system is thoroughly analyzed and evaluated, where the harvesting-enabled
secondary transmission is studied. The optimal power allocation, the effective
number of secondary transmit antennas, the efficient tradeoff between
transmit-and-harvest secondary antennas, and the average channel capacity of
the secondary system are analytically presented. Finally, extensive numerical
and simulation results corroborate the effectiveness of our analysis, while
some useful engineering insights are provided.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Journal</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07211</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handwriting Trajectory Recovery using End-to-End Deep Encoder-Decoder
  Network</dc:title>
 <dc:creator>Bhunia, Ayan Kumar</dc:creator>
 <dc:creator>Bhowmick, Abir</dc:creator>
 <dc:creator>Bhunia, Ankan Kumar</dc:creator>
 <dc:creator>Konwer, Aishik</dc:creator>
 <dc:creator>Banerjee, Prithaj</dc:creator>
 <dc:creator>Roy, Partha Pratim</dc:creator>
 <dc:creator>Pal, Umapada</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we introduce a novel technique to recover the pen trajectory
of offline characters which is a crucial step for handwritten character
recognition. Generally, online acquisition approach has more advantage than its
offline counterpart as the online technique keeps track of the pen movement.
Hence, pen tip trajectory retrieval from offline text can bridge the gap
between online and offline methods. Our proposed framework employs sequence to
sequence model which consists of an encoder-decoder LSTM module. Our encoder
module consists of Convolutional LSTM network, which takes an offline character
image as the input and encodes the feature sequence to a hidden representation.
The output of the encoder is fed to a decoder LSTM and we get the successive
coordinate points from every time step of the decoder LSTM. Although the
sequence to sequence model is a popular paradigm in various computer vision and
language translation tasks, the main contribution of our work lies in designing
an end-to-end network for a decade old popular problem in Document Image
Analysis community. Tamil, Telugu and Devanagari characters of LIPI Toolkit
dataset are used for our experiments. Our proposed method has achieved superior
performance compared to the other conventional approaches.
</dc:description>
 <dc:description>Comment: Submitted in ICPR 2018</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07215</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Get Your Workload in Order: Game Theoretic Prioritization of Database
  Auditing</dc:title>
 <dc:creator>Yan, Chao</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Vorobeychik, Yevgeniy</dc:creator>
 <dc:creator>Laszka, Aron</dc:creator>
 <dc:creator>Fabbri, Daniel</dc:creator>
 <dc:creator>Malin, Bradley</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>H.2.0</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  For enhancing the privacy protections of databases, where the increasing
amount of detailed personal data is stored and processed, multiple mechanisms
have been developed, such as audit logging and alert triggers, which notify
administrators about suspicious activities; however, the two main limitations
in common are: 1) the volume of such alerts is often substantially greater than
the capabilities of resource-constrained organizations, and 2) strategic
attackers may disguise their actions or carefully choosing which records they
touch, making incompetent the statistical detection models. For solving them,
we introduce a novel approach to database auditing that explicitly accounts for
adversarial behavior by 1) prioritizing the order in which types of alerts are
investigated and 2) providing an upper bound on how much resource to allocate
for each type. We model the interaction between a database auditor and
potential attackers as a Stackelberg game in which the auditor chooses an
auditing policy and attackers choose which records to target. A corresponding
approach combining linear programming, column generation, and heuristic search
is proposed to derive an auditing policy. For testing the policy-searching
performance, a publicly available credit card application dataset are adopted,
on which it shows that our methods produce high-quality mixed strategies as
database audit policies, and our general approach significantly outperforms
non-game-theoretic baselines.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07222</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rover Descent: Learning to optimize by learning to navigate on
  prototypical loss surfaces</dc:title>
 <dc:creator>Faury, Louis</dc:creator>
 <dc:creator>Vasile, Flavian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning to optimize - the idea that we can learn from data algorithms that
optimize a numerical criterion - has recently been at the heart of a growing
number of research efforts. One of the most challenging issues within this
approach is to learn a policy that is able to optimize over classes of
functions that are fairly different from the ones that it was trained on. We
propose a novel way of framing learning to optimize as a problem of learning a
good navigation policy on a partially observable loss surface. To this end, we
develop Rover Descent, a solution that allows us to learn a fairly broad
optimization policy from training on a small set of prototypical
two-dimensional surfaces that encompasses the classically hard cases such as
valleys, plateaus, cliffs and saddles and by using strictly zero-order
information. We show that, without having access to gradient or curvature
information, we achieve state-of-the-art convergence speed on optimization
problems not presented at training time such as the Rosenbrock function and
other hard cases in two dimensions. We extend our framework to optimize over
high dimensional landscapes, while still handling only two-dimensional local
landscape information and show good preliminary results.
</dc:description>
 <dc:description>Comment: 17 pages, 13 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07226</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Convergence for Distributed Learning with Stochastic Gradient
  Methods and Spectral-Regularization Algorithms</dc:title>
 <dc:creator>Lin, Junhong</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  We study generalization properties of distributed algorithms in the setting
of nonparametric regression over a reproducing kernel Hilbert space (RKHS). We
first investigate distributed stochastic gradient methods (SGM), with
mini-batches and multi-passes over the data. We show that optimal
generalization error bounds can be retained for distributed SGM provided that
the partition level is not too large. We then extend our results to
spectral-regularization algorithms (SRA), including kernel ridge regression
(KRR), kernel principal component analysis, and gradient methods. Our results
are superior to the state-of-the-art theory. Particularly, our results show
that distributed SGM has a smaller theoretical computational complexity,
compared with distributed KRR and classic SGM. Moreover, even for
non-distributed SRA, they provide the first optimal, capacity-dependent
convergence rates, considering the case that the regression function may not be
in the RKHS.
</dc:description>
 <dc:description>Comment: 53 pages, 4 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07229</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial framework for planning in geological exploration</dc:title>
 <dc:creator>Levin, Mark Sh.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>68T20, 90B18, 90B50, 90C27</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>J.6</dc:subject>
 <dc:description>  The paper describes combinatorial framework for planning of geological
exploration for oil-gas fields. The suggested scheme of the geological
exploration involves the following stages: (1) building of special 4-layer
tree-like model (layer of geological exploration): productive layer, group of
productive layers, oil-gas field, oil-gas region (or group of the fields); (2)
generations of local design (exploration) alternatives for each low-layer
geological objects: conservation, additional search, independent utilization,
joint utilization; (3) multicriteria (i.e., multi-attribute) assessment of the
design (exploration) alternatives and their interrelation (compatibility) and
mapping if the obtained vector estimates into integrated ordinal scale; (4)
hierarchical design ('bottom-up') of composite exploration plans for each
oil-gas field; (5) integration of the plans into region plans and (6)
aggregation of the region plans into a general exploration plan. Stages 2, 3,
4, and 5 are based on hierarchical multicriteria morphological design (HMMD)
method (assessment of ranking of alternatives, selection and composition of
alternatives into composite alternatives). The composition problem is based on
morphological clique model. Aggregation of the obtained modular alternatives
(stage 6) is based on detection of a alternatives 'kernel' and its extension by
addition of elements (multiple choice model). In addition, the usage of
multiset estimates for alternatives is described as well. The alternative
estimates are based on expert judgment. The suggested combinatorial planning
methodology is illustrated by numerical examples for geological exploration of
Yamal peninsula.
</dc:description>
 <dc:description>Comment: 14 pages, 15 figures, 11 tables</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07230</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DiscrimNet: Semi-Supervised Action Recognition from Videos using
  Generative Adversarial Networks</dc:title>
 <dc:creator>Ahsan, Unaiza</dc:creator>
 <dc:creator>Sun, Chen</dc:creator>
 <dc:creator>Essa, Irfan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an action recognition framework using Gen- erative Adversarial
Networks. Our model involves train- ing a deep convolutional generative
adversarial network (DCGAN) using a large video activity dataset without la-
bel information. Then we use the trained discriminator from the GAN model as an
unsupervised pre-training step and fine-tune the trained discriminator model on
a labeled dataset to recognize human activities. We determine good network
architectural and hyperparameter settings for us- ing the discriminator from
DCGAN as a trained model to learn useful representations for action
recognition. Our semi-supervised framework using only appearance infor- mation
achieves superior or comparable performance to the current state-of-the-art
semi-supervised action recog- nition methods on two challenging video activity
datasets: UCF101 and HMDB51.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07233</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving TSP Solutions Using GA with a New Hybrid Mutation Based on
  Knowledge and Randomness</dc:title>
 <dc:creator>Alkafaween, Esra'a</dc:creator>
 <dc:creator>Hassanat, Ahmad B. A.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Genetic algorithm (GA) is an efficient tool for solving optimization problems
by evolving solutions, as it mimics the Darwinian theory of natural evolution.
The mutation operator is one of the key success factors in GA, as it is
considered the exploration operator of GA. Various mutation operators exist to
solve hard combinatorial problems such as the TSP. In this paper, we propose a
hybrid mutation operator called &quot;IRGIBNNM&quot;, this mutation is a combination of
two existing mutations, a knowledge-based mutation, and a random-based
mutation. We also improve the existing &quot;select best mutation&quot; strategy using
the proposed mutation. We conducted several experiments on twelve benchmark
Symmetric traveling salesman problem (STSP) instances. The results of our
experiments show the efficiency of the proposed mutation, particularly when we
use it with some other mutations. Keyword: Knowledge-based mutation, Inversion
mutation, Slide mutation, RGIBNNM, SBM.
</dc:description>
 <dc:description>Comment: 18 pages, 9 figure and 4 tables</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07237</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smoke: Fine-grained Lineage at Interactive Speed</dc:title>
 <dc:creator>Psallidas, Fotis</dc:creator>
 <dc:creator>Wu, Eugene</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Data lineage describes the relationship between individual input and output
data items of a workflow, and has served as an integral ingredient for both
traditional (e.g., debugging, auditing, data integration, and security) and
emergent (e.g., interactive visualizations, iterative analytics, explanations,
and cleaning) applications. The core, long-standing problem that lineage
systems need to address---and the main focus of this paper---is to capture the
relationships between input and output data items across a workflow with the
goal to streamline queries over lineage. Unfortunately, current lineage systems
either incur high lineage capture overheads, or lineage query processing costs,
or both. As a result, applications, that in principle can express their logic
declaratively in lineage terms, resort to hand-tuned implementations. To this
end, we introduce Smoke, an in-memory database engine that neither lineage
capture overhead nor lineage query processing needs to be compromised. To do
so, Smoke introduces tight integration of the lineage capture logic into
physical database operators; efficient, write-optimized lineage representations
for storage; and optimizations when future lineage queries are known up-front.
Our experiments on microbenchmarks and realistic workloads show that Smoke
reduces the lineage capture overhead and streamlines lineage queries by
multiple orders of magnitude compared to state-of-the-art alternatives. Our
experiments on real-world applications highlight that Smoke can meet the
latency requirements of interactive visualizations (e.g., &lt;150ms) and
outperform hand-written implementations of data profiling primitives.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07239</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Food recognition and recipe analysis: integrating visual content,
  context and external knowledge</dc:title>
 <dc:creator>Herranz, Luis</dc:creator>
 <dc:creator>Min, Weiqing</dc:creator>
 <dc:creator>Jiang, Shuqiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The central role of food in our individual and social life, combined with
recent technological advances, has motivated a growing interest in applications
that help to better monitor dietary habits as well as the exploration and
retrieval of food-related information. We review how visual content, context
and external knowledge can be integrated effectively into food-oriented
applications, with special focus on recipe analysis and retrieval, food
recommendation, and the restaurant context as emerging directions.
</dc:description>
 <dc:description>Comment: Survey about contextual food recognition and multimodal recipe
  analysis</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07243</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personalizing Dialogue Agents: I have a dog, do you have pets too?</dc:title>
 <dc:creator>Zhang, Saizheng</dc:creator>
 <dc:creator>Dinan, Emily</dc:creator>
 <dc:creator>Urbanek, Jack</dc:creator>
 <dc:creator>Szlam, Arthur</dc:creator>
 <dc:creator>Kiela, Douwe</dc:creator>
 <dc:creator>Weston, Jason</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Chit-chat models are known to have several problems: they lack specificity,
do not display a consistent personality and are often not very captivating. In
this work we present the task of making chit-chat more engaging by conditioning
on profile information. We collect data and train models to (i) condition on
their given profile information; and (ii) information about the person they are
talking to, resulting in improved dialogues, as measured by next utterance
prediction. Since (ii) is initially unknown our model is trained to engage its
partner with personal topics, and we show the resulting dialogue can be used to
predict profile information about the interlocutors.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07246</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Frequency Offsets Estimation</dc:title>
 <dc:creator>Du, Jian</dc:creator>
 <dc:creator>Ma, Shaodan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we provide a distributed frequency offset estimation algorithm
based on a variant of belief propagation (BP). Each agent in the network
pre-compensates its carrier frequency individually so that there is no
frequency offset from the desired carrier frequency between each pair of
transceiver. The pre-compensated offset for each agent is computed in a
distributed fashion in order to be adaptive to the distributed network. The
updating procedure of the variant of BP is designed in a broadcasting fashion
to reduce communication burden. It is rigorously proved that the proposed
algorithm is convergence guaranteed. Simulations show that this method achieves
almost the optimal frequency compensation accuracy with an error approaching
the Cram\'er-Rao lower bound.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1710.00778</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07249</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-level Active Visual Navigation: Increasing robustness of
  vision-based localization using potential fields</dc:title>
 <dc:creator>Rodrigues, Romulo T.</dc:creator>
 <dc:creator>Basiri, Meysam</dc:creator>
 <dc:creator>Aguiar, A. Pedro</dc:creator>
 <dc:creator>Miraldo, Pedro</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper proposes a low-level visual navigation algorithm to improve visual
localization of a mobile robot. The algorithm, based on artificial potential
fields, associates each feature in the current image frame with an attractive
or neutral potential energy, with the objective of generating a control action
that drives the vehicle towards the goal, while still favoring feature-rich
areas within a local scope, \replaced{thus improving}{improving in this way}
the localization performance. One key property of the proposed method is that
it does not rely on mapping, and therefore it is a lightweight solution that
can be deployed on miniaturized aerial robots, in which memory and
computational power are major constraints. Simulations and real experimental
results using a mini quadrotor equipped with a downward looking camera
demonstrate that the proposed method can effectively drive the vehicle to
\replaced{a designated}{the} goal through a path that prevents localization
failure.
</dc:description>
 <dc:description>Comment: accepted for ICRA 2018. arXiv admin note: text overlap with
  arXiv:1709.04687</dc:description>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07288</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Siamese Neural Networks with Random Forest for detecting duplicate
  question pairs</dc:title>
 <dc:creator>Godbole, Ameya</dc:creator>
 <dc:creator>Dalmia, Aman</dc:creator>
 <dc:creator>Sahu, Sunil Kumar</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Determining whether two given questions are semantically similar is a fairly
challenging task given the different structures and forms that the questions
can take. In this paper, we use Gated Re- current Units(GRU) in combination
with other highly used machine learning algorithms like Random Forest, Adaboost
and SVM for the similarity prediction task on a dataset released by Quora,
consisting of about 400k labeled question pairs. We got the best result by
using the Siamese adaptation of a Bidirectional GRU with a Random Forest
classifier, which landed us among the top 24% in the competition Quora Question
Pairs hosted on Kaggle.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07292</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence of Value Aggregation for Imitation Learning</dc:title>
 <dc:creator>Cheng, Ching-An</dc:creator>
 <dc:creator>Boots, Byron</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Value aggregation is a general framework for solving imitation learning
problems. Based on the idea of data aggregation, it generates a policy sequence
by iteratively interleaving policy optimization and evaluation in an online
learning setting. While the existence of a good policy in the policy sequence
can be guaranteed non-asymptotically, little is known about the convergence of
the sequence or the performance of the last policy. In this paper, we debunk
the common belief that value aggregation always produces a convergent policy
sequence with improving performance. Moreover, we identify a critical stability
condition for convergence and provide a tight non-asymptotic bound on the
performance of the last policy. These new theoretical insights let us stabilize
problems with regularization, which removes the inconvenient process of
identifying the best policy in the policy sequence in stochastic problems.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07299</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Objective De Novo Drug Design with Conditional Graph Generative
  Model</dc:title>
 <dc:creator>Li, Yibo</dc:creator>
 <dc:creator>Zhang, Liangren</dc:creator>
 <dc:creator>Liu, Zhenming</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recently, deep generative models have revealed itself as a promising way of
performing de novo molecule design. However, previous research has largely
focused on generating SMILES strings instead of molecular graphs. Although
current graph generative models are available, they are often too general and
computationally expensive, which restricts their application to molecules with
small sizes. In this work, a new de novo molecular design framework is proposed
based on a sequential graph generator. Compared with previous graph generative
models, the proposed method is much more tuned for molecule generation and have
been scaled up to cover significantly larger molecules in the ChEMBL database.
It is shown that the graph-based model produces a higher fraction of valid
output structures compared with SMILES-based methods. For the application of
drug design tasks, conditional graph generative model is employed. This method
offers higher flexibility compared to previous fine-tuning based approach and
is suitable for generation based on multiple objectives. This approach is
applied to solve several drug design problems, including generation of
compounds containing a given scaffold, generation of compounds with specific
drug-likeness and synthetic accessibility requirements, as well as generating
dual inhibitors against JNK3 and GSK3b. Results show high enrichment rates for
outputs satisfying the given requirements.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07301</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Secure Computation of Statistical Functions with Applications
  to $k$-Nearest Neighbors</dc:title>
 <dc:creator>Shaul, Hayim</dc:creator>
 <dc:creator>Feldman, Dan</dc:creator>
 <dc:creator>Rus, Daniela</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Given a set $S$ of $n$ $d$-dimensional points, the $k$-nearest neighbors
(KNN) is the problem of quickly finding $k$ points in $S$ that are nearest to a
query point $q$. The $k$-nearest neighbors problem has applications in machine
learning for classification and regression and also in searching. The secure
version of KNN where either $q$ or $S$ are encrypted, has applications such as
providing services over sensitive (such as medical or localization) data.
  In this work we present the first scalable and efficient algorithm for
solving KNN with Fully Homomorphic Encryption (FHE) that is realized by a
polynomial whose degree is independent of $n$, the number of points. We
implemented our algorithm in an open source library based on HELib
implementation for the Brakerski-Gentry-Vakuntanthan's FHE scheme, and ran
experiments on MIT's OpenStack cloud. Our experiments show that given a query
point $q$, we can find the set of 20 nearest points out of more than 1000
points in less than an hour.
  Our result introduces a statistical coreset, which is a data summarization
technique that allows statistical functions, such as moments, to be efficiently
and scalably computed. As a central tool, we design a new coin toss technique
which we use to build the coreset. This coin toss technique and computation of
statistical functions may be of independent interest.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07311</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Class-specific Word Representations for Early Detection of
  Hoaxes in Social Media</dc:title>
 <dc:creator>Zubiaga, Arkaitz</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  As people increasingly use social media as a source for news consumption, its
unmoderated nature enables the diffusion of hoaxes, which in turn jeopardises
the credibility of information gathered from social media platforms. To
mitigate this problem, we study the development of a hoax detection system that
can distinguish true and false reports early on. We introduce a semi-automated
approach that leverages the Wikidata knowledge base to build large-scale
datasets for veracity classification, which enables us to create a dataset with
4,007 reports including over 13 million tweets, 15% of which are fake. We
describe a method for learning class-specific word representations using word
embeddings, which we call multiw2v. Our approach achieves competitive results
with F1 scores over 72% within 10 minutes of the first tweet being posted,
outperforming other baselines. Our dataset represents a realistic scenario with
a real distribution of true and false stories, which we release for further use
as a benchmark in future research.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07314</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control of Large Swarms via Random Finite Set Theory</dc:title>
 <dc:creator>Doerr, Bryce</dc:creator>
 <dc:creator>Linares, Richard</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Controlling large swarms of robotic agents has many challenges, including but
not limited to, computational complexity due to the number of agents,
uncertainty in the functionality of each agent in the swarm, and limited
knowledge of information of each agent. This work generalizes the swarm state
using Random Finite Set (RFS) theory and solves the control problem using model
predictive control. The proposed RFS-based approach naturally handled the
aforementioned challenges. This work uses information divergence to define the
distance between swarm RFS and a desired distribution. A stochastic optimal
control problem is formulated using a modified L2^2 distance. Simulation
results are shown for this problem formulation.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07316</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Hybrid Bootstrap: A Drop-in Replacement for Dropout</dc:title>
 <dc:creator>Kosar, Robert</dc:creator>
 <dc:creator>Scott, David W.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Regularization is an important component of predictive model building. The
hybrid bootstrap is a regularization technique that functions similarly to
dropout except that features are resampled from other training points rather
than replaced with zeros. We show that the hybrid bootstrap offers superior
performance to dropout. We also present a sampling based technique to simplify
hyperparameter choice. Next, we provide an alternative sampling technique for
convolutional neural networks. Finally, we demonstrate the efficacy of the
hybrid bootstrap on non-image tasks using tree-based models.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07317</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial-Time Random Oracles and Separating Complexity Classes</dc:title>
 <dc:creator>Hitchcock, John M.</dc:creator>
 <dc:creator>Sekoni, Adewale</dc:creator>
 <dc:creator>Shafei, Hadi</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Bennett and Gill (1981) showed that P^A != NP^A != coNP^A for a random oracle
A, with probability 1. We investigate whether this result extends to individual
polynomial-time random oracles. We consider two notions of random oracles:
p-random oracles in the sense of martingales and resource-bounded measure
(Lutz, 1992; Ambos-Spies et al., 1997), and p-betting-game random oracles using
the betting games generalization of resource-bounded measure (Buhrman et al.,
2000). Every p-betting-game random oracle is also p-random; whether the two
notions are equivalent is an open problem.
  (1) We first show that P^A != NP^A for every oracle A that is p-betting-game
random.
  Ideally, we would extend (1) to p-random oracles. We show that answering this
either way would imply an unrelativized complexity class separation:
  (2) If P^A != NP^A relative to every p-random oracle A, then BPP != EXP.
  (3) If P^A = NP^A relative to some p-random oracle A, then P != PSPACE.
  Rossman, Servedio, and Tan (2015) showed that the polynomial-time hierarchy
is infinite relative to a random oracle, solving a longstanding open problem.
We consider whether we can extend (1) to show that PHA is infinite relative to
oracles A that are p-betting-game random. Showing that PHA separates at even
its first level would also imply an unrelativized complexity class separation:
  (4) If NP^A != coNP^A for a p-betting-game measure 1 class of oracles A, then
NP != EXP.
  (5) If PH^A is infinite relative to every p-random oracle A, then PH != EXP.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07319</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimistic Execution in Key-Value Store</dc:title>
 <dc:creator>Nguyen, Duong</dc:creator>
 <dc:creator>Charapko, Aleksey</dc:creator>
 <dc:creator>Kulkarni, Sandeep</dc:creator>
 <dc:creator>Demirbas, Murat</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Limitations of CAP theorem imply that if availability is desired in the
presence of network partitions, one must sacrifice sequential consistency, a
consistency model that is more natural for system design. We focus on the
problem of what a designer should do if she has an algorithm that works
correctly with sequential consistency but is faced with an underlying key-value
store that provides a weaker (e.g., eventual or causal) consistency. We propose
a detect-rollback based approach: The designer identifies a correctness
predicate, say P , and continue to run the protocol, as our system monitors P .
If P is violated (because the underlying key-value store provides a weaker
consistency), the system rolls back and resumes the computation at a state
where P holds.
  We evaluate this approach in the Voldemort key-value store. Our experiments
with deployment of Voldemort on Amazon AWS shows that using eventual
consistency with monitoring can provide 20 - 40% increase in throughput when
compared with sequential consistency. We also show that the overhead of the
monitor itself is small (typically less than 8%) and the latency of detecting
violations is very low. For example, more than 99.9% violations are detected in
less than 1 second.
</dc:description>
 <dc:description>Comment: This paper is submitted to ICDCS 2018</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07321</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topological Entropy of Formal Languages</dc:title>
 <dc:creator>Starke, Florian</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this thesis we will introduce topological automata and the topological
entropy of a topological automaton, which is the topological entropy of the
dynamical system contained in the automaton. We will use these notions to
define a measure of complexity for formal languages. We assign to every
language the topological entropy of the unique minimal topological automaton
accepting it. We contribute several new results. We use a preexisting
characterization of the topological entropy of a formal language in terms of
Myhill-Nerode congruence classes to compute the topological entropy of several
new example languages. We determine the entropy of the Dyck languages and the
deterministic palindrom language. Also we will further develop an idea from
Schneider and Borchmann [5] to solve the previously open question of whether
the entropy function is surjective. Furthermore, we show that all languages
accepted by deterministic real-time multi-counter automata have zero entropy
and all languages accepted by deterministic real-time multi-push-down automata
have finite entropy, bounded in terms of the sizes of the stack alphabets of
the automaton. In particular this proves that all deterministic real-time
context-free languages have finite entropy. We also give an example of a
deterministic context-free language with infinite entropy, proving that not all
context-free languages have finite entropy. We show that there are encodings of
SAT, 3COLORING, and CLIQUE such that these languages have infinite entropy.
</dc:description>
 <dc:description>Comment: 77 pages</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07327</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication Model-Task Pairing in Artificial Swarm Design</dc:title>
 <dc:creator>Haque, Musad</dc:creator>
 <dc:creator>McGowan, Connor</dc:creator>
 <dc:creator>Guo, Yifan</dc:creator>
 <dc:creator>Kirkpatrick, Douglas</dc:creator>
 <dc:creator>Adams, Julie A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  Unraveling the nature of the communication model that governs which two
individuals in a swarm interact with each other is an important line of inquiry
in the collective behavior sciences. A number of models have been proposed in
the biological swarm literature, with the leading models being the metric,
topological, and visual models. The hypothesis evaluated in this manuscript is
whether the choice of a communication model impacts the performance of a tasked
artificial swarm. The biological models are used to design coordination
algorithms for a simulated swarm, which are evaluated over a range of six swarm
robotics tasks. Each task has an associated set of performance metrics that are
used to evaluate how the communication models fare against each other. The
general findings demonstrate that the communication model significantly affects
the swarm's performance for individual tasks, and this result implies that the
communication model-task pairing is an important consideration when designing
artificial swarms. Further analysis of each tasks' performance metrics reveal
instances in which pairwise considerations of model and one of the various
experimental factors becomes relevant. The reported research demonstrates that
the artificial swarm's task performance can be increased through the careful
selection of a communications model.
</dc:description>
 <dc:description>Comment: 10 pages, 29 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07330</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-throughput, high-resolution Generated Adversarial Network
  Microscopy</dc:title>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:creator>Xie, Xinlin</dc:creator>
 <dc:creator>Fang, Chunyu</dc:creator>
 <dc:creator>Yang, Yicong</dc:creator>
 <dc:creator>Jin, Di</dc:creator>
 <dc:creator>Fei, Peng</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Quantitative Biology - Tissues and Organs</dc:subject>
 <dc:description>  We for the first time combine generated adversarial network (GAN) with
wide-field light microscopy to achieve deep learning super-resolution under a
large field of view (FOV). By appropriately adopting prior microscopy data in
an adversarial training, the network can recover a high-resolution, accurate
image of new specimen from its single low-resolution measurement. This capacity
has been adequately demonstrated by imaging various types of samples, such as
USAF resolution target, human pathological slides and fluorescence-labelled
fibroblast cells. Their gigapixel, multi-color reconstructions verify a
successful GAN-based single image super-resolution procedure. Furthermore, this
deep learning-based imaging approach doesn;t necessarily introduce any change
to the setup of a conventional wide-filed microscope, reconstructing large FOV
(about 95 mm^2), high-resolution (about 1.7 {\mu}m) image at a high speed (in 1
second). As a result, GAN-microscopy opens a new way to computationally
overcome the general challenge of high-throughput, high-resolution microscopy
that is originally coupled to the physical limitation of system's optics.
</dc:description>
 <dc:description>Comment: 22 pages, 8 figures and 1 table. Peng Fe and Di Jin conceived the
  ides, initiated the investigation. Hao Zhang, Di Jin and Peng Fei prepared
  the manuscript</dc:description>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07337</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning and Finite Element Method for Physical Systems Modeling</dc:title>
 <dc:creator>Kononenko, O.</dc:creator>
 <dc:creator>Kononenko, I.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Modeling of physical systems includes extensive use of software packages that
implement the accurate finite element method for solving differential equations
considered along with the appropriate initial and boundary conditions. When the
problem size becomes large, time needed to solve the resulting linear systems
may range from hours to weeks, and if the input parameters need to be adjusted,
even slightly, the simulations has to be re-done from scratch. Recent advances
in machine learning algorithms and their successful applications in various
fields demonstrate that, if properly chosen and trained, these models can
significantly improve conventional techniques. In this note we discuss
possibilities to complement the finite element studies with machine learning
and provide several basic examples.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07339</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicle Detection in Aerial Images</dc:title>
 <dc:creator>Yang, Michael Ying</dc:creator>
 <dc:creator>Liao, Wentong</dc:creator>
 <dc:creator>Li, Xinbo</dc:creator>
 <dc:creator>Rosenhahn, Bodo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The detection of vehicles in aerial images is widely applied in many
applications. Comparing with object detection in the ground view images,
vehicle detection in aerial images remains a challenging problem because of
small vehicle size, monotone appearance and the complex background. In this
paper, we propose a novel double focal loss convolutional neural network
framework (DFL-CNN). In the proposed framework, the skip connection is used in
the CNN structure to enhance the feature learning. Also, the focal loss
function is used to substitute for conventional cross entropy loss function in
both of the region proposed network and the final classifier. We further
introduce the first large-scale vehicle detection dataset ITCVD with ground
truth annotations for all the vehicles in the scene. We demonstrate the
performance of our model on the existing benchmark DLR 3K dataset as well as
the ITCVD dataset. The experimental results show that our DFL-CNN outperforms
the baselines on vehicle detection.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07342</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perfect simulation of the Hard Disks Model by Partial Rejection Sampling</dc:title>
 <dc:creator>Guo, Heng</dc:creator>
 <dc:creator>Jerrum, Mark</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a perfect simulation of the hard disks model via the partial
rejection sampling method. Provided the density of disks is not too high, the
method produces exact samples in $O(\log n)$ rounds, where $n$ is the expected
number of disks. The method extends easily to the hard spheres model in $d&gt;2$
dimensions.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07347</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Performance Analysis of Full-Duplex Communications in
  Cache-Enabled D2D Networks</dc:title>
 <dc:creator>Naslcheraghi, Mansour</dc:creator>
 <dc:creator>Afshang, Mehrnaz</dc:creator>
 <dc:creator>Dhillon, Harpreet S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Cache-enabled Device-to-Device (D2D) communication is widely recognized as
one of the key components of the emerging fifth generation (5G) cellular
network architecture. However, conventional half-duplex (HD) transmission may
not be sufficient to provide fast enough content delivery over D2D links and to
meet strict latency targets of emerging D2D applications. In-band full-duplex
(FD), with its capability of allowing simultaneous transmission and reception,
can improve spectral efficiency and reduce latency by providing more content
delivery opportunities. In this paper, we consider a finite network of D2D
nodes in which each node is endowed with FD capability. We first carefully list
all possible operating modes for an arbitrary device and use it to compute the
number of devices that are actively transmitting at any given time. We then
characterize network performance in terms of the success probability, which
depends on the content availability, signal-to-interference ratio (SIR)
distribution, as well as the operating mode of the D2D receiver. Our analysis
concretely demonstrates that the caching dictates the system performance in
lower target SIR thresholds whereas interference dictates the performance at
the higher target SIR thresholds.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07351</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Network Dynamics: a review of distances and similarity metrics</dc:title>
 <dc:creator>Donnat, Claire</dc:creator>
 <dc:creator>Holmes, Susan</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  From longitudinal biomedical studies to social networks, graphs have emerged
as a powerful framework for describing evolving interactions between agents in
complex systems. In such studies, the data typically consists of a set of
graphs representing a system's state at different points in time or space. The
analysis of the system's dynamics depends on the selection of the appropriate
tools. In particular, after specifying properties characterizing similarities
between states, a critical step lies in the choice of a distance capable of
reflecting such similarities. While the literature offers a number of distances
that one could a priori choose from, their properties have been little
investigated and no guidelines regarding the choice of such a distance have yet
been provided. However, these distances' sensitivity to perturbations in the
network's structure and their ability to identify important changes are crucial
to the analysis, making the selection of an adequate metric a decisive -- yet
delicate -- practical matter.
  In the spirit of Goldenberg, Zheng and Fienberg's seminal 2009 review, the
purpose of this article is to provide an overview of commonly-used graph
distances and an explicit characterization of the structural changes that they
are best able to capture. To see how this translates in real-life situations,
we use as a guiding thread to our discussion the application of these distances
to the analysis a longitudinal microbiome study -- as well as on synthetic
examples. Having unveiled some of traditional distances' shortcomings, we also
suggest alternative similarity metrics and highlight their relative advantages
in specific analysis scenarios. Above all, we provide some guidance for
choosing one distance over another in certain types of applications. Finally,
we show an application of these different distances to a network created from
worldwide recipes.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07353</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Deep Neural Network Processing</dc:title>
 <dc:creator>Tann, Hokchhay</dc:creator>
 <dc:creator>Hashemi, Soheil</dc:creator>
 <dc:creator>Reda, Sherief</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The recent success of Deep Neural Networks (DNNs) has drastically improved
the state of the art for many application domains. While achieving high
accuracy performance, deploying state-of-the-art DNNs is a challenge since they
typically require billions of expensive arithmetic computations. In addition,
DNNs are typically deployed in ensemble to boost accuracy performance, which
further exacerbates the system requirements. This computational overhead is an
issue for many platforms, e.g. data centers and embedded systems, with tight
latency and energy budgets. In this article, we introduce flexible DNNs
ensemble processing technique, which achieves large reduction in average
inference latency while incurring small to negligible accuracy drop. Our
technique is flexible in that it allows for dynamic adaptation between quality
of results (QoR) and execution runtime. We demonstrate the effectiveness of the
technique on AlexNet and ResNet-50 using the ImageNet dataset. This technique
can also easily handle other types of networks.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07355</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Importance of Communities for Learning to Influence</dc:title>
 <dc:creator>Balkanski, Eric</dc:creator>
 <dc:creator>Immorlica, Nicole</dc:creator>
 <dc:creator>Singer, Yaron</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the canonical problem of influence maximization in social
networks. Since the seminal work of Kempe, Kleinberg, and Tardos, there have
been two largely disjoint efforts on this problem. The first studies the
problem associated with learning the parameters of the generative influence
model. The second focuses on the algorithmic challenge of identifying a set of
influencers, assuming the parameters of the generative model are known. Recent
results on learning and optimization imply that in general, if the generative
model is not known but rather learned from training data, no algorithm can
yield a constant factor approximation guarantee using polynomially-many
samples, drawn from any distribution.
  In this paper, we design a simple heuristic that overcomes this negative
result in practice by leveraging the strong community structure of social
networks. Although in general the approximation guarantee of our algorithm is
necessarily unbounded, we show that this algorithm performs well
experimentally. To justify its performance, we prove our algorithm obtains a
constant factor approximation guarantee on graphs generated through the
stochastic block model, traditionally used to model networks with community
structure.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07356</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Code-Frequency Block Group Coding for Anti-Spoofing Pilot Authentication
  in Multi-Antenna OFDM Systems</dc:title>
 <dc:creator>Xu, Dongyang</dc:creator>
 <dc:creator>Ren, Pinyi</dc:creator>
 <dc:creator>Ritcey, James A.</dc:creator>
 <dc:creator>Wang, Yichen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  A pilot spoofer can paralyze the channel estimation in multi-user orthogonal
frequency-division multiplexing (OFD- M) systems by using the same
publicly-known pilot tones as legitimate nodes. This causes the problem of
pilot authentication (PA). To solve this, we propose, for a two-user
multi-antenna OFDM system, a code-frequency block group (CFBG) coding based PA
mechanism. Here multi-user pilot information, after being randomized
independently to avoid being spoofed, are converted into activation patterns of
subcarrier-block groups on code-frequency domain. Those patterns, though
overlapped and interfered mutually in the wireless transmission environment,
are qualified to be separated and identified as the original pilots with high
accuracy, by exploiting CFBG coding theory and channel characteristic.
Particularly, we develop the CFBG code through two steps, i.e., 1) devising an
ordered signal detection technique to recognize the number of signals
coexisting on each subcarrier block, and encoding each subcarrier block with
the detected number; 2) constructing a zero-false-drop (ZFD) code and block
detection based (BD) code via k-dimensional Latin hypercubes and integrating
those two codes into the CFBG code. This code can bring a desirable pilot
separation error probability (SEP), inversely proportional to the number of
occupied subcarriers and antennas with a power of k. To apply the code to PA, a
scheme of pilot conveying, separation and identification is proposed. Based on
this novel PA, a joint channel estimation and identification mechanism is
proposed to achieve high-precision channel recovery and simultaneously enhance
PA without occupying extra resources. Simulation results verify the
effectiveness of our proposed mechanism.
</dc:description>
 <dc:description>Comment: accepted to IEEE Transactions on Information Forensics and Security,
  Jan. 2018</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07357</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CHALET: Cornell House Agent Learning Environment</dc:title>
 <dc:creator>Yan, Claudia</dc:creator>
 <dc:creator>Misra, Dipendra</dc:creator>
 <dc:creator>Bennnett, Andrew</dc:creator>
 <dc:creator>Walsman, Aaron</dc:creator>
 <dc:creator>Bisk, Yonatan</dc:creator>
 <dc:creator>Artzi, Yoav</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present CHALET, a 3D house simulator with support for navigation and
manipulation. CHALET includes 58 rooms and 10 house configuration, and allows
to easily create new house and room layouts. CHALET supports a range of common
household activities, including moving objects, toggling appliances, and
placing objects inside closeable containers. The environment and actions
available are designed to create a challenging domain to train and evaluate
autonomous agents, including for tasks that combine language, vision, and
planning in a dynamic environment.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07362</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Pairwise Intersections of Rectangles in a Query Rectangle</dc:title>
 <dc:creator>Oh, Eunjin</dc:creator>
 <dc:creator>Ahn, Hee-Kap</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We consider the following problem: Preprocess a set $\mathcal{S}$ of $n$
axis-parallel boxes in $\mathbb{R}^d$ so that given a query of an axis-parallel
box in $\mathbb{R}^d$, the pairs of boxes of $\mathcal{S}$ whose intersection
intersects the query box can be reported efficiently. For the case that $d=2$,
we present a data structure of size $O(n\log n)$ supporting $O(\log n+k)$ query
time, where $k$ is the size of the output. This improves the previously best
known result by de Berg et al. which requires $O(\log n+ k\log n)$ query time
using $O(n\log n)$ space. There has been no result known for this problem for
higher dimensions, except that for $d=3$, the best known data structure
supports $O(\sqrt{n}\log^2n+k\log^2n)$ query time using $O(n\sqrt {n}\log n)$
space. For a constant $d&gt;2$, we present a data structure supporting
$O(n^{1-\delta}\log^{d-1} n + k \text{ polylog } n)$ query time for any
constant $1/d\leq\delta&lt;1$. The size of the data structure is $O(n^{\delta d -
2\delta + 1}\log n)$.
</dc:description>
 <dc:description>Comment: The preliminary version appeared in the Proceedings of 28th
  International Symposium on Algorithms and Computation (ISAAC 2017)</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07365</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Prune Filters in Convolutional Neural Networks</dc:title>
 <dc:creator>Huang, Qiangui</dc:creator>
 <dc:creator>Zhou, Kevin</dc:creator>
 <dc:creator>You, Suya</dc:creator>
 <dc:creator>Neumann, Ulrich</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many state-of-the-art computer vision algorithms use large scale
convolutional neural networks (CNNs) as basic building blocks. These CNNs are
known for their huge number of parameters, high redundancy in weights, and
tremendous computing resource consumptions. This paper presents a learning
algorithm to simplify and speed up these CNNs. Specifically, we introduce a
&quot;try-and-learn&quot; algorithm to train pruning agents that remove unnecessary CNN
filters in a data-driven way. With the help of a novel reward function, our
agents removes a significant number of filters in CNNs while maintaining
performance at a desired level. Moreover, this method provides an easy control
of the tradeoff between network performance and its scale. Per- formance of our
algorithm is validated with comprehensive pruning experiments on several
popular CNNs for visual recognition and semantic segmentation tasks.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07367</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mean-Field Game Theoretic Edge Caching in Ultra-Dense Networks</dc:title>
 <dc:creator>Kim, Hyesung</dc:creator>
 <dc:creator>Park, Jihong</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Kim, Seong-Lyun</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates a cellular edge caching problem under a very large
number of small base stations (SBSs) and users. In this ultra-dense edge
caching network (UDCN), conventional caching algorithms may crumble in
effectiveness as their complexity increases with the number of SBSs.
Furthermore, the performance of a UDCN is highly sensitive to the dynamics of
user demand and inter-SBS interference, due to the large number of SBSs. To
overcome such difficulties, we propose a distributed caching algorithm under a
stochastic geometric network model, as well as a spatio-temporal user demand
model that specifies the content popularity changes within long-term and
short-term periods. By exploiting mean-field game (MFG) theory, the complexity
of the proposed UDCN caching algorithm becomes independent of the number of
SBSs. The performance of the proposed caching algorithm can easily be
calculated using stochastic geometry (SG). Numerical evaluations validate that
the proposed caching algorithm reduces not only the long run average cost of
the network but also the replicated caching data amount respectively by 24% and
42%, compared to a baseline caching algorithm. The simulation results also show
that the propose caching algorithm is robust to imperfect popularity
information, while ensuring the low computational complexity.
</dc:description>
 <dc:description>Comment: submitted to IEEE Journal on Selected Areas in Communications Special
  Issue on Caching for Communication Systems and Networks</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07372</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical Coordinate Regression with Convolutional Neural Networks</dc:title>
 <dc:creator>Nibali, Aiden</dc:creator>
 <dc:creator>He, Zhen</dc:creator>
 <dc:creator>Morgan, Stuart</dc:creator>
 <dc:creator>Prendergast, Luke</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study deep learning approaches to inferring numerical coordinates for
points of interest in an input image. Existing convolutional neural
network-based solutions to this problem either take a heatmap matching approach
or regress to coordinates with a fully connected output layer. Neither of these
approaches is ideal, since the former is not entirely differentiable, and the
latter lacks inherent spatial generalization. We propose our differentiable
spatial to numerical transform (DSNT) to fill this gap. The DSNT layer adds no
trainable parameters, is fully differentiable, and exhibits good spatial
generalization. Unlike heatmap matching, DSNT works well with low heatmap
resolutions, so it can be dropped in as an output layer for a wide range of
existing fully convolutional architectures. Consequently, DSNT offers a better
trade-off between inference speed and prediction accuracy compared to existing
techniques. When used to replace the popular heatmap matching approach used in
almost all state-of-the-art methods for pose estimation, DSNT gives better
prediction accuracy for all model architectures tested.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07379</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Mobile Crowdsensing with Deep Learning</dc:title>
 <dc:creator>Xiao, Liang</dc:creator>
 <dc:creator>Jiang, Donghua</dc:creator>
 <dc:creator>Xu, Dongjin</dc:creator>
 <dc:creator>An, Ning</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In order to stimulate secure sensing for Internet of Things (IoT)
applications such as healthcare and traffic monitoring, mobile crowdsensing
(MCS) systems have to address security threats, such as jamming, spoofing and
faked sensing attacks, during both the sensing and the information exchange
processes in large-scale dynamic and heterogenous networks. In this article, we
investigate secure mobile crowdsensing and present how to use deep learning
(DL) methods such as stacked autoencoder (SAE), deep neural network (DNN), and
convolutional neural network (CNN) to improve the MCS security approaches
including authentication, privacy protection, faked sensing countermeasures,
intrusion detection and anti-jamming transmissions in MCS. We discuss the
performance gain of these DL-based approaches compared with traditional
security schemes and identify the challenges that need to be addressed to
implement them in practical MCS systems.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07380</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dense 3-D Mapping with Spatial Correlation via Gaussian Filtering</dc:title>
 <dc:creator>Sun, Ke</dc:creator>
 <dc:creator>Saulnier, Kelsey</dc:creator>
 <dc:creator>Atanasov, Nikolay</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:creator>Kumar, Vijay</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Constructing an occupancy representation of the environment is a fundamental
problem for robot autonomy. Many accurate and efficient methods exist that
address this problem but most assume that the occupancy states of different
elements in the map representation are statistically independent. The focus of
this paper is to provide a model that captures correlation of the occupancy of
map elements. Correlation is important not only for improved accuracy but also
for quantifying uncertainty in the map and for planning autonomous mapping
trajectories based on the correlation among known and unknown areas. Recent
work proposes Gaussian Process (GP) regression to capture covariance
information and enable resolution-free occupancy estimation. The drawback of
techniques based on GP regression (or classification) is that the computation
complexity scales cubically with the length of the measurement history. Our
main contribution is a new approach for occupancy mapping that models the
binary nature of occupancy measurements precisely, via a Bernoulli
distribution, and provides an efficient approximation of GP classification with
complexity that does not scale with time. We prove that the error between the
estimates provided by our method and those provided by GP classification is
negligible. The proposed method is evaluated using both simulated data and real
data collected using a Velodyne Puck 3-D range sensor.
</dc:description>
 <dc:description>Comment: Accepted at American Control Conference 2018</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07384</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Gradient Boosting Trees and Neural Networks for Forecasting
  Operating Room Data</dc:title>
 <dc:creator>Chen, Hugh</dc:creator>
 <dc:creator>Lundberg, Scott</dc:creator>
 <dc:creator>Lee, Su-In</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Time series data constitutes a distinct and growing problem in machine
learning. As the corpus of time series data grows larger, deep models that
simultaneously learn features and classify with these features can be
intractable or suboptimal. In this paper, we present feature learning via long
short term memory (LSTM) networks and prediction via gradient boosting trees
(XGB). Focusing on the consequential setting of electronic health record data,
we predict the occurrence of hypoxemia five minutes into the future based on
past features. We make two observations: 1) long short term memory networks are
effective at capturing long term dependencies based on a single feature and 2)
gradient boosting trees are capable of tractably combining a large number of
features including static features like height and weight. With these
observations in mind, we generate features by performing &quot;supervised&quot;
representation learning with LSTM networks. Augmenting the original XGB model
with these features gives significantly better performance than either
individual method.
</dc:description>
 <dc:description>Comment: Presented at Machine Learning for Health Workshop: 31st Conference on
  Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07386</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Networks from Random Walk-Based Node Similarities</dc:title>
 <dc:creator>Hoskins, Jeremy G.</dc:creator>
 <dc:creator>Musco, Cameron</dc:creator>
 <dc:creator>Musco, Christopher</dc:creator>
 <dc:creator>Tsourakakis, Charalampos E.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Digital presence in the world of online social media entails significant
privacy risks. In this work we consider a privacy threat to a social network in
which an attacker has access to a subset of random walk-based node
similarities, such as effective resistances (i.e., commute times) or
personalized PageRank scores. Using these similarities, the attacker's goal is
to infer as much information as possible about the underlying network,
including any remaining unknown pairwise node similarities and edges.
  For the effective resistance metric, we show that with just a small subset of
measurements, the attacker can learn a large fraction of edges in a social
network, even when the measurements are noisy. We also show that it is possible
to learn a graph which accurately matches the underlying network on all other
effective resistances. This second observation is interesting from a data
mining perspective, since it can be expensive to accurately compute all
effective resistances. As an alternative, our graphs learned from just a subset
of approximate effective resistances can be used as surrogates in a wide range
of applications that use effective resistances to probe graph structure,
including for graph clustering, node centrality evaluation, and anomaly
detection.
  We obtain our results by formalizing the graph learning objective
mathematically, using two optimization problems. One formulation is convex and
can be solved provably in polynomial time. The other is not, but we solve it
efficiently with projected gradient and coordinate descent. We demonstrate the
effectiveness of these methods on a number of social networks obtained from
Facebook. We also discuss how our methods can be generalized to other random
walk-based similarities, such as personalized PageRank. Our code is available
at https://github.com/cnmusco/graph-similarity-learning.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07388</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Let's Dance: Learning From Online Dance Videos</dc:title>
 <dc:creator>Castro, Daniel</dc:creator>
 <dc:creator>Hickson, Steven</dc:creator>
 <dc:creator>Sangkloy, Patsorn</dc:creator>
 <dc:creator>Mittal, Bhavishya</dc:creator>
 <dc:creator>Dai, Sean</dc:creator>
 <dc:creator>Hays, James</dc:creator>
 <dc:creator>Essa, Irfan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  In recent years, deep neural network approaches have naturally extended to
the video domain, in their simplest case by aggregating per-frame
classifications as a baseline for action recognition. A majority of the work in
this area extends from the imaging domain, leading to visual-feature heavy
approaches on temporal data. To address this issue we introduce &quot;Let's Dance&quot;,
a 1000 video dataset (and growing) comprised of 10 visually overlapping dance
categories that require motion for their classification. We stress the
important of human motion as a key distinguisher in our work given that, as we
show in this work, visual information is not sufficient to classify
motion-heavy categories. We compare our datasets' performance using imaging
techniques with UCF-101 and demonstrate this inherent difficulty. We present a
comparison of numerous state-of-the-art techniques on our dataset using three
different representations (video, optical flow and multi-person pose data) in
order to analyze these approaches. We discuss the motion parameterization of
each of them and their value in learning to categorize online dance videos.
Lastly, we release this dataset (and its three representations) for the
research community to use.
</dc:description>
 <dc:description>Comment: first submitted November 2016</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07395</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Computation of Optimal Control Problems with Terminal Inequality
  Constraint via Variation Evolution</dc:title>
 <dc:creator>Zhang, Sheng</dc:creator>
 <dc:creator>Chenq, Yan-Qing</dc:creator>
 <dc:creator>Qian, Wei-Qi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Studies regarding the computation of Optimal Control Problems (OCPs) with
terminal inequality constraint, under the frame of the Variation Evolving
Method (VEM), are carried out. The attributes of equality constraints and
inequality constraints in the generalized optimization problem is traversed,
and the intrinsic relations to the multipliers are uncovered. Upon these
preliminaries, the right Evolution Partial Differential Equation (EPDE) is
derived, and the costate-free optimality conditions are established. Besides
the analytic expression for the costates in the classic treatment, they also
reveal the analytic relations between the states, the controls and the
(Lagrange and KKT) multipliers, which adjoin the terminal (equality and
inequality) constraints. Moreover, in solving the transformed Initial-value
Problems (IVPs) with common Ordinary Differential Equation (ODE) integration
methods, the numerical soft barrier is proposed to eliminate the numerical
error resulting from the suddenly triggered inequality constraint and it is
shown to be effective.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1801.01383,
  arXiv:1712.09702, arXiv:1709.02242</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07397</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HCIC: Hardware-assisted Control-flow Integrity Checking</dc:title>
 <dc:creator>Zhang, Jiliang</dc:creator>
 <dc:creator>Qi, Binhang</dc:creator>
 <dc:creator>Qu, Gang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Recently, code reuse attacks (CRAs), such as return-oriented programming
(ROP) and jump-oriented programming (JOP), have emerged as a new class of
ingenious security threatens. Attackers can utilize CRAs to hijack the control
flow of programs to perform malicious actions without injecting any codes. Many
defenses, classed into software-based and hardware-based, have been proposed.
However, software-based methods are difficult to be deployed in practical
systems due to high performance overhead. Hardware-based methods can reduce
performance overhead but may require extending instruction set architectures
(ISAs) and modifying compiler or suffer the vulnerability of key leakage. To
tackle these issues, this paper proposes a new hardware-based control flow
checking method to resist CRAs with negligible performance overhead without
extending ISAs, modifying compiler and leaking the encryption/decryption key.
The key technique involves two control flow checking mechanisms. The first one
is the encrypted Hamming distances (EHDs) matching between the physical
unclonable function (PUF) response and the return addresses, which prevents
attackers from returning between gadgets so long as the PUF response is secret,
thus resisting ROP attacks. The second one is the liner encryption/decryption
operation (XOR) between PUF response and the instructions at target addresses
of call and jmp instructions to defeat JOP attacks. Advanced return-based
full-function reuse attacks will be prevented with the dynamic key-updating
method. Experimental evaluations on benchmarks demonstrate that the proposed
method introduces negligible 0.95% run-time overhead and 0.78% binary size
overhead on average.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07399</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Onion Curve: A Space Filling Curve with Near-Optimal Clustering</dc:title>
 <dc:creator>Xu, Pan</dc:creator>
 <dc:creator>Nguyen, Cuong</dc:creator>
 <dc:creator>Tirthapura, Srikanta</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Space filling curves (SFCs) are widely used in the design of indexes for
spatial and temporal data. Clustering is a key metric for an SFC, that measures
how well the curve preserves locality in moving from higher dimensions to a
single dimension. We present the {\em onion curve}, an SFC whose clustering
performance is provably close to optimal for the cube and near-cube shaped
query sets, irrespective of the side length of the query. We show that in
contrast, the clustering performance of the widely used Hilbert curve can be
far from optimal, even for cube-shaped queries. Since the clustering
performance of an SFC is critical to the efficiency of multi-dimensional
indexes based on the SFC, the onion curve can deliver improved performance for
data structures involving multi-dimensional data.
</dc:description>
 <dc:description>Comment: The short version is to appear in ICDE 18</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07400</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-Resolution mmWave Channel Estimation using Atomic Norm
  Minimization</dc:title>
 <dc:creator>Chu, Hongyun</dc:creator>
 <dc:creator>Zheng, Le</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose super-resolution MIMO channel estimators for millimeter-wave
(mmWave) systems that employ hybrid analog and digital beamforming and
generalized spatial modulation, respectively. Exploiting the inherent sparsity
of mmWave channels, the channel estimation problem is formulated as an atomic
norm minimization that enhances sparsity in the continuous angles of departure
and arrival. Both pilot-assisted and data-aided channel estimators are
developed, with the former one formulated as a convex problem and the latter as
a non-convex problem. To solve these formulated channel estimation problems, we
develop a computationally efficient conjugate gradient descent method based on
non-convex factorization which restricts the search space to low-rank matrices.
Simulation results are presented to illustrate the superior channel estimation
performance of the proposed algorithms for both types of mmWave systems
compared to the existing compressed-sensing-based estimators with finely
quantized angle grids.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07402</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Studies of Fading in Underwater Wireless Optical Channels in
  the Presence of Air Bubble, Temperature, and Salinity Random Variations (Long
  Version)</dc:title>
 <dc:creator>Jamali, Mohammad Vahid</dc:creator>
 <dc:creator>Mirani, Ali</dc:creator>
 <dc:creator>Parsay, Alireza</dc:creator>
 <dc:creator>Abolhassani, Bahman</dc:creator>
 <dc:creator>Nabavi, Pooya</dc:creator>
 <dc:creator>Chizari, Ata</dc:creator>
 <dc:creator>Khorramshahi, Pirazh</dc:creator>
 <dc:creator>Abdollahramezani, Sajjad</dc:creator>
 <dc:creator>Salehi, Jawad A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Optical signal propagation through underwater channels is affected by three
main degrading phenomena, namely absorption, scattering, and fading. In this
paper, we experimentally study the statistical distribution of intensity
fluctuations in underwater wireless optical channels with random temperature
and salinity variations as well as the presence of air bubbles. In particular,
we define different scenarios to produce random fluctuations on the water
refractive index across the propagation path, and then examine the accuracy of
various statistical distributions in terms of their goodness of fit to the
experimental data. We also obtain the channel coherence time to address the
average period of fading temporal variations. The scenarios under consideration
cover a wide range of scintillation index from weak to strong turbulence.
Moreover, the effects of beam-collimator at the transmitter side and aperture
averaging lens at the receiver side are experimentally investigated. We show
that the use of a transmitter beam-collimator and/or a receiver aperture
averaging lens suits single-lobe distributions such that the generalized Gamma
and exponential Weibull distributions can excellently match the histograms of
the acquired data. Our experimental results further reveal that the channel
coherence time is on the order of $10^{-3}$ seconds and larger which implies to
the slow fading turbulent channels.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07411</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison Training for Computer Chinese Chess</dc:title>
 <dc:creator>Tseng, Wen-Jie</dc:creator>
 <dc:creator>Chen, Jr-Chang</dc:creator>
 <dc:creator>Wu, I-Chen</dc:creator>
 <dc:creator>Wei, Tinghan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper describes the application of comparison training (CT) for
automatic feature weight tuning, with the final objective of improving the
evaluation functions used in Chinese chess programs. First, we propose an
n-tuple network to extract features, since n-tuple networks require very little
expert knowledge through its large numbers of features, while simulta-neously
allowing easy access. Second, we propose a novel evalua-tion method that
incorporates tapered eval into CT. Experiments show that with the same features
and the same Chinese chess program, the automatically tuned comparison training
feature weights achieved a win rate of 86.58% against the weights that were
hand-tuned. The above trained version was then improved by adding additional
features, most importantly n-tuple features. This improved version achieved a
win rate of 81.65% against the trained version without additional features.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transaction on Games</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07412</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Agreement on Activity Driven Networks</dc:title>
 <dc:creator>Ogura, Masaki</dc:creator>
 <dc:creator>Tagawa, Junpei</dc:creator>
 <dc:creator>Masuda, Naoki</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we investigate asymptotic properties of a consensus protocol
taking place in a class of temporal (i.e., time-varying) networks called the
activity driven network. We first show that a standard methodology provides us
with an estimate of the convergence rate toward the consensus, in terms of the
eigenvalues of a matrix whose computational cost grows exponentially fast in
the number of nodes in the network. To overcome this difficulty, we then derive
alternative bounds involving the eigenvalues of a matrix that is easy to
compute. Our analysis covers the regimes of 1) sparse networks and 2)
fast-switching networks. We numerically confirm our theoretical results by
numerical simulations.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07413</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Greed is Still Good: Maximizing Monotone Submodular+Supermodular
  Functions</dc:title>
 <dc:creator>Bai, Wenruo</dc:creator>
 <dc:creator>Bilmes, Jeffrey A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We analyze the performance of the greedy algorithm, and also a discrete
semi-gradient based algorithm, for maximizing the sum of a suBmodular and
suPermodular (BP) function (both of which are non-negative monotone
non-decreasing) under two types of constraints, either a cardinality constraint
or $p\geq 1$ matroid independence constraints. These problems occur naturally
in several real-world applications in data science, machine learning, and
artificial intelligence. The problems are ordinarily inapproximable to any
factor (as we show). Using the curvature $\kappa_f$ of the submodular term, and
introducing $\kappa^g$ for the supermodular term (a natural dual curvature for
supermodular functions), however, both of which are computable in linear time,
we show that BP maximization can be efficiently approximated by both the greedy
and the semi-gradient based algorithm. The algorithms yield multiplicative
guarantees of $\frac{1}{\kappa_f}\left[1-e^{-(1-\kappa^g)\kappa_f}\right]$ and
$\frac{1-\kappa^g}{(1-\kappa^g)\kappa_f + p}$ for the two types of constraints
respectively. For pure monotone supermodular constrained maximization, these
yield $1-\kappa^g$ and $(1-\kappa^g)/p$ for the two types of constraints
respectively. We also analyze the hardness of BP maximization and show that our
guarantees match hardness by a constant factor and by $O(\ln(p))$ respectively.
Computational experiments are also provided supporting our analysis.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07414</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assertion-based QA with Question-Aware Open Information Extraction</dc:title>
 <dc:creator>Yan, Zhao</dc:creator>
 <dc:creator>Tang, Duyu</dc:creator>
 <dc:creator>Duan, Nan</dc:creator>
 <dc:creator>Liu, Shujie</dc:creator>
 <dc:creator>Wang, Wendi</dc:creator>
 <dc:creator>Jiang, Daxin</dc:creator>
 <dc:creator>Zhou, Ming</dc:creator>
 <dc:creator>Li, Zhoujun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present assertion based question answering (ABQA), an open domain question
answering task that takes a question and a passage as inputs, and outputs a
semi-structured assertion consisting of a subject, a predicate and a list of
arguments. An assertion conveys more evidences than a short answer span in
reading comprehension, and it is more concise than a tedious passage in
passage-based QA. These advantages make ABQA more suitable for human-computer
interaction scenarios such as voice-controlled speakers. Further progress
towards improving ABQA requires richer supervised dataset and powerful models
of text understanding. To remedy this, we introduce a new dataset called
WebAssertions, which includes hand-annotated QA labels for 358,427 assertions
in 55,960 web passages. To address ABQA, we develop both generative and
extractive approaches. The backbone of our generative approach is sequence to
sequence learning. In order to capture the structure of the output assertion,
we introduce a hierarchical decoder that first generates the structure of the
assertion and then generates the words of each field. The extractive approach
is based on learning to rank. Features at different levels of granularity are
designed to measure the semantic relevance between a question and an assertion.
Experimental results show that our approaches have the ability to infer
question-aware assertions from a passage. We further evaluate our approaches by
incorporating the ABQA results as additional features in passage-based QA.
Results on two datasets show that ABQA features significantly improve the
accuracy on passage-based~QA.
</dc:description>
 <dc:description>Comment: To be published at AAAI 2018</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07419</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimality of Simple Layered Superposition Coding in the 3 User MISO BC
  with Finite Precision CSIT</dc:title>
 <dc:creator>Davoodi, Arash Gholami</dc:creator>
 <dc:creator>Jafar, Syed Ali</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the $K=3$ user multiple input single output (MISO) broadcast channel
(BC) with $M=3$ antennas at the transmitter and $1$ antenna at each receiver,
from the generalized degrees of freedom (GDoF) perspective, under the
assumption that the channel state information at the transmitter (CSIT) is
limited to finite precision. In particular, our goal is to identify a parameter
regime where a simple layered superposition (SLS) coding scheme achieves the
entire GDoF region. With $\alpha_{ij}$ representing the channel strength
parameter for the link from the $j^{th}$ antenna of the transmitter to the
$i^{th}$ receiver, we prove that SLS is GDoF optimal without the need for
time-sharing if $\max(\alpha_{ki},\alpha_{im})\leq\alpha_{ii}$ and
$\alpha_{ki}+\alpha_{im}\le\alpha_{ii}+\alpha_{km}$ for all
$i,k\in[3],m\in[M]$. The GDoF region under this condition is a convex
polyhedron. The result generalizes to arbitrary $M\geq 3$.
</dc:description>
 <dc:description>Comment: 39 pages, 6 figures</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07423</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ultra-Reliable Short Message Cooperative Relaying Protocols under
  Nakagami-m Fading</dc:title>
 <dc:creator>Nouri, Parisa</dc:creator>
 <dc:creator>Alves, Hirley</dc:creator>
 <dc:creator>Souza, Richard Demo</dc:creator>
 <dc:creator>Latva-aho, Matti</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the next few years, the development of wireless communication systems
propel the world into a fully connected society where the Machine-type
Communications (MTC) plays a substantial role as key enabler in the future
cellular systems. MTC is categorized into mMTC and uMTC, where mMTC provides
the connectivity to massive number of devices while uMTC is related to low
latency and ultra-high reliability of the wireless communications. This paper
studies uMTC with incremental relaying technique, where the source and relay
collaborate to transfer the message to a destination. In this paper, we compare
the performance of two distinct cooperative relaying protocols with the direct
transmission under the finite blocklength (FB) regime. We define the overall
outage probability in each relaying scenario, supposing Nakagami-m fading. We
show that cooperative communication outperforms direct transmission under the
FB regime. In addition, we examine the impact of fading severity and power
allocation factor on the outage probability and the minimum delay required to
meet the ultra-reliable communication requirements. Moreover, we provide the
outage probability in closed form.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07423</dc:identifier>
 <dc:identifier>doi:10.1109/ISWCS.2017.8108126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07424</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Video Saliency: A Large-scale Benchmark and a New Model</dc:title>
 <dc:creator>Wang, Wenguan</dc:creator>
 <dc:creator>Shen, Jianbing</dc:creator>
 <dc:creator>Guo, Fang</dc:creator>
 <dc:creator>Cheng, Ming-Ming</dc:creator>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we contribute to video saliency research in two ways. First, we
introduce a new benchmark for predicting human eye movements during dynamic
scene free-viewing, which is long-time urged in this field. Our dataset, named
DHF1K (Dynamic Human Fixation), consists of 1K high-quality, elaborately
selected video sequences spanning a large range of scenes, viewpoints, motions,
object types and background complexity. Existing video saliency datasets lack
variety and generality of common dynamic scenes and fall short in covering
challenging situations in unconstrained environments. In contrast, DHF1K makes
a significant leap in terms of scalability, diversity and difficulty, and is
expected to boost video saliency modeling. Second, we propose a novel video
saliency model that augments the CNN-LSTM network architecture with an
attention mechanism to enable fast, end-to-end saliency learning. The attention
mechanism explicitly encodes static saliency information, thus allowing LSTM to
focus on learning more flexible temporal saliency representation across
successive frames. Such a design fully leverages existing large-scale static
fixation datasets, avoids overfitting, and significantly improves training
efficiency and testing performance. We thoroughly examine the performance of
our model, with respect to the state of the art saliency models, on three
large-scale datasets (i.e., DHF1K, Hollywood2, UCF sports). Experimental
results over more than 1.2K testing videos containing 400K frames demonstrate
that our model outperforms other competitors.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07426</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized two-dimensional linear discriminant analysis with
  regularization</dc:title>
 <dc:creator>Li, Chun-Na</dc:creator>
 <dc:creator>Shao, Yuan-Hai</dc:creator>
 <dc:creator>Chen, Wei-Jie</dc:creator>
 <dc:creator>Deng, Nai-Yang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent advances show that two-dimensional linear discriminant analysis
(2DLDA) is a successful matrix based dimensionality reduction method. However,
2DLDA may encounter the singularity issue theoretically and the sensitivity to
outliers. In this paper, a generalized Lp-norm 2DLDA framework with
regularization for an arbitrary $p&gt;0$ is proposed, named G2DLDA. There are
mainly two contributions of G2DLDA: one is G2DLDA model uses an arbitrary
Lp-norm to measure the between-class and within-class scatter, and hence a
proper $p$ can be selected to achieve the robustness. The other one is that by
introducing an extra regularization term, G2DLDA achieves better generalization
performance, and solves the singularity problem. In addition, G2DLDA can be
solved through a series of convex problems with equality constraint, and it has
closed solution for each single problem. Its convergence can be guaranteed
theoretically when $1\leq p\leq2$. Preliminary experimental results on three
contaminated human face databases show the effectiveness of the proposed
G2DLDA.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07430</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Edge Caching in NOMA Systems with QoS Requirements</dc:title>
 <dc:creator>Oviedo, Jose Armando</dc:creator>
 <dc:creator>Sadjadpour, Hamid R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A05, 62B10</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  Non-Orthogonal Multiple Access (NOMA) and caching are two proposed approaches
to increase the capacity of future 5G wireless systems. Typically in NOMA
systems, signals at the receiver are decoded using successive interference
cancellation in order to achieve capacity in multi-user systems. The leveraging
of caching in the physical layer to further improve on the benefits of NOMA is
investigated, which is termed cache-aided NOMA. Specific attention is given to
the caching cases where the users with weaker channel conditions possess a
cache of the information requested by a user with a stronger channel condition.
The probability that any of the users is in outage for any of the rates
required for this NOMA system, defined as the &quot;union-outage,&quot; is derived for
the case of fixed-power allocation, and the power allocation strategy that
minimizes the union-outage probability is derived. Simulation results confirm
the analytical results, which demonstrate the benefits of cache-aided NOMA on
reducing the union-outages probability.
</dc:description>
 <dc:description>Comment: Presented at IEEE Consumer Communications and Networking Conference
  (CCNC) 2018, Wireless Communications Fundamentals and PHY track, 5 pages, 3
  figures</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07438</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher-Order Equational Pattern Anti-Unification [Preprint]</dc:title>
 <dc:creator>Cerna, David M.</dc:creator>
 <dc:creator>Kutsia, Temur</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We consider anti-unification for simply typed lambda terms in associative,
commutative, and associative-commutative theories and develop a sound and
complete algorithm which takes two lambda terms and computes their
generalizations in the form of higher-order patterns. The problem is finitary:
the minimal complete set of generalizations contains finitely many elements. We
define the notion of optimal solution and investigate special fragments of the
problem for which the optimal solution can be computed in linear or polynomial
time.
</dc:description>
 <dc:description>Comment: Submitted to FSCD 2018</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07440</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Curiosity-driven reinforcement learning with homeostatic regulation</dc:title>
 <dc:creator>de Abril, Ildefons Magrans</dc:creator>
 <dc:creator>Kanai, Ryota</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a curiosity reward based on information theory principles and
consistent with the animal instinct to maintain certain critical parameters
within a bounded range. Our experimental validation shows the added value of
the additional homeostatic drive to enhance the overall information gain of a
reinforcement learning agent interacting with a complex environment using
continuous actions. Our method builds upon two ideas: i) To take advantage of a
new Bellman-like equation of information gain and ii) to simplify the
computation of the local rewards by avoiding the approximation of complex
distributions over continuous states and actions.
</dc:description>
 <dc:description>Comment: Presented at the NIPS 2017 Workshop: Cognitively Informed Artificial
  Intelligence: Insights From Natural Intelligence</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07446</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Double-Stage Delay Multiply and Sum Beamforming Algorithm: Application
  to Linear-Array Photoacoustic Imaging</dc:title>
 <dc:creator>Mozaffarzadeh, Moein</dc:creator>
 <dc:creator>Mahloojifar, Ali</dc:creator>
 <dc:creator>Orooji, Mahdi</dc:creator>
 <dc:creator>Adabi, Saba</dc:creator>
 <dc:creator>Nasiriavanaki, Mohammadreza</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Photoacoustic imaging (PAI) is an emerging medical imaging modality capable
of providing high spatial resolution of Ultrasound (US) imaging and high
contrast of optical imaging. Delay-and-Sum (DAS) is the most common beamforming
algorithm in PAI. However, using DAS beamformer leads to low resolution images
and considerable contribution of off-axis signals. A new paradigm namely
Delay-Multiply-and-Sum (DMAS), which was originally used as a reconstruction
algorithm in confocal microwave imaging, was introduced to overcome the
challenges in DAS. DMAS was used in PAI systems and it was shown that this
algorithm results in resolution improvement and sidelobe degrading. However,
DMAS is still sensitive to high levels of noise, and resolution improvement is
not satisfying. Here, we propose a novel algorithm based on DAS algebra inside
DMAS formula expansion, Double Stage DMAS (DS-DMAS), which improves the image
resolution and levels of sidelobe, and is much less sensitive to high level of
noise compared to DMAS. The performance of DS-DMAS algorithm is evaluated
numerically and experimentally. The resulted images are evaluated qualitatively
and quantitatively using established quality metrics including signal-to-noise
ratio (SNR), full-width-half-maximum (FWHM) and contrast ratio (CR). It is
shown that DS-DMAS outperforms DAS and DMAS at the expense of higher
computational load. DS-DMAS reduces the lateral valley for about 15 dB and
improves the SNR and FWHM better than 13% and 30%, respectively. Moreover, the
levels of sidelobe are reduced for about 10 dB in comparison with those in
DMAS.
</dc:description>
 <dc:description>Comment: This paper is accepted in &quot;IEEE Transaction on Biomedical
  Engineering&quot;</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07446</dc:identifier>
 <dc:identifier>IEEE Transaction on Biomedical Engineering, Volume: 65, Issue 1,
  Jan. 2018</dc:identifier>
 <dc:identifier>doi:10.1109/TBME.2017.2690959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07447</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Block arrivals in the Bitcoin blockchain</dc:title>
 <dc:creator>Bowden, R.</dc:creator>
 <dc:creator>Keeler, H. P.</dc:creator>
 <dc:creator>Krzesinski, A. E.</dc:creator>
 <dc:creator>Taylor, P. G.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Bitcoin is a electronic payment system where payment transactions are
verified and stored in a data structure called the blockchain. Bitcoin miners
work individually to solve a computationally intensive problem, and with each
solution a Bitcoin block is generated, resulting in a new arrival to the
blockchain. The difficulty of the computational problem is updated every 2,016
blocks in order to control the rate at which blocks are generated. In the
original Bitcoin paper, it was suggested that the blockchain arrivals occur
according to a homogeneous Poisson process. Based on blockchain block arrival
data and stochastic analysis of the block arrival process, we demonstrate that
this is not the case. We present a refined mathematical model for block
arrivals, focusing on both the block arrivals during a period of constant
difficulty and how the difficulty level evolves over time.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07449</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sliding Suffix Tree</dc:title>
 <dc:creator>Brodnik, Andrej</dc:creator>
 <dc:creator>Jekovec, Matev&#x17e;</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We consider a sliding window over a stream of characters from some finite
alphabet. The user wants to perform deterministic substring matching on the
current sliding window content and obtain positions of the matches. We present
an indexed version of the sliding window based on a suffix tree. The data
structure has optimal time queries $\Theta(m+occ)$ and amortized constant time
updates, where $m$ is the length of the query string and $occ$ the number of
occurrences.
</dc:description>
 <dc:description>Comment: to be submitted to CPM 2018</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07451</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Novel digital tissue phenotypic signatures of distant metastasis in
  colorectal cancer</dc:title>
 <dc:creator>Sirinukunwattana, Korsuk</dc:creator>
 <dc:creator>Snead, David</dc:creator>
 <dc:creator>Epstein, David</dc:creator>
 <dc:creator>Aftab, Zia</dc:creator>
 <dc:creator>Mujeeb, Imaad</dc:creator>
 <dc:creator>Tsang, Yee Wah</dc:creator>
 <dc:creator>Cree, Ian</dc:creator>
 <dc:creator>Rajpoot, Nasir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Quantitative Biology - Tissues and Organs</dc:subject>
 <dc:description>  Distant metastasis is the major cause of death in colorectal cancer (CRC).
Patients at high risk of developing distant metastasis could benefit from
appropriate adjuvant and follow-up treatments if stratified accurately at an
early stage of the disease. Studies have increasingly recognized the role of
diverse cellular components within the tumor microenvironment in the
development and progression of CRC tumors. In this paper, we show that a new
method of automated analysis of digitized images from colorectal cancer tissue
slides can provide important estimates of distant metastasis-free survival
(DMFS, the time before metastasis is first observed) on the basis of details of
the microenvironment. Specifically, we determine what cell types are found in
the vicinity of other cell types, and in what numbers, rather than
concentrating exclusively on the cancerous cells. We then extract novel tissue
phenotypic signatures using statistical measurements about tissue composition.
Such signatures can underpin clinical decisions about the advisability of
various types of adjuvant therapy.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07455</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action
  Recognition</dc:title>
 <dc:creator>Yan, Sijie</dc:creator>
 <dc:creator>Xiong, Yuanjun</dc:creator>
 <dc:creator>Lin, Dahua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dynamics of human body skeletons convey significant information for human
action recognition. Conventional approaches for modeling skeletons usually rely
on hand-crafted parts or traversal rules, thus resulting in limited expressive
power and difficulties of generalization. In this work, we propose a novel
model of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks
(ST-GCN), which moves beyond the limitations of previous methods by
automatically learning both the spatial and temporal patterns from data. This
formulation not only leads to greater expressive power but also stronger
generalization capability. On two large datasets, Kinetics and NTU-RGBD, it
achieves substantial improvements over mainstream methods.
</dc:description>
 <dc:description>Comment: Accepted by AAAI 2018</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07456</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heuristic algorithms for the Maximum Colorful Subtree problem</dc:title>
 <dc:creator>D&#xfc;hrkop, Kai</dc:creator>
 <dc:creator>Lataretu, Marie Anne</dc:creator>
 <dc:creator>White, W. Timothy J.</dc:creator>
 <dc:creator>B&#xf6;cker, Sebastian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In metabolomics, small molecules are structurally elucidated using tandem
mass spectrometry (MS/MS); this resulted in the computational Maximum Colorful
Subtree problem, which is NP-hard. Unfortunately, data from a single metabolite
requires us to solve hundreds or thousands of instances of this problem; and in
a single Liquid Chromatography MS/MS run, hundreds or thousands of metabolites
are measured.
  Here, we comprehensively evaluate the performance of several heuristic
algorithms for the problem against an exact algorithm. We put particular
emphasis on whether a heuristic is able to rank candidates such that the
correct solution is ranked highly. We propose this &quot;intermediate&quot; evaluation
because evaluating the approximating quality of heuristics is misleading: Even
a slightly suboptimal solution can be structurally very different from the true
solution. On the other hand, we cannot structurally evaluate against the ground
truth, as this is unknown. We find that particularly one of the heuristics
consistently ranks the correct solution in a favorable position. Integrating
the heuristic into the analysis pipeline results in a speedup of 10-fold or
more, without sacrificing accuracy.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07459</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stacked Filters Stationary Flow For Hardware-Oriented Acceleration Of
  Deep Convolutional Neural Networks</dc:title>
 <dc:creator>Gao, Yuechao</dc:creator>
 <dc:creator>Liu, Nianhong</dc:creator>
 <dc:creator>Zhang, Sheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To address memory and computation resource limitations for hardware-oriented
acceleration of deep convolutional neural networks (CNNs), we present a
computation flow, stacked filters stationary flow (SFS), and a corresponding
data encoding format, relative indexed compressed sparse filter format (CSF),
to make the best of data sparsity, and simplify data handling at execution
time. And we also propose a three dimensional Single Instruction Multiple Data
(3D-SIMD) processor architecture to take full advantage of these two features.
Comparing with the state-of-the-art result (Han et al., 2016b), our method
achieved 1.11x improvement in reducing the storage required by AlexNet, and
1.09x improvement in reducing the storage required by SqueezeNet, without loss
of accuracy on the ImageNet dataset. Moreover, using this approach, chip area
for logics handling irregular sparse data access can be saved.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07472</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient 3D Aerial Base Station Placement Considering Users Mobility by
  Reinforcement Learning</dc:title>
 <dc:creator>Ghanavi, Rozhina</dc:creator>
 <dc:creator>Kalantari, Elham</dc:creator>
 <dc:creator>Sabbaghian, Maryam</dc:creator>
 <dc:creator>Yanikomeroglu, Halim</dc:creator>
 <dc:creator>Yongacoglu, Abbas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper considers an aerial base station (aerial-BS) assisted terrestrial
network where user mobility is taken into account. User movement changes the
network dynamically which may result in performance loss. To avoid this loss,
guarantee a minimum quality of service (QoS) and possibly increase the QoS, we
add an aerial-BS to the network. For fair comparison between the conventional
terrestrial network and the aerial BS assisted one, we keep the total number of
BSs similar in both networks. Obtaining the max performance in such networks
highly depends on the optimal ultimate placement of the aerial-BS. To this end,
we need an algorithm which can rely on more general and realistic assumptions
and can decide where to go based on the past experiences. The proposed approach
for this goal is based on a discounted reward reinforcement learning which is
known as Q-learning. Simulation results show this method provides an effective
placement strategy which increases the QoS of wireless networks when it is
needed and promises to find the optimum position of the aerial-BS in discrete
environments.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, Accepted in IEEE Wireless Communications and
  Networking Conference (WCNC 2018)</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07478</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why and How to Avoid the Flipped Quaternion Multiplication</dc:title>
 <dc:creator>Sommer, Hannes</dc:creator>
 <dc:creator>Gilitschenski, Igor</dc:creator>
 <dc:creator>Bloesch, Michael</dc:creator>
 <dc:creator>Weiss, Stephan M.</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:creator>Nieto, Juan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Over the last decades quaternions have become a crucial and very successful
tool for attitude representation in robotics and aerospace. However, there is a
major problem that is continuously causing trouble in practice when it comes to
exchanging formulas or implementations: there are two quaternion
multiplications in common use, Hamilton's original multiplication and its
flipped version, which is often associated with NASA's Jet Propulsion
Laboratory. We believe that this particular issue is completely avoidable and
only exists today due to a lack of understanding. This paper explains the
underlying problem for the popular passive world to body usage of rotation
quaternions, and derives an alternative solution compatible with Hamilton's
multiplication. Furthermore, it argues for entirely discontinuing the flipped
multiplication. Additionally, it provides recipes for efficiently detecting
relevant conventions and migrating formulas or algorithms between them.
</dc:description>
 <dc:description>Comment: 18 pages, 1 figure, 2 tables</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07481</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Survey on Emotional Body Gesture Recognition</dc:title>
 <dc:creator>Noroozi, Fatemeh</dc:creator>
 <dc:creator>Corneanu, Ciprian Adrian</dc:creator>
 <dc:creator>Kami&#x144;ska, Dorota</dc:creator>
 <dc:creator>Sapi&#x144;ski, Tomasz</dc:creator>
 <dc:creator>Escalera, Sergio</dc:creator>
 <dc:creator>Anbarjafari, Gholamreza</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic emotion recognition has become a trending research topic in the
past decade. While works based on facial expressions or speech abound,
recognizing affect from body gestures remains a less explored topic. We present
a new comprehensive survey hoping to boost research in the field. We first
introduce emotional body gestures as a component of what is commonly known as
&quot;body language&quot; and comment general aspects as gender differences and culture
dependence. We then define a complete framework for automatic emotional body
gesture recognition. We introduce person detection and comment static and
dynamic body pose estimation methods both in RGB and 3D. We then comment the
recent literature related to representation learning and emotion recognition
from images of emotionally expressive gestures. We also discuss multi-modal
approaches that combine speech or face with body gestures for improved emotion
recognition. While pre-processing methodologies (e.g. human detection and pose
estimation) are nowadays mature technologies fully developed for robust large
scale analysis, we show that for emotion recognition the quantity of labelled
data is scarce, there is no agreement on clearly defined output spaces and the
representations are shallow and largely based on naive geometrical
representations.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07484</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Protograph-based Quasi-Cyclic MDPC Codes for McEliece Cryptosystems</dc:title>
 <dc:creator>Liva, Gianluigi</dc:creator>
 <dc:creator>Bartz, Hannes</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, ensembles of quasi-cyclic moderate-density parity-check (MDPC)
codes based on protographs are introduced and analyzed in the context of a
McEliece-like cryptosystem. The proposed ensembles significantly improve the
error correction capability of the regular MDPC code ensembles that are
currently considered for post-quantum cryptosystems without increasing the
public key size. The proposed ensembles are analyzed in the asymptotic setting
via density evolution, both under the sum-product algorithm and a
low-complexity (error-and-erasure) message passing algorithm. The asymptotic
analysis is complemented at finite block lengths by Monte Carlo simulations.
The enhanced error correction capability remarkably improves the scheme
robustness with respect to (known) decoding attacks.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07485</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Type-two polynomial-time and restricted lookahead</dc:title>
 <dc:creator>Kapron, Bruce M.</dc:creator>
 <dc:creator>Steinberg, Florian</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper provides an alternate characterization of type-two polynomial-time
computability, with the goal of making second-order complexity theory more
approachable. We rely on the usual oracle machines to model programs with
subroutine calls. In contrast to previous results, the use of higher-order
objects as running times is avoided, either explicitly or implicitly. Instead,
regular polynomials are used. This is achieved by refining the notion of
oracle-polynomial-time introduced by Cook. We impose a further restriction on
the oracle interactions to force feasibility. Both the restriction as well as
its purpose are very simple: it is well-known that Cook's model allows
polynomial depth iteration of functional inputs with no restrictions on size,
and thus does not guarantee that polynomial-time computability is preserved. To
mend this we restrict the number of lookahead revisions, that is the number of
times a query can be asked that is bigger than any of the previous queries. We
prove that this leads to a class of feasible functionals and that all feasible
problems can be solved within this class if one is allowed to separate a task
into efficiently solvable subtasks. Formally put: the closure of our class
under lambda-abstraction and application includes all feasible operations. We
also revisit the very similar class of strongly polynomial-time computable
operators previously introduced by Kawamura and Steinberg. We prove it to be
strictly included in our class and, somewhat surprisingly, to have the same
closure property. This can be attributed to properties of the limited recursion
operator: It is not strongly polynomial-time computable but decomposes into two
such operations and lies in our class.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07487</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Straggler Mitigation in Distributed Matrix Multiplication: Fundamental
  Limits and Optimal Coding</dc:title>
 <dc:creator>Yu, Qian</dc:creator>
 <dc:creator>Maddah-Ali, Mohammad Ali</dc:creator>
 <dc:creator>Avestimehr, A. Salman</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider the problem of massive matrix multiplication, which underlies
many data analytic applications, in a large-scale distributed system comprising
a group of worker nodes. We target the stragglers' delay performance
bottleneck, which is due to the unpredictable latency in waiting for slowest
nodes (or stragglers) to finish their tasks. We propose a novel coding
strategy, named \emph{entangled polynomial code}, for designing the
intermediate computations at the worker nodes in order to minimize the recovery
threshold (i.e., the number of workers that we need to wait for in order to
compute the final output). We demonstrate the optimality of entangled
polynomial code in several cases, and show that it provides orderwise
improvement over the conventional schemes for straggler mitigation.
Furthermore, using bilinear complexity, we characterize the optimal recovery
threshold among all linear coding strategies within a factor of $2$. In
particular, while evaluating bilinear complexity is a well-known challenging
problem, we show that optimal recovery threshold for linear coding strategies
can be approximated within a factor of $2$ of this fundamental quantity.
Finally, we show that the techniques developed in this paper can also be
extended to several other problems such as coded convolution and fault
tolerance computing, leading to tight characterizations.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07492</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistically Motivated Second Order Pooling</dc:title>
 <dc:creator>Yu, Kaicheng</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Second-order pooling, a.k.a. bilinear pooling, has proven effective for
visual recognition. The recent progress in this area has focused on either
designing normalization techniques for second-order models, or compressing the
second-order representations. However, these two directions have typically been
followed separately, and without any clear statistical motivation. Here, by
contrast, we introduce a statistically-motivated framework that jointly tackles
normalization and compression of second-order representations. To this end, we
design a parametric vectorization layer, which maps a covariance matrix, known
to follow a Wishart distribution, to a vector whose elements can be shown to
follow a Chi-square distribution. We then propose to make use of a square-root
normalization, which makes the distribution of the resulting representation
converge to a Gaussian, thus complying with the standard machine learning
assumption. As evidenced by our experiments, this lets us outperform the
state-of-the-art second-order models on several benchmark recognition datasets.
</dc:description>
 <dc:description>Comment: 8 page, 4 figures, 3 tables</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07495</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cyber Hate Classification: 'Othering' Language And Paragraph Embedding</dc:title>
 <dc:creator>Alorainy, Wafa</dc:creator>
 <dc:creator>Burnap, Pete</dc:creator>
 <dc:creator>Liu, Han</dc:creator>
 <dc:creator>Williams, Matthew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Hateful and offensive language (also known as hate speech or cyber hate)
posted and widely circulated via the World Wide Web can be considered as a key
risk factor for individual and societal tension linked to regional instability.
Automated Web-based hate speech detection is important for the observation and
understanding trends of societal tension. In this research, we improve on
existing research by proposing different data mining feature extraction
methods. While previous work has involved using lexicons, bags-of-words or
probabilistic parsing approach (e.g. using Typed Dependencies), they all suffer
from a similar issue which is that hate speech can often be subtle and
indirect, and depending on individual words or phrases can lead to a
significant number of false negatives. This problem motivated us to conduct new
experiments to identify subtle language use, such as references to immigration
or job prosperity in a hateful context. We propose a novel 'Othering Lexicon'
to identify these subtleties and we incorporate our lexicon with embedding
learning for feature extraction and subsequent classification using a neural
network approach. Our method first explores the context around othering terms
in a corpus, and identifies context patterns that are relevant to the othering
context. These patterns are used along with the othering pronoun and hate
speech terms to build our 'Othering Lexicon'. Embedding algorithm has the
superior characteristic that the similar words have a closer distance, which is
helpful to train our classifier on the negative and positive classes. For
validation, several experiments were conducted on different types of hate
speech, namely religion, disability, race and sexual orientation, with
F-measure scores for classifying hateful instances obtained through applying
our model of 0.93, 0.95, 0.97 and 0.92 respective.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07501</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When A Small Leak Sinks A Great Ship: Deanonymizing Tor Hidden Service
  Users Through Bitcoin Transactions Analysis</dc:title>
 <dc:creator>Jawaheri, Husam Al</dc:creator>
 <dc:creator>Sabah, Mashael Al</dc:creator>
 <dc:creator>Boshmaf, Yazan</dc:creator>
 <dc:creator>Erbad, Aimen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the rapid increase of threats on the Internet, people are continuously
seeking privacy and anonymity. Services such as Bitcoin and Tor were introduced
to provide anonymity for online transactions and Web browsing. Due to its
pseudonymity model, Bitcoin lacks retroactive operational security, which means
historical pieces of information could be used to identify a certain user. We
investigate the feasibility of deanonymizing users of Tor hidden services who
rely on Bitcoin as a payment method by exploiting public information leaked
from online social networks, the Blockchain, and onion websites. This, for
example, allows an adversary to link a user with @alice Twitter address to a
Tor hidden service with private.onion address by finding at least one past
transaction in the Blockchain that involves their publicly declared Bitcoin
addresses.
  To demonstrate the feasibility of this deanonymization attack, we carried out
a real-world experiment simulating a passive, limited adversary. We crawled
1.5K hidden services and collected 88 unique Bitcoin addresses. We then crawled
5B tweets and 1M BitcoinTalk forum pages and collected 4.2K and 41K unique
Bitcoin addresses, respectively. Each user address was associated with an
online identity along with its public profile information. By analyzing the
transactions in the Blockchain, we were able to link 125 unique users to 20 Tor
hidden services, including sensitive ones, such as The Pirate Bay and Silk
Road. We also analyzed two case studies in detail to demonstrate the
implications of the resulting information leakage on user anonymity. In
particular, we confirm that Bitcoin addresses should always be considered
exploitable, as they can be used to deanonymize users retroactively. This is
especially important for Tor hidden service users who actively seek and expect
privacy and anonymity.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07507</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What did you Mention? A Large Scale Mention Detection Benchmark for
  Spoken and Written Text</dc:title>
 <dc:creator>Mass, Yosi</dc:creator>
 <dc:creator>Kotlerman, Lili</dc:creator>
 <dc:creator>Mirkin, Shachar</dc:creator>
 <dc:creator>Venezian, Elad</dc:creator>
 <dc:creator>Witzling, Gera</dc:creator>
 <dc:creator>Slonim, Noam</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We describe a large, high-quality benchmark for the evaluation of Mention
Detection tools. The benchmark contains annotations of both named entities as
well as other types of entities, annotated on different types of text, ranging
from clean text taken from Wikipedia, to noisy spoken data. The benchmark was
built through a highly controlled crowd sourcing process to ensure its quality.
We describe the benchmark, the process and the guidelines that were used to
build it. We then demonstrate the results of a state-of-the-art system running
on that benchmark.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07513</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>System-Level Modeling and Optimization of the Energy Efficiency in
  Cellular Networks -- A Stochastic Geometry Framework</dc:title>
 <dc:creator>Di Renzo, Marco</dc:creator>
 <dc:creator>Zappone, Alessio</dc:creator>
 <dc:creator>Lam, Thanh Tu</dc:creator>
 <dc:creator>Debbah, Merouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we analyze and optimize the energy efficiency of downlink
cellular networks. With the aid of tools from stochastic geometry, we introduce
a new closed-form analytical expression of the potential spectral efficiency
(bit/sec/m$^2$). In the interference-limited regime for data transmission,
unlike currently available mathematical frameworks, the proposed analytical
formulation depends on the transmit power and deployment density of the base
stations. This is obtained by generalizing the definition of coverage
probability and by accounting for the sensitivity of the receiver not only
during the decoding of information data, but during the cell association phase
as well. Based on the new formulation of the potential spectral efficiency, the
energy efficiency (bit/Joule) is given in a tractable closed-form formula. An
optimization problem is formulated and is comprehensively studied. It is
mathematically proved, in particular, that the energy efficiency is a unimodal
and strictly pseudo-concave function in the transmit power, given the density
of the base stations, and in the density of the base stations, given the
transmit power. Under these assumptions, therefore, a unique transmit power and
density of the base stations exist, which maximize the energy efficiency.
Numerical results are illustrated in order to confirm the obtained findings and
to prove the usefulness of the proposed framework for optimizing the network
planning and deployment of cellular networks from the energy efficiency
standpoint.
</dc:description>
 <dc:description>Comment: To appear in IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07518</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Understanding Connections between Security/Privacy Attitudes and
  Unlock Authentication</dc:title>
 <dc:creator>Aviv, Adam J.</dc:creator>
 <dc:creator>Kuber, Ravi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this study, we examine the ways in which user attitudes towards privacy
and security relating to mobile devices and the data stored thereon may impact
the strength of unlock authentication, focusing on Android's graphical unlock
patterns. We conducted an online study with Amazon Mechanical Turk ($N=750$)
using self-reported unlock authentication choices, as well as Likert scale
agreement/disagreement responses to a set of seven privacy/security prompts. We
then analyzed the responses in multiple dimensions, including a straight
average of the Likert responses as well as using Principle Component Analysis
to expose latent factors. We found that responses to two of the seven questions
proved relevant and significant. These two questions considered attitudes
towards general concern for data stored on mobile devices, and attitudes
towards concerns for unauthorized access by {\em known} actors. Unfortunately,
larger conclusions cannot be drawn on the efficacy of the broader set of
questions for exposing connections between unlock authentication strength
(Pearson Rank $r=-0.08$, $p&lt;0.1$). However, both of our factor solutions
exposed differences in responses for demographics groups, including age,
gender, and residence type. The findings of this study suggests that there is
likely a link between perceptions of privacy/security on mobile devices and the
perceived threats therein, but more research is needed, particularly on
developing better survey and measurement techniques of privacy/security
attitudes that relate to mobile devices specifically.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07528</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer-Assisted Proving of Combinatorial Conjectures Over Finite
  Domains: A Case Study of a Chess Conjecture</dc:title>
 <dc:creator>Jani&#x10d;i&#x107;, Predrag</dc:creator>
 <dc:creator>Mari&#x107;, Filip</dc:creator>
 <dc:creator>Malikovi&#x107;, Marko</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B35, 68T15</dc:subject>
 <dc:description>  There are several approaches for using computers in deriving mathematical
proofs. For their illustration, we provide an in-depth study of using computer
support for proving one complex combinatorial conjecture -- correctness of a
strategy for the chess KRK endgame. The final, machine verifiable, result
presented in this paper is that there is a winning strategy for white in the
KRK endgame generalized to $n \times n$ board (for natural $n$ greater than
$3$). We demonstrate that different approaches for computer-based theorem
proving work best together and in synergy and that the technology currently
available is powerful enough for providing significant help to humans deriving
complex proofs.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07537</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Language Learned by an Active Question Answering Agent</dc:title>
 <dc:creator>Buck, Christian</dc:creator>
 <dc:creator>Bulian, Jannis</dc:creator>
 <dc:creator>Ciaramita, Massimiliano</dc:creator>
 <dc:creator>Gajewski, Wojciech</dc:creator>
 <dc:creator>Gesmundo, Andrea</dc:creator>
 <dc:creator>Houlsby, Neil</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We analyze the language learned by an agent trained with reinforcement
learning as a component of the ActiveQA system [Buck et al., 2017]. In
ActiveQA, question answering is framed as a reinforcement learning task in
which an agent sits between the user and a black box question-answering system.
The agent learns to reformulate the user's questions to elicit the optimal
answers. It probes the system with many versions of a question that are
generated via a sequence-to-sequence question reformulation model, then
aggregates the returned evidence to find the best answer. This process is an
instance of \emph{machine-machine} communication. The question reformulation
model must adapt its language to increase the quality of the answers returned,
matching the language of the question answering system. We find that the agent
does not learn transformations that align with semantic intuitions but
discovers through learning classical information retrieval techniques such as
tf-idf re-weighting and stemming.
</dc:description>
 <dc:description>Comment: Emergent Communication Workshop, NIPS 2017</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07541</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Pseudo-Polynomial-Time Approximation for Strip Packing</dc:title>
 <dc:creator>G&#xe1;lvez, Waldo</dc:creator>
 <dc:creator>Grandoni, Fabrizio</dc:creator>
 <dc:creator>Ingala, Salvatore</dc:creator>
 <dc:creator>Khan, Arindam</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We study the strip packing problem, a classical packing problem which
generalizes both bin packing and makespan minimization. Here we are given a set
of axis-parallel rectangles in the two-dimensional plane and the goal is to
pack them in a vertical strip of a fixed width such that the height of the
obtained packing is minimized. The packing must be non-overlapping and the
rectangles cannot be rotated. A reduction from the partition problem shows that
no approximation better than 3/2 is possible for strip packing in polynomial
time (assuming P$\neq$NP). Nadiradze and Wiese [SODA16] overcame this barrier
by presenting a $(\frac{7}{5}+\epsilon)$-approximation algorithm in
pseudo-polynomial-time (PPT). As the problem is strongly NP-hard, it does not
admit an exact PPT algorithm. In this paper, we make further progress on the
PPT approximability of strip packing, by presenting a
$(\frac43+\epsilon)$-approximation algorithm. Our result is based on a
non-trivial repacking of some rectangles in the \emph{empty space} left by the
construction by Nadiradze and Wiese, and in some sense pushes their approach to
its limit. Our PPT algorithm can be adapted to the case where we are allowed to
rotate the rectangles by $90^\circ$, achieving the same approximation factor
and breaking the polynomial-time approximation barrier of 3/2 for the case with
rotations as well.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07544</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Primal-Dual Algorithm for Fair Combinatorial Optimization
  Problems</dc:title>
 <dc:creator>Nguyen, Viet Hung</dc:creator>
 <dc:creator>Weng, Paul</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We consider a general class of combinatorial optimization problems including
among others allocation, multiple knapsack, matching or travelling salesman
problems. The standard version of those problems is the maximum weight
optimization problem where a sum of values is optimized. However, the sum is
not a good aggregation function when the fairness of the distribution of those
values (corresponding for example to different agents' utilities or criteria)
is important. In this paper, using the generalized Gini index (GGI), a
well-known inequality measure, instead of the sum to model fairness, we
formulate a new general problem, that we call fair combinatorial optimization.
Although GGI is a non-linear aggregating function, a $0,1$-linear program (IP)
can be formulated for finding a GGI-optimal solution by exploiting a
linearization of GGI proposed by Ogryczak and Sliwinski. However, the time
spent by commercial solvers (e.g., CPLEX, Gurobi...) for solving (IP) increases
very quickly with instances' size and can reach hours even for relatively
small-sized ones. As a faster alternative, we propose a heuristic for solving
(IP) based on a primal-dual approach using Lagrangian decomposition. %We
experimentally evaluate our methods against the exact solution of (IP) by CPLEX
on several fair optimization problems related to matching to demonstrate the
efficiency of our proposition. We demonstrate the efficiency of our method by
evaluating it against the exact solution of (IP) by CPLEX on several fair
optimization problems related to matching. The numerical results show that our
method outputs in a very short time efficient solutions giving lower bounds
that CPLEX may take several orders of magnitude longer to obtain. Moreover, for
instances for which we know the optimal value, these solutions are
quasi-optimal with optimality gap less than 0.3%.
</dc:description>
 <dc:description>Comment: accepted at COCOA 2017</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07546</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyper-heuristics Can Achieve Optimal Performance for Pseudo-Boolean
  Optimisation</dc:title>
 <dc:creator>Lissovoi, Andrei</dc:creator>
 <dc:creator>Oliveto, Pietro S.</dc:creator>
 <dc:creator>Warwicker, John Alasdair</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Selection hyper-heuristics are randomised search methodologies which choose
and execute heuristics from a set of low-level heuristics. Recent research for
the LeadingOnes benchmark function has shown that the standard Simple Random,
Permutation, Random Gradient, Greedy and Reinforcement Learning selection
mechanisms show no effects of learning. The idea behind the learning mechanisms
is to continue to exploit the currently selected heuristic as long as it is
successful. However, the probability that a promising heuristic is successful
in the next step is relatively low when perturbing a reasonable solution to a
combinatorial optimisation problem. In this paper we generalise the `simple'
selection-perturbation mechanisms so success can be measured over some fixed
period of time tau, rather than in a single iteration. We present a benchmark
function where it is necessary to learn to exploit a particular low-level
heuristic, rigorously proving that it makes the difference between an efficient
and an inefficient algorithm. For LeadingOnes we prove that the Generalised
Random Gradient, and the Generalised Greedy Gradient hyper-heuristics achieve
optimal performance, while Generalised Greedy, although not as fast, still
outperforms Random Local Search. The performance of the former two
hyper-heuristics improves as the number of operators to choose from increases,
while that of the Generalised Greedy hyper-heuristic does not. Experimental
analyses confirm these results for realistic problem sizes and shed some light
on the best choices of the parameter tau in various situations.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07548</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A hybrid architecture for astronomical computing</dc:title>
 <dc:creator>Li, Changhua</dc:creator>
 <dc:creator>Cui, Chenzhou</dc:creator>
 <dc:creator>He, Boliang</dc:creator>
 <dc:creator>Fan, Dongwei</dc:creator>
 <dc:creator>Mi, Linying</dc:creator>
 <dc:creator>Li, Shanshan</dc:creator>
 <dc:creator>Yang, Sisi</dc:creator>
 <dc:creator>Xu, Yunfei</dc:creator>
 <dc:creator>Han, Jun</dc:creator>
 <dc:creator>Chen, Junyi</dc:creator>
 <dc:creator>Zhang, Hailong</dc:creator>
 <dc:creator>Yu, Ce</dc:creator>
 <dc:creator>Xiao, Jian</dc:creator>
 <dc:creator>Wang, Chuanjun</dc:creator>
 <dc:creator>Cao, Zihuang</dc:creator>
 <dc:creator>Fan, Yufeng</dc:creator>
 <dc:creator>Liu, Liang</dc:creator>
 <dc:creator>Chen, Xiao</dc:creator>
 <dc:creator>Song, Wenming</dc:creator>
 <dc:creator>Du, Kangyu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:description>  With many large science equipment constructing and putting into use,
astronomy has stepped into the big data era. The new method and infrastructure
of big data processing has become a new requirement of many astronomers. Cloud
computing, Map/Reduce, Hadoop, Spark, etc. many new technology has sprung up in
recent years. Comparing to the high performance computing(HPC), Data is the
center of these new technology. So, a new computing architecture infrastructure
is necessary, which can be shared by both HPC and big data processing. Based on
Astronomy Cloud project of Chinese Virtual Observatory (China-VO), we have made
much efforts to optimize the designation of the hybrid computing platform.
which include the hardware architecture, cluster management, Job and Resource
scheduling.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, ADASS XXVI conference</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07549</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Metastability-Containing Sorting Networks</dc:title>
 <dc:creator>Bund, Johannes</dc:creator>
 <dc:creator>Lenzen, Christoph</dc:creator>
 <dc:creator>Medina, Moti</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  When setup/hold times of bistable elements are violated, they may become
metastable, i.e., enter a transient state that is neither digital 0 nor 1. In
general, metastability cannot be avoided, a problem that manifests whenever
taking discrete measurements of analog values. Metastability of the output then
reflects uncertainty as to whether a measurement should be rounded up or down
to the next possible measurement outcome.
  Surprisingly, Lenzen and Medina (ASYNC 2016) showed that metastability can be
contained, i.e., measurement values can be correctly sorted without resolving
metastability first. However, both their work and the state of the art by Bund
et al. (DATE 2017) leave open whether such a solution can be as small and fast
as standard sorting networks. We show that this is indeed possible, by
providing a circuit that sorts Gray code inputs (possibly containing a
metastable bit) and has asymptotically optimal depth and size. Concretely, for
10-channel sorting networks and 16-bit wide inputs, we improve by 48.46% in
delay and by 71.58% in area over Bund et al. Our simulations indicate that
straightforward transistor-level optimization is likely to result in
performance on par with standard (non-containing) solutions.
</dc:description>
 <dc:description>Comment: The paper will be published during DATE 2018</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07551</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy sustainable paradigms and methods for future mobile networks: A
  survey</dc:title>
 <dc:creator>Piovesan, Nicola</dc:creator>
 <dc:creator>Gambin, Angel Fernandez</dc:creator>
 <dc:creator>Miozzo, Marco</dc:creator>
 <dc:creator>Rossi, Michele</dc:creator>
 <dc:creator>Dini, Paolo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this survey, we discuss the role of energy in the design of future mobile
networks and, in particular, we advocate and elaborate on the use of energy
harvesting (EH) hardware as a means to decrease the environmental footprint of
5G technology. To take full advantage of the harvested (renewable) energy,
while still meeting the quality of service required by dense 5G deployments,
suitable management techniques are here reviewed, highlighting the open issues
that are still to be solved to provide eco-friendly and cost-effective mobile
architectures. Several solutions have recently been proposed to tackle
capacity, coverage and efficiency problems, including: C-RAN, Software Defined
Networking (SDN) and fog computing, among others. However, these are not
explicitly tailored to increase the energy efficiency of networks featuring
renewable energy sources, and have the following limitations: (i) their energy
savings are in many cases still insufficient and (ii) they do not consider
network elements possessing energy harvesting capabilities. In this paper, we
systematically review existing energy sustainable paradigms and methods to
address points (i) and (ii), discussing how these can be exploited to obtain
highly efficient, energy self-sufficient and high capacity networks. Several
open issues have emerged from our review, ranging from the need for accurate
energy, transmission and consumption models, to the lack of accurate data
traffic profiles, to the use of power transfer, energy cooperation and energy
trading techniques. These challenges are here discussed along with some
research directions to follow for achieving sustainable 5G systems.
</dc:description>
 <dc:description>Comment: Accepted by Elsevier Computer Communications, 21 pages, 9 figures</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07551</dc:identifier>
 <dc:identifier>doi:10.1016/j.comcom.2018.01.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07553</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable gonality is computable</dc:title>
 <dc:creator>Koerkamp, Ragnar Groot</dc:creator>
 <dc:creator>van der Wegen, Marieke</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  Stable gonality is a multigraph parameter that measures the complexity of a
graph. It is defined using maps to trees. Those maps, in some sense, divide the
edges equally over the edges of the tree; stable gonality asks for the map with
the minimum number of edges mapped to each edge of the tree. This parameter is
related to treewidth, but unlike treewidth, it distinguishes multigraphs from
their underlying simple graphs. Stable gonality is relevant for problems in
number theory. In this paper, we show that deciding whether the stable gonality
of a given graph is at most a given integer $k$ belongs to the class NP, and we
give an algorithm that computes the stable gonality of a graph in
$O((1.33n)^nm^m \text{poly}(n,m))$ time.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07555</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shake-n-Shack: Enabling Secure Data Exchange Between Smart Wearables via
  Handshakes</dc:title>
 <dc:creator>Shen, Yiran</dc:creator>
 <dc:creator>Yang, Fengyuan</dc:creator>
 <dc:creator>Du, Bowen</dc:creator>
 <dc:creator>Xu, Weitao</dc:creator>
 <dc:creator>Luo, Chengwen</dc:creator>
 <dc:creator>Wen, Hongkai</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Since ancient Greece, handshaking has been commonly practiced between two
people as a friendly gesture to express trust and respect, or form a mutual
agreement. In this paper, we show that such physical contact can be used to
bootstrap secure cyber contact between the smart devices worn by users. The key
observation is that during handshaking, although belonged to two different
users, the two hands involved in the shaking events are often rigidly
connected, and therefore exhibit very similar motion patterns. We propose a
novel Shake-n-Shack system, which harvests motion data during user handshaking
from the wrist worn smart devices such as smartwatches or fitness bands, and
exploits the matching motion patterns to generate symmetric keys on both
parties. The generated keys can be then used to establish a secure
communication channel for exchanging data between devices. This provides a much
more natural and user-friendly alternative for many applications, e.g.
exchanging/sharing contact details, friending on social networks, or even
making payments, since it doesn't involve extra bespoke hardware, nor require
the users to perform pre-defined gestures. We implement the proposed
Shake-n-Shack system on off-the-shelf smartwatches, and extensive evaluation
shows that it can reliably generate 128-bit symmetric keys just after around 1s
of handshaking (with success rate &gt;99%), and is resilient to real-time
mimicking attacks: in our experiments the Equal Error Rate (EER) is only 1.6%
on average. We also show that the proposed Shake-n-Shack system can be
extremely lightweight, and is able to run in-situ on the resource-constrained
smartwatches without incurring excessive resource consumption.
</dc:description>
 <dc:description>Comment: To appear in PerCom'18</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07560</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Efficiency Optimization For Millimeter Wave Multi-User MIMO
  Systems</dc:title>
 <dc:creator>Shi, Qingjiang</dc:creator>
 <dc:creator>Hong, Mingyi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  As a key enabling technology for 5G wireless, millimeter wave (mmWave)
communication motivates the utilization of large-scale antenna arrays for
achieving highly directional beamforming. However, the high cost and power
consumption of RF chains stands in the way of adoption of the optimal
fullydigital precoding in large-array systems. To reduce the number of RF
chains while still maintaining the spatial multiplexing gain of large-array,
hybrid precoding architecture has been proposed for mmWave systems and received
considerable interest in both industry and academia. However, the optimal
hybrid precoding design has not been fully understood, especially for the
multi-user MIMO case. This paper is the first work that directly addresses the
nonconvex hybrid precoding problem of mmWave multi-user MIMO systems (without
any approximation) by using penalty dual decomposition (PDD) method. The
proposed PDD method have a guaranteed convergence to KKT solutions of the
hybrid precoding problem under a mild assumption. Simulation results show that,
even when both the transmitter and the receivers are equipped with the fewest
RF chains that are required to support multi-stream transmission, hybrid
precoding can still approach the performance of fully-digital precoding in both
the infinite resolution phase shifter case and the finite resolution phase
shifter case with several bits quantization.
</dc:description>
 <dc:description>Comment: The first draft of this paper was finished when I was at Iowa in 2016</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07561</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-layer Recursive Residue Number System</dc:title>
 <dc:creator>Hollmann, Henk D. L.</dc:creator>
 <dc:creator>Rietman, Ronald</dc:creator>
 <dc:creator>de Hoogh, Sebastiaan</dc:creator>
 <dc:creator>Tolhuizen, Ludo M. G. M.</dc:creator>
 <dc:creator>Gorissen, Paul</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  We present a method to increase the dynamical range of a Residue Number
System (RNS) by adding virtual RNS layers on top of the original RNS, where the
required modular arithmetic for a modulus on any non-bottom layer is
implemented by means of an RNS Montgomery multiplication algorithm that uses
the RNS on the layer below. As a result, the actual arithmetic is deferred to
the bottom layer. The multiplication algorithm that we use is based on an
algorithm by Bajard and Imbert, extended to work with pseudo-residues
(remainders with a larger range than the modulus). The resulting Recursive
Residue Number System (RRNS) can be used to implement modular addition,
multiplication, and multiply-and-accumulate for very large (2000+ bits) moduli,
using only modular operations for small (for example 8-bits) moduli. A hardware
implementation of this method allows for massive parallelization.
  Our method can be applied in cryptographic algorithms such as RSA to realize
modular exponentiation with a large (2048-bit, or even 4096-bit) modulus. Due
to the use of full RNS Montgomery algorithms, the system does not involve any
carries, therefore cryptographic attacks that exploit carries cannot be
applied.
</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07562</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-Interference Tradeoff in OFDM-based Cognitive Radio Networks</dc:title>
 <dc:creator>Bedeer, Ebrahim</dc:creator>
 <dc:creator>Dobre, Octavia A.</dc:creator>
 <dc:creator>Ahmed, Mohamed H.</dc:creator>
 <dc:creator>Baddour, Kareem E.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In cognitive radio (CR) networks, secondary users (SUs) are allowed to
opportunistically access the primary users (PUs) spectrum to improve the
spectrum utilization; however, this increases the interference levels at the
PUs. In this paper, we consider an orthogonal frequency division multiplexing
OFDM-based CR network and investigate the tradeoff between increasing the SU
transmission rate (hence improving the spectrum utilization) and reducing the
interference levels at the PUs. We formulate a new multiobjective optimization
(MOOP) problem that jointly maximizes the SU transmission rate and minimizes
its transmit power, while imposing interference thresholds to the PUs. Further,
we propose an algorithm to strike a balance between the SU transmission rate
and the interference levels to the PUs. The proposed algorithm considers the
practical scenario of knowing partial channel state information (CSI) of the
links between the SU transmitter and the PUs receivers. Simulation results
illustrate the performance of the proposed algorithm and its superiority when
compared to the work in the literature.
</dc:description>
 <dc:description>Comment: GC</dc:description>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07564</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On $\mathcal{L}_{\infty}$ string stability of asymmetrically coupled
  bidirectional heterogeneous platoon systems</dc:title>
 <dc:creator>Monteil, Julien</dc:creator>
 <dc:creator>Russo, Giovanni</dc:creator>
 <dc:creator>Shorten, Robert</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper is concerned with the study of bidirectionally coupled platoon
systems. The case considered is when the vehicles are heterogeneous and the
coupling can be asymmetric and nonlinear. For such systems, a sufficient
condition for $\mathcal{L}_{\infty}$ string stability is presented. The
effectiveness of our approach is illustrated via a numerical example, where it
is shown how our result can be recast as an optimization problem, leading to a
bottom-up approach for the design of string stable platoon systems.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07579</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Work Zone Simulation Model for Travel Time Prediction in a Connected
  Vehicle Environment</dc:title>
 <dc:creator>Wen, Xuejin</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A work zone bottleneck in a roadway network can cause traffic delays,
emissions and safety issues. Accurate measurement and prediction of work zone
travel time can help travelers make better routing decisions and therefore
mitigate its impact. Historically, data used for travel time analyses comes
from fixed loop detectors, which are expensive to install and maintain. With
connected vehicle technology, such as Vehicle-to-Infrastructure, portable
roadside unit (RSU) can be located in and around a work zone segment to
communicate with the vehicles and collect traffic data. A PARAMICS simulation
model for a prototypical freeway work zone in a connected vehicle environment
was built to test this idea using traffic demand data from NY State Route 104.
For the simulation, twelve RSUs were placed along the work zone segment and
sixteen variables were extracted from the simulation results to explore travel
time estimation and prediction. For the travel time analysis, four types of
models were constructed, including linear regression, multivariate adaptive
regression splines (MARS), stepwise regression and elastic net. The results
show that the modeling approaches under consideration have similar performance
in terms of the Root of Mean Square Error (RMSE), which provides an opportunity
for model selection based on additional factors including the number and
locations of the RSUs according to the significant variables identified in the
various models. Among the four approaches, the stepwise regression model only
needs variables from two RSUs: one placed sufficiently upstream of the work
zone and one at the end of the work zone.
</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07580</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Side Information for Face Completion: a Robust PCA Approach</dc:title>
 <dc:creator>Xue, Niannan</dc:creator>
 <dc:creator>Deng, Jiankang</dc:creator>
 <dc:creator>Cheng, Shiyang</dc:creator>
 <dc:creator>Panagakis, Yannis</dc:creator>
 <dc:creator>Zafeiriou, Stefanos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Robust principal component analysis (RPCA) is a powerful method for learning
low-rank feature representation of various visual data. However, for certain
types as well as significant amount of error corruption, it fails to yield
satisfactory results; a drawback that can be alleviated by exploiting
domain-dependent prior knowledge or information. In this paper, we propose two
models for the RPCA that take into account such side information, even in the
presence of missing values. We apply this framework to the task of UV
completion which is widely used in pose-invariant face recognition. Moreover,
we construct a generative adversarial network (GAN) to extract side information
as well as subspaces. These subspaces not only assist in the recovery but also
speed up the process in case of large-scale data. We quantitatively and
qualitatively evaluate the proposed approaches through both synthetic data and
five real-world datasets to verify their effectiveness.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1702.00648</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07583</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Agent-Based Simulation Model for Optimization of the Signalized
  Intersection Connected to Freeway On-Ramp</dc:title>
 <dc:creator>Wen, Xuejin</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Unlike most existing studies on off-ramp traffic signal control, this paper
focuses on the optimization problem of the signalized intersection connected to
freeway on-ramps. Conflicts are often observed between the traffic heading to
an on-ramp and the traffic continuing straight which leads to issues such as
intersection overflow, increased delay, and concerns about safety. For studying
this problem, a real-world signalized intersection in Buffalo, New York was
chosen, which has two through lanes and one short shared (through and
right-turn) lane. At the downstream of the intersection are two following
on-ramps, one to the highway I-290 West and the other to I-290 East. During
peak hours, the shared lane often observes a long queue, which furthermore
blocks the through traffic on the parallel lane. To solve this problem, a
VISSIM agent-based simulation model was built and calibrated based on field
observations. Three potential optimization solutions were proposed and tested
with the help of VISSIM: (1) increasing the length of the short shared through
and right-turn lane; (2) making the short shared through and right-turn lane
right-turn only, and (3) adding a new diverge lane for the right-turn vehicles.
According to the simulation results, solution (3) performs the best, resulting
in the least vehicle delay time.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07587</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Low-Latency and Ultra-Reliable Virtual Reality</dc:title>
 <dc:creator>Elbamby, Mohammed S.</dc:creator>
 <dc:creator>Perfecto, Cristina</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Doppler, Klaus</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Virtual Reality (VR) is expected to be one of the killer-applications in 5G
networks. However, many technical bottlenecks and challenges need to be
overcome to facilitate its wide adoption. In particular, VR requirements in
terms of high-throughput, low-latency and reliable communication call for
innovative solutions and fundamental research cutting across several
disciplines. In view of this, this article discusses the challenges and
enablers for ultra-reliable and low-latency VR. Furthermore, in an interactive
VR gaming arcade case study, we show that a smart network design that leverages
the use of mmWave communication, edge computing and proactive caching can
achieve the future vision of VR over wireless.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Network. 8 pages, 5 figures</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07593</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mitigating Unwanted Biases with Adversarial Learning</dc:title>
 <dc:creator>Zhang, Brian Hu</dc:creator>
 <dc:creator>Lemoine, Blake</dc:creator>
 <dc:creator>Mitchell, Margaret</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Machine learning is a tool for building models that accurately represent
input training data. When undesired biases concerning demographic groups are in
the training data, well-trained models will reflect those biases. We present a
framework for mitigating such biases by including a variable for the group of
interest and simultaneously learning a predictor and an adversary. The input to
the network X, here text or census data, produces a prediction Y, such as an
analogy completion or income bracket, while the adversary tries to model a
protected variable Z, here gender or zip code.
  The objective is to maximize the predictor's ability to predict Y while
minimizing the adversary's ability to predict Z. Applied to analogy completion,
this method results in accurate predictions that exhibit less evidence of
stereotyping Z. When applied to a classification task using the UCI Adult
(Census) Dataset, it results in a predictive model that does not lose much
accuracy while achieving very close to equality of odds (Hardt, et al., 2016).
The method is flexible and applicable to multiple definitions of fairness as
well as a wide range of gradient-based learning models, including both
regression and classification tasks.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07599</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary output layer of feedforward neural networks for solving
  multi-class classification problems</dc:title>
 <dc:creator>Yang, Sibo</dc:creator>
 <dc:creator>Zhang, Chao</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  Considered in this short note is the design of output layer nodes of
feedforward neural networks for solving multi-class classification problems
with r (bigger than or equal to 3) classes of samples. The common and
conventional setting of output layer, called &quot;one-to-one approach&quot; in this
paper, is as follows: The output layer contains r output nodes corresponding to
the r classes. And for an input sample of the i-th class, the ideal output is 1
for the i-th output node, and 0 for all the other output nodes. We propose in
this paper a new &quot;binary approach&quot;: Suppose r is (2^(q minus 1), 2^q] with q
bigger than or equal to 2, then we let the output layer contain q output nodes,
and let the ideal outputs for the r classes be designed in a binary manner.
Numerical experiments carried out in this paper show that our binary approach
does equally good job as, but uses less output nodes than, the traditional
one-to-one approach.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07604</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized Caching for Content Delivery Based on Blockchain: A Game
  Theoretic Perspective</dc:title>
 <dc:creator>Wang, Wenbo</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Leshem, Amir</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Blockchains enables tamper-proof, ordered logging for transactional data in a
decentralized manner over open-access, overlay peer-to-peer networks. In this
paper, we propose a decentralized framework of proactive caching in a
hierarchical wireless network based on blockchains. We employ the
blockchain-based smart contracts to construct an autonomous content caching
market. In the market, the cache helpers are able to autonomously adapt their
caching strategies according to the market statistics obtained from the
blockchain, and the truthfulness of trustless nodes are financially enforced by
smart contract terms. Further, we propose an incentive-compatible consensus
mechanism based on proof-of-stake to financially encourage the cache helpers to
stay active in service. We model the interaction between the cache helpers and
the content providers as a Chinese restaurant game. Based on the theoretical
analysis regarding the Nash equilibrium of the game, we propose a decentralized
strategy-searching algorithm using sequential best response. The simulation
results demonstrate both the efficiency and reliability of the proposed
equilibrium searching algorithm.
</dc:description>
 <dc:description>Comment: IEEE ICC 2018 Next Generation Networking and Internet Symposium
  (ICC'18 NGNI)</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07606</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deeper Insights into Graph Convolutional Networks for Semi-Supervised
  Learning</dc:title>
 <dc:creator>Li, Qimai</dc:creator>
 <dc:creator>Han, Zhichao</dc:creator>
 <dc:creator>Wu, Xiao-Ming</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many interesting problems in machine learning are being revisited with new
deep learning tools. For graph-based semisupervised learning, a recent
important development is graph convolutional networks (GCNs), which nicely
integrate local vertex features and graph topology in the convolutional layers.
Although the GCN model compares favorably with other state-of-the-art methods,
its mechanisms are not clear and it still requires a considerable amount of
labeled data for validation and model selection. In this paper, we develop
deeper insights into the GCN model and address its fundamental limits. First,
we show that the graph convolution of the GCN model is actually a special form
of Laplacian smoothing, which is the key reason why GCNs work, but it also
brings potential concerns of over-smoothing with many convolutional layers.
Second, to overcome the limits of the GCN model with shallow architectures, we
propose both co-training and self-training approaches to train GCNs. Our
approaches significantly improve GCNs in learning with very few labels, and
exempt them from requiring additional labels for validation. Extensive
experiments on benchmarks have verified our theory and proposals.
</dc:description>
 <dc:description>Comment: AAAI-2018 Oral Presentation</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07614</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge Computing Meets Millimeter-wave Enabled VR: Paving the Way to
  Cutting the Cord</dc:title>
 <dc:creator>Elbamby, Mohammed S.</dc:creator>
 <dc:creator>Perfecto, Cristina</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Doppler, Klaus</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, a novel proactive computing and mmWave communication for
ultra-reliable and low latency wireless virtual reality (VR is proposed. By
leveraging information about users' poses, proactive computing and caching are
used to pre-compute and store users' HD video frames to minimize the computing
latency. Furthermore, multi-connectivity is exploited to ensure reliable mmWave
links to deliver users' requested HD frames. The performance of the proposed
approach is validated on a VR network serving an interactive gaming arcade,
where dynamic and real-time rendering of HD video frames is needed and impulse
actions of different players impact the content to be shown. Simulation results
show significant gains of up to $30\%$ reduction in end-to-end delay and $50\%$
in the $90^{\textrm{th}}$ percentile communication delay.
</dc:description>
 <dc:description>Comment: Accepted for presentation in IEEE WCNC 2018. 6 pages, 6 figures</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07618</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling and Using Response Times in Online Courses</dc:title>
 <dc:creator>Rushkin, Ilia</dc:creator>
 <dc:creator>Chuang, Isaac</dc:creator>
 <dc:creator>Tingley, Dustin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Each time a learner in a self-paced online course is trying to answer an
assessment question, it takes some time to submit the answer, and if multiple
attempts are allowed and the first answer was incorrect, it takes some time to
submit the second attempt, and so on. Here we study the distribution of such
&quot;response times&quot;. We find that the log-normal statistical model for such times,
previously suggested in the literature, holds for online courses qualitatively.
Users who, according to this model, tend to take longer on submits are more
likely to complete the course, have a higher level of engagement and achieve a
higher grade. This finding can be the basis for designing interventions in
online courses, such as MOOCs, which would encourage some users to slow down.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07624</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mistral Supercomputer Job History Analysis</dc:title>
 <dc:creator>Zasadzi&#x144;ski, Micha&#x142;</dc:creator>
 <dc:creator>Munt&#xe9;s-Mulero, Victor</dc:creator>
 <dc:creator>Sol&#xe9;, Marc</dc:creator>
 <dc:creator>Ludwig, Thomas</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this technical report, we show insights and results of operational data
analysis from petascale supercomputer Mistral, which is ranked as 42nd most
powerful in the world as of January 2018. Data sources include hardware
monitoring data, job scheduler history, topology, and hardware information. We
explore job state sequences, spatial distribution, and electric power patterns.
</dc:description>
 <dc:description>Comment: 16 pages, 14 figures, 5 tables</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07630</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Task-parallel Analysis of Molecular Dynamics Trajectories</dc:title>
 <dc:creator>Paraskevakos, Ioannis</dc:creator>
 <dc:creator>Luckow, Andre</dc:creator>
 <dc:creator>Chantzialexiou, George</dc:creator>
 <dc:creator>Khoshlessan, Mahzad</dc:creator>
 <dc:creator>Beckstein, Oliver</dc:creator>
 <dc:creator>Fox, Geoffrey C.</dc:creator>
 <dc:creator>Jha, Shantenu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Different frameworks for implementing parallel data analytics applications
have been proposed by the HPC and Big Data communities. In this paper, we
investigate three frameworks: Spark, Dask and RADICAL-Pilot with respect to
their ability to support data analytics requirements on HPC resources. We
investigate the data analysis requirements of Molecular Dynamics (MD)
simulations which are significant consumers of supercomputing cycles, producing
immense amounts of data: a typical large-scale MD simulation of physical
systems of O(100,000) atoms can produce from O(10) GB to O(1000) GBs of data.
We propose and evaluate different approaches for parallelization of a
representative set of MD trajectory analysis algorithms, in particular the
computation of path similarity and the identification of connected atom. We
evaluate Spark, Dask and \rp with respect to the provided abstractions and
runtime engine capabilities to support these algorithms. We provide a
conceptual basis for comparing and understanding the different frameworks that
enable users to select the optimal system for its application. Further, we
provide a quantitative performance analysis of the different algorithms across
the three frameworks using different high-performance computing resources.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07632</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Resolution Face Completion with Multiple Controllable Attributes
  via Fully End-to-End Progressive Generative Adversarial Networks</dc:title>
 <dc:creator>Chen, Zeyuan</dc:creator>
 <dc:creator>Nie, Shaoliang</dc:creator>
 <dc:creator>Wu, Tianfu</dc:creator>
 <dc:creator>Healey, Christopher G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a deep learning approach for high resolution face completion with
multiple controllable attributes (e.g., male and smiling) under arbitrary
masks. Face completion entails understanding both structural meaningfulness and
appearance consistency locally and globally to fill in &quot;holes&quot; whose content do
not appear elsewhere in an input image. It is a challenging task with the
difficulty level increasing significantly with respect to high resolution, the
complexity of &quot;holes&quot; and the controllable attributes of filled-in fragments.
Our system addresses the challenges by learning a fully end-to-end framework
that trains generative adversarial networks (GANs) progressively from low
resolution to high resolution with conditional vectors encoding controllable
attributes.
  We design novel network architectures to exploit information across multiple
scales effectively and efficiently. We introduce new loss functions encouraging
sharp completion. We show that our system can complete faces with large
structural and appearance variations using a single feed-forward pass of
computation with mean inference time of 0.007 seconds for images at 1024 x 1024
resolution. We also perform a pilot human study that shows our approach
outperforms state-of-the-art face completion methods in terms of rank analysis.
The code will be released upon publication.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07633</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Activity Recognition for Mobile Robot</dc:title>
 <dc:creator>Olatunji, Iyiola E.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Due to the increasing number of mobile robots including domestic robots for
cleaning and maintenance in developed countries, human activity recognition is
inevitable for congruent human-robot interaction. Needless to say that this is
indeed a challenging task for robots, it is expedient to learn human activities
for autonomous mobile robots (AMR) for navigating in an uncontrolled
environment without any guidance. Building a correct classifier for complex
human action is non-trivial since simple actions can be combined to recognize a
complex human activity. In this paper, we trained a model for human activity
recognition using convolutional neural network. We trained and validated the
model using the Vicon physical action dataset and also tested the model on our
generated dataset (VMCUHK). Our experiment shows that our method performs with
high accuracy, human activity recognition task both on the Vicon physical
action dataset and VMCUHK dataset.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07637</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepGestalt - Identifying Rare Genetic Syndromes Using Deep Learning</dc:title>
 <dc:creator>Gurovich, Yaron</dc:creator>
 <dc:creator>Hanani, Yair</dc:creator>
 <dc:creator>Bar, Omri</dc:creator>
 <dc:creator>Fleischer, Nicole</dc:creator>
 <dc:creator>Gelbman, Dekel</dc:creator>
 <dc:creator>Basel-Salmon, Lina</dc:creator>
 <dc:creator>Krawitz, Peter</dc:creator>
 <dc:creator>Kamphausen, Susanne B</dc:creator>
 <dc:creator>Zenker, Martin</dc:creator>
 <dc:creator>Bird, Lynne M.</dc:creator>
 <dc:creator>Gripp, Karen W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Facial analysis technologies have recently measured up to the capabilities of
expert clinicians in syndrome identification. To date, these technologies could
only identify phenotypes of a few diseases, limiting their role in clinical
settings where hundreds of diagnoses must be considered.
  We developed a facial analysis framework, DeepGestalt, using computer vision
and deep learning algorithms, that quantifies similarities to hundreds of
genetic syndromes based on unconstrained 2D images. DeepGestalt is currently
trained with over 26,000 patient cases from a rapidly growing
phenotype-genotype database, consisting of tens of thousands of validated
clinical cases, curated through a community-driven platform. DeepGestalt
currently achieves 91% top-10-accuracy in identifying over 215 different
genetic syndromes and has outperformed clinical experts in three separate
experiments.
  We suggest that this form of artificial intelligence is ready to support
medical genetics in clinical and laboratory practices and will play a key role
in the future of precision medicine.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07647</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enforcing Programming Guidelines with Region Types and Effects</dc:title>
 <dc:creator>Erbatur, Serdar</dc:creator>
 <dc:creator>Hofmann, Martin</dc:creator>
 <dc:creator>Zalinescu, Eugen</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We present in this paper a new type and effect system for Java which can be
used to ensure adherence to guidelines for secure web programming. The system
is based on the region and effect system by Beringer, Grabowski, and Hofmann.
It improves upon it by being parametrized over an arbitrary guideline supplied
in the form of a finite monoid or automaton and a type annotation or mockup
code for external methods. Furthermore, we add a powerful type inference based
on precise interprocedural analysis and provide an implementation in the Soot
framework which has been tested on a number of benchmarks including large parts
of the Stanford SecuriBench.
</dc:description>
 <dc:description>Comment: long version of APLAS'17 paper</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07647</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-71237-6_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07648</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering with Deep Learning: Taxonomy and New Methods</dc:title>
 <dc:creator>Aljalbout, Elie</dc:creator>
 <dc:creator>Golkov, Vladimir</dc:creator>
 <dc:creator>Siddiqui, Yawar</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>62H30, 62M45, 91C20</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  Clustering is a fundamental machine learning method. The quality of its
results is dependent on the data distribution. For this reason, deep neural
networks can be used for learning better representations of the data. In this
paper, we propose a systematic taxonomy for clustering with deep learning, in
addition to a review of methods from the field. Based on our taxonomy, creating
new methods is more straightforward. We also propose a new approach which is
built on the taxonomy and surpasses some of the limitations of some previous
work. Our experimental evaluation on image datasets shows that the method
approaches state-of-the-art clustering quality, and performs better in some
cases.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07650</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Optimization of Neural Network Structures Using Probabilistic
  Modeling</dc:title>
 <dc:creator>Shirakawa, Shinichi</dc:creator>
 <dc:creator>Iwata, Yasushi</dc:creator>
 <dc:creator>Akimoto, Youhei</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) are powerful machine learning models and have
succeeded in various artificial intelligence tasks. Although various
architectures and modules for the DNNs have been proposed, selecting and
designing the appropriate network structure for a target problem is a
challenging task. In this paper, we propose a method to simultaneously optimize
the network structure and weight parameters during neural network training. We
consider a probability distribution that generates network structures, and
optimize the parameters of the distribution instead of directly optimizing the
network structure. The proposed method can apply to the various network
structure optimization problems under the same framework. We apply the proposed
method to several structure optimization problems such as selection of layers,
selection of unit types, and selection of connections using the MNIST,
CIFAR-10, and CIFAR-100 datasets. The experimental results show that the
proposed method can find the appropriate and competitive network structures.
</dc:description>
 <dc:description>Comment: To appear in the Thirty-Second AAAI Conference on Artificial
  Intelligence (AAAI-18), 9 pages</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07653</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CaosDB - Research Data Management for Complex, Changing, and Automated
  Research Workflows</dc:title>
 <dc:creator>Fitschen, Timm</dc:creator>
 <dc:creator>Schlemmer, Alexander</dc:creator>
 <dc:creator>Hornung, Daniel</dc:creator>
 <dc:creator>W&#xf6;rden, Henrik tom</dc:creator>
 <dc:creator>Parlitz, Ulrich</dc:creator>
 <dc:creator>Luther, Stefan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Here we present CaosDB, a Research Data Management System (RDMS) designed to
ensure seamless integration of inhomogeneous data sources and repositories of
legacy data. Its primary purpose is the management of data from biomedical
sciences, both from simulations and experiments during the complete research
data lifecycle. An RDMS for this domain faces particular challenges: Research
data arise in huge amounts, from a wide variety of sources, and traverse a
highly branched path of further processing. To be accepted by its users, an
RDMS must be built around workflows of the scientists and practices and thus
support changes in workflow and data structure. Nevertheless it should
encourage and support the development and observation of standards and
furthermore facilitate the automation of data acquisition and processing with
specialized software. The storage data model of an RDMS must reflect these
complexities with appropriate semantics and ontologies while offering simple
methods for finding, retrieving, and understanding relevant data. We show how
CaosDB responds to these challenges and give an overview of the CaosDB Server,
its data model and its easy-to-learn CaosDB Query Language. We briefly discuss
the status of the implementation, how we currently use CaosDB, and how we plan
to use and extend it.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07654</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expectation Learning for Adaptive Crossmodal Stimuli Association</dc:title>
 <dc:creator>Barros, Pablo</dc:creator>
 <dc:creator>Parisi, German I.</dc:creator>
 <dc:creator>Fu, Di</dc:creator>
 <dc:creator>Liu, Xun</dc:creator>
 <dc:creator>Wermter, Stefan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The human brain is able to learn, generalize, and predict crossmodal stimuli.
Learning by expectation fine-tunes crossmodal processing at different levels,
thus enhancing our power of generalization and adaptation in highly dynamic
environments. In this paper, we propose a deep neural architecture trained by
using expectation learning accounting for unsupervised learning tasks. Our
learning model exhibits a self-adaptable behavior, setting the first steps
towards the development of deep learning architectures for crossmodal stimuli
association.
</dc:description>
 <dc:description>Comment: 3 pages 2017 EUCog meeting abstract</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07656</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Byzantine Gathering in Polynomial Time</dc:title>
 <dc:creator>Bouchard, S&#xe9;bastien</dc:creator>
 <dc:creator>Dieudonn&#xe9;, Yoann</dc:creator>
 <dc:creator>Lamani, Anissa</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We study the task of Byzantine gathering in a network modeled as a graph.
Despite the presence of Byzantine agents, all the other (good) agents, starting
from possibly different nodes and applying the same deterministic algorithm,
have to meet at the same node in finite time and stop moving. An adversary
chooses the initial nodes of the agents and assigns a different label to each
of them. The agents move in synchronous rounds and communicate with each other
only when located at the same node. Within the team, f of the agents are
Byzantine. A Byzantine agent acts in an unpredictable way: in particular it may
forge the label of another agent or create a completely new one. Besides its
label, which corresponds to a local knowledge, an agent is assigned some global
knowledge GK that is common to all agents. In literature, the Byzantine
gathering problem has been analyzed in arbitrary n-node graphs by considering
the scenario when GK=(n,f) and the scenario when GK=f. In the first (resp.
second) scenario, it has been shown that the minimum number of good agents
guaranteeing deterministic gathering of all of them is f+1 (resp. f+2). For
both these scenarios, all the existing deterministic algorithms, whether or not
they are optimal in terms of required number of good agents, have a time
complexity that is exponential in n and L, where L is the largest label
belonging to a good agent.
  In this paper, we seek to design a deterministic solution for Byzantine
gathering that makes a concession on the proportion of Byzantine agents within
the team, but that offers a significantly lower complexity. We also seek to use
a global knowledge whose the length of the binary representation is small.
Assuming that the agents are in a strong team i.e., a team in which the number
of good agents is at least some prescribed value that is quadratic in f, we
give positive and negative results.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07661</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximability in the GPAC</dc:title>
 <dc:creator>Po&#xe7;as, Diogo</dc:creator>
 <dc:creator>Zucker, Jeffery</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Most of the physical processes arising in nature are modeled by either
ordinary or partial differential equations. From the point of view of analog
computability, the existence of an effective way to obtain solutions of these
systems is essential. A pioneering model of analog computation is the General
Purpose Analog Computer (GPAC), introduced by Shannon as a model of the
Differential Analyzer and improved by Pour-El, Lipshitz and Rubel, Costa and
Gra\c{c}a and others. Its power is known to be characterized by the class of
differentially algebraic functions, which includes the solutions of initial
value problems for ordinary differential equations. We address one of the
limitations of this model, concerning the notion of approximability, a
desirable property in computation over continuous spaces that is however absent
in the GPAC. In particular, the Shannon GPAC cannot be used to generate
non-differentially algebraic functions which can be approximately computed in
other models of computation. We extend the class of data types using networks
with channels which carry information on a general complete metric space
$\xcal$; for example $\xcal=C(\rbb,\rbb)$, the class of continuous functions of
one real (spatial) variable. We consider the original modules in Shannon's
construction (constants, adders, multipliers, integrators) and we add
\emph{(continuous or discrete) limit} modules which have one input and one
output. We then define an L-GPAC to be a network built with $\xcal$-stream
channels and the above-mentioned modules. This leads us to a framework in which
the specifications of such analog systems are given by fixed points of certain
operators on continuous data streams. We study these analog systems and their
associated operators, and show how some classically non-generable functions,
such as the gamma function and the Riemann zeta function, can be captured with
the L-GPAC.
</dc:description>
 <dc:description>Comment: 21 pages, 14 figures, submission to LMCS special issue</dc:description>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07663</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverse reinforcement learning in continuous time and space</dc:title>
 <dc:creator>Kamalapurkar, Rushikesh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper develops a data-driven inverse reinforcement learning technique
for a class of linear systems to estimate the cost function of an agent online,
using input-output measurements. A simultaneous state and parameter estimator
is utilized to facilitate output-feedback inverse reinforcement learning, and
cost function estimation is achieved up to multiplication by a constant.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07664</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Internal Universes in Models of Homotopy Type Theory</dc:title>
 <dc:creator>Licata, Daniel R.</dc:creator>
 <dc:creator>Orton, Ian</dc:creator>
 <dc:creator>Pitts, Andrew M.</dc:creator>
 <dc:creator>Spitters, Bas</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  We show that universes of fibrations in various models of homotopy type
theory have an essentially global character: they cannot be described in the
internal language of the presheaf topos from which the model is constructed. We
get around this problem by extending the internal language with a modal
operator for expressing properties of global elements. In this setting we show
how to construct a universe that classifies the Cohen-Coquand-Huber-M\&quot;ortberg
(CCHM) notion of fibration from their cubical sets model, starting from the
assumption that the interval is tiny - a property that the interval in cubical
sets does indeed have. This leads to a completely internal development of
models of homotopy type theory within what we call crisp type theory.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07668</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pruning Techniques for Mixed Ensembles of Genetic Programming Models</dc:title>
 <dc:creator>Castelli, Mauro</dc:creator>
 <dc:creator>Gon&#xe7;alves, Ivo</dc:creator>
 <dc:creator>Manzoni, Luca</dc:creator>
 <dc:creator>Vanneschi, Leonardo</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The objective of this paper is to define an effective strategy for building
an ensemble of Genetic Programming (GP) models. Ensemble methods are widely
used in machine learning due to their features: they average out biases, they
reduce the variance and they usually generalize better than single models.
Despite these advantages, building ensemble of GP models is not a
well-developed topic in the evolutionary computation community. To fill this
gap, we propose a strategy that blends individuals produced by standard
syntax-based GP and individuals produced by geometric semantic genetic
programming, one of the newest semantics-based method developed in GP. In fact,
recent literature showed that combining syntax and semantics could improve the
generalization ability of a GP model. Additionally, to improve the diversity of
the GP models used to build up the ensemble, we propose different pruning
criteria that are based on correlation and entropy, a commonly used measure in
information theory. Experimental results,obtained over different complex
problems, suggest that the pruning criteria based on correlation and entropy
could be effective in improving the generalization ability of the ensemble
model and in reducing the computational burden required to build it.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07674</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Classification Refinement Strategy for Semantic Segmentation</dc:title>
 <dc:creator>Davis, James W.</dc:creator>
 <dc:creator>Menart, Christopher</dc:creator>
 <dc:creator>Akbar, Muhammad</dc:creator>
 <dc:creator>Ilin, Roman</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Based on the observation that semantic segmentation errors are partially
predictable, we propose a compact formulation using confusion statistics of the
trained classifier to refine (re-estimate) the initial pixel label hypotheses.
The proposed strategy is contingent upon computing the classifier confusion
probabilities for a given dataset and estimating a relevant prior on the object
classes present in the image to be classified. We provide a procedure to
robustly estimate the confusion probabilities and explore multiple prior
definitions. Experiments are shown comparing performances on multiple
challenging datasets using different priors to improve a state-of-the-art
semantic segmentation classifier. This study demonstrates the potential to
significantly improve semantic labeling and motivates future work for reliable
label prior estimation from images.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07691</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Drug Selection via Joint Push and Learning to Rank</dc:title>
 <dc:creator>He, Yicheng</dc:creator>
 <dc:creator>Liu, Junfeng</dc:creator>
 <dc:creator>Cheng, Lijun</dc:creator>
 <dc:creator>Ning, Xia</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Selecting the right drugs for the right patients is a primary goal of
precision medicine. In this manuscript, we consider the problem of cancer drug
selection in a learning-to-rank framework. We have formulated the cancer drug
selection problem as to accurately predicting 1). the ranking positions of
sensitive drugs and 2). the ranking orders among sensitive drugs in cancer cell
lines based on their responses to cancer drugs. We have developed a new
learning-to-rank method, denoted as pLETORg , that predicts drug ranking
structures in each cell line via using drug latent vectors and cell line latent
vectors. The pLETORg method learns such latent vectors through explicitly
enforcing that, in the drug ranking list of each cell line, the sensitive drugs
are pushed above insensitive drugs, and meanwhile the ranking orders among
sensitive drugs are correct. Genomics information on cell lines is leveraged in
learning the latent vectors. Our experimental results on a benchmark cell
line-drug response dataset demonstrate that the new pLETORg significantly
outperforms the state-of-the-art method in prioritizing new sensitive drugs.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07693</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tractable Learning and Inference for Large-Scale Probabilistic Boolean
  Networks</dc:title>
 <dc:creator>Apostolopoulou, Ifigeneia</dc:creator>
 <dc:creator>Marculescu, Diana</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Probabilistic Boolean Networks (PBNs) have been previously proposed so as to
gain insights into complex dy- namical systems. However, identification of
large networks and of the underlying discrete Markov Chain which describes
their temporal evolution, still remains a challenge. In this paper, we
introduce an equivalent representation for the PBN, the Stochastic Conjunctive
Normal Form (SCNF), which paves the way to a scalable learning algorithm and
helps predict long- run dynamic behavior of large-scale systems. Moreover, SCNF
allows its efficient sampling so as to statistically infer multi- step
transition probabilities which can provide knowledge on the activity levels of
individual nodes in the long run.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07695</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Homologous Codes for Multiple Access Channels</dc:title>
 <dc:creator>Sen, Pinar</dc:creator>
 <dc:creator>Kim, Young-Han</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Building on recent development by Padakandla and Pradhan, and by Lim, Feng,
Pastore, Nazer, and Gastpar, this paper studies the potential of structured
nested coset coding as a complete replacement for random coding in network
information theory. The roles of two techniques used in nested coset coding to
generate nonuniform codewords, namely, shaping and channel transformation, are
clarified and illustrated via the simple example of the two-sender multiple
access channel. While individually deficient, the optimal combination of
shaping and channel transformation is shown to achieve the same performance as
traditional random codes for the general two-sender multiple access channel.
The achievability proof of the capacity region is extended to the multiple
access channels with more than two senders, and with one or more receivers. A
quantization argument consistent with the construction of nested coset codes is
presented to prove achievability for their Gaussian counterparts. These results
open up new possibilities of utilizing nested coset codes with the same
generator matrix for a broader class of applications.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07698</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ArcFace: Additive Angular Margin Loss for Deep Face Recognition</dc:title>
 <dc:creator>Deng, Jiankang</dc:creator>
 <dc:creator>Guo, Jia</dc:creator>
 <dc:creator>Zafeiriou, Stefanos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks have significantly boosted the performance of
face recognition in recent years due to its high capacity in learning
discriminative features. To enhance the discriminative power of the Softmax
loss, multiplicative angular margin and additive cosine margin incorporate
angular margin and cosine margin into the loss functions, respectively. In this
paper, we propose a novel supervisor signal, additive angular margin (ArcFace),
which has a better geometrical interpretation than supervision signals proposed
so far. Specifically, the proposed ArcFace $\cos(\theta + m)$ directly maximise
decision boundary in angular (arc) space based on the L2 normalised weights and
features. Compared to multiplicative angular margin $\cos(m\theta)$ and
additive cosine margin $\cos\theta-m$, ArcFace can obtain more discriminative
deep features. We also emphasise the importance of network settings and data
refinement in the problem of deep face recognition. Extensive experiments on
several relevant face recognition benchmarks, LFW, CFP and AgeDB, prove the
effectiveness of the proposed ArcFace. Most importantly, we get state-of-art
performance in the MegaFace Challenge in a totally reproducible way. We make
data, models and training/test code public
available~\footnote{https://github.com/deepinsight/insightface}.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07702</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Post-Quantum Cryptography: Riemann Primitives and Chrysalis</dc:title>
 <dc:creator>Malloy, Ian</dc:creator>
 <dc:creator>Hollenbeck, Dennis</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Chrysalis project is a proposed method for post-quantum cryptography
using the Riemann sphere. To this end, Riemann primitives are introduced in
addition to a novel implementation of this new method. Chrysalis itself is the
first cryptographic scheme to rely on Holomorphic Learning with Errors, which
is a complex form of Learning with Errors relying on the Gauss Circle Problem
within the Riemann sphere. The principle security reduction proposed by this
novel cryptographic scheme applies complex analysis of a Riemannian manifold
along with tangent bundles relative to a disjoint union of subsets based upon a
maximal element. A surjective function allows the mapping of multivariate
integrals onto subspaces. The proposed NP-Hard problem for security reduction
is the non-commutative Grothendieck problem. The reduction of this problem is
achieved by applying bilinear matrices in terms of the holomorphic vector
bundle such that coordinate systems are intersected via surjective functions
between each holomorphic expression. The result is an arbitrarily selected set
of points within constraints of bilinear matrix inequalities approximate to the
non-commutative problem. This is achieved by applying the quadratic form of
bilinear matrices to a linear matrix inequality.
</dc:description>
 <dc:description>Comment: Originally available on ResearchGate and now archived</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07704</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query Focused Abstractive Summarization: Incorporating Query Relevance,
  Multi-Document Coverage, and Summary Length Constraints into seq2seq Models</dc:title>
 <dc:creator>Baumel, Tal</dc:creator>
 <dc:creator>Eyal, Matan</dc:creator>
 <dc:creator>Elhadad, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Query Focused Summarization (QFS) has been addressed mostly using extractive
methods. Such methods, however, produce text which suffers from low coherence.
We investigate how abstractive methods can be applied to QFS, to overcome such
limitations. Recent developments in neural-attention based sequence-to-sequence
models have led to state-of-the-art results on the task of abstractive generic
single document summarization. Such models are trained in an end to end method
on large amounts of training data. We address three aspects to make abstractive
summarization applicable to QFS: (a)since there is no training data, we
incorporate query relevance into a pre-trained abstractive model; (b) since
existing abstractive models are trained in a single-document setting, we design
an iterated method to embed abstractive models within the multi-document
requirement of QFS; (c) the abstractive models we adapt are trained to generate
text of specific length (about 100 words), while we aim at generating output of
a different size (about 250 words); we design a way to adapt the target size of
the generated summaries to a given size ratio. We compare our method (Relevance
Sensitive Attention for QFS) to extractive baselines and with various ways to
combine abstractive models on the DUC QFS datasets and demonstrate solid
improvements on ROUGE performance.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07710</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Neural Networks</dc:title>
 <dc:creator>Mullachery, Vikram</dc:creator>
 <dc:creator>Khera, Aniruddh</dc:creator>
 <dc:creator>Husain, Amir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper describes and discusses Bayesian Neural Network (BNN). The paper
showcases a few different applications of them for classification and
regression problems. BNNs are comprised of a Probabilistic Model and a Neural
Network. The intent of such a design is to combine the strengths of Neural
Networks and Stochastic modeling. Neural Networks exhibit continuous function
approximator capabilities. Stochastic models allow direct specification of a
model with known interaction between parameters to generate data. During the
prediction phase, stochastic models generate a complete posterior distribution
and produce probabilistic guarantees on the predictions. Thus BNNs are a unique
combination of neural network and stochastic models with the stochastic model
forming the core of this integration. BNNs can then produce probabilistic
guarantees on it's predictions and also generate the distribution of parameters
that it has learnt from the observations. That means, in the parameter space,
one can deduce the nature and shape of the neural network's learnt parameters.
These two characteristics makes them highly attractive to theoreticians as well
as practitioners. Recently there has been a lot of activity in this area, with
the advent of numerous probabilistic programming libraries such as: PyMC3,
Edward, Stan etc. Further this area is rapidly gaining ground as a standard
machine learning approach for numerous problems
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1111.4246 by other authors</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07722</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Markov Chain Monitoring</dc:title>
 <dc:creator>Chaudhari, Harshal A.</dc:creator>
 <dc:creator>Mathioudakis, Michael</dc:creator>
 <dc:creator>Terzi, Evimaria</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In networking applications, one often wishes to obtain estimates about the
number of objects at different parts of the network (e.g., the number of cars
at an intersection of a road network or the number of packets expected to reach
a node in a computer network) by monitoring the traffic in a small number of
network nodes or edges. We formalize this task by defining the 'Markov Chain
Monitoring' problem.
  Given an initial distribution of items over the nodes of a Markov chain, we
wish to estimate the distribution of items at subsequent times. We do this by
asking a limited number of queries that retrieve, for example, how many items
transitioned to a specific node or over a specific edge at a particular time.
We consider different types of queries, each defining a different variant of
the Markov chain monitoring. For each variant, we design efficient algorithms
for choosing the queries that make our estimates as accurate as possible. In
our experiments with synthetic and real datasets we demonstrate the efficiency
and the efficacy of our algorithms in a variety of settings.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures, 1 table</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07729</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Shape of Art History in the Eyes of the Machine</dc:title>
 <dc:creator>Elgammal, Ahmed</dc:creator>
 <dc:creator>Mazzone, Marian</dc:creator>
 <dc:creator>Liu, Bingchen</dc:creator>
 <dc:creator>Kim, Diana</dc:creator>
 <dc:creator>Elhoseiny, Mohamed</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  How does the machine classify styles in art? And how does it relate to art
historians's methods for analyzing style? Several studies have shown the
ability of the machine to learn and predict style categories, such as
Renaissance, Baroque, Impressionism, etc., from images of paintings. This
implies that the machine can learn an internal representation encoding
discriminative features through its visual analysis. However, such a
representation is not necessarily interpretable. We conducted a comprehensive
study of several of the state-of-the-art convolutional neural networks applied
to the task of style classification on 77K images of paintings, and analyzed
the learned representation through correlation analysis with concepts derived
from art history. Surprisingly, the networks could place the works of art in a
smooth temporal arrangement mainly based on learning style labels, without any
a priori knowledge of time of creation, the historical time and context of
styles, or relations between styles. The learned representations showed that
there are few underlying factors that explain the visual variations of style in
art. Some of these factors were found to correlate with style patterns
suggested by Heinrich W\&quot;olfflin (1846-1945). The learned representations also
consistently highlighted certain artists as the extreme distinctive
representative of their styles, which quantitatively confirms art historian
observations.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07733</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Key Generation Rate of Physically Unclonable Functions</dc:title>
 <dc:creator>Chen, Yitao</dc:creator>
 <dc:creator>Kim, Muryong</dc:creator>
 <dc:creator>Vishwanath, Sriram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, an algebraic binning based coding scheme and its associated
achievable rate for key generation using physically unclonable functions (PUFs)
is determined. This achievable rate is shown to be optimal under the
generated-secret (GS) model for PUFs. Furthermore, a polar code based
polynomial-time encoding and decoding scheme that achieves this rate is also
presented.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07734</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Centralized to Decentralized Coded Caching</dc:title>
 <dc:creator>Chen, Yitao</dc:creator>
 <dc:creator>Shanmugam, Karthikeyan</dc:creator>
 <dc:creator>Dimakis, Alexandros G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of designing decentralized schemes for coded caching.
In this problem there are $K$ users each caching $M$ files out of a library of
$N$ total files. The question is to minimize $R$, the number of broadcast
transmissions to satisfy all the user demands. Decentralized schemes allow the
creation of each cache independently, allowing users to join or leave without
dependencies. Previous work showed that to achieve a coding gain $g$, i.e. $R
\leq K (1-M/N)/g$ transmissions, each file has to be divided into number of
subpackets that is exponential in $g$.
  In this work we propose a simple translation scheme that converts any
constant rate centralized scheme into a random decentralized placement scheme
that guarantees a target coding gain of $g$. If the file size in the original
constant rate centralized scheme is subexponential in $K$, then the file size
for the resulting scheme is subexponential in $g$. When new users join, the
rest of the system remains the same. However, we require an additional
communication overhead of $O(\log K)$ bits to determine the new user's cache
state. We also show that the worst-case rate guarantee degrades only by a
constant factor due to the dynamics of user arrival and departure.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07736</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MaskGAN: Better Text Generation via Filling in the ______</dc:title>
 <dc:creator>Fedus, William</dc:creator>
 <dc:creator>Goodfellow, Ian</dc:creator>
 <dc:creator>Dai, Andrew M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural text generation models are often autoregressive language models or
seq2seq models. These models generate text by sampling words sequentially, with
each word conditioned on the previous word, and are state-of-the-art for
several machine translation and summarization benchmarks. These benchmarks are
often defined by validation perplexity even though this is not a direct measure
of the quality of the generated text. Additionally, these models are typically
trained via maxi- mum likelihood and teacher forcing. These methods are
well-suited to optimizing perplexity but can result in poor sample quality
since generating text requires conditioning on sequences of words that may have
never been observed at training time. We propose to improve sample quality
using Generative Adversarial Networks (GANs), which explicitly train the
generator to produce high quality samples and have shown a lot of success in
image generation. GANs were originally designed to output differentiable
values, so discrete language generation is challenging for them. We claim that
validation perplexity alone is not indicative of the quality of text generated
by a model. We introduce an actor-critic conditional GAN that fills in missing
text conditioned on the surrounding context. We show qualitatively and
quantitatively, evidence that this produces more realistic conditional and
unconditional text samples compared to a maximum likelihood trained model.
</dc:description>
 <dc:description>Comment: 16 pages, ICLR 2018 submission</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07737</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SentiPers: A Sentiment Analysis Corpus for Persian</dc:title>
 <dc:creator>Hosseini, Pedram</dc:creator>
 <dc:creator>Ramaki, Ali Ahmadian</dc:creator>
 <dc:creator>Maleki, Hassan</dc:creator>
 <dc:creator>Anvari, Mansoureh</dc:creator>
 <dc:creator>Mirroshandel, Seyed Abolghasem</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Sentiment Analysis (SA) is a major field of study in natural language
processing, computational linguistics and information retrieval. Interest in SA
has been constantly growing in both academia and industry over the recent
years. Moreover, there is an increasing need for generating appropriate
resources and datasets in particular for low resource languages including
Persian. These datasets play an important role in designing and developing
appropriate opinion mining platforms using supervised, semi-supervised or
unsupervised methods. In this paper, we outline the entire process of
developing a manually annotated sentiment corpus, SentiPers, which covers
formal and informal written contemporary Persian. To the best of our knowledge,
SentiPers is a unique sentiment corpus with such a rich annotation in three
different levels including document-level, sentence-level, and
entity/aspect-level for Persian. The corpus contains more than 26000 sentences
of users opinions from digital product domain and benefits from special
characteristics such as quantifying the positiveness or negativity of an
opinion through assigning a number within a specific range to any given
sentence. Furthermore, we present statistics on various components of our
corpus as well as studying the inter-annotator agreement among the annotators.
Finally, some of the challenges that we faced during the annotation process
will be discussed as well.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07740</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of Variance and Spatial Correlation Width for Fine-scale
  Measurement Error in Digital Elevation Model</dc:title>
 <dc:creator>Uss, Mykhail</dc:creator>
 <dc:creator>Vozel, Benoit</dc:creator>
 <dc:creator>Lukin, Vladimir</dc:creator>
 <dc:creator>Chehdi, Kacem</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we borrow from blind noise parameter estimation (BNPE)
methodology early developed in the image processing field an original and
innovative no-reference approach to estimate Digital Elevation Model (DEM)
vertical error parameters without resorting to a reference DEM. The challenges
associated with the proposed approach related to the physical nature of the
error and its multifactor structure in DEM are discussed in detail. A suitable
multivariate method is then developed for estimating the error in gridded DEM.
It is built on a recently proposed vectorial BNPE method for estimating
spatially correlated noise using Noise Informative areas and Fractal Brownian
Motion. The newly multivariate method is derived to estimate the effect of the
stacking procedure and that of the epipolar line error on local (fine-scale)
standard deviation and autocorrelation function width of photogrammetric DEM
measurement error. Applying the new estimator to ASTER GDEM2 and ALOS World 3D
DEMs, good agreement of derived estimates with results available in the
literature is evidenced. In future works, the proposed no-reference method for
analyzing DEM error can be extended to a larger number of predictors for
accounting for other factors influencing remote sensing (RS) DEM accuracy.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures, 3 tables</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07741</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who Killed My Parked Car?</dc:title>
 <dc:creator>Cho, Kyong-Tak</dc:creator>
 <dc:creator>Kim, Yuseung</dc:creator>
 <dc:creator>Shin, Kang G.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We find that the conventional belief of vehicle cyber attacks and their
defenses---attacks are feasible and thus defenses are required only when the
vehicle's ignition is turned on---does not hold. We verify this fact by
discovering and applying two new practical and important attacks: battery-drain
and Denial-of-Body-control (DoB). The former can drain the vehicle battery
while the latter can prevent the owner from starting or even opening/entering
his car, when either or both attacks are mounted with the ignition off. We
first analyze how operation (e.g., normal, sleep, listen) modes of ECUs are
defined in various in-vehicle network standards and how they are implemented in
the real world. From this analysis, we discover that an adversary can exploit
the wakeup function of in-vehicle networks---which was originally designed for
enhanced user experience/convenience (e.g., remote diagnosis, remote
temperature control)---as an attack vector. Ironically, a core battery-saving
feature in in-vehicle networks makes it easier for an attacker to wake up ECUs
and, therefore, mount and succeed in battery-drain and/or DoB attacks. Via
extensive experimental evaluations on various real vehicles, we show that by
mounting the battery-drain attack, the adversary can increase the average
battery consumption by at least 12.57x, drain the car battery within a few
hours or days, and therefore immobilize/cripple the vehicle. We also
demonstrate the proposed DoB attack on a real vehicle, showing that the
attacker can cut off communications between the vehicle and the driver's key
fob by indefinitely shutting down an ECU, thus making the driver unable to
start and/or even enter the car.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07743</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entity Retrieval and Text Mining for Online Reputation Monitoring</dc:title>
 <dc:creator>Saleiro, Pedro</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Online Reputation Monitoring (ORM) is concerned with the use of computational
tools to measure the reputation of entities online, such as politicians or
companies. In practice, current ORM methods are constrained to the generation
of data analytics reports, which aggregate statistics of popularity and
sentiment on social media. We argue that this format is too restrictive as end
users often like to have the flexibility to search for entity-centric
information that is not available in predefined charts. As such, we propose the
inclusion of entity retrieval capabilities as a first step towards the
extension of current ORM capabilities. However, an entity's reputation is also
influenced by the entity's relationships with other entities. Therefore, we
address the problem of Entity-Relationship (E-R) retrieval in which the goal is
to search for multiple connected entities. This is a challenging problem which
traditional entity search systems cannot cope with. Besides E-R retrieval we
also believe ORM would benefit of text-based entity-centric prediction
capabilities, such as predicting entity popularity on social media based on
news events or the outcome of political surveys. However, none of these tasks
can provide useful results if there is no effective entity disambiguation and
sentiment analysis tailored to the context of ORM. Consequently, this thesis
address two computational problems in Online Reputation Monitoring: Entity
Retrieval and Text Mining. We researched and developed methods to extract,
retrieve and predict entity-centric information spread across the Web.
</dc:description>
 <dc:description>Comment: PhD Thesis</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07745</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Transport on Discrete Domains</dc:title>
 <dc:creator>Solomon, Justin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Inspired by the matching of supply to demand in logistical problems, the
optimal transportation (or Monge-Kantorovich) problem involves the matching of
probability distributions defined over a geometric domain such as a surface or
manifold. After discretization, optimal transportation becomes a large-scale
linear program, which typically is infeasible to solve efficiently on triangle
meshes, graphs, point clouds, and other domains encountered in graphics and
machine learning. Recent breakthroughs in numerical optimal transportation
enable scalability to orders-of-magnitude larger problems, solvable in a
fraction of a second. In these lecture notes, we discuss advances in numerical
optimal transport that leverage understanding of both discrete and smooth
aspects of the problem. State-of-the-art techniques in discrete optimal
transportation combine insight from partial differential equations (PDE) with
convex analysis to reformulate, discretize, and optimize transportation
problems. The end result is a set of theoretically-justified models suitable
for domains with thousands or millions of vertices. Since numerical optimal
transport is a relatively new discipline, special emphasis is placed on
identifying and explaining open problems in need of mathematical insight and
additional research.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07746</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HappyDB: A Corpus of 100,000 Crowdsourced Happy Moments</dc:title>
 <dc:creator>Asai, Akari</dc:creator>
 <dc:creator>Evensen, Sara</dc:creator>
 <dc:creator>Golshan, Behzad</dc:creator>
 <dc:creator>Halevy, Alon</dc:creator>
 <dc:creator>Li, Vivian</dc:creator>
 <dc:creator>Lopatenko, Andrei</dc:creator>
 <dc:creator>Stepanov, Daniela</dc:creator>
 <dc:creator>Suhara, Yoshihiko</dc:creator>
 <dc:creator>Tan, Wang-Chiew</dc:creator>
 <dc:creator>Xu, Yinzhan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The science of happiness is an area of positive psychology concerned with
understanding what behaviors make people happy in a sustainable fashion.
Recently, there has been interest in developing technologies that help
incorporate the findings of the science of happiness into users' daily lives by
steering them towards behaviors that increase happiness. With the goal of
building technology that can understand how people express their happy moments
in text, we crowd-sourced HappyDB, a corpus of 100,000 happy moments that we
make publicly available. This paper describes HappyDB and its properties, and
outlines several important NLP problems that can be studied with the help of
the corpus. We also apply several state-of-the-art analysis techniques to
analyze HappyDB. Our results demonstrate the need for deeper NLP techniques to
be developed which makes HappyDB an exciting resource for follow-on research.
</dc:description>
 <dc:description>Comment: Typos fixed</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07747</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantified Degrees of Group Responsibility (Extended Abstract)</dc:title>
 <dc:creator>Yazdanpanah, Vahid</dc:creator>
 <dc:creator>Dastani, Mehdi</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper builds on an existing notion of group responsibility and proposes
two ways to define the degree of group responsibility: structural and
functional degrees of responsibility. These notions measure the potential
responsibilities of (agent) groups for avoiding a state of affairs. According
to these notions, a degree of responsibility for a state of affairs can be
assigned to a group of agents if, and to the extent that, the group has the
potential to preclude the state of affairs.
</dc:description>
 <dc:description>Comment: Presented in the 27th Belgian-Netherlands Conference on Artificial
  Intelligence (BNAIC 2015), Hasselt, Belgium</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07756</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Electromyographic Hand Gesture Signal Classification
  by Leveraging Transfer Learning</dc:title>
 <dc:creator>C&#xf4;t&#xe9;-Allard, Ulysse</dc:creator>
 <dc:creator>Fall, Cheikh Latyr</dc:creator>
 <dc:creator>Drouin, Alexandre</dc:creator>
 <dc:creator>Campeau-Lecours, Alexandre</dc:creator>
 <dc:creator>Gosselin, Cl&#xe9;ment</dc:creator>
 <dc:creator>Glette, Kyrre</dc:creator>
 <dc:creator>Laviolette, Fran&#xe7;ois</dc:creator>
 <dc:creator>Gosselin, Benoit</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In recent years, the use of deep learning algorithms has become increasingly
more prominent. Within the field of electromyography-based gesture recognition
however, deep learning algorithms are seldom employed. This is due in part to
the large quantity of data required for the network to train on. The data
sparsity arises from the fact that it would take an unreasonable amount of time
for a single person to generate tens of thousands of examples for training such
algorithms. In this paper, two datasets are recorded with the Myo Armband
(Thalmic Labs), a low-cost, low-sampling rate (200Hz), 8-channel,
consumer-grade, dry electrode sEMG armband. These datasets, referred to as the
pre-training and evaluation dataset, are comprised of 19 and 17 able-bodied
participants respectively. A convolutional network (ConvNet) is augmented with
transfer learning techniques to leverage inter-user data from the first
dataset, alleviating the burden imposed on a single individual to generate a
vast quantity of training data for sEMG-based gesture recognition. This
transfer learning scheme is shown to outperform the current state-of-the-art in
gesture recognition achieving an average accuracy of 98.31% for 7 hand/wrist
gestures over 17 able-bodied participants. Finally, a use-case study of eight
able-bodied participants is presented to evaluate the impact of feedback on the
degradation accuracy normally experienced from a classifier over time.
</dc:description>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07757</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SAVITR: A System for Real-time Location Extraction from Microblogs
  during Emergencies</dc:title>
 <dc:creator>Dutt, Ritam</dc:creator>
 <dc:creator>Hiware, Kaustubh</dc:creator>
 <dc:creator>Ghosh, Avijit</dc:creator>
 <dc:creator>Bhaskaran, Rameshwar</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present SAVITR, a system that leverages the information posted on the
Twitter microblogging site to monitor and analyse emergency situations. Given
that only a very small percentage of microblogs are geo-tagged, it is essential
for such a system to extract locations from the text of the microblogs. We
employ natural language processing techniques to infer the locations mentioned
in the microblog text, in an unsupervised fashion and display it on a map-based
interface. The system is designed for efficient performance, achieving an
F-score of 0.79, and is approximately two orders of magnitude faster than other
available tools for location extraction.
</dc:description>
 <dc:description>Comment: Submission in SMERP - WWW 2018</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07759</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Whose Hands Are in the Finnish Cookie Jar?</dc:title>
 <dc:creator>Ruohonen, Jukka</dc:creator>
 <dc:creator>Lepp&#xe4;nen, Ville</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Web cookies are ubiquitously used to track and profile the behavior of users.
Although there is a solid empirical foundation for understanding the use of
cookies in the global world wide web, thus far, limited attention has been
devoted for country-specific and company-level analysis of cookies. To patch
this limitation in the literature, this paper investigates persistent
third-party cookies used in the Finnish web. The exploratory results reveal
some similarities and interesting differences between the Finnish and the
global web---in particular, popular Finnish web sites are mostly owned by media
companies, which have established their distinct partnerships with online
advertisement companies. The results reported can be also reflected against
current and future privacy regulation in the European Union.
</dc:description>
 <dc:description>Comment: Proceedings of the European Intelligence and Security Informatics
  Conference (EISIC 2017)</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07759</dc:identifier>
 <dc:identifier>doi:10.1109/EISIC.2017.25</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07772</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Layers of Representation in Neural Machine Translation on
  Part-of-Speech and Semantic Tagging Tasks</dc:title>
 <dc:creator>Belinkov, Yonatan</dc:creator>
 <dc:creator>M&#xe0;rquez, Llu&#xed;s</dc:creator>
 <dc:creator>Sajjad, Hassan</dc:creator>
 <dc:creator>Durrani, Nadir</dc:creator>
 <dc:creator>Dalvi, Fahim</dc:creator>
 <dc:creator>Glass, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  While neural machine translation (NMT) models provide improved translation
quality in an elegant, end-to-end framework, it is less clear what they learn
about language. Recent work has started evaluating the quality of vector
representations learned by NMT models on morphological and syntactic tasks. In
this paper, we investigate the representations learned at different layers of
NMT encoders. We train NMT systems on parallel data and use the trained models
to extract features for training a classifier on two tasks: part-of-speech and
semantic tagging. We then measure the performance of the classifier as a proxy
to the quality of the original NMT model for the given task. Our quantitative
analysis yields interesting insights regarding representation learning in NMT
models. For instance, we find that higher layers are better at learning
semantics while lower layers tend to be better for part-of-speech tagging. We
also observe little effect of the target language on source-side
representations, especially with higher quality NMT models.
</dc:description>
 <dc:description>Comment: IJCNLP 2017</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07772</dc:identifier>
 <dc:identifier>IJCNLP 8 (2017), volume 1, 1-10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07777</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Reliability Function of Discrete Memoryless Multiple-Access
  Channel with Feedback</dc:title>
 <dc:creator>Heidari, Mohsen</dc:creator>
 <dc:creator>Anastasopoulos, Achilleas</dc:creator>
 <dc:creator>Pradhan, S. Sandeep</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We derive a lower and upper bound on the reliability function of discrete
memoryless multiple-access channel (MAC) with noiseless feedback and
variable-length codes (VLCs). The bounds are similar to the one for
point-to-point channels, increasing linearly with respect to an appropriate
distance between the rate pair and the capacity boundary. For the lower bound
on the error exponent, we adapt Yamamoto and Itoh's coding scheme consisting of
a data and a confirmation stage. In the data stage we use arbitrary feedback
capacity-achieving codes. In the confirmation stage, each transmitter sends one
bit of information to the receiver using a pair of codebooks of size two, one
for each transmitter. The codewords at this stage are selected randomly
according to an appropriately optimized joint probability distribution. For the
upper bound on the error exponent, we adopt the proof techniques of Burnashev
for the reliability function of the point-to-point case. The upper bound is
derived by studying the rate of decrease of appropriate message entropies.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07779</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The WiLI benchmark dataset for written language identification</dc:title>
 <dc:creator>Thoma, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes the WiLI-2018 benchmark dataset for monolingual written
natural language identification. WiLI-2018 is a publicly available, free of
charge dataset of short text extracts from Wikipedia. It contains 1000
paragraphs of 235 languages, totaling in 23500 paragraphs. WiLI is a
classification dataset: Given an unknown paragraph written in one dominant
language, it has to be decided which language it is.
</dc:description>
 <dc:description>Comment: {&quot;pages&quot;: 12, &quot;figures&quot;: 4, &quot;language&quot;: &quot;English&quot;, &quot;author-ORCiD&quot;:
  [&quot;https://orcid.org/0000-0002-6517-1690&quot;]}</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07782</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Role of Spreadsheets in Clinical Decision Support: A Survey of the
  Medical Algorithms Company User Community</dc:title>
 <dc:creator>Thorne, Simon</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper presents and discusses the results of a small scoping survey of
Clinical Decision Support System (CDSS) users from the Medical Algorithms
Company website which hosts 24,000 different CDSS. These results are analysed,
discussed, and compared with other similar studies and contribute to the wider
understanding of how CDSS impact on clinical practice. The results show that
CDSS provided by Medal are being used by clinical professionals in a variety of
settings, both as an operational tool and as a research and reference tool.
Whilst these tools are implemented and executed in a database, the initial
logic is worked out on a spreadsheet. The paper describes that process and
examines some of the results of the survey.
</dc:description>
 <dc:description>Comment: 13 pages, 6 Colour Figures</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07782</dc:identifier>
 <dc:identifier>Proceedings of the EuSpRIG 2017 Conference &quot;Spreadsheet Risk
  Management&quot;, Imperial College, London, pp137-151 ISBN: 978-1-905404-54-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07783</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Definition of Network Communities and the Corresponding
  Detection Algorithm</dc:title>
 <dc:creator>Lu, Haoye</dc:creator>
 <dc:creator>Nayak, Amiya</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Network structures, consisting of nodes and edges, have applications in
almost all subjects. The sets of nodes strongly connected internally are called
communities. Industries (including cell phone carriers and online social media
companies) need community structures to allocate network resources and provide
proper customer services. However, all community detection methods are
motivated by solving some concrete problems, while the applicabilities in other
fields are open to question. Therefore, confronting a new community problem,
researchers need to derive algorithms ad hoc, which is time-consuming and even
unnecessary. In this paper, we represent a general procedure to find community
structures in concrete problems. We mainly focus on two typical types of
networks: transmission networks and similarity networks. We reduce them to a
unified graph model, based on which we propose a general method to define and
detect communities. Readers can specialize our general algorithm to accommodate
their problems. In the end, we also give a demonstration to show how the
algorithm works.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07789</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data is the Fuel of Organizations: Opportunities and Challenges in
  Afghanistan</dc:title>
 <dc:creator>Sherzad, Abdul Rahman</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>E.0</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>H.2</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>K.3.1</dc:subject>
 <dc:description>  In this paper, the author at first briefly outlines the value of data in
organizations and the opportunities and challenges in Afghanistan. Then the
author takes the Kankor (National University Entrance Exam) data, particularly
names of participants, locations, high schools and higher education
institutions into account and explains how these data, that organizations in
Afghanistan do not use for anything, can be useful in several cases and areas.
The application of these data is shown through cases such as Auto filling
missing values, identifying names of people, locations, and institutions from
unstructured text, generating fake data to benchmark the database and web
application performance and appearance, comparing and matching high school data
with Kankor data, producing the top-n male and female names very common in
Afghanistan or province-wise, and the data mining application in education and
higher education institutions.
</dc:description>
 <dc:description>Comment: This paper consists of 14 pages, and it includes 7 figures</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07791</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PointCNN</dc:title>
 <dc:creator>Li, Yangyan</dc:creator>
 <dc:creator>Bu, Rui</dc:creator>
 <dc:creator>Sun, Mingchao</dc:creator>
 <dc:creator>Chen, Baoquan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.4.7</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  We present a simple and general framework for feature learning from point
cloud. The key to the success of CNNs is the convolution operator that is
capable of leveraging spatially-local correlation in data represented densely
in grids (e.g. images). However, point cloud are irregular and unordered, thus
a direct convolving of kernels against the features associated with the points
will result in deserting the shape information while being variant to the
orders. To address these problems, we propose to learn a X-transformation from
the input points, and then use it to simultaneously weight the input features
associated with the points and permute them into latent potentially canonical
order, before the element-wise product and sum operations are applied. The
proposed method is a generalization of typical CNNs into learning features from
point cloud, thus we call it PointCNN. Experiments show that PointCNN achieves
on par or better performance than state-of-the-art methods on multiple
challenging benchmark datasets and tasks.
</dc:description>
 <dc:description>Comment: Small updates</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07792</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contact Localization through Spatially Overlapping Piezoresistive
  Signals</dc:title>
 <dc:creator>Piacenza, Pedro</dc:creator>
 <dc:creator>Xiao, Yuchen</dc:creator>
 <dc:creator>Park, Steve</dc:creator>
 <dc:creator>Kymissis, Ioannis</dc:creator>
 <dc:creator>Ciocarlie, Matei</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Achieving high spatial resolution in contact sensing for robotic manipulation
often comes at the price of increased complexity in fabrication and
integration. One traditional approach is to fabricate a large number of taxels,
each delivering an individual, isolated response to a stimulus. In contrast, we
propose a method where the sensor simply consists of a continuous volume of
piezoresistive elastomer with a number of electrodes embedded inside. We
measure piezoresistive effects between all pairs of electrodes in the set, and
count on this rich signal set containing the information needed to pinpoint
contact location with high accuracy using regression algorithms. In our
validation experiments, we demonstrate submillimeter median accuracy in
locating contact on a 10mm by 16mm sensor using only four electrodes (creating
six unique pairs). In addition to extracting more information from fewer wires,
this approach lends itself to simple fabrication methods and makes no
assumptions about the underlying geometry, simplifying future integration on
robot fingers.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, IROS 2016</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07800</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>qrypt0 - encrypted short messages exchanged between offline computers</dc:title>
 <dc:creator>Bender, Andreas O.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A system is described for exchanging encrypted short messages between
computers which remain permanently isolated from any network accessible to the
attacker. The main advantage is effective protection of these computers from
malware which could circumvent the encryption. For transmission, the ciphertext
is passed between isolated and connected computers in the form of a QR code,
which is displayed on and scanned from a screen. The security of qrypt0
therefore rests on the cryptography and the computer's physical isolation
rather than on the computer security of the encrypting device.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07804</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vietnamese Open Information Extraction</dc:title>
 <dc:creator>Truong, Diem</dc:creator>
 <dc:creator>Vo, Duc-Thuan</dc:creator>
 <dc:creator>Nguyen, U. T</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Open information extraction (OIE) is the process to extract relations and
their arguments automatically from textual documents without the need to
restrict the search to predefined relations. In recent years, several OIE
systems for the English language have been created but there is not any system
for the Vietnamese language. In this paper, we propose a method of OIE for
Vietnamese using a clause-based approach. Accordingly, we exploit Vietnamese
dependency parsing using grammar clauses that strives to consider all possible
relations in a sentence. The corresponding clause types are identified by their
propositions as extractable relations based on their grammatical functions of
constituents. As a result, our system is the first OIE system named vnOIE for
the Vietnamese language that can generate open relations and their arguments
from Vietnamese text with highly scalable extraction while being domain
independent. Experimental results show that our OIE system achieves promising
results with a precision of 83.71%.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07807</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic Bio-surveillance For Precise Spatio-temporal Prediction of
  Zoonotic Emergence</dc:title>
 <dc:creator>Dhanoa, Jaideep</dc:creator>
 <dc:creator>Manicassamy, Balaji</dc:creator>
 <dc:creator>Chattopadhyay, Ishanu</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Viral zoonoses have emerged as the key drivers of recent pandemics. Human
infection by zoonotic viruses are either spillover events -- isolated
infections that fail to cause a widespread contagion -- or species jumps, where
successful adaptation to the new host leads to a pandemic. Despite expensive
bio-surveillance efforts, historically emergence response has been reactive,
and post-hoc. Here we use machine inference to demonstrate a high accuracy
predictive bio-surveillance capability, designed to pro-actively localize an
impending species jump via automated interrogation of massive sequence
databases of viral proteins. Our results suggest that a jump might not purely
be the result of an isolated unfortunate cross-infection localized in space and
time; there are subtle yet detectable patterns of genotypic changes
accumulating in the global viral population leading up to emergence. Using tens
of thousands of protein sequences simultaneously, we train models that track
maximum achievable accuracy for disambiguating host tropism from the primary
structure of surface proteins, and show that the inverse classification
accuracy is a quantitative indicator of jump risk. We validate our claim in the
context of the 2009 swine flu outbreak, and the 2004 emergence of H5N1
subspecies of Influenza A from avian reservoirs; illustrating that
interrogation of the global viral population can unambiguously track a near
monotonic risk elevation over several preceding years leading to eventual
emergence.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07814</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Green Mining: toward a less energetic impact of cryptocurrencies</dc:title>
 <dc:creator>Jacquet, Philippe</dc:creator>
 <dc:creator>Mans, Bernard</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  While cryptocurrencies continue to gain popularity, their energy cost is
increasingly becoming unsustainable. In this paper, we present an innovative
scheme which eliminates the burden of the proof of work which is the main cause
of the energy waste in cryptocurrencies such as Bitcoin. The scheme is based on
a green leader election scheme which guarantees a bounded average number of
simultaneous mining whatever the size of the population in competition.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07826</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Heterogeneous Consumer Preferences for Restaurants and Travel
  Time Using Mobile Location Data</dc:title>
 <dc:creator>Athey, Susan</dc:creator>
 <dc:creator>Blei, David</dc:creator>
 <dc:creator>Donnelly, Robert</dc:creator>
 <dc:creator>Ruiz, Francisco</dc:creator>
 <dc:creator>Schmidt, Tobias</dc:creator>
 <dc:subject>Economics - Econometrics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper analyzes consumer choices over lunchtime restaurants using data
from a sample of several thousand anonymous mobile phone users in the San
Francisco Bay Area. The data is used to identify users' approximate typical
morning location, as well as their choices of lunchtime restaurants. We build a
model where restaurants have latent characteristics (whose distribution may
depend on restaurant observables, such as star ratings, food category, and
price range), each user has preferences for these latent characteristics, and
these preferences are heterogeneous across users. Similarly, each item has
latent characteristics that describe users' willingness to travel to the
restaurant, and each user has individual-specific preferences for those latent
characteristics. Thus, both users' willingness to travel and their base utility
for each restaurant vary across user-restaurant pairs. We use a Bayesian
approach to estimation. To make the estimation computationally feasible, we
rely on variational inference to approximate the posterior distribution, as
well as stochastic gradient descent as a computational approach. Our model
performs better than more standard competing models such as multinomial logit
and nested logit models, in part due to the personalization of the estimates.
We analyze how consumers re-allocate their demand after a restaurant closes to
nearby restaurants versus more distant restaurants with similar
characteristics, and we compare our predictions to actual outcomes. Finally, we
show how the model can be used to analyze counterfactual questions such as what
type of restaurant would attract the most consumers in a given location.
</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07827</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Supervised Convolutional Neural Networks for Human Activity
  Recognition</dc:title>
 <dc:creator>Zeng, Ming</dc:creator>
 <dc:creator>Yu, Tong</dc:creator>
 <dc:creator>Wang, Xiao</dc:creator>
 <dc:creator>Nguyen, Le T.</dc:creator>
 <dc:creator>Mengshoel, Ole J.</dc:creator>
 <dc:creator>Lane, Ian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Labeled data used for training activity recognition classifiers are usually
limited in terms of size and diversity. Thus, the learned model may not
generalize well when used in real-world use cases. Semi-supervised learning
augments labeled examples with unlabeled examples, often resulting in improved
performance. However, the semi-supervised methods studied in the activity
recognition literatures assume that feature engineering is already done. In
this paper, we lift this assumption and present two semi-supervised methods
based on convolutional neural networks (CNNs) to learn discriminative hidden
features. Our semi-supervised CNNs learn from both labeled and unlabeled data
while also performing feature learning on raw sensor data. In experiments on
three real world datasets, we show that our CNNs outperform supervised methods
and traditional semi-supervised learning methods by up to 18% in mean F1-score
(Fm).
</dc:description>
 <dc:description>Comment: Accepted by BigData2017</dc:description>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07829</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Graph CNN for Learning on Point Clouds</dc:title>
 <dc:creator>Wang, Yue</dc:creator>
 <dc:creator>Sun, Yongbin</dc:creator>
 <dc:creator>Liu, Ziwei</dc:creator>
 <dc:creator>Sarma, Sanjay E.</dc:creator>
 <dc:creator>Bronstein, Michael M.</dc:creator>
 <dc:creator>Solomon, Justin M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Point clouds provide a flexible and scalable geometric representation
suitable for countless applications in computer graphics; they also comprise
the raw output of most 3D data acquisition devices. Hence, the design of
intelligent computational models that act directly on point clouds is critical,
especially when efficiency considerations or noise preclude the possibility of
expensive denoising and meshing procedures. While hand-designed features on
point clouds have long been proposed in graphics and vision, however, the
recent overwhelming success of convolutional neural networks (CNNs) for image
analysis suggests the value of adapting insight from CNN to the point cloud
world. To this end, we propose a new neural network module dubbed EdgeConv
suitable for CNN-based high-level tasks on point clouds including
classification and segmentation. EdgeConv is differentiable and can be plugged
into existing architectures. Compared to existing modules operating largely in
extrinsic space or treating each point independently, EdgeConv has several
appealing properties: It incorporates local neighborhood information; it can be
stacked or recurrently applied to learn global shape properties; and in
multi-layer systems affinity in feature space captures semantic characteristics
over potentially long distances in the original embedding. Beyond proposing
this module, we provide extensive evaluation and analysis revealing that
EdgeConv captures and exploits fine-grained geometric properties of point
clouds. The proposed approach achieves state-of-the-art performance on standard
benchmarks including ModelNet40 and S3DIS.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07839</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random linear binary codes have smaller list sizes than uniformly random
  binary codes</dc:title>
 <dc:creator>Li, Ray</dc:creator>
 <dc:creator>Wootters, Mary</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  There has been a great deal of work establishing that random linear codes are
as list-decodable as uniformly random codes, in the sense that a random linear
binary code of rate $1 - H(p) - \epsilon$ is
$(p,O(1/\epsilon))$-list-decodable. In this work, we show that in fact random
linear binary codes are \em more \em list-decodable than uniformly random
codes, in the sense that the constant in the $O(1/\epsilon)$ is strictly
smaller for random linear codes than for uniformly random codes.
  For our upper bound on the list size of random linear codes, we strengthen an
existential argument of (Guruswami, H{\aa}stad, Sudan and Zuckerman, IEEE
Trans. IT, 2002) to hold with high probability. In addition to improving known
list-size bounds, our argument works simultaneously for all values of $p$,
while previous works obtaining $L = O(1/\epsilon)$ patched together different
arguments to cover different parameter regimes. To complement our upper bound
for random linear codes, we also improve an argument of (Guruswami, Narayanan,
IEEE Trans. IT, 2014) to obtain an essentially tight lower bound on the list
size of uniformly random codes.
  To demonstrate the applicability of these techniques, we use them to (a)
obtain more information about the distribution of list sizes of random linear
codes and (b) to prove a similar result for random linear rank-metric codes.
More precisely, we prove that in some parameter regimes, random linear
rank-metric codes have strictly smaller list sizes than uniformly random
rank-metric codes; our upper bound improves upon a recent result of Guruswami
and Resch, and we prove a new lower bound on the list size for uniformly rank
metric codes.
</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07844</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Server-Aided Revocable Predicate Encryption: Formalization and
  Lattice-Based Instantiation</dc:title>
 <dc:creator>Ling, San</dc:creator>
 <dc:creator>Nguyen, Khoa</dc:creator>
 <dc:creator>Wang, Huaxiong</dc:creator>
 <dc:creator>Zhang, Juanyang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Efficient user revocation is a necessary but challenging problem in many
multi-user cryptosystems. Among known approaches, server-aided revocation
yields a promising solution, because it allows to outsource the major workloads
of system users to a computationally powerful third party, called the server,
whose only requirement is to carry out the computations correctly. Such a
revocation mechanism was considered in the settings of identity-based
encryption and attribute-based encryption by Qin et al. (ESORICS 2015) and Cui
et al. (ESORICS 2016), respectively.
  In this work, we consider the server-aided revocation mechanism in the more
elaborate setting of predicate encryption (PE). The latter, introduced by Katz,
Sahai, and Waters (EUROCRYPT 2008), provides fine-grained and role-based access
to encrypted data and can be viewed as a generalization of identity-based and
attribute-based encryption. Our contribution is two-fold. First, we formalize
the model of server-aided revocable predicate encryption (SR-PE), with rigorous
definitions and security notions. Our model can be seen as a non-trivial
adaptation of Cui et al.'s work into the PE context. Second, we put forward a
lattice-based instantiation of SR-PE. The scheme employs the PE scheme of
Agrawal, Freeman and Vaikuntanathan (ASIACRYPT 2011) and the complete subtree
method of Naor, Naor, and Lotspiech (CRYPTO 2001) as the two main ingredients,
which work smoothly together thanks to a few additional techniques. Our scheme
is proven secure in the standard model (in a selective manner), based on the
hardness of the Learning With Errors (LWE) problem.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07848</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feeding Hand-Crafted Features for Enhancing the Performance of
  Convolutional Neural Networks</dc:title>
 <dc:creator>Hosseini, Sepidehsadat</dc:creator>
 <dc:creator>Lee, Seok Hee</dc:creator>
 <dc:creator>Cho, Nam Ik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Since the convolutional neural network (CNN) is be- lieved to find right
features for a given problem, the study of hand-crafted features is somewhat
neglected these days. In this paper, we show that finding an appropriate
feature for the given problem may be still important as they can en- hance the
performance of CNN-based algorithms. Specif- ically, we show that feeding an
appropriate feature to the CNN enhances its performance in some face related
works such as age/gender estimation, face detection and emotion recognition. We
use Gabor filter bank responses for these tasks, feeding them to the CNN along
with the input image. The stack of image and Gabor responses can be fed to the
CNN as a tensor input, or as a fused image which is a weighted sum of image and
Gabor responses. The Gabor filter parameters can also be tuned depending on the
given problem, for increasing the performance. From the extensive experiments,
it is shown that the proposed methods provide better performance than the
conventional CNN-based methods that use only the input images.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07853</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Triplet Learning with POS-tag Guided Attention for Visual
  Question Answering</dc:title>
 <dc:creator>Wang, Zhe</dc:creator>
 <dc:creator>Liu, Xiaoyi</dc:creator>
 <dc:creator>Chen, Liangjian</dc:creator>
 <dc:creator>Wang, Limin</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:creator>Xie, Xiaohui</dc:creator>
 <dc:creator>Fowlkes, Charless</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual question answering (VQA) is of significant interest due to its
potential to be a strong test of image understanding systems and to probe the
connection between language and vision. Despite much recent progress, general
VQA is far from a solved problem. In this paper, we focus on the VQA
multiple-choice task, and provide some good practices for designing an
effective VQA model that can capture language-vision interactions and perform
joint reasoning. We explore mechanisms of incorporating part-of-speech (POS)
tag guided attention, convolutional n-grams, triplet attention interactions
between the image, question and candidate answer, and structured learning for
triplets based on image-question pairs. We evaluate our models on two popular
datasets: Visual7W and VQA Real Multiple Choice. Our final model achieves the
state-of-the-art performance of 68.2% on Visual7W, and a very competitive
performance of 69.6% on the test-standard split of VQA Real Multiple Choice.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, state-of-the-art VQA system;
  https://github.com/wangzheallen/STL-VQA</dc:description>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07860</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable and accurate deep learning for electronic health records</dc:title>
 <dc:creator>Rajkomar, Alvin</dc:creator>
 <dc:creator>Oren, Eyal</dc:creator>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:creator>Dai, Andrew M.</dc:creator>
 <dc:creator>Hajaj, Nissan</dc:creator>
 <dc:creator>Liu, Peter J.</dc:creator>
 <dc:creator>Liu, Xiaobing</dc:creator>
 <dc:creator>Sun, Mimi</dc:creator>
 <dc:creator>Sundberg, Patrik</dc:creator>
 <dc:creator>Yee, Hector</dc:creator>
 <dc:creator>Zhang, Kun</dc:creator>
 <dc:creator>Duggan, Gavin E.</dc:creator>
 <dc:creator>Flores, Gerardo</dc:creator>
 <dc:creator>Hardt, Michaela</dc:creator>
 <dc:creator>Irvine, Jamie</dc:creator>
 <dc:creator>Le, Quoc</dc:creator>
 <dc:creator>Litsch, Kurt</dc:creator>
 <dc:creator>Marcus, Jake</dc:creator>
 <dc:creator>Mossin, Alexander</dc:creator>
 <dc:creator>Tansuwan, Justin</dc:creator>
 <dc:creator>Wang, De</dc:creator>
 <dc:creator>Wexler, James</dc:creator>
 <dc:creator>Wilson, Jimbo</dc:creator>
 <dc:creator>Ludwig, Dana</dc:creator>
 <dc:creator>Volchenboum, Samuel L.</dc:creator>
 <dc:creator>Chou, Katherine</dc:creator>
 <dc:creator>Pearson, Michael</dc:creator>
 <dc:creator>Madabushi, Srinivasan</dc:creator>
 <dc:creator>Shah, Nigam H.</dc:creator>
 <dc:creator>Butte, Atul J.</dc:creator>
 <dc:creator>Howell, Michael</dc:creator>
 <dc:creator>Cui, Claire</dc:creator>
 <dc:creator>Corrado, Greg</dc:creator>
 <dc:creator>Dean, Jeff</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Predictive modeling with electronic health record (EHR) data is anticipated
to drive personalized medicine and improve healthcare quality. Constructing
predictive statistical models typically requires extraction of curated
predictor variables from normalized EHR data, a labor-intensive process that
discards the vast majority of information in each patient's record. We propose
a representation of patients' entire, raw EHR records based on the Fast
Healthcare Interoperability Resources (FHIR) format. We demonstrate that deep
learning methods using this representation are capable of accurately predicting
multiple medical events from multiple centers without site-specific data
harmonization. We validated our approach using de-identified EHR data from two
U.S. academic medical centers with 216,221 adult patients hospitalized for at
least 24 hours. In the sequential format we propose, this volume of EHR data
unrolled into a total of 46,864,534,945 data points, including clinical notes.
Deep learning models achieved high accuracy for tasks such as predicting
in-hospital mortality (AUROC across sites 0.93-0.94), 30-day unplanned
readmission (AUROC 0.75-0.76), prolonged length of stay (AUROC 0.85-0.86), and
all of a patient's final discharge diagnoses (frequency-weighted AUROC 0.90).
These models outperformed state-of-the-art traditional predictive models in all
cases. We also present a case-study of a neural-network attribution system,
which illustrates how clinicians can gain some transparency into the
predictions. We believe that this approach can be used to create accurate and
scalable predictions for a variety of clinical scenarios, complete with
explanations that directly highlight evidence in the patient's chart.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07861</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Review Representations with User Attention and Product
  Attention for Sentiment Classification</dc:title>
 <dc:creator>Wu, Zhen</dc:creator>
 <dc:creator>Dai, Xin-Yu</dc:creator>
 <dc:creator>Yin, Cunyan</dc:creator>
 <dc:creator>Huang, Shujian</dc:creator>
 <dc:creator>Chen, Jiajun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural network methods have achieved great success in reviews sentiment
classification. Recently, some works achieved improvement by incorporating user
and product information to generate a review representation. However, in
reviews, we observe that some words or sentences show strong user's preference,
and some others tend to indicate product's characteristic. The two kinds of
information play different roles in determining the sentiment label of a
review. Therefore, it is not reasonable to encode user and product information
together into one representation. In this paper, we propose a novel framework
to encode user and product information. Firstly, we apply two individual
hierarchical neural networks to generate two representations, with user
attention or with product attention. Then, we design a combined strategy to
make full use of the two representations for training and final prediction. The
experimental results show that our model obviously outperforms other
state-of-the-art methods on IMDB and Yelp datasets. Through the visualization
of attention over words related to user or product, we validate our observation
mentioned above.
</dc:description>
 <dc:description>Comment: Accepted by AAAI-18</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07862</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Downlink Power Control in Massive MIMO Networks with Distributed Antenna
  Arrays</dc:title>
 <dc:creator>Akbar, Noman</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate downlink power control in massive
multiple-input multiple-output (MIMO) networks with distributed antenna arrays.
The base station (BS) in each cell consists of multiple antenna arrays, which
are deployed in arbitrary locations within the cell. Due to the spatial
separation between antenna arrays, the large-scale propagation effect is
different from a user to different antenna arrays in a cell, which makes power
control a challenging problem as compared to conventional massive MIMO. We
assume that the BS in each cell obtains the channel estimates via uplink
pilots. Based on the channel estimates, the BSs perform maximum ratio
transmission for the downlink. We then derive a closed-form spectral efficiency
(SE) expression, where the channels are subject to correlated fading. Utilizing
the derived expression, we propose a max-min power control algorithm to ensure
that each user in the network receives a uniform quality of service. Numerical
results demonstrate that, for the network considered in this work, optimizing
for max-min SE through the max-min power control improves the sum SE of the
network as compared to equal power allocation.
</dc:description>
 <dc:description>Comment: Accepted to appear in ICC 2018, Kansas City, MO</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07863</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opinion Dynamics with Varying Susceptibility to Persuasion</dc:title>
 <dc:creator>Abebe, Rediet</dc:creator>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:creator>Parkes, David</dc:creator>
 <dc:creator>Tsourakakis, Charalampos E.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A long line of work in social psychology has studied variations in people's
susceptibility to persuasion -- the extent to which they are willing to modify
their opinions on a topic. This body of literature suggests an interesting
perspective on theoretical models of opinion formation by interacting parties
in a network: in addition to considering interventions that directly modify
people's intrinsic opinions, it is also natural to consider interventions that
modify people's susceptibility to persuasion. In this work, we adopt a popular
model for social opinion dynamics, and we formalize the opinion maximization
and minimization problems where interventions happen at the level of
susceptibility.
  We show that modeling interventions at the level of susceptibility lead to an
interesting family of new questions in network opinion dynamics. We find that
the questions are quite different depending on whether there is an overall
budget constraining the number of agents we can target or not. We give a
polynomial-time algorithm for finding the optimal target-set to optimize the
sum of opinions when there are no budget constraints on the size of the
target-set. We show that this problem is NP-hard when there is a budget, and
that the objective function is neither submodular nor supermodular. Finally, we
propose a heuristic for the budgeted opinion optimization and show its efficacy
at finding target-sets that optimize the sum of opinions compared on real world
networks, including a Twitter network with real opinion estimates.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07864</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Behavior Trees as a Representation for Medical Procedures</dc:title>
 <dc:creator>Hannaford, Blake</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Behavior trees (BTs) emerged from video game development as a graphical
language for modeling intelligent agent behavior. BTs have several properties
which are attractive for modeling medical procedures including
human-readability, authoring tools, and composability. This paper will
illustrate construction of BTs for exemplary medical procedures. We are pleased
to acknowledge support from National Science Foundation grant #IIS-1637444 and
collaborations on that project with Johns Hopkins University and Worcester
Polytechnic Institute.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, 22 references</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07865</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Further Progress on the GM-MDS Conjecture for Reed-Solomon Codes</dc:title>
 <dc:creator>Yildiz, Hikmet</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Designing good error correcting codes whose generator matrix has a support
constraint, i.e., one for which only certain entries of the generator matrix
are allowed to be non-zero, has found many recent applications, including in
distributed coding and storage, multiple access networks, and weakly secure
data exchange. The dual problem, where the parity check matrix has a support
constraint, comes up in the design of locally repairable codes. The central
problem here is to design codes with the largest possible minimum distance,
subject to the given support constraint on the generator matrix. An upper bound
on the minimum distance can be obtained through a set of singleton bounds,
which can be alternatively thought of as a cut-set bound. Furthermore, it is
well known that, if the field size is large enough, any random generator matrix
obeying the support constraint will achieve the maximum minimum distance with
high probability. Since random codes are not easy to decode, structured codes
with efficient decoders, e.g., Reed-Solomon codes, are much more desirable. The
GM-MDS conjecture of Dau et al states that the maximum minimum distance over
all codes satisfying the generator matrix support constraint can be obtained by
a Reed Solomon code. If true, this would have significant consequences. The
conjecture has been proven for several special case: when the dimension of the
code k is less than or equal to five, when the number of distinct support sets
on the rows of the generator matrix m, say, is less than or equal to three, or
when the generator matrix is sparsest and balanced. In this paper, we report on
further progress on the GM-MDS conjecture. In particular, we show that the
conjecture is true for all m less than equal to six. This generalizes all
previous known results (except for the sparsest and balanced case, which is a
very special support constraint).
</dc:description>
 <dc:description>Comment: Submitted to ISIT 2018</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07875</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Support Vector Machine Active Learning Algorithms with
  Query-by-Committee versus Closest-to-Hyperplane Selection</dc:title>
 <dc:creator>Bloodgood, Michael</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  This paper investigates and evaluates support vector machine active learning
algorithms for use with imbalanced datasets, which commonly arise in many
applications such as information extraction applications. Algorithms based on
closest-to-hyperplane selection and query-by-committee selection are combined
with methods for addressing imbalance such as positive amplification based on
prevalence statistics from initial random samples. Three algorithms (ClosestPA,
QBagPA, and QBoostPA) are presented and carefully evaluated on datasets for
text classification and relation extraction. The ClosestPA algorithm is shown
to consistently outperform the other two in a variety of ways and insights are
provided as to why this is the case.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures, 3 tables; to appear in Proceedings of the IEEE
  12th International Conference on Semantic Computing (ICSC 2018), Laguna
  Hills, California, 2018</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07877</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Spectrum Sharing with ARQ based Legacy Users via Chain Decoding</dc:title>
 <dc:creator>Michelusi, Nicolo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the design of access policies in spectrum sharing
networks by exploiting the retransmission protocol of legacy primary users
(PUs) to improve the spectral efficiency via opportunistic retransmissions at
secondary users (SUs) and chain decoding [1]. The optimal access policy which
maximizes the SU throughput under a maximum interference constraint to the PU
and its performance are found in closed form. It is shown that the optimal
policy randomizes among three modes: 1) Idle: the SU remains idle over the
retransmission window of the PU, to avoid interfering; 2) Interference
cancellation: the SU transmits only after decoding the PU packet, to improve
its own throughput via interference cancellation; 3) Always transmit: the SU
transmits over the retransmission window of the PU to maximize the future
potential of interference cancellation via chain decoding. This structure is
exploited to design a stochastic gradient descent algorithm to facilitate
learning and adaptation in settings where the model parameters are unknown or
vary over time, based on ARQ feedback from the PU and CSI measurements at the
SU receiver. It is shown numerically that, for a 10\% interference constraint,
the optimal access policy yields 15\% improvement over a state-of-the-art
scheme without selective SU retransmissions, and up to $2\times$ gain over a
scheme using a non-adaptive access policy instead of the optimal one.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07880</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>vLibOS: Babysitting OS Evolution with a Virtualized Library OS</dc:title>
 <dc:creator>Ye, Ying</dc:creator>
 <dc:creator>Cheng, Zhuoqun</dc:creator>
 <dc:creator>Sinha, Soham</dc:creator>
 <dc:creator>West, Richard</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Many applications have service requirements that are not easily met by
existing operating systems. Real-time and security-critical tasks, for example,
often require custom OSes to meet their needs. However, development of special
purpose OSes is a time-consuming and difficult exercise. Drivers, libraries and
applications have to be written from scratch or ported from existing sources.
Many researchers have tackled this problem by developing ways to extend
existing systems with application-specific services. However, it is often
difficult to ensure an adequate degree of separation between legacy and new
services, especially when security and timing requirements are at stake.
Virtualization, for example, supports logical isolation of separate guest
services, but suffers from inadequate temporal isolation of time-critical code
required for real-time systems. This paper presents vLibOS, a master-slave
paradigm for new systems, whose services are built on legacy code that is
temporally and spatially isolated in separate VM domains. Existing OSes are
treated as sandboxed libraries, providing legacy services that are requested by
inter-VM calls, which execute with the time budget of the caller. We evaluate a
real-time implementation of vLibOS. Empirical results show that vLibOS achieves
as much as a 50\% reduction in performance slowdown for real-time threads, when
competing for a shared memory bus with a Linux VM.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07883</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Sentiment Analysis : A Survey</dc:title>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:creator>Wang, Shuai</dc:creator>
 <dc:creator>Liu, Bing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning has emerged as a powerful machine learning technique that
learns multiple layers of representations or features of the data and produces
state-of-the-art prediction results. Along with the success of deep learning in
many other application domains, deep learning is also popularly used in
sentiment analysis in recent years. This paper first gives an overview of deep
learning and then provides a comprehensive survey of its current applications
in sentiment analysis.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07884</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Pilot and Payload Power Control for Uplink MIMO-NOMA with MRC-SIC
  Receivers</dc:title>
 <dc:creator>Wei, Zhiqiang</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Yuan, Jinhong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter proposes a joint pilot and payload power allocation (JPA) scheme
to mitigate the error propagation problem for uplink multiple-input
multiple-output non-orthogonal multiple access (MIMO-NOMA) systems. A base
station equipped with a maximum ratio combining and successive interference
cancellation (MRC-SIC) receiver is adopted for multiuser detection. The average
signal-to-interference-plus-noise ratio (ASINR) of each user during the MRC-SIC
decoding is analyzed by taking into account the error propagation due to the
channel estimation error. Furthermore, the JPA design is formulated as a
nonconvex optimization problem to maximize the minimum weighted ASINR and is
solved optimally with geometric programming. Simulation results confirm the
developed performance analysis and show that our proposed scheme can
effectively alleviate the error propagation of MRC-SIC and enhance the
detection performance, especially for users with moderate energy budgets.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, accepted in IEEE Communications Letters</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07887</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Batch Size on Stopping Active Learning for Text Classification</dc:title>
 <dc:creator>Beatty, Garrett</dc:creator>
 <dc:creator>Kochis, Ethan</dc:creator>
 <dc:creator>Bloodgood, Michael</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  When using active learning, smaller batch sizes are typically more efficient
from a learning efficiency perspective. However, in practice due to speed and
human annotator considerations, the use of larger batch sizes is necessary.
While past work has shown that larger batch sizes decrease learning efficiency
from a learning curve perspective, it remains an open question how batch size
impacts methods for stopping active learning. We find that large batch sizes
degrade the performance of a leading stopping method over and above the
degradation that results from reduced learning efficiency. We analyze this
degradation and find that it can be mitigated by changing the window size
parameter of how many past iterations of learning are taken into account when
making the stopping decision. We find that when using larger batch sizes,
stopping methods are more effective when smaller window sizes are used.
</dc:description>
 <dc:description>Comment: 2 pages, 1 table; to appear in Proceedings of the IEEE 12th
  International Conference on Semantic Computing (ICSC 2018), Laguna Hills,
  California, 2018</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07889</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theoretical Investigation of Graph Degree as an Unsupervised Normality
  Measure</dc:title>
 <dc:creator>Aytekin, Caglar</dc:creator>
 <dc:creator>Cricri, Francesco</dc:creator>
 <dc:creator>Fan, Lixin</dc:creator>
 <dc:creator>Aksu, Emre</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For a graph representation of a dataset, a straightforward normality measure
for a sample can be its graph degree. Considering a weighted graph, degree of a
sample corresponds to sum the corresponding row's values in a similarity
matrix. The measure is intuitive given the abnormal samples are usually rare
and they are dissimilar to the rest of the data. In order to have an in-depth
theoretical understanding, in this manuscript, we investigate the graph degree
in spectral graph clustering based and kernel based point of views and draw
connections to a recent kernel method for the two sample problem. We show that
our analyses guide us to choose fully-connected graphs whose edge weights are
calculated via universal kernels. We show that a simple graph degree based
unsupervised anomaly detection method with the above properties, achieves
higher accuracy compared to other unsupervised anomaly detection methods on
average over 10 widely used datasets. We also provide an extensive analysis on
the effect of the kernel parameter on the method's accuracy.
</dc:description>
 <dc:description>Comment: Submitted to IJCAI 2018</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07892</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Image Inpainting with Contextual Attention</dc:title>
 <dc:creator>Yu, Jiahui</dc:creator>
 <dc:creator>Lin, Zhe</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Lu, Xin</dc:creator>
 <dc:creator>Huang, Thomas S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Recent deep learning based approaches have shown promising results on image
inpainting for the challenging task of filling in large missing regions in an
image. These methods can generate visually plausible image structures and
textures, but often create distorted structures or blurry textures inconsistent
with surrounding areas. This is mainly due to ineffectiveness of convolutional
neural networks in explicitly borrowing or copying information from distant
spatial locations. On the other hand, traditional texture and patch synthesis
approaches are particularly suitable when it needs to borrow textures from the
surrounding regions. Motivated by these observations, we propose a new deep
generative model-based approach which can not only synthesize novel image
structures but also explicitly utilize surrounding image features as references
during network training to make better predictions. The model is a
feed-forward, fully convolutional neural network which can process images with
multiple holes at arbitrary locations and with variable sizes during the test
time. Experiments on multiple datasets including faces, textures and natural
images demonstrate that the proposed approach generates higher-quality
inpainting results than existing ones. Code and trained models will be
released.
</dc:description>
 <dc:description>Comment: technical report</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07899</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UAV Visual Teach and Repeat Using Only Semantic Object Features</dc:title>
 <dc:creator>Toudeshki, Amirmasoud Ghasemi</dc:creator>
 <dc:creator>Shamshirdar, Faraz</dc:creator>
 <dc:creator>Vaughan, Richard</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We demonstrate the use of semantic object detections as robust features for
Visual Teach and Repeat (VTR). Recent CNN-based object detectors are able to
reliably detect objects of tens or hundreds of categories in a video at frame
rates. We show that such detections are repeatable enough to use as landmarks
for VTR, without any low-level image features. Since object detections are
highly invariant to lighting and surface appearance changes, our VTR can cope
with global lighting changes and local movements of the landmark objects. In
the teaching phase, we build a series of compact scene descriptors: a list of
detected object labels and their image-plane locations. In the repeating phase,
we use Seq-SLAM-like relocalization to identify the most similar learned scene,
then use a motion control algorithm based on the funnel lane theory to navigate
the robot along the previously piloted trajectory. We evaluate the method on a
commodity UAV, examining the robustness of the algorithm to new viewpoints,
lighting conditions, and movements of landmark objects. The results suggest
that semantic object features could be useful due to their invariance to
superficial appearance changes compared to low-level image features.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07910</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Waveform Modeling and Generation Using Hierarchical Recurrent Neural
  Networks for Speech Bandwidth Extension</dc:title>
 <dc:creator>Ling, Zhen-Hua</dc:creator>
 <dc:creator>Ai, Yang</dc:creator>
 <dc:creator>Gu, Yu</dc:creator>
 <dc:creator>Dai, Li-Rong</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  This paper presents a waveform modeling and generation method using
hierarchical recurrent neural networks (HRNN) for speech bandwidth extension
(BWE). Different from conventional BWE methods which predict spectral
parameters for reconstructing wideband speech waveforms, this BWE method models
and predicts waveform samples directly without using vocoders. Inspired by
SampleRNN which is an unconditional neural audio generator, the HRNN model
represents the distribution of each wideband or high-frequency waveform sample
conditioned on the input narrowband waveform samples using a neural network
composed of long short-term memory (LSTM) layers and feed-forward (FF) layers.
The LSTM layers form a hierarchical structure and each layer operates at a
specific temporal resolution to efficiently capture long-span dependencies
between temporal sequences. Furthermore, additional conditions, such as the
bottleneck (BN) features derived from narrowband speech using a deep neural
network (DNN)-based state classifier, are employed as auxiliary input to
further improve the quality of generated wideband speech. The experimental
results of comparing several waveform modeling methods show that the HRNN-based
method can achieve better speech quality and run-time efficiency than the
dilated convolutional neural network (DCNN)-based method and the plain
sample-level recurrent neural network (SRNN)-based method. Our proposed method
also outperforms the conventional vocoder-based BWE method using LSTM-RNNs in
terms of the subjective quality of the reconstructed wideband speech.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Audio, Speech and Language
  Processing</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07910</dc:identifier>
 <dc:identifier>doi:10.1109/TASLP.2018.2798811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07912</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine learning in APOGEE: Unsupervised spectral classification with
  $K$-means</dc:title>
 <dc:creator>Garcia-Dias, Rafael</dc:creator>
 <dc:creator>Prieto, Carlos Allende</dc:creator>
 <dc:creator>Almeida, Jorge S&#xe1;nchez</dc:creator>
 <dc:creator>Ordov&#xe1;s-Pascual, Ignacio</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Astrophysics - Astrophysics of Galaxies</dc:subject>
 <dc:subject>Astrophysics - Solar and Stellar Astrophysics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The data volume generated by astronomical surveys is growing rapidly.
Traditional analysis techniques in spectroscopy either demand intensive human
interaction or are computationally expensive. In this scenario, machine
learning, and unsupervised clustering algorithms in particular offer
interesting alternatives. The Apache Point Observatory Galactic Evolution
Experiment (APOGEE) offers a vast data set of near-infrared stellar spectra
which is perfect for testing such alternatives. Apply an unsupervised
classification scheme based on $K$-means to the massive APOGEE data set.
Explore whether the data are amenable to classification into discrete classes.
We apply the $K$-means algorithm to 153,847 high resolution spectra
($R\approx22,500$). We discuss the main virtues and weaknesses of the
algorithm, as well as our choice of parameters. We show that a classification
based on normalised spectra captures the variations in stellar atmospheric
parameters, chemical abundances, and rotational velocity, among other factors.
The algorithm is able to separate the bulge and halo populations, and
distinguish dwarfs, sub-giants, RC and RGB stars. However, a discrete
classification in flux space does not result in a neat organisation in the
parameters space. Furthermore, the lack of obvious groups in flux space causes
the results to be fairly sensitive to the initialisation, and disrupts the
efficiency of commonly-used methods to select the optimal number of clusters.
Our classification is publicly available, including extensive online material
associated with the APOGEE Data Release 12 (DR12). Our description of the
APOGEE database can enormously help with the identification of specific types
of targets for various applications. We find a lack of obvious groups in flux
space, and identify limitations of the $K$-means algorithm in dealing with this
kind of data.
</dc:description>
 <dc:description>Comment: 23 pages, 24 images and online material</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07936</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anticipating epileptic seizures through the analysis of EEG
  synchronization as a data classification problem</dc:title>
 <dc:creator>Detti, Paolo</dc:creator>
 <dc:creator>de Lara, Garazi Zabalo Manrique</dc:creator>
 <dc:creator>Bruni, Renato</dc:creator>
 <dc:creator>Pranzo, Marco</dc:creator>
 <dc:creator>Sarnari, Francesco</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Epilepsy is a neurological disorder arising from anomalies of the electrical
activity in the brain, affecting about 0.5--0.8\% of the world population.
Several studies investigated the relationship between seizures and brainwave
synchronization patterns, pursuing the possibility of identifying interictal,
preictal, ictal and postictal states. In this work, we introduce a graph-based
model of the brain interactions developed to study synchronization patterns in
the electroencephalogram (EEG) signals. The aim is to develop a
patient-specific approach, also for a real-time use, for the prediction of
epileptic seizures' occurrences. Different synchronization measures of the EEG
signals and easily computable functions able to capture in real-time the
variations of EEG synchronization have been considered. Both standard and
ad-hoc classification algorithms have been developed and used. Results on scalp
EEG signals show that this simple and computationally viable processing is able
to highlight the changes in the synchronization corresponding to the preictal
state.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07937</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrality Gaps for Bounded Color Matchings</dc:title>
 <dc:creator>Kelk, Steven</dc:creator>
 <dc:creator>Stamoulis, Georgios</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We investigate the performance of two common lift-and-project techniques, the
Sherali-Adams (SA) and the Balas, Ceria and Cornu\'ejols (BCC) hierarchies, on
the natural linear relaxation of the Bounded Color Matching polyhedron and
generalizations. We prove the following unconditional inapproximability
results: even a large family of linear programs, generated by an asymptotically
linear number of rounds of the Sherali-Adams hierarchy or a linear number of
rounds of the BCC hierarchy, is not enough to improve the integrality gap of
the natural LP relaxation even in bipartite graphs. We complement these results
by showing in a non-algorithmic way that if we exclude certain sub-structures
from our instance graphs, then the integrality gap of the natural linear
formulation improves.
</dc:description>
 <dc:description>Comment: 19 pages, 1 Figure</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07939</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Structured Energy-Based Image Inpainting</dc:title>
 <dc:creator>Altinel, Fazil</dc:creator>
 <dc:creator>Ozay, Mete</dc:creator>
 <dc:creator>Okatani, Takayuki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a structured image inpainting method employing an
energy based model. In order to learn structural relationship between patterns
observed in images and missing regions of the images, we employ an energy-based
structured prediction method. The structural relationship is learned by
minimizing an energy function which is defined by a simple convolutional neural
network. The experimental results on various benchmark datasets show that our
proposed method significantly outperforms the state-of-the-art methods which
use Generative Adversarial Networks (GANs). We obtained 497.35 mean squared
error (MSE) on the Olivetti face dataset compared to 833.0 MSE provided by the
state-of-the-art method. Moreover, we obtained 28.4 dB peak signal to noise
ratio (PSNR) on the SVHN dataset and 23.53 dB on the CelebA dataset, compared
to 22.3 dB and 21.3 dB, provided by the state-of-the-art methods, respectively.
The code is publicly available.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07945</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Filtering with Unknown Sensor Measurement Losses</dc:title>
 <dc:creator>Zhang, Jiaqi</dc:creator>
 <dc:creator>You, Keyou</dc:creator>
 <dc:creator>Xie, Lihua</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This work studies the state estimation problem of a stochastic nonlinear
system with unknown sensor measurement losses. If the estimator knows the
sensor measurement losses of a linear Gaussian system, the minimum variance
estimate is easily computed by the celebrated intermittent Kalman filter (IKF).
However, this will no longer be the case when the measurement losses are
unknown and/or the system is nonlinear or non-Gaussian. By exploiting the
binary property of the measurement loss process and the IKF, we design three
suboptimal filters for the state estimation, i.e., BKF-I, BKF-II and RBPF. The
BKF-I is based on the MAP estimator of the measurement loss process and the
BKF-II is derived by estimating the conditional loss probability. The RBPF is a
particle filter based algorithm which marginalizes out the loss process to
increase the efficiency of particles. All the proposed filters can be easily
implemented in recursive forms. Finally, a linear system, a target tracking
system and a quadrotor's path control problem are included to illustrate their
effectiveness, and show the tradeoff between computational complexity and
estimation accuracy of the proposed filters.
</dc:description>
 <dc:description>Comment: Conditionally accepted by IEEE TCNS</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07947</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TritanDB: Time-series Rapid Internet of Things Analytics</dc:title>
 <dc:creator>Siow, Eugene</dc:creator>
 <dc:creator>Tiropanis, Thanassis</dc:creator>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Hall, Wendy</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The efficient management of data is an important prerequisite for realising
the potential of the Internet of Things (IoT). Two issues given the large
volume of structured time-series IoT data are, addressing the difficulties of
data integration between heterogeneous Things and improving ingestion and query
performance across databases on both resource-constrained Things and in the
cloud. In this paper, we examine the structure of public IoT data and discover
that the majority exhibit unique flat, wide and numerical characteristics with
a mix of evenly and unevenly-spaced time-series. We investigate the advances in
time-series databases for telemetry data and combine these findings with
microbenchmarks to determine the best compression techniques and storage data
structures to inform the design of a novel solution optimised for IoT data. A
query translation method with low overhead even on resource-constrained Things
allows us to utilise rich data models like the Resource Description Framework
(RDF) for interoperability and data integration on top of the optimised
storage. Our solution, TritanDB, shows an order of magnitude performance
improvement across both Things and cloud hardware on many state-of-the-art
databases within IoT scenarios. Finally, we describe how TritanDB supports
various analyses of IoT time-series data like forecasting.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07948</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical observations of ultraslow diffusion driven by the fractional
  dynamics in languages: Dynamical statistical properties of word counts of
  already popular words</dc:title>
 <dc:creator>Watanabe, Hayafumi</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Ultraslow diffusion (i.e. logarithmic diffusion) has been extensively studied
theoretically, but has hardly been observed empirically. In this paper,
firstly, we find the ultraslow-like diffusion of the time-series of word counts
of already popular words by analysing three different nationwide language
databases: (i) newspaper articles (Japanese), (ii) blog articles (Japanese),
and (iii) page views of Wikipedia (English, French, Chinese, and Japanese).
Secondly, we use theoretical analysis to show that this diffusion is basically
explained by the random walk model with the power-law forgetting with the
exponent $\beta \approx 0.5$, which is related to the fractional Langevin
equation. The exponent $\beta$ characterises the speed of forgetting and $\beta
\approx 0.5$ corresponds to (i) the border (or thresholds) between the
stationary and the nonstationary and (ii) the right-in-the-middle dynamics
between the IID noise for $\beta=1$ and the normal random walk for $\beta=0$.
Thirdly, the generative model of the time-series of word counts of already
popular words, which is a kind of Poisson process with the Poisson parameter
sampled by the above-mentioned random walk model, can almost reproduce not only
the empirical mean-squared displacement but also the power spectrum density and
the probability density function.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07954</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Block SOS Decomposition</dc:title>
 <dc:creator>Li, Haokun</dc:creator>
 <dc:creator>Xia, Bican</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  A widely used method for solving SOS (Sum Of Squares) decomposition problem
is to reduce it to the problem of semi-definite programs (SDPs) which can be
efficiently solved in theory. In practice, although many SDP solvers can work
out some problems of big scale, the efficiency and reliability of such method
decrease greatly while the input size increases. Recently, by exploiting the
sparsity of the input SOS decomposition problem, some preprocessing algorithms
were proposed [5,17], which first divide the input problem satisfying special
definitions or properties into smaller SDP problems and then pass the smaller
ones to SDP solvers to obtain reliable results efficiently. A natural question
is that to what extent the above mentioned preprocessing algorithms work. That
is, how many polynomials satisfying those definitions or properties are there
in the SOS polynomials? In this paper, we define a concept of block SOS
decomposable polynomials which is a generalization of those special classes in
[5] and [17]. Roughly speaking, it is a class of polynomials whose SOS
decomposition problem can be transformed into smaller ones (in other words, the
corresponding SDP matrices can be block-diagnolized) by considering their
supports only (coefficients are not considered). Then we prove that the set of
block SOS decomposable polynomials has measure zero in the set of SOS
polynomials. That means if we only consider supports (not with coefficients) of
polynomials, such algorithms decreasing the size of SDPs for those SDP-based
SOS solvers can only work on very few polynomials. As a result, this shows that
the SOS decomposition problems that can be optimized by the above mentioned
preprocessing algorithms are very few.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07961</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partitioning of the Free Space-Time for On-Road Navigation of Autonomous
  Ground Vehicles</dc:title>
 <dc:creator>Altch&#xe9;, Florent</dc:creator>
 <dc:creator>de La Fortelle, Arnaud</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this article, we consider the problem of trajectory planning and control
for on-road driving of an autonomous ground vehicle (AGV) in presence of static
or moving obstacles. We propose a systematic approach to partition the
collision-free portion of the space-time into convex sub-regions that can be
interpreted in terms of relative positions with respect to a set of fixed or
mobile obstacles. We show that this partitioning allows decomposing the NP-hard
problem of computing an optimal collision-free trajectory, as a path-finding
problem in a well-designed graph followed by a simple (polynomial time)
optimization phase for any quadratic convex cost function. Moreover, robustness
criteria such as margin of error while executing the trajectory can easily be
taken into account at the graph-exploration phase, thus reducing the number of
paths to explore.
</dc:description>
 <dc:description>Comment: Presented at IEEE CDC2017</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07962</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An LSTM Network for Highway Trajectory Prediction</dc:title>
 <dc:creator>Altch&#xe9;, Florent</dc:creator>
 <dc:creator>de La Fortelle, Arnaud</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In order to drive safely and efficiently on public roads, autonomous vehicles
will have to understand the intentions of surrounding vehicles, and adapt their
own behavior accordingly. If experienced human drivers are generally good at
inferring other vehicles' motion up to a few seconds in the future, most
current Advanced Driving Assistance Systems (ADAS) are unable to perform such
medium-term forecasts, and are usually limited to high-likelihood situations
such as emergency braking. In this article, we present a first step towards
consistent trajectory prediction by introducing a long short-term memory (LSTM)
neural network, which is capable of accurately predicting future longitudinal
and lateral trajectories for vehicles on highway. Unlike previous work focusing
on a low number of trajectories collected from a few drivers, our network was
trained and validated on the NGSIM US-101 dataset, which contains a total of
800 hours of recorded trajectories in various traffic densities, representing
more than 6000 individual drivers.
</dc:description>
 <dc:description>Comment: Presented at IEEE ITSC 2017</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07964</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Interactive Machine Learning Systems</dc:title>
 <dc:creator>Boukhelifa, Nadia</dc:creator>
 <dc:creator>Bezerianos, Anastasia</dc:creator>
 <dc:creator>Lutton, Evelyne</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The evaluation of interactive machine learning systems remains a difficult
task. These systems learn from and adapt to the human, but at the same time,
the human receives feedback and adapts to the system. Getting a clear
understanding of these subtle mechanisms of co-operation and co-adaptation is
challenging. In this chapter, we report on our experience in designing and
evaluating various interactive machine learning applications from different
domains. We argue for coupling two types of validation: algorithm-centered
analysis, to study the computational behaviour of the system; and
human-centered evaluation, to observe the utility and effectiveness of the
application for end-users. We use a visual analytics application for guided
search, built using an interactive evolutionary approach, as an exemplar of our
work. Our observation is that human-centered design and evaluation complement
algorithmic analysis, and can play an important role in addressing the
&quot;black-box&quot; effect of machine learning. Finally, we discuss research
opportunities that require human-computer interaction methodologies, in order
to support both the visible and hidden roles that humans play in interactive
machine learning.
</dc:description>
 <dc:description>Comment: 20</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07965</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Winning the Caucus Race: Continuous Leader Election via Public
  Randomness</dc:title>
 <dc:creator>Azouvi, Sarah</dc:creator>
 <dc:creator>McCorry, Patric</dc:creator>
 <dc:creator>Meiklejohn, Sarah</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Consensus protocols inherently rely on the notion of leader election, in
which one or a subset of participants are temporarily elected to authorize and
announce the network's latest state. While leader election is a well studied
problem, the rise of distributed ledgers (i.e., blockchains) has led to a new
perspective on how to perform large-scale leader elections via solving a
computationally difficult puzzle (i.e., proof of work). In this paper, we
present Caucus, a large-scale leader election protocol with minimal
coordination costs that does not require the computational cost of
proof-of-work. We evaluate Caucus in terms of its security, using a new model
for blockchain-focused leader election, before testing an implementation of
Caucus on an Ethereum private network. Our experiments highlight that one
variant of Caucus costs only $0.10 per leader election if deployed on Ethereum.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07983</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mitigating CSRF attacks on OAuth 2.0 and OpenID Connect</dc:title>
 <dc:creator>Li, Wanpeng</dc:creator>
 <dc:creator>Mitchell, Chris J</dc:creator>
 <dc:creator>Chen, Thomas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Many millions of users routinely use their Google, Facebook and Microsoft
accounts to log in to websites supporting OAuth 2.0 and/or OpenID Connect-based
single sign on. The security of OAuth 2.0 and OpenID Connect is therefore of
critical importance, and it has been widely examined both in theory and in
practice. Unfortunately, as these studies have shown, real-world
implementations of both schemes are often vulnerable to attack, and in
particular to cross-site request forgery (CSRF) attacks. In this paper we
propose a new technique which can be used to mitigate CSRF attacks against both
OAuth 2.0 and OpenID Connect.
</dc:description>
 <dc:description>Comment: 18 pages, 3 figures</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07985</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intrinsic dimension of concept lattices</dc:title>
 <dc:creator>Hanika, Tom</dc:creator>
 <dc:creator>Schneider, Friedrich Martin</dc:creator>
 <dc:creator>Stumme, Gerd</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>03G10 68P05 68T01</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Geometric analysis is a very capable theory to understand the influence of
the high dimensionality of the input data in machine learning (ML) and
knowledge discovery (KD). With our approach we can assess how far the
application of a specific KD/ML-algorithm to a concrete data set is prone to
the curse of dimensionality. To this end we extend V.~Pestov's axiomatic
approach to the instrinsic dimension of data sets, based on the seminal work by
M.~Gromov on concentration phenomena, and provide an adaptable and
computationally feasible model for studying observable geometric invariants
associated to features that are natural to both the data and the learning
procedure. In detail, we investigate data represented by formal contexts and
give first theoretical as well as experimental insights into the intrinsic
dimension of a concept lattice. Because of the correspondence between formal
concepts and maximal cliques in graphs, applications to social network analysis
are at hand.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07987</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-lossless L-infinity constrained Multi-rate Image Decompression via
  Deep Neural Network</dc:title>
 <dc:creator>Zhang, Xi</dc:creator>
 <dc:creator>Wu, Xiaolin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently a number of CNN-based techniques were proposed to remove image
compression artifacts. As in other restoration applications, these techniques
all learn a mapping from decompressed patches to the original counterparts
under the ubiquitous L2 metric. However, this approach is incapable of
restoring distinctive image details which may be statistical outliers but have
high semantic importance (e.g., tiny lesions in medical images). To overcome
this weakness, we propose to incorporate an L-infinity fidelity criterion in
the design of neural network so that no small, distinctive structures of the
original image can be dropped or distorted. Moreover, our anti-artifacts neural
network is designed to work on a range of compression bit rates, rather than a
fixed one as in the past. Experimental results demonstrate that the proposed
method outperforms the state-of-the-art methods in both L2 and L-infinity error
metrics, and also perceptually. It can restore subtle image details that are
otherwise destroyed or missed by other algorithms. Our research suggests a new
machine learning paradigm of ultra high fidelity image compression that is
ideally suited for applications in medicine, space, and sciences.
</dc:description>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07988</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding news story chains using information retrieval and network
  clustering techniques</dc:title>
 <dc:creator>Nicholls, Tom</dc:creator>
 <dc:creator>Bright, Jonathan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Content analysis of news stories (whether manual or automatic) is a
cornerstone of the communication studies field. However, much research is
conducted at the level of individual news articles, despite the fact that news
events (especially significant ones) are frequently presented as &quot;stories&quot; by
news outlets: chains of connected articles covering the same event from
different angles. These stories are theoretically highly important in terms of
increasing public recall of news items and enhancing the agenda-setting power
of the press. Yet thus far, the field has lacked an efficient method for
detecting groups of articles which form stories in a way that enables their
analysis.
  In this work, we present a novel, automated method for identifying linked
news stories from within a corpus of articles. This method makes use of
techniques drawn from the field of information retrieval to identify textual
closeness of pairs of articles, and then clustering techniques taken from the
field of network analysis to group these articles into stories. We demonstrate
the application of the method to a corpus of 61,864 articles, and show how it
can efficiently identify valid story clusters within the corpus. We use the
results to make observations about the prevalence and dynamics of stories
within the UK news media, showing that more than 50% of news production takes
place within stories.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07992</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>XZero: On Practical Cross-Technology Interference-Nulling for LTE-U/WiFi
  Coexistence</dc:title>
 <dc:creator>Zubow, Anatolij</dc:creator>
 <dc:creator>Gaw&#x142;owicz, Piotr</dc:creator>
 <dc:creator>Bayhan, Suzan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  LTE-U/WiFi coexistence can be significantly improved by placing so-called
coexistence gaps in space through cross-technology interference-nulling (CTIN)
from LTE-U BS towards WiFi nodes. Such coordinated co-existence scheme
requires, for the exchange of control messages, a cross-technology control
channel (CTC) between LTE-U and WiFi networks which was presented recently.
However, it is unclear how a practical CTIN operates in the absence of channel
state information which is needed for CTIN but cannot be obtained from the CTC.
We present XZero, the first practical CTIN system that is able to quickly find
the suitable precoding configuration used for interference nulling without
having to search the whole space of angular orientations. XZero performs a
tree-based search to find the direction for the null beam(s) by exploiting the
feedback received from the WiFi AP on the tested null directions. We have
implemented a prototype of XZero using SDR platform for LTE-U and commodity
hardware for WiFi and evaluated its performance in a large indoor testbed.
Evaluation results reveal on average a reduction by 15.7 dB in
interference-to-noise ratio at the nulled WiFi nodes when using a ULA with four
antennas. Moreover, XZero has a sub-second reconfiguration delay which is up to
10x smaller as compared to naive exhaustive linear search.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.07992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08003</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Threadable Curves</dc:title>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:creator>Rogers, Emmely</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>52C25</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We define a plane curve to be threadable if it can rigidly pass through a
point-hole in a line L without otherwise touching L. Threadable curves are in a
sense generalizations of monotone curves. Our main result is a linear-time
algorithm for deciding whether a polygonal curve is threadable, and if so,
finding a sequence of rigid motions to thread it through a hole. In addition,
we sketch arguments that show that the threadability of algebraic curves can be
decided in time polynomial in the degree of the curve, and that threading a 3D
polygonal curve through a point-hole in a plane can be decided in quadratic
time. Finally, we connect threadable curves to the problem known as &quot;moving a
chair through a doorway.&quot;
</dc:description>
 <dc:description>Comment: 15 pages, 12 figures, 7 references</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08018</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Cache Leasing from a Mobile Network Operator to a Content
  Provider</dc:title>
 <dc:creator>Krolikowski, Jonatan</dc:creator>
 <dc:creator>Giovanidis, Anastasios</dc:creator>
 <dc:creator>Di Renzo, Marco</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Caching popular content at the wireless edge is recently proposed as a means
to reduce congestion at the backbone of cellular networks. The two main actors
involved are Mobile Network Operators (MNOs) and Content Providers (CPs). In
this work, we consider the following arrangement: an MNO pre-installs memory on
its wireless equipment (e.g. Base Stations) and invites a unique CP to use
them, with monetary cost. The CP will lease memory space and place its content;
the MNO will associate network users to stations. For a given association
policy, the MNO may help (or not) the CP to offload traffic, depending on
whether the association takes into account content placement. We formulate an
optimization problem from the CP perspective, which aims at maximizing traffic
offloading with minimum leasing costs. This is a joint optimization problem
that can include any association policy, and can also derive the optimal one.
We present a general exact solution using Benders decomposition. It iteratively
updates decisions of the two actors separately and converges to the global
optimum. We illustrate the optimal CP leasing/placement strategy and hit
probability gains under different association policies. Performance is
maximised when the MNO association follows CP actions.
</dc:description>
 <dc:description>Comment: 9 pages, double column, 4 figures, INFOCOM 2018 Honolulu, HI, USA</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08019</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Set Debugging Using Trusted Items</dc:title>
 <dc:creator>Zhang, Xuezhou</dc:creator>
 <dc:creator>Zhu, Xiaojin</dc:creator>
 <dc:creator>Wright, Stephen J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Training set bugs are flaws in the data that adversely affect machine
learning. The training set is usually too large for man- ual inspection, but
one may have the resources to verify a few trusted items. The set of trusted
items may not by itself be adequate for learning, so we propose an algorithm
that uses these items to identify bugs in the training set and thus im- proves
learning. Specifically, our approach seeks the smallest set of changes to the
training set labels such that the model learned from this corrected training
set predicts labels of the trusted items correctly. We flag the items whose
labels are changed as potential bugs, whose labels can be checked for veracity
by human experts. To find the bugs in this way is a challenging combinatorial
bilevel optimization problem, but it can be relaxed into a continuous
optimization problem. Ex- periments on toy and real data demonstrate that our
approach can identify training set bugs effectively and suggest appro- priate
changes to the labels. Our algorithm is a step toward trustworthy machine
learning.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08024</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Collective Knowledge workflow for collaborative research into
  multi-objective autotuning and machine learning techniques</dc:title>
 <dc:creator>Fursin, Grigori</dc:creator>
 <dc:creator>Lokhmotov, Anton</dc:creator>
 <dc:creator>Savenko, Dmitry</dc:creator>
 <dc:creator>Upton, Eben</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Developing efficient software and hardware has never been harder whether it
is for a tiny IoT device or an Exascale supercomputer. Apart from the ever
growing design and optimization complexity, there exist even more fundamental
problems such as lack of interdisciplinary knowledge required for effective
software/hardware co-design, and a growing technology transfer gap between
academia and industry.
  We introduce our new educational initiative to tackle these problems by
developing Collective Knowledge (CK), a unified experimental framework for
computer systems research and development. We use CK to teach the community how
to make their research artifacts and experimental workflows portable,
reproducible, customizable and reusable while enabling sustainable R&amp;D and
facilitating technology transfer. We also demonstrate how to redesign
multi-objective autotuning and machine learning as a portable and extensible CK
workflow. Such workflows enable researchers to experiment with different
applications, data sets and tools; crowdsource experimentation across diverse
platforms; share experimental results, models, visualizations; gradually expose
more design and optimization choices using a simple JSON API; and ultimately
build upon each other's findings.
  As the first practical step, we have implemented customizable compiler
autotuning, crowdsourced optimization of diverse workloads across Raspberry Pi
3 devices, reduced the execution time and code size by up to 40%, and applied
machine learning to predict optimizations. We hope such approach will help
teach students how to build upon each others' work to enable efficient and
self-optimizing software/hardware/model stack for emerging workloads.
</dc:description>
 <dc:description>Comment: Interactive CK report: http://cKnowledge.org/rpi-crowd-tuning ; CK
  repository with artifacts:
  https://github.com/ctuning/ck-rpi-optimization-results ; FigShare data
  archive: https://doi.org/10.6084/m9.figshare.5789007.v2</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08026</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Framework for Centrality Measures in Multiplex Networks</dc:title>
 <dc:creator>Spatocco, Carlo</dc:creator>
 <dc:creator>Stilo, Giovanni</dc:creator>
 <dc:creator>Domeniconi, Carlotta</dc:creator>
 <dc:creator>Stilo, Giovanni</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The non-trivial structure of such complex systems makes the analysis of their
collective behavior a challenge. The problem is even more difficult when the
information is distributed across networks (e.g., communication networks in
different media); in this case, it becomes impossible to have a complete, or
even partial picture, if situations are analyzed separately within each network
due to sparsity. A multiplex network is well-suited to model the complexity of
this kind of systems by preserving the semantics associated with each network.
Centrality measures are fundamental for the identification of key players, but
existing approaches are typically designed to capture a predefined aspect of
the system, ignoring or merging the semantics of the individual layers. To
overcome the aforementioned limitations, we present a Framework for Tailoring
Centrality Measures in Multiplex networks (TaCMM), which offers a flexible
methodology that encompasses and generalizes previous approaches. The strength
of TaCMM is to enable the encoding of specific dependencies between the subnets
of multiplex networks to define semantic-aware centrality measures. We develop
a theoretically sound iterative method, based on Perron-Frobenius theory,
designed to be effective also in high-sparsity conditions. We formally and
experimentally prove its convergence for ranking computation. We provide a
thorough investigation of our methodology against existing techniques using
different types of subnets in multiplex networks. The results clearly show the
power and flexibility of the proposed framework.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08030</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Scale-out Deep Learning Training for Cloud and HPC</dc:title>
 <dc:creator>Sridharan, Srinivas</dc:creator>
 <dc:creator>Vaidyanathan, Karthikeyan</dc:creator>
 <dc:creator>Kalamkar, Dhiraj</dc:creator>
 <dc:creator>Das, Dipankar</dc:creator>
 <dc:creator>Smorkalov, Mikhail E.</dc:creator>
 <dc:creator>Shiryaev, Mikhail</dc:creator>
 <dc:creator>Mudigere, Dheevatsa</dc:creator>
 <dc:creator>Mellempudi, Naveen</dc:creator>
 <dc:creator>Avancha, Sasikanth</dc:creator>
 <dc:creator>Kaul, Bharat</dc:creator>
 <dc:creator>Dubey, Pradeep</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The exponential growth in use of large deep neural networks has accelerated
the need for training these deep neural networks in hours or even minutes. This
can only be achieved through scalable and efficient distributed training, since
a single node/card cannot satisfy the compute, memory, and I/O requirements of
today's state-of-the-art deep neural networks. However, scaling synchronous
Stochastic Gradient Descent (SGD) is still a challenging problem and requires
continued research/development. This entails innovations spanning algorithms,
frameworks, communication libraries, and system design. In this paper, we
describe the philosophy, design, and implementation of Intel Machine Learning
Scalability Library (MLSL) and present proof-points demonstrating scaling DL
training on 100s to 1000s of nodes across Cloud and HPC systems.
</dc:description>
 <dc:description>Comment: Accepted in SysML 2018 conference</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08052</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Historic Development of the Zooarchaeological Database OssoBook and
  the xBook Framework for Scientific Databases</dc:title>
 <dc:creator>Kaltenthaler, Daniel</dc:creator>
 <dc:creator>Lohrer, Johannes-Y.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this technical report, we describe the historic development of the
zooarchaeological database OssoBook and the resulting framework xBook, a
generic infrastructure for distributed, relational data management that is
mainly designed for the needs of scientific data. We describe the concepts of
the architecture and its most important features. We especially point out the
Server-Client architecture, the synchronization process, the Launcher
application, and the structure and features of the application.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08058</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intel nGraph: An Intermediate Representation, Compiler, and Executor for
  Deep Learning</dc:title>
 <dc:creator>Cyphers, Scott</dc:creator>
 <dc:creator>Bansal, Arjun K.</dc:creator>
 <dc:creator>Bhiwandiwalla, Anahita</dc:creator>
 <dc:creator>Bobba, Jayaram</dc:creator>
 <dc:creator>Brookhart, Matthew</dc:creator>
 <dc:creator>Chakraborty, Avijit</dc:creator>
 <dc:creator>Constable, Will</dc:creator>
 <dc:creator>Convey, Christian</dc:creator>
 <dc:creator>Cook, Leona</dc:creator>
 <dc:creator>Kanawi, Omar</dc:creator>
 <dc:creator>Kimball, Robert</dc:creator>
 <dc:creator>Knight, Jason</dc:creator>
 <dc:creator>Korovaiko, Nikolay</dc:creator>
 <dc:creator>Kumar, Varun</dc:creator>
 <dc:creator>Lao, Yixing</dc:creator>
 <dc:creator>Lishka, Christopher R.</dc:creator>
 <dc:creator>Menon, Jaikrishnan</dc:creator>
 <dc:creator>Myers, Jennifer</dc:creator>
 <dc:creator>Narayana, Sandeep Aswath</dc:creator>
 <dc:creator>Procter, Adam</dc:creator>
 <dc:creator>Webb, Tristan J.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The Deep Learning (DL) community sees many novel topologies published each
year. Achieving high performance on each new topology remains challenging, as
each requires some level of manual effort. This issue is compounded by the
proliferation of frameworks and hardware platforms. The current approach, which
we call &quot;direct optimization&quot;, requires deep changes within each framework to
improve the training performance for each hardware backend (CPUs, GPUs, FPGAs,
ASICs) and requires $\mathcal{O}(fp)$ effort; where $f$ is the number of
frameworks and $p$ is the number of platforms. While optimized kernels for
deep-learning primitives are provided via libraries like Intel Math Kernel
Library for Deep Neural Networks (MKL-DNN), there are several compiler-inspired
ways in which performance can be further optimized. Building on our experience
creating neon (a fast deep learning library on GPUs), we developed Intel
nGraph, a soon to be open-sourced C++ library to simplify the realization of
optimized deep learning performance across frameworks and hardware platforms.
Initially-supported frameworks include TensorFlow, MXNet, and Intel neon
framework. Initial backends are Intel Architecture CPUs (CPU), the Intel(R)
Nervana Neural Network Processor(R) (NNP), and NVIDIA GPUs. Currently supported
compiler optimizations include efficient memory management and data layout
abstraction. In this paper, we describe our overall architecture and its core
components. In the future, we envision extending nGraph API support to a wider
range of frameworks, hardware (including FPGAs and ASICs), and compiler
optimizations (training versus inference optimizations, multi-node and
multi-device scaling via efficient sub-graph partitioning, and HW-specific
compounding of operations).
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08059</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Construction of Nonbinary Polar Codes with Two-stage Polarization</dc:title>
 <dc:creator>Chen, Peiyao</dc:creator>
 <dc:creator>Bai, Baoming</dc:creator>
 <dc:creator>Ma, Xiao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a new class of nonbinary polar codes with two-stage
polarization, where the outer polarization (symbol-level polarization) kernel
is a nonbinary matrix resembling Ar{\i}kan's kernel, and the inner polarization
(bit-level polarization) kernel is a properly designed binary matrix. The
encoder/decoder of the proposed nonbinary polar codes have the same structure
as the original binary polar codes, admitting an easily configurable and
flexible implementation. This is an obvious advantage over the nonbinary polar
codes based on Reed-Solomon (RS) codes. Simulation results show that, compared
with modified RS-based polar codes, our proposed nonbinary polar codes can
achieve similar performance but with a smaller list size. When compared with
binary polar codes, the proposed nonbinary polar codes exhibit better
performance and lower decoding latency (benefitted from the fact that multiple
bits can be decoded as a symbol simultaneously).
</dc:description>
 <dc:description>Comment: Submitted to ISIT'2018</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08064</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SoK: Uncentralisable Ledgers and their Impact on Voting Systems</dc:title>
 <dc:creator>Dricot, Lionel</dc:creator>
 <dc:creator>Pereira, Olivier</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  As we observe a trend towards the recentralisation of the Internet, this
paper raises the question of guaranteeing an everlasting decentralisation. We
introduce the properties of strong and soft uncentralisability in order to
describe systems in which all authorities can be untrusted at any time without
affecting the system. We link the soft uncentralisability to another property
called perfect forkability. Using that knowledge, we introduce a new
cryptographic primitive called uncentralisable ledger and study its properties.
We use those properties to analyse what an uncentralisable ledger may offer to
classic electronic voting systems and how it opens up the realm of
possibilities for completely new voting mechanisms. We review a list of
selected projects that implement voting systems using blockchain technol- ogy.
We then conclude that the true revolutionary feature enabled by uncentralisable
ledgers is a self-sovereign and distributed identity provider.
</dc:description>
 <dc:description>Comment: 10 pages + biblio</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08074</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-parametric Estimation of Mutual Information with Application to
  Nonlinear Optical Fibers</dc:title>
 <dc:creator>Catuogno, Tommaso</dc:creator>
 <dc:creator>Camara, Menelaos Ralli</dc:creator>
 <dc:creator>Secondini, Marco</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  This paper compares and evaluates a set of non-parametric mutual information
estimators with the goal of providing a novel toolset to progress in the
analysis of the capacity of the nonlinear optical channel, which is currently
an open problem. In the first part of the paper, the methods of the study are
presented. The second part details their application to several
optically-related channels to highlight their features.
</dc:description>
 <dc:description>Comment: This work has been submited to IEEE International Symposium on
  Information Theory</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08088</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pointer-Chase Prefetcher for Linked Data Structures</dc:title>
 <dc:creator>Srivastava, Nitish Kumar</dc:creator>
 <dc:creator>Navalakha, Akshay Dilip</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Caches only exploit spatial and temporal locality in a set of address
referenced in a program. Due to dynamic construction of linked data-structures,
they are difficult to cache as the spatial locality between the nodes is highly
dependent on the data layout. Prefetching can play an important role in
improving the performance of linked data-structures. In this project, a pointer
chase mechanism along with compiler hints is adopted to design a prefetcher for
linked data-structures. The design is evaluated against the baseline of
processor with cache in terms of performance, area and energy
</dc:description>
 <dc:description>Comment: 12 pages, 37 figures</dc:description>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08090</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Algebraic Approach for Reasoning About Information Flow</dc:title>
 <dc:creator>Am&#xe9;rico, Arthur</dc:creator>
 <dc:creator>Alvim, M&#xe1;rio S.</dc:creator>
 <dc:creator>McIver, Annabelle</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper concerns the analysis of information leaks in security systems. We
address the problem of specifying and analyzing large systems in the (standard)
channel model used in quantitative information flow (QIF). We propose several
operators which match typical interactions between system components. We
explore their algebraic properties with respect to the security-preserving
refinement relation defined by Alvim et al. and McIver et al.
  We show how the algebra can be used to simplify large system specifications
in order to facilitate the computation of information leakage bounds. We
demonstrate our results on the specification and analysis of the Crowds
Protocol. Finally, we use the algebra to justify a new algorithm to compute
leakage bounds for this protocol.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08092</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalizable Data-free Objective for Crafting Universal Adversarial
  Perturbations</dc:title>
 <dc:creator>Mopuri, Konda Reddy</dc:creator>
 <dc:creator>Ganeshan, Aditya</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning models are susceptible to adversarial perturbations: small
changes to input that can cause large changes in output. It is also
demonstrated that there exist input-agnostic perturbations, called universal
adversarial perturbations, which can change the inference of target model on
most of the data samples. However, existing methods to craft universal
perturbations are (i) task specific, (ii) require samples from the training
data distribution, and (iii) perform complex optimizations. Also, because of
the data dependence, fooling ability of the crafted perturbations is
proportional to the available training data. In this paper, we present a novel,
generalizable and data-free objective for crafting universal adversarial
perturbations. Independent of the underlying task, our objective achieves
fooling via corrupting the extracted features at multiple layers. Therefore,
the proposed objective is generalizable to craft image-agnostic perturbations
across multiple vision tasks such as object recognition, semantic segmentation
and depth estimation. In the practical setting of black-box attacking scenario,
we show that our objective outperforms the data dependent objectives to fool
the learned models. Further, via exploiting simple priors related to the data
distribution, our objective remarkably boosts the fooling ability of the
crafted perturbations. Significant fooling rates achieved by our objective
emphasize that the current deep learning models are now at an increased risk,
since our objective generalizes across multiple tasks without the requirement
of training data for crafting the perturbations.
</dc:description>
 <dc:description>Comment: Under review. Contains low-res images</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08093</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Symmetry and Low-energy Locomotion</dc:title>
 <dc:creator>Yu, Wenhao</dc:creator>
 <dc:creator>Turk, Greg</dc:creator>
 <dc:creator>Liu, C. Karen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Learning locomotion skills is a challenging problem. To generate realistic
and smooth locomotion, existing methods use motion capture, finite state
machines or morphology-specific knowledge to guide the motion generation
algorithms. Deep reinforcement learning (DRL) is a promising approach for the
automatic creation of locomotion control. Indeed, a standard benchmark for DRL
is to automatically create a running controller for a biped character from a
simple reward function. Although several different DRL algorithms can
successfully create a running controller, the resulting motions usually look
nothing like a real runner. This paper takes a minimalist learning approach to
the locomotion problem, without the use of motion examples, finite state
machines, or morphology-specific knowledge. We introduce two modifications to
the DRL approach that, when used together, produce locomotion behaviors that
are symmetric, low-energy, and much closer to that of a real person. First, we
introduce a new term to the loss function (not the reward function) that
encourages symmetric actions. Second, we introduce a new curriculum learning
method that provides modulated physical assistance to help the character with
left/right balance and forward movement. The algorithm automatically computes
appropriate assistance to the character and gradually relaxes this assistance,
so that eventually the character learns to move entirely without help. Because
our method does not make use of motion capture data, it can be applied to a
variety of character morphologies. We demonstrate locomotion controllers for
the lower half of a biped, a full humanoid, a quadruped, and a hexapod. Our
results show that learned policies are able to produce symmetric, low-energy
gaits. In addition, speed-appropriate gait patterns emerge without any guidance
from motion examples or contact planning.
</dc:description>
 <dc:description>Comment: supplementary video: https://www.youtube.com/watch?v=ckQHuElLJiA</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08094</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PRNN: Recurrent Neural Network with Persistent Memory</dc:title>
 <dc:creator>Zhao, Kui</dc:creator>
 <dc:creator>Li, Yuechuan</dc:creator>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:creator>Yang, Cheng</dc:creator>
 <dc:creator>Zhu, Shenghuo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Although Recurrent Neural Network (RNN) has been a powerful tool for modeling
sequential data, its performance is inadequate when processing sequences with
multiple patterns. In this paper, we address this challenge by introducing an
external memory and constructing a novel persistent memory augmented RNN (term
as PRNN) model. The PRNN model captures the principle patterns in training
sequences and stores them in the explicit memory. By leveraging the persistent
memory, the proposed method can adaptively update states according to the
similarities between encoded inputs and memory slots, leading to a stronger
capacity in assimilating sequences with multiple patterns. Content-based
addressing is suggested in memory accessing, and gradient descent is utilized
for implicitly updating the memory. Experiments on several datasets demonstrate
the effectiveness of the proposed method.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08098</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Chronological Edge-Driven Approach to Temporal Subgraph Isomorphism</dc:title>
 <dc:creator>Mackey, Patrick</dc:creator>
 <dc:creator>Porterfield, Katherine</dc:creator>
 <dc:creator>Fitzhenry, Erin</dc:creator>
 <dc:creator>Choudhury, Sutanay</dc:creator>
 <dc:creator>Chin Jr, George</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Many real world networks are considered temporal networks, in which the
chronological ordering of the edges has importance to the meaning of the data.
Performing temporal subgraph matching on such graphs requires the edges in the
subgraphs to match the order of the temporal graph motif we are searching for.
Previous methods for solving this rely on the use of static subgraph matching
to find potential matches first, before filtering them based on edge order to
find the true temporal matches. We present a new algorithm for temporal
subgraph isomorphism that performs the subgraph matching directly on the
chronologically sorted edges. By restricting our search to only the subgraphs
with chronologically correct edges, we can improve the performance of the
algorithm significantly. We present experimental timing results to show
significant performance improvements on publicly available datasets for a
number of different temporal query graph motifs with four or more nodes. We
also demonstrate a practical example of how temporal subgraph isomorphism can
produce more meaningful results than traditional static subgraph searches.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08099</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logically-Correct Reinforcement Learning</dc:title>
 <dc:creator>Hasanbeig, Mohammadhosein</dc:creator>
 <dc:creator>Abate, Alessandro</dc:creator>
 <dc:creator>Kroening, Daniel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We propose a novel Reinforcement Learning (RL) algorithm to synthesize
policies for a Markov Decision Process (MDP), such that a linear time property
is satisfied. We convert the property into a Limit Deterministic Buchi
Automaton (LDBA), then construct a product MDP between the automaton and the
original MDP. A reward function is then assigned to the states of the product
automaton, according to accepting conditions of the LDBA. With this reward
function, RL synthesizes a policy that satisfies the property: as such, the
policy synthesis procedure is &quot;constrained&quot; by the given specification.
Additionally, we show that the RL procedure sets up an online value iteration
method to calculate the maximum probability of satisfying the given property,
at any given state of the MDP - a convergence proof for the procedure is
provided. Finally, the performance of the algorithm is evaluated via a set of
numerical examples. We observe an improvement of one order of magnitude in the
number of iterations required for the synthesis compared to existing
approaches.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08100</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised learning from videos using temporal coherency deep networks</dc:title>
 <dc:creator>Redondo-Cabrera, Carolina</dc:creator>
 <dc:creator>L&#xf3;pez-Sastre, Roberto J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we address the challenging problem of unsupervised learning from
videos. Existing methods utilize the spatio-temporal continuity in contiguous
video frames as regularization for the learning process. Typically, this
temporal coherence of close frames is used as a free form of annotation,
encouraging the learned representations to exhibit small differences between
these frames. But this type of approach fails to capture the dissimilarity
between videos with different content, hence learning less discriminative
features. We here propose two Siamese architectures for Convolutional Neural
Networks, and their corresponding novel loss functions, to learn from unlabeled
videos, which jointly exploit the local temporal coherence between contiguous
frames, and a global discriminative margin used to separate representations of
different videos. An extensive experimental evaluation is presented, where we
validate the proposed models on various tasks. First, we show how the learned
features can be used to discover actions and scenes in video collections.
Second, we show the benefits of such an unsupervised learning from just
unlabeled videos, which can be directly used as a prior for the supervised
recognition tasks of actions and objects in images, where our results further
show that our features can even surpass a traditional and heavily supervised
pre-training plus fine-tunning strategy.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08102</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-constrained two-way assisted private and quantum capacities of
  quantum channels</dc:title>
 <dc:creator>Davis, Noah</dc:creator>
 <dc:creator>Shirokov, Maksim E.</dc:creator>
 <dc:creator>Wilde, Mark M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  With the rapid growth of quantum technologies, knowing the fundamental
characteristics of quantum systems and protocols is essential for their
effective implementation. A particular communication setting that has received
increased focus is related to quantum key distribution and distributed quantum
computation. In this setting, a quantum channel connects a sender to a
receiver, and their goal is to distill either a secret key or entanglement,
along with the help of arbitrary local operations and classical communication
(LOCC). In this work, we establish a general theory of energy-constrained,
LOCC-assisted private and quantum capacities of quantum channels, which are the
maximum rates at which an LOCC-assisted quantum channel can reliably establish
secret key or entanglement, respectively, subject to an energy constraint on
the channel input states. We prove that the energy-constrained squashed
entanglement of a channel is an upper bound on these capacities. We also
explicitly prove that a thermal state maximizes a relaxation of the squashed
entanglement of all phase-insensitive, single-mode input bosonic Gaussian
channels, generalizing results from prior work. After doing so, we prove that a
variation of the method introduced in [Goodenough et al., New J. Phys. 18,
063005 (2016)] leads to improved upper bounds on the energy-constrained
secret-key-agreement capacity of a bosonic thermal channel. We then consider a
multipartite setting and prove that two known multipartite generalizations of
the squashed entanglement are in fact equal. We finally show that the
energy-constrained, multipartite squashed entanglement plays a role in bounding
the energy-constrained LOCC-assisted private and quantum capacity regions of
quantum broadcast channels.
</dc:description>
 <dc:description>Comment: 30 pages, 6 figures</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08107</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Choreographies for Reactive Programming</dc:title>
 <dc:creator>Carbone, Marco</dc:creator>
 <dc:creator>Montesi, Fabrizio</dc:creator>
 <dc:creator>Vieira, Hugo Torres</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Modular programming is a cornerstone in software development, as it allows to
build complex systems from the assembly of simpler components, and support
reusability and substitution principles. In a distributed setting, component
assembly is supported by communication that is often required to follow a
prescribed protocol of interaction. In this paper, we present a language for
the modular development of distributed systems, where the assembly of
components is supported by a choreography that specifies the communication
protocol. Our language allows to separate component behaviour, given in terms
of reactive data ports, and choreographies, specified as first class entities.
This allows us to consider reusability and substitution principles for both
components and choreographies. We show how our model can be compiled into a
more operational perspective in a provably-correct way, and we present a typing
discipline that addresses communication safety and progress of systems, where a
notion of substitutability naturally arises.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08110</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The challenge of simultaneous object detection and pose estimation: a
  comparative study</dc:title>
 <dc:creator>O&#xf1;oro-Rubio, Daniel</dc:creator>
 <dc:creator>L&#xf3;pez-Sastre, Roberto J.</dc:creator>
 <dc:creator>Redondo-Cabrera, Carolina</dc:creator>
 <dc:creator>Gil-Jim&#xe9;nez, Pedro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detecting objects and estimating their pose remains as one of the major
challenges of the computer vision research community. There exists a compromise
between localizing the objects and estimating their viewpoints. The detector
ideally needs to be view-invariant, while the pose estimation process should be
able to generalize towards the category-level. This work is an exploration of
using deep learning models for solving both problems simultaneously. For doing
so, we propose three novel deep learning architectures, which are able to
perform a joint detection and pose estimation, where we gradually decouple the
two tasks. We also investigate whether the pose estimation problem should be
solved as a classification or regression problem, being this still an open
question in the computer vision community. We detail a comparative analysis of
all our solutions and the methods that currently define the state of the art
for this problem. We use PASCAL3D+ and ObjectNet3D datasets to present the
thorough experimental evaluation and main results. With the proposed models we
achieve the state-of-the-art performance in both datasets.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08113</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Free Energy Minimization Using the 2-D Cluster Variation Method: Initial
  Code Verification and Validation</dc:title>
 <dc:creator>Maren, Alianna J.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A new approach for general artificial intelligence (GAI), building on neural
network deep learning architectures, can make use of one or more hidden layers
that have the ability to continuously reach a free energy minimum even after
input stimulus is removed, allowing for a variety of possible behaviors. One
reason that this approach has not been developed until now has been the lack of
a suitable free energy equation. The Cluster Variation Method (CVM) offers a
means for characterizing 2-D local pattern distributions, or configuration
variables, and provides a free energy formalism in terms of these configuration
variables. The equilibrium distribution of these configuration variables is
defined in terms of a single interaction enthalpy parameter, h, for the case of
equiprobable distribution of bistate units. For non-equiprobable distributions,
the equilibrium distribution can be characterized by providing a fixed value
for the fraction of units in the active state (x1), corresponding to the
influence of a per-unit activation enthalpy, together with the pairwise
interaction enthalpy parameter h. This paper provides verification and
validation (V&amp;V) for code that computes the configuration variable and
thermodynamic values for 2-D CVM grids characterized by different interaction
enthalpy parameters, or h-values. This work provides a foundation for
experimenting with a 2-D CVM-based hidden layer that can, as an alternative to
responding strictly to inputs, also now independently come to its own free
energy minimum and also return to a free energy-minimized state after
perturbations, which will enable a range of input-independent behaviors. A
further use of this 2-D CVM grid is that by characterizing local patterns in
terms of their corresponding h-values (together with their x1 values), we have
a means for quantitatively characterizing different kinds of neural
topographies.
</dc:description>
 <dc:description>Comment: 26 pages, 14 figures</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08114</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depending on Session-Typed Processes</dc:title>
 <dc:creator>Toninho, Bernardo</dc:creator>
 <dc:creator>Yoshida, Nobuko</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This work proposes a dependent type theory that combines functions and
session-typed processes (with value dependencies) through a contextual monad,
internalising typed processes in a dependently-typed lambda-calculus. The
proposed framework, by allowing session processes to depend on functions and
vice-versa, enables us to specify and statically verify protocols where the
choice of the next communication action can depend on specific values of
received data. Moreover, the type theoretic nature of the framework endows us
with the ability to internally describe and prove predicates on process
behaviours. Our main results are type soundness of the framework, and a
faithful embedding of the functional layer of the calculus within the
session-typed layer, showcasing the expressiveness of dependent session types.
</dc:description>
 <dc:description>Comment: Extended version</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08115</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eight Years of Rider Measurement in the Android Malware Ecosystem:
  Evolution and Lessons Learned</dc:title>
 <dc:creator>Suarez-Tangil, Guillermo</dc:creator>
 <dc:creator>Stringhini, Gianluca</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Despite the growing threat posed by Android malware, the research community
is still lacking a comprehensive view of common behaviors and trends exposed by
malware families active on the platform. Without such view, the researchers
incur the risk of developing systems that only detect outdated threats, missing
the most recent ones. In this paper, we conduct the largest measurement of
Android malware behavior to date, analyzing over 1.2 million malware samples
that belong to 1.2K families over a period of eight years (from 2010 to 2017).
We aim at understanding how the behavior of Android malware has evolved over
time, focusing on repackaging malware. In this type of threats different
innocuous apps are piggybacked with a malicious payload (rider), allowing
inexpensive malware manufacturing.
  One of the main challenges posed when studying repackaged malware is slicing
the app to split benign components apart from the malicious ones. To address
this problem, we use differential analysis to isolate software components that
are irrelevant to the campaign and study the behavior of malicious riders
alone. Our analysis framework relies on collective repositories and recent
advances on the systematization of intelligence extracted from multiple
anti-virus vendors. We find that since its infancy in 2010, the Android malware
ecosystem has changed significantly, both in the type of malicious activity
performed by the malicious samples and in the level of obfuscation used by
malware to avoid detection. We then show that our framework can aid analysts
who attempt to study unknown malware families. Finally, we discuss what our
findings mean for Android malware detection research, highlighting areas that
need further attention by the research community.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08116</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents</dc:title>
 <dc:creator>Leibo, Joel Z.</dc:creator>
 <dc:creator>d'Autume, Cyprien de Masson</dc:creator>
 <dc:creator>Zoran, Daniel</dc:creator>
 <dc:creator>Amos, David</dc:creator>
 <dc:creator>Beattie, Charles</dc:creator>
 <dc:creator>Anderson, Keith</dc:creator>
 <dc:creator>Casta&#xf1;eda, Antonio Garc&#xed;a</dc:creator>
 <dc:creator>Sanchez, Manuel</dc:creator>
 <dc:creator>Green, Simon</dc:creator>
 <dc:creator>Gruslys, Audrunas</dc:creator>
 <dc:creator>Legg, Shane</dc:creator>
 <dc:creator>Hassabis, Demis</dc:creator>
 <dc:creator>Botvinick, Matthew M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Psychlab is a simulated psychology laboratory inside the first-person 3D game
world of DeepMind Lab (Beattie et al. 2016). Psychlab enables implementations
of classical laboratory psychological experiments so that they work with both
human and artificial agents. Psychlab has a simple and flexible API that
enables users to easily create their own tasks. As examples, we are releasing
Psychlab implementations of several classical experimental paradigms including
visual search, change detection, random dot motion discrimination, and multiple
object tracking. We also contribute a study of the visual psychophysics of a
specific state-of-the-art deep reinforcement learning agent: UNREAL (Jaderberg
et al. 2016). This study leads to the surprising conclusion that UNREAL learns
more quickly about larger target stimuli than it does about smaller stimuli. In
turn, this insight motivates a specific improvement in the form of a simple
model of foveal vision that turns out to significantly boost UNREAL's
performance, both on Psychlab tasks, and on standard DeepMind Lab tasks. By
open-sourcing Psychlab we hope to facilitate a range of future such studies
that simultaneously advance deep reinforcement learning and improve its links
with cognitive science.
</dc:description>
 <dc:description>Comment: 28 pages, 11 figures</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08117</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is the coexistence of Catalan and Spanish possible in Catalonia?</dc:title>
 <dc:creator>Seoane, Lu&#xed;s F.</dc:creator>
 <dc:creator>Loredo, Xaqu&#xed;n</dc:creator>
 <dc:creator>Monteagudo, Henrique</dc:creator>
 <dc:creator>Mira, Jorge</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We study the stability of two coexisting languages (Catalan and Spanish) in
Catalonia (North-Eastern Spain), a key European region in political and
economic terms. Our analysis relies on recent, abundant empirical data that is
studied within an analytic model of population dynamics. This model
contemplates the possibilities of long-term language coexistence or extinction.
We establish that the most likely scenario is a sustained coexistence. The data
needs to be interpreted under different circumstances, some of them leading to
the asymptotic extinction of one of the languages involved. We delimit the
cases in which this can happen. Asymptotic behavior is often unrealistic as a
predictor for complex social systems, hence we make an attempt at forecasting
trends of speakers towards $2030$. These also suggest sustained coexistence
between both tongues, but some counterintuitive dynamics are unveiled for
extreme cases in which Catalan would be likely to lose an important fraction of
speakers. As an intermediate step, model parameters are obtained that convey
relevant information about the prestige and interlinguistic similarity of the
tongues as perceived by the population. This is the first time that these
parameters are quantified rigorously for this couple of languages. Remarkably,
Spanish is found to have a larger prestige specially in areas which
historically had larger communities of Catalan monolingual speakers. Limited,
spatially-segregated data allows us to examine more fine grained dynamics, thus
better addressing the likely coexistence or extinction. Variation of the model
parameters across regions are informative about how the two languages are
perceived in more urban or rural environments.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures, preprint</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08133</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causal Inference in Disease Spread across a Heterogeneous Social System</dc:title>
 <dc:creator>Kim, Minkyoung</dc:creator>
 <dc:creator>Paini, Dean</dc:creator>
 <dc:creator>Jurdak, Raja</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Diffusion processes are governed by external triggers and internal dynamics
in complex systems. Timely and cost-effective control of infectious disease
spread critically relies on uncovering the underlying diffusion mechanisms,
which is challenging due to invisible causality between events and their
time-evolving intensity. We infer causal relationships between infections and
quantify the reflexivity of a meta-population, the level of feedback on event
occurrences by its internal dynamics (likelihood of a regional outbreak
triggered by previous cases). These are enabled by our new proposed model, the
Latent Influence Point Process (LIPP) which models disease spread by
incorporating macro-level internal dynamics of meta-populations based on human
mobility. We analyse 15-year dengue cases in Queensland, Australia. From our
causal inference, outbreaks are more likely driven by statewide global
diffusion over time, leading to complex behavior of disease spread. In terms of
reflexivity, precursory growth and symmetric decline in populous regions is
attributed to slow but persistent feedback on preceding outbreaks via
inter-group dynamics, while abrupt growth but sharp decline in peripheral areas
is led by rapid but inconstant feedback via intra-group dynamics. Our proposed
model reveals probabilistic causal relationships between discrete events based
on intra- and inter-group dynamics and also covers direct and indirect
diffusion processes (contact-based and vector-borne disease transmissions).
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1711.06359</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08154</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Gold Standard for Security of Universal Steganography</dc:title>
 <dc:creator>Berndt, Sebastian</dc:creator>
 <dc:creator>Li&#x15b;kiewicz, Maciej</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  While symmetric-key steganography is quite well understood both in the
information-theoretic and in the computational setting, many fundamental
questions about its public-key counterpart resist persistent attempts to solve
them. The computational model for public-key steganography was proposed by von
Ahn and Hopper in EUROCRYPT 2004. At TCC 2005, Backes and Cachin gave the first
universal public-key stegosystem - i.e. one that works on all channels -
achieving security against replayable chosen-covertext attacks (SS-RCCA) and
asked whether security against non-replayable chosen-covertext attacks (SS-CCA)
is achievable. Later, Hopper (ICALP 2005) provided such a stegosystem for every
efficiently sampleable channel, but did not achieve universality. He posed the
question whether universality and SS-CCA-security can be achieved
simultaneously. No progress on this question has been achieved since more than
a decade. In our work we solve Hopper's problem in a somehow complete manner:
As our main positive result we design an SS-CCA-secure stegosystem that works
for every memoryless channel. On the other hand, we prove that this result is
the best possible in the context of universal steganography. We provide a
family of 0-memoryless channels - where the already sent documents have only
marginal influence on the current distribution - and prove that no
SS-CCA-secure steganography for this family exists in the standard
non-look-ahead model.
</dc:description>
 <dc:description>Comment: EUROCRYPT 2018, llncs style</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08155</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FLORIS and CLORIS: Hybrid Source and Network Localization Based on
  Ranges and Video</dc:title>
 <dc:creator>Ferreira, Beatriz Quintino</dc:creator>
 <dc:creator>Gomes, Jo&#xe3;o</dc:creator>
 <dc:creator>Soares, Cl&#xe1;udia</dc:creator>
 <dc:creator>Costeira, Jo&#xe3;o P.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We propose hybrid methods for localization in wireless sensor networks fusing
noisy range measurements with angular information (extracted from video).
Compared with conventional methods that rely on a single sensed variable, this
may pave the way for improved localization accuracy and robustness. We address
both the single-source and network (i.e., cooperative multiple-source)
localization paradigms, solving them via optimization of a convex surrogate.
The formulations for hybrid localization are unified in the sense that we
propose a single nonlinear least-squares cost function, fusing both angular and
range measurements. We then relax the problem to obtain an estimate of the
optimal positions. This contrasts with other hybrid approaches that alternate
the execution of localization algorithms for each type of measurement
separately, to progressively refine the position estimates. Single-source
localization uses a semidefinite relaxation to obtain a one-shot matrix
solution from which the source position is derived via factorization. Network
localization uses a different approach where sensor coordinates are retained as
optimization variables, and the relaxed cost function is efficiently minimized
using fast iterations based on Nesterov's optimal method. Further, an automated
calibration procedure is developed to express range and angular information,
obtained by different devices, possibly deployed at different locations, in a
single consistent coordinate system. This drastically reduces the need for
manual calibration that would otherwise negatively impact the practical
usability of hybrid range/video localization systems. We develop and test, both
in simulation and experimentally, the new hybrid localization algorithms, which
not only overcome the limitations of previous fusing approaches but also
compare favorably to state-of-the-art methods, outperforming them in some
scenarios.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08159</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Classification on Social Networks</dc:title>
 <dc:creator>Yu, Sixie</dc:creator>
 <dc:creator>Vorobeychik, Yevgeniy</dc:creator>
 <dc:creator>Alfeld, Scott</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The spread of unwanted or malicious content through social media has become a
major challenge. Traditional examples of this include social network spam, but
an important new concern is the propagation of fake news through social media.
A common approach for mitigating this problem is by using standard statistical
classification to distinguish malicious (e.g., fake news) instances from benign
(e.g., actual news stories). However, such an approach ignores the fact that
malicious instances propagate through the network, which is consequential both
in quantifying consequences (e.g., fake news diffusing through the network),
and capturing detection redundancy (bad content can be detected at different
nodes). An additional concern is evasion attacks, whereby the generators of
malicious instances modify the nature of these to escape detection. We model
this problem as a Stackelberg game between the defender who is choosing
parameters of the detection model, and an attacker, who is choosing both the
node at which to initiate malicious spread, and the nature of malicious
entities. We develop a novel bi-level programming approach for this problem, as
well as a novel solution approach based on implicit function gradients, and
experimentally demonstrate the advantage of our approach over alternatives
which ignore network structure.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08163</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DVQA: Understanding Data Visualizations via Question Answering</dc:title>
 <dc:creator>Kafle, Kushal</dc:creator>
 <dc:creator>Cohen, Scott</dc:creator>
 <dc:creator>Price, Brian</dc:creator>
 <dc:creator>Kanan, Christopher</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Bar charts are an effective way for humans to convey information to each
other, but today's algorithms cannot parse them. Existing methods fail when
faced with minor variations in appearance. Here, we present DVQA, a dataset
that tests many aspects of bar chart understanding in a question answering
framework. Unlike visual question answering (VQA), DVQA requires processing
words and answers that are unique to a particular bar chart. State-of-the-art
VQA algorithms perform poorly on DVQA, and we propose two strong baselines that
perform considerably better. Our work will enable algorithms to automatically
extract semantic information from vast quantities of literature in science,
business, and other areas.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08170</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Antenna Assisted Non-Orthogonal Multiple Access</dc:title>
 <dc:creator>Liu, Yuanwei</dc:creator>
 <dc:creator>Xing, Hong</dc:creator>
 <dc:creator>Pan, Cunhua</dc:creator>
 <dc:creator>Nallanathan, Arumugam</dc:creator>
 <dc:creator>Elkashlan, Maged</dc:creator>
 <dc:creator>Hanzo, Lajos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Non-orthogonal multiple access (NOMA) is potentially capable of circumventing
the limitations of the classic orthogonal multiple access schemes, hence it has
recently received significant research attention both in industry and academia.
This article is focused on exploiting multiple antenna techniques in NOMA
networks, with an emphasis on investigating the rate region of multiple-input
multiple-output (MIMO)-NOMA, whist reviewing two popular multiple antennas
aided NOMA structures, as well as underlining resource management problems of
both single-carrier and multi-carrier MIMO-NOMA networks. This article also
points out several effective methods of tackling the practical implementation
constraints of multiple antenna NOMA networks. Finally, some promising open
research directions are provided in context of multiple antenna aided NOMA.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures, 2 tables, accepted by IEEE Wireless
  Communications</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08175</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development and application of a machine learning supported methodology
  for measurement and verification (M&amp;V) 2.0</dc:title>
 <dc:creator>Gallagher, Colm V.</dc:creator>
 <dc:creator>Leahy, Kevin</dc:creator>
 <dc:creator>O'Donovan, Peter</dc:creator>
 <dc:creator>Bruton, Ken</dc:creator>
 <dc:creator>O'Sullivan, Dominic T. J.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The foundations of all methodologies for the measurement and verification
(M&amp;V) of energy savings are based on the same five key principles: accuracy,
completeness, conservatism, consistency and transparency. The most widely
accepted methodologies tend to generalise M&amp;V so as to ensure applicability
across the spectrum of energy conservation measures (ECM's). These do not
provide a rigid calculation procedure to follow. This paper aims to bridge the
gap between high-level methodologies and the practical application of modelling
algorithms, with a focus on the industrial buildings sector. This is achieved
with the development of a novel, machine learning supported methodology for M&amp;V
2.0 which enables accurate quantification of savings.
  A novel and computationally efficient feature selection algorithm and
powerful machine learning regression algorithms are employed to maximise the
effectiveness of available data. The baseline period energy consumption is
modelled using artificial neural networks, support vector machines, k-nearest
neighbours and multiple ordinary least squares regression. Improved knowledge
discovery and an expanded boundary of analysis allow more complex energy
systems be analysed, thus increasing the applicability of M&amp;V. A case study in
a large biomedical manufacturing facility is used to demonstrate the
methodology's ability to accurately quantify the savings under real-world
conditions. The ECM was found to result in 604,527 kWh of energy savings with
57% uncertainty at a confidence interval of 68%. 20 baseline energy models are
developed using an exhaustive approach with the optimal model being used to
quantify savings. The range of savings estimated with each model are presented
and the acceptability of uncertainty is reviewed. The case study demonstrates
the ability of the methodology to perform M&amp;V to an acceptable standard in
challenging circumstances.
</dc:description>
 <dc:description>Comment: 17 pages. Pre-print submitted to Energy and Buildings. This
  manuscript version is made available under the CC-BY-NC-ND 4.0 licence</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08177</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outage Performance of Two-Way Relay Non-Orthogonal Multiple Access
  Systems</dc:title>
 <dc:creator>Yue, Xinwei</dc:creator>
 <dc:creator>Liu, Yuanwei</dc:creator>
 <dc:creator>Kang, Shaoli</dc:creator>
 <dc:creator>Nallanathan, Arumugam</dc:creator>
 <dc:creator>Chen, Yue</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates a two-way relay nonorthogonal multiple access
(TWR-NOMA) system, where two groups of NOMA users exchange messages with the
aid of one half-duplex (HD) decode-and-forward (DF) relay. Since the
signal-plus-interference-to-noise ratios (SINRs) of NOMA signals mainly depend
on effective successive interference cancellation (SIC) schemes, imperfect SIC
(ipSIC) and perfect SIC (pSIC) are taken into consideration. To characterize
the performance of TWR-NOMA systems, we derive closed-form expressions for both
exact and asymptotic outage probabilities of NOMA users' signals with
ipSIC/pSIC. Based on the results derived, the diversity order and throughput of
the system are examined. Numerical simulations demonstrate that: 1) TWR-NOMA is
superior to TWR-OMA in terms of outage probability in low SNR regimes; and 2)
Due to the impact of interference signal (IS) at the relay, error floors and
throughput ceilings exist in outage probabilities and ergodic rates for
TWR-NOMA, respectively.
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08181</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outage Performance of A Unified Non-Orthogonal Multiple Access Framework</dc:title>
 <dc:creator>Yue, Xinwei</dc:creator>
 <dc:creator>Qin, Zhijin</dc:creator>
 <dc:creator>Liu, Yuanwei</dc:creator>
 <dc:creator>Dai, Xiaoming</dc:creator>
 <dc:creator>Chen, Yue</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a unified framework of non-orthogonal multiple access (NOMA)
networks is proposed, which can be applied to code-domain NOMA (CD-NOMA) and
power-domain NOMA (PD-NOMA). Since the detection of NOMA users mainly depend on
efficient successive interference cancellation (SIC) schemes, both imperfect
SIC (ipSIC) and perfect SIC (pSIC) are taken into considered. To characterize
the performance of this unified framework, the exact and asymptotic expressions
of outage probabilities as well as delay-limited throughput for CD/PD-NOMA with
ipSIC/pSIC are derived. Based on the asymptotic analysis, the diversity orders
of CD/PD-NOMA are provided. It is confirmed that due to the impact of residual
interference (RI), the outage probability of the n-th user with ipSIC for
CD/PD-NOMA converges to an error floor in the high signal-to-noise ratio (SNR)
region. Numerical simulations demonstrate that the outage behavior of CD-NOMA
is superior to that of PD-NOMA.
</dc:description>
 <dc:description>Comment: Accecpted by IEEE ICC 2018</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08185</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exposing Vulnerabilities in Mobile Networks: A Mobile Data Consumption
  Attack</dc:title>
 <dc:creator>Wasil, Dean</dc:creator>
 <dc:creator>Nakhila, Omar</dc:creator>
 <dc:creator>Bacanli, Salih Safa</dc:creator>
 <dc:creator>Zou, Cliff</dc:creator>
 <dc:creator>Turgut, Damla</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Smartphone carrier companies rely on mobile networks for keeping an accurate
record of customer data usage for billing purposes. In this paper, we present a
vulnerability that allows an attacker to force the victim's smartphone to
consume data through the cellular network by starting the data download on the
victim's cell phone without the victim's knowledge. The attack is based on
switching the victim's smartphones from the Wi-Fi network to the cellular
network while downloading a large data file. This attack has been implemented
in real-life scenarios where the test's outcomes demonstrate that the attack is
feasible and that mobile networks do not record customer data usage accurately.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures, presented on IEEE MASS 2017</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08185</dc:identifier>
 <dc:identifier>IEEE International Conference on Mobile Ad-hoc Sensor Systems(IEEE
  MASS 2017), pp.550-554, October 2017</dc:identifier>
 <dc:identifier>doi:10.1109/MASS.2017.76</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08186</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MAttNet: Modular Attention Network for Referring Expression
  Comprehension</dc:title>
 <dc:creator>Yu, Licheng</dc:creator>
 <dc:creator>Lin, Zhe</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Lu, Xin</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:creator>Berg, Tamara L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we address referring expression comprehension: localizing an
image region described by a natural language expression. While most recent work
treats expressions as a single unit, we propose to decompose them into three
modular components related to subject appearance, location, and relationship to
other objects. This allows us to flexibly adapt to expressions containing
different types of information in an end-to-end framework. In our model, which
we call the Modular Attention Network (MAttNet), two types of attention are
utilized: language-based attention that learns the module weights as well as
the word/phrase attention that each module should focus on; and visual
attention that allows the subject and relationship modules to focus on relevant
image components. Module weights combine scores from all three modules
dynamically to output an overall score. Experiments show that MAttNet
outperforms previous state-of-art methods by a large margin on both
bounding-box-level and pixel-level comprehension tasks.
</dc:description>
 <dc:description>Comment: 14 pages, 13 figures, Project and Demo:
  http://gpuvision.cs.unc.edu/refer/comprehension</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08191</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Per-user Flexible Management in 5G</dc:title>
 <dc:creator>Zabala, Aitor</dc:creator>
 <dc:creator>Rojas, Elisa</dc:creator>
 <dc:creator>Roldan, Jos&#xe9; Mar&#xed;a</dc:creator>
 <dc:creator>Pulido, Luis</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Flexible management is one of the key components of next-generation 5G
networks. Currently, many approaches focus on network functionality (services)
and translate it afterward into end-user requirements, which slightly
constrains the flexibility for both management and end users. Furthermore,
moving the intelligence of the network towards the edge (i.e. the users) has
already proven its benefits, such as computational offloading, lower latency
and higher bandwidth utilization. In this article, we try to move management as
close as possible to final users, providing per-user flexibility and unique
user to service paths, enabling custom paths adapted for each user requirements
instead of users adapting to service requirements. To validate our ideas, we
work on two different use cases, implemented as proof-of-concepts in the ONOS
platform. From the results obtained we conclude that there is still work to be
done regarding the integration of SDN in the radio access and evolved packet
core functions to provide the desired flexibility.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures, preprint</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08196</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Eigenpair Computation for Graph Laplacian Matrices: Theory
  and Applications</dc:title>
 <dc:creator>Chen, Pin-Yu</dc:creator>
 <dc:creator>Zhang, Baichuan</dc:creator>
 <dc:creator>Hasan, Mohammad Al</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The smallest eigenvalues and the associated eigenvectors (i.e., eigenpairs)
of a graph Laplacian matrix have been widely used in spectral clustering and
community detection. However, in real-life applications the number of clusters
or communities (say, $K$) is generally unknown a-priori. Consequently, the
majority of the existing methods either choose $K$ heuristically or they repeat
the clustering method with different choices of $K$ and accept the best
clustering result. The first option, more often, yields suboptimal result,
while the second option is computationally expensive. In this work, we propose
an incremental method for constructing the eigenspectrum of the graph Laplacian
matrix. This method leverages the eigenstructure of graph Laplacian matrix to
obtain the $K$-th smallest eigenpair of the Laplacian matrix given a collection
of all previously computed $K-1$ smallest eigenpairs. Our proposed method
adapts the Laplacian matrix such that the batch eigenvalue decomposition
problem transforms into an efficient sequential leading eigenpair computation
problem. As a practical application, we consider user-guided spectral
clustering. Specifically, we demonstrate that users can utilize the proposed
incremental method for effective eigenpair computation and for determining the
desired number of clusters based on multiple clustering metrics.
</dc:description>
 <dc:description>Comment: Accept to publish in Social Network Analysis and Mining. arXiv admin
  note: text overlap with arXiv:1512.07349</dc:description>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08196</dc:identifier>
 <dc:identifier>Social Network Analysis and Mining, 2018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08198</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Association and Resource Allocation in Unified Non-Orthogonal
  Multiple Access Enabled Heterogeneous Ultra Dense Networks</dc:title>
 <dc:creator>Qin, Z.</dc:creator>
 <dc:creator>Yue, X.</dc:creator>
 <dc:creator>Liu, Y.</dc:creator>
 <dc:creator>Ding, Z.</dc:creator>
 <dc:creator>Nallanathan, A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Heterogeneous ultra dense networks (HUDNs) and non-orthogonal multiple access
(NOMA) have been identified as two proposing techniques for the fifth
generation (5G) mobile communication systems due to their great capabilities to
enhance spectrum efficiency. This article investigates the application of NOMA
techniques in HUDNs to support massive connectivity in 5G systems.
Particularly, a unified NOMA framework is proposed, including power-domain NOMA
and code-domain NOMA, which can be configured flexibly to serve different
applications scenarios. As a further advance, the unified NOMA framework
enabled HUDNs is further investigated, with particular focuses on the user
association and resource allocation. Two case studies are provided for
demonstrating the effectiveness of the unified NOMA enabled HUDNs. Finally,
some main challenges and promising research directions in NOMA enabled HUDNs
are identified. Index Terms Heterogeneous ultra dense networks, non-orthogonal
multiple access, massive connectivity, user association, and resource
allocation
</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08206</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Representation for Wireless Communications</dc:title>
 <dc:creator>Qin, Zhijin</dc:creator>
 <dc:creator>Fan, Jiancun</dc:creator>
 <dc:creator>Liu, Yuanwei</dc:creator>
 <dc:creator>Gao, Yue</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Sparse representation can efficiently model signals in different applications
to facilitate processing. In this article, we will discuss various applications
of sparse representation in wireless communications, with focus on the most
recent compressive sensing (CS) enabled approaches. With the help of the
sparsity property, CS is able to enhance the spectrum efficiency and energy
efficiency for the fifth generation (5G) networks and Internet of Things (IoT)
networks. This article starts from a comprehensive overview of CS principles
and different sparse domains potentially used in 5G and IoT networks. Then
recent research progress on applying CS to address the major opportunities and
challenges in 5G and IoT networks is introduced, including wideband spectrum
sensing in cognitive radio networks, data collection in IoT networks, and
channel estimation and feedback in massive MIMO systems. Moreover, other
potential applications and research challenges on sparse representation for 5G
and IoT networks are identified. This article will provide readers a clear
picture of how to exploit the sparsity properties to process wireless signals
in different applications.
</dc:description>
 <dc:description>Comment: This paper has been accepted by IEEE Signal Processing Magazine.
  Please cite the format version of this paper</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08212</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-optional Many-sorted Past Present Future structures and its
  description</dc:title>
 <dc:creator>Tom&#xe9;, Sergio Miguel</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T99</dc:subject>
 <dc:description>  The cognitive theory of true conditions (CTTC) is a proposal to describe the
model-theoretic semantics of symbolic cognitive architectures and design the
implementation of cognitive abilities. The CTTC is formulated mathematically
using the multi-optional many-sorted past present future(MMPPF) structures.
This article defines mathematically the MMPPF structures and the formal
languages proposed to describe them by the CTTC.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.08212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="145000" completeListSize="155308">2369777|146001</resumptionToken>
</ListRecords>
</OAI-PMH>
