<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:09:26Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|101001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08893</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficiently Inferring Pairwise Subtree Prune-and-Regraft Adjacencies
  between Phylogenetic Trees</dc:title>
 <dc:creator>Whidden, Chris</dc:creator>
 <dc:creator>Matsen IV, Frederick A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We develop a time-optimal $O(mn^2)$-time algorithm to construct the subtree
prune-regraft (SPR) graph on a collection of m phylogenetic trees with n
leaves. This improves on the previous bound of $O(mn^3)$. Such graphs are used
to better understand the behaviour of phylogenetic methods and recommend
parameter choices and diagnostic criteria. The limiting factor in these
analyses has been the difficulty in constructing such graphs for large numbers
of trees. We also develop the first efficient algorithms for constructing the
nearest-neighbor interchange (NNI) and tree bisection-and-reconnection (TBR)
graphs
</dc:description>
 <dc:description>Comment: 21 pages, 3 figures. Revised in response to peer review</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08896</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Semantic Relationship between Probabilistic Soft Logic and Markov
  Logic</dc:title>
 <dc:creator>Lee, Joohyung</dc:creator>
 <dc:creator>Wang, Yi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Markov Logic Networks (MLN) and Probabilistic Soft Logic (PSL) are widely
applied formalisms in Statistical Relational Learning, an emerging area in
Artificial Intelligence that is concerned with combining logical and
statistical AI. Despite their resemblance, the relationship has not been
formally stated. In this paper, we describe the precise semantic relationship
between them from a logical perspective. This is facilitated by first extending
fuzzy logic to allow weights, which can be also viewed as a generalization of
PSL, and then relate that generalization to MLN. We observe that the
relationship between PSL and MLN is analogous to the known relationship between
fuzzy logic and Boolean logic, and furthermore the weight scheme of PSL is
essentially a generalization of the weight scheme of MLN for the many-valued
setting.
</dc:description>
 <dc:description>Comment: In Working Notes of the 6th International Workshop on Statistical
  Relational AI</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08904</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Multi-Agent Optimization: Coping with Packet-Dropping Link
  Failures</dc:title>
 <dc:creator>Su, Lili</dc:creator>
 <dc:creator>Vaidya, Nitin H.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study the problem of multi-agent optimization in the presence of
communication failures, where agents are connected by a strongly connected
communication network. Specifically, we are interested in optimizing
$h(x)=\frac{1}{n}\sum_{i=1}^n h_i(x)$, where $\mathcal{V}=\{1, \ldots, n\}$ is
the set of agents, and $h_i(\cdot)$ is agent $i$'s local cost function. We
consider the scenario where the communication links may suffer packet-dropping
failures (i.e., the sent messages are not guaranteed to be delivered in the
same iteration), but each link is reliable at least once in every $B$
consecutive message transmissions. This bounded time reliability assumption is
reasonable since it has been shown that with unbounded message delays,
convergence is not guaranteed for reaching consensus -- a special case of the
optimization problem of interest. We propose a robust distributed optimization
algorithm wherein each agent updates its local estimate using slightly
different routines in odd and even iterations. We show that these local
estimates converge to a common optimum of $h(\cdot)$ sub-linearly at
convergence rate $O(\frac{1}{\sqrt{t}})$, where $t$ is the number of iteration.
Our proposed algorithm combines the Push-Sum Distributed Dual Averaging method
with a robust average consensus algorithm. The main analysis challenges come
from the fact that the effective communication network is time varying, and
that each agent does not know the actual number of reliable outgoing links at
each iteration.
</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08905</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>knor: A NUMA-Optimized In-Memory, Distributed and Semi-External-Memory
  k-means Library</dc:title>
 <dc:creator>Mhembere, Disa</dc:creator>
 <dc:creator>Zheng, Da</dc:creator>
 <dc:creator>Priebe, Carey E.</dc:creator>
 <dc:creator>Vogelstein, Joshua T.</dc:creator>
 <dc:creator>Burns, Randal</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  k-means is one of the most influential and utilized machine learning
algorithms. Its computation limits the performance and scalability of many
statistical analysis and machine learning tasks. We rethink and optimize
k-means in terms of modern NUMA architectures to develop a novel
parallelization scheme that delays and minimizes synchronization barriers. The
\textit{k-means NUMA Optimized Routine} (\textsf{knor}) library has (i)
in-memory (\textsf{knori}), (ii) distributed memory (\textsf{knord}), and (iii)
semi-external memory (\textsf{knors}) modules that radically improve the
performance of k-means for varying memory and hardware budgets. \textsf{knori}
boosts performance for single machine datasets by an order of magnitude or
more. \textsf{knors} improves the scalability of k-means on a memory budget
using SSDs. \textsf{knors} scales to billions of points on a single machine,
using a fraction of the resources that distributed in-memory systems require.
\textsf{knord} retains \textsf{knori}'s performance characteristics, while
scaling in-memory through distributed computation in the cloud. \textsf{knor}
modifies Elkan's triangle inequality pruning algorithm such that we utilize it
on billion-point datasets without the significant memory overhead of the
original algorithm. We demonstrate \textsf{knor} outperforms distributed
commercial products like H$_2$O, Turi (formerly Dato, GraphLab) and Spark's
MLlib by more than an order of magnitude for datasets of $10^7$ to $10^9$
points.
</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:date>2017-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08906</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring high-level Perspectives on Self-Configuration Capabilities of
  Systems</dc:title>
 <dc:creator>Lodwich, Aleksander</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Optimization of product performance repetitively introduces the need to make
products adaptive in a more general sense. This more general idea is often
captured under the term 'self-configuration'. Despite the importance of such
capability, research work on this feature appears isolated by technical
domains. It is not easy to tell quickly whether the approaches chosen in
different technological domains introduce new ideas or whether the differences
just reflect domain idiosyncrasies. For the sake of easy identification of key
differences between systems with self-configuring capabilities, I will explore
higher level concepts for understanding self-configuration, such as the
{\Omega}-units, in order to provide theoretical instruments for connecting
different areas of technology and research.
</dc:description>
 <dc:description>Comment: 46 pages, 62 figures</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08906</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.1.2945.6885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08920</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Lower Bounds for the Agnostic Probably-Approximately-Correct (PAC)
  Machine Learning Model</dc:title>
 <dc:creator>Kontorovich, Aryeh</dc:creator>
 <dc:creator>Pinelis, Iosif</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Primary 68T05, 62C20, 62C10, 62C12, 62G20, 62H30, secondary 62G10,
  62C20, 91A35, 60C05</dc:subject>
 <dc:description>  We provide an exact non-asymptotic lower bound on the minimax expected excess
risk (EER) in the agnostic probably-ap\-proximately-correct (PAC) machine
learning classification model and identify minimax learning algorithms as
certain maximally symmetric and minimally randomized &quot;voting&quot; procedures. Based
on this result, an exact asymptotic lower bound on the minimax EER is provided.
This bound is of the simple form $c_\infty/\sqrt{\nu}$ as $\nu\to\infty$, where
$c_\infty=0.16997\dots$ is a universal constant, $\nu=m/d$, $m$ is the size of
the training sample, and $d$ is the Vapnik--Chervonenkis dimension of the
hypothesis class. It is shown that the differences between these asymptotic and
non-asymptotic bounds, as well as the differences between these two bounds and
the maximum EER of any learning algorithms that minimize the empirical risk,
are asymptotically negligible, and all these differences are due to ties in the
mentioned &quot;voting&quot; procedures. A few easy to compute non-asymptotic lower
bounds on the minimax EER are also obtained, which are shown to be close to the
exact asymptotic lower bound $c_\infty/\sqrt{\nu}$ even for rather small values
of the ratio $\nu=m/d$. As an application of these results, we substantially
improve existing lower bounds on the tail probability of the excess risk. Among
the tools used are Bayes estimation and apparently new identities and
inequalities for binomial distributions.
</dc:description>
 <dc:description>Comment: Version 2: modified presentation in accordance with referees'
  comments</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:date>2017-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08921</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Restoration Using Convolutional Auto-encoders with Symmetric Skip
  Connections</dc:title>
 <dc:creator>Mao, Xiao-Jiao</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Yang, Yu-Bin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image restoration, including image denoising, super resolution, inpainting,
and so on, is a well-studied problem in computer vision and image processing,
as well as a test bed for low-level image modeling algorithms. In this work, we
propose a very deep fully convolutional auto-encoder network for image
restoration, which is a encoding-decoding framework with symmetric
convolutional-deconvolutional layers. In other words, the network is composed
of multiple layers of convolution and de-convolution operators, learning
end-to-end mappings from corrupted images to the original ones. The
convolutional layers capture the abstraction of image contents while
eliminating corruptions. Deconvolutional layers have the capability to upsample
the feature maps and recover the image details. To deal with the problem that
deeper networks tend to be more difficult to train, we propose to symmetrically
link convolutional and deconvolutional layers with skip-layer connections, with
which the training converges much faster and attains better results.
</dc:description>
 <dc:description>Comment: 17 pages. A journal extension of the version at arXiv:1603.09056</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08927</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Least Cost Influence Maximization Across Multiple Social Networks</dc:title>
 <dc:creator>Zhang, Huiyuan</dc:creator>
 <dc:creator>Nguyen, Dung T.</dc:creator>
 <dc:creator>Das, Soham</dc:creator>
 <dc:creator>Zhang, Huiling</dc:creator>
 <dc:creator>Thai, My T.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Recently in Online Social Networks (OSNs), the Least Cost Influence (LCI)
problem has become one of the central research topics. It aims at identifying a
minimum number of seed users who can trigger a wide cascade of information
propagation. Most of existing literature investigated the LCI problem only
based on an individual network. However, nowadays users often join several OSNs
such that information could be spread across different networks simultaneously.
Therefore, in order to obtain the best set of seed users, it is crucial to
consider the role of overlapping users under this circumstances.
  In this article, we propose a unified framework to represent and analyze the
influence diffusion in multiplex networks. More specifically, we tackle the LCI
problem by mapping a set of networks into a single one via lossless and lossy
coupling schemes. The lossless coupling scheme preserves all properties of
original networks to achieve high quality solutions, while the lossy coupling
scheme offers an attractive alternative when the running time and memory
consumption are of primary concern. Various experiments conducted on both real
and synthesized datasets have validated the effectiveness of the coupling
schemes, which also provide some interesting insights into the process of
influence propagation in multiplex networks.
</dc:description>
 <dc:description>Comment: 21 pages, published in IEEE/ACM Transactions on Networking</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08927</dc:identifier>
 <dc:identifier>IEEE/ACM Transactions on Networking, 24(2), 929-939, March 12,
  2015</dc:identifier>
 <dc:identifier>doi:10.1109/TNET.2015.2394793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08928</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>subgraph2vec: Learning Distributed Representations of Rooted Sub-graphs
  from Large Graphs</dc:title>
 <dc:creator>Narayanan, Annamalai</dc:creator>
 <dc:creator>Chandramohan, Mahinthan</dc:creator>
 <dc:creator>Chen, Lihui</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Saminathan, Santhoshkumar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper, we present subgraph2vec, a novel approach for learning latent
representations of rooted subgraphs from large graphs inspired by recent
advancements in Deep Learning and Graph Kernels. These latent representations
encode semantic substructure dependencies in a continuous vector space, which
is easily exploited by statistical models for tasks such as graph
classification, clustering, link prediction and community detection.
subgraph2vec leverages on local information obtained from neighbourhoods of
nodes to learn their latent representations in an unsupervised fashion. We
demonstrate that subgraph vectors learnt by our approach could be used in
conjunction with classifiers such as CNNs, SVMs and relational data clustering
algorithms to achieve significantly superior accuracies. Also, we show that the
subgraph vectors could be used for building a deep learning variant of
Weisfeiler-Lehman graph kernel. Our experiments on several benchmark and
large-scale real-world datasets reveal that subgraph2vec achieves significant
improvements in accuracies over existing graph kernels on both supervised and
unsupervised learning tasks. Specifically, on two realworld program analysis
tasks, namely, code clone and malware detection, subgraph2vec outperforms
state-of-the-art kernels by more than 17% and 4%, respectively.
</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08936</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Time-constraint Satisfying and Cost-reducing node evaluation metric
  for Message Routing in Mobile Crowd Sensing Networks</dc:title>
 <dc:creator>Wang, Qian</dc:creator>
 <dc:creator>Gao, Zhipeng</dc:creator>
 <dc:creator>Niu, Kun</dc:creator>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Qiu, Xuesong</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In mobile crowd sensing networks data forwarding through opportunistic
contacts between participants. Data is replicated to encountered participants.
For optimizing data delivery ratio and reducing redundant data a lot of data
forwarding schemes, which selectively replicate data to encountered
participants through node's data forwarding metric are proposed. However most
of them neglect a kind of redundant data whose Time-To-Live is expired. For
reducing this kind of redundant data we proposed a new method to evaluate
node's data forwarding metric, which is used to measure the node's probability
of forwarding data to destination within data's constraint time. The method is
divided into two parts. The first is evaluating nodes whether have possibility
to contact destination within time constraint based on transient cluster. We
propose a method to detect node's transient cluster, which is based on node's
contact rate. Only node, which has possibility to contact destination, has
chances to the second step. It effectively reduces the computational
complexity. The second is calculating data forwarding probability of node to
destination according to individual ICT (inter contact time) distribution.
Evaluation results show that our proposed transient cluster detection method is
more simple and quick. And from two aspects of data delivery ratio and network
overhead our approach outperforms other existing data forwarding approach.
</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08939</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Optimization Under Adversarial Nodes</dc:title>
 <dc:creator>Sundaram, Shreyas</dc:creator>
 <dc:creator>Gharesifard, Bahman</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We investigate the vulnerabilities of consensus-based distributed
optimization protocols to nodes that deviate from the prescribed update rule
(e.g., due to failures or adversarial attacks). We first characterize certain
fundamental limitations on the performance of any distributed optimization
algorithm in the presence of adversaries. We then propose a resilient
distributed optimization algorithm that guarantees that the non-adversarial
nodes converge to the convex hull of the minimizers of their local functions
under certain conditions on the graph topology, regardless of the actions of a
certain number of adversarial nodes. In particular, we provide sufficient
conditions on the graph topology to tolerate a bounded number of adversaries in
the neighborhood of every non-adversarial node, and necessary and sufficient
conditions to tolerate a globally bounded number of adversaries. For situations
where there are up to F adversaries in the neighborhood of every node, we use
the concept of maximal F-local sets of graphs to provide lower bounds on the
distance-to-optimality of achievable solutions under any algorithm. We show
that finding the size of such sets is NP-hard.
</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08942</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting risky behavior in social communities</dc:title>
 <dc:creator>Simpson, Olivia</dc:creator>
 <dc:creator>McAuley, Julian</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Predicting risk profiles of individuals in networks (e.g.~susceptibility to a
particular disease, or likelihood of smoking) is challenging for a variety of
reasons. For one, `local' features (such as an individual's demographic
information) may lack sufficient information to make informative predictions;
this is especially problematic when predicting `risk,' as the relevant features
may be precisely those that an individual is disinclined to reveal in a survey.
Secondly, even if such features are available, they still may miss crucial
information, as `risk' may be a function not just of an individual's features
but also those of their friends and social communities. Here, we predict
individual's risk profiles as a function of both their local features and those
of their friends. Instead of modeling influence from the social network
directly (which proved difficult as friendship links may be sparse and
partially observed), we instead model influence by discovering social
communities in the network that may be related to risky behavior. The result is
a model that predicts risk as a function of local features, while making up for
their deficiencies and accounting for social influence by uncovering community
structure in the network. We test our model by predicting risky behavior among
adolescents from the Add health data set, and hometowns among users in a
Facebook ego net. Compared to prediction by features alone, our model
demonstrates better predictive accuracy when measured as a whole, and in
particular when measured as a function of network &quot;richness.&quot;
</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08948</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PRESAGE: Protecting Structured Address Generation against Soft Errors</dc:title>
 <dc:creator>Sharma, Vishal Chandra</dc:creator>
 <dc:creator>Gopalakrishnan, Ganesh</dc:creator>
 <dc:creator>Krishnamoorthy, Sriram</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Modern computer scaling trends in pursuit of larger component counts and
power efficiency have, unfortunately, lead to less reliable hardware and
consequently soft errors escaping into application data (&quot;silent data
corruptions&quot;). Techniques to enhance system resilience hinge on the
availability of efficient error detectors that have high detection rates, low
false positive rates, and lower computational overhead. Unfortunately,
efficient detectors to detect faults during address generation (to index large
arrays) have not been widely researched. We present a novel lightweight
compiler-driven technique called PRESAGE for detecting bit-flips affecting
structured address computations. A key insight underlying PRESAGE is that any
address computation scheme that flows an already incurred error is better than
a scheme that corrupts one particular array access but otherwise (falsely)
appears to compute perfectly. Enabling the flow of errors allows one to situate
detectors at loop exit points, and helps turn silent corruptions into easily
detectable error situations. Our experiments using PolyBench benchmark suite
indicate that PRESAGE-based error detectors have a high error-detection rate
while incurring low overheads.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08950</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-layer design for downlink multi-hop cloud radio access networks
  with network coding</dc:title>
 <dc:creator>Liu, Liang</dc:creator>
 <dc:creator>Yu, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  There are two fundamentally different fronthaul techniques in the downlink
communication of cloud radio access network (C-RAN): the data-sharing strategy
and the compression-based strategy. Under the former strategy, each user's
message is multicast from the central processor (CP) to all the serving remote
radio heads (RRHs) over the fronthaul network, which then cooperatively serve
the users through joint beamforming; while under the latter strategy, the user
messages are first beamformed then quantized at the CP, and the compressed
signal is unicast to the corresponding RRH, which then decompresses its
received signal for wireless transmission. Previous works show that in general
the compression-based strategy outperforms the data-sharing strategy. This
paper, on the other hand, point s out that in a C-RAN model where the RRHs are
connected to the CP via multi-hop routers, data-sharing can be superior to
compression if the network coding technique is adopted for multicasting user
messages to the cooperating RRHs, and the RRH's beamforming vectors, the
user-RRH association, and the network coding design over the fronthaul network
are jointly optimized based on the techniques of sparse optimization an d
successive convex approximation. This is in comparison to the compression-based
strategy, where information is unicast over the fronthaul network by simple
routing, and the RRH's compression noise covariance and beamforming vectors, as
well as the routing strategy over the fronthaul network are jointly optimized
based on the successive convex approximation technique. The observed gain in
overall network throughput is due to that information multicast is more
efficient than information unicast over the multi-hop fronthaul of a C-RAN.
</dc:description>
 <dc:description>Comment: submitted for possible publication</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08950</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2649486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08952</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Several Classes of Negabent Functions over Finite Fields</dc:title>
 <dc:creator>Wu, Gaofei</dc:creator>
 <dc:creator>Li, Nian</dc:creator>
 <dc:creator>Zhang, Yuqing</dc:creator>
 <dc:creator>Liu, Xuefeng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Negabent functions as a class of generalized bent functions have attracted a
lot of attention recently due to their applications in cryptography and coding
theory. In this paper, we consider the constructions of negabent functions over
finite fields. First, by using the compositional inverses of certain binomial
and trinomial permutations, we present several classes of negabent functions of
the form $f(x)=\Tr_1^n(\lambda x^{2^k+1})+\Tr_1^n(ux)\Tr_1^n(vx)$, where
$\lambda\in \F_{2^n}$, $2\leq k\leq n-1$, $(u,v)\in \F^*_{2^n}\times
\F^*_{2^n}$, and $\Tr_1^n(\cdot)$ is the trace function from $\F_{2^n}$ to
$\F_{2}$. Second, by using Kloosterman sum, we prove that the condition for the
cubic monomials given by Zhou and Qu (Cryptogr. Commun., to appear, DOI
10.1007/s12095-015-0167-0.) to be negabent is also necessary. In addition, a
conjecture on negabent monomials whose exponents are of Niho type is given.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08954</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Greedy, Joint Syntactic-Semantic Parsing with Stack LSTMs</dc:title>
 <dc:creator>Swayamdipta, Swabha</dc:creator>
 <dc:creator>Ballesteros, Miguel</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Smith, Noah A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present a transition-based parser that jointly produces syntactic and
semantic dependencies. It learns a representation of the entire algorithm
state, using stack long short-term memories. Our greedy inference algorithm has
linear time, including feature extraction. On the CoNLL 2008--9 English shared
tasks, we obtain the best published parsing performance among models that
jointly learn syntax and semantics.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures, accepted to CoNLL 2016</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08955</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Contextual Cues for Generating Basketball Highlights</dc:title>
 <dc:creator>Bettadapura, Vinay</dc:creator>
 <dc:creator>Pantofaru, Caroline</dc:creator>
 <dc:creator>Essa, Irfan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  The massive growth of sports videos has resulted in a need for automatic
generation of sports highlights that are comparable in quality to the
hand-edited highlights produced by broadcasters such as ESPN. Unlike previous
works that mostly use audio-visual cues derived from the video, we propose an
approach that additionally leverages contextual cues derived from the
environment that the game is being played in. The contextual cues provide
information about the excitement levels in the game, which can be ranked and
selected to automatically produce high-quality basketball highlights. We
introduce a new dataset of 25 NCAA games along with their play-by-play stats
and the ground-truth excitement data for each basket. We explore the
informativeness of five different cues derived from the video and from the
environment through user studies. Our experiments show that for our study
participants, the highlights produced by our system are comparable to the ones
produced by ESPN for the same games.
</dc:description>
 <dc:description>Comment: Proceedings of ACM Multimedia 2016</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08962</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation and selection of Medical Tourism sites: A rough AHP based
  MABAC approach</dc:title>
 <dc:creator>Roy, Jagannath</dc:creator>
 <dc:creator>Chatterjee, Kajal</dc:creator>
 <dc:creator>Bandhopadhyay, Abhirup</dc:creator>
 <dc:creator>Kar, Samarjit</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, a novel multiple criteria decision making (MCDM) methodology
is presented for assessing and prioritizing medical tourism destinations in
uncertain environment. A systematic evaluation and assessment method is
proposed by integrating rough number based AHP (Analytic Hierarchy Process) and
rough number based MABAC (Multi-Attributive Border Approximation area
Comparison). Rough number is used to aggregate individual judgments and
preferences to deal with vagueness in decision making due to limited data.
Rough AHP analyzes the relative importance of criteria based on their
preferences given by experts. Rough MABAC evaluates the alternative sites based
on the criteria weights. The proposed methodology is explained through a case
study considering different cities for healthcare service in India. The
validity of the obtained ranking for the given decision making problem is
established by testing criteria proposed by Wang and Triantaphyllou (2008)
along with further analysis and discussion.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08962</dc:identifier>
 <dc:identifier>doi:10.1111/exsy.12232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08963</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-linear Label Ranking for Large-scale Prediction of Long-Term User
  Interests</dc:title>
 <dc:creator>Djuric, Nemanja</dc:creator>
 <dc:creator>Grbovic, Mihajlo</dc:creator>
 <dc:creator>Radosavljevic, Vladan</dc:creator>
 <dc:creator>Bhamidipati, Narayan</dc:creator>
 <dc:creator>Vucetic, Slobodan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of personalization of online services from the
viewpoint of ad targeting, where we seek to find the best ad categories to be
shown to each user, resulting in improved user experience and increased
advertisers' revenue. We propose to address this problem as a task of ranking
the ad categories depending on a user's preference, and introduce a novel label
ranking approach capable of efficiently learning non-linear, highly accurate
models in large-scale settings. Experiments on a real-world advertising data
set with more than 3.2 million users show that the proposed algorithm
outperforms the existing solutions in terms of both rank loss and top-K
retrieval performance, strongly suggesting the benefit of using the proposed
model on large-scale ranking problems.
</dc:description>
 <dc:description>Comment: 28th AAAI Conference on Artificial Intelligence (AAAI-14)</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08965</identifier>
 <datestamp>2016-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Credibilistic TOPSIS Model for Evaluation and Selection of Municipal
  Solid Waste Disposal Methods</dc:title>
 <dc:creator>Roy, Jagannath</dc:creator>
 <dc:creator>Adhikary, Krishnendu</dc:creator>
 <dc:creator>Kar, Samarjit</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Municipal solid waste management (MSWM) is a challenging issue of urban
development in developing countries. Each country having different
socio-economic-environmental background, might not accept a particular disposal
method as the optimal choice. Selection of suitable disposal method in MSWM,
under vague and imprecise information can be considered as multi criteria
decision making problem (MCDM). In the present paper, TOPSIS (Technique for
Order Preference by Similarity to Ideal Solution) methodology is extended based
on credibility theory for evaluating the performances of MSW disposal methods
under some criteria fixed by experts. The proposed model helps decision makers
to choose a preferable alternative for their municipal area. A sensitivity
analysis by our proposed model confirms this fact.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08968</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Knowledge-Based Resource Discovery for Internet of Things</dc:title>
 <dc:creator>Perera, Charith</dc:creator>
 <dc:creator>Vasilakos, Athanasios V.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the sensing as a service paradigm, Internet of Things (IoT) Middleware
platforms allow data consumers to retrieve the data they want without knowing
the underlying technical details of IoT resources (i.e. sensors and data
processing components). However, configuring an IoT middleware platform and
retrieving data is a significant challenge for data consumers as it requires
both technical knowledge and domain expertise. In this paper, we propose a
knowledge driven approach called Context Aware Sensor Configuration Model
(CASCOM) to simplify the process of configuring IoT middleware platforms, so
the data consumers, specifically non-technical personnel, can easily retrieve
the data they required. In this paper, we demonstrate how IoT resources can be
described using semantics in such away that they can later be used to compose
service work-flows. Such automated semantic-knowledge based IoT resource
composition approach advances the current research. We demonstrate the
feasibility and the usability of our approach through a prototype
implementation based on an IoT middleware called Global Sensor Networks (GSN),
though our model can be generalized to any other middleware platform.
</dc:description>
 <dc:description>Comment: Knowledge-Based Systems Journal 2016. arXiv admin note: substantial
  text overlap with arXiv:1309.1515, arXiv:1309.1811</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08970</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The rotating normal form is regular</dc:title>
 <dc:creator>Fromentin, Jean</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Defined on Birman-Ko-Lee monoids, the rotating normal form has strong
connections with the Dehornoy's braid ordering. It can be seen as a process for
selecting between all the representative words of a Birman-Ko-Lee braid a
particular one, called rotating word. In this paper we construct, for all n
\textgreater{} 1, a finite state automaton which recognizes the rotating words
on n strands. As a consequence the language of rotating words on n strands is
proved to be regular for any n \textgreater{} 1.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08971</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Millimeter Wave and Microwave Resources Allocation in Cellular
  Networks with Dual-Mode Base Stations</dc:title>
 <dc:creator>Semiari, Omid</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper, a novel dual-mode scheduling framework is proposed that
jointly performs user applications (UA) selection and scheduling over microwave
($\mu$W) and millimeter wave (mmW) bands. The proposed scheduling framework
utilizes a set of context information, including the channel state information,
the delay tolerance and required load per UA, and the uncertainty of mmW
channels, to maximize the quality-of-service (QoS) per UA. The scheduling
problem is formulated as an optimization with minimum unsatisfied relations
(min-UR) problem which is shown to be challenging to solve. Consequently, a
long-term scheduling framework, consisting of two stages, is proposed. Within
this framework, first, the scheduling over $\mu$W band is formulated as a
matching game and to solve this problem, a novel algorithm is proposed and
shown to yield a two-sided stable resource allocation. Second, over the mmW
band, the scheduling problem is formulated as a 0-1 Knapsack problem and a
novel algorithm is proposed to solve it. Furthermore, it is shown that the
proposed framework can find an effective scheduling solution, over both $\mu$W
and mmW, in polynomial time. Simulation results show that, compared with
conventional scheduling schemes, the proposed approach significantly increases
the number of satisfied UAs and enhances the users' quality-of-experience.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Wireless Communications, May 2017</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08972</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Generalised Colouring Numbers on Classes of Bounded Expansion</dc:title>
 <dc:creator>Kreutzer, Stephan</dc:creator>
 <dc:creator>Pilipczuk, Micha&#x142;</dc:creator>
 <dc:creator>Rabinovich, Roman</dc:creator>
 <dc:creator>Siebertz, Sebastian</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The generalised colouring numbers $\mathrm{adm}_r(G)$, $\mathrm{col}_r(G)$,
and $\mathrm{wcol}_r(G)$ were introduced by Kierstead and Yang as
generalisations of the usual colouring number, also known as the degeneracy of
a graph, and have since then found important applications in the theory of
bounded expansion and nowhere dense classes of graphs, introduced by
Ne\v{s}et\v{r}il and Ossona de Mendez. In this paper, we study the relation of
the colouring numbers with two other measures that characterise nowhere dense
classes of graphs, namely with uniform quasi-wideness, studied first by Dawar
et al. in the context of preservation theorems for first-order logic, and with
the splitter game, introduced by Grohe et al. We show that every graph
excluding a fixed topological minor admits a universal order, that is, one
order witnessing that the colouring numbers are small for every value of $r$.
Finally, we use our construction of such orders to give a new proof of a result
of Eickmeyer and Kawarabayashi, showing that the model-checking problem for
successor-invariant first-order formulas is fixed-parameter tractable on
classes of graphs with excluded topological minors.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08973</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity Analysis of Discrete Energy Harvesting Channels</dc:title>
 <dc:creator>Mao, Wei</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the channel capacity of a general discrete energy harvesting channel
with a finite battery. Contrary to traditional communication systems, the
transmitter of such a channel is powered by a device that harvests energy from
a random exogenous energy source and has a finite-sized battery. As a
consequence, at each transmission opportunity the system can only transmit a
symbol whose energy is no more than the energy currently available. This new
type of power supply introduces an unprecedented input constraint for the
channel, which is simultaneously random, instantaneous, and influenced by the
full history of the inputs and the energy harvesting process. Furthermore,
naturally, in such a channel the energy information is observed causally at the
transmitter. Both of these characteristics pose great challenges for the
analysis of the channel capacity. In this work we use techniques developed for
channels with side information and finite state channels, to obtain lower and
upper bounds on the capacity of energy harvesting channels. In particular, in a
general case with Markov energy harvesting processes we use stationarity and
ergodicity theory to compute and optimize the achievable rates for the
channels, and derive series of computable capacity upper and lower bounds.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08990</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extended OOBE Comparisons for OFDM, GFDM and WCP-COQAM at Equal Spectral
  Efficiency</dc:title>
 <dc:creator>&#xdc;&#xe7;&#xfc;nc&#xfc;, Ali Bulut</dc:creator>
 <dc:creator>Y&#x131;lmaz, Ali &#xd6;zg&#xfc;r</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Generalized frequency division multiplexing (GFDM), windowed cyclic prefix
circular offset quadrature amplitude modulation (WCP-COQAM) and orthogonal
frequency division multiplexing (OFDM) are among the candidate 5G modulation
formats. In this study, we present additional results for the OOBE comparisons
between OFDM, GFDM and WCP-COQAM under equal or unequal spectral efficiency
conditions for various simulation scenarios.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08998</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LCrowdV: Generating Labeled Videos for Simulation-based Crowd Behavior
  Learning</dc:title>
 <dc:creator>Cheung, Ernest</dc:creator>
 <dc:creator>Wong, Tsan Kwong</dc:creator>
 <dc:creator>Bera, Aniket</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>Manocha, Dinesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel procedural framework to generate an arbitrary number of
labeled crowd videos (LCrowdV). The resulting crowd video datasets are used to
design accurate algorithms or training models for crowded scene understanding.
Our overall approach is composed of two components: a procedural simulation
framework for generating crowd movements and behaviors, and a procedural
rendering framework to generate different videos or images. Each video or image
is automatically labeled based on the environment, number of pedestrians,
density, behavior, flow, lighting conditions, viewpoint, noise, etc.
Furthermore, we can increase the realism by combining synthetically-generated
behaviors with real-world background videos. We demonstrate the benefits of
LCrowdV over prior lableled crowd datasets by improving the accuracy of
pedestrian detection and crowd behavior classification algorithms. LCrowdV
would be released on the WWW.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.08999</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>De-Hashing: Server-Side Context-Aware Feature Reconstruction for Mobile
  Visual Search</dc:title>
 <dc:creator>Kuo, Yin-Hsi</dc:creator>
 <dc:creator>Hsu, Winston H.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Due to the prevalence of mobile devices, mobile search becomes a more
convenient way than desktop search. Different from the traditional desktop
search, mobile visual search needs more consideration for the limited resources
on mobile devices (e.g., bandwidth, computing power, and memory consumption).
The state-of-the-art approaches show that bag-of-words (BoW) model is robust
for image and video retrieval; however, the large vocabulary tree might not be
able to be loaded on the mobile device. We observe that recent works mainly
focus on designing compact feature representations on mobile devices for
bandwidth-limited network (e.g., 3G) and directly adopt feature matching on
remote servers (cloud). However, the compact (binary) representation might fail
to retrieve target objects (images, videos). Based on the hashed binary codes,
we propose a de-hashing process that reconstructs BoW by leveraging the
computing power of remote servers. To mitigate the information loss from binary
codes, we further utilize contextual information (e.g., GPS) to reconstruct a
context-aware BoW for better retrieval results. Experiment results show that
the proposed method can achieve competitive retrieval accuracy as BoW while
only transmitting few bits from mobile devices.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Circuits and Systems
  for Video Technology (TCSVT)</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.08999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09000</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The parameterized complexity of finding secluded solutions to some
  classical optimization problems on graphs</dc:title>
 <dc:creator>van Bevern, Ren&#xe9;</dc:creator>
 <dc:creator>Fluschnik, Till</dc:creator>
 <dc:creator>Mertzios, George B.</dc:creator>
 <dc:creator>Molter, Hendrik</dc:creator>
 <dc:creator>Sorge, Manuel</dc:creator>
 <dc:creator>Such&#xfd;, Ond&#x159;ej</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68Q17, 68Q25, 68W40, 68R05, 68R10</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  This work studies the parameterized complexity of finding secluded solutions
to classical combinatorial optimization problems on graphs such as finding
minimum s-t separators, feedback vertex sets, dominating sets, maximum
independent sets, and vertex deletion problems for hereditary graph properties:
Herein, one searches not only to minimize or maximize the size of the solution,
but also to minimize the size of its neighborhood. This restriction has
applications in secure routing and community detection.
</dc:description>
 <dc:description>Comment: Compared to the previous version, this version additionally shows
  that Small Secluded s-t-Separator is fixed-parameter tractable parameterized
  by the combination of the solution size and the open neighborhood size
  (Theorem 3.5)</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09000</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.IPEC.2016.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09002</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene Text Detection via Holistic, Multi-Channel Prediction</dc:title>
 <dc:creator>Yao, Cong</dc:creator>
 <dc:creator>Bai, Xiang</dc:creator>
 <dc:creator>Sang, Nong</dc:creator>
 <dc:creator>Zhou, Xinyu</dc:creator>
 <dc:creator>Zhou, Shuchang</dc:creator>
 <dc:creator>Cao, Zhimin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, scene text detection has become an active research topic in
computer vision and document analysis, because of its great importance and
significant challenge. However, vast majority of the existing methods detect
text within local regions, typically through extracting character, word or line
level candidates followed by candidate aggregation and false positive
elimination, which potentially exclude the effect of wide-scope and long-range
contextual cues in the scene. To take full advantage of the rich information
available in the whole natural image, we propose to localize text in a holistic
manner, by casting scene text detection as a semantic segmentation problem. The
proposed algorithm directly runs on full images and produces global, pixel-wise
prediction maps, in which detections are subsequently formed. To better make
use of the properties of text, three types of information regarding text
region, individual characters and their relationship are estimated, with a
single Fully Convolutional Network (FCN) model. With such predictions of text
properties, the proposed algorithm can simultaneously handle horizontal,
multi-oriented and curved text in real-world natural images. The experiments on
standard benchmarks, including ICDAR 2013, ICDAR 2015 and MSRA-TD500,
demonstrate that the proposed algorithm substantially outperforms previous
state-of-the-art approaches. Moreover, we report the first baseline result on
the recently-released, large-scale dataset COCO-Text.
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures, 5 tables</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09012</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Multi-Hop Extension of Energy-Efficient WSN Time Synchronization
  Based on Time-Translating Gateways</dc:title>
 <dc:creator>Liao, Qimeng</dc:creator>
 <dc:creator>Kim, Kyeong Soo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We report preliminary results of a simulation study on the multi-hop
extension of the recently-proposed energy-efficient wireless sensor network
time synchronization scheme based on time-translating gateways. Unlike the
single-hop case, in multi-hop time synchronization a sensor node sends
measurement data to a head node through gateways which translate the timestamp
values of the received measurement data. Through simulations for two-hop time
synchronization, we analyze the impact of the addition of a gateway and its
translation of timestamp values on the clock frequency and measurement time
estimation and thereby demonstrate the feasibility of the multi-hop extension
of the energy-efficient WSN time synchronization based on time-translating
gateways.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, ICISCA2016, Chiang Mai, Thailand, July 13-16,
  2016</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09016</identifier>
 <datestamp>2017-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proof Diagrams for Multiplicative Linear Logic</dc:title>
 <dc:creator>Acclavio, Matteo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The original idea of proof nets can be formulated by means of interaction
nets syntax. Additional machinery as switching, jumps and graph connectivity is
needed in order to ensure correspondence between a proof structure and a
correct proof in sequent calculus.
  In this paper we give an interpretation of proof nets in the syntax of string
diagrams. Even though we lose standard proof equivalence, our construction
allows to define a framework where soundness and well-typeness of a diagram can
be verified in linear time.
</dc:description>
 <dc:description>Comment: In Proceedings LINEARITY 2016, arXiv:1701.04522</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09016</dc:identifier>
 <dc:identifier>EPTCS 238, 2017, pp. 11-23</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.238.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09022</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision making via semi-supervised machine learning techniques</dc:title>
 <dc:creator>Protopapadakis, Eftychios</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Semi-supervised learning (SSL) is a class of supervised learning tasks and
techniques that also exploits the unlabeled data for training. SSL
significantly reduces labeling related costs and is able to handle large data
sets. The primary objective is the extraction of robust inference rules.
Decision support systems (DSSs) who utilize SSL have significant advantages.
Only a small amount of labelled data is required for the initialization. Then,
new (unlabeled) data can be utilized and improve system's performance. Thus,
the DSS is continuously adopted to new conditions, with minimum effort.
Techniques which are cost effective and easily adopted to dynamic systems, can
be beneficial for many practical applications. Such applications fields are:
(a) industrial assembly lines monitoring, (b) sea border surveillance, (c)
elders' falls detection, (d) transportation tunnels inspection, (e) concrete
foundation piles defect recognition, (f) commercial sector companies financial
assessment and (g) image advanced filtering for cultural heritage applications.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:math/0604233,
  arXiv:1208.2128, arXiv:1406.5298 by other authors</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09029</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometry in Active Learning for Binary and Multi-class Image
  Segmentation</dc:title>
 <dc:creator>Konyushkova, Ksenia</dc:creator>
 <dc:creator>Sznitman, Raphael</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an Active Learning approach to image segmentation that exploits
geometric priors to streamline the annotation process. We demonstrate this for
both background-foreground and multi-class segmentation tasks in 2D images and
3D image volumes. Our approach combines geometric smoothness priors in the
image space with more traditional uncertainty measures to estimate which pixels
or voxels are most in need of annotation. For multi-class settings, we
additionally introduce two novel criteria for uncertainty. In the 3D case, we
use the resulting uncertainty measure to show the annotator voxels lying on the
same planar patch, which makes batch annotation much easier than if they were
randomly distributed in the volume. The planar patch is found using a
branch-and-bound algorithm that finds a patch with the most informative
instances. We evaluate our approach on Electron Microscopy and Magnetic
Resonance image volumes, as well as on regular images of horses and faces. We
demonstrate a substantial performance increase over state-of-the-art
approaches.
</dc:description>
 <dc:description>Comment: Extension of our previous paper arXiv:1508.04955</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09035</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compositionality, Decompositionality and Refinement in Input/Output
  Conformance Testing - Technical Report</dc:title>
 <dc:creator>Luthmann, Lars</dc:creator>
 <dc:creator>Mennicke, Stephan</dc:creator>
 <dc:creator>Lochau, Malte</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68Q45 (Primary), 68N30, 68Q60 (Secondary)</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  We propose an input/output conformance testing theory utilizing Modal
Interface Automata with Input Refusals (IR-MIA) as novel behavioral formalism
for both the specification and the implementation under test. A modal
refinement relation on IR-MIA allows distinguishing between obligatory and
allowed output behaviors, as well as between implicitly underspecified and
explicitly forbidden input behaviors. The theory therefore supports positive
and negative conformance testing with optimistic and pessimistic environmental
assumptions. We further show that the resulting conformance relation on IR-MIA,
called modal-irioco, enjoys many desirable properties concerning
component-based behaviors. First, modal-irioco is preserved under modal
refinement and constitutes a preorder under certain restrictions which can be
ensured by a canonical input completion for IR-MIA. Second, under the same
restrictions, modal-irioco is compositional with respect to parallel
composition of IR-MIA with multi-cast and hiding. Finally, the quotient
operator on IR-MIA, as the inverse to parallel composition, facilitates
decompositionality in conformance testing to solve the unknown-component
problem.
</dc:description>
 <dc:description>Comment: 36 pages, 14 figures</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09035</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-57666-4_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09042</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Attack Model for Dynamic Risk Assessment</dc:title>
 <dc:creator>Fran&#xe7;ois-Xavier, Aguessy</dc:creator>
 <dc:creator>Olivier, Bettan</dc:creator>
 <dc:creator>Gr&#xe9;gory, Blanc</dc:creator>
 <dc:creator>Vania, Conan</dc:creator>
 <dc:creator>Herv&#xe9;, Debar</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Because of the threat of advanced multi-step attacks, it is often difficult
for security operators to completely cover all vulnerabilities when deploying
remediations. Deploying sensors to monitor attacks exploiting residual
vulnerabilities is not sufficient and new tools are needed to assess the risk
associated to the security events produced by these sensors. Although attack
graphs were proposed to represent known multi-step attacks occurring in an
information system, they are not directly suited for dynamic risk assessment.
In this paper, we present the Bayesian Attack Model (BAM), a Bayesian
network-based extension to topological attack graphs, capable of handling
topological cycles, making it fit for any information system. Evaluation is
performed on realistic topologies to study the sensitivity of its probabilistic
parameters.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09043</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IoT Cloud-based Distribution System State Estimation: Virtual Objects
  and Context-Awareness</dc:title>
 <dc:creator>Meloni, Alessio</dc:creator>
 <dc:creator>Pegoraro, Paolo Attilio</dc:creator>
 <dc:creator>Atzori, Luigi</dc:creator>
 <dc:creator>Castello, Paolo</dc:creator>
 <dc:creator>Sulis, Sara</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper presents an IoT cloud-based state estimation system for
distribution networks in which the PMUs (Phasor Measurement Units) are
virtualized with respect to the physical devices. In the considered system only
application level entities are put in the cloud, whereas virtualized PMUs are
running in the communication network edge (i.e. closer to the physical objects)
in order to have a certain degree of local logic, which allows to implement a
bandwidth-efficient and smart data transmission to the involved applications in
the cloud. The major contributions of the paper are the following: we
demonstrate that a cloud-based architecture is capable of achieving the QoS
level required by the specific state estimation application; we show that
implementing a certain local logic for data transmission in the cloud, the
result of the state estimation is not degraded with respect to the case of an
estimation that takes place frequently at fixed intervals; we show the results
in terms of latency and reduced network load for a reference smart grid
network.
</dc:description>
 <dc:description>Comment: in IEEE International Conference on Communications 2016</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09043</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2016.7511051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09047</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum-latency Time-frequency Analysis Using Asymmetric Window
  Functions</dc:title>
 <dc:creator>Su, Li</dc:creator>
 <dc:creator>Wu, Hau-tieng</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We study the real-time dynamics retrieval from a time series via the
time-frequency (TF) analysis with the minimal latency guarantee. While
different from the well-known intrinsic latency definition in the filter
design, a rigorous definition of intrinsic latency for different time-frequency
representations (TFR) is provided, including the short time Fourier transform
(STFT), synchrosqeezing transform (SST) and reassignment method (RM). To
achieve the minimal latency, a systematic method is proposed to construct an
asymmetric window from a well-designed symmetric one based on the concept of
minimum-phase, if the window satisfies some weak conditions. We theoretically
show that the TFR determined by SST with the constructed asymmetric window does
have a smaller intrinsic latency. Finally, the music onset detection problem is
studied to show the strength of the proposed algorithm.
</dc:description>
 <dc:description>Comment: 29 pages, 7 figures</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09058</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributional Semantics Approach to Implicit Language Learning</dc:title>
 <dc:creator>Alikaniotis, Dimitrios</dc:creator>
 <dc:creator>Williams, John N.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In the present paper we show that distributional information is particularly
important when considering concept availability under implicit language
learning conditions. Based on results from different behavioural experiments we
argue that the implicit learnability of semantic regularities depends on the
degree to which the relevant concept is reflected in language use. In our
simulations, we train a Vector-Space model on either an English or a Chinese
corpus and then feed the resulting representations to a feed-forward neural
network. The task of the neural network was to find a mapping between the word
representations and the novel words. Using datasets from four behavioural
experiments, which used different semantic manipulations, we were able to
obtain learning patterns very similar to those obtained by humans.
</dc:description>
 <dc:description>Comment: 5 pages, 7 figures, NetWords 2015</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09065</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The complexity of positive semidefinite matrix factorization</dc:title>
 <dc:creator>Shitov, Yaroslav</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Let $A$ be a matrix with nonnegative real entries. The PSD rank of $A$ is the
smallest integer $k$ for which there exist $k\times k$ real PSD matrices
$B_1,\ldots,B_m$, $C_1,\ldots,C_n$ satisfying
$A(i|j)=\operatorname{tr}(B_iC_j)$ for all $i,j$. This paper determines the
computational complexity status of the PSD rank. Namely, we show that the
problem of computing this function is polynomial-time equivalent to the
existential theory of the reals.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09072</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resolution- and throughput-enhanced spectroscopy using high-throughput
  computational slit</dc:title>
 <dc:creator>Kazemzadeh, Farnoud</dc:creator>
 <dc:creator>Wong, Alexander</dc:creator>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  There exists a fundamental tradeoff between spectral resolution and the
efficiency or throughput for all optical spectrometers. The primary factors
affecting the spectral resolution and throughput of an optical spectrometer are
the size of the entrance aperture and the optical power of the focusing
element. Thus far collective optimization of the above mentioned has proven
difficult. Here, we introduce the concept of high-throughput computational
slits (HTCS), a numerical technique for improving both the effective spectral
resolution and efficiency of a spectrometer. The proposed HTCS approach was
experimentally validated using an optical spectrometer configured with a 200 um
entrance aperture, test, and a 50 um entrance aperture, control, demonstrating
improvements in spectral resolution of the spectrum by ~ 50% over the control
spectral resolution and improvements in efficiency of &gt; 2 times over the
efficiency of the largest entrance aperture used in the study while producing
highly accurate spectra.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09072</dc:identifier>
 <dc:identifier>doi:10.1364/OL.41.004352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09073</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locally Recoverable codes from rational maps</dc:title>
 <dc:creator>Munuera, Carlos</dc:creator>
 <dc:creator>Ten&#xf3;rio, Wanderson</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We give a method to construct Locally Recoverable Error-Correcting codes.
This method is based on the use of rational maps between affine spaces. The
recovery of erasures is carried out by Lagrangian interpolation in general and
simply by one addition in some good cases.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09075</identifier>
 <datestamp>2017-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Keystroke Biometric Anomaly Detection</dc:title>
 <dc:creator>Monaco, John V.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Keystroke Biometrics Ongoing Competition (KBOC) presented an anomaly
detection challenge with a public keystroke dataset containing a large number
of subjects and real-world aspects. Over 300 subjects typed case-insensitive
repetitions of their first and last name, and as a result, keystroke sequences
could vary in length and order depending on the usage of modifier keys. To deal
with this, a keystroke alignment preprocessing algorithm was developed to
establish a semantic correspondence between keystrokes in mismatched sequences.
The method is robust in the sense that query keystroke sequences need only
approximately match a target sequence, and alignment is agnostic to the
particular anomaly detector used. This paper describes the fifteen
best-performing anomaly detection systems submitted to the KBOC, which ranged
from auto-encoding neural networks to ensemble methods. Manhattan distance
achieved the lowest equal error rate of 5.32%, while all fifteen systems
performed better than any other submission. Performance gains are shown to be
due in large part not to the particular anomaly detector, but to preprocessing
and score normalization techniques.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09076</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized Caching in Two-layer Networks: Algorithms and Limits</dc:title>
 <dc:creator>Zhang, Lin</dc:creator>
 <dc:creator>Wang, Zhao</dc:creator>
 <dc:creator>Xiao, Ming</dc:creator>
 <dc:creator>Wu, Gang</dc:creator>
 <dc:creator>Li, Shaoqian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The decentralized caching is studied in two-layer networks, where users
request contents through intermediate nodes (helpers) from a file server. By
placing contents randomly and independently in each node and carefully
designing the data delivery, the correlations of the pre-stored contents across
layers can be utilized to reduce the transmission rates in the network. A
hybrid caching scheme is developed by exploiting the cross-layer storage
correlations, the single-layer multicast opportunities from the server (each
helper) to helpers (the attached users), and the cross-layer multicast
opportunities from the server to users. It is observed that, by the hybrid
caching scheme, the achievable rate in the first layer is reduced without
compromising the achievable rate in the second layer compared with the state of
art. Furthermore, the achievable rate region is shown to be order-optimal and
lies within constant margins to the information theoretic optimum. In
particular, the multiplicative and additive factors are carefully sharpened to
be $\frac{1}{48}$ and $4$, respectively.
</dc:description>
 <dc:description>Comment: This manuscript has been submitted to IEEE Transactions on Mobile
  Computing</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09082</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formation of homophily in academic performance: students prefer to
  change their friends rather than performance</dc:title>
 <dc:creator>Smirnov, Ivan</dc:creator>
 <dc:creator>Thurner, Stefan</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Homophily, the tendency of individuals to associate with others who share
similar traits, has been identified as a major driving force in the formation
and evolution of social ties. In many cases, it is not clear if homophily is
the result of a socialization process, where individuals change their traits
according to the dominance of that trait in their local social networks, or if
it results from a selection process, in which individuals reshape their social
networks so that their traits match those in the new environment. Here we
demonstrate the detailed temporal formation of strong homophily in academic
achievements of high school and university students. We analyze a unique
dataset that contains information about the detailed time evolution of a
friendship network of 6,000 students across 42 months. Combining the evolving
social network data with the time series of the academic performance (GPA) of
individual students, we show that academic homophily is a result of selection:
students prefer to gradually reorganize their social networks according to
their performance levels, rather than adapting their performance to the level
of their local group. We find no signs for a pull effect, where a social
environment of good performers motivates bad students to improve their
performance. We are able to understand the underlying dynamics of grades and
networks with a simple model. The lack of a social pull effect in classical
educational settings could have important implications for the understanding of
the observed persistence of segregation, inequality and social immobility in
societies.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09082</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0183473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09093</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An IoT Architecture for Wide Area Measurement Systems: a Virtualized PMU
  Based Approach</dc:title>
 <dc:creator>Meloni, Alessio</dc:creator>
 <dc:creator>Pegoraro, Paolo Attilio</dc:creator>
 <dc:creator>Atzori, Luigi</dc:creator>
 <dc:creator>Sulis, Sara</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Internet of Things (IoT) technologies are pervading different application
domains by relying on sensing and actuating devices that share, process and
present meaningful real-world information. One of the most important of these
domains is certainly the Smart Grid (SG), where the use of advanced measurement
and control equipment and the diffusion of communication technologies are
making an adaptive, reliable, and efficient management of the energy possible,
with several new applications. In this scenario, this paper focuses on one of
the major IoT features, which is the virtualization, and proposes an IoT
solution for wide area measurement systems where virtualized phasor measurement
resources are introduced. Such a solution is intended to make a programmable
and smart environment fostering interoperability, reusability and flexibility
of SG services. The performance of the system is evaluated for both the traffic
generated and the latency to understand which scenarios can benefit from its
deployment.
</dc:description>
 <dc:description>Comment: in IEEE International Energy Conference 2016</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09093</dc:identifier>
 <dc:identifier>doi:10.1109/ENERGYCON.2016.7513935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09099</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Colorability Saturation Games</dc:title>
 <dc:creator>Keusch, Ralph</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>91A46</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We consider the following two-player game: Maxi and Mini start with the empty
graph on $n$ vertices and take turns, always adding one additional edge to the
graph such that the chromatic number is at most $k$, where $k \in N$ is a given
parameter. The game is over when the graph is saturated and no further edge can
be inserted. Maxi wants to maximize the length of the game while Mini wants to
minimize it. The score $s(n,k)$ denotes the final number of edges in the graph,
given that both players played optimally.
  This colorability game belongs to the general class of saturation games which
aroused interest in the field of combinatorial games during the last years, as
they exhibit simple yet challenging problems. The analysis of the described
colorability saturation game has been initiated recently by Hefetz et al.
[European J. of Comb., Vol. 51(C), 2016]. In this paper, we provide
almost-matching lower and upper bounds on the score $s(n,k)$ of the game. In
addition, we consider the special case $k=4$ for which we prove
$s(n,4)=n^2/3+O(n)$.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09101</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modularity of regular and treelike graphs</dc:title>
 <dc:creator>McDiarmid, Colin</dc:creator>
 <dc:creator>Skerman, Fiona</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Clustering algorithms for large networks typically use modularity values to
test which partitions of the vertex set better represent structure in the data.
The modularity of a graph is the maximum modularity of a partition. We consider
the modularity of two kinds of graphs.
  For $r$-regular graphs with a given number of vertices, we investigate the
minimum possible modularity, the typical modularity, and the maximum possible
modularity. In particular, we see that for random cubic graphs the modularity
is usually in the interval $(0.666, 0.804)$, and for random $r$-regular graphs
with large $r$ it usually is of order $1/\sqrt{r}$. These results help to
establish baselines for statistical tests on regular graphs.
  The modularity of cycles and low degree trees is known to be close to 1: we
extend these results to `treelike' graphs, where the product of treewidth and
maximum degree is much less than the number of edges. This yields for example
the (deterministic) lower bound $0.666$ mentioned above on the modularity of
random cubic graphs.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09106</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new trace bilinear form on cyclic $\mathbb{F}_q$-linear
  $\mathbb{F}_{q^t}$-codes</dc:title>
 <dc:creator>Gao, Yun</dc:creator>
 <dc:creator>Wu, Tingting</dc:creator>
 <dc:creator>Fu, Fang-Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Let $\mathbb{F}_q$ be a finite field of cardinality $q$, where $q$ is a power
of a prime number $p$, $t\geq 2$ an even number satisfying $t \not\equiv 1
\;(\bmod \;p)$ and $\mathbb{F}_{q^t}$ an extension field of $\mathbb{F}_q$ with
degree $t$. First, a new trace bilinear form on $\mathbb{F}_{{q^t}}^n$ which is
called $\Delta$-bilinear form is given, where $n$ is a positive integer coprime
to $q$. Then according to this new trace bilinear form, bases and enumeration
of cyclic $\Delta$-self-orthogonal and cyclic $\Delta$-self-dual
$\mathbb{F}_q$-linear $\mathbb{F}_{q^t}$-codes are investigated when $t=2$.
Furthermore, some good $\mathbb{F}_q$-linear $\mathbb{F}_{q^2}$-codes are
obtained.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09107</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How many subsets of edges of a directed multigraph can be represented as
  trails?</dc:title>
 <dc:creator>Shayani, Joseph</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  For each subset of edges of a (directed multi-) graph, one may determine
whether the edges can be represented as a trail. I prove that the fraction
trail-representable subsets of edges is at most $O(\sqrt{\log m}/\sqrt{m})$,
where $m$ is the number of edges, and show by example that the upper bound is
nearly tight.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09110</identifier>
 <datestamp>2016-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesis of Strategies Using the Hoare Logic of Angelic and Demonic
  Nondeterminism</dc:title>
 <dc:creator>Mamouras, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:description>  We study a propositional variant of Hoare logic that can be used for
reasoning about programs that exhibit both angelic and demonic nondeterminism.
We work in an uninterpreted setting, where the meaning of the atomic actions is
specified axiomatically using hypotheses of a certain form. Our logical
formalism is entirely compositional and it subsumes the non-compositional
formalism of safety games on finite graphs. We present sound and complete
Hoare-style calculi that are useful for establishing partial-correctness
assertions, as well as for synthesizing implementations. The computational
complexity of the Hoare theory of dual nondeterminism is investigated using
operational models, and it is shown that the theory is complete for exponential
time.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09110</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 12, Issue 3 (September
  5, 2016) lmcs:2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09116</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive PMU-based Distribution System State Estimation exploiting the
  Cloud-based IoT paradigm</dc:title>
 <dc:creator>Pegoraro, Paolo Attilio</dc:creator>
 <dc:creator>Meloni, Alessio</dc:creator>
 <dc:creator>Atzori, Luigi</dc:creator>
 <dc:creator>Castello, Paolo</dc:creator>
 <dc:creator>Sulis, Sara</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper presents an adaptive Distribution System State Estimation (DSSE)
which relies on a Cloud-based IoT paradigm. The methodology is adaptive in
terms of the rate of execution of the estimation process which varies depending
on the indications of the distributed measurement system. The system is
composed, in particular, of Phasor Measurement Units (PMUs). PMUs are
virtualized with respect to the physical devices and the corresponding
virtualizing modules run in the communication network edge (i.e. closer to the
physical objects). PMUs are set at a higher measurement rate, while the
estimation process works at a given slower rate, for example once per second,
in normal operative conditions. A local decision algorithm implemented in the
virtualized module, monitors the measured quantities in order to detect and
address possible unexpected dynamics. In particular, different metrics can be
applied: the variations and the trend of variation of the rms voltage values,
but also the Rate Of Change Of Frequency (ROCOF) of the monitored signals can
be used to trigger rate variation in the DSSE.In case dynamics are detected,
the measurement data is sent to the DSSE at higher rates and the estimation
process runs consequently on a finer time scale. In the considered system only
application level entities are located in the Cloud, thus allowing to obtain a
bandwidth-efficient and smart data transmission. The results obtained on a
13-bus systems prove the goodness of the proposed methodologies.
</dc:description>
 <dc:description>Comment: in IEEE International Instrumentation and Measurement Technology
  Conference 2016</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09116</dc:identifier>
 <dc:identifier>doi:10.1109/I2MTC.2016.7520461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09118</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A spectral-spatial fusion model for robust blood pulse waveform
  extraction in photoplethysmographic imaging</dc:title>
 <dc:creator>Amelard, Robert</dc:creator>
 <dc:creator>Clausi, David A</dc:creator>
 <dc:creator>Wong, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  Photoplethysmographic imaging is a camera-based solution for non-contact
cardiovascular monitoring from a distance. This technology enables monitoring
in situations where contact-based devices may be problematic or infeasible,
such as ambulatory, sleep, and multi-individual monitoring. However, extracting
the blood pulse waveform signal is challenging due to the unknown mixture of
relevant (pulsatile) and irrelevant pixels in the scene. Here, we design and
implement a signal fusion framework, FusionPPG, for extracting a blood pulse
waveform signal with strong temporal fidelity from a scene without requiring
anatomical priors (e.g., facial tracking). The extraction problem is posed as a
Bayesian least squares fusion problem, and solved using a novel probabilistic
pulsatility model that incorporates both physiologically derived spectral and
spatial waveform priors to identify pulsatility characteristics in the scene.
Experimental results show statistically significantly improvements compared to
the FaceMeanPPG method ($p&lt;0.001$) and DistancePPG ($p&lt;0.001$) methods. Heart
rates predicted using FusionPPG correlated strongly with ground truth
measurements ($r^2=0.9952$). FusionPPG was the only method able to assess
cardiac arrhythmia via temporal analysis.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09131</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An uplink-downlink duality for cloud radio access network</dc:title>
 <dc:creator>Liu, Liang</dc:creator>
 <dc:creator>Patil, Pratik</dc:creator>
 <dc:creator>Yu, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Uplink-downlink duality refers to the fact that the Gaussian broadcast
channel has the same capacity region as the dual Gaussian multiple-access
channel under the same sumpower constraint. This paper investigates a similar
duality relationship between the uplink and downlink of a cloud radio access
network (C-RAN), where a central processor (CP) cooperatively serves multiple
mobile users through multiple remote radio heads (RRHs) connected to the CP
with finite-capacity fronthaul links. The uplink of such a C-RAN model
corresponds to a multipleaccess relay channel; the downlink corresponds to a
broadcast relay channel. This paper considers compression-based relay
strategies in both uplink and downlink C-RAN, where the quantization noise
levels are functions of the fronthaul link capacities. If the fronthaul
capacities are infinite, the conventional uplinkdownlink duality applies. The
main result of this paper is that even when the fronthaul capacities are
finite, duality continues to hold for the case where independent compression is
applied across each RRH in the sense that when the transmission and compression
designs are jointly optimized, the achievable rate regions of the uplink and
downlink remain identical under the same sum-power and individual fronthaul
capacity constraints. As an application of the duality result, the power
minimization problem in downlink C-RAN can be efficiently solved based on its
uplink counterpart.
</dc:description>
 <dc:description>Comment: to appear in ISIT 2016</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09135</identifier>
 <datestamp>2017-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Zero Delay Coding of Markov Sources: Stationary and Finite
  Memory Codes</dc:title>
 <dc:creator>Wood, Richard G.</dc:creator>
 <dc:creator>Linder, Tam&#xe1;s</dc:creator>
 <dc:creator>Y&#xfc;ksel, Serdar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>68P30</dc:subject>
 <dc:description>  The optimal zero delay coding of a finite state Markov source is considered.
The existence and structure of optimal codes are studied using a stochastic
control formulation. Prior results in the literature established the optimality
of deterministic Markov (Walrand-Varaiya type) coding policies for finite time
horizon problem, and the optimality of both deterministic nonstationary and
randomized stationary policies for the infinite time horizon problem. Our main
result here shows that for any irreducible and aperiodic Markov source with a
finite alphabet, \emph{deterministic and stationary} Markov coding policies are
optimal for the infinite horizon problem. In addition, the finite blocklength
(time horizon) performance on an optimal (stationary and Markov) coding policy
is shown to approach the infinite time horizon optimum at a rate $O(1/T)$. The
results are extended to systems where zero delay communication takes place
across a noisy channel with noiseless feedback.
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09136</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Routing Memento Requests Using Binary Classifiers</dc:title>
 <dc:creator>Bornand, Nicolas J.</dc:creator>
 <dc:creator>Balakireva, Lyudmila</dc:creator>
 <dc:creator>Van de Sompel, Herbert</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:description>  The Memento protocol provides a uniform approach to query individual web
archives. Soon after its emergence, Memento Aggregator infrastructure was
introduced that supports querying across multiple archives simultaneously. An
Aggregator generates a response by issuing the respective Memento request
against each of the distributed archives it covers. As the number of archives
grows, it becomes increasingly challenging to deliver aggregate responses while
keeping response times and computational costs under control. Ad-hoc heuristic
approaches have been introduced to address this challenge and research has been
conducted aimed at optimizing query routing based on archive profiles. In this
paper, we explore the use of binary, archive-specific classifiers generated on
the basis of the content cached by an Aggregator, to determine whether or not
to query an archive for a given URI. Our results turn out to be readily
applicable and can help to significantly decrease both the number of requests
and the overall response times without compromising on recall. We find, among
others, that classifiers can reduce the average number of requests by 77%
compared to a brute force approach on all archives, and the overall response
time by 42% while maintaining a recall of 0.847.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, 11 tables, accepted to be published at JCDL 2016</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09136</dc:identifier>
 <dc:identifier>doi:10.1145/2910896.2910899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09137</identifier>
 <datestamp>2017-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control-Data Separation across Edge and Cloud for Uplink Communications
  in C-RAN</dc:title>
 <dc:creator>Kang, Jinkyu</dc:creator>
 <dc:creator>Simeone, Osvaldo</dc:creator>
 <dc:creator>Kang, Joonhyuk</dc:creator>
 <dc:creator>Shamai, Shlomo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Fronthaul limitations in terms of capacity and latency motivate the growing
interest in the wireless industry for the study of alternative functional
splits between cloud and edge nodes in Cloud Radio Access Network (C-RAN). This
work contributes to this line of work by investigating the optimal functional
split of control and data plane functionalities at the edge nodes and at the
Remote Cloud Center (RCC) as a function of the fronthaul latency. The model
under study consists of a two-user time-varying uplink channel in which the RCC
has global but delayed channel state information (CSI) due to fronthaul
latency, while edge nodes have local but timely CSI. Adopting the adaptive
sum-rate as the performance criterion, functional splits whereby the control
functionality of rate selection and the decoding of the data-plane frames are
carried out at either the edge nodes or at the RCC are compared through
analysis and numerical results.
</dc:description>
 <dc:description>Comment: This work is a part of newly submitted manuscript in arXiv:1706.06451</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09140</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic foundations for qualitative calculi and networks</dc:title>
 <dc:creator>Hirsch, Robin</dc:creator>
 <dc:creator>Jackson, Marcel</dc:creator>
 <dc:creator>Kowalski, Tomasz</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T30</dc:subject>
 <dc:description>  A qualitative representation $\phi$ is like an ordinary representation of a
relation algebra, but instead of requiring $(a; b)^\phi = a^\phi | b^\phi$, as
we do for ordinary representations, we only require that $c^\phi\supseteq
a^\phi | b^\phi \iff c\geq a ; b$, for each $c$ in the algebra. A constraint
network is qualitatively satisfiable if its nodes can be mapped to elements of
a qualitative representation, preserving the constraints. If a constraint
network is satisfiable then it is clearly qualitatively satisfiable, but the
converse can fail. However, for a wide range of relation algebras including the
point algebra, the Allen Interval Algebra, RCC8 and many others, a network is
satisfiable if and only if it is qualitatively satisfiable.
  Unlike ordinary composition, the weak composition arising from qualitative
representations need not be associative, so we can generalise by considering
network satisfaction problems over non-associative algebras. We prove that
computationally, qualitative representations have many advantages over ordinary
representations: whereas many finite relation algebras have only infinite
representations, every finite qualitatively representable algebra has a finite
qualitative representation; the representability problem for (the atom
structures of) finite non-associative algebras is NP-complete; the network
satisfaction problem over a finite qualitatively representable algebra is
always in NP; the validity of equations over qualitative representations is
co-NP-complete. On the other hand we prove that there is no finite
axiomatisation of the class of qualitatively representable algebras.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09140</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09152</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Actor-critic versus direct policy search: a comparison based on sample
  complexity</dc:title>
 <dc:creator>de Broissia, Arnaud de Froissard</dc:creator>
 <dc:creator>Sigaud, Olivier</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sample efficiency is a critical property when optimizing policy parameters
for the controller of a robot. In this paper, we evaluate two state-of-the-art
policy optimization algorithms. One is a recent deep reinforcement learning
method based on an actor-critic algorithm, Deep Deterministic Policy Gradient
(DDPG), that has been shown to perform well on various control benchmarks. The
other one is a direct policy search method, Covariance Matrix Adaptation
Evolution Strategy (CMA-ES), a black-box optimization method that is widely
used for robot learning. The algorithms are evaluated on a continuous version
of the mountain car benchmark problem, so as to compare their sample
complexity. From a preliminary analysis, we expect DDPG to be more sample
efficient than CMA-ES, which is confirmed by our experimental results.
</dc:description>
 <dc:description>Comment: Proceedings JFPDA (Journees Francaises Planification Decision
  Apprentissage)</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09155</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated first-order primal-dual proximal methods for linearly
  constrained composite convex programming</dc:title>
 <dc:creator>Xu, Yangyang</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>90C06, 90C25, 68W40, 49M27</dc:subject>
 <dc:description>  Motivated by big data applications, first-order methods have been extremely
popular in recent years. However, naive gradient methods generally converge
slowly. Hence, much efforts have been made to accelerate various first-order
methods. This paper proposes two accelerated methods towards solving structured
linearly constrained convex programming, for which we assume composite convex
objective.
  The first method is the accelerated linearized augmented Lagrangian method
(LALM). At each update to the primal variable, it allows linearization to the
differentiable function and also the augmented term, and thus it enables easy
subproblems. Assuming merely weak convexity, we show that LALM owns $O(1/t)$
convergence if parameters are kept fixed during all the iterations and can be
accelerated to $O(1/t^2)$ if the parameters are adapted, where $t$ is the
number of total iterations.
  The second method is the accelerated linearized alternating direction method
of multipliers (LADMM). In addition to the composite convexity, it further
assumes two-block structure on the objective. Different from classic ADMM, our
method allows linearization to the objective and also augmented term to make
the update simple. Assuming strong convexity on one block variable, we show
that LADMM also enjoys $O(1/t^2)$ convergence with adaptive parameters. This
result is a significant improvement over that in [Goldstein et. al, SIIMS'14],
which requires strong convexity on both block variables and no linearization to
the objective or augmented term.
  Numerical experiments are performed on quadratic programming, image
denoising, and support vector machine. The proposed accelerated methods are
compared to nonaccelerated ones and also existing accelerated methods. The
results demonstrate the validness of acceleration and superior performance of
the proposed methods over existing ones.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09163</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimising The Input Window Alignment in CD-DNN Based Phoneme
  Recognition for Low Latency Processing</dc:title>
 <dc:creator>Dhaka, Akash Kumar</dc:creator>
 <dc:creator>Salvi, Giampiero</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a systematic analysis on the performance of a phonetic recogniser
when the window of input features is not symmetric with respect to the current
frame. The recogniser is based on Context Dependent Deep Neural Networks
(CD-DNNs) and Hidden Markov Models (HMMs). The objective is to reduce the
latency of the system by reducing the number of future feature frames required
to estimate the current output. Our tests performed on the TIMIT database show
that the performance does not degrade when the input window is shifted up to 5
frames in the past compared to common practice (no future frame). This
corresponds to improving the latency by 50 ms in our settings. Our tests also
show that the best results are not obtained with the symmetric window commonly
employed, but with an asymmetric window with eight past and two future context
frames, although this observation should be confirmed on other data sets. The
reduction in latency suggested by our results is critical for specific
applications such as real-time lip synchronisation for tele-presence, but may
also be beneficial in general applications to improve the lag in human-machine
spoken interaction.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09176</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tighter Lower Bounds on Mutual Information for Fiber-Optic Channels</dc:title>
 <dc:creator>Irukulapati, Naga V.</dc:creator>
 <dc:creator>Secondini, Marco</dc:creator>
 <dc:creator>Agrell, Erik</dc:creator>
 <dc:creator>Johannisson, Pontus</dc:creator>
 <dc:creator>Wymeersch, Henk</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  In fiber-optic communications, evaluation of mutual information (MI) is still
an open issue due to the unavailability of an exact and mathematically
tractable channel model. Traditionally, lower bounds on MI are computed by
approximating the (original) channel with an auxiliary forward channel. In this
paper, lower bounds are computed using an auxiliary backward channel, which has
not been previously considered in the context of fiber-optic communications.
Distributions obtained through two variations of the stochastic digital
backpropagation (SDBP) algorithm are used as auxiliary backward channels and
these bounds are compared with bounds obtained through the conventional digital
backpropagation (DBP). Through simulations, higher information rates were
achieved with SDBP compared with DBP, which implies that tighter lower bound on
MI can be achieved through SDBP.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, submitted to Journal of Lightwave Technology</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09178</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-frequency asymptotic compression of dense BEM matrices for general
  geometries without ray tracing</dc:title>
 <dc:creator>Huybrechs, Daan</dc:creator>
 <dc:creator>Opsomer, Peter</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>65N38 (Primary), 65F50, 45A05, 45M05, 65R20 (Secondary)</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.1.9</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  Wave propagation and scattering problems in acoustics are often solved with
boundary element methods. They lead to a discretization matrix that is
typically dense and large: its size and condition number grow with increasing
frequency. Yet, high frequency scattering problems are intrinsically local in
nature, which is well represented by highly localized rays bouncing around.
Asymptotic methods can be used to reduce the size of the linear system, even
making it frequency independent, by explicitly extracting the oscillatory
properties from the solution using ray tracing or analogous techniques.
However, ray tracing becomes expensive or even intractable in the presence of
(multiple) scattering obstacles with complicated geometries. In this paper, we
start from the same discretization that constructs the fully resolved large and
dense matrix, and achieve asymptotic compression by explicitly localizing the
Green's function instead. This results in a large but sparse matrix, with a
faster associated matrix-vector product and, as numerical experiments indicate,
a much improved condition number. Though an appropriate localisation of the
Green's function also depends on asymptotic information unavailable for general
geometries, we can construct it adaptively in a frequency sweep from small to
large frequencies in a way which automatically takes into account a general
incident wave. We show that the approach is robust with respect to non-convex,
multiple and even near-trapping domains, though the compression rate is clearly
lower in the latter case. Furthermore, in spite of its asymptotic nature, the
method is robust with respect to low-order discretizations such as piecewise
constants, linears or cubics, commonly used in applications. On the other hand,
we do not decrease the total number of degrees of freedom compared to a
conventional classical discretization. The combination of the ...
</dc:description>
 <dc:description>Comment: 24 pages, 13 figures</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09184</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disease Trajectory Maps</dc:title>
 <dc:creator>Schulam, Peter</dc:creator>
 <dc:creator>Arora, Raman</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Medical researchers are coming to appreciate that many diseases are in fact
complex, heterogeneous syndromes composed of subpopulations that express
different variants of a related complication. Time series data extracted from
individual electronic health records (EHR) offer an exciting new way to study
subtle differences in the way these diseases progress over time. In this paper,
we focus on answering two questions that can be asked using these databases of
time series. First, we want to understand whether there are individuals with
similar disease trajectories and whether there are a small number of degrees of
freedom that account for differences in trajectories across the population.
Second, we want to understand how important clinical outcomes are associated
with disease trajectories. To answer these questions, we propose the Disease
Trajectory Map (DTM), a novel probabilistic model that learns low-dimensional
representations of sparse and irregularly sampled time series. We propose a
stochastic variational inference algorithm for learning the DTM that allows the
model to scale to large modern medical datasets. To demonstrate the DTM, we
analyze data collected on patients with the complex autoimmune disease,
scleroderma. We find that DTM learns meaningful representations of disease
trajectories and that the representations are significantly associated with
important clinical outcomes.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09187</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Boundary Detection and Classification with Image-level Labels</dc:title>
 <dc:creator>Koh, Jing Yu</dc:creator>
 <dc:creator>Samek, Wojciech</dc:creator>
 <dc:creator>M&#xfc;ller, Klaus-Robert</dc:creator>
 <dc:creator>Binder, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Semantic boundary and edge detection aims at simultaneously detecting object
edge pixels in images and assigning class labels to them. Systematic training
of predictors for this task requires the labeling of edges in images which is a
particularly tedious task. We propose a novel strategy for solving this task,
when pixel-level annotations are not available, performing it in an almost
zero-shot manner by relying on conventional whole image neural net classifiers
that were trained using large bounding boxes. Our method performs the following
two steps at test time. Firstly it predicts the class labels by applying the
trained whole image network to the test images. Secondly, it computes
pixel-wise scores from the obtained predictions by applying backprop gradients
as well as recent visualization algorithms such as deconvolution and layer-wise
relevance propagation. We show that high pixel-wise scores are indicative for
the location of semantic boundaries, which suggests that the semantic boundary
problem can be approached without using edge labels during the training phase.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures, accepted for GCPR 2017 - 39th German Conference
  on Pattern Recognition</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09188</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Three dimensional graph drawing with fixed vertices and one bend per
  edge</dc:title>
 <dc:creator>Wood, David R.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We prove that for every graph $G$, given fixed locations for the vertices of
$G$ in $\mathbb{Z}^3$, there is a three-dimensional grid-drawing of $G$ with
one bend per edge. The best previous bound was three bends per edge.
</dc:description>
 <dc:date>2016-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09190</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semi-Definite Programming approach to low dimensional embedding for
  unsupervised clustering</dc:title>
 <dc:creator>Chr&#xe9;tien, St&#xe9;phane</dc:creator>
 <dc:creator>Dombry, Cl&#xe9;ment</dc:creator>
 <dc:creator>Faivre, Adrien</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a variant of the method of Gu\'edon and Verhynin for
estimating the cluster matrix in the Mixture of Gaussians framework via
Semi-Definite Programming. A clustering oriented embedding is deduced from this
estimate. The procedure is suitable for very high dimensional data because it
is based on pairwise distances only. Theoretical garantees are provided and an
eigenvalue optimisation approach is proposed for computing the embedding. The
performance of the method is illustrated via Monte Carlo experiements and
comparisons with other embeddings from the literature.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09197</identifier>
 <datestamp>2017-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-Free Trajectory Optimization with Monotonic Improvement</dc:title>
 <dc:creator>Akrour, Riad</dc:creator>
 <dc:creator>Abdolmaleki, Abbas</dc:creator>
 <dc:creator>Abdulsamad, Hany</dc:creator>
 <dc:creator>Peters, Jan</dc:creator>
 <dc:creator>Neumann, Gerhard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Many of the recent trajectory optimization algorithms alternate between
linear approximation of the system dynamics around the mean trajectory and
conservative policy update. One way of constraining the policy change is by
bounding the Kullback-Leibler (KL) divergence between successive policies.
These approaches already demonstrated great experimental success in challenging
problems such as end-to-end control of physical systems. However, these
approaches lack any improvement guarantee as the linear approximation of the
system dynamics can introduce a bias in the policy update and prevent
convergence to the optimal policy. In this article, we propose a new model-free
trajectory optimization algorithm with guaranteed monotonic improvement. The
algorithm backpropagates a local, quadratic and time-dependent Q-Function
learned from trajectory data instead of a model of the system dynamics. Our
policy update ensures exact KL-constraint satisfaction without simplifying
assumptions on the system dynamics. We experimentally demonstrate on highly
non-linear control tasks the improvement in performance of our algorithm in
comparison to approaches linearizing the system dynamics. In order to show the
monotonic improvement of our algorithm, we additionally conduct a theoretical
analysis of our policy update scheme to derive a lower bound of the change in
policy return between successive iterations.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09202</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tighter bounds lead to improved classifiers</dc:title>
 <dc:creator>Roux, Nicolas Le</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The standard approach to supervised classification involves the minimization
of a log-loss as an upper bound to the classification error. While this is a
tight bound early on in the optimization, it overemphasizes the influence of
incorrectly classified examples far from the decision boundary. Updating the
upper bound during the optimization leads to improved classification rates
while transforming the learning into a sequence of minimization problems. In
addition, in the context where the classifier is part of a larger system, this
modification makes it possible to link the performance of the classifier to
that of the whole system, allowing the seamless introduction of external
constraints.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09205</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Next Generation Robotics</dc:title>
 <dc:creator>Christensen, Henrik I</dc:creator>
 <dc:creator>Okamura, Allison</dc:creator>
 <dc:creator>Mataric, Maja</dc:creator>
 <dc:creator>Kumar, Vijay</dc:creator>
 <dc:creator>Hager, Greg</dc:creator>
 <dc:creator>Choset, Howie</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The National Robotics Initiative (NRI) was launched 2011 and is about to
celebrate its 5 year anniversary. In parallel with the NRI, the robotics
community, with support from the Computing Community Consortium, engaged in a
series of road mapping exercises. The first version of the roadmap appeared in
September 2009; a second updated version appeared in 2013. While not directly
aligned with the NRI, these road-mapping documents have provided both a useful
charting of the robotics research space, as well as a metric by which to
measure progress. This report sets forth a perspective of progress in robotics
over the past five years, and provides a set of recommendations for the future.
The NRI has in its formulation a strong emphasis on co-robot, i.e., robots that
work directly with people. An obvious question is if this should continue to be
the focus going forward? To try to assess what are the main trends, what has
happened the last 5 years and what may be promising directions for the future a
small CCC sponsored study was launched to have two workshops, one in Washington
DC (March 5th, 2016) and another in San Francisco, CA (March 11th, 2016). In
this report we brief summarize some of the main discussions and observations
from those workshops. We will present a variety of background information in
Section 2, and outline various issues related to progress over the last 5 years
in Section 3. In Section 4 we will outline a number of opportunities for moving
forward. Finally, we will summarize the main points in Section 5.
</dc:description>
 <dc:description>Comment: A Computing Community Consortium (CCC) white paper, 22 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09206</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance of spatial Multi-LRU caching under traffic with temporal
  locality</dc:title>
 <dc:creator>Avranas, Apostolos</dc:creator>
 <dc:creator>Giovanidis, Anastasios</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  In this work a novel family of decentralised caching policies for wireless
networks is introduced, referred to as spatial multi-LRU. These improve
cache-hit probability by exploiting multi-coverage. Two variations are
proposed, the multi-LRU-One and -All, which differ in the number of replicas
inserted in the covering edge-caches. The evaluation is done under spatial
traffic that exhibits temporal locality, with varying content catalogue and
dependent demands. The performance metric is hit probability and the policies
are compared to (1) the single-LRU and (2) an upper bound for all centralised
policies with periodic popularity updates. Numerical results show the multi-LRU
policies outperform both comparison policies. The reason is their passive
adaptability to popularity changes. Between the -One and -All variation, which
one is preferable strongly depends on the available storage space and on
traffic characteristics. The performance also depends on the popularity shape.
</dc:description>
 <dc:description>Comment: 6 pages, double column, invited paper in 5G Workshop, part of
  ISTC'16, Brest, France</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09206</dc:identifier>
 <dc:identifier>2016 9th International Symposium on Turbo Codes and Iterative
  Information Processing (ISTC)</dc:identifier>
 <dc:identifier>doi:10.1109/ISTC.2016.7593134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09219</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation Results on Selector Adaptation in Behavior Trees</dc:title>
 <dc:creator>Hannaford, Blake</dc:creator>
 <dc:creator>Hu, Danying</dc:creator>
 <dc:creator>Zhang, Dianmu</dc:creator>
 <dc:creator>Li, Yangming</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Behavior trees (BTs) emerged from video game development as a graphical
language for modeling intelligent agent behavior. However as initially
implemented, behavior trees are static plans. This paper adds to recent
literature exploring the ability of BTs to adapt to their success or failure in
achieving tasks. The &quot;Selector&quot; node of a BT tries alternative strategies (its
children) and returns success only if all of its children return failure. This
paper studies several means by which Selector nodes can learn from experience,
in particular, learn conditional probabilities of success based on sensor
information, and modify the execution order based on the learned iformation.
Furthermore, a &quot;Greedy Selector&quot; is studied which only tries the child having
the highest success probability. Simulation results indicate significantly
increased task performance, especially when frequentist probability estimate is
conditioned on sensor information. The Greedy selector was ineffective unless
it was preceded by a period of training in which all children were exercised.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09221</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The new challenges of multiplex networks: measures and models</dc:title>
 <dc:creator>Battiston, Federico</dc:creator>
 <dc:creator>Nicosia, Vincenzo</dc:creator>
 <dc:creator>Latora, Vito</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  What do societies, the Internet, and the human brain have in common? They are
all examples of complex relational systems, whose emerging behaviours are
largely determined by the non-trivial networks of interactions among their
constituents, namely individuals, computers, or neurons, rather than the
properties of the units themselves. In the last two decades, network scientists
have proposed models of increasing complexity to better understand real-world
systems. Only recently we have realised that multiplexity, i.e. the coexistence
of several types of interactions among the constituents of a complex system, is
responsible for substantial qualitative and quantitative differences in the
type and variety of behaviours that a complex system can exhibit. As a
consequence, multilayer and multiplex networks have become a hot topic in
complexity science. Here we provide an overview of some of the measures
proposed so far to characterise the structure of multiplex networks, and a
selection of models aiming at reproducing those structural properties and
quantifying their statistical significance. Focusing on a subset of relevant
topics, this brief review is a quite comprehensive introduction to the most
basic tools for the analysis of multiplex networks observed in the real-world.
The wide applicability of multiplex networks as a framework to model complex
systems in different fields, from biology to social sciences, and the
colloquial tone of the paper will make it an interesting read for researchers
working on both theoretical and experimental analysis of networked systems.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09221</dc:identifier>
 <dc:identifier>EPJ Special Topics 226(3), 401-416 (2017)</dc:identifier>
 <dc:identifier>doi:10.1140/epjst/e2016-60274-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09222</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Penambahan emosi menggunakan metode manipulasi prosodi untuk sistem text
  to speech bahasa Indonesia</dc:title>
 <dc:creator>Prini, Salita Ulitia</dc:creator>
 <dc:creator>Prihatmanto, Ary Setijadi</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  Adding an emotions using prosody manipulation method for Indonesian text to
speech system. Text To Speech (TTS) is a system that can convert text in one
language into speech, accordance with the reading of the text in the language
used. The focus of this research is a natural sounding concept, the make
&quot;humanize&quot; for the pronunciation of voice synthesis system Text To Speech.
Humans have emotions / intonation that may affect the sound produced. The main
requirement for the system used Text To Speech in this research is eSpeak, the
database MBROLA using id1, Human Speech Corpus database from a website that
summarizes the words with the highest frequency (Most Common Words) used in a
country. And there are 3 types of emotional / intonation designed base. There
is a happy, angry and sad emotion. Method for develop the emotional filter is
manipulate the relevant features of prosody (especially pitch and duration
value) using a predetermined rate factor that has been established by analyzing
the differences between the standard output Text To Speech and voice recording
with emotional prosody / a particular intonation. The test results for the
perception tests of Human Speech Corpus for happy emotion is 95 %, 96.25 % for
angry emotion and 98.75 % for sad emotions. For perception test system carried
by intelligibility and naturalness test. Intelligibility test for the accuracy
of sound with the original sentence is 93.3%, and for clarity rate for each
sentence is 62.8%. For naturalness, accuracy emotional election amounted to
75.6 % for happy emotion, 73.3 % for angry emotion, and 60 % for sad emotions.
  -----
  Text To Speech (TTS) merupakan suatu sistem yang dapat mengonversi teks dalam
format suatu bahasa menjadi ucapan sesuai dengan pembacaan teks dalam bahasa
yang digunakan.
</dc:description>
 <dc:description>Comment: Keywords: Text To Speech; eSpeak; MBROLA; Human Speech Corpus;
  emotion; intonation; prosody manipulation; emosi; intonasi; manipulasi
  prosodi</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09222</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.1.4140.6165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09233</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unequal Error Protection Querying Policies for the Noisy 20 Questions
  Problem</dc:title>
 <dc:creator>Chung, Hye Won</dc:creator>
 <dc:creator>Sadler, Brian M.</dc:creator>
 <dc:creator>Zheng, Lizhong</dc:creator>
 <dc:creator>Hero, Alfred O.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose an open-loop unequal-error-protection querying
policy based on superposition coding for the noisy 20 questions problem. In
this problem, a player wishes to successively refine an estimate of the value
of a continuous random variable by posing binary queries and receiving noisy
responses. When the queries are designed non-adaptively as a single block and
the noisy responses are modeled as the output of a binary symmetric channel the
20 questions problem can be mapped to an equivalent problem of channel coding
with unequal error protection (UEP). A new non-adaptive querying strategy based
on UEP superposition coding is introduced whose estimation error decreases with
an exponential rate of convergence that is significantly better than that of
the UEP repetition coding introduced by Variani et al. (2015). With the
proposed querying strategy, the rate of exponential decrease in the number of
queries matches the rate of a closed-loop adaptive scheme where queries are
sequentially designed with the benefit of feedback. Furthermore, the achievable
error exponent is significantly better than that of random block codes
employing equal error protection.
</dc:description>
 <dc:description>Comment: To appear in IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09233</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2760634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09236</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Future of Computing Research: Industry-Academic Collaborations</dc:title>
 <dc:creator>Boules, Nady</dc:creator>
 <dc:creator>Douglas, Khari</dc:creator>
 <dc:creator>Feldman, Stuart</dc:creator>
 <dc:creator>Fix, Limor</dc:creator>
 <dc:creator>Hager, Gregory</dc:creator>
 <dc:creator>Hailpern, Brent</dc:creator>
 <dc:creator>Hebert, Martial</dc:creator>
 <dc:creator>Lopresti, Dan</dc:creator>
 <dc:creator>Mynatt, Beth</dc:creator>
 <dc:creator>Rossbach, Chris</dc:creator>
 <dc:creator>Wright, Helen</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  IT-driven innovation is an enormous factor in the worldwide economic
leadership of the United States. It is larger than finance, construction, or
transportation, and it employs nearly 6% of the US workforce. The top three
companies, as measured by market capitalization, are IT companies - Apple,
Google (now Alphabet), and Microsoft. Facebook, a relatively recent entry in
the top 10 list by market capitalization has surpassed Walmart, the nation's
largest retailer, and the largest employer in the world. The net income of just
the top three exceeds $80 billion - roughly 100 times the total budget of the
NSF CISE directorate which funds 87% of computing research. In short, the
direct return on federal research investments in IT research has been
enormously profitable to the nation.
  The IT industry ecosystem is also evolving. The time from conception to
market of successful products has been cut from years to months. Product life
cycles are increasingly a year or less. This change has pressured companies to
focus industrial R&amp;D on a pipeline or portfolio of technologies that bring
immediate, or almost immediate, value to the companies. To defeat the
competition and stay ahead of the pack, a company must devote resources to
realizing gains that are shorter term, and must remain agile to respond quickly
to market changes driven by new technologies, new startups, evolving user
experience expectations, and the continuous consumer demand for new and
exciting products.
  Amidst this landscape, the Computing Community Consortium convened a
round-table of industry and academic participants to better understand the
landscape of industry-academic interaction, and to discuss possible actions
that might be taken to enhance those interactions. We close with some
recommendations for actions that could expand the lively conversation we
experienced at the round-table to a national scale.
</dc:description>
 <dc:description>Comment: A Computing Community Consortium (CCC) white paper, 19 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09239</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Concept Taxonomies from Multi-modal Data</dc:title>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:creator>Hu, Zhiting</dc:creator>
 <dc:creator>Deng, Yuntian</dc:creator>
 <dc:creator>Sachan, Mrinmaya</dc:creator>
 <dc:creator>Yan, Zhicheng</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of automatically building hypernym taxonomies from
textual and visual data. Previous works in taxonomy induction generally ignore
the increasingly prominent visual data, which encode important perceptual
semantics. Instead, we propose a probabilistic model for taxonomy induction by
jointly leveraging text and images. To avoid hand-crafted feature engineering,
we design end-to-end features based on distributed representations of images
and words. The model is discriminatively trained given a small set of existing
ontologies and is capable of building full taxonomies from scratch for a
collection of unseen conceptual label items with associated images. We evaluate
our model and features on the WordNet hierarchies, where our system outperforms
previous approaches by a large gap.
</dc:description>
 <dc:description>Comment: To appear in ACL 2016</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09242</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Swift: Compiled Inference for Probabilistic Programming Languages</dc:title>
 <dc:creator>Wu, Yi</dc:creator>
 <dc:creator>Li, Lei</dc:creator>
 <dc:creator>Russell, Stuart</dc:creator>
 <dc:creator>Bodik, Rastislav</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  A probabilistic program defines a probability measure over its semantic
structures. One common goal of probabilistic programming languages (PPLs) is to
compute posterior probabilities for arbitrary models and queries, given
observed evidence, using a generic inference engine. Most PPL inference
engines---even the compiled ones---incur significant runtime interpretation
overhead, especially for contingent and open-universe models. This paper
describes Swift, a compiler for the BLOG PPL. Swift-generated code incorporates
optimizations that eliminate interpretation overhead, maintain dynamic
dependencies efficiently, and handle memory management for possible worlds of
varying sizes. Experiments comparing Swift with other PPL engines on a variety
of inference problems demonstrate speedups ranging from 12x to 326x.
</dc:description>
 <dc:description>Comment: IJCAI 2016</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09264</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How smart does your profile image look? Estimating intelligence from
  social network profile images</dc:title>
 <dc:creator>Wei, Xingjie</dc:creator>
 <dc:creator>Stillwell, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Profile images on social networks are users' opportunity to present
themselves and to affect how others judge them. We examine what Facebook images
say about users' perceived and measured intelligence. 1,122 Facebook users
completed a matrices intelligence test and shared their current Facebook
profile image. Strangers also rated the images for perceived intelligence. We
use automatically extracted image features to predict both measured and
perceived intelligence. Intelligence estimation from images is a difficult task
even for humans, but experimental results show that human accuracy can be
equalled using computing methods. We report the image features that predict
both measured and perceived intelligence, and highlight misleading features
such as &quot;smiling&quot; and &quot;wearing glasses&quot; that are correlated with perceived but
not measured intelligence. Our results give insights into inaccurate
stereotyping from profile images and also have implications for privacy,
especially since in most social networks profile images are public by default.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09264</dc:identifier>
 <dc:identifier>doi:10.1145/3018661.3018663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09270</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinodynamic Motion Planning: A Novel Type Of Nonlinear, Passive Damping
  Forces And Advantages</dc:title>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This article extends the capabilities of the harmonic potential field
approach to planning to cover both the kinematic and dynamic aspects of a robot
motion. The suggested approach converts the gradient guidance field from a
harmonic potential to a control signal by augmenting it with a novel type of
damping forces called nonlinear, anisotropic, damping forces. The combination
of the two provides a signal that can both guide a robot and effectively manage
its dynamics. The kinodynamic planning signal inherits the guidance
capabilities of the harmonic gradient field. It can also be easily configured
to efficiently suppress the inertia-induced transients in the robot trajectory
without compromising the speed of operation. The approach works with
dissipative systems as well as systems acted on by external forces without
needing the full knowledge of the system dynamics. Theoretical developments and
simulation results are provided in this article.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09270</dc:identifier>
 <dc:identifier>IEEE Robotics And Automation Magazine, March 2010, Pp. 85-99</dc:identifier>
 <dc:identifier>doi:10.1109/MRA.2010.935794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09274</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compression of Neural Machine Translation Models via Pruning</dc:title>
 <dc:creator>See, Abigail</dc:creator>
 <dc:creator>Luong, Minh-Thang</dc:creator>
 <dc:creator>Manning, Christopher D.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Neural Machine Translation (NMT), like many other deep learning domains,
typically suffers from over-parameterization, resulting in large storage sizes.
This paper examines three simple magnitude-based pruning schemes to compress
NMT models, namely class-blind, class-uniform, and class-distribution, which
differ in terms of how pruning thresholds are computed for the different
classes of weights in the NMT architecture. We demonstrate the efficacy of
weight pruning as a compression technique for a state-of-the-art NMT system. We
show that an NMT model with over 200 million parameters can be pruned by 40%
with very little performance loss as measured on the WMT'14 English-German
translation task. This sheds light on the distribution of redundancy in the NMT
architecture. Our main result is that with retraining, we can recover and even
surpass the original performance with an 80%-pruned model.
</dc:description>
 <dc:description>Comment: Accepted to CoNLL 2016. 9 pages plus references</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09275</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Harmonic Potential Approach For Simultaneous Planning And Control Of A
  Generic UAV Platform</dc:title>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Simultaneous planning and control of a large variety of unmanned aerial
vehicles (UAVs) is tackled using the harmonic potential field (HPF) approach. A
dense reference velocity field generated from the gradient of an HPF is used to
regulate the velocity of the UAV concerned in a manner that would propel the
UAV to a target point while enforcing the constraints on behavior that were a
priori encoded in the reference field. The regulation process is carried-out
using a novel and simple concept called the: virtual velocity attractor (VVA).
The combined effect of the HPF gradient and the VVA is found able to yield an
efficient, easy to implement, well-behaved and provably-correct
context-sensitive control action that suits a wide variety of UAVs. The
approach is developed and basic proofs of correctness are provided along with
simulation results.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09275</dc:identifier>
 <dc:identifier>Journal Of Intelligent &amp; Robotic Systems: Volume 65, Issue 1
  (2012), Page 153-173</dc:identifier>
 <dc:identifier>doi:10.1007/s10846-011-9570-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09278</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion Planning With Gamma-Harmonic Potential Fields</dc:title>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper extends the capabilities of the harmonic potential field (HPF)
approach to planning. The extension covers the situation where the workspace of
a robot cannot be segmented into geometrical subregions where each region has
an attribute of its own. The suggested approach uses a task-centered,
probabilistic descriptor of the workspace as an input to the planner. This
descriptor is processed, along with a goal point, to yield the navigation
policy needed to steer the agent from any point in its workspace to the target.
The approach is easily adaptable to planning in a cluttered environment
containing a vector drift field. The extension of the HPF approach is based on
the physical analogy with an electric current flowing in a nonhomogeneous
conducting medium. The resulting potential field is known as the gamma-harmonic
potential (GHPF). Proofs of the ability of the modified approach to avoid
zero-probability (definite threat) regions and to converge to the goal are
provided. The capabilities of the planer are demonstrated using simulation.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09278</dc:identifier>
 <dc:identifier>IEEE Transactions on Aerospace and Electronic Systems, 48 (4),
  2012, pp. 2786 - 2801</dc:identifier>
 <dc:identifier>doi:10.1109/TAES.2012.6324661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09279</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The matching relaxation for a class of generalized set partitioning
  problems</dc:title>
 <dc:creator>Cavalcante, Evellyn</dc:creator>
 <dc:creator>Oppen, Johan</dc:creator>
 <dc:creator>Samer, Phillippe</dc:creator>
 <dc:creator>Urrutia, Sebasti&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>05, 68, 90</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:description>  This paper introduces a discrete relaxation for the class of combinatorial
optimization problems which can be described by a set partitioning formulation
under packing constraints. We present two combinatorial relaxations based on
computing maximum weighted matchings in suitable graphs. Besides providing dual
bounds, the relaxations are also used on a variable reduction technique and a
matheuristic. We show how that general method can be tailored to sample
applications and, in particular, perform a successful computational evaluation
with benchmark instances of a problem in maritime logistics.
</dc:description>
 <dc:description>Comment: 29 pages; preliminary (4-page) version presented at CTW 2016
  (Cologne-Twente Workshop on Graphs and Combinatorial Optimization)</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09281</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiphase Segmentation For Simultaneously Homogeneous and Textural
  Images</dc:title>
 <dc:creator>Thai, Duy Hoang</dc:creator>
 <dc:creator>Mentch, Lucas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmentation remains an important problem in image processing. For
homogeneous (piecewise smooth) images, a number of important models have been
developed and refined over the past several decades. However, these models
often fail when applied to the substantially larger class of natural images
that simultaneously contain regions of both texture and homogeneity. This work
introduces a bi-level constrained minimization model for simultaneous
multiphase segmentation of images containing both homogeneous and textural
regions. We develop novel norms defined in different functional Banach spaces
for the segmentation which results in a non-convex minimization. Finally, we
develop a generalized notion of segmentation delving into approximation theory
and demonstrating that a more refined decomposition of these images results in
multiple meaningful components. Both theoretical results and demonstrations on
natural images are provided.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09282</identifier>
 <datestamp>2017-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning without Forgetting</dc:title>
 <dc:creator>Li, Zhizhong</dc:creator>
 <dc:creator>Hoiem, Derek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  When building a unified vision system or gradually adding new capabilities to
a system, the usual assumption is that training data for all tasks is always
available. However, as the number of tasks grows, storing and retraining on
such data becomes infeasible. A new problem arises where we add new
capabilities to a Convolutional Neural Network (CNN), but the training data for
its existing capabilities are unavailable. We propose our Learning without
Forgetting method, which uses only new task data to train the network while
preserving the original capabilities. Our method performs favorably compared to
commonly used feature extraction and fine-tuning adaption techniques and
performs similarly to multitask learning that uses original task data we assume
unavailable. A more surprising observation is that Learning without Forgetting
may be able to replace fine-tuning with similar old and new task datasets for
improved new task performance.
</dc:description>
 <dc:description>Comment: Conference version appears in ECCV 2016; updated with journal version</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09296</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Many Folders Do You Really Need?</dc:title>
 <dc:creator>Grbovic, Mihajlo</dc:creator>
 <dc:creator>Halawi, Guy</dc:creator>
 <dc:creator>Karnin, Zohar</dc:creator>
 <dc:creator>Maarek, Yoelle</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.4.3</dc:subject>
 <dc:description>  Email classification is still a mostly manual task. Consequently, most Web
mail users never define a single folder. Recently however, automatic
classification offering the same categories to all users has started to appear
in some Web mail clients, such as AOL or Gmail. We adopt this approach, rather
than previous (unsuccessful) personalized approaches because of the change in
the nature of consumer email traffic, which is now dominated by (non-spam)
machine-generated email. We propose here a novel approach for (1) automatically
distinguishing between personal and machine-generated email and (2) classifying
messages into latent categories, without requiring users to have defined any
folder. We report how we have discovered that a set of 6 &quot;latent&quot; categories
(one for human- and the others for machine-generated messages) can explain a
significant portion of email traffic. We describe in details the steps involved
in building a Web-scale email categorization system, from the collection of
ground-truth labels, the selection of features to the training of models.
Experimental evaluation was performed on more than 500 billion messages
received during a period of six months by users of Yahoo mail service, who
elected to be part of such research studies. Our system achieved precision and
recall rates close to 90% and the latent categories we discovered were shown to
cover 70% of both email traffic and email search queries. We believe that these
results pave the way for a change of approach in the Web mail industry, and
could support the invention of new large-scale email discovery paradigms that
had not been possible before.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures, Proceedings of the 23rd ACM International
  Conference on Information and Knowledge Management (CIKM 2014), Shanghai,
  China</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09296</dc:identifier>
 <dc:identifier>Proceedings of the 23rd ACM International Conference on
  Information and Knowledge Management (CIKM 2014), Shanghai, China</dc:identifier>
 <dc:identifier>doi:10.1145/2661829.2662018.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09308</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monitoring communication outbreaks among an unknown team of actors in
  dynamic networks</dc:title>
 <dc:creator>Sparks, Ross</dc:creator>
 <dc:creator>Wilson, James D.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  This paper investigates the detection of communication outbreaks among a
small team of actors in time-varying networks. We propose monitoring plans for
known and unknown teams based on generalizations of the exponentially weighted
moving average (EWMA) statistic. For unknown teams, we propose an efficient
neighborhood-based search to estimate a collection of candidate teams. This
procedure dramatically reduces the computational complexity of an exhaustive
search. Our procedure consists of two steps: communication counts between
actors are first smoothed using a multivariate EWMA strategy. Densely connected
teams are identified as candidates using a neighborhood search approach. These
candidate teams are then monitored using a surveillance plan derived from a
generalized EWMA statistic. Monitoring plans are established for collaborative
teams, teams with a dominant leader, as well as for global outbreaks. We
consider weighted heterogeneous dynamic networks, where the expected
communication count between each pair of actors is potentially different across
pairs and time, as well as homogeneous networks, where the expected
communication count is constant across time and actors. Our monitoring plans
are evaluated on a test bed of simulated networks as well as on the U.S. Senate
co-voting network, which models the Senate voting patterns from 1857 to 2015.
Our analysis suggests that our surveillance strategies can efficiently detect
relevant and significant changes in dynamic networks.
</dc:description>
 <dc:description>Comment: 23 pages, 2 figures, Submitted</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09314</identifier>
 <datestamp>2017-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entanglement-assisted classical capacities of compound and arbitrarily
  varying quantum channels</dc:title>
 <dc:creator>Boche, Holger</dc:creator>
 <dc:creator>Jan&#xdf;en, Gisbert</dc:creator>
 <dc:creator>Kaltenstadler, Stephan</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider classical message transmission under entanglement assistance for
compound memoryless and arbitrarily varying quantum channels. In both cases, we
prove general coding theorems together with corresponding weak converse bounds.
In this way, we obtain single-letter characterizations of the
entanglement-assisted classical capacities for both channel models. Moreover,
we show that the entanglement-assisted classical capacity does exhibit no
strong converse property for some compound quantum channels for the average as
well as the maximal error criterion. A strong converse to the
entanglement-assisted classical capacities does hold for each arbitrarily
varying quantum channel.
</dc:description>
 <dc:description>Comment: Minor corrections, results unchanged, presentation updated, 21 pages,
  0 figures, accepted for publication in Quant. Inf. Proc</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2017-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09315</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Compression for Analytics over Large-scale In-memory Column
  Databases</dc:title>
 <dc:creator>Lin, Chunbin</dc:creator>
 <dc:creator>Wang, Jianguo</dc:creator>
 <dc:creator>Papakonstantinou, Yannis</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Data compression schemes have exhibited their importance in column databases
by contributing to the high-performance OLAP (Online Analytical Processing)
query processing. Existing works mainly concentrate on evaluating compression
schemes for disk-resident databases as data is mostly stored on disks. With the
continuously decreasing of the price/capacity ratio of main memory, it is the
tendencies of the times to reside data in main memory. But the discussion of
data compression on in-memory databases is very vague in the literature. In
this work, we present an updated discussion about whether it is valuable to use
data compression techniques in memory databases. If yes, how should memory
databases apply data compression schemes to maximize performance?
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09329</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Average Tracking for Multiple Signals Generated by Linear
  Dynamical Systems: An Edge-based Framework</dc:title>
 <dc:creator>Zhao, Yu</dc:creator>
 <dc:creator>Liu, Yongfang</dc:creator>
 <dc:creator>Li, Zhongkui</dc:creator>
 <dc:creator>Duan, Zhisheng</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies the distributed average tracking problem for multiple
time-varying signals generated by linear dynamics, whose reference inputs are
nonzero and not available to any agent in the network. In the edge-based
framework, a pair of continuous algorithms with, respectively, static and
adaptive coupling strengths are designed. Based on the boundary layer concept,
the proposed continuous algorithm with static coupling strengths can
asymptotically track the average of multiple reference signals without the
chattering phenomenon. Furthermore, for the case of algorithms with adaptive
coupling strengths, average tracking errors are uniformly ultimately bounded
and exponentially converge to a small adjustable bounded set. Finally, a
simulation example is presented to show the validity of theoretical results.
</dc:description>
 <dc:description>Comment: accepted in press, Automatica 2016. arXiv admin note: substantial
  text overlap with arXiv:1312.7445</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09333</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dimension-Free Iteration Complexity of Finite Sum Optimization Problems</dc:title>
 <dc:creator>Arjevani, Yossi</dc:creator>
 <dc:creator>Shamir, Ohad</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Many canonical machine learning problems boil down to a convex optimization
problem with a finite sum structure. However, whereas much progress has been
made in developing faster algorithms for this setting, the inherent limitations
of these problems are not satisfactorily addressed by existing lower bounds.
Indeed, current bounds focus on first-order optimization algorithms, and only
apply in the often unrealistic regime where the number of iterations is less
than $\mathcal{O}(d/n)$ (where $d$ is the dimension and $n$ is the number of
samples). In this work, we extend the framework of (Arjevani et al., 2015) to
provide new lower bounds, which are dimension-free, and go beyond the
assumptions of current bounds, thereby covering standard finite sum
optimization methods, e.g., SAG, SAGA, SVRG, SDCA without duality, as well as
stochastic coordinate-descent methods, such as SDCA and accelerated proximal
SDCA.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09344</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully integrated 3.2 Gbps quantum random number generator with real-time
  extraction</dc:title>
 <dc:creator>Zhang, Xiao-Guang</dc:creator>
 <dc:creator>Nie, You-Qi</dc:creator>
 <dc:creator>Zhou, Hongyi</dc:creator>
 <dc:creator>Liang, Hao</dc:creator>
 <dc:creator>Ma, Xiongfeng</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Pan, Jian-Wei</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present a real-time and fully integrated quantum random number generator
(QRNG) by measuring laser phase fluctuations. The QRNG scheme based on laser
phase fluctuations is featured for its capability of generating ultra
high-speed random numbers. However, the speed bottleneck of a practical QRNG
lies on the limited speed of randomness extraction. To close the gap between
the fast randomness generation and the slow post-processing, we propose a
pipeline extraction algorithm based on Toeplitz matrix hashing and implement it
in a high-speed field-programmable gate array. Further, all the QRNG components
are integrated into a module, including a compact and actively stabilized
interferometer, high-speed data acquisition, and real-time data post-processing
and transmission. The final generation rate of the QRNG module with real-time
extraction can reach 3.2 Gbps.
</dc:description>
 <dc:description>Comment: 3 pages, 3 figures. Accepted for publication in Review of Scientific
  Instrument</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09344</dc:identifier>
 <dc:identifier>Rev. Sci. Instrum. 87, 076102 (2016)</dc:identifier>
 <dc:identifier>doi:10.1063/1.4958663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09349</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Shot Learning with Multi-Battery Factor Analysis</dc:title>
 <dc:creator>Ji, Zhong</dc:creator>
 <dc:creator>Xie, Yuzhong</dc:creator>
 <dc:creator>Pang, Yanwei</dc:creator>
 <dc:creator>Chen, Lei</dc:creator>
 <dc:creator>Zhang, Zhongfei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-shot learning (ZSL) extends the conventional image classification
technique to a more challenging situation where the test image categories are
not seen in the training samples. Most studies on ZSL utilize side information
such as attributes or word vectors to bridge the relations between the seen
classes and the unseen classes. However, existing approaches on ZSL typically
exploit a shared space for each type of side information independently, which
cannot make full use of the complementary knowledge of different types of side
information. To this end, this paper presents an MBFA-ZSL approach to embed
different types of side information as well as the visual feature into one
shared space. Specifically, we first develop an algorithm named Multi-Battery
Factor Analysis (MBFA) to build a unified semantic space, and then employ
multiple types of side information in it to achieve the ZSL. The close-form
solution makes MBFA-ZSL simple to implement and efficient to run on large
datasets. Extensive experiments on the popular AwA, CUB, and SUN datasets show
its significant superiority over the state-of-the-art approaches.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09367</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parking Stall Vacancy Indicator System Based on Deep Convolutional
  Neural Networks</dc:title>
 <dc:creator>Valipour, Sepehr</dc:creator>
 <dc:creator>Siam, Mennatullah</dc:creator>
 <dc:creator>Stroulia, Eleni</dc:creator>
 <dc:creator>Jagersand, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Parking management systems, and vacancy-indication services in particular,
can play a valuable role in reducing traffic and energy waste in large cities.
Visual detection methods represent a cost-effective option, since they can take
advantage of hardware usually already available in many parking lots, namely
cameras. However, visual detection methods can be fragile and not easily
generalizable. In this paper, we present a robust detection algorithm based on
deep convolutional neural networks. We implemented and tested our algorithm on
a large baseline dataset, and also on a set of image feeds from actual cameras
already installed in parking lots. We have developed a fully functional system,
from server-side image analysis to front-end user interface, to demonstrate the
practicality of our method.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09368</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Construction and Analysis of Seminormalized Hadamard
  Matrices</dc:title>
 <dc:creator>Suksmono, Andriyan B.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let o be a 4k-length column vector whose all entries are 1s, with k a
positive integer. Let V={v_i} be a set of semi-normalized Hadamard
(SH)-vectors, which are 4k-length vectors whose 2k entries are -1s and the
remaining 2k are 1s. We define a 4k-order QSH (Quasi SH)-matrix, Q, as a 4kx4k
matrix where the first column is o and the remaining ones are distinct v_i in
V. When Q is orthogonal, it becomes an SH-matrix H. Therefore, 4k-order
SH-matrices can be built by enumerate all possible Q from every combination of
v_i, then evaluate the orthogonality of each one of them. Since such exhaustive
method requires a large amount of computing resource, we can employ
probabilistic algorithms to construct H, such as, by Random Vector Selection
(RVS) or the Orthogonalization by Simulated Annealing (OSA) algorithms. We
demonstrate the constructions of low-order SH-matrices by using these methods.
We also analyze some probabilistic aspects of the constructions, including
orthogonal probability p between a pair of randomly selected SH-vectors, the
existence probability p_H|Q that a randomly generated Q is in fact an SH-matrix
H, and address the discrepancy of the distribution between the known number of
SH-matrix with expected number derived from the probabilistic analysis.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09370</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relation extraction from clinical texts using domain invariant
  convolutional neural network</dc:title>
 <dc:creator>Sahu, Sunil Kumar</dc:creator>
 <dc:creator>Anand, Ashish</dc:creator>
 <dc:creator>Oruganty, Krishnadev</dc:creator>
 <dc:creator>Gattu, Mahanandeeshwar</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In recent years extracting relevant information from biomedical and clinical
texts such as research articles, discharge summaries, or electronic health
records have been a subject of many research efforts and shared challenges.
Relation extraction is the process of detecting and classifying the semantic
relation among entities in a given piece of texts. Existing models for this
task in biomedical domain use either manually engineered features or kernel
methods to create feature vector. These features are then fed to classifier for
the prediction of the correct class. It turns out that the results of these
methods are highly dependent on quality of user designed features and also
suffer from curse of dimensionality. In this work we focus on extracting
relations from clinical discharge summaries. Our main objective is to exploit
the power of convolution neural network (CNN) to learn features automatically
and thus reduce the dependency on manual feature engineering. We evaluate
performance of the proposed model on i2b2-2010 clinical relation extraction
challenge dataset. Our results indicate that convolution neural network can be
a good model for relation exaction in clinical text without being dependent on
expert's knowledge on defining quality features.
</dc:description>
 <dc:description>Comment: This paper has been accepted in ACL BioNLP 2016 Workshop</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09371</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent neural network models for disease name recognition using
  domain invariant features</dc:title>
 <dc:creator>Sahu, Sunil Kumar</dc:creator>
 <dc:creator>Anand, Ashish</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Hand-crafted features based on linguistic and domain-knowledge play crucial
role in determining the performance of disease name recognition systems. Such
methods are further limited by the scope of these features or in other words,
their ability to cover the contexts or word dependencies within a sentence. In
this work, we focus on reducing such dependencies and propose a
domain-invariant framework for the disease name recognition task. In
particular, we propose various end-to-end recurrent neural network (RNN) models
for the tasks of disease name recognition and their classification into four
pre-defined categories. We also utilize convolution neural network (CNN) in
cascade of RNN to get character-based embedded features and employ it with
word-embedded features in our model. We compare our models with the
state-of-the-art results for the two tasks on NCBI disease dataset. Our results
for the disease mention recognition task indicate that state-of-the-art
performance can be obtained without relying on feature engineering. Further the
proposed models obtained improved performance on the classification task of
disease names.
</dc:description>
 <dc:description>Comment: This work has been accepted in ACL-2016 as long paper</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09375</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Networks on Graphs with Fast Localized Spectral
  Filtering</dc:title>
 <dc:creator>Defferrard, Micha&#xeb;l</dc:creator>
 <dc:creator>Bresson, Xavier</dc:creator>
 <dc:creator>Vandergheynst, Pierre</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work, we are interested in generalizing convolutional neural networks
(CNNs) from low-dimensional regular grids, where image, video and speech are
represented, to high-dimensional irregular domains, such as social networks,
brain connectomes or words' embedding, represented by graphs. We present a
formulation of CNNs in the context of spectral graph theory, which provides the
necessary mathematical background and efficient numerical schemes to design
fast localized convolutional filters on graphs. Importantly, the proposed
technique offers the same linear computational complexity and constant learning
complexity as classical CNNs, while being universal to any graph structure.
Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep
learning system to learn local, stationary, and compositional features on
graphs.
</dc:description>
 <dc:description>Comment: NIPS 2016 final revision</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09375</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems 29 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09376</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Design of Arbitrage-Free Data Pricing Schemes</dc:title>
 <dc:creator>Deep, Shaleen</dc:creator>
 <dc:creator>Koutris, Paraschos</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Motivated by a growing market that involves buying and selling data over the
web, we study pricing schemes that assign value to queries issued over a
database. Previous work studied pricing mechanisms that compute the price of a
query by extending a data seller's explicit prices on certain queries, or
investigated the properties that a pricing function should exhibit without
detailing a generic construction. In this work, we present a formal framework
for pricing queries over data that allows the construction of general families
of pricing functions, with the main goal of avoiding arbitrage. We consider two
types of pricing schemes: instance-independent schemes, where the price depends
only on the structure of the query, and answer-dependent schemes, where the
price also depends on the query output. Our main result is a complete
characterization of the structure of pricing functions in both settings, by
relating it to properties of a function over a lattice. We use our
characterization, together with information-theoretic methods, to construct a
variety of arbitrage-free pricing functions. Finally, we discuss various
tradeoffs in the design space and present techniques for efficient computation
of the proposed pricing functions.
</dc:description>
 <dc:description>Comment: full paper</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09383</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Approximate Dynamic Programming with Multivariate Splines for
  Adaptive Control</dc:title>
 <dc:creator>Eerland, Willem</dc:creator>
 <dc:creator>de Visser, Coen</dc:creator>
 <dc:creator>van Kampen, Erik-Jan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We define a SDP framework based on the RLSTD algorithm and multivariate
simplex B-splines. We introduce a local forget factor capable of preserving the
continuity of the simplex splines. This local forget factor is integrated with
the RLSTD algorithm, resulting in a modified RLSTD algorithm that is capable of
tracking time-varying systems. We present the results of two numerical
experiments, one validating SDP and comparing it with NDP and another to show
the advantages of the modified RLSTD algorithm over the original. While SDP
requires more computations per time-step, the experiment shows that for the
same amount of function approximator parameters, there is an increase in
performance in terms of stability and learning rate compared to NDP. The second
experiment shows that SDP in combination with the modified RLSTD algorithm
allows for faster recovery compared to the original RLSTD algorithm when system
parameters are altered, paving the way for an adaptive high-performance
non-linear control method.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09388</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotically Optimal Algorithms for Budgeted Multiple Play Bandits</dc:title>
 <dc:creator>Luedtke, Alexander</dc:creator>
 <dc:creator>Kaufmann, Emilie</dc:creator>
 <dc:creator>Chambaz, Antoine</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study a generalization of the multi-armed bandit problem with multiple
plays where there is a cost associated with pulling each arm and the agent has
a budget at each time that dictates how much she can expect to spend. We derive
an asymptotic regret lower bound for any uniformly efficient algorithm in our
setting. We then study a variant of Thompson sampling for Bernoulli rewards and
a variant of KL-UCB for both single-parameter exponential families and bounded,
finitely supported rewards. We show these algorithms are asymptotically
optimal, both in rate and leading problem-dependent constants, including in the
thick margin setting where multiple arms fall on the decision boundary.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09395</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Packet Scheduling with Bounded Delay and Lookahead</dc:title>
 <dc:creator>B&#xf6;hm, Martin</dc:creator>
 <dc:creator>Chrobak, Marek</dc:creator>
 <dc:creator>Je&#x17c;, &#x141;ukasz</dc:creator>
 <dc:creator>Li, Fei</dc:creator>
 <dc:creator>Sgall, Ji&#x159;&#xed;</dc:creator>
 <dc:creator>Vesel&#xfd;, Pavel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We study the online bounded-delay packet scheduling problem (BDPS), where
packets of unit size arrive at a router over time and need to be transmitted
over a network link. Each packet has two attributes: a non-negative weight and
a deadline for its transmission. The objective is to maximize the total weight
of the transmitted packets. This problem has been well studied in the
literature, yet its optimal competitive ratio remains unknown: the best upper
bound is $1.828$, still quite far from the best lower bound of $\phi \approx
1.618$.
  In the variant of BDPS with $s$-bounded instances, each packet can be
scheduled in at most $s$ consecutive slots, starting at its release time. The
lower bound of $\phi$ applies even to the special case of $2$-bounded
instances, and a $\phi$-competitive algorithm for $3$-bounded instances was
given in Chin et al. Improving that result, and addressing a question posed by
Goldwasser, we present a $\phi$-competitive algorithm for $4$-bounded
instances.
  We also study a variant of BDPS where an online algorithm has the additional
power of $1$-lookahead, knowing at time $t$ which packets will arrive at time
$t+1$. For BDPS with $1$-lookahead restricted to $2$-bounded instances, we
present an online algorithm with competitive ratio $(\sqrt{13} - 1)/2 \approx
1.303$ and we prove a nearly tight lower bound of $(1 + \sqrt{17})/4 \approx
1.281$.
</dc:description>
 <dc:description>Comment: 18 pages, 4 figures, submitted to ISAAC 2016</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09399</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coalgebraic Trace Semantics for Buechi and Parity Automata</dc:title>
 <dc:creator>Urabe, Natsuki</dc:creator>
 <dc:creator>Shimizu, Shunsuke</dc:creator>
 <dc:creator>Hasuo, Ichiro</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Despite its success in producing numerous general results on state-based
dynamics, the theory of coalgebra has struggled to accommodate the Buechi
acceptance condition---a basic notion in the theory of automata for infinite
words or trees. In this paper we present a clean answer to the question that
builds on the &quot;maximality&quot; characterization of infinite traces (by Jacobs and
Cirstea): the accepted language of a Buechi automaton is characterized by two
commuting diagrams, one for a least homomorphism and the other for a greatest,
much like in a system of (least and greatest) fixed-point equations. This
characterization works uniformly for the nondeterministic branching and the
probabilistic one; and for words and trees alike. We present our results in
terms of the parity acceptance condition that generalizes Buechi's.
</dc:description>
 <dc:description>Comment: A preprint version of the paper to appear in CONCUR 2016; with
  appendices</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09402</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient randomized algorithms for adaptive low-rank factorizations of
  large matrices</dc:title>
 <dc:creator>Gu, Yu</dc:creator>
 <dc:creator>Yu, Wenjian</dc:creator>
 <dc:creator>Li, Yaohang</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>15A18, 65F30, 65F15, 68W20, 60B20</dc:subject>
 <dc:description>  In this paper, randomized techniques for computing low-rank factorizations
are presented. The proposed methods take in a tolerance $\varepsilon$ and an $m
\times n$ matrix $\boldsymbol{A}$, and output an approximate low-rank
factorization of $\boldsymbol{A}$, whose error measured in the Frobenius norm
is within $\varepsilon$. The techniques are based on the blocked randQB scheme
proposed by P.-G. Martinsson and S. Voronin, producing a QB factorization. By
employing an economic error indicator and moving $\boldsymbol{A}$ out of the
loop, the techniques result in two algorithms called randQB_EI and randQB_FP.
They are mathematically equivalent to the existing blocked scheme, but are more
computationally efficient. The randQB_FP algorithm also owns the merit of
pass-efficiency. Numerical experiments on a multi-core parallel computing
server show that the proposed algorithms have the similar accuracy as the
blocked randQB scheme, but cost a small fraction of runtime and memory. The
benefits are even larger (up to 20X) for handling large sparse matrices.
Compared with the adaptive range finder algorithm, the proposed methods output
much smaller and close to optimal rank while satisfying the preset accuracy
tolerance.
</dc:description>
 <dc:description>Comment: 23 pages, 10 figures</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09403</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Crosslingual Word Embeddings without Bilingual Corpora</dc:title>
 <dc:creator>Duong, Long</dc:creator>
 <dc:creator>Kanayama, Hiroshi</dc:creator>
 <dc:creator>Ma, Tengfei</dc:creator>
 <dc:creator>Bird, Steven</dc:creator>
 <dc:creator>Cohn, Trevor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Crosslingual word embeddings represent lexical items from different languages
in the same vector space, enabling transfer of NLP tools. However, previous
attempts had expensive resource requirements, difficulty incorporating
monolingual data or were unable to handle polysemy. We address these drawbacks
in our method which takes advantage of a high coverage dictionary in an EM
style training algorithm over monolingual corpora in two languages. Our model
achieves state-of-the-art performance on bilingual lexicon induction task
exceeding models using large bilingual corpora, and competitive results on the
monolingual word similarity and cross-lingual document classification task.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09424</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variance Allocation and Shapley Value</dc:title>
 <dc:creator>Colini-Baldeschi, Riccardo</dc:creator>
 <dc:creator>Scarsini, Marco</dc:creator>
 <dc:creator>Vaccari, Stefano</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>91A12, 62J10</dc:subject>
 <dc:description>  Motivated by the problem of utility allocation in a portfolio under a
Markowitz mean-variance choice paradigm, we propose an allocation criterion for
the variance of the sum of $n$ possibly dependent random variables. This
criterion, the Shapley value, requires to translate the problem into a
cooperative game. The Shapley value has nice properties, but, in general, is
computationally demanding. The main result of this paper shows that in our
particular case the Shapley value has a very simple form that can be easily
computed. The same criterion is used also to allocate the standard deviation of
the sum of $n$ random variables and a conjecture about the relation of the
values in the two games is formulated.
</dc:description>
 <dc:description>Comment: 20pages</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09424</dc:identifier>
 <dc:identifier>doi:10.1007/s11009-016-9540-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09433</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Steering a Predator Robot using a Mixed Frame/Event-Driven Convolutional
  Neural Network</dc:title>
 <dc:creator>Moeys, Diederik Paul</dc:creator>
 <dc:creator>Corradi, Federico</dc:creator>
 <dc:creator>Kerr, Emmett</dc:creator>
 <dc:creator>Vance, Philip</dc:creator>
 <dc:creator>Das, Gautham</dc:creator>
 <dc:creator>Neil, Daniel</dc:creator>
 <dc:creator>Kerr, Dermot</dc:creator>
 <dc:creator>Delbruck, Tobi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper describes the application of a Convolutional Neural Network (CNN)
in the context of a predator/prey scenario. The CNN is trained and run on data
from a Dynamic and Active Pixel Sensor (DAVIS) mounted on a Summit XL robot
(the predator), which follows another one (the prey). The CNN is driven by both
conventional image frames and dynamic vision sensor &quot;frames&quot; that consist of a
constant number of DAVIS ON and OFF events. The network is thus &quot;data driven&quot;
at a sample rate proportional to the scene activity, so the effective sample
rate varies from 15 Hz to 240 Hz depending on the robot speeds. The network
generates four outputs: steer right, left, center and non-visible. After
off-line training on labeled data, the network is imported on the on-board
Summit XL robot which runs jAER and receives steering directions in real time.
Successful results on closed-loop trials, with accuracies up to 87% or 92%
(depending on evaluation criteria) are reported. Although the proposed approach
discards the precise DAVIS event timing, it offers the significant advantage of
compatibility with conventional deep learning technology without giving up the
advantage of data-driven computing.
</dc:description>
 <dc:description>Comment: Paper presented at the conference: Second International Conference on
  Event-Based Control, Communication and Signal Processing (EBCCSP) 2016, At
  Krakow, Poland</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09446</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering topically- and temporally-coherent events in interaction
  networks</dc:title>
 <dc:creator>Xiao, Han</dc:creator>
 <dc:creator>Rozenshtein, Polina</dc:creator>
 <dc:creator>Gionis, Aristides</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  With the increasing use of online communication platforms, such as email,
twitter, and messaging applications, we are faced with a growing amount of data
that combine content (what is said), time (when), and user (by whom)
information. An important computational challenge is to analyze these data,
discover meaningful patterns, and understand what is happening. We consider the
problem of mining online communication data and finding top-k temporal events.
We define a temporal event to be a coherent topic that is discussed frequently,
in a relatively short time span, while the information ow of the event respects
the underlying network structure. We construct our model for detecting temporal
events in two steps. We first introduce the notion of interaction meta-graph,
which connects associated interactions. Using this notion, we define a temporal
event to be a subset of interactions that (i) are topically and temporally
close and (ii) correspond to a tree that captures the information ow. Finding
the best temporal event leads to budget version of the prize-collecting
Steiner-tree (PCST) problem, which we solve using three different methods: a
greedy approach, a dynamic-programming algorithm, and an adaptation to an
existing approximation algorithm. The problem of finding the top- k events
among a set of candidate events maps to maximum set-cover problem, and thus,
solved by greedy. We compare and analyze our algorithms in both synthetic and
real datasets, such as twitter and email communication. The results show that
our methods are able to detect meaningful temporal events.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09449</identifier>
 <datestamp>2017-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clique-Width and Directed Width Measures for Answer-Set Programming</dc:title>
 <dc:creator>Bliem, Bernhard</dc:creator>
 <dc:creator>Ordyniak, Sebastian</dc:creator>
 <dc:creator>Woltran, Stefan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Disjunctive Answer Set Programming (ASP) is a powerful declarative
programming paradigm whose main decision problems are located on the second
level of the polynomial hierarchy. Identifying tractable fragments and
developing efficient algorithms for such fragments are thus important
objectives in order to complement the sophisticated ASP systems available to
date. Hard problems can become tractable if some problem parameter is bounded
by a fixed constant; such problems are then called fixed-parameter tractable
(FPT). While several FPT results for ASP exist, parameters that relate to
directed or signed graphs representing the program at hand have been neglected
so far. In this paper, we first give some negative observations showing that
directed width measures on the dependency graph of a program do not lead to FPT
results. We then consider the graph parameter of signed clique-width and
present a novel dynamic programming algorithm that is FPT w.r.t. this
parameter. Clique-width is more general than the well-known treewidth, and, to
the best of our knowledge, ours is the first FPT algorithm for bounded
clique-width for reasoning problems beyond SAT.
</dc:description>
 <dc:description>Comment: A short version of this paper has been accepted to ECAI 2016 and
  TAASP 2016</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09452</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Suppression Algorithms for Surveillance Applications of Wireless
  Sensor and Actor Networks</dc:title>
 <dc:creator>Placzek, Bartlomiej</dc:creator>
 <dc:creator>Bernas, Marcin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper introduces algorithms for surveillance applications of wireless
sensor and actor networks (WSANs) that reduce communication cost by suppressing
unnecessary data transfers. The objective of the considered WSAN system is to
capture and eliminate distributed targets in the shortest possible time.
Computational experiments were performed to evaluate effectiveness of the
proposed algorithms. The experimental results show that a considerable
reduction of the communication costs together with a performance improvement of
the WSAN system can be obtained by using the communication algorithms that are
based on spatiotemporal and decision aware suppression methods.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09452</dc:identifier>
 <dc:identifier>Communications in Computer and Information Science, vol. 522, pp.
  23-32, Springer International Publishing, 2015</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-19419-6_3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09455</identifier>
 <datestamp>2016-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Guarded Lambda-Calculus: Programming and Reasoning with Guarded
  Recursion for Coinductive Types</dc:title>
 <dc:creator>Clouston, Ranald</dc:creator>
 <dc:creator>Bizjak, Ale&#x161;</dc:creator>
 <dc:creator>Grathwohl, Hans Bugge</dc:creator>
 <dc:creator>Birkedal, Lars</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present the guarded lambda-calculus, an extension of the simply typed
lambda-calculus with guarded recursive and coinductive types. The use of
guarded recursive types ensures the productivity of well-typed programs.
Guarded recursive types may be transformed into coinductive types by a
type-former inspired by modal logic and Atkey-McBride clock quantification,
allowing the typing of acausal functions. We give a call-by-name operational
semantics for the calculus, and define adequate denotational semantics in the
topos of trees. The adequacy proof entails that the evaluation of a program
always terminates. We introduce a program logic with L\&quot;ob induction for
reasoning about the contextual equivalence of programs. We demonstrate the
expressiveness of the calculus by showing the definability of solutions to
Rutten's behavioural differential equations.
</dc:description>
 <dc:description>Comment: Accepted to Logical Methods in Computer Science special issue on the
  18th International Conference on Foundations of Software Science and
  Computation Structures (FoSSaCS 2015)</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09455</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 12, Issue 3 (September
  6, 2016) lmcs:2019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09458</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vote-boosting ensembles</dc:title>
 <dc:creator>Sabzevari, Maryam</dc:creator>
 <dc:creator>Mart&#xed;nez-Mu&#xf1;oz, Gonzalo</dc:creator>
 <dc:creator>Su&#xe1;rez, Alberto</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Vote-boosting is a sequential ensemble learning method in which individual
classifiers are built on different weighted versions of the training data. To
build a new classifier, the weight of each training instance is determined as a
function of the disagreement rate of the current ensemble predictions for that
particular instance. Experiments using the symmetric beta distribution as the
emphasis function and different base learners are used to illustrate the
properties and to analyze the performance of these types of ensembles. In
classification problems with low or no class-label noise, when simple base
learners are used, vote-boosting behaves as if it were an interpolation between
bagging and standard boosting (e.g. AdaBoost), depending on the value of the
shape parameter of the beta distribution. In terms of predictive accuracy the
best results, which are comparable or better than random forests, are obtained
with vote-boosting ensembles of random trees.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09463</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Locally Repairable Codes with Improved Update Complexity</dc:title>
 <dc:creator>Mehrabi, Mehrtash</dc:creator>
 <dc:creator>Shahabinejad, Mostafa</dc:creator>
 <dc:creator>Ardakani, Masoud</dc:creator>
 <dc:creator>Khabbazian, Majid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For a systematic erasure code, update complexity (UC) is defined as the
maximum number of parity blocks needed to be changed when some information
blocks are updated. Locally repairable codes (LRCs) have been recently proposed
and used in real-world distributed storage systems. In this paper, update
complexity for optimal LRC is studied and both lower and upper bounds on UC are
established in terms of length (n), dimension (k), minimum distance (d), and
locality (r) of the code, when (r+1)|n. Furthermore, a class of optimal LRCs
with small UC is proposed. Our proposed LRCs could be of interest as they
improve UC without sacrificing optimality of the code.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09470</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Programming Patterns in Dataflow Matrix Machines and Generalized
  Recurrent Neural Nets</dc:title>
 <dc:creator>Bukatin, Michael</dc:creator>
 <dc:creator>Matthews, Steve</dc:creator>
 <dc:creator>Radul, Andrey</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Dataflow matrix machines arise naturally in the context of synchronous
dataflow programming with linear streams. They can be viewed as a rather
powerful generalization of recurrent neural networks. Similarly to recurrent
neural networks, large classes of dataflow matrix machines are described by
matrices of numbers, and therefore dataflow matrix machines can be synthesized
by computing their matrices. At the same time, the evidence is fairly strong
that dataflow matrix machines have sufficient expressive power to be a
convenient general-purpose programming platform. Because of the network nature
of this platform, programming patterns often correspond to patterns of
connectivity in the generalized recurrent neural networks understood as
programs. This paper explores a variety of such programming patterns.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09481</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating massive complex networks with hyperbolic geometry faster in
  practice</dc:title>
 <dc:creator>von Looz, Moritz</dc:creator>
 <dc:creator>&#xd6;zdayi, Mustafa</dc:creator>
 <dc:creator>Laue, S&#xf6;ren</dc:creator>
 <dc:creator>Meyerhenke, Henning</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Generative network models play an important role in algorithm development,
scaling studies, network analysis, and realistic system benchmarks for graph
data sets. The commonly used graph-based benchmark model R-MAT has some
drawbacks concerning realism and the scaling behavior of network properties. A
complex network model gaining considerable popularity builds random hyperbolic
graphs, generated by distributing points within a disk in the hyperbolic plane
and then adding edges between points whose hyperbolic distance is below a
threshold.
  We present in this paper a fast generation algorithm for such graphs. Our
experiments show that our new generator achieves speedup factors of 3-60 over
the best previous implementation. One billion edges can now be generated in
under one minute on a shared-memory workstation. Furthermore, we present a
dynamic extension to model gradual network change, while preserving at each
step the point position probabilities.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09488</identifier>
 <datestamp>2016-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A weakly universal cellular automaton in the heptagrid</dc:title>
 <dc:creator>Margenstern, Maurice</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>68R05</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In this paper, we construct a weakly universal cellular automaton in the
heptagrid, the tessellation $\{7,3\}$ which is not rotation invariant but which
is truly planar. This result, under these conditions, cannot be improved for
the tessellations $\{p,3\}$.
</dc:description>
 <dc:description>Comment: 32 pages, 16 figures. arXiv admin note: substantial text overlap with
  arXiv:1606.03938; text overlap with arXiv:1605.09518</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09493</identifier>
 <datestamp>2016-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comments on &quot;sub-KBT micro-electromechanical irreversible logic gate&quot;</dc:title>
 <dc:creator>Kish, Laszlo B.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  In a recent article, Nature Communications 7 (2016) 12068, the authors
claimed that they demonstrated sub-kBT energy dissipation at elementary logic
operations. However, the argumentation is invalid because it neglects the
dominant source of energy dissipation, namely, the charging energy of the
capacitance of the input electrode, which totally dissipates during the full
(0-1-0) cycle of logic values. The neglected dissipation phenomenon is
identical with the mechanism that leads to the lower physical limit of
dissipation (70-100 kBT) in today's microprocessors (CMOS logic) and in any
other system with thermally activated errors thus the same limit holds for the
new scheme, too.
</dc:description>
 <dc:description>Comment: Version after galley proof corrections. Fluctuation and Noise
  Letters, in press</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09493</dc:identifier>
 <dc:identifier>Fluctuation and Noise Letters Vol. 15, No. 4 (2016) 1620001</dc:identifier>
 <dc:identifier>doi:10.1142/S0219477516200017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09494</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matched Metrics to the Binary Asymmetric Channels</dc:title>
 <dc:creator>Qureshi, Claudio M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we establish some criteria to decide when a discrete memoryless
channel admits a metric in such a way that the maximum likelihood decoding
coincides with the nearest neighbour decoding. In particular we prove a
conjecture presented by M. Firer and J. L. Walker establishing that every
binary asymmetric channel admits a matched metric.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09510</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supplementary Appendix for: Constrained Perturbation Regularization
  Approach for Signal Estimation Using Random Matrix Theory</dc:title>
 <dc:creator>Suliman, Mohamed</dc:creator>
 <dc:creator>Ballal, Tarig</dc:creator>
 <dc:creator>Kammoun, Abla</dc:creator>
 <dc:creator>Al-Naffouri, Tareq Y.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this supplementary appendix we provide proofs and additional extensive
simulations that complement the analysis of the main paper (constrained
perturbation regularization approach for signal estimation using random matrix
theory).
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09510</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2615683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09514</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Bell inequalities from communication complexity</dc:title>
 <dc:creator>Laplante, Sophie</dc:creator>
 <dc:creator>Lauri&#xe8;re, Mathieu</dc:creator>
 <dc:creator>Nolin, Alexandre</dc:creator>
 <dc:creator>Roland, J&#xe9;r&#xe9;mie</dc:creator>
 <dc:creator>Senno, Gabriel</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  The question of how large Bell inequality violations can be, for quantum
distributions, has been the object of much work in the past several years. We
say that a Bell inequality is normalized if its absolute value does not exceed
1 for any classical (i.e. local) distribution. Upper and (almost) tight lower
bounds have been given for the quantum violation of these Bell inequalities in
terms of number of outputs of the distribution, number of inputs, and the
dimension of the shared quantum states. In this work, we revisit normalized
Bell inequalities together with another family: inefficiency-resistant Bell
inequalities. To be inefficiency-resistant, the Bell value must not exceed 1
for any local distribution, including those that can abort. This makes the Bell
inequality resistant to the detection loophole, while a normalized Bell
inequality is resistant to general local noise. Both these families of Bell
inequalities are closely related to communication complexity lower bounds. We
show how to derive large violations from any gap between classical and quantum
communication complexity, provided the lower bound on classical communication
is proven using these lower bound techniques. This leads to
inefficiency-resistant violations that can be exponential in the size of the
inputs. Finally, we study resistance to noise and inefficiency for these Bell
inequalities.
</dc:description>
 <dc:description>Comment: The main addition in this new version is an analysis of the tradeoff
  between the number of outputs of the constructed quantum distributions and
  the amount of uniform noise tolerated by the quantum Bell violations</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09517</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Model Explanation System: Latest Updates and Extensions</dc:title>
 <dc:creator>Turner, Ryan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a general model explanation system (MES) for &quot;explaining&quot; the
output of black box classifiers. This paper describes extensions to Turner
(2015), which is referred to frequently in the text. We use the motivating
example of a classifier trained to detect fraud in a credit card transaction
history. The key aspect is that we provide explanations applicable to a single
prediction, rather than provide an interpretable set of parameters. We focus on
explaining positive predictions (alerts). However, the presented methodology is
symmetrically applicable to negative predictions.
</dc:description>
 <dc:description>Comment: Presented at 2016 ICML Workshop on Human Interpretability in Machine
  Learning (WHI 2016), New York, NY</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09518</identifier>
 <datestamp>2017-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>maskSLIC: Regional Superpixel Generation with Application to Local
  Pathology Characterisation in Medical Images</dc:title>
 <dc:creator>Irving, Benjamin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Supervoxel methods such as Simple Linear Iterative Clustering (SLIC) are an
effective technique for partitioning an image or volume into locally similar
regions, and are a common building block for the development of detection,
segmentation and analysis methods. We introduce maskSLIC an extension of SLIC
to create supervoxels within regions-of-interest, and demonstrate,on examples
from 2-dimensions to 4-dimensions, that maskSLIC overcomes issues that affect
SLIC within an irregular mask. We highlight the benefits of this method through
examples, and show that it is able to better represent underlying tumour
subregions and achieves significantly better results than SLIC on the BRATS
2013 brain tumour challenge data (p=0.001) - outperforming SLIC on 18/20 scans.
Finally, we show an application of this method for the analysis of functional
tumour subregions and demonstrate that it is more effective than voxel
clustering.
</dc:description>
 <dc:description>Comment: The article has been submitted to IEEE TPAMI</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09521</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Reasoning in the Description Logic ALCP with the Principle
  of Maximum Entropy (Full Version)</dc:title>
 <dc:creator>Pe&#xf1;aloza, Rafael</dc:creator>
 <dc:creator>Potyka, Nico</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A central question for knowledge representation is how to encode and handle
uncertain knowledge adequately. We introduce the probabilistic description
logic ALCP that is designed for representing context-dependent knowledge, where
the actual context taking place is uncertain. ALCP allows the expression of
logical dependencies on the domain and probabilistic dependencies on the
possible contexts. In order to draw probabilistic conclusions, we employ the
principle of maximum entropy. We provide reasoning algorithms for this logic,
and show that it satisfies several desirable properties of probabilistic
logics.
</dc:description>
 <dc:description>Comment: Full version of paper accepted at the Tenth International Conference
  on Scalable Uncertainty Management (SUM 2016)</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09530</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Predicting DNS Server Load</dc:title>
 <dc:creator>Wang, Zheng</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The DNS relies on caching to ensure high scalability and good performance. In
optimizing caching, TTL adjustment provides a means of balancing between query
load and TTL-dependent performances such as data consistency, load balancing,
migration time, etc. To gain the desired balance, TTL adjustment depends on
predictions of query loads under alternative TTLs. This paper proposes a model
of DNS server load, which employs the uniform aggregate caching model to
simplify the complexity of modeling clients' requests and their caching. A
method of predicting DNS server load is developed using that model. The
prediction method is solely based on the unilateral measurements or
observations at authoritative servers. Without reliance on lots of multi-point
measurements nor distributed measuring facilities, the method is best suited
for DNS authoritative operators. The proposed model and prediction method are
validated through extensive simulations. Finally, global sensibility analysis
is conducted to evaluate the impacts of measurement uncertainties or errors on
the predictions.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09540</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SurfCuit: Surface Mounted Circuits on 3D Prints</dc:title>
 <dc:creator>Umetani, Nobuyuki</dc:creator>
 <dc:creator>Schmidt, Ryan</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present, SurfCuit, a novel approach to design and construction of electric
circuits on the surface of 3D prints. Our surface mounting technique allows
durable construction of circuits on the surface of 3D prints. SurfCuit does not
require tedious circuit casing design or expensive set-ups, thus we can
expedite the process of circuit construction for 3D models. Our technique
allows the user to construct complex circuits for consumer-level desktop fused
decomposition modeling (FDM) 3D printers. The key idea behind our technique is
that FDM plastic forms a strong bond with metal when it is melted. This
observation enables construction of a robust circuit traces using copper tape
and soldering. We also present an interactive tool to design such circuits on
arbitrary 3D geometry. We demonstrate the effectiveness of our approach through
various actual construction examples.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09548</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Joint Typicality Approach to Algebraic Network Information Theory</dc:title>
 <dc:creator>Lim, Sung Hoon</dc:creator>
 <dc:creator>Feng, Chen</dc:creator>
 <dc:creator>Pastore, Adriano</dc:creator>
 <dc:creator>Nazer, Bobak</dc:creator>
 <dc:creator>Gastpar, Michael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents a joint typicality framework for encoding and decoding
nested linear codes for multi-user networks. This framework provides a new
perspective on compute-forward within the context of discrete memoryless
networks. In particular, it establishes an achievable rate region for computing
the weighted sum of nested linear codewords over a discrete memoryless
multiple-access channel (MAC). When specialized to the Gaussian MAC, this rate
region recovers and improves upon the lattice-based compute-forward rate region
of Nazer and Gastpar, thus providing a unified approach for discrete memoryless
and Gaussian networks. Furthermore, this framework can be used to shed light on
the joint decoding rate region for compute-forward, which is considered an open
problem. Specifically, this work establishes an achievable rate region for
simultaneously decoding two linear combinations of nested linear codewords from
K senders.
</dc:description>
 <dc:description>Comment: 69 pages, 11 figures, submitted to the IEEE Transactions on
  Information Theory</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09549</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully-Convolutional Siamese Networks for Object Tracking</dc:title>
 <dc:creator>Bertinetto, Luca</dc:creator>
 <dc:creator>Valmadre, Jack</dc:creator>
 <dc:creator>Henriques, Jo&#xe3;o F.</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The problem of arbitrary object tracking has traditionally been tackled by
learning a model of the object's appearance exclusively online, using as sole
training data the video itself. Despite the success of these methods, their
online-only approach inherently limits the richness of the model they can
learn. Recently, several attempts have been made to exploit the expressive
power of deep convolutional networks. However, when the object to track is not
known beforehand, it is necessary to perform Stochastic Gradient Descent online
to adapt the weights of the network, severely compromising the speed of the
system. In this paper we equip a basic tracking algorithm with a novel
fully-convolutional Siamese network trained end-to-end on the ILSVRC15 dataset
for object detection in video. Our tracker operates at frame-rates beyond
real-time and, despite its extreme simplicity, achieves state-of-the-art
performance in multiple benchmarks.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally, and are listed in
  alphabetical order. Code available at
  http://www.robots.ox.ac.uk/~luca/siamese-fc.html</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09552</identifier>
 <datestamp>2017-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proximity Operators of Discrete Information Divergences</dc:title>
 <dc:creator>Gheche, Mireille El</dc:creator>
 <dc:creator>Chierchia, Giovanni</dc:creator>
 <dc:creator>Pesquet, Jean-Christophe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Information divergences allow one to assess how close two distributions are
from each other. Among the large panel of available measures, a special
attention has been paid to convex $\varphi$-divergences, such as
Kullback-Leibler, Jeffreys-Kullback, Hellinger, Chi-Square, Renyi, and
I$_{\alpha}$ divergences. While $\varphi$-divergences have been extensively
studied in convex analysis, their use in optimization problems often remains
challenging. In this regard, one of the main shortcomings of existing methods
is that the minimization of $\varphi$-divergences is usually performed with
respect to one of their arguments, possibly within alternating optimization
techniques. In this paper, we overcome this limitation by deriving new
closed-form expressions for the proximity operator of such two-variable
functions. This makes it possible to employ standard proximal methods for
efficiently solving a wide range of convex optimization problems involving
$\varphi$-divergences. In addition, we show that these proximity operators are
useful to compute the epigraphical projection of several functions of practical
interest. The proposed proximal tools are numerically validated in the context
of optimal query execution within database management systems, where the
problem of selectivity estimation plays a central role. Experiments are carried
out on small to large scale scenarios.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09560</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network-based Word Alignment through Score Aggregation</dc:title>
 <dc:creator>Legrand, Joel</dc:creator>
 <dc:creator>Auli, Michael</dc:creator>
 <dc:creator>Collobert, Ronan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a simple neural network for word alignment that builds source and
target word window representations to compute alignment scores for sentence
pairs. To enable unsupervised training, we use an aggregation operation that
summarizes the alignment scores for a given target word. A soft-margin
objective increases scores for true target words while decreasing scores for
target words that are not present. Compared to the popular Fast Align model,
our approach improves alignment accuracy by 7 AER on English-Czech, by 6 AER on
Romanian-English and by 1.7 AER on English-French alignment.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09564</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Architecture and Algorithms for Privacy Preserving Thermal Inertial Load
  Management by A Load Serving Entity</dc:title>
 <dc:creator>Halder, Abhishek</dc:creator>
 <dc:creator>Geng, Xinbo</dc:creator>
 <dc:creator>Kumar, P. R.</dc:creator>
 <dc:creator>Xie, Le</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Motivated by the growing importance of demand response in modern power
system's operations, we propose an architecture and supporting algorithms for
privacy preserving thermal inertial load management as a service provided by
the load serving entity (LSE). We focus on an LSE managing a population of its
customers' air conditioners, and propose a contractual model where the LSE
guarantees quality of service to each customer in terms of keeping their indoor
temperature trajectories within respective bands around the desired individual
comfort temperatures. We show how the LSE can price the contracts
differentiated by the flexibility embodied by the width of the specified bands.
We address architectural questions of (i) how the LSE can strategize its energy
procurement based on price and ambient temperature forecasts, (ii) how an LSE
can close the real time control loop at the aggregate level while providing
individual comfort guarantees to loads, without ever measuring the states of an
air conditioner for privacy reasons. Control algorithms to enable our proposed
architecture are given, and their efficacy is demonstrated on real data.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09567</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinite Dimensional Multipliers and Pontryagin Principles for
  Discrete-Time Problems</dc:title>
 <dc:creator>Bachir, Mohammed</dc:creator>
 <dc:creator>Blot, Joel</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  The aim of this paper is to provide improvments to Pontryagin principles in
infinite-horizon discrete-time framework when the space of states and of space
of controls are infinite-dimensional. We use the method of reduction to finite
horizon and several functional-analytic lemmas to realize our aim.
</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09577</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ordering as privileged information</dc:title>
 <dc:creator>Vacek, Thomas</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose to accelerate the rate of convergence of the pattern recognition
task by directly minimizing the variance diameters of certain hypothesis
spaces, which are critical quantities in fast-convergence results.We show that
the variance diameters can be controlled by dividing hypothesis spaces into
metric balls based on a new order metric. This order metric can be minimized as
an ordinal regression problem, leading to a LUPI (Learning Using Privileged
Information) application where we take the privileged information as some
desired ordering, and construct a faster-converging hypothesis space by
empirically restricting some larger hypothesis space according to that
ordering. We give a risk analysis of the approach. We discuss the difficulties
with model selection and give an innovative technique for selecting multiple
model parameters. Finally, we provide some data experiments.
</dc:description>
 <dc:description>Comment: 10 pages, 1 table, 2 page appendix giving proofs</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09581</identifier>
 <datestamp>2016-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Based Evaluation of Various Machine Learning Classification
  Techniques for Chronic Kidney Disease Diagnosis</dc:title>
 <dc:creator>Sharma, Sahil</dc:creator>
 <dc:creator>Sharma, Vinod</dc:creator>
 <dc:creator>Sharma, Atul</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Areas where Artificial Intelligence (AI) &amp; related fields are finding their
applications are increasing day by day, moving from core areas of computer
science they are finding their applications in various other domains.In recent
times Machine Learning i.e. a sub-domain of AI has been widely used in order to
assist medical experts and doctors in the prediction, diagnosis and prognosis
of various diseases and other medical disorders. In this manuscript the authors
applied various machine learning algorithms to a problem in the domain of
medical diagnosis and analyzed their efficiency in predicting the results. The
problem selected for the study is the diagnosis of the Chronic Kidney
Disease.The dataset used for the study consists of 400 instances and 24
attributes. The authors evaluated 12 classification techniques by applying them
to the Chronic Kidney Disease data. In order to calculate efficiency, results
of the prediction by candidate methods were compared with the actual medical
results of the subject.The various metrics used for performance evaluation are
predictive accuracy, precision, sensitivity and specificity. The results
indicate that decision-tree performed best with nearly the accuracy of 98.6%,
sensitivity of 0.9720, precision of 1 and specificity of 1.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:date>2016-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09581</dc:identifier>
 <dc:identifier>International Journal of Modern Computer Science, Vol.4, Issue3,
  June 2016, pp.11-16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09589</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Changing Locus of Health Data Production and Use: Patient-Generated
  Health Data, Observations of Daily Living, and Personal Health Information
  Management</dc:title>
 <dc:creator>Piras, Enrico Maria</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Despite the growing attention of researcher, healthcare managers and policy
makers, data gathering and information management practices are largely
untheorized areas. In this work are presented and discussed some early-stage
conceptualizations: Patient-Generated Health Data (PGHD), Observations of Daily
Living (ODLs) and Personal Health Information Management (PHIM). As I shall try
to demonstrate, these labels are not neutral rather they underpin quite
different perspectives with respect to health, patient-doctor relationship, and
the status of data.
</dc:description>
 <dc:description>Comment: presented at &quot;Exploring data-work in Healthcare: making sense of data
  across boundaries&quot;, 24th May 2016, Trento, Italy</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09594</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextual Symmetries in Probabilistic Graphical Models</dc:title>
 <dc:creator>Anand, Ankit</dc:creator>
 <dc:creator>Grover, Aditya</dc:creator>
 <dc:creator>Mausam</dc:creator>
 <dc:creator>Singla, Parag</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  An important approach for efficient inference in probabilistic graphical
models exploits symmetries among objects in the domain. Symmetric variables
(states) are collapsed into meta-variables (meta-states) and inference
algorithms are run over the lifted graphical model instead of the flat one. Our
paper extends existing definitions of symmetry by introducing the novel notion
of contextual symmetry. Two states that are not globally symmetric, can be
contextually symmetric under some specific assignment to a subset of variables,
referred to as the context variables. Contextual symmetry subsumes previous
symmetry definitions and can rep resent a large class of symmetries not
representable earlier. We show how to compute contextual symmetries by reducing
it to the problem of graph isomorphism. We extend previous work on exploiting
symmetries in the MCMC framework to the case of contextual symmetries. Our
experiments on several domains of interest demonstrate that exploiting
contextual symmetries can result in significant computational gains.
</dc:description>
 <dc:description>Comment: 9 Pages, 4 figures</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09594</dc:identifier>
 <dc:identifier>IJCAI, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09596</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing the Total Movement for Movement to Independence Problem on a
  Line</dc:title>
 <dc:creator>Ghadiri, Mehrdad</dc:creator>
 <dc:creator>Yazdanbod, Sina</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Given a positive real value $\delta$, a set $P$ of points along a line and a
distance function $d$, in the movement to independence problem, we wish to move
the points to new positions on the line such that for every two points
$p_{i},p_{j} \in P$, we have $d(p_{i},p_{j}) \geq \delta$ while minimizing the
sum of movements of all points. This measure of the cost for moving the points
was previously unsolved in this setting. However for different cost measures
there are algorithms of $O(n \log(n))$ or of $O(n)$. We present an $O(n
\log(n))$ algorithm for the points on a line and thus conclude the setting in
one dimension.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09600</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Prediction Uncertainty in Machine Translation Quality
  Estimation</dc:title>
 <dc:creator>Beck, Daniel</dc:creator>
 <dc:creator>Specia, Lucia</dc:creator>
 <dc:creator>Cohn, Trevor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Machine Translation Quality Estimation is a notoriously difficult task, which
lessens its usefulness in real-world translation environments. Such scenarios
can be improved if quality predictions are accompanied by a measure of
uncertainty. However, models in this task are traditionally evaluated only in
terms of point estimate metrics, which do not take prediction uncertainty into
account. We investigate probabilistic methods for Quality Estimation that can
provide well-calibrated uncertainty estimates and evaluate them in terms of
their full posterior predictive distributions. We also show how this posterior
information can be useful in an asymmetric risk scenario, which aims to capture
typical situations in translation workflows.
</dc:description>
 <dc:description>Comment: Proceedings of CoNLL 2016</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09604</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SnapToGrid: From Statistical to Interpretable Models for Biomedical
  Information Extraction</dc:title>
 <dc:creator>Valenzuela-Escarcega, Marco A.</dc:creator>
 <dc:creator>Hahn-Powell, Gus</dc:creator>
 <dc:creator>Bell, Dane</dc:creator>
 <dc:creator>Surdeanu, Mihai</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose an approach for biomedical information extraction that marries the
advantages of machine learning models, e.g., learning directly from data, with
the benefits of rule-based approaches, e.g., interpretability. Our approach
starts by training a feature-based statistical model, then converts this model
to a rule-based variant by converting its features to rules, and &quot;snapping to
grid&quot; the feature weights to discrete votes. In doing so, our proposal takes
advantage of the large body of work in machine learning, but it produces an
interpretable model, which can be directly edited by experts. We evaluate our
approach on the BioNLP 2009 event extraction task. Our results show that there
is a small performance penalty when converting the statistical model to rules,
but the gain in interpretability compensates for that: with minimal effort,
human experts improve this model to have similar performance to the statistical
model that served as starting point.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09605</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LocationSafe: Granular Location Privacy for IoT Devices</dc:title>
 <dc:creator>Joy, Joshua</dc:creator>
 <dc:creator>Le, Minh</dc:creator>
 <dc:creator>Gerla, Mario</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Today, mobile data owners lack consent and control over the release and
utilization of their location data. Third party applications continuously
process and access location data without data owners granular control and
without knowledge of how location data is being used. The proliferation of IoT
devices will lead to larger scale abuses of trust.
  In this paper we present the first design and implementation of a privacy
module built into the GPSD daemon. The GPSD daemon is a low-level GPS interface
that runs on GPS enabled devices. The integration of the privacy module ensures
that data owners have granular control over the release of their GPS location.
We describe the design of our privacy module and then evaluate the performance
of private GPS release and demonstrate that strong privacy guarantees can be
built into the GPSD daemon itself with minimal to no overhead.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1604.04892</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09610</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Crowdsourcing Approach To Collecting Tutorial Videos -- Toward
  Personalized Learning-at-Scale</dc:title>
 <dc:creator>Whitehill, Jacob</dc:creator>
 <dc:creator>Seltzer, Margo</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We investigated the feasibility of crowdsourcing full-fledged tutorial videos
from ordinary people on the Web on how to solve math problems related to
logarithms. This kind of approach (a form of learnersourcing) to efficiently
collecting tutorial videos and other learning resources could be useful for
realizing personalized learning-at-scale, whereby students receive specific
learning resources -- drawn from a large and diverse set -- that are tailored
to their individual and time-varying needs. Results of our study, in which we
collected 399 videos from 66 unique &quot;teachers&quot; on Mechanical Turk, suggest that
(1) approximately 100 videos -- over $80\%$ of which are mathematically fully
correct -- can be crowdsourced per week for \$5/video; (2) the crowdsourced
videos exhibit significant diversity in terms of language style, presentation
media, and pedagogical approach; (3) the average learning gains (posttest minus
pretest score) associated with watching the videos was stat.~sig.~higher than
for a control video ($0.105$ versus $0.045$); and (4) the average learning
gains ($0.1416$) from watching the best tested crowdsourced videos was
comparable to the learning gains ($0.1506$) from watching a popular Khan
Academy video on logarithms.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09632</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Permutation-based Model for Crowd Labeling: Optimal Estimation and
  Robustness</dc:title>
 <dc:creator>Shah, Nihar B.</dc:creator>
 <dc:creator>Balakrishnan, Sivaraman</dc:creator>
 <dc:creator>Wainwright, Martin J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The aggregation and denoising of crowd labeled data is a task that has gained
increased significance with the advent of crowdsourcing platforms and massive
datasets. In this paper, we propose a permutation-based model for crowd labeled
data that is a significant generalization of the common Dawid-Skene model, and
introduce a new error metric by which to compare different estimators. Working
in a high-dimensional non-asymptotic framework that allows both the number of
workers and tasks to scale, we derive optimal rates of convergence for the
permutation-based model. We show that the permutation-based model offers
significant robustness in estimation due to its richness, while surprisingly
incurring only a small additional statistical penalty as compared to the
Dawid-Skene model. Finally, we propose a computationally-efficient method,
called the OBI-WAN estimator, that is uniformly optimal over a class
intermediate between the permutation-based and the Dawid-Skene models, and is
uniformly consistent over the entire permutation-based model class. In
contrast, the guarantees for estimators available in prior literature are
sub-optimal over the original Dawid-Skene model.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09636</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation of texts as complex networks: a mesoscopic approach</dc:title>
 <dc:creator>de Arruda, Henrique F.</dc:creator>
 <dc:creator>Silva, Filipi N.</dc:creator>
 <dc:creator>Marinho, Vanessa Q.</dc:creator>
 <dc:creator>Amancio, Diego R.</dc:creator>
 <dc:creator>Costa, Luciano da F.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Statistical techniques that analyze texts, referred to as text analytics,
have departed from the use of simple word count statistics towards a new
paradigm. Text mining now hinges on a more sophisticated set of methods,
including the representations in terms of complex networks. While
well-established word-adjacency (co-occurrence) methods successfully grasp
syntactical features of written texts, they are unable to represent important
aspects of textual data, such as its topical structure, i.e. the sequence of
subjects developing at a mesoscopic level along the text. Such aspects are
often overlooked by current methodologies. In order to grasp the mesoscopic
characteristics of semantical content in written texts, we devised a network
model which is able to analyze documents in a multi-scale fashion. In the
proposed model, a limited amount of adjacent paragraphs are represented as
nodes, which are connected whenever they share a minimum semantical content. To
illustrate the capabilities of our model, we present, as a case example, a
qualitative analysis of &quot;Alice's Adventures in Wonderland&quot;. We show that the
mesoscopic structure of a document, modeled as a network, reveals many semantic
traits of texts. Such an approach paves the way to a myriad of semantic-based
applications. In addition, our approach is illustrated in a machine learning
context, in which texts are classified among real texts and randomized
instances.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09636</dc:identifier>
 <dc:identifier>Journal of Complex Networks, cnx023, 2017 (Available at
  https://goo.gl/Wo8FFZ)</dc:identifier>
 <dc:identifier>doi:10.1093/comnet/cnx023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09637</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lifted Region-Based Belief Propagation</dc:title>
 <dc:creator>Smith, David</dc:creator>
 <dc:creator>Singla, Parag</dc:creator>
 <dc:creator>Gogate, Vibhav</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Due to the intractable nature of exact lifted inference, research has
recently focused on the discovery of accurate and efficient approximate
inference algorithms in Statistical Relational Models (SRMs), such as Lifted
First-Order Belief Propagation. FOBP simulates propositional factor graph
belief propagation without constructing the ground factor graph by identifying
and lifting over redundant message computations. In this work, we propose a
generalization of FOBP called Lifted Generalized Belief Propagation, in which
both the region structure and the message structure can be lifted. This
approach allows more of the inference to be performed intra-region (in the
exact inference step of BP), thereby allowing simulation of propagation on a
graph structure with larger region scopes and fewer edges, while still
maintaining tractability. We demonstrate that the resulting algorithm converges
in fewer iterations to more accurate results on a variety of SRMs.
</dc:description>
 <dc:description>Comment: Sixth International Workshop on Statistical Relational AI</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09638</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Higher Type Theory II: Dependent Cubical Realizability</dc:title>
 <dc:creator>Angiuli, Carlo</dc:creator>
 <dc:creator>Harper, Robert</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This is the second in a series of papers extending Martin-L\&quot;{o}f's meaning
explanation of dependent type theory to account for higher-dimensional types.
We build on the cubical realizability framework for simple types developed in
Part I, and extend it to a meaning explanation of dependent higher-dimensional
type theory. This extension requires generalizing the computational Kan
condition given in Part I, and considering the action of type families on
paths. We define identification types, which classify identifications (paths)
in a type, and dependent function and pair types. The main result is a
canonicity theorem, which states that a closed term of boolean type evaluates
to either true or false. This result establishes the first computational
interpretation of higher dependent type theory by giving a deterministic
operational semantics for its programs, including operations that realize the
Kan condition.
</dc:description>
 <dc:description>Comment: 65 pages. v2: added sections A.1, A.2. v3: added sections A.3, A.4.
  arXiv admin note: text overlap with arXiv:1604.08873</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1606.09641</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Dynamics at a Phase Transition</dc:title>
 <dc:creator>Sowinski, Damian</dc:creator>
 <dc:creator>Gleiser, Marcelo</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Pattern Formation and Solitons</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  We propose a new way of investigating phase transitions in the context of
information theory. We use an information-entropic measure of spatial
complexity known as configurational entropy (CE) to quantify both the storage
and exchange of information in a lattice simulation of a Ginzburg-Landau model
with a scalar order parameter coupled to a heat bath. The CE is built from the
Fourier spectrum of fluctuations around the mean-field and reaches a minimum at
criticality. In particular, we investigate the behavior of CE near and at
criticality, exploring the relation between information and the emergence of
ordered domains. We show that as the temperature is increased from below, the
CE displays three essential scaling regimes at different spatial scales: scale
free, turbulent, and critical. Together, they offer an information-entropic
characterization of critical behavior where the storage and processing of
information is maximized at criticality.
</dc:description>
 <dc:description>Comment: updated text and added references</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1606.09641</dc:identifier>
 <dc:identifier>doi:10.1007/s10955-017-1762-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00022</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling confirmation bias and polarization</dc:title>
 <dc:creator>Del Vicario, Michela</dc:creator>
 <dc:creator>Scala, Antonio</dc:creator>
 <dc:creator>Caldarelli, Guido</dc:creator>
 <dc:creator>Stanley, H Eugene</dc:creator>
 <dc:creator>Quattrociocchi, Walter</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online users tend to select claims that adhere to their system of beliefs and
to ignore dissenting information. Confirmation bias, indeed, plays a pivotal
role in viral phenomena. Furthermore, the wide availability of content on the
web fosters the aggregation of likeminded people where debates tend to enforce
group polarization. Such a configuration might alter the public debate and thus
the formation of the public opinion. In this paper we provide a mathematical
model to study online social debates and the related polarization dynamics. We
assume the basic updating rule of the Bounded Confidence Model (BCM) and we
develop two variations a) the Rewire with Bounded Confidence Model (RBCM), in
which discordant links are broken until convergence is reached; and b) the
Unbounded Confidence Model, under which the interaction among discordant pairs
of users is allowed even with a negative feedback, either with the rewiring
step (RUCM) or without it (UCM). From numerical simulations we find that the
new models (UCM and RUCM), unlike the BCM, are able to explain the coexistence
of two stable final opinions, often observed in reality. Lastly, we present a
mean field approximation of the newly introduced models.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00024</identifier>
 <datestamp>2016-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Review Based Rating Prediction</dc:title>
 <dc:creator>Hadad, Tal</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recommendation systems are an important units in today's e-commerce
applications, such as targeted advertising, personalized marketing and
information retrieval. In recent years, the importance of contextual
information has motivated generation of personalized recommendations according
to the available contextual information of users.
  Compared to the traditional systems which mainly utilize users' rating
history, review-based recommendation hopefully provide more relevant results to
users. We introduce a review-based recommendation approach that obtains
contextual information by mining user reviews. The proposed approach relate to
features obtained by analyzing textual reviews using methods developed in
Natural Language Processing (NLP) and information retrieval discipline to
compute a utility function over a given item. An item utility is a measure that
shows how much it is preferred according to user's current context.
  In our system, the context inference is modeled as similarity between the
users reviews history and the item reviews history. As an example application,
we used our method to mine contextual data from customers' reviews of movies
and use it to produce review-based rating prediction. The predicted ratings can
generate recommendations that are item-based and should appear at the
recommended items list in the product page. Our evaluations suggest that our
system can help produce better prediction rating scores in comparison to the
standard prediction methods.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00030</identifier>
 <datestamp>2016-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HUME: Human UCCA-Based Evaluation of Machine Translation</dc:title>
 <dc:creator>Birch, Alexandra</dc:creator>
 <dc:creator>Abend, Omri</dc:creator>
 <dc:creator>Bojar, Ondrej</dc:creator>
 <dc:creator>Haddow, Barry</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Human evaluation of machine translation normally uses sentence-level measures
such as relative ranking or adequacy scales. However, these provide no insight
into possible errors, and do not scale well with sentence length. We argue for
a semantics-based evaluation, which captures what meaning components are
retained in the MT output, thus providing a more fine-grained analysis of
translation quality, and enabling the construction and tuning of
semantics-based MT. We present a novel human semantic evaluation measure, Human
UCCA-based MT Evaluation (HUME), building on the UCCA semantic representation
scheme. HUME covers a wider range of semantic phenomena than previous methods
and does not rely on semantic annotation of the potentially garbled MT output.
We experiment with four language pairs, demonstrating HUME's broad
applicability, and report good inter-annotator agreement rates and correlation
with human adequacy scores.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00034</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ballpark Learning: Estimating Labels from Rough Group Comparisons</dc:title>
 <dc:creator>Hope, Tom</dc:creator>
 <dc:creator>Shahaf, Dafna</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We are interested in estimating individual labels given only coarse,
aggregated signal over the data points. In our setting, we receive sets
(&quot;bags&quot;) of unlabeled instances with constraints on label proportions. We relax
the unrealistic assumption of known label proportions, made in previous work;
instead, we assume only to have upper and lower bounds, and constraints on bag
differences. We motivate the problem, propose an intuitive formulation and
algorithm, and apply our methods to real-world scenarios. Across several
domains, we show how using only proportion constraints and no labeled examples,
we can achieve surprisingly high accuracy. In particular, we demonstrate how to
predict income level using rough stereotypes and how to perform sentiment
analysis using very little information. We also apply our method to guide
exploratory analysis, recovering geographical differences in twitter dialect.
</dc:description>
 <dc:description>Comment: To appear in the European Conference on Machine Learning and
  Principles and Practice of Knowledge Discovery (ECML-PKDD) 2016</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00036</identifier>
 <datestamp>2017-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes</dc:title>
 <dc:creator>Gulcehre, Caglar</dc:creator>
 <dc:creator>Chandar, Sarath</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We extend neural Turing machine (NTM) model into a dynamic neural Turing
machine (D-NTM) by introducing a trainable memory addressing scheme. This
addressing scheme maintains for each memory cell two separate vectors, content
and address vectors. This allows the D-NTM to learn a wide variety of
location-based addressing strategies including both linear and nonlinear ones.
We implement the D-NTM with both continuous, differentiable and discrete,
non-differentiable read/write mechanisms. We investigate the mechanisms and
effects of learning to read and write into a memory through experiments on
Facebook bAbI tasks using both a feedforward and GRUcontroller. The D-NTM is
evaluated on a set of Facebook bAbI tasks and shown to outperform NTM and LSTM
baselines. We have done extensive analysis of our model and different
variations of NTM on bAbI task. We also provide further experimental results on
sequential pMNIST, Stanford Natural Language Inference, associative recall and
copy tasks.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00051</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Learning and Topological Inference with Biobotic Networks:
  Convergence Analysis</dc:title>
 <dc:creator>Dirafzoon, Alireza</dc:creator>
 <dc:creator>Bozkurt, Alper</dc:creator>
 <dc:creator>Lobaton, Edgar</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this study, we present and analyze a framework for geometric and
topological estimation for mapping of unknown environments. We consider agents
mimicking motion behaviors of cyborg insects, known as biobots, and exploit
coordinate-free local interactions among them to infer geometric and
topological information about the environment, under minimal sensing and
localization constraints. Local interactions are used to create a graphical
representation referred to as the encounter graph. A metric is estimated over
the encounter graph of the agents in order to construct a geometric point cloud
using manifold learning techniques. Topological data analysis (TDA), in
particular persistent homology, is used in order to extract topological
features of the space and a classification method is proposed to infer robust
features of interest (e.g. existence of obstacles). We examine the asymptotic
behavior of the proposed metric in terms of the convergence to the geodesic
distances in the underlying manifold of the domain, and provide stability
analysis results for the topological persistence. The proposed framework and
its convergences and stability analysis are demonstrated through numerical
simulations and experiments.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00061</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards A Virtual Assistant That Can Be Taught New Tasks In Any Domain
  By Its End-Users</dc:title>
 <dc:creator>Melamed, I. Dan</dc:creator>
 <dc:creator>Niraula, Nobal B.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The challenge stated in the title can be divided into two main problems. The
first problem is to reliably mimic the way that users interact with user
interfaces. The second problem is to build an instructible agent, i.e. one that
can be taught to execute tasks expressed as previously unseen natural language
commands. This paper proposes a solution to the second problem, a system we
call Helpa. End-users can teach Helpa arbitrary new tasks whose level of
complexity is similar to the tasks available from today's most popular virtual
assistants. Teaching Helpa does not involve any programming. Instead, users
teach Helpa by providing just one example of a command paired with a
demonstration of how to execute that command. Helpa does not rely on any
pre-existing domain-specific knowledge. It is therefore completely
domain-independent. Our usability study showed that end-users can teach Helpa
many new tasks in less than a minute each, often much less.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00064</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing CNN Accelerator Efficiency Through Resource Partitioning</dc:title>
 <dc:creator>Shen, Yongming</dc:creator>
 <dc:creator>Ferdman, Michael</dc:creator>
 <dc:creator>Milder, Peter</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) are revolutionizing a variety of machine
learning tasks, but they present significant computational challenges.
Recently, FPGA-based accelerators have been proposed to improve the speed and
efficiency of CNNs. Current approaches construct a single processor that
computes the CNN layers one at a time; this single processor is optimized to
maximize the overall throughput at which the collection of layers are computed.
However, this approach leads to inefficient designs because the same processor
structure is used to compute CNN layers of radically varying dimensions.
  We present a new CNN accelerator paradigm and an accompanying automated
design methodology that partitions the available FPGA resources into multiple
processors, each of which is tailored for a different subset of the CNN
convolutional layers. Using the same FPGA resources as a single large
processor, multiple smaller specialized processors result in increased
computational efficiency and lead to a higher overall throughput. Our design
methodology achieves 1.51x higher throughput than the state of the art approach
on evaluating the popular AlexNet CNN on a Xilinx Virtex-7 FPGA. Our
projections indicate that the benefit of our approach increases with the amount
of available FPGA resources, already growing to over 3x over the state of the
art within the next generation of FPGAs.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00067</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning with Imbalanced Data via Structure Consolidation
  Latent Variable Model</dc:title>
 <dc:creator>Yousefi, Fariba</dc:creator>
 <dc:creator>Dai, Zhenwen</dc:creator>
 <dc:creator>Ek, Carl Henrik</dc:creator>
 <dc:creator>Lawrence, Neil</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Unsupervised learning on imbalanced data is challenging because, when given
imbalanced data, current model is often dominated by the major category and
ignores the categories with small amount of data. We develop a latent variable
model that can cope with imbalanced data by dividing the latent space into a
shared space and a private space. Based on Gaussian Process Latent Variable
Models, we propose a new kernel formulation that enables the separation of
latent space and derives an efficient variational inference method. The
performance of our model is demonstrated with an imbalanced medical image
dataset.
</dc:description>
 <dc:description>Comment: ICLR 2016 Workshop</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00070</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue
  Systems</dc:title>
 <dc:creator>Asri, Layla El</dc:creator>
 <dc:creator>He, Jing</dc:creator>
 <dc:creator>Suleman, Kaheer</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  User simulation is essential for generating enough data to train a
statistical spoken dialogue system. Previous models for user simulation suffer
from several drawbacks, such as the inability to take dialogue history into
account, the need of rigid structure to ensure coherent user behaviour, heavy
dependence on a specific domain, the inability to output several user
intentions during one dialogue turn, or the requirement of a summarized action
space for tractability. This paper introduces a data-driven user simulator
based on an encoder-decoder recurrent neural network. The model takes as input
a sequence of dialogue contexts and outputs a sequence of dialogue acts
corresponding to user intentions. The dialogue contexts include information
about the machine acts and the status of the user goal. We show on the Dialogue
State Tracking Challenge 2 (DSTC2) dataset that the sequence-to-sequence model
outperforms an agenda-based simulator and an n-gram simulator, according to
F-score. Furthermore, we show how this model can be used on the original action
space and thereby models user behaviour with finer granularity.
</dc:description>
 <dc:description>Comment: Accepted for publication at Interspeech 2016</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00076</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-class classification: mirror descent approach</dc:title>
 <dc:creator>Reshetova, Daria</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of multi-class classification and a stochastic opti-
mization approach to it. We derive risk bounds for stochastic mirror descent
algorithm and provide examples of set geometries that make the use of the
algorithm efficient in terms of error in k.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00087</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fractal Dimension Pattern Based Multiresolution Analysis for Rough
  Estimator of Person-Dependent Audio Emotion Recognition</dc:title>
 <dc:creator>Cheng, Miao</dc:creator>
 <dc:creator>Tsoi, Ah Chung</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  As a general means of expression, audio analysis and recognition has
attracted much attentions for its wide applications in real-life world. Audio
emotion recognition (AER) attempts to understand emotional states of human with
the given utterance signals, and has been studied abroad for its further
development on friendly human-machine interfaces. Distinguish from other
existing works, the person-dependent patterns of audio emotions are conducted,
and fractal dimension features are calculated for acoustic feature extraction.
Furthermore, it is able to efficiently learn intrinsic characteristics of
auditory emotions, while the utterance features are learned from fractal
dimensions of each sub-bands. Experimental results show the proposed method is
able to provide comparative performance for audio emotion recognition.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00089</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Algebraic Manipulation in Leaky Storage Systems</dc:title>
 <dc:creator>Lin, Fuchun</dc:creator>
 <dc:creator>Safavi-Naini, Reihaneh</dc:creator>
 <dc:creator>Wang, Pengwei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Algebraic Manipulation Detection (AMD) Codes detect adversarial noise that is
added to a coded message and stored in a storage that is opaque to the
adversary. We study AMD codes when the storage can leak up to \rho\log|G| bits
of information about the stored codeword, where G is the group in which the
stored codeword lives and \rho is a constant. We propose \rho-AMD codes that
provide protection in this new setting, and define weak and strong \rho-AMD
codes that provide security for a random and an arbitrary message,
respectively. We derive concrete and asymptotic bounds for the efficiency of
these codes featuring a rate upper bound of 1-\rho for the strong codes. We
also define the class of \rho^{LV}-AMD codes that provide protection when
leakage is in the form of a number of codeword components, and give
constructions featuring a strong \rho^{LV}-AMD codes that asymptotically
achieve the rate 1-\rho. We describe applications of \rho-AMD codes to, (i)
robust ramp secret sharing scheme and, (ii) wiretap II channel when the
adversary can eavesdrop a \rho fraction of codeword components and tamper with
all components of the codeword.
</dc:description>
 <dc:description>Comment: 22 pages, 2 figures</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00096</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HEAP: Reliable Assessment of BGP Hijacking Attacks</dc:title>
 <dc:creator>Schlamp, Johann</dc:creator>
 <dc:creator>Holz, Ralph</dc:creator>
 <dc:creator>Jacquemart, Quentin</dc:creator>
 <dc:creator>Carle, Georg</dc:creator>
 <dc:creator>Biersack, Ernst W.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:subject>C.2.6</dc:subject>
 <dc:description>  The detection of BGP prefix hijacking attacks has been the focus of research
for more than a decade. However, state-of-the-art techniques fall short of
detecting more elaborate types of attack. To study such attacks, we devise a
novel formalization of Internet routing, and apply this model to routing
anomalies in order to establish a comprehensive attacker model. We use this
model to precisely classify attacks and to evaluate their impact and
detectability. We analyze the eligibility of attack tactics that suit an
attacker's goals and demonstrate that related work mostly focuses on less
impactful kinds of attacks.
  We further propose, implement and test the Hijacking Event Analysis Program
(HEAP), a new approach to investigate hijacking alarms. Our approachis designed
to seamlessly integrate with previous work in order to reduce the high rates of
false alarms inherent to these techniques. We leverage several unique data
sources that can reliably disprove malicious intent. First, we make use of an
Internet Routing Registry to derive business or organisational relationships
between the parties involved in an event. Second, we use a topology-based
reasoning algorithm to rule out events caused by legitimate operational
practice. Finally, we use Internet-wide network scans to identify
SSL/TLS-enabled hosts, which helps to identify non-malicious events by
comparing public keys prior to and during an event. In our evaluation, we prove
the effectiveness of our approach, and show that day-to-day routing anomalies
are harmless for the most part. More importantly, we use HEAP to assess the
validity of publicly reported alarms. We invite researchers to interface with
HEAP in order to cross-check and narrow down their hijacking alerts.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00101</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized block proximal damped Newton method for composite
  self-concordant minimization</dc:title>
 <dc:creator>Lu, Zhaosong</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>49M15, 65K05, 90C06, 90C25, 90C51</dc:subject>
 <dc:description>  In this paper we consider the composite self-concordant (CSC) minimization
problem, which minimizes the sum of a self-concordant function $f$ and a
(possibly nonsmooth) proper closed convex function $g$. The CSC minimization is
the cornerstone of the path-following interior point methods for solving a
broad class of convex optimization problems. It has also found numerous
applications in machine learning. The proximal damped Newton (PDN) methods have
been well studied in the literature for solving this problem that enjoy a nice
iteration complexity. Given that at each iteration these methods typically
require evaluating or accessing the Hessian of $f$ and also need to solve a
proximal Newton subproblem, the cost per iteration can be prohibitively high
when applied to large-scale problems. Inspired by the recent success of block
coordinate descent methods, we propose a randomized block proximal damped
Newton (RBPDN) method for solving the CSC minimization. Compared to the PDN
methods, the computational cost per iteration of RBPDN is usually significantly
lower. The computational experiment on a class of regularized logistic
regression problems demonstrate that RBPDN is indeed promising in solving
large-scale CSC minimization problems. The convergence of RBPDN is also
analyzed in the paper. In particular, we show that RBPDN is globally convergent
when $g$ is Lipschitz continuous. It is also shown that RBPDN enjoys a local
linear convergence. Moreover, we show that for a class of $g$ including the
case where $g$ is Lipschitz differentiable, RBPDN enjoys a global linear
convergence. As a striking consequence, it shows that the classical damped
Newton methods [22,40] and the PDN [31] for such $g$ are globally linearly
convergent, which was previously unknown in the literature. Moreover, this
result can be used to sharpen the existing iteration complexity of these
methods.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00106</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on extended Euclid's algorithm</dc:title>
 <dc:creator>Leung, Hing</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>68R99</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>G.2.0</dc:subject>
 <dc:description>  Starting with the recursive extended Euclid's algorithm, we apply a
systematic approach using matrix notation to transform it into an iterative
algorithm. The partial correctness proof derived from the transformation turns
out to be very elegant, and easy to follow. The paper provides a connection
between recursive and iterative versions of extended Euclid's algorithm.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00110</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Gradient Boosting Machines with Collective Inference to
  Predict Continuous Values</dc:title>
 <dc:creator>Alodah, Iman</dc:creator>
 <dc:creator>Neville, Jennifer</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Gradient boosting of regression trees is a competitive procedure for learning
predictive models of continuous data that fits the data with an additive
non-parametric model. The classic version of gradient boosting assumes that the
data is independent and identically distributed. However, relational data with
interdependent, linked instances is now common and the dependencies in such
data can be exploited to improve predictive performance. Collective inference
is one approach to exploit relational correlation patterns and significantly
reduce classification error. However, much of the work on collective learning
and inference has focused on discrete prediction tasks rather than continuous.
%target values has not got that attention in terms of collective inference. In
this work, we investigate how to combine these two paradigms together to
improve regression in relational domains. Specifically, we propose a boosting
algorithm for learning a collective inference model that predicts a continuous
target variable. In the algorithm, we learn a basic relational model,
collectively infer the target values, and then iteratively learn relational
models to predict the residuals. We evaluate our proposed algorithm on a real
network dataset and show that it outperforms alternative boosting methods.
However, our investigation also revealed that the relational features interact
together to produce better predictions.
</dc:description>
 <dc:description>Comment: 7 pages, 3 Figures, Sixth International Workshop on Statistical
  Relational AI</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00117</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>All Your Cards Are Belong To Us: Understanding Online Carding Forums</dc:title>
 <dc:creator>Haslebacher, Andreas</dc:creator>
 <dc:creator>Onaolapo, Jeremiah</dc:creator>
 <dc:creator>Stringhini, Gianluca</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Underground online forums are platforms that enable trades of illicit
services and stolen goods. Carding forums, in particular, are known for being
focused on trading financial information. However, little evidence exists about
the sellers that are present on carding forums, the precise types of products
they advertise, and the prices buyers pay. Existing literature mainly focuses
on the organisation and structure of the forums. Furthermore, studies on
carding forums are usually based on literature review, expert interviews, or
data from forums that have already been shut down. This paper provides
first-of-its-kind empirical evidence on active forums where stolen financial
data is traded. We monitored 5 out of 25 discovered forums, collected posts
from the forums over a three-month period, and analysed them quantitatively and
qualitatively. We focused our analyses on products, prices, seller prolificacy,
seller specialisation, and seller reputation.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00122</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Less-forgetting Learning in Deep Neural Networks</dc:title>
 <dc:creator>Jung, Heechul</dc:creator>
 <dc:creator>Ju, Jeongwoo</dc:creator>
 <dc:creator>Jung, Minju</dc:creator>
 <dc:creator>Kim, Junmo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A catastrophic forgetting problem makes deep neural networks forget the
previously learned information, when learning data collected in new
environments, such as by different sensors or in different light conditions.
This paper presents a new method for alleviating the catastrophic forgetting
problem. Unlike previous research, our method does not use any information from
the source domain. Surprisingly, our method is very effective to forget less of
the information in the source domain, and we show the effectiveness of our
method using several experiments. Furthermore, we observed that the forgetting
problem occurs between mini-batches when performing general training processes
using stochastic gradient descent methods, and this problem is one of the
factors that degrades generalization performance of the network. We also try to
solve this problem using the proposed method. Finally, we show our
less-forgetting learning method is also helpful to improve the performance of
deep neural networks in terms of recognition rates.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00127</identifier>
 <datestamp>2016-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor Network alternating linear scheme for MIMO Volterra system
  identification</dc:title>
 <dc:creator>Batselier, Kim</dc:creator>
 <dc:creator>Chen, Zhongming</dc:creator>
 <dc:creator>Wong, Ngai</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This article introduces two Tensor Network-based iterative algorithms for the
identification of high-order discrete-time nonlinear multiple-input
multiple-output (MIMO) Volterra systems. The system identification problem is
rewritten in terms of a Volterra tensor, which is never explicitly constructed,
thus avoiding the curse of dimensionality. It is shown how each iteration of
the two identification algorithms involves solving a linear system of low
computational complexity. The proposed algorithms are guaranteed to
monotonically converge and numerical stability is ensured through the use of
orthogonal matrix factorizations. The performance and accuracy of the two
identification algorithms are illustrated by numerical experiments, where
accurate degree-10 MIMO Volterra models are identified in about 1 second in
Matlab on a standard desktop pc.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00133</identifier>
 <datestamp>2016-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning with Differential Privacy</dc:title>
 <dc:creator>Abadi, Mart&#xed;n</dc:creator>
 <dc:creator>Chu, Andy</dc:creator>
 <dc:creator>Goodfellow, Ian</dc:creator>
 <dc:creator>McMahan, H. Brendan</dc:creator>
 <dc:creator>Mironov, Ilya</dc:creator>
 <dc:creator>Talwar, Kunal</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning techniques based on neural networks are achieving remarkable
results in a wide variety of domains. Often, the training of models requires
large, representative datasets, which may be crowdsourced and contain sensitive
information. The models should not expose private information in these
datasets. Addressing this goal, we develop new algorithmic techniques for
learning and a refined analysis of privacy costs within the framework of
differential privacy. Our implementation and experiments demonstrate that we
can train deep neural networks with non-convex objectives, under a modest
privacy budget, and at a manageable cost in software complexity, training
efficiency, and model quality.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00133</dc:identifier>
 <dc:identifier>doi:10.1145/2976749.2978318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00136</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Missing Data Estimation in High-Dimensional Datasets: A Swarm
  Intelligence-Deep Neural Network Approach</dc:title>
 <dc:creator>Leke, Collins</dc:creator>
 <dc:creator>Marwala, Tshilidzi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we examine the problem of missing data in high-dimensional
datasets by taking into consideration the Missing Completely at Random and
Missing at Random mechanisms, as well as theArbitrary missing pattern.
Additionally, this paper employs a methodology based on Deep Learning and Swarm
Intelligence algorithms in order to provide reliable estimates for missing
data. The deep learning technique is used to extract features from the input
data via an unsupervised learning approach by modeling the data distribution
based on the input. This deep learning technique is then used as part of the
objective function for the swarm intelligence technique in order to estimate
the missing data after a supervised fine-tuning phase by minimizing an error
function based on the interrelationship and correlation between features in the
dataset. The investigated methodology in this paper therefore has longer
running times, however, the promising potential outcomes justify the trade-off.
Also, basic knowledge of statistics is presumed.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00137</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Graphical Representation based Discriminant Analysis for
  Heterogeneous Face Recognition</dc:title>
 <dc:creator>Peng, Chunlei</dc:creator>
 <dc:creator>Gao, Xinbo</dc:creator>
 <dc:creator>Wang, Nannan</dc:creator>
 <dc:creator>Li, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face images captured in heterogeneous environments, e.g., sketches generated
by the artists or composite-generation software, photos taken by common cameras
and infrared images captured by corresponding infrared imaging devices, usually
subject to large texture (i.e., style) differences. This results in heavily
degraded performance of conventional face recognition methods in comparison
with the performance on images captured in homogeneous environments. In this
paper, we propose a novel sparse graphical representation based discriminant
analysis (SGR-DA) approach to address aforementioned face recognition in
heterogeneous scenarios. An adaptive sparse graphical representation scheme is
designed to represent heterogeneous face images, where a Markov networks model
is constructed to generate adaptive sparse vectors. To handle the complex
facial structure and further improve the discriminability, a spatial
partition-based discriminant analysis framework is presented to refine the
adaptive sparse vectors for face matching. We conducted experiments on six
commonly used heterogeneous face datasets and experimental results illustrate
that our proposed SGR-DA approach achieves superior performance in comparison
with state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 13 pages, 17 figures, submitted to IEEE TNNLS</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00138</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing Pattern Matching Algorithms by Polynomial-Size Automata</dc:title>
 <dc:creator>Marschall, Tobias</dc:creator>
 <dc:creator>Passing, Noemi E.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Pattern matching algorithms to find exact occurrences of a pattern
$S\in\Sigma^m$ in a text $T\in\Sigma^n$ have been analyzed extensively with
respect to asymptotic best, worst, and average case runtime. For more detailed
analyses, the number of text character accesses $X^{\mathcal{A},S}_n$ performed
by an algorithm $\mathcal{A}$ when searching a random text of length $n$ for a
fixed pattern $S$ has been considered. Constructing a state space and
corresponding transition rules (e.g. in a Markov chain) that reflect the
behavior of a pattern matching algorithm is a key step in existing analyses of
$X^{\mathcal{A},S}_n$ in both the asymptotic ($n\to\infty$) and the
non-asymptotic regime. The size of this state space is hence a crucial
parameter for such analyses. In this paper, we introduce a general methodology
to construct corresponding state spaces and demonstrate that it applies to a
wide range of algorithms, including Boyer-Moore (BM), Boyer-Moore-Horspool
(BMH), Backward Oracle Matching (BOM), and Backward (Non-Deterministic) DAWG
Matching (B(N)DM). In all cases except BOM, our method leads to state spaces of
size $O(m^3)$ for pattern length $m$, a result that has previously only been
obtained for BMH. In all other cases, only state spaces with size exponential
in $m$ had been reported. Our results immediately imply an algorithm to compute
the distribution of $X^{\mathcal{A},S}_n$ for fixed $S$, fixed $n$, and
$\mathcal{A}\in\{\text{BM},\text{BMH},\text{B(N)DM}\}$ in polynomial time for a
very general class of random text models.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00139</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TensiStrength: Stress and relaxation magnitude detection for social
  media texts</dc:title>
 <dc:creator>Thelwall, Mike</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Computer systems need to be able to react to stress in order to perform
optimally on some tasks. This article describes TensiStrength, a system to
detect the strength of stress and relaxation expressed in social media text
messages. TensiStrength uses a lexical approach and a set of rules to detect
direct and indirect expressions of stress or relaxation, particularly in the
context of transportation. It is slightly more effective than a comparable
sentiment analysis program, although their similar performances occur despite
differences on almost half of the tweets gathered. The effectiveness of
TensiStrength depends on the nature of the tweets classified, with tweets that
are rich in stress-related terms being particularly problematic. Although
generic machine learning methods can give better performance than TensiStrength
overall, they exploit topic-related terms in a way that may be undesirable in
practical applications and that may not work as well in more focused contexts.
In conclusion, TensiStrength and generic machine learning approaches work well
enough to be practical choices for intelligent applications that need to take
advantage of stress information, and the decision about which to use depends on
the nature of the texts analysed and the purpose of the task.
</dc:description>
 <dc:description>Comment: Thelwall, M. (in press). TensiStrength: Stress and relaxation
  magnitude detection for social media texts. Information Processing &amp;
  Management</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00139</dc:identifier>
 <dc:identifier>doi:10.1016/j.ipm.2016.06.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00141</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fully Abstract Semantics for Value-passing CCS for Trees</dc:title>
 <dc:creator>Liu, Shichao</dc:creator>
 <dc:creator>Ehrhard, Thomas</dc:creator>
 <dc:creator>Jiang, Ying</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper provides a fully abstract semantics for value-passing CCS for
trees (VCCTS). The operational semantics is given both in terms of a reduction
semantics and in terms of a labelled transition semantics. The labelled
transition semantics is non-sequential, allowing more than one action occurring
simultaneously. We develop the theory of behavioral equivalence by introducing
both weak barbed congruence and weak bisimilarity. In particular, we show that
weak barbed congruence coincides with weak bisimilarity on image-finite
processes. This is the first such result for a concurrent model with tree
structures. Distributed systems can be naturally modeled by means of this
graph-based system, and some examples are given to illustrate this.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1512.00550</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00145</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of a high-performance GEMM-like Tensor-Tensor Multiplication</dc:title>
 <dc:creator>Springer, Paul</dc:creator>
 <dc:creator>Bientinesi, Paolo</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>I.1.3</dc:subject>
 <dc:description>  We present &quot;GEMM-like Tensor-Tensor multiplication&quot; (GETT), a novel approach
to tensor contractions that mirrors the design of a high-performance general
matrix-matrix multiplication (GEMM). The critical insight behind GETT is the
identification of three index sets, involved in the tensor contraction, which
enable us to systematically reduce an arbitrary tensor contraction to loops
around a highly tuned &quot;macro-kernel&quot;. This macro-kernel operates on suitably
prepared (&quot;packed&quot;) sub-tensors that reside in a specified level of the cache
hierarchy. In contrast to previous approaches to tensor contractions, GETT
exhibits desirable features such as unit-stride memory accesses,
cache-awareness, as well as full vectorization, without requiring auxiliary
memory. To compare our technique with other modern tensor contractions, we
integrate GETT alongside the so called Transpose-Transpose-GEMM-Transpose and
Loops-over-GEMM approaches into an open source &quot;Tensor Contraction Code
Generator&quot; (TCCG). The performance results for a wide range of tensor
contractions suggest that GETT has the potential of becoming the method of
choice: While GETT exhibits excellent performance across the board, its
effectiveness for bandwidth-bound tensor contractions is especially impressive,
outperforming existing approaches by up to $12.4\times$. More precisely, GETT
achieves speedups of up to $1.41\times$ over an equivalent-sized GEMM for
bandwidth-bound tensor contractions while attaining up to $91.3\%$ of peak
floating-point performance for compute-bound tensor contractions.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00146</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient and Consistent Robust Time Series Analysis</dc:title>
 <dc:creator>Bhatia, Kush</dc:creator>
 <dc:creator>Jain, Prateek</dc:creator>
 <dc:creator>Kamalaruban, Parameswaran</dc:creator>
 <dc:creator>Kar, Purushottam</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of robust time series analysis under the standard
auto-regressive (AR) time series model in the presence of arbitrary outliers.
We devise an efficient hard thresholding based algorithm which can obtain a
consistent estimate of the optimal AR model despite a large fraction of the
time series points being corrupted. Our algorithm alternately estimates the
corrupted set of points and the model parameters, and is inspired by recent
advances in robust regression and hard-thresholding methods. However, a direct
application of existing techniques is hindered by a critical difference in the
time-series domain: each point is correlated with all previous points rendering
existing tools inapplicable directly. We show how to overcome this hurdle using
novel proof techniques. Using our techniques, we are also able to provide the
first efficient and provably consistent estimator for the robust regression
problem where a standard linear observation model with white additive noise is
corrupted arbitrarily. We illustrate our methods on synthetic datasets and show
that our methods indeed are able to consistently recover the optimal parameters
despite a large fraction of points being corrupted.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00148</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection</dc:title>
 <dc:creator>Malhotra, Pankaj</dc:creator>
 <dc:creator>Ramakrishnan, Anusha</dc:creator>
 <dc:creator>Anand, Gaurangi</dc:creator>
 <dc:creator>Vig, Lovekesh</dc:creator>
 <dc:creator>Agarwal, Puneet</dc:creator>
 <dc:creator>Shroff, Gautam</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Mechanical devices such as engines, vehicles, aircrafts, etc., are typically
instrumented with numerous sensors to capture the behavior and health of the
machine. However, there are often external factors or variables which are not
captured by sensors leading to time-series which are inherently unpredictable.
For instance, manual controls and/or unmonitored environmental conditions or
load may lead to inherently unpredictable time-series. Detecting anomalies in
such scenarios becomes challenging using standard approaches based on
mathematical models that rely on stationarity, or prediction models that
utilize prediction errors to detect anomalies. We propose a Long Short Term
Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD)
that learns to reconstruct 'normal' time-series behavior, and thereafter uses
reconstruction error to detect anomalies. We experiment with three publicly
available quasi predictable time-series datasets: power demand, space shuttle,
and ECG, and two real-world engine datasets with both predictive and
unpredictable behavior. We show that EncDec-AD is robust and can detect
anomalies from predictable, unpredictable, periodic, aperiodic, and
quasi-periodic time-series. Further, we show that EncDec-AD is able to detect
anomalies from short time-series (length as small as 30) as well as long
time-series (length as large as 500).
</dc:description>
 <dc:description>Comment: Accepted at ICML 2016 Anomaly Detection Workshop, New York, NY, USA,
  2016. Reference update in this version (v2)</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00150</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Control of Energy Storage Systems for Electric Vehicles Fast
  Charging in Service Areas</dc:title>
 <dc:creator>Di Giorgio, Alessandro</dc:creator>
 <dc:creator>Liberati, Francesco</dc:creator>
 <dc:creator>German&#xe0;, Roberto</dc:creator>
 <dc:creator>Presciuttini, Marco</dc:creator>
 <dc:creator>Celsi, Lorenzo Ricciardi</dc:creator>
 <dc:creator>Priscoli, Francesco Delli</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a real time control strategy for energy storage systems
integration in electric vehicles fast charging applications combined with
generation from intermittent renewable energy sources. A two steps approach
taking advantage of the model predictive control methodology is designed on
purpose to optimally allocate the reference charging power while managing the
priority among the plugged vehicles and then control the storage for
efficiently sustaining the charging process. Two different use cases are
considered: in the former the charging area is disconnected from the grid, so
that the objective is to minimize the deviation of electric vehicles charging
power from the nominal value; in the latter the focus is on the point of
connection to the grid and the need of mitigating the related power flow. In
both cases the fundamental requirement for feasible control system operation is
to guarantee stability of the storage's state of charge over the time.
Simulation results are provided and discussed in detail, showing the
effectiveness of the proposed approach.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00167</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SentiBubbles: Topic Modeling and Sentiment Visualization of
  Entity-centric Tweets</dc:title>
 <dc:creator>Oliveira, Jo&#xe3;o</dc:creator>
 <dc:creator>Pinto, Mike</dc:creator>
 <dc:creator>Saleiro, Pedro</dc:creator>
 <dc:creator>Teixeira, Jorge</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Social Media users tend to mention entities when reacting to news events. The
main purpose of this work is to create entity-centric aggregations of tweets on
a daily basis. By applying topic modeling and sentiment analysis, we create
data visualization insights about current events and people reactions to those
events from an entity-centric perspective.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00174</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Blockchain for Peer-to-Peer Proof-of-Location</dc:title>
 <dc:creator>Brambilla, Giacomo</dc:creator>
 <dc:creator>Amoretti, Michele</dc:creator>
 <dc:creator>Zanichelli, Francesco</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  Location-Based Services (LBSs) build upon geographic information to provide
users with location-dependent functionalities. In such a context, it is
particularly important that geographic locations claimed by users are the
actual ones. Centralized verification approaches proposed in the last few years
are not satisfactory, as they entail a high risk to the privacy of users. In
this paper, we present and evaluate a novel decentralized,
infrastructure-independent proof-of-location scheme based on the blockchain
technology. Our scheme guarantees both location trustworthiness and user
privacy preservation.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00178</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MPI Derived Datatypes: Performance Expectations and Status Quo</dc:title>
 <dc:creator>Carpen-Amarie, Alexandra</dc:creator>
 <dc:creator>Hunold, Sascha</dc:creator>
 <dc:creator>Tr&#xe4;ff, Jesper Larsson</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We examine natural expectations on communication performance using MPI
derived datatypes in comparison to the baseline, &quot;raw&quot; performance of
communicating simple, non-contiguous data layouts. We show that common MPI
libraries sometimes violate these datatype performance expectations, and
discuss reasons why this happens, but also show cases where MPI libraries
perform well. Our findings are in many ways surprising and disappointing.
First, the performance of derived datatypes is sometimes worse than the
semantically equivalent packing and unpacking using the corresponding MPI
functionality. Second, the communication performance equivalence stated in the
MPI standard between a single contiguous datatype and the repetition of its
constituent datatype does not hold universally. Third, the heuristics that are
typically employed by MPI libraries at type-commit time are insufficient to
enforce natural performance guidelines, and better type normalization
heuristics may have a significant performance impact. We show cases where all
the MPI type constructors are necessary to achieve the expected performance for
certain data layouts. We describe our benchmarking approach to verify the
datatype performance guidelines, and present extensive verification results for
different MPI libraries.
</dc:description>
 <dc:description>Comment: 46 pages, 107 figures</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00185</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Simplification for Secure AF Relaying</dc:title>
 <dc:creator>Agrawal, Tulika</dc:creator>
 <dc:creator>Agnihotri, Samar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a class of Gaussian layered networks where a source communicates
with a destination through L intermediate relay layers with N nodes in each
layer in the presence of a single eavesdropper which can overhear the
transmissions of the nodes in the last layer. For such networks we address the
question: what fraction of maximum secure achievable rate can be maintained if
only a fraction of available relay nodes are used in each layer? In particular,
we provide upper bounds on additive and multiplicative gaps between the optimal
secure AF when all N relays in each layer are used and when only k, 1 &lt;= k &lt; N,
relays are used in each layer. We show that asymptotically (in source power),
the additive gap increases at most logarithmically with ratio N/k and L, and
the corresponding multiplicative gap increases at most quadratically with ratio
N/k and L. To the best of our knowledge, this work offers the first
characterization of the performance of network simplification in layered
amplify-and-forward relay networks in the presence of an eavesdropper.
</dc:description>
 <dc:description>Comment: 14 pages, 1 figure. arXiv admin note: text overlap with
  arXiv:1204.2150</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00186</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throwing fuel on the embers: Probability or Dichotomy, Cognitive or
  Linguistic?</dc:title>
 <dc:creator>Powers, David M. W.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Prof. Robert Berwick's abstract for his forthcoming invited talk at the
ACL2016 workshop on Cognitive Aspects of Computational Language Learning
revives an ancient debate. Entitled &quot;Why take a chance?&quot;, Berwick seems to
refer implicitly to Chomsky's critique of the statistical approach of Harris as
well as the currently dominant paradigms in CoNLL.
  Berwick avoids Chomsky's use of &quot;innate&quot; but states that &quot;the debate over the
existence of sophisticated mental grammars was settled with Chomsky's Logical
Structure of Linguistic Theory (1957/1975)&quot;, acknowledging that &quot;this debate
has often been revived&quot;.
  This paper agrees with the view that this debate has long since been settled,
but with the opposite outcome! Given the embers have not yet died away, and the
questions remain fundamental, perhaps it is appropriate to refuel the debate,
so I would like to join Bob in throwing fuel on this fire by reviewing the
evidence against the Chomskian position!
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00198</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sharing Network Parameters for Crosslingual Named Entity Recognition</dc:title>
 <dc:creator>Murthy V, Rudra</dc:creator>
 <dc:creator>Khapra, Mitesh</dc:creator>
 <dc:creator>Bhattacharyya, Pushpak</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Most state of the art approaches for Named Entity Recognition rely on hand
crafted features and annotated corpora. Recently Neural network based models
have been proposed which do not require handcrafted features but still require
annotated corpora. However, such annotated corpora may not be available for
many languages. In this paper, we propose a neural network based model which
allows sharing the decoder as well as word and character level parameters
between two languages thereby allowing a resource fortunate language to aid a
resource deprived language. Specifically, we focus on the case when limited
annotated corpora is available in one language ($L_1$) and abundant annotated
corpora is available in another language ($L_2$). Sharing the network
architecture and parameters between $L_1$ and $L_2$ leads to improved
performance in $L_1$. Further, our approach does not require any hand crafted
features but instead directly learns meaningful feature representations from
the training data itself. We experiment with 4 language pairs and show that
indeed in a resource constrained setup (lesser annotated corpora), a model
jointly trained with data from another language performs better than a model
trained only on the limited corpora in one language.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00208</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimal Algorithm for Range Search on Multidimensional Points</dc:title>
 <dc:creator>Hema, T.</dc:creator>
 <dc:creator>Easwarakumar, K. S.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  This paper proposes an efficient and novel method to address range search on
multidimensional points in $\theta(t)$ time, where $t$ is the number of points
reported in $\Re^k$ space. This is accomplished by introducing a new data
structure, called BITS $k$d-tree. This structure also supports fast updation
that takes $\theta(1)$ time for insertion and $O(\log n)$ time for deletion.
The earlier best known algorithm for this problem is $O(\log^k n+t)$ time in
the pointer machine model.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00208</dc:identifier>
 <dc:identifier>Asian Journal of Information Technology, 15:11,1723-1730, 2016</dc:identifier>
 <dc:identifier>doi:10.3923/ajit.2016.1723.1730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00211</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spherical Harmonic Signal Covariance and Sound Field Diffuseness</dc:title>
 <dc:creator>Epain, Nicolas</dc:creator>
 <dc:creator>Jin, Craig T.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Characterizing sound field diffuseness has many practical applications, from
room acoustics analysis to speech enhancement and sound field reproduction. In
this paper we investigate how spherical microphone arrays (SMAs) can be used to
characterize diffuseness. Due to their specific geometry, SMAs are particularly
well suited for analyzing the spatial properties of sound fields. In
particular, the signals recorded by an SMA can be analyzed in the spherical
harmonic (SH) domain, which has special and desirable mathematical properties
when it comes to analyzing diffuse sound fields. We present a new measure of
diffuseness, the COMEDIE diffuseness estimate, which is based on the analysis
of the SH signal covariance matrix. This algorithm is suited for the estimation
of diffuseness arising either from the presence of multiple sources distributed
around the SMA or from the presence of a diffuse noise background. As well, we
introduce the concept of a diffuseness profile, which consists in measuring the
diffuseness for several SH orders simultaneously. Experimental results indicate
that diffuseness profiles better describe the properties of the sound field
than a single diffuseness measurement.
</dc:description>
 <dc:description>Comment: Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00215</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why is Posterior Sampling Better than Optimism for Reinforcement
  Learning?</dc:title>
 <dc:creator>Osband, Ian</dc:creator>
 <dc:creator>Van Roy, Benjamin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Computational results demonstrate that posterior sampling for reinforcement
learning (PSRL) dramatically outperforms algorithms driven by optimism, such as
UCRL2. We provide insight into the extent of this performance boost and the
phenomenon that drives it. We leverage this insight to establish an
$\tilde{O}(H\sqrt{SAT})$ Bayesian expected regret bound for PSRL in
finite-horizon episodic Markov decision processes, where $H$ is the horizon,
$S$ is the number of states, $A$ is the number of actions and $T$ is the time
elapsed. This improves upon the best previous bound of $\tilde{O}(H S
\sqrt{AT})$ for any reinforcement learning algorithm.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00223</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory Based Collaborative Filtering with Lucene</dc:title>
 <dc:creator>Gennaro, Claudio</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:description>  Memory Based Collaborative Filtering is a widely used approach to provide
recommendations. It exploits similarities between ratings across a population
of users by forming a weighted vote to predict unobserved ratings. Bespoke
solutions are frequently adopted to deal with the problem of high quality
recommendations on large data sets. A disadvantage of this approach, however,
is the loss of generality and flexibility of the general collaborative
filtering systems. In this paper, we have developed a methodology that allows
one to build a scalable and effective collaborative filtering system on top of
a conventional full-text search engine such as Apache Lucene.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00225</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Unsupervised Dutch Word Embeddings as a Linguistic Resource</dc:title>
 <dc:creator>Tulkens, St&#xe9;phan</dc:creator>
 <dc:creator>Emmery, Chris</dc:creator>
 <dc:creator>Daelemans, Walter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word embeddings have recently seen a strong increase in interest as a result
of strong performance gains on a variety of tasks. However, most of this
research also underlined the importance of benchmark datasets, and the
difficulty of constructing these for a variety of language-specific tasks.
Still, many of the datasets used in these tasks could prove to be fruitful
linguistic resources, allowing for unique observations into language use and
variability. In this paper we demonstrate the performance of multiple types of
embeddings, created with both count and prediction-based architectures on a
variety of corpora, in two language-specific tasks: relation evaluation, and
dialect identification. For the latter, we compare unsupervised methods with a
traditional, hand-crafted dictionary. With this research, we provide the
embeddings themselves, the relation evaluation task benchmark for use in
further research, and demonstrate how the benchmarked embeddings prove a useful
unsupervised linguistic resource, effectively used in a downstream task.
</dc:description>
 <dc:description>Comment: in LREC 2016</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00226</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Millimeter-Wave Human Blockage at 73 GHz with a Simple Double Knife-Edge
  Diffraction Model and Extension for Directional Antennas</dc:title>
 <dc:creator>MacCartney Jr., George R.</dc:creator>
 <dc:creator>Deng, Sijia</dc:creator>
 <dc:creator>Sun, Shu</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents 73 GHz human blockage measurements for a point-to-point
link with a 5 m transmitter-receiver separation distance in an indoor
environment, with a human that walked at a speed of approximately 1 m/s at a
perpendicular orientation to the line between the transmitter and receiver, at
various distances between them. The experiment measures the shadowing effect of
a moving human body when using directional antennas at the transmitter and
receiver for millimeter-wave radio communications. The measurements were
conducted using a 500 Megachips-per-second wideband correlator channel sounder
with a 1 GHz first null-to-null RF bandwidth. Results indicate high shadowing
attenuation is not just due to the human blocker but also is due to the static
directional nature of the antennas used, leading to the need for phased-array
antennas to switch beam directions in the presence of obstructions and
blockages at millimeter-waves. A simple model for human blockage is provided
based on the double knife-edge diffraction (DKED) model where humans are
approximated by a rectangular screen with infinite vertical height, similar to
the human blockage model given by the METIS project.
</dc:description>
 <dc:description>Comment: To be published in 2016 IEEE 84th Vehicular Technology Conference
  (VTC2016-Fall), Montreal, Canada, Sept. 2016</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00234</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neutrosophic Overset, Neutrosophic Underset, and Neutrosophic Offset.
  Similarly for Neutrosophic Over-/Under-/Off- Logic, Probability, and
  Statistics</dc:title>
 <dc:creator>Smarandache, Florentin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>94D05</dc:subject>
 <dc:description>  Neutrosophic Over-/Under-/Off-Set and -Logic were defined by the author in
1995 and published for the first time in 2007. We extended the neutrosophic set
respectively to Neutrosophic Overset {when some neutrosophic component is over
1}, Neutrosophic Underset {when some neutrosophic component is below 0}, and to
Neutrosophic Offset {when some neutrosophic components are off the interval [0,
1], i.e. some neutrosophic component over 1 and other neutrosophic component
below 0}. This is no surprise with respect to the classical fuzzy set/logic,
intuitionistic fuzzy set/logic, or classical/imprecise probability, where the
values are not allowed outside the interval [0, 1], since our real-world has
numerous examples and applications of over-/under-/off-neutrosophic components.
For example, person working overtime deserves a membership degree over 1, while
a person producing more damage than benefit to a company deserves a membership
below 0. Then, similarly, the Neutrosophic Logic/Measure/Probability/Statistics
etc. were extended to respectively Neutrosophic Over-/Under-/Off-Logic,
-Measure, -Probability, -Statistics etc. [Smarandache, 2007].
</dc:description>
 <dc:description>Comment: 170 pages</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00234</dc:identifier>
 <dc:identifier>Pons Editions, Bruxelles, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00235</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PIR Array Codes with Optimal PIR Rate</dc:title>
 <dc:creator>Blackburn, Simon</dc:creator>
 <dc:creator>Etzion, Tuvi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  There has been much recent interest in Private information Retrieval (PIR) in
models where a database is stored across several servers using coding
techniques from distributed storage, rather than being simply replicated. In
particular, a recent breakthrough result of Fazelli, Vardy and Yaakobi
introduces the notion of a PIR code and a PIR array code, and uses this notion
to produce efficient protocols.
  In this paper we are interested in designing PIR array codes. We consider the
case when we have $m$ servers, with each server storing a fraction $(1/s)$ of
the bits of the database; here $s$ is a fixed rational number with $s &gt; 1$. We
study the maximum PIR rate of a PIR array code with the $k$-PIR property (which
enables a $k$-server PIR protocol to be emulated on the $m$ servers), where the
PIR rate is defined to be $k/m$. We present upper bounds on the achievable
rate, some constructions, and ideas how to obtain PIR array codes with the
highest possible PIR rate. In particular, we present constructions that
asymptotically meet our upper bounds, and the exact largest PIR rate is
obtained when $1 &lt; s \leq 2$.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00242</identifier>
 <datestamp>2017-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A linear lower bound for incrementing a space-optimal integer
  representation in the bit-probe model</dc:title>
 <dc:creator>Raskin, M.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We present the first linear lower bound for the number of bits required to be
accessed in the worst case to increment an integer in an arbitrary space-
optimal binary representation. The best previously known lower bound was
logarithmic. It is known that a logarithmic number of read bits in the worst
case is enough to increment some of the integer representations that use one
bit of redundancy, therefore we show an exponential gap between space-optimal
and redundant counters.
  Our proof is based on considering the increment procedure for a space optimal
counter as a permutation and calculating its parity. For every space optimal
counter, the permutation must be odd, and implementing an odd permutation
requires reading at least half the bits in the worst case. The combination of
these two observations explains why the worst-case space-optimal problem is
substantially different from both average-case approach with constant expected
number of reads and almost space optimal representations with logarithmic
number of reads in the worst case.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00249</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Nonconvex Multiagent Optimization Over Time-Varying Networks</dc:title>
 <dc:creator>Sun, Ying</dc:creator>
 <dc:creator>Scutari, Gesualdo</dc:creator>
 <dc:creator>Palomar, Daniel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study nonconvex distributed optimization in multiagent networks where the
communications between nodes is modeled as a time-varying sequence of arbitrary
digraphs. We introduce a novel broadcast-based distributed algorithmic
framework for the (constrained) minimization of the sum of a smooth (possibly
nonconvex and nonseparable) function, i.e., the agents' sum-utility, plus a
convex (possibly nonsmooth and nonseparable) regularizer. The latter is usually
employed to enforce some structure in the solution, typically sparsity. The
proposed method hinges on Successive Convex Approximation (SCA) techniques
coupled with i) a tracking mechanism instrumental to locally estimate the
gradients of agents' cost functions; and ii) a novel broadcast protocol to
disseminate information and distribute the computation among the agents.
Asymptotic convergence to stationary solutions is established. A key feature of
the proposed algorithm is that it neither requires the double-stochasticity of
the consensus matrices (but only column stochasticity) nor the knowledge of the
graph sequence to implement. To the best of our knowledge, the proposed
framework is the first broadcast-based distributed algorithm for convex and
nonconvex constrained optimization over arbitrary, time-varying digraphs.
Numerical results show that our algorithm outperforms current schemes on both
convex and nonconvex problems.
</dc:description>
 <dc:description>Comment: Copyright 2001 SS&amp;C. Published in the Proceedings of the 50th annual
  Asilomar conference on signals, systems, and computers, Nov. 6-9, 2016, CA,
  USA</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00259</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower Bounds for Alternating Online State Complexity</dc:title>
 <dc:creator>Fijalkow, Nathana&#xeb;l</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The notion of Online State Complexity, introduced by Karp in 1967, quantifies
the amount of states required to solve a given problem using an online
algorithm, which is represented by a deterministic machine scanning the input
from left to right in one pass. In this paper, we extend the setting to
alternating machines as introduced by Chandra, Kozen and Stockmeyer in 1976:
such machines run independent passes scanning the input from left to right and
gather their answers through boolean combinations. We devise a lower bound
technique relying on boundedly generated lattices of languages, and give two
applications of this technique. The first is a hierarchy theorem , stating that
the polynomial hierarchy of alternating online state complexity is infinite,
and the second is a linear lower bound on the alternating online state
complexity of the prime numbers written in binary. This second result
strengthens a result of Hartmanis and Shank from 1968, which implies an
exponentially worse lower bound for the same model.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00266</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Art of DNA Strings: Sixteen Years of DNA Coding Theory</dc:title>
 <dc:creator>Limbachiya, Dixita</dc:creator>
 <dc:creator>Rao, Bansari</dc:creator>
 <dc:creator>Gupta, Manish K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The idea of computing with DNA was given by Tom Head in 1987, however in 1994
in a seminal paper, the actual successful experiment for DNA computing was
performed by Adleman. The heart of the DNA computing is the DNA hybridization,
however, it is also the source of errors. Thus the success of the DNA computing
depends on the error control techniques. The classical coding theory techniques
have provided foundation for the current information and communication
technology (ICT). Thus it is natural to expect that coding theory will be the
foundational subject for the DNA computing paradigm. For the successful
experiments with DNA computing usually we design DNA strings which are
sufficiently dissimilar. This leads to the construction of a large set of DNA
strings which satisfy certain combinatorial and thermodynamic constraints. Over
the last 16 years, many approaches such as combinatorial, algebraic,
computational have been used to construct such DNA strings. In this work, we
survey this interesting area of DNA coding theory by providing key ideas of the
area and current known results.
</dc:description>
 <dc:description>Comment: 19 pages, 4 figures, draft review on DNA codes</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00267</identifier>
 <datestamp>2016-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated 5-year Mortality Prediction using Deep Learning and Radiomics
  Features from Chest Computed Tomography</dc:title>
 <dc:creator>Carneiro, Gustavo</dc:creator>
 <dc:creator>Oakden-Rayner, Luke</dc:creator>
 <dc:creator>Bradley, Andrew P.</dc:creator>
 <dc:creator>Nascimento, Jacinto</dc:creator>
 <dc:creator>Palmer, Lyle</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose new methods for the prediction of 5-year mortality in elderly
individuals using chest computed tomography (CT). The methods consist of a
classifier that performs this prediction using a set of features extracted from
the CT image and segmentation maps of multiple anatomic structures. We explore
two approaches: 1) a unified framework based on deep learning, where features
and classifier are automatically learned in a single optimisation process; and
2) a multi-stage framework based on the design and selection/extraction of
hand-crafted radiomics features, followed by the classifier learning process.
Experimental results, based on a dataset of 48 annotated chest CTs, show that
the deep learning model produces a mean 5-year mortality prediction accuracy of
68.5%, while radiomics produces a mean accuracy that varies between 56% to 66%
(depending on the feature selection/extraction method and classifier). The
successful development of the proposed models has the potential to make a
profound impact in preventive and personalised healthcare.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00269</identifier>
 <datestamp>2017-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does Your DNS Recursion Really Time Out as Intended? A Timeout
  Vulnerability of DNS Recursive Servers</dc:title>
 <dc:creator>Wang, Zheng</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Parallelization is featured by DNS recursive servers to do time-consuming
recursions on behalf on clients. As common DNS configurations, recursive
servers should allow a reasonable timeout for each recursion which may take as
long as several seconds. However, it is proposed in this paper that recursion
parallelization may be exploited by attackers to compromise the recursion
timeout mechanism for the purpose of DoS or DDoS attacks. Attackers can have
recursive servers drop early existing recursions in service by saturating
recursion parallelization. The key of the proposed attack model is to reliably
prolong service times for any attacking queries. As means of prolong service
times, serval techniques are proposed to effectively avoiding cache hit and
prolonging overall latency of external DNS lookups respectively. The impacts of
saturated recursion parallelization on timeout are analytically provided. The
testing on BIND servers demonstrates that with carefully crafted queries, an
attacker can use a low or moderate level of query load to successfully
overwhelm a target recursive server from serving the legitimate clients.
</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-02-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00273</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noise Models in Feature-based Stereo Visual Odometry</dc:title>
 <dc:creator>Alcantarilla, Pablo F.</dc:creator>
 <dc:creator>Woodford, Oliver J.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Feature-based visual structure and motion reconstruction pipelines, common in
visual odometry and large-scale reconstruction from photos, use the location of
corresponding features in different images to determine the 3D structure of the
scene, as well as the camera parameters associated with each image. The noise
model, which defines the likelihood of the location of each feature in each
image, is a key factor in the accuracy of such pipelines, alongside
optimization strategy. Many different noise models have been proposed in the
literature; in this paper we investigate the performance of several. We
evaluate these models specifically w.r.t. stereo visual odometry, as this task
is both simple (camera intrinsics are constant and known; geometry can be
initialized reliably) and has datasets with ground truth readily available
(KITTI Odometry and New Tsukuba Stereo Dataset). Our evaluation shows that
noise models which are more adaptable to the varying nature of noise generally
perform better.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00278</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Obstructing Visibilities with One Obstacle</dc:title>
 <dc:creator>Chaplick, Steven</dc:creator>
 <dc:creator>Lipp, Fabian</dc:creator>
 <dc:creator>Park, Ji-won</dc:creator>
 <dc:creator>Wolff, Alexander</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Obstacle representations of graphs have been investigated quite intensely
over the last few years. We focus on graphs that can be represented by a single
obstacle. Given a (topologically open) polygon $C$ and a finite set $P$ of
points in general position in the complement of $C$, the visibility graph
$G_C(P)$ has a vertex for each point in $P$ and an edge $pq$ for any two points
$p$ and $q$ in $P$ that can see each other, that is, $\overline{pq} \cap
C=\emptyset$. We draw $G_C(P)$ straight-line. Given a graph $G$, we want to
compute an obstacle representation of $G$, that is, an obstacle $C$ and a set
of points $P$ such that $G=G_C(P)$. The complexity of this problem is open,
even for the case that the points are exactly the vertices of a simple polygon
and the obstacle is the complement of the polygon-the simple-polygon visibility
graph problem. There are two types of obstacles; an inside obstacle lies in a
bounded component of the complement of the visibility drawing, whereas an
outside obstacle lies in the unbounded component.
  We show that the class of graphs with an inside-obstacle representation is
incomparable with the class of graphs that have an outside-obstacle
representation. We further show that any graph with at most seven vertices or
circumference at most 6 has an outside-obstacle representation, which does not
hold for a specific graph with 8 vertices and circumference 8. Finally, we
consider the outside-obstacle graph sandwich problem: given graphs $G$ and $H$
on the same vertex set, is there a graph $K$ such that $G \subseteq K \subseteq
H$ and $K$ has an outside-obstacle representation? We show that this problem is
NP-hard even for co-bipartite graphs. With slight modifications, our proof also
shows that the inside-obstacle graph sandwich problem, the single-obstacle
graph sandwich problem, and the simple-polygon visibility graph sandwich
problem are all NP-hard.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00279</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meaningful Models: Utilizing Conceptual Structure to Improve Machine
  Learning Interpretability</dc:title>
 <dc:creator>Condry, Nick</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The last decade has seen huge progress in the development of advanced machine
learning models; however, those models are powerless unless human users can
interpret them. Here we show how the mind's construction of concepts and
meaning can be used to create more interpretable machine learning models. By
proposing a novel method of classifying concepts, in terms of 'form' and
'function', we elucidate the nature of meaning and offer proposals to improve
model understandability. As machine learning begins to permeate daily life,
interpretable models may serve as a bridge between domain-expert authors and
non-expert users.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, presented at 2016 ICML Workshop on Human
  Interpretability in Machine Learning (WHI 2016), New York, NY</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00291</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Performance Tensor Contraction without Transposition</dc:title>
 <dc:creator>Matthews, Devin A.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>15A69</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  Tensor computations--in particular tensor contraction (TC)--are important
kernels in many scientific computing applications. Due to the fundamental
similarity of TC to matrix multiplication (MM) and to the availability of
optimized implementations such as the BLAS, tensor operations have
traditionally been implemented in terms of BLAS operations, incurring both a
performance and a storage overhead. Instead, we implement TC using the flexible
BLIS framework, which allows for transposition (reshaping) of the tensor to be
fused with internal partitioning and packing operations, requiring no explicit
transposition operations or additional workspace. This implementation, TBLIS,
achieves performance approaching that of MM, and in some cases considerably
higher than that of traditional TC. Our implementation supports multithreading
using an approach identical to that used for MM in BLIS, with similar
performance characteristics. The complexity of managing tensor-to-matrix
transformations is also handled automatically in our approach, greatly
simplifying its use in scientific applications.
</dc:description>
 <dc:description>Comment: 24 pages, 8 figures, uses pgfplots</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00298</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CLEX: Yet Another Supercomputer Architecture?</dc:title>
 <dc:creator>Lenzen, Christoph</dc:creator>
 <dc:creator>Wattenhofer, Roger</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We propose the CLEX supercomputer topology and routing scheme. We prove that
CLEX can utilize a constant fraction of the total bandwidth for point-to-point
communication, at delays proportional to the sum of the number of intermediate
hops and the maximum physical distance between any two nodes. Moreover, %
applying an asymmetric bandwidth assignment to the links, all-to-all
communication can be realized $(1+o(1))$-optimally both with regard to
bandwidth and delays. This is achieved at node degrees of $n^{\varepsilon}$,
for an arbitrary small constant $\varepsilon\in (0,1]$. In contrast, these
results are impossible in any network featuring constant or polylogarithmic
node degrees. Through simulation, we assess the benefits of an implementation
of the proposed communication strategy. Our results indicate that, for a
million processors, CLEX can increase bandwidth utilization and reduce average
routing path length by at least factors $10$ respectively $5$ in comparison to
a torus network. Furthermore, the CLEX communication scheme features several
other properties, such as deadlock-freedom, inherent fault-tolerance, and
canonical partition into smaller subsystems.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00307</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Tree Hash Modes: the Case of Trees Having their Leaves at All
  the Levels</dc:title>
 <dc:creator>Atighehchi, Kevin</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A recent work shows how we can optimize a tree based mode of operation for a
hash function where the sizes of input message blocks and digest are the same,
subject to the constraint that the involved tree structure has all its leaves
at the same depth. In this work, we show that we can further optimize the
running time of such a mode by using a tree having leaves at all its levels. We
make the assumption that the input message block has a size a multiple of that
of the digest and denote by $d$ the ratio block size over digest size. The
running time is evaluated in terms of number of operations performed by the
hash function, i.e. the number of calls to its underlying function. It turns
out that a digest can be computed in $\lceil \log_{d+1} (l/2) \rceil+2$
evaluations of the underlying function using $\lceil l/2 \rceil$ processors,
where $l$ is the number of blocks of the message. Other results of interest are
discussed, such as the optimization of the parallel running time for a tree of
restricted height.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00315</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multilevel framework for sparse optimization with application to
  inverse covariance estimation and logistic regression</dc:title>
 <dc:creator>Treister, Eran</dc:creator>
 <dc:creator>Turek, Javier S.</dc:creator>
 <dc:creator>Yavneh, Irad</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Solving l1 regularized optimization problems is common in the fields of
computational biology, signal processing and machine learning. Such l1
regularization is utilized to find sparse minimizers of convex functions. A
well-known example is the LASSO problem, where the l1 norm regularizes a
quadratic function. A multilevel framework is presented for solving such l1
regularized sparse optimization problems efficiently. We take advantage of the
expected sparseness of the solution, and create a hierarchy of problems of
similar type, which is traversed in order to accelerate the optimization
process. This framework is applied for solving two problems: (1) the sparse
inverse covariance estimation problem, and (2) l1-regularized logistic
regression. In the first problem, the inverse of an unknown covariance matrix
of a multivariate normal distribution is estimated, under the assumption that
it is sparse. To this end, an l1 regularized log-determinant optimization
problem needs to be solved. This task is challenging especially for large-scale
datasets, due to time and memory limitations. In the second problem, the
l1-regularization is added to the logistic regression classification objective
to reduce overfitting to the data and obtain a sparse model. Numerical
experiments demonstrate the efficiency of the multilevel framework in
accelerating existing iterative solvers for both of these problems.
</dc:description>
 <dc:description>Comment: To appear on SISC journal</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00318</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Evolution of Sex through the Baldwin Effect</dc:title>
 <dc:creator>Bull, Larry</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  This paper suggests that the fundamental haploid-diploid cycle of eukaryotic
sex exploits a rudimentary form of the Baldwin effect. With this explanation
for the basic cycle, the other associated phenomena can be explained as
evolution tuning the amount and frequency of learning experienced by an
organism. Using the well-known NK model of fitness landscapes it is shown that
varying landscape ruggedness varies the benefit of the haploid-diploid cycle,
whether based upon endomitosis or syngamy. The utility of pre-meiotic doubling
and recombination during the cycle are also shown to vary with landscape
ruggedness. This view is suggested as underpinning, rather than contradicting,
many existing explanations for sex.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00321</identifier>
 <datestamp>2016-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Definition of QoE Metrics</dc:title>
 <dc:creator>Hossfeld, Tobias</dc:creator>
 <dc:creator>Heegaard, Poul E.</dc:creator>
 <dc:creator>Varela, Martin</dc:creator>
 <dc:creator>M&#xf6;ller, Sebastian</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This technical report formally defines the QoE metrics which are introduced
and discussed in the article &quot;QoE Beyond the MOS: An In-Depth Look at QoE via
Better Metrics and their Relation to MOS&quot; by Tobias Ho{\ss}feld, Poul E.
Heegaard, Martin Varela, Sebastian M\&quot;oller, accepted for publication in the
Springer journal &quot;Quality and User Experience&quot;. Matlab scripts for computing
the QoE metrics for given data sets are available in GitHub.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00321</dc:identifier>
 <dc:identifier>Quality and User Experience (2016) 1: 2</dc:identifier>
 <dc:identifier>doi:10.1007/s41233-016-0002-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00325</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Permutation Invariant Training of Deep Models for Speaker-Independent
  Multi-talker Speech Separation</dc:title>
 <dc:creator>Yu, Dong</dc:creator>
 <dc:creator>Kolb&#xe6;k, Morten</dc:creator>
 <dc:creator>Tan, Zheng-Hua</dc:creator>
 <dc:creator>Jensen, Jesper</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We propose a novel deep learning model, which supports permutation invariant
training (PIT), for speaker independent multi-talker speech separation,
commonly known as the cocktail-party problem. Different from most of the prior
arts that treat speech separation as a multi-class regression problem and the
deep clustering technique that considers it a segmentation (or clustering)
problem, our model optimizes for the separation regression error, ignoring the
order of mixing sources. This strategy cleverly solves the long-lasting label
permutation problem that has prevented progress on deep learning based
techniques for speech separation. Experiments on the equal-energy mixing setup
of a Danish corpus confirms the effectiveness of PIT. We believe improvements
built upon PIT can eventually solve the cocktail-party problem and enable
real-world adoption of, e.g., automatic meeting transcription and multi-party
human-computer interaction, where overlapping speech is common.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00329</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proactive Location-Based Scheduling of Delay-Constrained Traffic Over
  Fading Channels</dc:title>
 <dc:creator>Girgis, Antonious M.</dc:creator>
 <dc:creator>El-Keyi, Amr</dc:creator>
 <dc:creator>Nafie, Mohammed</dc:creator>
 <dc:creator>Gohary, Ramy</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, proactive resource allocation based on user location for
point-to-point communication over fading channels is introduced, whereby the
source must transmit a packet when the user requests it within a deadline of a
single time slot. We introduce a prediction model in which the source predicts
the request arrival $T_p$ slots ahead, where $T_p$ denotes the prediction
window (PW) size. The source allocates energy to transmit some bits proactively
for each time slot of the PW with the objective of reducing the transmission
energy over the non-predictive case. The requests are predicted based on the
user location utilizing the prior statistics about the user requests at each
location. We also assume that the prediction is not perfect. We propose
proactive scheduling policies to minimize the expected energy consumption
required to transmit the requested packets under two different assumptions on
the channel state information at the source. In the first scenario, offline
scheduling, we assume the channel states are known a-priori at the source at
the beginning of the PW. In the second scenario, online scheduling, it is
assumed that the source has causal knowledge of the channel state. Numerical
results are presented showing the gains achieved by using proactive scheduling
policies compared with classical (reactive) networks. Simulation results also
show that increasing the PW size leads to a significant reduction in the
consumed transmission energy even with imperfect prediction.
</dc:description>
 <dc:description>Comment: Conference: VTC2016-Fall, At Montreal-Canada</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00331</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine-based Multimodal Pain Assessment Tool for Infants: A Review</dc:title>
 <dc:creator>Zamzmi, Ghada</dc:creator>
 <dc:creator>Pai, Chih-Yun</dc:creator>
 <dc:creator>Goldgof, Dmitry</dc:creator>
 <dc:creator>Kasturi, Rangachar</dc:creator>
 <dc:creator>Sun, Yu</dc:creator>
 <dc:creator>Ashmeade, Terri</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The current practice of assessing infants' pain depends on using subjective
tools that fail to meet rigorous psychometric standards and requires continuous
monitoring by health professionals. Therefore, pain may be misinterpreted or
totally missed leading to misdiagnosis and over/under treatment. To address
these shortcomings, the current practice can be augmented with a machine-based
assessment tool that continuously monitors various pain cues and provides a
consistent and minimally biased evaluation of pain. Several machine-based
approaches have been proposed to assess infants' pain based on analysis of
whether behavioral or physiological pain indictors (i.e., single modality). The
aim of this review paper is to provide the reader with the current
machine-based approaches in assessing infants' pain. It also proposes the
development of a multimodal machine-based pain assessment tool and presents
preliminary implementation results.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00345</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Rate of Frank-Wolfe for Non-Convex Objectives</dc:title>
 <dc:creator>Lacoste-Julien, Simon</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>90C52, 90C90, 68T05</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  We give a simple proof that the Frank-Wolfe algorithm obtains a stationary
point at a rate of $O(1/\sqrt{t})$ on non-convex objectives with a Lipschitz
continuous gradient. Our analysis is affine invariant and is the first, to the
best of our knowledge, giving a similar rate to what was already proven for
projected gradient methods (though on slightly different measures of
stationarity).
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00346</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed-memory Hierarchical Interpolative Factorization</dc:title>
 <dc:creator>Li, Yingzhou</dc:creator>
 <dc:creator>Ying, Lexing</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The hierarchical interpolative factorization (HIF) offers an efficient way
for solving or preconditioning elliptic partial differential equations. By
exploiting locality and low-rank properties of the operators, the HIF achieves
quasi-linear complexity for factorizing the discrete positive definite elliptic
operator and linear complexity for solving the associated linear system. In
this paper, the distributed-memory HIF (DHIF) is introduced as a parallel and
distributed-memory implementation of the HIF. The DHIF organizes the processes
in a hierarchical structure and keep the communication as local as possible.
The computation complexity is $O\left(\frac{N\log N}{P}\right)$ and
$O\left(\frac{N}{P}\right)$ for constructing and applying the DHIF,
respectively, where $N$ is the size of the problem and $P$ is the number of
processes. The communication complexity is $O\left(\sqrt{P}\log^3
P\right)\alpha + O\left(\frac{N^{2/3}}{\sqrt{P}}\right)\beta$ where $\alpha$ is
the latency and $\beta$ is the inverse bandwidth. Extensive numerical examples
are performed on the NERSC Edison system with up to 8192 processes. The
numerical results agree with the complexity analysis and demonstrate the
efficiency and scalability of the DHIF.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00346</dc:identifier>
 <dc:identifier>doi:10.1186/s40687-017-0100-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00354</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>STAM: A Framework for Spatio-Temporal Affordance Maps</dc:title>
 <dc:creator>Riccio, Francesco</dc:creator>
 <dc:creator>Capobianco, Roberto</dc:creator>
 <dc:creator>Hanheide, Marc</dc:creator>
 <dc:creator>Nardi, Daniele</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Affordances have been introduced in literature as action opportunities that
objects offer, and used in robotics to semantically represent their
interconnection. However, when considering an environment instead of an object,
the problem becomes more complex due to the dynamism of its state. To tackle
this issue, we introduce the concept of Spatio-Temporal Affordances (STA) and
Spatio-Temporal Affordance Map (STAM). Using this formalism, we encode action
semantics related to the environment to improve task execution capabilities of
an autonomous robot. We experimentally validate our approach to support the
execution of robot tasks by showing that affordances encode accurate semantics
of the environment.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00355</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on some inequalities used in channel polarization and polar
  coding</dc:title>
 <dc:creator>Jayram, T. S.</dc:creator>
 <dc:creator>Arikan, Erdal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We give a unified treatment of some inequalities that are used in the proofs
of channel polarization theorems involving a binary-input discrete memoryless
channel.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00356</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of Robust, Protograph Based LDPC Codes for Rate-Adaptation via
  Probabilistic Shaping</dc:title>
 <dc:creator>Steiner, Fabian</dc:creator>
 <dc:creator>Schulte, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, the design of robust, protograph-based low-density parity-check
(LDPC) codes for rate-adaptive communication via probabilistic shaping is
considered. Recently, probabilistic amplitude shaping (PAS) by B\&quot;ocherer et
al. has been introduced for capacity approaching and rate-adaptive
communication with a bitwise-demapper and binary decoder. Previous work by the
authors considered the optimization of protograph based LDPC codes for PAS and
specific spectral efficiencies (SEs) to jointly optimize the LDPC code node
degrees and the mapping of the coded bits to the bit-interleaved coded
modulation (BICM) bit-channels. We show that these codes tend to perform poor
when operated at other rates and propose the design of robust LDPC codes by
employing a min-max approach in the search for good protograph ensembles via
differential evolution. The considered design uses a single 16
amplitude-shift-keying (ASK) constellation and a robust 13/16 rate LDPC code to
operate between 0.7 to 2.7 bits per channel use. For a blocklength of 16224
bits and a target frame error rate of 1e-3 the proposed code operates within
1.32 dB of continuous AWGN capacity for 0.7 to 1.3 bpcu and within 1.05 dB for
1.3 bpcu to 2.7 bpcu.
</dc:description>
 <dc:description>Comment: Accepted for Publication in the Proceedings of 2016 9th International
  Symposium on Turbo Codes and Iterative Information Processing (ISTC), Invited
  paper for the special session on &quot;Recent Advances in Coding for Higher Order
  Modulation&quot;</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00359</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Moving Toward High Precision Dynamical Modelling in Hidden Markov Models</dc:title>
 <dc:creator>Gagnon, S&#xe9;bastien</dc:creator>
 <dc:creator>Rouat, Jean</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Hidden Markov Model (HMM) is often regarded as the dynamical model of choice
in many fields and applications. It is also at the heart of most
state-of-the-art speech recognition systems since the 70's. However, from
Gaussian mixture models HMMs (GMM-HMM) to deep neural network HMMs (DNN-HMM),
the underlying Markovian chain of state-of-the-art models did not changed much.
The &quot;left-to-right&quot; topology is mostly always employed because very few other
alternatives exist. In this paper, we propose that finely-tuned HMM topologies
are essential for precise temporal modelling and that this approach should be
investigated in state-of-the-art HMM system. As such, we propose a
proof-of-concept framework for learning efficient topologies by pruning down
complex generic models. Speech recognition experiments that were conducted
indicate that complex time dependencies can be better learned by this approach
than with classical &quot;left-to-right&quot; models.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00360</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A scaled Bregman theorem with applications</dc:title>
 <dc:creator>Nock, Richard</dc:creator>
 <dc:creator>Menon, Aditya Krishna</dc:creator>
 <dc:creator>Ong, Cheng Soon</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Bregman divergences play a central role in the design and analysis of a range
of machine learning algorithms. This paper explores the use of Bregman
divergences to establish reductions between such algorithms and their analyses.
We present a new scaled isodistortion theorem involving Bregman divergences
(scaled Bregman theorem for short) which shows that certain &quot;Bregman
distortions'&quot; (employing a potentially non-convex generator) may be exactly
re-written as a scaled Bregman divergence computed over transformed data.
Admissible distortions include geodesic distances on curved manifolds and
projections or gauge-normalisation, while admissible data include scalars,
vectors and matrices.
  Our theorem allows one to leverage to the wealth and convenience of Bregman
divergences when analysing algorithms relying on the aforementioned Bregman
distortions. We illustrate this with three novel applications of our theorem: a
reduction from multi-class density ratio to class-probability estimation, a new
adaptive projection free yet norm-enforcing dual norm mirror descent algorithm,
and a reduction from clustering on flat manifolds to clustering on curved
manifolds. Experiments on each of these domains validate the analyses and
suggest that the scaled Bregman theorem might be a worthy addition to the
popular handful of Bregman divergence properties that have been pervasive in
machine learning.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00372</identifier>
 <datestamp>2016-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Timeout Synthesis in Fixed-Delay CTMC Using Policy Iteration</dc:title>
 <dc:creator>Koren&#x10d;iak, &#x13d;ubo&#x161;</dc:creator>
 <dc:creator>Ku&#x10d;era, Anton&#xed;n</dc:creator>
 <dc:creator>&#x158;eh&#xe1;k, Vojt&#x11b;ch</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We consider the fixed-delay synthesis problem for continuous-time Markov
chains extended with fixed-delay transitions (fdCTMC). The goal is to
synthesize concrete values of the fixed-delays (timeouts) that minimize the
expected total cost incurred before reaching a given set of target states. The
same problem has been considered and solved in previous works by computing an
optimal policy in a certain discrete-time Markov decision process (MDP) with a
huge number of actions that correspond to suitably discretized values of the
timeouts.
  In this paper, we design a symbolic fixed-delay synthesis algorithm which
avoids the explicit construction of large action spaces. Instead, the algorithm
computes a small sets of &quot;promising&quot; candidate actions on demand. The candidate
actions are selected by minimizing a certain objective function by computing
its symbolic derivative and extracting a univariate polynomial whose roots are
precisely the points where the derivative takes zero value. Since roots of high
degree univariate polynomials can be isolated very efficiently using modern
mathematical software, we achieve not only drastic memory savings but also
speedup by three orders of magnitude compared to the previous methods.
</dc:description>
 <dc:description>Comment: This article is a full version of a paper published at Modeling,
  Analysis, and Simulation On Computer and Telecommunication Systems (MASCOTS)
  2016 conference</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00376</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Men Set Their Own Cites High: Gender and Self-citation across Fields and
  over Time</dc:title>
 <dc:creator>King, Molly M.</dc:creator>
 <dc:creator>Bergstrom, Carl T.</dc:creator>
 <dc:creator>Correll, Shelley J.</dc:creator>
 <dc:creator>Jacquet, Jennifer</dc:creator>
 <dc:creator>West, Jevin D.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  How common is self-citation in scholarly publication, and does the practice
vary by gender? Using novel methods and a data set of 1.5 million research
papers in the scholarly database JSTOR published between 1779 and 2011, the
authors find that nearly 10 percent of references are self-citations by a
paper's authors. The findings also show that between 1779 and 2011, men cited
their own papers 56 percent more than did women. In the last two decades of
data, men self-cited 70 percent more than women. Women are also more than 10
percentage points more likely than men to not cite their own previous work at
all. While these patterns could result from differences in the number of papers
that men and women authors have published rather than gender-specific patterns
of self-citation behavior, this gender gap in self-citation rates has remained
stable over the last 50 years, despite increased representation of women in
academia. The authors break down self-citation patterns by academic field and
number of authors and comment on potential mechanisms behind these
observations. These findings have important implications for scholarly
visibility and cumulative advantage in academic careers.
</dc:description>
 <dc:description>Comment: final published article</dc:description>
 <dc:date>2016-06-30</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00376</dc:identifier>
 <dc:identifier>Socius 3: 1-22 (2017)</dc:identifier>
 <dc:identifier>doi:10.1177/2378023117738903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00378</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Want Drugs? Use Python</dc:title>
 <dc:creator>Nowotka, Micha&#x142;</dc:creator>
 <dc:creator>Papadatos, George</dc:creator>
 <dc:creator>Davies, Mark</dc:creator>
 <dc:creator>Dedman, Nathan</dc:creator>
 <dc:creator>Hersey, Anne</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  We describe how Python can be leveraged to streamline the curation, modelling
and dissemination of drug discovery data as well as the development of
innovative, freely available tools for the related scientific community. We
look at various examples, such as chemistry toolkits, machine-learning
applications and web frameworks and show how Python can glue it all together to
create efficient data science pipelines.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00379</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Programming and PyMC3</dc:title>
 <dc:creator>Coyle, Peadar</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  In recent years sports analytics has gotten more and more popular. We propose
a model for Rugby data - in particular to model the 2014 Six Nations
tournament. We propose a Bayesian hierarchical model to estimate the
characteristics that bring a team to lose or win a game, and predict the score
of particular matches. This is intended to be a brief introduction to
Probabilistic Programming in Python and in particular the powerful library
called PyMC3.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00405</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Social Media to Promote STEM Education: Matching College Students
  with Role Models</dc:title>
 <dc:creator>He, Ling</dc:creator>
 <dc:creator>Murphy, Lee</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  STEM (Science, Technology, Engineering, and Mathematics) fields have become
increasingly central to U.S. economic competitiveness and growth. The shortage
in the STEM workforce has brought promoting STEM education upfront. The rapid
growth of social media usage provides a unique opportunity to predict users'
real-life identities and interests from online texts and photos. In this paper,
we propose an innovative approach by leveraging social media to promote STEM
education: matching Twitter college student users with diverse LinkedIn STEM
professionals using a ranking algorithm based on the similarities of their
demographics and interests. We share the belief that increasing STEM presence
in the form of introducing career role models who share similar interests and
demographics will inspire students to develop interests in STEM related fields
and emulate their models. Our evaluation on 2,000 real college students
demonstrated the accuracy of our ranking algorithm. We also design a novel
implementation that recommends matched role models to the students.
</dc:description>
 <dc:description>Comment: 16 pages, 8 figures, accepted by ECML/PKDD 2016, Industrial Track</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00410</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain Adaptation for Neural Networks by Parameter Augmentation</dc:title>
 <dc:creator>Watanabe, Yusuke</dc:creator>
 <dc:creator>Hashimoto, Kazuma</dc:creator>
 <dc:creator>Tsuruoka, Yoshimasa</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a simple domain adaptation method for neural networks in a
supervised setting. Supervised domain adaptation is a way of improving the
generalization performance on the target domain by using the source domain
dataset, assuming that both of the datasets are labeled. Recently, recurrent
neural networks have been shown to be successful on a variety of NLP tasks such
as caption generation; however, the existing domain adaptation techniques are
limited to (1) tune the model parameters by the target dataset after the
training by the source dataset, or (2) design the network to have dual output,
one for the source domain and the other for the target domain. Reformulating
the idea of the domain adaptation technique proposed by Daume (2007), we
propose a simple domain adaptation method, which can be applied to neural
networks trained with a cross-entropy loss. On captioning datasets, we show
performance improvements over other domain adaptation methods.
</dc:description>
 <dc:description>Comment: 9 page. To appear in the first ACL Workshop on Representation
  Learning for NLP</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00417</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Adaptation of Multi-Camera Person Identification Models
  through Sparse Non-redundant Representative Selection</dc:title>
 <dc:creator>Das, Abir</dc:creator>
 <dc:creator>Panda, Rameswar</dc:creator>
 <dc:creator>Roy-Chowdhury, Amit K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The problem of image-base person identification/recognition is to provide an
identity to the image of an individual based on learned models that describe
his/her appearance. Most traditional person identification systems rely on
learning a static model on tediously labeled training data. Though labeling
manually is an indispensable part of a supervised framework, for a large scale
identification system labeling huge amount of data is a significant overhead.
For large multi-sensor data as typically encountered in camera networks,
labeling a lot of samples does not always mean more information, as redundant
images are labeled several times. In this work, we propose a convex
optimization based iterative framework that progressively and judiciously
chooses a sparse but informative set of samples for labeling, with minimal
overlap with previously labeled images. We also use a structure preserving
sparse reconstruction based classifier to reduce the training burden typically
seen in discriminative classifiers. The two stage approach leads to a novel
framework for online update of the classifiers involving only the incorporation
of new labeled data rather than any expensive training phase. We demonstrate
the effectiveness of our approach on multi-camera person re-identification
datasets, to demonstrate the feasibility of learning online classification
models in multi-camera big data applications. Using three benchmark datasets,
we validate our approach and demonstrate that our framework achieves superior
performance with significantly less amount of manual labeling.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00421</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Migration Corridors to Clusters: The Value of Google+ Data for
  Migration Studies</dc:title>
 <dc:creator>Messias, Johnnatan</dc:creator>
 <dc:creator>Benevenuto, Fabricio</dc:creator>
 <dc:creator>Weber, Ingmar</dc:creator>
 <dc:creator>Zagheni, Emilio</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Recently, there have been considerable efforts to use online data to
investigate international migration. These efforts show that Web data are
valuable for estimating migration rates and are relatively easy to obtain.
However, existing studies have only investigated flows of people along
migration corridors, i.e. between pairs of countries. In our work, we use data
about &quot;places lived&quot; from millions of Google+ users in order to study migration
&quot;clusters&quot;, i.e. groups of countries in which individuals have lived. For the
first time, we consider information about more than two countries people have
lived in. We argue that these data are very valuable because this type of
information is not available in traditional demographic sources which record
country-to-country migration flows independent of each other. We show that
migration clusters of country triads cannot be identified using information
about bilateral flows alone. To demonstrate the additional insights that can be
gained by using data about migration clusters, we first develop a model that
tries to predict the prevalence of a given triad using only data about its
constituent pairs. We then inspect the groups of three countries which are more
or less prominent, compared to what we would expect based on bilateral flows
alone. Next, we identify a set of features such as a shared language or
colonial ties that explain which triple of country pairs are more or less
likely to be clustered when looking at country triples. Then we select and
contrast a few cases of clusters that provide some qualitative information
about what our data set shows. The type of data that we use is potentially
available for a number of social media services. We hope that this first study
about migration clusters will stimulate the use of Web data for the development
of new theories of international migration that could not be tested
appropriately before.
</dc:description>
 <dc:description>Comment: 2016 IEEE/ACM International Conference on Advances in Social Networks
  Analysis and Mining (ASONAM)</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00424</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Relational Dependency Networks for Relation Extraction</dc:title>
 <dc:creator>Viswanathan, Dileep</dc:creator>
 <dc:creator>Soni, Ameet</dc:creator>
 <dc:creator>Shavlik, Jude</dc:creator>
 <dc:creator>Natarajan, Sriraam</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the task of KBP slot filling -- extracting relation information
from newswire documents for knowledge base construction. We present our
pipeline, which employs Relational Dependency Networks (RDNs) to learn
linguistic patterns for relation extraction. Additionally, we demonstrate how
several components such as weak supervision, word2vec features, joint learning
and the use of human advice, can be incorporated in this relational framework.
We evaluate the different components in the benchmark KBP 2015 task and show
that RDNs effectively model a diverse set of features and perform competitively
with current state-of-the-art relation extraction.
</dc:description>
 <dc:description>Comment: In Proceedings of Sixth International Workshop on Statistical
  Relational AI at the 25th International Joint Conference on Artificial
  Intelligence (IJCAI)</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00428</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Situated Structure Learning of a Bayesian Logic Network for Commonsense
  Reasoning</dc:title>
 <dc:creator>Garrison, Haley</dc:creator>
 <dc:creator>Chernova, Sonia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper details the implementation of an algorithm for automatically
generating a high-level knowledge network to perform commonsense reasoning,
specifically with the application of robotic task repair. The network is
represented using a Bayesian Logic Network (BLN) (Jain, Waldherr, and Beetz
2009), which combines a set of directed relations between abstract concepts,
including IsA, AtLocation, HasProperty, and UsedFor, with a corresponding
probability distribution that models the uncertainty inherent in these
relations. Inference over this network enables reasoning over the abstract
concepts in order to perform appropriate object substitution or to locate
missing objects in the robot's environment. The structure of the network is
generated by combining information from two existing knowledge sources:
ConceptNet (Speer and Havasi 2012), and WordNet (Miller 1995). This is done in
a &quot;situated&quot; manner by only including information relevant a given context.
Results show that the generated network is able to accurately predict object
categories, locations, properties, and affordances in three different household
scenarios.
</dc:description>
 <dc:description>Comment: International Joint Conference on Artificial Intelligence (IJCAI),
  StarAI workshop</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00431</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniqueness of Normal Forms for Shallow Term Rewrite Systems</dc:title>
 <dc:creator>Radcliffe, Nicholas</dc:creator>
 <dc:creator>Moraes, Luis</dc:creator>
 <dc:creator>Verma, Rakesh</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Uniqueness of normal forms ($UN^=$) is an important property of term rewrite
systems. $UN^=$ is decidable for ground (i.e., variable-free) systems and
undecidable in general. Recently it was shown to be decidable for linear,
shallow systems. We generalize this previous result and show that this property
is decidable for shallow rewrite systems, in contrast to confluence,
reachability and other properties, which are all undecidable for flat systems.
Our result is also optimal in some sense, since we prove that the $UN^=$
property is undecidable for two classes of linear rewrite systems: left-flat
systems in which right-hand sides are of depth at most two and right-flat
systems in which left-hand sides are of depth at most two.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00435</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoding the Encoding of Functional Brain Networks: an fMRI
  Classification Comparison of Non-negative Matrix Factorization (NMF),
  Independent Component Analysis (ICA), and Sparse Coding Algorithms</dc:title>
 <dc:creator>Xie, Jianwen</dc:creator>
 <dc:creator>Douglas, Pamela K.</dc:creator>
 <dc:creator>Wu, Ying Nian</dc:creator>
 <dc:creator>Brody, Arthur L.</dc:creator>
 <dc:creator>Anderson, Ariana E.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Brain networks in fMRI are typically identified using spatial independent
component analysis (ICA), yet mathematical constraints such as sparse coding
and positivity both provide alternate biologically-plausible frameworks for
generating brain networks. Non-negative Matrix Factorization (NMF) would
suppress negative BOLD signal by enforcing positivity. Spatial sparse coding
algorithms ($L1$ Regularized Learning and K-SVD) would impose local
specialization and a discouragement of multitasking, where the total observed
activity in a single voxel originates from a restricted number of possible
brain networks.
  The assumptions of independence, positivity, and sparsity to encode
task-related brain networks are compared; the resulting brain networks for
different constraints are used as basis functions to encode the observed
functional activity at a given time point. These encodings are decoded using
machine learning to compare both the algorithms and their assumptions, using
the time series weights to predict whether a subject is viewing a video,
listening to an audio cue, or at rest, in 304 fMRI scans from 51 subjects.
  For classifying cognitive activity, the sparse coding algorithm of $L1$
Regularized Learning consistently outperformed 4 variations of ICA across
different numbers of networks and noise levels (p$&lt;$0.001). The NMF algorithms,
which suppressed negative BOLD signal, had the poorest accuracy. Within each
algorithm, encodings using sparser spatial networks (containing more
zero-valued voxels) had higher classification accuracy (p$&lt;$0.001). The success
of sparse coding algorithms may suggest that algorithms which enforce sparse
coding, discourage multitasking, and promote local specialization may capture
better the underlying source processes than those which allow inexhaustible
local processes such as ICA.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00436</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Terminal-Set-Enhanced Community Detection in Social Networks</dc:title>
 <dc:creator>Tong, G.</dc:creator>
 <dc:creator>Cui, L.</dc:creator>
 <dc:creator>Wu, W.</dc:creator>
 <dc:creator>Liu, C.</dc:creator>
 <dc:creator>Du, D-Z.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Community detection aims to reveal the community structure in a social
network, which is one of the fundamental problems. In this paper we investigate
the community detection problem based on the concept of terminal set. A
terminal set is a group of users within which any two users belong to different
communities. Although the community detection is hard in general, the terminal
set can be very helpful in designing effective community detection algorithms.
We first present a 2-approximation algorithm running in polynomial time for the
original community detection problem. In the other issue, in order to better
support real applications we further consider the case when extra restrictions
are imposed on feasible partitions. For such customized community detection
problems, we provide two randomized algorithms which are able to find the
optimal partition with a high probability. Demonstrated by the experiments
performed on benchmark networks the proposed algorithms are able to produce
high-quality communities.
</dc:description>
 <dc:description>Comment: INFOCOM 2016</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00442</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Datasets on object manipulation and interaction: a survey</dc:title>
 <dc:creator>Huang, Yongqiang</dc:creator>
 <dc:creator>Sun, Yu</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A dataset is crucial for model learning and evaluation. Choosing the right
dataset to use or making a new dataset requires the knowledge of those that are
available. In this work, we provide that knowledge, by reviewing twenty
datasets that were published in the recent six years and that are directly
related to object manipulation. We report on modalities, activities, and
annotations for each individual dataset and give our view on its use for object
manipulation. We also compare the datasets and summarize them. We conclude with
our suggestion on future datasets.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, 3 tables</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00442</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00443</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic Proof Complexity: Progress, Frontiers and Challenges</dc:title>
 <dc:creator>Pitassi, Tonnian</dc:creator>
 <dc:creator>Tzameret, Iddo</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03F20, 68Q25</dc:subject>
 <dc:description>  We survey recent progress in the proof complexity of strong proof systems and
its connection to algebraic circuit complexity, showing how the synergy between
the two gives rise to new approaches to fundamental open questions, solutions
to old problems, and new directions of research. In particular, we focus on
tight connections between proof complexity lower bounds (namely, lower bounds
on the size of proofs of certain tautologies), algebraic circuit lower bounds,
and the Polynomial Identity Testing problem from derandomization theory.
</dc:description>
 <dc:description>Comment: Complexity Column of the ACM SIGLOG News, ACM New York, NY, USA, July
  2016</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00446</identifier>
 <datestamp>2016-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Greedy Approach to Adapting the Trace Parameter for Temporal
  Difference Learning</dc:title>
 <dc:creator>White, Martha</dc:creator>
 <dc:creator>White, Adam</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  One of the main obstacles to broad application of reinforcement learning
methods is the parameter sensitivity of our core learning algorithms. In many
large-scale applications, online computation and function approximation
represent key strategies in scaling up reinforcement learning algorithms. In
this setting, we have effective and reasonably well understood algorithms for
adapting the learning-rate parameter, online during learning. Such
meta-learning approaches can improve robustness of learning and enable
specialization to current task, improving learning speed. For
temporal-difference learning algorithms which we study here, there is yet
another parameter, $\lambda$, that similarly impacts learning speed and
stability in practice. Unfortunately, unlike the learning-rate parameter,
$\lambda$ parametrizes the objective function that temporal-difference methods
optimize. Different choices of $\lambda$ produce different fixed-point
solutions, and thus adapting $\lambda$ online and characterizing the
optimization is substantially more complex than adapting the learning-rate
parameter. There are no meta-learning method for $\lambda$ that can achieve (1)
incremental updating, (2) compatibility with function approximation, and (3)
maintain stability of learning under both on and off-policy sampling. In this
paper we contribute a novel objective function for optimizing $\lambda$ as a
function of state rather than time. We derive a new incremental, linear
complexity $\lambda$-adaption algorithm that does not require offline batch
updating or access to a model of the world, and present a suite of experiments
illustrating the practicality of our new algorithm in three different settings.
Taken together, our contributions represent a concrete step towards black-box
application of temporal-difference learning methods in real world problems.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:date>2016-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00455</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alzheimer's Disease Diagnostics by Adaptation of 3D Convolutional
  Network</dc:title>
 <dc:creator>Hosseini-Asl, Ehsan</dc:creator>
 <dc:creator>Keynto, Robert</dc:creator>
 <dc:creator>El-Baz, Ayman</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Early diagnosis, playing an important role in preventing progress and
treating the Alzheimer\{'}s disease (AD), is based on classification of
features extracted from brain images. The features have to accurately capture
main AD-related variations of anatomical brain structures, such as, e.g.,
ventricles size, hippocampus shape, cortical thickness, and brain volume. This
paper proposed to predict the AD with a deep 3D convolutional neural network
(3D-CNN), which can learn generic features capturing AD biomarkers and adapt to
different domain datasets. The 3D-CNN is built upon a 3D convolutional
autoencoder, which is pre-trained to capture anatomical shape variations in
structural brain MRI scans. Fully connected upper layers of the 3D-CNN are then
fine-tuned for each task-specific AD classification. Experiments on the
CADDementia MRI dataset with no skull-stripping preprocessing have shown our
3D-CNN outperforms several conventional classifiers by accuracy. Abilities of
the 3D-CNN to generalize the features learnt and adapt to other domains have
been validated on the ADNI dataset.
</dc:description>
 <dc:description>Comment: This paper is accepted for publication at IEEE ICIP 2016 conference</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00455</dc:identifier>
 <dc:identifier>doi:10.1109/ICIP.2016.7532332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00464</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NIST: An Image Classification Network to Image Semantic Retrieval</dc:title>
 <dc:creator>Dong, Le</dc:creator>
 <dc:creator>Chen, Xiuyuan</dc:creator>
 <dc:creator>Mao, Mengdie</dc:creator>
 <dc:creator>Zhang, Qianni</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a classification network to image semantic retrieval
(NIST) framework to counter the image retrieval challenge. Our approach
leverages the successful classification network GoogleNet based on
Convolutional Neural Networks to obtain the semantic feature matrix which
contains the serial number of classes and corresponding probabilities. Compared
with traditional image retrieval using feature matching to compute the
similarity between two images, NIST leverages the semantic information to
construct semantic feature matrix and uses the semantic distance algorithm to
compute the similarity. Besides, the fusion strategy can significantly reduce
storage and time consumption due to less classes participating in the last
semantic distance computation. Experiments demonstrate that our NIST framework
produces state-of-the-art results in retrieval experiments on MIRFLICKR-25K
dataset.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00466</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outlier absorbing based on a Bayesian approach</dc:title>
 <dc:creator>Bagherzadeh, Parsa</dc:creator>
 <dc:creator>Yazdi, Hadi Sadoghi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The presence of outliers is prevalent in machine learning applications and
may produce misleading results. In this paper a new method for dealing with
outliers and anomal samples is proposed. To overcome the outlier issue, the
proposed method combines the global and local views of the samples. By
combination of these views, our algorithm performs in a robust manner. The
experimental results show the capabilities of the proposed method.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00467</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Security of AoA Estimation</dc:title>
 <dc:creator>Abdelaziz, Amr</dc:creator>
 <dc:creator>Koksal, C. Emre</dc:creator>
 <dc:creator>Gamal, Hesham El</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Angle of Arrival (AoA) estimation has found its way to a wide range of
applications. Much attention have been paid to study different techniques for
AoA estimation and its applications for jamming suppression, however, security
vulnerability issues of AoA estimation itself under hostile activity have not
been paid the same attention. In this paper, the problem of AoA estimation in
Rician flat fading channel under jamming condition is investigated. We consider
the scenario in which a receiver with multiple antenna is trying to estimate
the AoA of the specular line of sight (LOS) component of signal received from a
given single antenna transmitter using a predefined training sequence. A jammer
equipped with multiple antennas is trying to interrupt the AoA estimation phase
by sending an arbitrary signal. We derive the optimal jammer and receiver
strategies in various scenarios based on the knowledge of the opponent
strategies and the available information about the communication channel. In
all scenarios, we derive the optimal jammer signal design as well as its
optimal power allocation policy. The results show the optimality of the
training based Maximum Likelihood (ML) AoA estimator in case of randomly
generated jamming signal. We also show that, the optimal jammer strategy is to
emit a signal identical to the predefined training sequence turning the
estimation process into a highest power competition scenario in which the
detected AoA is the one for the transmitting entity of higher power. The
obtained results are supported by the provided computer simulation.
</dc:description>
 <dc:description>Comment: 9 Pages</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00468</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unbreakable distributed storage with quantum key distribution network
  and password-authenticated secret sharing</dc:title>
 <dc:creator>Fujiwara, Mikio</dc:creator>
 <dc:creator>Waseda, Atsushi</dc:creator>
 <dc:creator>Nojima, Ryo</dc:creator>
 <dc:creator>Moriai, Shiho</dc:creator>
 <dc:creator>Ogata, Wakaha</dc:creator>
 <dc:creator>Sasaki, Masahide</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Distributed storage plays an essential role in realizing robust and secure
data storage in a network over long periods of time. A distributed storage
system consists of a data owner machine, multiple storage servers and channels
to link them. In such a system, secret sharing scheme is widely adopted, in
which secret data are split into multiple pieces and stored in each server. To
reconstruct them, the data owner should gather plural pieces. Shamir's (k,
n)-threshold scheme, in which the data are split into n pieces (shares) for
storage and at least k pieces of them must be gathered for reconstruction,
furnishes information theoretic security, that is, even if attackers could
collect shares of less than the threshold k, they cannot get any information
about the data, even with unlimited computing power. Behind this scenario,
however, assumed is that data transmission and authentication must be perfectly
secure, which is not trivial in practice. Here we propose a totally information
theoretically secure distributed storage system based on a user-friendly
single-password-authenticated secret sharing scheme and secure transmission
using quantum key distribution, and demonstrate it in the Tokyo metropolitan
area.
</dc:description>
 <dc:description>Comment: 16 pages, 3 figures, and supplementary information, Scientific
  Reports srep28988 2016</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00470</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Keyframe-based monocular SLAM: design, survey, and future directions</dc:title>
 <dc:creator>Younes, Georges</dc:creator>
 <dc:creator>Asmar, Daniel</dc:creator>
 <dc:creator>Shammas, Elie</dc:creator>
 <dc:creator>Zelek, John</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Extensive research in the field of monocular SLAM for the past fifteen years
has yielded workable systems that found their way into various applications in
robotics and augmented reality. Although filter-based monocular SLAM systems
were common at some time, the more efficient keyframe-based solutions are
becoming the de facto methodology for building a monocular SLAM system. The
objective of this paper is threefold: first, the paper serves as a guideline
for people seeking to design their own monocular SLAM according to specific
environmental constraints. Second, it presents a survey that covers the various
keyframe-based monocular SLAM systems in the literature, detailing the
components of their implementation, and critically assessing the specific
strategies made in each proposed solution. Third, the paper provides insight
into the direction of future research in this field, to address the major
limitations still facing monocular SLAM; namely, in the issues of illumination
changes, initialization, highly dynamic motion, poorly textured scenes,
repetitive textures, map maintenance, and failure recovery.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00470</dc:identifier>
 <dc:identifier>Robotics and Autonomous Systems, Volume 98, 2017, Pages 67-88</dc:identifier>
 <dc:identifier>doi:10.1016/j.robot.2017.09.010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00474</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Neighborhood Graph Construction for Inference in
  Multi-Relational Networks</dc:title>
 <dc:creator>Fakhraei, Shobeir</dc:creator>
 <dc:creator>Sridhar, Dhanya</dc:creator>
 <dc:creator>Pujara, Jay</dc:creator>
 <dc:creator>Getoor, Lise</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A neighborhood graph, which represents the instances as vertices and their
relations as weighted edges, is the basis of many semi-supervised and
relational models for node labeling and link prediction. Most methods employ a
sequential process to construct the neighborhood graph. This process often
consists of generating a candidate graph, pruning the candidate graph to make a
neighborhood graph, and then performing inference on the variables (i.e.,
nodes) in the neighborhood graph. In this paper, we propose a framework that
can dynamically adapt the neighborhood graph based on the states of variables
from intermediate inference results, as well as structural properties of the
relations connecting them. A key strength of our framework is its ability to
handle multi-relational data and employ varying amounts of relations for each
instance based on the intermediate inference results. We formulate the link
prediction task as inference on neighborhood graphs, and include preliminary
results illustrating the effects of different strategies in our proposed
framework.
</dc:description>
 <dc:description>Comment: Presented at SIGKDD 12th International Workshop on Mining and
  Learning with Graphs (MLG'16)</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00475</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lessons from DEPLOYment</dc:title>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Jones, Cliff</dc:creator>
 <dc:creator>Iliasov, Alexei</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper reviews the major lessons learnt during two significant pilot
projects by Bosch Research during the DEPLOY project. Principally, the use of a
single formalism, even when it comes together with a rigorous refinement
methodology like Event-B, cannot offer a complete solution. Unfortunately (but
not unexpectedly), we cannot offer a panacea to cover every phase from
requirements to code; in fact any specific formalism or language (or tool)
should be used only where and when it is really suitable and not necessarily
(and somehow forcibly) over the entire lifecycle.
</dc:description>
 <dc:description>Comment: Rodin Workshop, February 2012 ,Fontainebleau, France</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00476</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equimatchable Claw-Free Graphs</dc:title>
 <dc:creator>Akbari, Saieed</dc:creator>
 <dc:creator>Alizadeh, Hadi</dc:creator>
 <dc:creator>Ekim, T&#x131;naz</dc:creator>
 <dc:creator>G&#xf6;z&#xfc;pek, Didem</dc:creator>
 <dc:creator>Shalom, Mordechai</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A graph is equimatchable if all of its maximal matchings have the same size.
A graph is claw-free if it does not have a claw as an induced subgraph. In this
paper, we provide, to the best of our knowledge, the first characterization of
claw-free equimatchable graphs by identifying the equimatchable claw-free graph
families. This characterization implies an efficient recognition algorithm.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00478</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Checking of BPMN Models for Reconfigurable Workflows</dc:title>
 <dc:creator>Aguilar, Juan Carlos Polanco</dc:creator>
 <dc:creator>Hasebe, Koji</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Kato, Kazuhiko</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Nowadays, business enterprises often need to dynamically reconfigure their
internal processes in order to improve the efficiency of the business flow.
However, modifications of the workflow usually lead to several problems in
terms of deadlock freedom, completeness and security. A solid solution to these
problems consists in the application of model checking techniques in order to
verify if specific properties of the workflow are preserved by the change in
configuration. Our goal in this work is to develop a formal verification
procedure to deal with these problems. The first step consists in developing a
formal definition of a BPMN model of a business workflow. Then, a given BPMN
model is translated into a formal model specified in Promela. Finally, by using
the SPIN model checker, the correctness of the reconfigured workflow is
verified.
</dc:description>
 <dc:description>Comment: Conference of Japan Society for Software Science and Technology,
  JSSST 2011</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00485</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Sparse Regularization for Deep Neural Networks</dc:title>
 <dc:creator>Scardapane, Simone</dc:creator>
 <dc:creator>Comminiello, Danilo</dc:creator>
 <dc:creator>Hussain, Amir</dc:creator>
 <dc:creator>Uncini, Aurelio</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we consider the joint task of simultaneously optimizing (i)
the weights of a deep neural network, (ii) the number of neurons for each
hidden layer, and (iii) the subset of active input features (i.e., feature
selection). While these problems are generally dealt with separately, we
present a simple regularized formulation allowing to solve all three of them in
parallel, using standard optimization routines. Specifically, we extend the
group Lasso penalty (originated in the linear regression literature) in order
to impose group-level sparsity on the network's connections, where each group
is defined as the set of outgoing weights from a unit. Depending on the
specific case, the weights can be related to an input variable, to a hidden
neuron, or to a bias unit, thus performing simultaneously all the
aforementioned tasks in order to obtain a compact network. We perform an
extensive experimental evaluation, by comparing with classical weight decay and
Lasso penalties. We show that a sparse version of the group Lasso penalty is
able to achieve competitive performances, while at the same time resulting in
extremely compact networks with a smaller number of input features. We evaluate
both on a toy dataset for handwritten digit recognition, and on multiple
realistic large-scale classification problems.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00485</dc:identifier>
 <dc:identifier>doi:10.1016/j.neucom.2017.02.029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00490</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalar Solvability of Network Computation Problems and Representable
  Matroids</dc:title>
 <dc:creator>Gupta, Anindya</dc:creator>
 <dc:creator>Rajan, B. Sundar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the following \textit{network computation problem}. In an acyclic
network, there are multiple source nodes, each generating multiple messages,
and there are multiple sink nodes, each demanding a function of the source
messages. The network coding problem corresponds to the case in which every
demand function is equal to some source message, i.e., each sink demands some
source message. Connections between network coding problems and matroids have
been well studied. In this work, we establish a relation between network
computation problems and representable matroids. We show that a network
computation problem in which the sinks demand linear functions of source
messages admits a scalar linear solution if and only if it is matroidal with
respect to a representable matroid whose representation fulfills certain
constraints dictated by the network computation problem. Next, we obtain a
connection between network computation problems and functional dependency
relations (FD-relations) and show that FD-relations can be used to characterize
network computation problem with arbitrary (not necessarily linear) function
demands as well as nonlinear network codes.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures and 1 table. arXiv admin note: text overlap with
  arXiv:1603.05365</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00494</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Double-detector for Sparse Signal Detection from One Bit Compressed
  Sensing Measurements</dc:title>
 <dc:creator>Zayyani, Hadi</dc:creator>
 <dc:creator>Haddadi, Farzan</dc:creator>
 <dc:creator>Korki, Mehdi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This letter presents the sparse vector signal detection from one bit
compressed sensing measurements, in contrast to the previous works which deal
with scalar signal detection. In this letter, available results are extended to
the vector case and the GLRT detector and the optimal quantizer design are
obtained. Also, a double-detector scheme is introduced in which a sensor level
threshold detector is integrated into network level GLRT to improve the
performance. The detection criteria of oracle and clairvoyant detectors are
also derived. Simulation results show that with careful design of the threshold
detector, the overall detection performance of double-detector scheme would be
better than the sign-GLRT proposed in [1] and close to oracle and clairvoyant
detectors. Also, the proposed detector is applied to spectrum sensing and the
results are near the well known energy detector which uses the real valued data
while the proposed detector only uses the sign of the data.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00494</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2613898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00497</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying ECUs Using Inimitable Characteristics of Signals in
  Controller Area Networks</dc:title>
 <dc:creator>Choi, Wonsuk</dc:creator>
 <dc:creator>Jo, Hyo Jin</dc:creator>
 <dc:creator>Woo, Samuel</dc:creator>
 <dc:creator>Chun, Ji Young</dc:creator>
 <dc:creator>Park, Jooyoung</dc:creator>
 <dc:creator>Lee, Dong Hoon</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In the last several decades, the automotive industry has come to incorporate
the latest Information and Communications (ICT) technology, increasingly
replacing mechanical components of vehicles with electronic components. These
electronic control units (ECUs) communicate with each other in an in-vehicle
network that makes the vehicle both safer and easier to drive. Controller Area
Networks (CANs) are the current standard for such high quality in-vehicle
communication. Unfortunately, however, CANs do not currently offer protection
against security attacks. In particular, they do not allow for message
authentication and hence are open to attacks that replay ECU messages for
malicious purposes. Applying the classic cryptographic method of message
authentication code (MAC) is not feasible since the CAN data frame is not long
enough to include a sufficiently long MAC to provide effective authentication.
In this paper, we propose a novel identification method, which works in the
physical layer of an in-vehicle CAN network. Our method identifies ECUs using
inimitable characteristics of signals enabling detection of a compromised or
alien ECU being used in a replay attack. Unlike previous attempts to address
security issues in the in-vehicle CAN network, our method works by simply
adding a monitoring unit to the existing network, making it deployable in
current systems and compliant with required CAN standards. Our experimental
results show that the bit string and classification algorithm that we utilized
yielded more accurate identification of compromised ECUs than any other method
proposed to date. The false positive rate is more than 2 times lower than the
method proposed by P.-S. Murvay et al. This paper is also the first to identify
potential attack models that systems should be able to detect.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00500</identifier>
 <datestamp>2016-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-Temporal Network Dynamics Framework for Energy-Efficient
  Ultra-Dense Cellular Networks</dc:title>
 <dc:creator>Park, Jihong</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Kim, Seong-Lyun</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This article investigates the performance of an ultra-dense network (UDN)
from an energy-efficiency (EE) standpoint leveraging the interplay between
stochastic geometry (SG) and mean-field game (MFG) theory. In this setting,
base stations (BSs) (resp. users) are uniformly distributed over a
two-dimensional plane as two independent homogeneous Poisson point processes
(PPPs), where users associate to their nearest BSs. The goal of every BS is to
maximize its own energy efficiency subject to channel uncertainty, random BS
location, and interference levels. Due to the coupling in interference, the
problem is solved in the mean-field (MF) regime where each BS interacts with
the whole BS population via time-varying MF interference. As a main
contribution, the asymptotic convergence of MF interference to zero is
rigorously proved in a UDN with multiple transmit antennas. It allows us to
derive a closed-form EE representation, yielding a tractable EE optimal power
control policy. This proposed power control achieves more than 1.5 times higher
EE compared to a fixed power baseline.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, to appear in proc. IEEE GLOBECOM 2016</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:date>2016-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00501</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Deep Representation Learning Model for Big Image Data
  Classification</dc:title>
 <dc:creator>Dong, Le</dc:creator>
 <dc:creator>Lv, Na</dc:creator>
 <dc:creator>Zhang, Qianni</dc:creator>
 <dc:creator>Xie, Shanshan</dc:creator>
 <dc:creator>He, Ling</dc:creator>
 <dc:creator>Mao, Mengdie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper describes an effective and efficient image classification
framework nominated distributed deep representation learning model (DDRL). The
aim is to strike the balance between the computational intensive deep learning
approaches (tuned parameters) which are intended for distributed computing, and
the approaches that focused on the designed parameters but often limited by
sequential computing and cannot scale up. In the evaluation of our approach, it
is shown that DDRL is able to achieve state-of-art classification accuracy
efficiently on both medium and large datasets. The result implies that our
approach is more efficient than the conventional deep learning approaches, and
can be applied to big data that is too complex for parameter designing focused
approaches. More specifically, DDRL contains two main components, i.e., feature
extraction and selection. A hierarchical distributed deep representation
learning algorithm is designed to extract image statistics and a nonlinear
mapping algorithm is used to map the inherent statistics into abstract
features. Both algorithms are carefully designed to avoid millions of
parameters tuning. This leads to a more compact solution for image
classification of big data. We note that the proposed approach is designed to
be friendly with parallel computing. It is generic and easy to be deployed to
different distributed computing resources. In the experiments, the largescale
image datasets are classified with a DDRM implementation on Hadoop MapReduce,
which shows high scalability and resilience.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00502</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Threshold Decoding for Disjunctive Group Testing</dc:title>
 <dc:creator>D'yachkov, A. G.</dc:creator>
 <dc:creator>Vorobyev, I. V.</dc:creator>
 <dc:creator>Polyanskii, N. A.</dc:creator>
 <dc:creator>Shchukin, V. Yu.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Let $1 \le s &lt; t$, $N \ge 1$ be integers and a complex electronic circuit of
size $t$ is said to be an $s$-active, $\; s \ll t$, and can work as a system
block if not more than $s$ elements of the circuit are defective. Otherwise,
the circuit is said to be an $s$-defective and should be replaced by a similar
$s$-active circuit. Suppose that there exists a possibility to run $N$
non-adaptive group tests to check the $s$-activity of the circuit. As usual, we
say that a (disjunctive) group test yields the positive response if the group
contains at least one defective element. Along with the conventional decoding
algorithm based on disjunctive $s$-codes, we consider a threshold decision rule
with the minimal possible decoding complexity, which is based on the simple
comparison of a fixed threshold $T$, $1 \le T \le N - 1$, with the number of
positive responses $p$, $0 \le p \le N$. For the both of decoding algorithms we
discuss upper bounds on the $\alpha$-level of significance of the statistical
test for the null hypothesis $\left\{ H_0 \,:\, \text{the circuit is
$s$-active} \right\}$ verse the alternative hypothesis $\left\{ H_1 \,:\,
\text{the circuit is $s$-defective} \right\}$.
</dc:description>
 <dc:description>Comment: ACCT 2016, 6 pages</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00507</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Learning a Hidden Hypergraph</dc:title>
 <dc:creator>D'yachkov, A. G.</dc:creator>
 <dc:creator>Vorobyev, I. V.</dc:creator>
 <dc:creator>Polyanskii, N. A.</dc:creator>
 <dc:creator>Shchukin, V. Yu.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Learning a hidden hypergraph is a natural generalization of the classical
group testing problem that consists in detecting unknown hypergraph
$H_{un}=H(V,E)$ by carrying out edge-detecting tests. In the given paper we
focus our attention only on a specific family $\mathcal{F}(t,s,\ell)$ of
localized hypergraphs for which the total number of vertices $|V| = t$, the
number of edges $|E|\le s$, $s\ll t$, and the cardinality of any edge
$|e|\le\ell$, $\ell\ll t$. Our goal is to identify all edges of $H_{un}\in
\mathcal{F}(t,s,\ell)$ by using the minimal number of tests. We provide an
adaptive algorithm that matches the information theory bound, i.e., the total
number of tests of the algorithm in the worst case is at most $s\ell\log_2
t(1+o(1))$.
</dc:description>
 <dc:description>Comment: ACCT 2016, 6 pages. arXiv admin note: text overlap with
  arXiv:1601.06705</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00509</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Big IoT and social networking data for smart cities: Algorithmic
  improvements on Big Data Analysis in the context of RADICAL city applications</dc:title>
 <dc:creator>Psomakelis, Evangelos</dc:creator>
 <dc:creator>Aisopos, Fotis</dc:creator>
 <dc:creator>Litke, Antonios</dc:creator>
 <dc:creator>Tserpes, Konstantinos</dc:creator>
 <dc:creator>Kardara, Magdalini</dc:creator>
 <dc:creator>Campo, Pablo Mart&#xed;nez</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper we present a SOA (Service Oriented Architecture)-based
platform, enabling the retrieval and analysis of big datasets stemming from
social networking (SN) sites and Internet of Things (IoT) devices, collected by
smart city applications and socially-aware data aggregation services. A large
set of city applications in the areas of Participating Urbanism, Augmented
Reality and Sound-Mapping throughout participating cities is being applied,
resulting into produced sets of millions of user-generated events and online SN
reports fed into the RADICAL platform. Moreover, we study the application of
data analytics such as sentiment analysis to the combined IoT and SN data saved
into an SQL database, further investigating algorithmic and configurations to
minimize delays in dataset processing and results retrieval.
</dc:description>
 <dc:description>Comment: Conference</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00510</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harnessing Self-Interference in Full-Duplex Relaying: An Analog
  Filter-and-Forward Approach</dc:title>
 <dc:creator>Xu, Jie</dc:creator>
 <dc:creator>Duan, Lingjie</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies a full-duplex filter-and-forward (FD-FF) relay system in
frequency-selective channels. Conventionally, the loop-back signal at the FD
relay is treated as harmful self-interference and needs to be significantly
suppressed via both analog- and digital-domain cancellation. However, the
performance of the conventional self-interference cancellation approach is
fundamentally limited due to the quantization error induced by the
analog-to-digital converter (ADC) with limited dynamic range. In this paper, we
consider an analog filter-and-forward design to help avoid the quantization
error, and surprisingly show that the maximum achievable rate of such an FD-FF
relay system is in fact regardless of the loop-back channel at the FD relay. We
characterize the maximum achievable rate of this channel by jointly optimizing
the transmit power allocation over frequency at the source and the frequency
response of the filter at the relay, subject to their individual power
constraints. Although this problem is non-convex, we obtain its optimal
solution by applying the Lagrange duality method. By simulations it is shown
that the proposed joint source and relay optimization achieves rate gains over
other heuristic designs, and is also advantageous over the conventional
approach by cancelling the relay loop-back signal as self-interference,
especially when the residual self-interference after cancellation is still
significant.
</dc:description>
 <dc:description>Comment: This is a paper to be presented in Globecom 2016</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00511</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a Hypergraph Approach to Multistage Group Testing Problems</dc:title>
 <dc:creator>D'yachkov, A. G.</dc:creator>
 <dc:creator>Vorobyev, I. V.</dc:creator>
 <dc:creator>Polyanskii, N. A.</dc:creator>
 <dc:creator>Shchukin, V. Yu.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Group testing is a well known search problem that consists in detecting up to
$s$ defective elements of the set $[t]=\{1,\ldots,t\}$ by carrying out tests on
properly chosen subsets of $[t]$. In classical group testing the goal is to
find all defective elements by using the minimal possible number of tests. In
this paper we consider multistage group testing. We propose a general idea how
to use a hypergraph approach to searching defects. For the case $s=2$, we
design an explicit construction, which makes use of $2\log_2t(1+o(1))$ tests in
the worst case and consists of $4$ stages.
</dc:description>
 <dc:description>Comment: ACCT 2016, 6 pages</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00514</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Joint Matrix Triangularization</dc:title>
 <dc:creator>Colombo, Nicolo</dc:creator>
 <dc:creator>Vlassis, Nikos</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>15A23, 15A42, 15A45, 15B10</dc:subject>
 <dc:description>  We consider the problem of approximate joint triangularization of a set of
noisy jointly diagonalizable real matrices. Approximate joint triangularizers
are commonly used in the estimation of the joint eigenstructure of a set of
matrices, with applications in signal processing, linear algebra, and tensor
decomposition. By assuming the input matrices to be perturbations of
noise-free, simultaneously diagonalizable ground-truth matrices, the
approximate joint triangularizers are expected to be perturbations of the exact
joint triangularizers of the ground-truth matrices. We provide a priori and a
posteriori perturbation bounds on the `distance' between an approximate joint
triangularizer and its exact counterpart. The a priori bounds are theoretical
inequalities that involve functions of the ground-truth matrices and noise
matrices, whereas the a posteriori bounds are given in terms of observable
quantities that can be computed from the input matrices. From a practical
perspective, the problem of finding the best approximate joint triangularizer
of a set of noisy matrices amounts to solving a nonconvex optimization problem.
We show that, under a condition on the noise level of the input matrices, it is
possible to find a good initial triangularizer such that the solution obtained
by any local descent-type algorithm has certain global guarantees. Finally, we
discuss the application of approximate joint matrix triangularization to
canonical tensor decomposition and we derive novel estimation error bounds.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00533</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypothesis Testing in the High Privacy Limit</dc:title>
 <dc:creator>Liao, Jiachun</dc:creator>
 <dc:creator>Sankar, Lalitha</dc:creator>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:creator>Calmon, Flavio P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Binary hypothesis testing under the Neyman-Pearson formalism is a statistical
inference framework for distinguishing data generated by two different source
distributions. Privacy restrictions may require the curator of the data or the
data respondents themselves to share data with the test only after applying a
randomizing privacy mechanism. Using mutual information as the privacy metric
and the relative entropy between the two distributions of the output
(postrandomization) source classes as the utility metric (motivated by the
Chernoff-Stein Lemma), this work focuses on finding an optimal mechanism that
maximizes the chosen utility function while ensuring that the mutual
information based leakage for both source distributions is bounded. Focusing on
the high privacy regime, an Euclidean information-theoretic (E-IT)
approximation to the tradeoff problem is presented. It is shown that the
solution to the E-IT approximation is independent of the alphabet size and
clarifies that a mutual information based privacy metric preserves the privacy
of the source symbols in inverse proportion to their likelihood.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, conference</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00534</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text comparison using word vector representations and dimensionality
  reduction</dc:title>
 <dc:creator>Heuer, Hendrik</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes a technique to compare large text sources using word
vector representations (word2vec) and dimensionality reduction (t-SNE) and how
it can be implemented using Python. The technique provides a bird's-eye view of
text sources, e.g. text summaries and their source material, and enables users
to explore text sources like a geographical map. Word vector representations
capture many linguistic properties such as gender, tense, plurality and even
semantic concepts like &quot;capital city of&quot;. Using dimensionality reduction, a 2D
map can be computed where semantically similar words are close to each other.
The technique uses the word2vec model from the gensim Python library and t-SNE
from scikit-learn.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00537</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Badge System Analysis and Design</dc:title>
 <dc:creator>Zhang, Jiawei</dc:creator>
 <dc:creator>Kong, Xiangnan</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  To incentivize users' participations and steer their online activities,
online social networks start to provide users with various kinds of rewards for
their contributions to the sites. The most frequently distributed rewards
include account levels, reputation scores, different kinds of badges, and even
material awards like small gifts and cash back, etc. Attracted by these
rewards, users will spend more time using the network services. In this paper,
we will mainly focus on &quot;badges reward systems&quot; but the proposed models can be
applied to other reward systems as well. Badges are small icons attached to
users' homepages and profiles denoting their achievements. People like to
accumulate badge for various reasons and different badges can have specific
values for them. Meanwhile, to get badges, they also need to exert efforts to
finish the required tasks, which can lead to certain costs. To understand and
model users' motivations in badge achievement activities, we will study an
existing badge system launched inside a real-world online social network,
Foursquare, in this paper. At the same time, to maximize users' contributions
to online social networks, social network system designers need to determine
the optimal badge system mechanism carefully. Badge system mechanism describes
various detailed aspects of the system and can involve many parameters, e.g.,
categories of existing badges, number of badges available as well as the
minimum contributions required to obtain the badges, which all need to be
designed with meticulous investigations. Based on the model of users' badges
accumulating activities, in this paper, we will also study how to design the
badge system that can incentivize the maximum users' contributions to the
social networks.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures, 3 tables, accepted by ASONAM 2016</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00538</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reversible Nets of Polyhedra</dc:title>
 <dc:creator>Akiyama, Jin</dc:creator>
 <dc:creator>Langerman, Stefan</dc:creator>
 <dc:creator>Matsunaga, Kiyoko</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  An example of reversible (or hinge inside-out transformable) figures is the
Dudeney's Haberdasher's puzzle in which an equilateral triangle is dissected
into four pieces, then hinged like a chain, and then is transformed into a
square by rotating the hinged pieces. Furthermore, the entire boundary of each
figure goes into the inside of the other figure and becomes the dissection
lines of the other figure. Many intriguing results on reversibilities of
figures have been found in prior research, but most of them are results on
polygons. This paper generalizes those results to a wider range of general
connected figures. It is shown that two nets obtained by cutting the surface of
an arbitrary convex polyhedron along non-intersecting dissection trees are
reversible. Moreover, a condition for two nets of an isotetrahedron to be both
reversible and tessellative is given.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00542</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intertwined Viral Marketing through Online Social Networks</dc:title>
 <dc:creator>Zhang, Jiawei</dc:creator>
 <dc:creator>Wang, Senzhang</dc:creator>
 <dc:creator>Zhan, Qianyi</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Traditional viral marketing problems aim at selecting a subset of seed users
for one single product to maximize its awareness in social networks. However,
in real scenarios, multiple products can be promoted in social networks at the
same time. At the product level, the relationships among these products can be
quite intertwined, e.g., competing, complementary and independent. In this
paper, we will study the &quot;interTwined Influence Maximization&quot; (i.e., TIM)
problem for one product that we target on in online social networks, where
multiple other competing/complementary/independent products are being promoted
simultaneously. The TIM problem is very challenging to solve due to (1) few
existing models can handle the intertwined diffusion procedure of multiple
products concurrently, and (2) optimal seed user selection for the target
product may depend on other products' marketing strategies a lot. To address
the TIM problem, a unified greedy framework TIER (interTwined Influence
EstimatoR) is proposed in this paper. Extensive experiments conducted on four
different types of real-world social networks demonstrate that TIER can
outperform all the comparison methods with significant advantages in solving
the TIM problem.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures, Accepted by ASONAM 2016</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00548</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Object Localization in Visual Situations</dc:title>
 <dc:creator>Quinn, Max H.</dc:creator>
 <dc:creator>Rhodes, Anthony D.</dc:creator>
 <dc:creator>Mitchell, Melanie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We describe a method for performing active localization of objects in
instances of visual situations. A visual situation is an abstract
concept---e.g., &quot;a boxing match&quot;, &quot;a birthday party&quot;, &quot;walking the dog&quot;,
&quot;waiting for a bus&quot;---whose image instantiations are linked more by their
common spatial and semantic structure than by low-level visual similarity. Our
system combines given and learned knowledge of the structure of a particular
situation, and adapts that knowledge to a new situation instance as it actively
searches for objects. More specifically, the system learns a set of probability
distributions describing spatial and other relationships among relevant
objects. The system uses those distributions to iteratively sample object
proposals on a test image, but also continually uses information from those
object proposals to adaptively modify the distributions based on what the
system has detected. We test our approach's ability to efficiently localize
objects, using a situation-specific image dataset created by our group. We
compare the results with several baselines and variations on our method, and
demonstrate the strong benefit of using situation knowledge and active
context-driven localization. Finally, we contrast our method with several other
approaches that use context as well as active search for object localization in
images.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00550</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-Theoretic Lower Bounds on Bayes Risk in Decentralized
  Estimation</dc:title>
 <dc:creator>Xu, Aolin</dc:creator>
 <dc:creator>Raginsky, Maxim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We derive lower bounds on the Bayes risk in decentralized estimation, where
the estimator does not have direct access to the random samples generated
conditionally on the random parameter of interest, but only to the data
received from local processors that observe the samples. The received data are
subject to communication constraints, due to quantization and the noise in the
communication channels from the processors to the estimator. We first derive
general lower bounds on the Bayes risk using information-theoretic quantities,
such as mutual information, information density, small ball probability, and
differential entropy. We then apply these lower bounds to the decentralized
case, using strong data processing inequalities to quantify the contraction of
information due to communication constraints. We treat the cases of a single
processor and of multiple processors, where the samples observed by different
processors may be conditionally dependent given the parameter, for
noninteractive and interactive communication protocols. Our results recover and
improve recent lower bounds on the Bayes risk and the minimax risk for certain
decentralized estimation problems, where previously only conditionally
independent sample sets and noiseless channels have been considered. Moreover,
our results provide a general way to quantify the degradation of estimation
performance caused by distributing resources to multiple processors, which is
only discussed for specific examples in existing works.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00554</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Completely Reachable Automata</dc:title>
 <dc:creator>Bondar, Evgenija</dc:creator>
 <dc:creator>Volkov, Mikhail</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68Q45</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  We present a few results and several open problems concerning complete
deterministic finite automata in which every non-empty subset of the state set
occurs as the image of the whole state set under the action of a suitable input
word.
</dc:description>
 <dc:description>Comment: 23 pages, 12 figures. This is an expanded version of the conference
  paper published in C. Campeanu et al. (eds.), Descriptional Complexity of
  Formal Systems. DCFS 2016 [Lect. Notes Comp. Sci. 9777], Springer-Verlag,
  Berlin-Heidelberg-N.Y., 2016, 1-17</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00556</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alzheimer's Disease Diagnostics by a Deeply Supervised Adaptable 3D
  Convolutional Network</dc:title>
 <dc:creator>Hosseini-Asl, Ehsan</dc:creator>
 <dc:creator>Gimel'farb, Georgy</dc:creator>
 <dc:creator>El-Baz, Ayman</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Early diagnosis, playing an important role in preventing progress and
treating the Alzheimer's disease (AD), is based on classification of features
extracted from brain images. The features have to accurately capture main
AD-related variations of anatomical brain structures, such as, e.g., ventricles
size, hippocampus shape, cortical thickness, and brain volume. This paper
proposes to predict the AD with a deep 3D convolutional neural network
(3D-CNN), which can learn generic features capturing AD biomarkers and adapt to
different domain datasets. The 3D-CNN is built upon a 3D convolutional
autoencoder, which is pre-trained to capture anatomical shape variations in
structural brain MRI scans. Fully connected upper layers of the 3D-CNN are then
fine-tuned for each task-specific AD classification. Experiments on the
\emph{ADNI} MRI dataset with no skull-stripping preprocessing have shown our
3D-CNN outperforms several conventional classifiers by accuracy and robustness.
Abilities of the 3D-CNN to generalize the features learnt and adapt to other
domains have been validated on the \emph{CADDementia} dataset.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00562</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrated Task and Motion Planning for Multiple Robots under Path and
  Communication Uncertainties</dc:title>
 <dc:creator>Woosley, Bradley</dc:creator>
 <dc:creator>Dasgupta, Prithviraj</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We consider a problem called task ordering with path uncertainty (TOP-U)
where multiple robots are provided with a set of task locations to visit in a
bounded environment, but the length of the path between a pair of task
locations is initially known only coarsely by the robots. The objective of the
robots is to find the order of tasks that reduces the path length (or, energy
expended) to visit the task locations in such a scenario. To solve this
problem, we propose an abstraction called a task reachability graph (TRG) that
integrates the task ordering with the path planning by the robots. The TRG is
updated dynamically based on inter-task path costs calculated using a
sampling-based motion planner, and, a Hidden Markov Model (HMM)-based technique
that calculates the belief in the current path costs based on the environment
perceived by the robot's sensors and task completion information received from
other robots. We then describe a Markov Decision Process (MDP)-based algorithm
that can select the paths that reduce the overall path length to visit the task
locations and a coordination algorithm that resolves path conflicts between
robots. We have shown analytically that our task selection algorithm finds the
lowest cost path returned by the motion planner, and, that our proposed
coordination algorithm is deadlock free. We have also evaluated our algorithm
on simulated Corobot robots within different environments while varying the
number of task locations, obstacle geometries and number of robots, as well as
on physical Corobot robots. Our results show that the TRG-based approach can
perform considerably better in planning and locomotion times, and number of
re-plans, while traveling almost-similar distances as compared to a closest
first, no uncertainty (CFNU) task selection algorithm.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00567</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rademacher Complexity Bounds for a Penalized Multiclass Semi-Supervised
  Algorithm</dc:title>
 <dc:creator>Maximov, Yury</dc:creator>
 <dc:creator>Amini, Massih-Reza</dc:creator>
 <dc:creator>Harchaoui, Zaid</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose Rademacher complexity bounds for multiclass classifiers trained
with a two-step semi-supervised model. In the first step, the algorithm
partitions the partially labeled data and then identifies dense clusters
containing $\kappa$ predominant classes using the labeled training examples
such that the proportion of their non-predominant classes is below a fixed
threshold. In the second step, a classifier is trained by minimizing a margin
empirical loss over the labeled training set and a penalization term measuring
the disability of the learner to predict the $\kappa$ predominant classes of
the identified clusters. The resulting data-dependent generalization error
bound involves the margin distribution of the classifier, the stability of the
clustering technique used in the first step and Rademacher complexity terms
corresponding to partially labeled training data. Our theoretical result
exhibit convergence rates extending those proposed in the literature for the
binary case, and experimental results on different multiclass classification
problems show empirical evidence that supports the theory.
</dc:description>
 <dc:description>Comment: 26 pages, 6 figures</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00570</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation learning for very short texts using weighted word
  embedding aggregation</dc:title>
 <dc:creator>De Boom, Cedric</dc:creator>
 <dc:creator>Van Canneyt, Steven</dc:creator>
 <dc:creator>Demeester, Thomas</dc:creator>
 <dc:creator>Dhoedt, Bart</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Short text messages such as tweets are very noisy and sparse in their use of
vocabulary. Traditional textual representations, such as tf-idf, have
difficulty grasping the semantic meaning of such texts, which is important in
applications such as event detection, opinion mining, news recommendation, etc.
We constructed a method based on semantic word embeddings and frequency
information to arrive at low-dimensional representations for short texts
designed to capture semantic similarity. For this purpose we designed a
weight-based model and a learning procedure based on a novel median-based loss
function. This paper discusses the details of our model and the optimization
methods, together with the experimental results on both Wikipedia and Twitter
data. We find that our method outperforms the baseline approaches in the
experiments, and that it generalizes well on different word embeddings without
retraining. Our method is therefore capable of retaining most of the semantic
information in the text, and is applicable out-of-the-box.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, 2 tables, appears in Pattern Recognition Letters</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00570</dc:identifier>
 <dc:identifier>doi:10.1016/j.patrec.2016.06.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00574</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum state and circuit distinguishability with single-qubit
  measurements</dc:title>
 <dc:creator>Morimae, Tomoyuki</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We show that the Quantum State Distinguishability (QSD), which is a
QSZK-complete problem, and the Quantum Circuit Distinguishability (QCD), which
is a QIP-complete problem, can be solved by the verifier who can perform only
single-qubit measurements. To show these results, we use measurement-based
quantum computing: the honest prover sends a graph state to the verifier, and
the verifier can perform universal quantum computing on it with only
single-qubit measurements. If the prover is malicious, he does not necessarily
generate the correct graph state, but the verifier can verify the correctness
of the graph state by measuring the stabilizer operators.
</dc:description>
 <dc:description>Comment: 17 pages, 5 figures</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00575</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Networked MIMO with Fractional Joint Transmission in Energy Harvesting
  Systems</dc:title>
 <dc:creator>Gong, Jie</dc:creator>
 <dc:creator>Zhou, Sheng</dc:creator>
 <dc:creator>Zhou, Zhenyu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers two base stations (BSs) powered by renewable energy
serving two users cooperatively. With different BS energy arrival rates, a
fractional joint transmission (JT) strategy is proposed, which divides each
transmission frame into two subframes. In the first subframe, one BS keeps
silent to store energy while the other transmits data, and then they perform
zero-forcing JT (ZF-JT) in the second subframe. We consider the average
sum-rate maximization problem by optimizing the energy allocation and the time
fraction of ZF-JT in two steps. Firstly, the sum-rate maximization for given
energy budget in each frame is analyzed. We prove that the optimal transmit
power can be derived in closed-form, and the optimal time fraction can be found
via bi-section search. Secondly, approximate dynamic programming (DP) algorithm
is introduced to determine the energy allocation among frames. We adopt a
linear approximation with the features associated with system states, and
determine the weights of features by simulation. We also operate the
approximation several times with random initial policy, named as policy
exploration, to broaden the policy search range. Numerical results show that
the proposed fractional JT greatly improves the performance. Also, appropriate
policy exploration is shown to perform close to the optimal.
</dc:description>
 <dc:description>Comment: 33 pages, 7 figures, accepted by IEEE Transactions on Communications</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00575</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2016.2589267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00577</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hierarchical Distributed Processing Framework for Big Image Data</dc:title>
 <dc:creator>Dong, Le</dc:creator>
 <dc:creator>Lin, Zhiyu</dc:creator>
 <dc:creator>Liang, Yan</dc:creator>
 <dc:creator>He, Ling</dc:creator>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Chen, Qi</dc:creator>
 <dc:creator>Cao, Xiaochun</dc:creator>
 <dc:creator>lzquierdo, Ebroul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces an effective processing framework nominated ICP (Image
Cloud Processing) to powerfully cope with the data explosion in image
processing field. While most previous researches focus on optimizing the image
processing algorithms to gain higher efficiency, our work dedicates to
providing a general framework for those image processing algorithms, which can
be implemented in parallel so as to achieve a boost in time efficiency without
compromising the results performance along with the increasing image scale. The
proposed ICP framework consists of two mechanisms, i.e. SICP (Static ICP) and
DICP (Dynamic ICP). Specifically, SICP is aimed at processing the big image
data pre-stored in the distributed system, while DICP is proposed for dynamic
input. To accomplish SICP, two novel data representations named P-Image and
Big-Image are designed to cooperate with MapReduce to achieve more optimized
configuration and higher efficiency. DICP is implemented through a parallel
processing procedure working with the traditional processing mechanism of the
distributed system. Representative results of comprehensive experiments on the
challenging ImageNet dataset are selected to validate the capacity of our
proposed ICP framework over the traditional state-of-the-art methods, both in
time efficiency and quality of results.
</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00578</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-Dependent Word Representation for Neural Machine Translation</dc:title>
 <dc:creator>Choi, Heeyoul</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We first observe a potential weakness of continuous vector representations of
symbols in neural machine translation. That is, the continuous vector
representation, or a word embedding vector, of a symbol encodes multiple
dimensions of similarity, equivalent to encoding more than one meaning of the
word. This has the consequence that the encoder and decoder recurrent networks
in neural machine translation need to spend substantial amount of their
capacity in disambiguating source and target words based on the context which
is defined by a source sentence. Based on this observation, in this paper we
propose to contextualize the word embedding vectors using a nonlinear
bag-of-words representation of the source sentence. Additionally, we propose to
represent special tokens (such as numbers, proper nouns and acronyms) with
typed symbols to facilitate translating those words that are not well-suited to
be translated via continuous vectors. The experiments on En-Fr and En-De reveal
that the proposed approaches of contextualization and symbolization improves
the translation quality of neural machine translation systems significantly.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00582</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Deeply Supervised Network for Automatic Liver Segmentation from CT
  Volumes</dc:title>
 <dc:creator>Dou, Qi</dc:creator>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Jin, Yueming</dc:creator>
 <dc:creator>Yu, Lequan</dc:creator>
 <dc:creator>Qin, Jing</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic liver segmentation from CT volumes is a crucial prerequisite yet
challenging task for computer-aided hepatic disease diagnosis and treatment. In
this paper, we present a novel 3D deeply supervised network (3D DSN) to address
this challenging task. The proposed 3D DSN takes advantage of a fully
convolutional architecture which performs efficient end-to-end learning and
inference. More importantly, we introduce a deep supervision mechanism during
the learning process to combat potential optimization difficulties, and thus
the model can acquire a much faster convergence rate and more powerful
discrimination capability. On top of the high-quality score map produced by the
3D DSN, a conditional random field model is further employed to obtain refined
segmentation results. We evaluated our framework on the public MICCAI-SLiver07
dataset. Extensive experiments demonstrated that our method achieves
competitive segmentation results to state-of-the-art approaches with a much
faster processing speed.
</dc:description>
 <dc:description>Comment: Accepted to MICCAI 2016</dc:description>
 <dc:date>2016-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00588</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improvement of the Orthogonal Code Convolution Capabilities Using FPGA
  Implementation</dc:title>
 <dc:creator>Kaabouch, Naima</dc:creator>
 <dc:creator>Dhirde, Aparna</dc:creator>
 <dc:creator>Faruque, Saleh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  When data is stored, compressed, or communicated through a media such as
cable or air, sources of noise and other parameters such as EMI, crosstalk, and
distance can considerably affect the reliability of these data. Error detection
and correction techniques are therefore required. Orthogonal Code is one of the
codes that can detect errors and correct corrupted data. An n-bit orthogonal
code has n/2 1s and n/2 0s. In a previous work these properties have been
exploited to detect and correct errors. In this paper we present a new
methodology to enhance error detection capabilities of the orthogonal code. The
technique was implemented experimentally using Field Programmable Gate Arrays
(FPGA). The results show that the proposed technique improves the detection
capabilities of the orthogonal code by approximately 50%, resulting in 99.9%
error detection, and corrects as predicted up to (n/4-1) bits of error in the
received impaired code with bandwidth efficiency.
</dc:description>
 <dc:description>Comment: 5 pages, IEEE Electro/information Technology Conference, 2007</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00588</dc:identifier>
 <dc:identifier>doi:10.1109/EIT.2007.4374465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00589</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analysis System for DNA Gel Electrophoresis Images Based on Automatic
  Thresholding an Enhancement</dc:title>
 <dc:creator>Kaabouch, Naima</dc:creator>
 <dc:creator>Schultz, Richard R.</dc:creator>
 <dc:creator>Milavetz, Barry</dc:creator>
 <dc:creator>Balakrishnan, Lata</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Gel electrophoresis, a widely used technique to separate DNA according to
their size and weight, generates images that can be analyzed automatically.
Manual or semiautomatic image processing presents a bottleneck for further
development and leads to reproducibility issues. In this paper, we present a
fully automated system with high accuracy for analyzing DNA and proteins. The
proposed algorithm consists of four main steps: automatic thresholding,
shifting, filtering, and data processing. Automatic thresholding, used to
equalize the gray values of the gel electrophoresis image background, is one of
the novel operations in this algorithm. Enhancement is also used to improve
poor quality images that have faint DNA bands. Experimental results show that
the proposed technique eliminates defects due to noise for average quality gel
electrophoresis images, while it also improves the quality of poor images.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00589</dc:identifier>
 <dc:identifier>IEEE Electro/Information Technology, 2007</dc:identifier>
 <dc:identifier>doi:10.1109/EIT.2007.4374496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00590</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum Occupancy Measurement: An Autocorrelation based Scanning
  Technique using USRP</dc:title>
 <dc:creator>Subramaniam, Sriram</dc:creator>
 <dc:creator>Reyes, Hector</dc:creator>
 <dc:creator>Kaabouch, Naima</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents a technique for scanning and evaluating the radio
spectrum use. This technique determines the average occupancy of a channel over
a specific duration. The technique was implemented using Software Defined Radio
units and GNU Radio software. The survey was conducted in Grand Forks, North
Dakota, over a frequency range of 824 MHz to 5.8 GHz. The results of this
technique were compared to those of two existing techniques, energy detection
and autocorrelation, that were also implemented. The results show that the
proposed technique is more efficient at scanning the radio spectrum than the
other two techniques.
</dc:description>
 <dc:description>Comment: 5 pages, IEEE Wireless and Microwave Technology Conference (WAMICON),
  2015</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00590</dc:identifier>
 <dc:identifier>doi:10.1109/WAMICON.2015.7120376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00591</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Network Model of the Bit Error Rate for Cognitive Radio
  Networks</dc:title>
 <dc:creator>Reyes, Hector</dc:creator>
 <dc:creator>Subramaniam, Sriram</dc:creator>
 <dc:creator>Kaabouch, Naima</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In addition to serve as platforms for dynamic spectrum access, cognitive
radios can also serve as a method for improving the performance of wireless
communication systems by smartly adjusting their operating parameters according
to the environment and requirements. The uncertainty always present in the
environment makes the practical implementation of the latter application
difficult. In this paper, we propose a probabilistic graphical model, Bayesian
network that captures the causal relationships among the variables bit energy
to noise spectral density ratio (EbN0), carrier to interference ratio (C/I),
modulation scheme (MOD), Doppler phase shift (Dop_Phi), and bit error rate
(BER). BER indicates how the communication link is performing. The goal of our
proposed Bayesian network is to use the BER as evidence in order to infer the
behavior of the other variables, so the cognitive radio can learn how the
conditions of the environment are, and based on that knowledge make better
informed decisions. This model along with the method used to build it are
described in this paper.
</dc:description>
 <dc:description>Comment: 4 pages, IEEE Wireless and Microwave Technology Conference (WAMICON),
  2015</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00591</dc:identifier>
 <dc:identifier>doi:10.1109/WAMICON.2015.7120377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00592</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Techniques for Gridding cDNA Microarray Images</dc:title>
 <dc:creator>Kaabouch, Naima</dc:creator>
 <dc:creator>Shahbazkia, Hamid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Microarray is considered an important instrument and powerful new technology
for large-scale gene sequence and gene expression analysis. One of the major
challenges of this technique is the image processing phase. The accuracy of
this phase has an important impact on the accuracy and effectiveness of the
subsequent gene expression and identification analysis. The processing can be
organized mainly into four steps: gridding, spot isolation, segmentation, and
quantification. Although several commercial software packages are now
available, microarray image analysis still requires some intervention by the
user, and thus a certain level of image processing expertise. This paper
describes and compares four techniques that perform automatic gridding and spot
isolation. The proposed techniques are based on template matching technique,
standard deviation, sum, and derivative of these profiles. Experimental results
show that the accuracy of the derivative of the sum profile is highly accurate
compared to other techniques for good and poor quality microarray images.
</dc:description>
 <dc:description>Comment: 5 pages, IEEE Electro/Information Technology, 2008</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00595</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Residential Demand Response Targeting Using Machine Learning with
  Observational Data</dc:title>
 <dc:creator>Zhou, Datong</dc:creator>
 <dc:creator>Balandat, Maximilian</dc:creator>
 <dc:creator>Tomlin, Claire</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The large scale deployment of Advanced Metering Infrastructure among
residential energy customers has served as a boon for energy systems research
relying on granular consumption data. Residential Demand Response aims to
utilize the flexibility of consumers to reduce their energy usage during times
when the grid is strained. Suitable incentive mechanisms to encourage customers
to deviate from their usual behavior have to be implemented to correctly
control the bids into the wholesale electricity market as a Demand Response
provider. In this paper, we present a framework for short term load forecasting
on an individual user level, and relate nonexperimental estimates of Demand
Response efficacy, i.e. the estimated reduction of consumption during Demand
Response events, to the variability of user consumption. We apply our framework
on a data set from a residential Demand Response program in the Western United
States. Our results suggest that users with more variable consumption patterns
are more likely to reduce their consumption compared to users with a more
regular consumption behavior.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00597</identifier>
 <datestamp>2016-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Performance of DCSK MIMO Relay Cooperative Diversity in
  Nakagami-m and Generalized Gaussian Noise Scenarios</dc:title>
 <dc:creator>Salahat, Ehab</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Chaotic Communications have drawn a great deal of attention to the wireless
communication industry and research due to its limitless meritorious features,
including excellent anti-fading and anti-intercept capabilities and jamming
resistance exempli gratia. Differential Chaos Shift Keying (DCSK) is of
particular interest due to its low-complexity and low-power and many attractive
properties. However, most of the DCSK studies reported in the literature
considered the additive white Gaussian noise environment in non-cooperative
scenarios. Moreover, the analytical derivations and evaluation of the error
rates and other performance metrics are generally left in an integral form and
evaluated using numerical techniques. To circumvent on these issues, this work
is dedicated to present a new approximate error rates analysis of multi-access
multiple-input multiple-output dual-hop relaying DCSK cooperative diversity
(DCSK-CD) in Nakagami-m fading channels (enclosing the Rayleigh fading as a
particular case). Based on this approximation, closed-form expressions for the
average error rates are derived for multiple relaying protocols, namely the
error-free and the decode-and-forward relaying. Testing results validate the
accuracy of the derived analytical expressions.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:date>2016-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00598</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Coarse-to-Fine Indoor Layout Estimation (CFILE) Method</dc:title>
 <dc:creator>Ren, Yuzhuo</dc:creator>
 <dc:creator>Chen, Chen</dc:creator>
 <dc:creator>Li, Shangwen</dc:creator>
 <dc:creator>Kuo, C. -C. Jay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The task of estimating the spatial layout of cluttered indoor scenes from a
single RGB image is addressed in this work. Existing solutions to this problems
largely rely on hand-craft features and vanishing lines, and they often fail in
highly cluttered indoor rooms. The proposed coarse-to-fine indoor layout
estimation (CFILE) method consists of two stages: 1) coarse layout estimation;
and 2) fine layout localization. In the first stage, we adopt a fully
convolutional neural network (FCN) to obtain a coarse-scale room layout
estimate that is close to the ground truth globally. The proposed FCN considers
combines the layout contour property and the surface property so as to provide
a robust estimate in the presence of cluttered objects. In the second stage, we
formulate an optimization framework that enforces several constraints such as
layout contour straightness, surface smoothness and geometric constraints for
layout detail refinement. Our proposed system offers the state-of-the-art
performance on two commonly used benchmark datasets.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00604</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Message Routing in Wireless and Mobile Networks using TDMA Technology</dc:title>
 <dc:creator>Aslanidis, Timotheos</dc:creator>
 <dc:creator>Tsepenekas, Leonidas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In an era where communication has a most important role in modern societies,
designing efficient algorithms for data transmission is of the outmost
importance. TDMA is a technology used in many communication systems such as
satellite, cell phone as well as other wireless or mobile networks. Most 2G
cellular systems as well as some 3G are TDMA based. In order to transmit data
in such systems we need to cluster them in packages. To achieve a faster
transmission we are allowed to preempt the transmission of any packet in order
to resume at a later time. Preemption can be used to reduce idleness of some
stations. Such preemptions though come with a reconfiguration cost in order to
setup for the next transmission. In this paper we propose two algorithms which
yield improved transmission scheduling. These two algorithms we call MGA and
IMGA (Improved MGA). We have proven an approximation ratio for MGA and ran
experiments to establish that it works even better in practice. In order to
conclude that MGA will be a very helpful tool in constructing an improved
schedule for packet routing using preemtion with a setup cost, we compare its
results to two other efficient algorithms designed by researchers in the past:
A-PBS(d+1) and GWA. To establish the efficiency of IMGA we ran experiments in
comparison to MGA as well as A-PBS(d+1) and GWA. IMGA has proven to produce the
most efficient schedule on all counts.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures, 1 table, International Journal of Wireless &amp;
  Mobile Networks (IJWMN), vol. 8, No. 3, June 2016</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00607</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Business Process Mining</dc:title>
 <dc:creator>Pourmasoumi, Asef</dc:creator>
 <dc:creator>Bagheri, Ebrahim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  One of the most valuable assets of an organization is its organizational
data. The analysis and mining of this potential hidden treasure can lead to
much added-value for the organization. Process mining is an emerging area that
can be useful in helping organizations understand the status quo, check for
compliance and plan for improving their processes. The aim of process mining is
to extract knowledge from event logs of today's organizational information
systems. Process mining includes three main types: discovering process models
from event logs, conformance checking and organizational mining. In this paper,
we briefly introduce process mining and review some of its most important
techniques. Also, we investigate some of the applications of process mining in
industry and present some of the most important challenges that are faced in
this area.
</dc:description>
 <dc:description>Comment: 8 pages,6 figures</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00623</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing Natural Language Descriptions: A Survey</dc:title>
 <dc:creator>Hassani, Kaveh</dc:creator>
 <dc:creator>Lee, Won-Sook</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  A natural language interface exploits the conceptual simplicity and
naturalness of the language to create a high-level user-friendly communication
channel between humans and machines. One of the promising applications of such
interfaces is generating visual interpretations of semantic content of a given
natural language that can be then visualized either as a static scene or a
dynamic animation. This survey discusses requirements and challenges of
developing such systems and reports 26 graphical systems that exploit natural
language interfaces and addresses both artificial intelligence and
visualization aspects. This work serves as a frame of reference to researchers
and to enable further advances in the field.
</dc:description>
 <dc:description>Comment: Due to copyright most of the figures only appear in the journal
  version</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00623</dc:identifier>
 <dc:identifier>ACM Computing Surveys, Volume 49 Issue 1, Article No. 17, June
  2016</dc:identifier>
 <dc:identifier>doi:10.1145/2932710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00633</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exception Handling in Logic Programming</dc:title>
 <dc:creator>Kwon, Keehang</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  One of the long-standing problems on logic programming is to express
exception handling in a high-level way. We argue that this problem can be
solved by adopting computability logic and sequential-choice disjunctive goal
formulas of the form $G_0 \bigtriangledown G_1$ where $G_0, G_1$ are goals.
These goals have the following intended semantics: sequentially $choose$ the
first true goal $G_i$ and execute $G_i$ where $i (= 0\ {\rm or}\ 1)$. These
goals thus allow us to specify a task $G_0$ with the failure-handling
(exception handling) routine $G_1$.
</dc:description>
 <dc:description>Comment: 2 pages</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00644</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearest Neighbor-based Rendezvous for Sparsely Connected Mobile Agents</dc:title>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper a convergent, nearest-neighbor, control protocol is suggested
for agents with nontrivial dynamics. The protocol guarantees convergence to a
common point in space even if each agent is restricted to communicate with a
single nearest neighbor. The neighbor, however, is required to lie outside an
arbitrarily small priority zone surrounding the agent. The control protocol
consists of two layers interconnected in a provably-correct manner. The first
layer provides the guidance signal to a rendezvous point assuming that the
agents have first order dynamics. The other layer converts in a decentralized
manner the guidance signal to a control signal that suits realistic agents such
as UGVs, UAVs and holonomic agents with second order dynamics.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00644</dc:identifier>
 <dc:identifier>ASME. J. Dyn. Sys., Meas., Control. 2015;137(12):121002-121002-18</dc:identifier>
 <dc:identifier>doi:10.1115/1.4031248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00647</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Point-of-interest Recommendation in Location-based Social
  Networks</dc:title>
 <dc:creator>Zhao, Shenglin</dc:creator>
 <dc:creator>King, Irwin</dc:creator>
 <dc:creator>Lyu, Michael R.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Point-of-interest (POI) recommendation that suggests new places for users to
visit arises with the popularity of location-based social networks (LBSNs). Due
to the importance of POI recommendation in LBSNs, it has attracted much
academic and industrial interest. In this paper, we offer a systematic review
of this field, summarizing the contributions of individual efforts and
exploring their relations. We discuss the new properties and challenges in POI
recommendation, compared with traditional recommendation problems, e.g., movie
recommendation. Then, we present a comprehensive review in three aspects:
influential factors for POI recommendation, methodologies employed for POI
recommendation, and different tasks in POI recommendation. Specifically, we
propose three taxonomies to classify POI recommendation systems. First, we
categorize the systems by the influential factors check-in characteristics,
including the geographical information, social relationship, temporal
influence, and content indications. Second, we categorize the systems by the
methodology, including systems modeled by fused methods and joint methods.
Third, we categorize the systems as general POI recommendation and successive
POI recommendation by subtle differences in the recommendation task whether to
be bias to the recent check-in. For each category, we summarize the
contributions and system features, and highlight the representative work.
Moreover, we discuss the available data sets and the popular metrics. Finally,
we point out the possible future directions in this area and conclude this
survey.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00648</identifier>
 <datestamp>2017-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasi-matrix-free hybrid multigrid on dynamically adaptive Cartesian
  grids</dc:title>
 <dc:creator>Weinzierl, Marion</dc:creator>
 <dc:creator>Weinzierl, Tobias</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>97N80, 65M50, 65N50, 68W10, 65M55</dc:subject>
 <dc:description>  We present a family of spacetree-based multigrid realizations using the
tree's multiscale nature to derive coarse grids. They align with matrix-free
geometric multigrid solvers as they never assemble the system matrices which is
cumbersome for dynamically adaptive grids and full multigrid. The most
sophisticated realizations use BoxMG to construct operator-dependent
prolongation and restriction in combination with Galerkin/Petrov-Galerkin
coarse-grid operators. This yields robust solvers for nontrivial elliptic
problems. We embed the algebraic, problem- and grid-dependent multigrid
operators as stencils into the grid and evaluate all matrix-vector products
in-situ throughout the grid traversals. While such an approach is not literally
matrix-free---the grid carries the matrix---we propose to switch to a
hierarchical representation of all operators. Only differences of algebraic
operators to their geometric counterparts are held. These hierarchical
differences can be stored and exchanged with small memory footprint. Our
realizations support arbitrary dynamically adaptive grids while they vertically
integrate the multilevel operations through spacetree linearization. This
yields good memory access characteristics, while standard colouring of mesh
entities with domain decomposition allows us to use parallel manycore clusters.
All realization ingredients are detailed such that they can be used by other
codes.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00653</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>node2vec: Scalable Feature Learning for Networks</dc:title>
 <dc:creator>Grover, Aditya</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Prediction tasks over nodes and edges in networks require careful effort in
engineering features used by learning algorithms. Recent research in the
broader field of representation learning has led to significant progress in
automating prediction by learning the features themselves. However, present
feature learning approaches are not expressive enough to capture the diversity
of connectivity patterns observed in networks. Here we propose node2vec, an
algorithmic framework for learning continuous feature representations for nodes
in networks. In node2vec, we learn a mapping of nodes to a low-dimensional
space of features that maximizes the likelihood of preserving network
neighborhoods of nodes. We define a flexible notion of a node's network
neighborhood and design a biased random walk procedure, which efficiently
explores diverse neighborhoods. Our algorithm generalizes prior work which is
based on rigid notions of network neighborhoods, and we argue that the added
flexibility in exploring neighborhoods is the key to learning richer
representations. We demonstrate the efficacy of node2vec over existing
state-of-the-art techniques on multi-label classification and link prediction
in several real-world networks from diverse domains. Taken together, our work
represents a new way for efficiently learning state-of-the-art task-independent
representations in complex networks.
</dc:description>
 <dc:description>Comment: In Proceedings of the 22nd ACM SIGKDD International Conference on
  Knowledge Discovery and Data Mining, 2016</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00655</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The End of a Myth: Distributed Transactions Can Scale</dc:title>
 <dc:creator>Zamanian, Erfan</dc:creator>
 <dc:creator>Binnig, Carsten</dc:creator>
 <dc:creator>Kraska, Tim</dc:creator>
 <dc:creator>Harris, Tim</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The common wisdom is that distributed transactions do not scale. But what if
distributed transactions could be made scalable using the next generation of
networks and a redesign of distributed databases? There would be no need for
developers anymore to worry about co-partitioning schemes to achieve decent
performance. Application development would become easier as data placement
would no longer determine how scalable an application is. Hardware provisioning
would be simplified as the system administrator can expect a linear scale-out
when adding more machines rather than some complex sub-linear function, which
is highly application specific.
  In this paper, we present the design of our novel scalable database system
NAM-DB and show that distributed transactions with the very common Snapshot
Isolation guarantee can indeed scale using the next generation of RDMA-enabled
network technology without any inherent bottlenecks. Our experiments with the
TPC-C benchmark show that our system scales linearly to over 6.5 million
new-order (14.5 million total) distributed transactions per second on 56
machines.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00656</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hybrid POMDP-BDI Agent Architecture with Online Stochastic Planning
  and Plan Caching</dc:title>
 <dc:creator>Rens, Gavin</dc:creator>
 <dc:creator>Moodley, Deshendran</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This article presents an agent architecture for controlling an autonomous
agent in stochastic environments. The architecture combines the partially
observable Markov decision process (POMDP) model with the
belief-desire-intention (BDI) framework. The Hybrid POMDP-BDI agent
architecture takes the best features from the two approaches, that is, the
online generation of reward-maximizing courses of action from POMDP theory, and
sophisticated multiple goal management from BDI theory. We introduce the
advances made since the introduction of the basic architecture, including (i)
the ability to pursue multiple goals simultaneously and (ii) a plan library for
storing pre-written plans and for storing recently generated plans for future
reuse. A version of the architecture without the plan library is implemented
and is evaluated using simulations. The results of the simulation experiments
indicate that the approach is feasible.
</dc:description>
 <dc:description>Comment: 26 pages, 3 figures, unpublished version</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00658</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity and Computation of Connected Zero Forcing</dc:title>
 <dc:creator>Brimkov, Boris</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C15</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Zero forcing is an iterative graph coloring process whereby a colored vertex
with a single uncolored neighbor forces that neighbor to be colored. It is
NP-hard to find a minimum zero forcing set - a smallest set of initially
colored vertices which forces the entire graph to be colored. We show that the
problem remains NP-hard when the initially colored set induces a connected
subgraph. We also give structural results about the connected zero forcing sets
of a graph related to the graph's density, separating sets, and certain induced
subgraphs, and we characterize the cardinality of the minimum connected zero
forcing sets of unicyclic graphs and variants of cactus and block graphs.
Finally, we identify several families of graphs whose connected zero forcing
sets define greedoids and matroids.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00659</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Deep Appearance Models</dc:title>
 <dc:creator>Quach, Kha Gia</dc:creator>
 <dc:creator>Duong, Chi Nhan</dc:creator>
 <dc:creator>Luu, Khoa</dc:creator>
 <dc:creator>Bui, Tien D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel Robust Deep Appearance Models to learn the
non-linear correlation between shape and texture of face images. In this
approach, two crucial components of face images, i.e. shape and texture, are
represented by Deep Boltzmann Machines and Robust Deep Boltzmann Machines
(RDBM), respectively. The RDBM, an alternative form of Robust Boltzmann
Machines, can separate corrupted/occluded pixels in the texture modeling to
achieve better reconstruction results. The two models are connected by
Restricted Boltzmann Machines at the top layer to jointly learn and capture the
variations of both facial shapes and appearances. This paper also introduces
new fitting algorithms with occlusion awareness through the mask obtained from
the RDBM reconstruction. The proposed approach is evaluated in various
applications by using challenging face datasets, i.e. Labeled Face Parts in the
Wild (LFPW), Helen, EURECOM and AR databases, to demonstrate its robustness and
capabilities.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, submitted to ICPR 2016</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00662</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of 3D Structure from Images</dc:title>
 <dc:creator>Rezende, Danilo Jimenez</dc:creator>
 <dc:creator>Eslami, S. M. Ali</dc:creator>
 <dc:creator>Mohamed, Shakir</dc:creator>
 <dc:creator>Battaglia, Peter</dc:creator>
 <dc:creator>Jaderberg, Max</dc:creator>
 <dc:creator>Heess, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A key goal of computer vision is to recover the underlying 3D structure from
2D observations of the world. In this paper we learn strong deep generative
models of 3D structures, and recover these structures from 3D and 2D images via
probabilistic inference. We demonstrate high-quality samples and report
log-likelihoods on several datasets, including ShapeNet [2], and establish the
first benchmarks in the literature. We also show how these models and their
inference networks can be trained end-to-end from 2D images. This demonstrates
for the first time the feasibility of learning to infer 3D representations of
the world in a purely unsupervised manner.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00667</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reducing the Energy Cost of Inference via In-sensor Information
  Processing</dc:title>
 <dc:creator>Zhang, Sai</dc:creator>
 <dc:creator>Kang, Mingu</dc:creator>
 <dc:creator>Sakr, Charbel</dc:creator>
 <dc:creator>Shanbhag, Naresh</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  There is much interest in incorporating inference capabilities into
sensor-rich embedded platforms such as autonomous vehicles, wearables, and
others. A central problem in the design of such systems is the need to extract
information locally from sensed data on a severely limited energy budget. This
necessitates the design of energy-efficient sensory embedded system. A typical
sensory embedded system enforces a physical separation between sensing and
computational subsystems - a separation mandated by the differing requirements
of the sensing and computational functions. As a consequence, the energy
consumption in such systems tends to be dominated by the energy consumed in
transferring data over the sensor-processor interface (communication energy)
and the energy consumed in processing the data in digital processor
(computational energy). In this article, we propose an in-sensor computing
architecture which (mostly) eliminates the sensor-processor interface by
embedding inference computations in the noisy sensor fabric in analog and
retraining the hyperparameters in order to compensate for non-ideal
computations. The resulting architecture referred to as the Compute Sensor - a
sensor that computes in addition to sensing - represents a radical departure
from the conventional. We show that a Compute Sensor for image data can be
designed by embedding both feature extraction and classification functions in
the analog domain in close proximity to the CMOS active pixel sensor (APS)
array. Significant gains in energy-efficiency are demonstrated using behavioral
and energy models in a commercial semiconductor process technology. In the
process, the Compute Sensor creates a unique opportunity to develop machine
learning algorithms for information extraction from data on a noisy underlying
computational fabric.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00669</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding the Energy and Precision Requirements for Online Learning</dc:title>
 <dc:creator>Sakr, Charbel</dc:creator>
 <dc:creator>Patil, Ameya</dc:creator>
 <dc:creator>Zhang, Sai</dc:creator>
 <dc:creator>Kim, Yongjune</dc:creator>
 <dc:creator>Shanbhag, Naresh</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  It is well-known that the precision of data, hyperparameters, and internal
representations employed in learning systems directly impacts its energy,
throughput, and latency. The precision requirements for the training algorithm
are also important for systems that learn on-the-fly. Prior work has shown that
the data and hyperparameters can be quantized heavily without incurring much
penalty in classification accuracy when compared to floating point
implementations. These works suffer from two key limitations. First, they
assume uniform precision for the classifier and for the training algorithm and
thus miss out on the opportunity to further reduce precision. Second, prior
works are empirical studies. In this article, we overcome both these
limitations by deriving analytical lower bounds on the precision requirements
of the commonly employed stochastic gradient descent (SGD) on-line learning
algorithm in the specific context of a support vector machine (SVM). Lower
bounds on the data precision are derived in terms of the the desired
classification accuracy and precision of the hyperparameters used in the
classifier. Additionally, lower bounds on the hyperparameter precision in the
SGD training algorithm are obtained. These bounds are validated using both
synthetic and the UCI breast cancer dataset. Additionally, the impact of these
precisions on the energy consumption of a fixed-point SVM with on-line training
is studied.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures 4 of which have 2 subfigures</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00675</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical physics of linear and bilinear inference problems</dc:title>
 <dc:creator>Sch&#xfc;lke, Christophe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The recent development of compressed sensing has led to spectacular advances
in the understanding of sparse linear estimation problems as well as in
algorithms to solve them. It has also triggered a new wave of developments in
the related fields of generalized linear and bilinear inference problems, that
have very diverse applications in signal processing and are furthermore a
building block of deep neural networks. These problems have in common that they
combine a linear mixing step and a nonlinear, probabilistic sensing step,
producing indirect measurements of a signal of interest. Such a setting arises
in problems as different as medical or astronomical imaging, clustering, matrix
completion or blind source separation. The aim of this thesis is to propose
efficient algorithms for this class of problems and to perform their
theoretical analysis. To this end, it uses belief propagation, thanks to which
high-dimensional distributions can be sampled efficiently, thus making a
Bayesian approach to inference tractable. The resulting algorithms undergo
phase transitions just as physical systems do. These phase transitions can be
analyzed using the replica method, initially developed in statistical physics
of disordered systems. The analysis reveals phases in which inference is easy,
hard or impossible. These phases correspond to different energy landscapes of
the problem. The main contributions of this thesis can be divided into three
categories. First, the application of known algorithms to concrete problems:
community detection, superposition codes and an innovative imaging system.
Second, a new, efficient message-passing algorithm for a class of problems
called blind sensor calibration. Third, a theoretical analysis of matrix
compressed sensing and of instabilities in Bayesian bilinear inference
algorithms.
</dc:description>
 <dc:description>Comment: Phd thesis</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00678</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing the Expected Mean Payoff in Energy Markov Decision Processes</dc:title>
 <dc:creator>Br&#xe1;zdil, Tom&#xe1;&#x161;</dc:creator>
 <dc:creator>Ku&#x10d;era, Anton&#xed;n</dc:creator>
 <dc:creator>Novotn&#xfd;, Petr</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Energy Markov Decision Processes (EMDPs) are finite-state Markov decision
processes where each transition is assigned an integer counter update and a
rational payoff. An EMDP configuration is a pair s(n), where s is a control
state and n is the current counter value. The configurations are changed by
performing transitions in the standard way. We consider the problem of
computing a safe strategy (i.e., a strategy that keeps the counter
non-negative) which maximizes the expected mean payoff.
</dc:description>
 <dc:description>Comment: Full version of a paper published in proceedings of ATVA'16</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00695</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can we reach Pareto optimal outcomes using bottom-up approaches?</dc:title>
 <dc:creator>Sanchez-Anguix, Victor</dc:creator>
 <dc:creator>Aydogan, Reyhan</dc:creator>
 <dc:creator>Baarslag, Tim</dc:creator>
 <dc:creator>Jonker, Catholijn M.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  Traditionally, researchers in decision making have focused on attempting to
reach Pareto Optimality using horizontal approaches, where optimality is
calculated taking into account every participant at the same time. Sometimes,
this may prove to be a difficult task (e.g., conflict, mistrust, no information
sharing, etc.). In this paper, we explore the possibility of achieving Pareto
Optimal outcomes in a group by using a bottom-up approach: discovering Pareto
optimal outcomes by interacting in subgroups. We analytically show that Pareto
optimal outcomes in a subgroup are also Pareto optimal in a supergroup of those
agents in the case of strict, transitive, and complete preferences. Then, we
empirically analyze the prospective usability and practicality of bottom-up
approaches in a variety of decision making domains.
</dc:description>
 <dc:description>Comment: 2nd Workshop on Conflict Resolution in Decision Making
  (COREDEMA@ECAI2016)</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00697</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural ideals and stimulus space visualization</dc:title>
 <dc:creator>Gross, Elizabeth</dc:creator>
 <dc:creator>Obatake, Nida Kazi</dc:creator>
 <dc:creator>Youngs, Nora</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:description>  A neural code $\mathcal{C}$ is a collection of binary vectors of a given
length n that record the co-firing patterns of a set of neurons. Our focus is
on neural codes arising from place cells, neurons that respond to geographic
stimulus. In this setting, the stimulus space can be visualized as subset of
$\mathbb{R}^2$ covered by a collection $\mathcal{U}$ of convex sets such that
the arrangement $\mathcal{U}$ forms an Euler diagram for $\mathcal{C}$. There
are some methods to determine whether such a convex realization $\mathcal{U}$
exists; however, these methods do not describe how to draw a realization. In
this work, we look at the problem of algorithmically drawing Euler diagrams for
neural codes using two polynomial ideals: the neural ideal, a pseudo-monomial
ideal; and the neural toric ideal, a binomial ideal. In particular, we study
how these objects are related to the theory of piercings in information
visualization, and we show how minimal generating sets of the ideals reveal
whether or not a code is $0$, $1$, or $2$-inductively pierced.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00711</identifier>
 <datestamp>2017-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Energy Allocation For Delay-Constrained Traffic Over Fading
  Multiple Access Channels</dc:title>
 <dc:creator>Girgis, Antonious M.</dc:creator>
 <dc:creator>El-Keyi, Amr</dc:creator>
 <dc:creator>Nafie, Mohammed</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider a multiple-access fading channel where $N$ users
transmit to a single base station (BS) within a limited number of time slots.
We assume that each user has a fixed amount of energy available to be consumed
over the transmission window. We derive the optimal energy allocation policy
for each user that maximizes the total system throughput under two different
assumptions on the channel state information. First, we consider the offline
allocation problem where the channel states are known a priori before
transmission. We solve a convex optimization problem to maximize the
sum-throughput under energy and delay constraints. Next, we consider the online
allocation problem, where the channels are causally known to the BS and obtain
the optimal energy allocation via dynamic programming when the number of users
is small. We also develop a suboptimal resource allocation algorithm whose
performance is close to the optimal one. Numerical results are presented
showing the superiority of the proposed algorithms over baseline algorithms in
various scenarios.
</dc:description>
 <dc:description>Comment: IEEE Global Communications Conference: Wireless Communications
  (Globecom2016 WC)</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:date>2016-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00711</dc:identifier>
 <dc:identifier>doi:10.1109/GLOCOM.2016.7842084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00714</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Modeling of Hybrid Cache Systems</dc:title>
 <dc:creator>Ju, Gaoying</dc:creator>
 <dc:creator>Li, Yongkun</dc:creator>
 <dc:creator>Xu, Yinlong</dc:creator>
 <dc:creator>Chen, Jiqiang</dc:creator>
 <dc:creator>Lui, John C. S.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  In recent years, there is an increasing demand of big memory systems so to
perform large scale data analytics. Since DRAM memories are expensive, some
researchers are suggesting to use other memory systems such as non-volatile
memory (NVM) technology to build large-memory computing systems. However,
whether the NVM technology can be a viable alternative (either economically and
technically) to DRAM remains an open question. To answer this question, it is
important to consider how to design a memory system from a &quot;system
perspective&quot;, that is, incorporating different performance characteristics and
price ratios from hybrid memory devices.
  This paper presents an analytical model of a &quot;hybrid page cache system&quot; so to
understand the diverse design space and performance impact of a hybrid cache
system. We consider (1) various architectural choices, (2) design strategies,
and (3) configuration of different memory devices. Using this model, we provide
guidelines on how to design hybrid page cache to reach a good trade-off between
high system throughput (in I/O per sec or IOPS) and fast cache reactivity which
is defined by the time to fill the cache. We also show how one can configure
the DRAM capacity and NVM capacity under a fixed budget. We pick PCM as an
example for NVM and conduct numerical analysis. Our analysis indicates that
incorporating PCM in a page cache system significantly improves the system
performance, and it also shows larger benefit to allocate more PCM in page
cache in some cases. Besides, for the common setting of performance-price ratio
of PCM, &quot;flat architecture&quot; offers as a better choice, but &quot;layered
architecture&quot; outperforms if PCM write performance can be significantly
improved in the future.
</dc:description>
 <dc:description>Comment: 14 pages; mascots 2016</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00715</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Path planning with Inventory-driven Jump-Point-Search</dc:title>
 <dc:creator>Aversa, Davide</dc:creator>
 <dc:creator>Sardina, Sebastian</dc:creator>
 <dc:creator>Vassos, Stavros</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In many navigational domains the traversability of cells is conditioned on
the path taken. This is often the case in video-games, in which a character may
need to acquire a certain object (i.e., a key or a flying suit) to be able to
traverse specific locations (e.g., doors or high walls). In order for
non-player characters to handle such scenarios we present invJPS, an
&quot;inventory-driven&quot; pathfinding approach based on the highly successful
grid-based Jump-Point-Search (JPS) algorithm. We show, formally and
experimentally, that the invJPS preserves JPS's optimality guarantees and its
symmetry breaking advantages in inventory-based variants of game maps.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00715</dc:identifier>
 <dc:identifier>In Proceedings of the AAAI Conference on Artificial Intelligence
  and Interactive Digital Entertainment (AIIDE), pp. 2-8, 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00718</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent
  Unit for Summarization</dc:title>
 <dc:creator>Kim, Minsoo</dc:creator>
 <dc:creator>Singh, Moirangthem Dennis</dc:creator>
 <dc:creator>Lee, Minho</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this work, we introduce temporal hierarchies to the sequence to sequence
(seq2seq) model to tackle the problem of abstractive summarization of
scientific articles. The proposed Multiple Timescale model of the Gated
Recurrent Unit (MTGRU) is implemented in the encoder-decoder setting to better
deal with the presence of multiple compositionalities in larger texts. The
proposed model is compared to the conventional RNN encoder-decoder, and the
results demonstrate that our model trains faster and shows significant
performance gains. The results also show that the temporal hierarchies help
improve the ability of seq2seq models to capture compositionalities better
without the presence of highly complex architectural hierarchies.
</dc:description>
 <dc:description>Comment: To appear in RepL4NLP at ACL 2016</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00719</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coarse2Fine: Two-Layer Fusion For Image Retrieval</dc:title>
 <dc:creator>Kong, Gaipeng</dc:creator>
 <dc:creator>Dong, Le</dc:creator>
 <dc:creator>Dong, Wenpu</dc:creator>
 <dc:creator>Zheng, Liang</dc:creator>
 <dc:creator>Tian, Qi</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper addresses the problem of large-scale image retrieval. We propose a
two-layer fusion method which takes advantage of global and local cues and
ranks database images from coarse to fine (C2F). Departing from the previous
methods fusing multiple image descriptors simultaneously, C2F is featured by a
layered procedure composed by filtering and refining. In particular, C2F
consists of three components. 1) Distractor filtering. With holistic
representations, noise images are filtered out from the database, so the number
of candidate images to be used for comparison with the query can be greatly
reduced. 2) Adaptive weighting. For a certain query, the similarity of
candidate images can be estimated by holistic similarity scores in
complementary to the local ones. 3) Candidate refining. Accurate retrieval is
conducted via local features, combining the pre-computed adaptive weights.
Experiments are presented on two benchmarks, \emph{i.e.,} Holidays and Ukbench
datasets. We show that our method outperforms recent fusion methods in terms of
storage consumption and computation complexity, and that the accuracy is
competitive to the state-of-the-arts.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00720</identifier>
 <datestamp>2016-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Evaluation Of Social Influence Metrics</dc:title>
 <dc:creator>Kumar, Nikhil</dc:creator>
 <dc:creator>Guo, Ruocheng</dc:creator>
 <dc:creator>Aleali, Ashkan</dc:creator>
 <dc:creator>Shakarian, Paulo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Predicting when an individual will adopt a new behavior is an important
problem in application domains such as marketing and public health. This paper
examines the perfor- mance of a wide variety of social network based
measurements proposed in the literature - which have not been previously
compared directly. We study the probability of an individual becoming
influenced based on measurements derived from neigh- borhood (i.e. number of
influencers, personal network exposure), structural diversity, locality,
temporal measures, cascade mea- sures, and metadata. We also examine the
ability to predict influence based on choice of classifier and how the ratio of
positive to negative samples in both training and testing affect prediction
results - further enabling practical use of these concepts for social influence
applications.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:date>2016-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00729</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retrofitting mutual authentication to GSM using RAND hijacking</dc:title>
 <dc:creator>Khan, Mohammed Shafiul Alam</dc:creator>
 <dc:creator>Mitchell, Chris J</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  As has been widely discussed, the GSM mobile telephony system only offers
unilateral authentication of the mobile phone to the network; this limitation
permits a range of attacks. While adding support for mutual authentication
would be highly beneficial, changing the way GSM serving networks operate is
not practical. This paper proposes a novel modification to the relationship
between a Subscriber Identity Module (SIM) and its home network which allows
mutual authentication without changing any of the existing mobile
infrastructure, including the phones; the only necessary changes are to the
authentication centres and the SIMs. This enhancement, which could be deployed
piecemeal in a completely transparent way, not only addresses a number of
serious vulnerabilities in GSM but is also the first proposal for enhancing GSM
authentication that possesses such transparency properties.
</dc:description>
 <dc:description>Comment: 17 pages, 2 figures</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00730</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Two-Streamed Network for Estimating Fine-Scaled Depth Maps from Single
  RGB Images</dc:title>
 <dc:creator>Li, Jun</dc:creator>
 <dc:creator>Klein, Reinhard</dc:creator>
 <dc:creator>Yao, Angela</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Estimating depth from a single RGB image is an ill-posed and inherently
ambiguous problem. State-of-the-art deep learning methods can now estimate
accurate 2D depth maps, but when the maps are projected into 3D, they lack
local detail and are often highly distorted. We propose a fast-to-train
two-streamed CNN that predicts depth and depth gradients, which are then fused
together into an accurate and detailed depth map. We also define a novel set
loss over multiple images; by regularizing the estimation between a common set
of images, the network is less prone to over-fitting and achieves better
accuracy than competing methods. Experiments on the NYU Depth v2 dataset shows
that our depth predictions are competitive with state-of-the-art and lead to
faithful 3D projections.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00762</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Constrained Coding Scheme for Correcting Asymmetric Magnitude-$1$
  Errors in $q$-ary Channels</dc:title>
 <dc:creator>Hemo, Evyatar</dc:creator>
 <dc:creator>Cassuto, Yuval</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present a constraint-coding scheme to correct asymmetric magnitude-$1$
errors in multi-level non-volatile memories. For large numbers of such errors,
the scheme is shown to deliver better correction capability compared to known
alternatives, while admitting low-complexity of decoding. Our results include
an algebraic formulation of the constraint, necessary and sufficient conditions
for correctability, a maximum-likelihood decoder running in complexity linear
in the alphabet size, and upper bounds on the probability of failing to correct
$t$ errors. Besides the superior rate-correction tradeoff, another advantage of
this scheme over standard error-correcting codes is the flexibility to vary the
code parameters without significant modifications.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00762</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00765</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Objective Design of State Feedback Controllers Using Reinforced
  Quantum-Behaved Particle Swarm Optimization</dc:title>
 <dc:creator>Hassani, Kaveh</dc:creator>
 <dc:creator>Lee, Won-Sook</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, a novel and generic multi-objective design paradigm is
proposed which utilizes quantum-behaved PSO(QPSO) for deciding the optimal
configuration of the LQR controller for a given problem considering a set of
competing objectives. There are three main contributions introduced in this
paper as follows. (1) The standard QPSO algorithm is reinforced with an
informed initialization scheme based on the simulated annealing algorithm and
Gaussian neighborhood selection mechanism. (2) It is also augmented with a
local search strategy which integrates the advantages of memetic algorithm into
conventional QPSO. (3) An aggregated dynamic weighting criterion is introduced
that dynamically combines the soft and hard constraints with control objectives
to provide the designer with a set of Pareto optimal solutions and lets her to
decide the target solution based on practical preferences. The proposed method
is compared against a gradient-based method, seven meta-heuristics, and the
trial-and-error method on two control benchmarks using sensitivity analysis and
full factorial parameter selection and the results are validated using
one-tailed T-test. The experimental results suggest that the proposed method
outperforms opponent methods in terms of controller effort, measures associated
with transient response and criteria related to steady-state.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00765</dc:identifier>
 <dc:identifier>Applied Soft Computing, 41, pp. 66-76, 2016</dc:identifier>
 <dc:identifier>doi:10.1016/j.asoc.2015.12.024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00771</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OpenGeoBase: Information Centric Networking meets Spatial Database
  applications - Extended Version</dc:title>
 <dc:creator>Detti, Andrea</dc:creator>
 <dc:creator>Melazzi, Nicola Blefari</dc:creator>
 <dc:creator>Orru, Michele</dc:creator>
 <dc:creator>Paolillo, Riccardo</dc:creator>
 <dc:creator>Rossi, Giulio</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper explores methodologies, advantages and challenges related to the
use of Information Centric Networking (ICN) for realizing distributed spatial
databases. Our findings show that the ICN functionality perfectly fits database
requirements: routing-by-name can be used to dispatch queries and insertions,
in-network caching to accelerate queries, and data-centric security to
implement secure multi-tenancy. We present an ICN-based distributed spatial
database, named OpenGeoBase, and describe its design choices. Thanks to ICN,
OpenGeoBase can quickly and efficiently provide information to database users;
easily operate in a distributed way, deploying and using many database engines
in parallel; secure every piece of content; naturally slice resources, so that
several tenants and users can concurrently and independently use the database.
We also show how OpenGeoBase can support a real world Intelligent Transport
System application, by enabling discovery of geo-referenced public
transportation information.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00773</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Echo State Networks for Proactive Caching in Cloud-Based Radio Access
  Networks with Mobile Users</dc:title>
 <dc:creator>Chen, Mingzhe</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Yin, Changchuan</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, the problem of proactive caching is studied for cloud radio
access networks (CRANs). In the studied model, the baseband units (BBUs) can
predict the content request distribution and mobility pattern of each user,
determine which content to cache at remote radio heads and BBUs. This problem
is formulated as an optimization problem which jointly incorporates backhaul
and fronthaul loads and content caching. To solve this problem, an algorithm
that combines the machine learning framework of echo state networks with
sublinear algorithms is proposed. Using echo state networks (ESNs), the BBUs
can predict each user's content request distribution and mobility pattern while
having only limited information on the network's and user's state. In order to
predict each user's periodic mobility pattern with minimal complexity, the
memory capacity of the corresponding ESN is derived for a periodic input. This
memory capacity is shown to be able to record the maximum amount of user
information for the proposed ESN model. Then, a sublinear algorithm is proposed
to determine which content to cache while using limited content request
distribution samples. Simulation results using real data from Youku and the
Beijing University of Posts and Telecommunications show that the proposed
approach yields significant gains, in terms of sum effective capacity, that
reach up to 27.8% and 30.7%, respectively, compared to random caching with
clustering and random caching without clustering algorithm.
</dc:description>
 <dc:description>Comment: Accepted in the IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00782</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-driven Access Control in Social Networks by Means of Automatic
  Semantic Annotation</dc:title>
 <dc:creator>Imran-Daud, Malik</dc:creator>
 <dc:creator>S&#xe1;nchez, David</dc:creator>
 <dc:creator>Viejo, Alexandre</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In online social networks (OSN), users quite usually disclose sensitive
information about themselves by publishing messages. At the same time, they are
(in many cases) unable to properly manage the access to this sensitive
information due to the following issues: i) the rigidness of the access control
mechanism implemented by the OSN, and ii) many users lack of technical
knowledge about data privacy and access control. To tackle these limitations,
in this paper, we propose a dynamic, transparent and privacy-driven access
control mechanism for textual messages published in OSNs. The notion of
privacy-driven is achieved by analyzing the semantics of the messages to be
published and, according to that, assessing the degree of sensitiveness of
their contents. For this purpose, the proposed system relies on an automatic
semantic annotation mechanism that, by using knowledge bases and linguistic
tools, is able to associate a meaning to the information to be published. By
means of this annotation, our mechanism automatically detects the information
that is sensitive according to the privacy requirements of the publisher of
data, with regard to the type of reader that may access such data. Finally, our
access control mechanism automatically creates sanitized versions of the users'
publications according to the type of reader that accesses them. As a result,
our proposal, which can be integrated in already existing social networks,
provides an automatic, seamless and content-driven protection of user
publications, which are coherent with her privacy requirements and the type of
readers that access them. Complementary to the system design, we also discuss
the feasibility of the system by illustrating it through a real example and
evaluate its accuracy and effectiveness over standard approaches.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00782</dc:identifier>
 <dc:identifier>Computer Communications 76: 12-25 (2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.comcom.2016.01.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00791</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal analysis of HTM Spatial Pooler performance under predefined
  operation conditions</dc:title>
 <dc:creator>Pietron, M.</dc:creator>
 <dc:creator>Wielgosz, M.</dc:creator>
 <dc:creator>Wiatr, K.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper introduces mathematical formalism for Spatial (SP) of Hierarchical
Temporal Memory (HTM) with a spacial consideration for its hardware
implementation. Performance of HTM network and its ability to learn and adjust
to a problem at hand is governed by a large set of parameters. Most of
parameters are codependent which makes creating efficient HTM-based solutions
challenging. It requires profound knowledge of the settings and their impact on
the performance of system. Consequently, this paper introduced a set of
formulas which are to facilitate the design process by enhancing tedious
trial-and-error method with a tool for choosing initial parameters which enable
quick learning convergence. This is especially important in hardware
implementations which are constrained by the limited resources of a platform.
The authors focused especially on a formalism of Spatial Pooler and derive at
the formulas for quality and convergence of the model. This may be considered
as recipes for designing efficient HTM models for given input patterns.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00800</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Message Passing Iterative Detection for MIMO-NOMA Systems with
  Massive Access</dc:title>
 <dc:creator>Liu, Lei</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:creator>Guan, Yong Liang</dc:creator>
 <dc:creator>Li, Ying</dc:creator>
 <dc:creator>Huang, Chongwen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers a low-complexity Gaussian Message Passing Iterative
Detection (GMPID) algorithm for Multiple-Input Multiple-Output systems with
Non-Orthogonal Multiple Access (MIMO-NOMA), in which a base station with $N_r$
antennas serves $N_u$ sources simultaneously. Both $N_u$ and $N_r$ are very
large numbers and we consider the cases that $N_u&gt;N_r$. The GMPID is based on a
fully connected loopy graph, which is well understood to be not convergent in
some cases. The large-scale property of the MIMO-NOMA is used to simplify the
convergence analysis. Firstly, we prove that the variances of the GMPID
definitely converge to that of Minimum Mean Square Error (MMSE) detection.
Secondly, two sufficient conditions that the means of the GMPID converge to a
higher MSE than that of the MMSE detection are proposed. However, the means of
the GMPID may still not converge when $ N_u/N_r&lt; (\sqrt{2}-1)^{-2}$. Therefore,
a new convergent SA-GMPID is proposed, which converges to the MMSE detection
for any $N_u&gt; N_r$ with a faster convergence speed. Finally, numerical results
are provided to verify the validity of the proposed theoretical results.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, IEEE GLOBECOM 2016, Accepted. arXiv admin note:
  text overlap with arXiv:1606.06408</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00801</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Honey Sheets: What Happens to Leaked Google Spreadsheets?</dc:title>
 <dc:creator>Lazarov, Martin</dc:creator>
 <dc:creator>Onaolapo, Jeremiah</dc:creator>
 <dc:creator>Stringhini, Gianluca</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cloud-based documents are inherently valuable, due to the volume and nature
of sensitive personal and business content stored in them. Despite the
importance of such documents to Internet users, there are still large gaps in
the understanding of what cybercriminals do when they illicitly get access to
them by for example compromising the account credentials they are associated
with. In this paper, we present a system able to monitor user activity on
Google spreadsheets. We populated 5 Google spreadsheets with fake bank account
details and fake funds transfer links. Each spreadsheet was configured to
report details of accesses and clicks on links back to us. To study how people
interact with these spreadsheets in case they are leaked, we posted unique
links pointing to the spreadsheets on a popular paste site. We then monitored
activity in the accounts for 72 days, and observed 165 accesses in total. We
were able to observe interesting modifications to these spreadsheets performed
by illicit accesses. For instance, we observed deletion of some fake bank
account information, in addition to insults and warnings that some visitors
entered in some of the spreadsheets. Our preliminary results show that our
system can be used to shed light on cybercriminal behavior with regards to
leaked online documents.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00811</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>2-tape 1-way Quantum Finite State Automata</dc:title>
 <dc:creator>Ganguly, Debayan</dc:creator>
 <dc:creator>Ray, Kumar Sankar</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  1-way quantum finite state automata are reversible in nature, which greatly
reduces its accepting property. In fact, the set of languages accepted by 1-way
quantum finite automata is a proper subset of regular languages. We introduce
2-tape 1-way quantum finite state automaton (2T1QFA(2))which is a modified
version of 1-way 2-head quantum finite state automaton(1QFA(2)). In this paper,
we replace the single tape of 1-way 2-head quantum finite state automaton with
two tapes. The content of the second tape is determined using a relation
defined on input alphabet. The main claims of this paper are as follows: (1)We
establish that 2-tape 1-way quantum finite state automaton(2T1QFA(2)) can
accept all regular languages (2)A language which cannot be accepted by any
multi-head deterministic finite automaton can be accepted by 2-tape 1-way
quantum finite state automaton(2T1QFA(2)) .(3) Exploiting the superposition
property of quantum automata we show that 2-tape 1-way quantum finite state
automaton(2T1QFA(2)) can accept the language L=ww.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00813</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query Answering with Transitive and Linear-Ordered Data</dc:title>
 <dc:creator>Amarilli, Antoine</dc:creator>
 <dc:creator>Benedikt, Michael</dc:creator>
 <dc:creator>Bourhis, Pierre</dc:creator>
 <dc:creator>Boom, Michael Vanden</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We consider entailment problems involving powerful constraint languages such
as guarded existential rules, in which additional semantic restrictions are put
on a set of distinguished relations. We consider restricting a relation to be
transitive, restricting a relation to be the transitive closure of another
relation, and restricting a relation to be a linear order. We give some natural
generalizations of guardedness that allow inference to be decidable in each
case, and isolate the complexity of the corresponding decision problems.
Finally we show that slight changes in our conditions lead to undecidability.
</dc:description>
 <dc:description>Comment: 36 pages. To appear in IJCAI 2016. Extended version with proofs</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00816</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time for dithering: fast and quantized random embeddings via the
  restricted isometry property</dc:title>
 <dc:creator>Jacques, Laurent</dc:creator>
 <dc:creator>Cambareri, Valerio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recently, many works have focused on the characterization of non-linear
dimensionality reduction methods obtained by quantizing linear embeddings,
e.g., to reach fast processing time, efficient data compression procedures,
novel geometry-preserving embeddings or to estimate the information/bits stored
in this reduced data representation. In this work, we prove that many linear
maps known to respect the restricted isometry property (RIP) can induce a
quantized random embedding with controllable multiplicative and additive
distortions with respect to the pairwise distances of the data points beings
considered. In other words, linear matrices having fast matrix-vector
multiplication algorithms (e.g., based on partial Fourier ensembles or on the
adjacency matrix of unbalanced expanders) can be readily used in the definition
of fast quantized embeddings with small distortions. This implication is made
possible by applying right after the linear map an additive and random &quot;dither&quot;
that stabilizes the impact of the uniform scalar quantization operator applied
afterwards. For different categories of RIP matrices, i.e., for different
linear embeddings of a metric space $(\mathcal K \subset \mathbb R^n, \ell_q)$
in $(\mathbb R^m, \ell_p)$ with $p,q \geq 1$, we derive upper bounds on the
additive distortion induced by quantization, showing that it decays either when
the embedding dimension $m$ increases or when the distance of a pair of
embedded vectors in $\mathcal K$ decreases. Finally, we develop a novel
&quot;bi-dithered&quot; quantization scheme, which allows for a reduced distortion that
decreases when the embedding dimension grows and independently of the
considered pair of vectors.
</dc:description>
 <dc:description>Comment: Keywords: random projections, non-linear embeddings, quantization,
  dither, restricted isometry property, dimensionality reduction, compressive
  sensing, low-complexity signal models, fast and structured sensing matrices,
  quantized rank-one projections (31 pages)</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2016-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00819</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding the Abstract Dialectical Framework (Preliminary Report)</dc:title>
 <dc:creator>Polberg, Sylwia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Among the most general structures extending the framework by Dung are the
abstract dialectical frameworks (ADFs). They come equipped with various types
of semantics, with the most prominent - the labeling-based one - analyzed in
the context of computational complexity, signatures, instantiations and
software support. This makes the abstract dialectical frameworks valuable tools
for argumentation. However, there are fewer results available concerning the
relation between the ADFs and other argumentation frameworks. In this paper we
would like to address this issue by introducing a number of translations from
various formalisms into ADFs. The results of our study show the similarities
and differences between them, thus promoting the use and understanding of ADFs.
Moreover, our analysis also proves their capability to model many of the
existing frameworks, including those that go beyond the attack relation.
Finally, translations allow other structures to benefit from the research on
ADFs in general and from the existing software in particular.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00825</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Garbage Collection in JyNI - How to bridge Mark/Sweep and Reference
  Counting GC</dc:title>
 <dc:creator>Richthofer, Stefan</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Jython is a Java-based Python implementation and the most seamless way to
integrate Python and Java. It achieves high efficiency by compiling Python code
to Java bytecode and thus letting Java's JIT optimize it - an approach that
enables Python code to call Java functions or to subclass Java classes. It
enables Python code to leverage Java's multithreading features and utilizes
Java's built-in garbage collection (GC). However, it currently does not support
CPython's C-API and thus does not support native extensions like NumPy and
SciPy. Since most scientific code depends on such extensions, it is not
runnable with Jython. Jython Native Interface (JyNI) is a compatibility layer
that aims to provide CPython's native C extension API on top of Jython. JyNI is
implemented using the Java Native Interface (JNI) and its native part is
designed to be binary compatible with existing extension builds [...].
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00827</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preventing Malware Pandemics in Mobile Devices by Establishing
  Response-time Bounds</dc:title>
 <dc:creator>Nikolopoulos, Stavros D.</dc:creator>
 <dc:creator>Polenakis, Iosif</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  We study the propagation of a malicious software in a network of mobile
devices, which are moving in a specific city area, and establish time bounds
for the activation of a counter-measure, i.e., an antivirus or a cleaner in
order to prevent pandemic. More precisely, given an initial infected population
(mobile devices), we establish upper bounds on the time needed for a
counter-measure to take effect after infection (response-time), in order to
prevent the rest susceptible devices to get infected. Thus, within a period of
time, we guarantee that not all the susceptible devices in the city get
infected and the infected ones get sanitized. In our work, we first propose a
malware propagation model along with a device mobility model and then,
utilizing these models, we develop a simulator that we use to study the spread
of malware in such networks. Finally, we provide experimental results for the
pandemic prevention taken by our simulator for various response-time intervals.
</dc:description>
 <dc:description>Comment: 13 pages, 33 figures</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00844</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using the pyMIC Offload Module in PyFR</dc:title>
 <dc:creator>Klemm, Michael</dc:creator>
 <dc:creator>Witherden, Freddie</dc:creator>
 <dc:creator>Vincent, Peter</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  PyFR is an open-source high-order accurate computational fluid dynamics
solver for unstructured grids. It is designed to efficiently solve the
compressible Navier-Stokes equations on a range of hardware platforms,
including GPUs and CPUs. In this paper we will describe how the Python Offload
Infrastructure for the Intel Many Integrated Core Architecture (pyMIC) was used
to enable PyFR to run with near native performance on the Intel Xeon Phi
coprocessor. We will introduce the architecture of both pyMIC and PyFR and
present a variety of examples showcasing the capabilities of pyMIC. Further, we
will also compare the contrast pyMIC to other approaches including native
execution and OpenCL. The process of adding support for pyMIC into PyFR will be
described in detail. Benchmark results show that for a standard cylinder flow
problem PyFR with pyMIC is able achieve 240 GFLOP/s of sustained double
precision floating point performance; for a 1.85 times improvement over PyFR
with C/OpenMP on a 12 core Intel Xeon E5-2697 v2 CPU.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00847</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Confidence-Weighted Bipartite Ranking</dc:title>
 <dc:creator>Khalid, Majdi</dc:creator>
 <dc:creator>Ray, Indrakshi</dc:creator>
 <dc:creator>Chitsaz, Hamidreza</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Bipartite ranking is a fundamental machine learning and data mining problem.
It commonly concerns the maximization of the AUC metric. Recently, a number of
studies have proposed online bipartite ranking algorithms to learn from massive
streams of class-imbalanced data. These methods suggest both linear and
kernel-based bipartite rank- ing algorithms based on first and second-order
online learning. Unlike kernelized ranker, linear ranker is more scalable
learning algorithm. The existing linear online bipartite ranking algorithms
lack either handling non-separable data or constructing adaptive large margin.
These limitations yield unreliable bipartite ranking performance. In this work,
we propose a linear online confidence-weighted bipartite ranking algorithm
(CBR) that adopts soft confidence-weighted learning. The proposed algorithm
leverages the same properties of soft confidence-weighted learning in a
framework for bipartite ranking. We also develop a diagonal variation of the
proposed confidence-weighted bipartite ranking algorithm to deal with
high-dimensional data by maintaining only the diagonal elements of the
covariance matrix. We empirically evaluate the effectiveness of the proposed
algorithms on several benchmark and high-dimensional datasets. The experimental
results validate the reliability of the pro- posed algorithms. The results also
show that our algorithms outperform or are at least comparable to the competing
online AUC maximization methods.
</dc:description>
 <dc:description>Comment: 15 pages, 6 tables, and 2 figures</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00850</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massively parallel implementation in Python of a pseudo-spectral DNS
  code for turbulent flows</dc:title>
 <dc:creator>Mortensen, Mikael</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Direct Numerical Simulations (DNS) of the Navier Stokes equations is a
valuable research tool in fluid dynamics, but there are very few publicly
available codes and, due to heavy number crunching, codes are usually written
in low-level languages. In this work a \textasciitilde{}100 line standard
scientific Python DNS code is described that nearly matches the performance of
pure C for thousands of processors and billions of unknowns. With optimization
of a few routines in Cython, it is found to match the performance of a more or
less identical solver implemented from scratch in C++. Keys to the efficiency
of the solver are the mesh decomposition and three dimensional FFT routines,
implemented directly in Python using MPI, wrapped through MPI for Python, and a
serial FFT module (both numpy.fft or pyFFTW may be used). Two popular
decomposition strategies, slab and pencil, have been implemented and tested.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00853</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint User Association and Power Control for Load Balancing in Downlink
  Heterogeneous Cellular Networks</dc:title>
 <dc:creator>Zhou, Tianqing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Instead of achievable rate in the conventional association, we utilize the
effective rate to design two association schemes for load balancing in
heterogeneous cellular networks (HCNs), which are both formulated as such
problems with maximizing the sum of effective rates. In these two schemes, the
one just considers user association, but the other introduces power control to
mitigate interference and reduce energy consumption while performing user
association. Since the effective rate is closely related to the load of some BS
and the achievable rate of some user, it can be used as a key factor of
association schemes for load balancing in HCNs. To solve the association
problem without power control, we design a one-layer iterative algorithm, which
converts the sum-of-ratio form of original optimization problem into a
parameterized polynomial form. By combining this algorithm with power control
algorithm, we propose a two-layer iterative algorithm for the association
problem with power control. Specially, the outer layer performs user
association using the algorithm of problem without power control, and the inner
layer updates the transmit power of each BS using a power update function
(PUF). At last, we give some convergence and complexity analyses for the
proposed algorithms. As shown in simulation results, the proposed schemes have
superior performance than the conventional association, and the scheme with
joint user association and power control achieves a higher load balancing gain
and energy efficiency than conventional scheme and other offloading scheme.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00854</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lecture Notes on the ARV Algorithm for Sparsest Cut</dc:title>
 <dc:creator>Rothvoss, Thomas</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  One of the landmarks in approximation algorithms is the $O(\sqrt{\log
n})$-approximation algorithm for the Uniform Sparsest Cut problem by Arora, Rao
and Vazirani from 2004. The algorithm is based on a semidefinite program that
finds an embedding of the nodes respecting the triangle inequality. Their core
argument shows that a random hyperplane approach will find two large sets of
$\Theta(n)$ many nodes each that have a distance of $\Theta(1/\sqrt{\log n})$
to each other if measured in terms of $\|\cdot \|_2^2$.
  Here we give a detailed set of lecture notes describing the algorithm. For
the proof of the Structure Theorem we use a cleaner argument based on expected
maxima over $k$-neighborhoods that significantly simplifies the analysis.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00858</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embracing Data Science</dc:title>
 <dc:creator>Loy, Adam</dc:creator>
 <dc:subject>Statistics - Other Statistics</dc:subject>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:description>  Statistics is running the risk of appearing irrelevant to today's
undergraduate students. Today's undergraduate students are familiar with data
science projects and they judge statistics against what they have seen.
Statistics, especially at the introductory level, should take inspiration from
data science so that the discipline is not seen as somehow lesser than data
science. This article provides a brief overview of data science, outlines ideas
for how introductory courses could take inspiration from data science, and
provides a reference to materials for developing stand-alone data science
courses.
</dc:description>
 <dc:description>Comment: 9 pages, 1 figure</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00858</dc:identifier>
 <dc:identifier>The UMAP Journal 36 (2015) 285-292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00859</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PyCells for an Open Semiconductor Industry</dc:title>
 <dc:creator>Alassi, Sepideh</dc:creator>
 <dc:creator>Winter, Bertram</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  In the modern semiconductor industry, automatic generation of parameterized
and recurring layout structures plays an important role and should be present
as a feature in Electronic Design Automation (EDA)-tools. Currently these
layout generators are developed with a proprietary programming language and can
be used with a specific EDA-tool. Therefore, the semiconductor companies find
the development of the layout generators that can be used in all state of the
art EDA-tools which support OpenAccess database appealing. The goal of this
project is to develop computationally efficient layout generators with Python
(PyCells), for ams AG technologies, that possess all the features of
comprehensive layout generators.
</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00861</identifier>
 <datestamp>2016-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$\lambda$-persistant CSMA: a radio-channel access protocol</dc:title>
 <dc:creator>B&#x142;a&#x15b;kiewicz, Przemys&#x142;aw</dc:creator>
 <dc:creator>Cicho&#x144;, Jacek</dc:creator>
 <dc:creator>Lemiesz, Jakub</dc:creator>
 <dc:creator>Kuty&#x142;owski, Miros&#x142;aw</dc:creator>
 <dc:creator>Zawada, Marcin</dc:creator>
 <dc:creator>Stefa&#x144;ski, Szymon</dc:creator>
 <dc:creator>Chrobak, Krzysztof</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper presents an algorithm that improves channel-access statistics for
wireless medium. The proposed modification of the standard CSMA algorithm is
analytically shown to yield better results and simulation results are given to
support this claim.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00862</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One- and Multi-Pass Long-Hop Routing for Wireless Network</dc:title>
 <dc:creator>B&#x142;a&#x15b;kiewicz, Przemys&#x142;aw</dc:creator>
 <dc:creator>Cicho&#x144;, Jacek</dc:creator>
 <dc:creator>Lemiesz, Jakub</dc:creator>
 <dc:creator>Kuty&#x142;owski, Miros&#x142;aw</dc:creator>
 <dc:creator>Zawada, Marcin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In our paper we provide mathematical analysis of a probabilistic long-hop
routing algorithms which uses as the randomizing factor the estimate of
distance of a station from the previous-hop source of the message.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00863</identifier>
 <datestamp>2016-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Jamming-Resilient MAC-layer Device Identification for Internet of
  Things</dc:title>
 <dc:creator>B&#x142;a&#x15b;kiewicz, Przemys&#x142;aw</dc:creator>
 <dc:creator>Cicho&#x144;, Jacek</dc:creator>
 <dc:creator>Lemiesz, Jakub</dc:creator>
 <dc:creator>Kuty&#x142;owski, Miros&#x142;aw</dc:creator>
 <dc:creator>Zawada, Marcin</dc:creator>
 <dc:creator>Napiera&#x142;a, Krystyna</dc:creator>
 <dc:creator>Panek, Micha&#x142;</dc:creator>
 <dc:creator>Strzy&#x17c;, Stanis&#x142;aw</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In a number of practical scenarios a wireless device needs to mark its
presence, for instance, to some access point. That enables the access point to
assign the device its transmission slot or update the count of the network
nodes. Many protocols can achieve exactly this result. In this paper, our goal
is to show how that can be done in the simplest messaging model, the so-called
beeping model. Consequently, we constrain our design so that the station does
not send any modulated information in the signal and the receiver actually does
not need to demodulate/decode it. We are interested in sending just a short
signal, so called 'beep'. Moreover, we want to design such protocol that is
resilient to random interference and enables us to identify devices which are
sending the signal, as opposed to only note their presence. To do that, we
leverage temporal correlations of a sequence of beeps issued by a device, as if
the time-moments when they happen come from a pre-defined probability
distribution, that is the fingerpring of the device.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00866</identifier>
 <datestamp>2017-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Primal versus the Dual Ising Model</dc:title>
 <dc:creator>Molkaraie, Mehdi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  We represent the Ising model of statistical physics by Forney factor graphs
in the primal and in the dual domains. By analogy with Kirchhoff's voltage and
current laws, we show that in the primal Forney factor graph, the dependency
among the variables is along the cycles, whereas in the dual Forney factor
graph, the dependency is on the cutsets. In the primal (resp. dual) domain,
dependent variables can be computed via their fundamental cycles (resp.
fundamental cutsets). In each domain, we propose an importance sampling
algorithm to estimate the partition function. In the primal domain, the
proposal distribution is defined on a spanning tree, and computations are done
on the cospanning tree. In contrast, in the dual domain, computations are done
on a spanning tree of the model, and the proposal distribution is defined on
the cospanning tree.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00868</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New error measures and methods for realizing protein graphs from
  distance data</dc:title>
 <dc:creator>D'Ambrosio, Claudia</dc:creator>
 <dc:creator>Vu, Ky</dc:creator>
 <dc:creator>Lavor, Carlile</dc:creator>
 <dc:creator>Liberti, Leo</dc:creator>
 <dc:creator>Maculan, Nelson</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  The interval Distance Geometry Problem (iDGP) consists in finding a
realization in $\mathbb{R}^K$ of a simple undirected graph $G=(V,E)$ with
nonnegative intervals assigned to the edges in such a way that, for each edge,
the Euclidean distance between the realization of the adjacent vertices is
within the edge interval bounds. In this paper, we focus on the application to
the conformation of proteins in space, which is a basic step in determining
protein function: given interval estimations of some of the inter-atomic
distances, find their shape. Among different families of methods for
accomplishing this task, we look at mathematical programming based methods,
which are well suited for dealing with intervals. The basic question we want to
answer is: what is the best such method for the problem? The most meaningful
error measure for evaluating solution quality is the coordinate root mean
square deviation. We first introduce a new error measure which addresses a
particular feature of protein backbones, i.e. many partial reflections also
yield acceptable backbones. We then present a set of new and existing quadratic
and semidefinite programming formulations of this problem, and a set of new and
existing methods for solving these formulations. Finally, we perform a
computational evaluation of all the feasible solver$+$formulation combinations
according to new and existing error measures, finding that the best methodology
is a new heuristic method based on multiplicative weights updates.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00869</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling of Item-Difficulty for Ontology-based MCQs</dc:title>
 <dc:creator>E. V, Vinu</dc:creator>
 <dc:creator>Alsubait, Tahani</dc:creator>
 <dc:creator>Kumar, P. Sreenivasa</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Multiple choice questions (MCQs) that can be generated from a domain ontology
can significantly reduce human effort &amp; time required for authoring &amp;
administering assessments in an e-Learning environment. Even though here are
various methods for generating MCQs from ontologies, methods for determining
the difficulty-levels of such MCQs are less explored. In this paper, we study
various aspects and factors that are involved in determining the
difficulty-score of an MCQ, and propose an ontology-based model for the
prediction. This model characterizes the difficulty values associated with the
stem and choice set of the MCQs, and describes a measure which combines both
the scores. Further more, the notion of assigning difficultly-scores based on
the skill level of the test taker is utilized for predicating difficulty-score
of a stem. We studied the effectiveness of the predicted difficulty-scores with
the help of a psychometric model from the Item Response Theory, by involving
real-students and domain experts. Our results show that, the predicated
difficulty-levels of the MCQs are having high correlation with their actual
difficulty-levels.
</dc:description>
 <dc:description>Comment: Under review</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00872</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neighborhood Features Help Detecting Non-Technical Losses in Big Data
  Sets</dc:title>
 <dc:creator>Glauner, Patrick</dc:creator>
 <dc:creator>Meira, Jorge</dc:creator>
 <dc:creator>Dolberg, Lautaro</dc:creator>
 <dc:creator>State, Radu</dc:creator>
 <dc:creator>Bettinger, Franck</dc:creator>
 <dc:creator>Rangoni, Yves</dc:creator>
 <dc:creator>Duarte, Diogo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Electricity theft is a major problem around the world in both developed and
developing countries and may range up to 40% of the total electricity
distributed. More generally, electricity theft belongs to non-technical losses
(NTL), which are losses that occur during the distribution of electricity in
power grids. In this paper, we build features from the neighborhood of
customers. We first split the area in which the customers are located into
grids of different sizes. For each grid cell we then compute the proportion of
inspected customers and the proportion of NTL found among the inspected
customers. We then analyze the distributions of features generated and show why
they are useful to predict NTL. In addition, we compute features from the
consumption time series of customers. We also use master data features of
customers, such as their customer class and voltage of their connection. We
compute these features for a Big Data base of 31M meter readings, 700K
customers and 400K inspection results. We then use these features to train four
machine learning algorithms that are particularly suitable for Big Data sets
because of their parallelizable structure: logistic regression, k-nearest
neighbors, linear support vector machine and random forest. Using the
neighborhood features instead of only analyzing the time series has resulted in
appreciable results for Big Data sets for varying NTL proportions of 1%-90%.
This work can therefore be deployed to a wide range of different regions around
the world.
</dc:description>
 <dc:description>Comment: Proceedings of the 3rd IEEE/ACM International Conference on Big Data
  Computing Applications and Technologies (BDCAT 2016)</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00876</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Corporate system of monitoring network informational resources based on
  agent-based approach</dc:title>
 <dc:creator>Lande, D. V.</dc:creator>
 <dc:creator>Dodonov, V. A.</dc:creator>
 <dc:creator>Kovalenko, T. V.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The paper provides a agent-based model, which describes distribution of
informative messages, containing links to informational resources in the
Internet. The results of modeling have been confirmed by studying a real
network of Twitter microblogs. The paper describes stages of building a
corporate system of monitoring network informational resources, the content of
which is determined by links in microblogs. The advantages of such approach are
set forth.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00880</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MDS-Coded Distributed Storage for Low Delay Wireless Content Delivery</dc:title>
 <dc:creator>Piemontese, Amina</dc:creator>
 <dc:creator>Amat, Alexandre Graell i</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We address the use of maximum distance separable (MDS) codes for distributed
storage (DS) to enable efficient content delivery in wireless networks. Content
is stored in a number of the mobile devices and can be retrieved from them
using device-to-device communication or, alternatively, from the base station
(BS). We derive an analytical expression for the download delay in the
hypothesis that the reliability state of the network is periodically restored.
Our analysis shows that MDS-coded DS can dramatically reduce the download time
with respect to the reference scenario where content is always downloaded from
the BS.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, accepted to the International Symposium on Turbo
  Codes &amp; Iterative Information Processing, September 2016 in Brest, France</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00888</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding Cryptographic Functions to SAT Using Transalg System</dc:title>
 <dc:creator>Otpuschennikov, Ilya</dc:creator>
 <dc:creator>Semenov, Alexander</dc:creator>
 <dc:creator>Gribanova, Irina</dc:creator>
 <dc:creator>Zaikin, Oleg</dc:creator>
 <dc:creator>Kochemazov, Stepan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper we propose the technology for constructing propositional
encodings of discrete functions. It is aimed at solving inversion problems of
considered functions using state-of-the-art SAT solvers. We implemented this
technology in the form of the software system called Transalg, and used it to
construct SAT encodings for a number of cryptanalysis problems. By applying SAT
solvers to these encodings we managed to invert several cryptographic
functions. In particular, we used the SAT encodings produced by Transalg to
construct the family of two-block MD5 collisions in which the first 10 bytes
are zeros. Also we used Transalg encoding for the widely known A5/1 keystream
generator to solve several dozen of its cryptanalysis instances in a
distributed computing environment. In the paper we compare in detail the
functionality of Transalg with that of similar software systems.
</dc:description>
 <dc:description>Comment: Short variant of this paper was accepted to ECAI2016 conference</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00890</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Citation score normalized by cited references (CSNCR): The introduction
  of a new citation impact indicator</dc:title>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this paper, a new field-normalized indicator is introduced, which is
rooted in early insights in bibliometrics, and is compared with several
established field-normalized indicators (e.g. the mean normalized citation
score, MNCS, and indicators based on percentile approaches). Garfield (1979)
emphasizes that bare citation counts from different fields cannot be compared
for evaluative purposes, because the &quot;citation potential&quot; can vary
significantly between the fields. Garfield (1979) suggests that &quot;the most
accurate measure of citation potential is the average number of references per
paper published in a given field&quot;. Based on this suggestion, the new indicator
is basically defined as follows: the citation count of a focal paper is divided
by the mean number of cited references in a field to normalize citations. The
new indicator is called citation score normalized by cited references (CSNCR).
The theoretical analysis of the CSNCR shows that it has the properties of
consistency and homogeneous normalization. The close relation of the new
indicator to the MNCS is discussed. The empirical comparison of the CSNCR with
other field-normalized indicators shows that it is slightly poorer able to
field-normalize citation counts than other cited-side normalized indicators
(e.g. the MNCS), but its results are favorable compared to two citing-side
indicator variants (SNCS indicators). Taken as a whole, the results of this
study confirm the ability of established indicators to field-normalize
citations.
</dc:description>
 <dc:description>Comment: Accepted for publication in the Journal of Informetrics</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00890</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2016.07.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00905</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Observing Custom Software Modifications: A Quantitative Approach of
  Tracking the Evolution of Patch Stacks</dc:title>
 <dc:creator>Ramsauer, Ralf</dc:creator>
 <dc:creator>Lohmann, Daniel</dc:creator>
 <dc:creator>Mauerer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Modifications to open-source software (OSS) are often provided in the form of
&quot;patch stacks&quot; - sets of changes (patches) that modify a given body of source
code. Maintaining patch stacks over extended periods of time is problematic
when the underlying base project changes frequently. This necessitates a
continuous and engineering-intensive adaptation of the stack. Nonetheless,
long-term maintenance is an important problem for changes that are not
integrated into projects, for instance when they are controversial or only of
value to a limited group of users.
  We present and implement a methodology to systematically examine the temporal
evolution of patch stacks, track non-functional properties like integrability
and maintainability, and estimate the eventual economic and engineering effort
required to successfully develop and maintain patch stacks.
  Our results provide a basis for quantitative research on patch stacks,
including statistical analyses and other methods that lead to actionable advice
on the construction and long-term maintenance of custom extensions to OSS.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00905</dc:identifier>
 <dc:identifier>doi:10.1145/2957792.2957810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00913</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Superintelligence cannot be contained: Lessons from Computability Theory</dc:title>
 <dc:creator>Alfonseca, Manuel</dc:creator>
 <dc:creator>Cebrian, Manuel</dc:creator>
 <dc:creator>Anta, Antonio Fernandez</dc:creator>
 <dc:creator>Coviello, Lorenzo</dc:creator>
 <dc:creator>Abeliuk, Andres</dc:creator>
 <dc:creator>Rahwan, Iyad</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Superintelligence is a hypothetical agent that possesses intelligence far
surpassing that of the brightest and most gifted human minds. In light of
recent advances in machine intelligence, a number of scientists, philosophers
and technologists have revived the discussion about the potential catastrophic
risks entailed by such an entity. In this article, we trace the origins and
development of the neo-fear of superintelligence, and some of the major
proposals for its containment. We argue that such containment is, in principle,
impossible, due to fundamental limits inherent to computing itself. Assuming
that a superintelligence will contain a program that includes all the programs
that can be executed by a universal Turing machine on input potentially as
complex as the state of the world, strict containment requires simulations of
such a program, something theoretically (and practically) infeasible.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00918</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatially Coupled LDPC Codes Affected by a Single Random Burst of
  Erasures</dc:title>
 <dc:creator>Aref, Vahid</dc:creator>
 <dc:creator>Rengaswamy, Narayanan</dc:creator>
 <dc:creator>Schmalen, Laurent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Spatially-Coupled LDPC (SC-LDPC) ensembles achieve the capacity of binary
memoryless channels (BMS), asymptotically, under belief-propagation (BP)
decoding. In this paper, we study the BP decoding of these code ensembles over
a BMS channel and in the presence of a single random burst of erasures. We show
that in the limit of code length, codewords can be recovered successfully if
the length of the burst is smaller than some maximum recoverable burst length.
We observe that the maximum recoverable burst length is practically the same if
the transmission takes place over binary erasure channel or over binary
additive white Gaussian channel with the same capacity. Analyzing the stopping
sets, we also estimate the decoding failure probability (the error floor) when
the code length is finite.
</dc:description>
 <dc:description>Comment: Accepted for presentation in 2016 International Symposium on Turbo
  Codes &amp; Iterative Information Processing</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00931</identifier>
 <datestamp>2016-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deletion Operations on Deterministic Families of Automata</dc:title>
 <dc:creator>Eremondi, Joey</dc:creator>
 <dc:creator>Ibarra, Oscar H.</dc:creator>
 <dc:creator>McQuillan, Ian</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Many different deletion operations are investigated applied to languages
accepted by one-way and two-way deterministic reversal-bounded multicounter
machines, deterministic pushdown automata, and finite automata. Operations
studied include the prefix, suffix, infix and outfix operations, as well as
left and right quotient with languages from different families. It is often
expected that language families defined from deterministic machines will not be
closed under deletion operations. However, here, it is shown that one-way
deterministic reversal-bounded multicounter languages are closed under right
quotient with languages from many different language families; even those
defined by nondeterministic machines such as the context-free languages. Also,
it is shown that when starting with one-way deterministic machines with one
counter that makes only one reversal, taking the left quotient with languages
from many different language families -- again including those defined by
nondeterministic machines such as the context-free languages -- yields only
one-way deterministic reversal-bounded multicounter languages (by increasing
the number of counters). However, if there are two more reversals on the
counter, or a second 1-reversal-bounded counter, taking the left quotient (or
even just the suffix operation) yields languages that can neither be accepted
by deterministic reversal-bounded multicounter machines, nor by 2-way
nondeterministic machines with one reversal-bounded counter.
</dc:description>
 <dc:description>Comment: 20 pages, accepted version to Information and Computation</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2016-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00932</identifier>
 <datestamp>2017-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Quantum Sample Complexity of Learning Algorithms</dc:title>
 <dc:creator>Arunachalam, Srinivasan</dc:creator>
 <dc:creator>de Wolf, Ronald</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  $ \newcommand{\eps}{\varepsilon} $In learning theory, the VC dimension of a
concept class $C$ is the most common way to measure its &quot;richness.&quot; In the PAC
model $$ \Theta\Big(\frac{d}{\eps} + \frac{\log(1/\delta)}{\eps}\Big) $$
examples are necessary and sufficient for a learner to output, with probability
$1-\delta$, a hypothesis $h$ that is $\eps$-close to the target concept $c$. In
the related agnostic model, where the samples need not come from a $c\in C$, we
know that $$ \Theta\Big(\frac{d}{\eps^2} + \frac{\log(1/\delta)}{\eps^2}\Big)
$$ examples are necessary and sufficient to output an hypothesis $h\in C$ whose
error is at most $\eps$ worse than the best concept in $C$.
  Here we analyze quantum sample complexity, where each example is a coherent
quantum state. This model was introduced by Bshouty and Jackson, who showed
that quantum examples are more powerful than classical examples in some
fixed-distribution settings. However, Atici and Servedio, improved by Zhang,
showed that in the PAC setting, quantum examples cannot be much more powerful:
the required number of quantum examples is $$
\Omega\Big(\frac{d^{1-\eta}}{\eps} + d + \frac{\log(1/\delta)}{\eps}\Big)\mbox{
for all }\eta&gt; 0. $$ Our main result is that quantum and classical sample
complexity are in fact equal up to constant factors in both the PAC and
agnostic models. We give two approaches. The first is a fairly simple
information-theoretic argument that yields the above two classical bounds and
yields the same bounds for quantum sample complexity up to a $\log(d/\eps)$
factor. We then give a second approach that avoids the log-factor loss, based
on analyzing the behavior of the &quot;Pretty Good Measurement&quot; on the quantum state
identification problems that correspond to learning. This shows classical and
quantum sample complexity are equal up to constant factors.
</dc:description>
 <dc:description>Comment: 31 pages LaTeX. Arxiv abstract shortened to fit in their
  1920-character limit. Version 3: many small changes, no change in results</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00934</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Game Framework for Harmonized LTE-U and WiFi Coexistence over
  Unlicensed Bands</dc:title>
 <dc:creator>Hamidouche, Kenza</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The introduction of LTE over unlicensed bands (LTE-U) will enable LTE base
stations (BSs) to boost their capacity and offload their traffic by exploiting
the underused unlicensed bands. However, to reap the benefits of LTE-U, it is
necessary to address various new challenges associated with LTE-U and WiFi
coexistence. In particular, new resource management techniques must be
developed to optimize the usage of the network resources while handling the
interdependence between WiFi and LTE users and ensuring that WiFi users are not
jeopardized. To this end, in this paper, a new game theoretic tool, dubbed as
\emph{multi-game} framework is proposed as a promising approach for modeling
resource allocation problems in LTE-U. In such a framework, multiple,
co-existing and coupled games across heterogeneous channels can be formulated
to capture the specific characteristics of LTE-U. Such games can be of
different properties and types but their outcomes are largely interdependent.
After introducing the basics of the multi-game framework, two classes of
algorithms are outlined to achieve the new solution concepts of multi-games.
Simulation results are then conducted to show how such a multi-game can
effectively capture the specific properties of LTE-U and make of it a
&quot;friendly&quot; neighbor to WiFi.
</dc:description>
 <dc:description>Comment: Accepted for publication at IEEE Wireless Communications Magazine,
  Special Issue on LTE in Unlicensed Spectrum</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00942</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Artificial-Noise Aided Transmit Design for Multi-User MISO Systems
  with Integrated Services</dc:title>
 <dc:creator>Mei, Weidong</dc:creator>
 <dc:creator>Chen, Zhi</dc:creator>
 <dc:creator>Li, Lingxiang</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:creator>Li, Shaoqian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers artificial noise (AN)-aided transmit designs for
multi-user MISO systems in the eyes of service integration. Specifically, we
combine two sorts of services, and serve them simultaneously: one multicast
message intended for all receivers and one confidential message intended for
only one receiver. The confidential message is kept perfectly secure from all
the unauthorized receivers. Our goal is to jointly design the optimal input
covariances for the multicast message, confidential message and AN, such that
the achievable secrecy rate region is maximized subject to the sum power
constraint. This secrecy rate region maximization (SRRM) problem is a nonconvex
vector maximization problem. To handle it, we reformulate the SRRM problem into
a provably equivalent scalar optimization problem and propose a searching
method to find all of its Pareto optimal points. The equivalent scalar
optimization problem is identified as a secrecy rate maximization (SRM) problem
with the quality of multicast service (QoMS) constraints. Further, we show that
this equivalent QoMS-constrained SRM problem, albeit nonconvex, can be
efficiently handled based on a two-stage optimization approach, including
solving a sequence of semidefinite programs. Moreover, we also extend the SRRM
problem to an imperfect channel state information (CSI) case where a worst-case
robust formulation is considered. In particular, while transmit beamforming is
generally a suboptimal technique to the SRRM problem, we prove that it is
optimal for the confidential message transmission whether in the perfect CSI
scenario or in the imperfect CSI scenario. Finally, numerical results
demonstrate that the AN-aided transmit designs are effective in expanding the
achievable secrecy rate regions.
</dc:description>
 <dc:description>Comment: Part of this work has been presented in IEEE GlobalSIP 2015 and in
  IEEE ICASSP 2016</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00942</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2017.2676244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00945</identifier>
 <datestamp>2016-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Width, depth and space</dc:title>
 <dc:creator>Chen, Li-Hsuan</dc:creator>
 <dc:creator>Reidl, Felix</dc:creator>
 <dc:creator>Rossmanith, Peter</dc:creator>
 <dc:creator>Villaamil, Fernando S&#xe1;nchez</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The width measure treedepth, also known as vertex ranking, centered coloring
and elimination tree height, is a well-established notion which has recently
seen a resurgence of interest. Since graphs of bounded treedepth are more
restricted than graphs of bounded tree- or pathwidth, we are interested in the
algorithmic utility of this additional structure.
  On the negative side, we show that every dynamic programming algorithm on
treedepth decompositions of depth~$t$ cannot solve Dominating Set with
$O((3-\epsilon)^t \cdot \log n)$ space for any $\epsilon &gt; 0$. This result
implies the same space lower bound for dynamic programming algorithms on tree
and path decompositions. We supplement this result by showing a space lower
bound of $O((3-\epsilon)^t \cdot \log n)$ for 3-Coloring and $O((2-\epsilon)^t
\cdot \log n)$ for Vertex Cover. This formalizes the common intuition that
dynamic programming algorithms on graph decompositions necessarily consume a
lot of space and complements known results of the time-complexity of problems
restricted to low-treewidth classes.
  We then show that treedepth lends itself to the design of branching
algorithms. This class of algorithms has in general distinct advantages over
dynamic programming algorithms: a) They use less space than algorithms based on
dynamic programming, b) they are easy to parallelize and c) they provide
possible solutions before terminating.
  Specifically, we design for Dominating Set a pure branching algorithm that
runs in time $t^{O(t^2)}\cdot n$ and uses space $O(t^3 \log t + t \log n)$ and
a hybrid of branching and dynamic programming that achieves a running time of
$O(3^t \log t \cdot n)$ while using $O(2^t t \log t + t \log n)$ space.
Algorithms for 3-Coloring and Vertex Cover with space complexity $O(t \cdot
\log n)$ and time complexity $O(3^t \cdot n)$ and $O(2^t\cdot n)$,
respectively, are included for completeness.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2016-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00946</identifier>
 <datestamp>2017-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct Localization for Massive MIMO</dc:title>
 <dc:creator>Garcia, Nil</dc:creator>
 <dc:creator>Wymeersch, Henk</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:creator>Haimovich, Alexander M.</dc:creator>
 <dc:creator>Coulon, Martial</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Large-scale MIMO systems are well known for their advantages in
communications, but they also have the potential for providing very accurate
localization thanks to their high angular resolution. A difficult problem
arising indoors and outdoors is localizing users over multipath channels.
Localization based on angle of arrival (AOA) generally involves a two-step
procedure, where signals are first processed to obtain a user's AOA at
different base stations, followed by triangulation to determine the user's
position. In the presence of multipath, the performance of these methods is
greatly degraded due to the inability to correctly detect and/or estimate the
AOA of the line-of-sight (LOS) paths. To counter the limitations of this
two-step procedure which is inherently sub-optimal, we propose a direct
localization approach in which the position of a user is localized by jointly
processing the observations obtained at distributed massive MIMO base stations.
Our approach is based on a novel compressed sensing framework that exploits
channel properties to distinguish LOS from non-LOS signal paths, and leads to
improved performance results compared to previous existing methods.
</dc:description>
 <dc:description>Comment: 11 pages, journal</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00946</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2666779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00956</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependence of dissipation on the initial distribution over states</dc:title>
 <dc:creator>Kolchinsky, Artemy</dc:creator>
 <dc:creator>Wolpert, David H.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>82C05</dc:subject>
 <dc:description>  We analyze how the amount of work dissipated by a fixed nonequilibrium
process depends on the initial distribution over states. Specifically, we
compare the amount of dissipation when the process is used with some specified
initial distribution to the minimal amount of dissipation possible for any
initial distribution. We show that the difference between those two amounts of
dissipation is given by a simple information-theoretic function that depends
only on the initial and final state distributions. Crucially, this difference
is independent of the details of the process relating those distributions. We
then consider how dissipation depends on the initial distribution for a
'computer', i.e., a nonequilibrium process whose dynamics over coarse-grained
macrostates implement some desired input-output map. We show that our results
still apply when stated in terms of distributions over the computer's
coarse-grained macrostates. This can be viewed as a novel thermodynamic cost of
computation, reflecting changes in the distribution over inputs rather than the
logical dynamics of the computation.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00956</dc:identifier>
 <dc:identifier>J. Stat. Mech. (2017) 083202</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/aa7ee1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00964</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A general framework for weighted sum-rate and common-rate optimization</dc:title>
 <dc:creator>Roshandeh, Koosha Pourtahmasi</dc:creator>
 <dc:creator>Ardakani, Masoud</dc:creator>
 <dc:creator>Tellambura, Chintha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a framework for solving a class of optimization
problems encountered in a range of power allocation problems in wireless relay
networks. In particular, power allocation for weighted sum-rate and common-rate
optimization problems fall in this framework. Subject to some conditions on the
region of feasible powers, the optimal solutions are analytically found. The
optimization problems are posed in a general form and their solutions are shown
to have applications in a number of practical scenarios. Numerical results
verify the optimality of the analytical approach.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00968</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full waveform inversion guided by travel time tomography</dc:title>
 <dc:creator>Treister, Eran</dc:creator>
 <dc:creator>Haber, Eldad</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Full waveform inversion (FWI) is a process in which seismic numerical
simulations are fit to observed data by changing the wave velocity model of the
medium under investigation. The problem is non-linear, and therefore
optimization techniques have been used to find a reasonable solution to the
problem. The main problem in fitting the data is the lack of low spatial
frequencies. This deficiency often leads to a local minimum and to
non-plausible solutions. In this work we explore how to obtain low frequency
information for FWI. Our approach involves augmenting FWI with travel time
tomography, which has low-frequency features. By jointly inverting these two
problems we enrich FWI with information that can replace low frequency data. In
addition, we use high order regularization, in a preliminary inversion stage,
to prevent high frequency features from polluting our model in the initial
stages of the reconstruction. This regularization also promotes the
non-dominant low-frequency modes that exist in the FWI sensitivity. By applying
a joint FWI and travel time inversion we are able to obtain a smooth model than
can later be used to recover a good approximation for the true model. A second
contribution of this paper involves the acceleration of the main computational
bottleneck in FWI--the solution of the Helmholtz equation. We show that the
solution time can be reduced by solving the equation for multiple right hand
sides using block multigrid preconditioned Krylov methods.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00969</identifier>
 <datestamp>2017-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cell assemblies at multiple time scales with arbitrary lag
  constellations</dc:title>
 <dc:creator>Russo, Eleonora</dc:creator>
 <dc:creator>Durstewitz, Daniel</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hebb's idea of a cell assembly as the fundamental unit of neural information
processing has dominated neuroscience like no other theoretical concept within
the past 60 years. A range of different physiological phenomena, from precisely
synchronized spiking to broadly simultaneous rate increases, has been subsumed
under this term. Yet progress in this area is hampered by the lack of
statistical tools that would enable to extract assemblies with arbitrary
constellations of time lags, and at multiple temporal scales, partly due to the
severe computational burden. Here we present such a unifying methodological and
conceptual framework which detects assembly structure at many different time
scales, levels of precision, and with arbitrary internal organization. Applying
this methodology to multiple single unit recordings from various cortical
areas, we find that there is no universal cortical coding scheme, but that
assembly structure and precision significantly depends on brain area recorded
and ongoing task demands.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00969</dc:identifier>
 <dc:identifier>eLife 2017;6:e19428</dc:identifier>
 <dc:identifier>doi:10.7554/eLife.19428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00970</identifier>
 <datestamp>2016-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence to Backward and Forward Sequences: A Content-Introducing
  Approach to Generative Short-Text Conversation</dc:title>
 <dc:creator>Mou, Lili</dc:creator>
 <dc:creator>Song, Yiping</dc:creator>
 <dc:creator>Yan, Rui</dc:creator>
 <dc:creator>Li, Ge</dc:creator>
 <dc:creator>Zhang, Lu</dc:creator>
 <dc:creator>Jin, Zhi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Using neural networks to generate replies in human-computer dialogue systems
is attracting increasing attention over the past few years. However, the
performance is not satisfactory: the neural network tends to generate safe,
universally relevant replies which carry little meaning. In this paper, we
propose a content-introducing approach to neural network-based generative
dialogue systems. We first use pointwise mutual information (PMI) to predict a
noun as a keyword, reflecting the main gist of the reply. We then propose
seq2BF, a &quot;sequence to backward and forward sequences&quot; model, which generates a
reply containing the given keyword. Experimental results show that our approach
significantly outperforms traditional sequence-to-sequence models in terms of
human evaluation and the entropy measure, and that the predicted keyword can
appear at an appropriate position in the reply.
</dc:description>
 <dc:description>Comment: Accepted by COLING</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2016-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00971</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can we unify monocular detectors for autonomous driving by using the
  pixel-wise semantic segmentation of CNNs?</dc:title>
 <dc:creator>Romera, Eduardo</dc:creator>
 <dc:creator>Bergasa, Luis M.</dc:creator>
 <dc:creator>Arroyo, Roberto</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Autonomous driving is a challenging topic that requires complex solutions in
perception tasks such as recognition of road, lanes, traffic signs or lights,
vehicles and pedestrians. Through years of research, computer vision has grown
capable of tackling these tasks with monocular detectors that can provide
remarkable detection rates with relatively low processing times. However, the
recent appearance of Convolutional Neural Networks (CNNs) has revolutionized
the computer vision field and has made possible approaches to perform full
pixel-wise semantic segmentation in times close to real time (even on hardware
that can be carried on a vehicle). In this paper, we propose to use full image
segmentation as an approach to simplify and unify most of the detection tasks
required in the perception module of an autonomous vehicle, analyzing major
concerns such as computation time and detection performance.
</dc:description>
 <dc:description>Comment: Extended abstract presented in IV16-WS Deepdriving
  (http://iv2016.berkeleyvision.org/)</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00973</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A fast marching algorithm for the factored eikonal equation</dc:title>
 <dc:creator>Treister, Eran</dc:creator>
 <dc:creator>Haber, Eldad</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The eikonal equation is instrumental in many applications in several fields
ranging from computer vision to geoscience. This equation can be efficiently
solved using the iterative Fast Sweeping (FS) methods and the direct Fast
Marching (FM) methods. However, when used for a point source, the original
eikonal equation is known to yield inaccurate numerical solutions, because of a
singularity at the source. In this case, the factored eikonal equation is often
preferred, and is known to yield a more accurate numerical solution. One
application that requires the solution of the eikonal equation for point
sources is travel time tomography. This inverse problem may be formulated using
the eikonal equation as a forward problem. While this problem has been solved
using FS in the past, the more recent choice for applying it involves FM
methods because of the efficiency in which sensitivities can be obtained using
them. However, while several FS methods are available for solving the factored
equation, the FM method is available only for the original eikonal equation.
  In this paper we develop a Fast Marching algorithm for the factored eikonal
equation, using both first and second order finite-difference schemes. Our
algorithm follows the same lines as the original FM algorithm and requires the
same computational effort. In addition, we show how to obtain sensitivities
using this FM method and apply travel time tomography, formulated as an inverse
factored eikonal equation. Numerical results in two and three dimensions show
that our algorithm solves the factored eikonal equation efficiently, and
demonstrate the achieved accuracy for computing the travel time. We also
demonstrate a recovery of a 2D and 3D heterogeneous medium by travel time
tomography using the eikonal equation for forward modelling and inversion by
Gauss-Newton.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00973</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2016.08.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00974</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lecture Notes on Channel Coding</dc:title>
 <dc:creator>B&#xf6;cherer, Georg</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  These lecture notes on channel coding were developed for a one-semester
course for graduate students of electrical engineering. Chapter 1 reviews the
basic problem of channel coding. Chapters 2-5 are on linear block codes, cyclic
codes, Reed-Solomon codes, and BCH codes, respectively. The notes are
self-contained and were written with the intent to derive the presented results
with mathematical rigor. The notes contain in total 68 homework problems, of
which 20% require computer programming.
</dc:description>
 <dc:description>Comment: 5 chapters, 68 homework problems</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00976</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling Context with User Embeddings for Sarcasm Detection in Social
  Media</dc:title>
 <dc:creator>Amir, Silvio</dc:creator>
 <dc:creator>Wallace, Byron C.</dc:creator>
 <dc:creator>Lyu, Hao</dc:creator>
 <dc:creator>Silva, Paula Carvalho M&#xe1;rio J.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce a deep neural network for automated sarcasm detection. Recent
work has emphasized the need for models to capitalize on contextual features,
beyond lexical and syntactic cues present in utterances. For example, different
speakers will tend to employ sarcasm regarding different subjects and, thus,
sarcasm detection models ought to encode such speaker information. Current
methods have achieved this by way of laborious feature engineering. By
contrast, we propose to automatically learn and then exploit user embeddings,
to be used in concert with lexical signals to recognize sarcasm. Our approach
does not require elaborate feature engineering (and concomitant data scraping);
fitting user embeddings requires only the text from their previous posts. The
experimental results show that our model outperforms a state-of-the-art
approach leveraging an extensive set of carefully crafted features.
</dc:description>
 <dc:description>Comment: published as a conference paper at CONLL 2016</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00991</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifying Reachability in Networks with Mutable Datapaths</dc:title>
 <dc:creator>Panda, Aurojit</dc:creator>
 <dc:creator>Lahav, Ori</dc:creator>
 <dc:creator>Argyraki, Katerina</dc:creator>
 <dc:creator>Sagiv, Mooly</dc:creator>
 <dc:creator>Shenker, Scott</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Recent work has made great progress in verifying the forwarding correctness
of networks . However, these approaches cannot be used to verify networks
containing middleboxes, such as caches and firewalls, whose forwarding behavior
depends on previously observed traffic. We explore how to verify reachability
properties for networks that include such &quot;mutable datapath&quot; elements. We want
our verification results to hold not just for the given network, but also in
the presence of failures. The main challenge lies in scaling the approach to
handle large and complicated networks, We address by developing and leveraging
the concept of slices, which allow network-wide verification to only require
analyzing small portions of the network. We show that with slices the time
required to verify an invariant on many production networks is independent of
the size of the network itself.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00992</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generic Statistical Relational Entity Resolution in Knowledge Graphs</dc:title>
 <dc:creator>Pujara, Jay</dc:creator>
 <dc:creator>Getoor, Lise</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Entity resolution, the problem of identifying the underlying entity of
references found in data, has been researched for many decades in many
communities. A common theme in this research has been the importance of
incorporating relational features into the resolution process. Relational
entity resolution is particularly important in knowledge graphs (KGs), which
have a regular structure capturing entities and their interrelationships. We
identify three major problems in KG entity resolution: (1) intra-KG reference
ambiguity; (2) inter-KG reference ambiguity; and (3) ambiguity when extending
KGs with new facts. We implement a framework that generalizes across these
three settings and exploits this regular structure of KGs. Our framework has
many advantages over custom solutions widely deployed in industry, including
collective inference, scalability, and interpretability. We apply our framework
to two real-world KG entity resolution problems, ambiguity in NELL and merging
data from Freebase and MusicBrainz, demonstrating the importance of relational
features.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.00992</dc:identifier>
 <dc:identifier>In the Sixth International Workshop on Statistical Relational AI,
  2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01027</identifier>
 <datestamp>2017-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Stochastic Subgradient Methods under Local Error Bound
  Condition</dc:title>
 <dc:creator>Xu, Yi</dc:creator>
 <dc:creator>Lin, Qihang</dc:creator>
 <dc:creator>Yang, Tianbao</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose two {\bf accelerated stochastic subgradient}
methods for stochastic non-strongly convex optimization problems by leveraging
a generic local error bound condition. The novelty of the proposed methods lies
at smartly leveraging the recent historical solution to tackle the variance in
the stochastic subgradient. The key idea of both methods is to iteratively
solve the original problem approximately in a local region around a recent
historical solution with size of the local region gradually decreasing as the
solution approaches the optimal set. The difference of the two methods lies at
how to construct the local region. The first method uses an explicit ball
constraint and the second method uses an implicit regularization approach. For
both methods, we establish the improved iteration complexity in a high
probability for achieving an $\epsilon$-optimal solution. Besides the improved
order of iteration complexity with a high probability, the proposed algorithms
also enjoy a logarithmic dependence on the distance of the initial solution to
the optimal set. We also consider applications in machine learning and
demonstrate that the proposed algorithms enjoy faster convergence than the
traditional stochastic subgradient method. For example, when applied to the
$\ell_1$ regularized polyhedral loss minimization (e.g., hinge loss, absolute
loss), the proposed stochastic methods have a logarithmic iteration complexity.
</dc:description>
 <dc:description>Comment: added some new results in this version</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01032</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Echo Chambers: Emotional Contagion and Group Polarization on Facebook</dc:title>
 <dc:creator>Del Vicario, Michela</dc:creator>
 <dc:creator>Vivaldo, Gianna</dc:creator>
 <dc:creator>Bessi, Alessandro</dc:creator>
 <dc:creator>Zollo, Fabiana</dc:creator>
 <dc:creator>Scala, Antonio</dc:creator>
 <dc:creator>Caldarelli, Guido</dc:creator>
 <dc:creator>Quattrociocchi, Walter</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Recent findings showed that users on Facebook tend to select information that
adhere to their system of beliefs and to form polarized groups -- i.e., echo
chambers. Such a tendency dominates information cascades and might affect
public debates on social relevant issues. In this work we explore the
structural evolution of communities of interest by accounting for users
emotions and engagement. Focusing on the Facebook pages reporting on scientific
and conspiracy content, we characterize the evolution of the size of the two
communities by fitting daily resolution data with three growth models -- i.e.
the Gompertz model, the Logistic model, and the Log-logistic model. Then, we
explore the interplay between emotional state and engagement of users in the
group dynamics. Our findings show that communities' emotional behavior is
affected by the users' involvement inside the echo chamber. Indeed, to an
higher involvement corresponds a more negative approach. Moreover, we observe
that, on average, more active users show a faster shift towards the negativity
than less active ones.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01033</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Application of the EM-algorithm to Approximate Empirical
  Distributions of Financial Indices with the Gaussian Mixtures</dc:title>
 <dc:creator>Tarasenko, Sergey</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In this study I briefly illustrate application of the Gaussian mixtures to
approximate empirical distributions of financial indices (DAX, Dow Jones,
Nikkei, RTSI, S&amp;P 500). The resulting distributions illustrate very high
quality of approximation as evaluated by Kolmogorov-Smirnov test. This implies
further study of application of the Gaussian mixtures to approximate empirical
distributions of financial indices.
</dc:description>
 <dc:description>Comment: 3 pages, 5 figures</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01036</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bootstrap Model Aggregation for Distributed Statistical Learning</dc:title>
 <dc:creator>Han, Jun</dc:creator>
 <dc:creator>Liu, Qiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In distributed, or privacy-preserving learning, we are often given a set of
probabilistic models estimated from different local repositories, and asked to
combine them into a single model that gives efficient statistical estimation. A
simple method is to linearly average the parameters of the local models, which,
however, tends to be degenerate or not applicable on non-convex models, or
models with different parameter dimensions. One more practical strategy is to
generate bootstrap samples from the local models, and then learn a joint model
based on the combined bootstrap set. Unfortunately, the bootstrap procedure
introduces additional noise and can significantly deteriorate the performance.
In this work, we propose two variance reduction methods to correct the
bootstrap noise, including a weighted M-estimator that is both statistically
efficient and practically powerful. Both theoretical and empirical analysis is
provided to demonstrate our methods.
</dc:description>
 <dc:description>Comment: This paper is about variance reduction on Monte Carol estimation of
  KL divergence, NIPS, 2016</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01039</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Tera-scale Walsh-Hadamard Transform</dc:title>
 <dc:creator>Lu, Yi</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In the mid-second decade of new millennium, the development of IT has reached
unprecedented new heights. As one derivative of Moore's law, the operating
system evolves from the initial 16 bits, 32 bits, to the ultimate 64 bits. Most
modern computing platforms are in transition to the 64-bit versions. For
upcoming decades, IT industry will inevitably favor software and systems, which
can efficiently utilize the new 64-bit hardware resources. In particular, with
the advent of massive data outputs regularly, memory-efficient software and
systems would be leading the future.
  In this paper, we aim at studying practical Walsh-Hadamard Transform (WHT).
WHT is popular in a variety of applications in image and video coding, speech
processing, data compression, digital logic design, communications, just to
name a few. The power and simplicity of WHT has stimulated research efforts and
interests in (noisy) sparse WHT within interdisciplinary areas including (but
is not limited to) signal processing, cryptography. Loosely speaking, sparse
WHT refers to the case that the number of nonzero Walsh coefficients is much
smaller than the dimension; the noisy version of sparse WHT refers to the case
that the number of large Walsh coefficients is much smaller than the dimension
while there exists a large number of small nonzero Walsh coefficients. Clearly,
general Walsh-Hadamard Transform is a first solution to the noisy sparse WHT,
which can obtain all Walsh coefficients larger than a given threshold and the
index positions. In this work, we study efficient implementations of very large
dimensional general WHT. Our work is believed to shed light on noisy sparse
WHT, which remains to be a big open challenge. Meanwhile, the main idea behind
will help to study parallel data-intensive computing, which has a broad range
of applications.
</dc:description>
 <dc:description>Comment: to appear in proceedings of Future Technologies Conference - FTC
  2016, San Francisco, 6 - 7 Dec, IEEE</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:date>2016-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01039</dc:identifier>
 <dc:identifier>doi:10.1109/FTC.2016.7821757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01040</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Facial Expression Classification Using Rotation Slepian-based Moment
  Invariants</dc:title>
 <dc:creator>Zou, Cuiming</dc:creator>
 <dc:creator>Kou, Kit Ian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>30E05, 33E10, 14L24</dc:subject>
 <dc:description>  Rotation moment invariants have been of great interest in image processing
and pattern recognition. This paper presents a novel kind of rotation moment
invariants based on the Slepian functions, which were originally introduced in
the method of separation of variables for Helmholtz equations. They were first
proposed for time series by Slepian and his coworkers in the 1960s. Recent
studies have shown that these functions have an good performance in local
approximation compared to other approximation basis. Motivated by the good
approximation performance, we construct the Slepian-based moments and derive
the rotation invariant. We not only theoretically prove the invariance, but
also discuss the experiments on real data. The proposed rotation invariants are
robust to noise and yield decent performance in facial expression
classification.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures</dc:description>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01044</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient target control of complex networks based on preferential
  matching</dc:title>
 <dc:creator>Zhang, Xizhe</dc:creator>
 <dc:creator>Wang, Huaizhen</dc:creator>
 <dc:creator>Lv, Tianyang</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Controlling a complex network towards a desire state is of great importance
in many applications. Existing works present an approximate algorithm to find
the driver nodes used to control partial nodes of the network. However, the
driver nodes obtained by this algorithm depend on the matching order of nodes
and cannot get the optimum results. Here we present a novel algorithm to find
the driver nodes for target control based on preferential matching. The
algorithm elaborately arrange the matching order of nodes in order to minimize
the size of the driver nodes set. The results on both synthetic and real
networks indicate that the performance of proposed algorithm are better than
the previous one. The algorithm may have various application in controlling
complex networks.
</dc:description>
 <dc:date>2016-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01044</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0175375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01046</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Walking without a Map: Optimizing Response Times of Traversal-Based
  Linked Data Queries (Extended Version)</dc:title>
 <dc:creator>Hartig, Olaf</dc:creator>
 <dc:creator>&#xd6;zsu, M. Tamer</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The emergence of Linked Data on the WWW has spawned research interest in an
online execution of declarative queries over this data. A particularly
interesting approach is traversal-based query execution which fetches data by
traversing data links and, thus, is able to make use of up-to-date data from
initially unknown data sources. The downside of this approach is the delay
before the query engine completes a query execution. In this paper, we address
this problem by proposing an approach to return as many elements of the result
set as soon as possible. The basis of this approach is a traversal strategy
that aims to fetch result-relevant data as early as possible. The challenge for
such a strategy is that the query engine does not know a priori which of the
data sources that will be discovered during the query execution contain
result-relevant data. We introduce 16 different traversal approaches and
experimentally study their impact on response times. Our experiments show that
some of the approaches can achieve significant improvements over the baseline
of looking up URIs on a first-come, first-served basis. Additionally, we verify
the importance of these approaches by showing that typical query optimization
techniques that focus solely on the process of constructing the query result
cannot have any significant impact on the response times of traversal-based
query executions.
</dc:description>
 <dc:description>Comment: This document is an extended version of a paper published in ISWC
  2016. In addition to a more detailed discussion of the experimental results
  presented in the conference version, this extended version provides an
  in-depth description of our approach to implement traversal-based query
  execution, and we present a number of additional experiments</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01048</identifier>
 <datestamp>2017-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity of Gaussian Many-Access Channels</dc:title>
 <dc:creator>Chen, Xu</dc:creator>
 <dc:creator>Chen, Tsung-Yi</dc:creator>
 <dc:creator>Guo, Dongning</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Classical multiuser information theory studies the fundamental limits of
models with a fixed (often small) number of users as the coding blocklength
goes to infinity. This work proposes a new paradigm, referred to as {\em
many-user information theory}, where the number of users is allowed to grow
with the blocklength. This paradigm is motivated by emerging systems with a
massive number of users in an area, such as machine-to-machine communication
systems and sensor networks. The focus of the current paper is the {\em
many-access} channel model, which consists of a single receiver and many
transmitters, whose number increases unboundedly with the blocklength.
Moreover, an unknown subset of transmitters may transmit in a given block and
need to be identified. A new notion of capacity is introduced and characterized
for the Gaussian many-access channel with random user activities. The capacity
can be achieved by first detecting the set of active users and then decoding
their messages.
</dc:description>
 <dc:description>Comment: To appear in the IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01050</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Statistical Relational Learning to Hybrid Recommendation
  Systems</dc:title>
 <dc:creator>Yang, Shuo</dc:creator>
 <dc:creator>Korayem, Mohammed</dc:creator>
 <dc:creator>AlJadda, Khalifeh</dc:creator>
 <dc:creator>Grainger, Trey</dc:creator>
 <dc:creator>Natarajan, Sriraam</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recommendation systems usually involve exploiting the relations among known
features and content that describe items (content-based filtering) or the
overlap of similar users who interacted with or rated the target item
(collaborative filtering). To combine these two filtering approaches, current
model-based hybrid recommendation systems typically require extensive feature
engineering to construct a user profile. Statistical Relational Learning (SRL)
provides a straightforward way to combine the two approaches. However, due to
the large scale of the data used in real world recommendation systems, little
research exists on applying SRL models to hybrid recommendation systems, and
essentially none of that research has been applied on real big-data-scale
systems. In this paper, we proposed a way to adapt the state-of-the-art in SRL
learning approaches to construct a real hybrid recommendation system.
Furthermore, in order to satisfy a common requirement in recommendation systems
(i.e. that false positives are more undesirable and therefore penalized more
harshly than false negatives), our approach can also allow tuning the trade-off
between the precision and recall of the system in a principled way. Our
experimental results demonstrate the efficiency of our proposed approach as
well as its improved performance on recommendation precision.
</dc:description>
 <dc:description>Comment: Statistical Relational AI 2016</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01059</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Sparse Representation-Based Classification Using Local
  Principal Component Analysis</dc:title>
 <dc:creator>Weaver, Chelsea</dc:creator>
 <dc:creator>Saito, Naoki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse representation-based classification (SRC), proposed by Wright et al.,
seeks the sparsest decomposition of a test sample over the dictionary of
training samples, with classification to the most-contributing class. Because
it assumes test samples can be written as linear combinations of their
same-class training samples, the success of SRC depends on the size and
representativeness of the training set. Our proposed classification algorithm
enlarges the training set by using local principal component analysis to
approximate the basis vectors of the tangent hyperplane of the class manifold
at each training sample. The dictionary in SRC is replaced by a local
dictionary that adapts to the test sample and includes training samples and
their corresponding tangent basis vectors. We use a synthetic data set and
three face databases to demonstrate that this method can achieve higher
classification accuracy than SRC in cases of sparse sampling, nonlinear class
manifolds, and stringent dimension reduction.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01064</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GfcLLL: A Greedy Selection Based Approach for Fixed-Complexity LLL
  Reduction</dc:title>
 <dc:creator>Wen, Jinming</dc:creator>
 <dc:creator>Chang, Xiao Wen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The LLL lattice reduction has been widely used to decrease the bit error rate
(BER) of the Babai point, but its running time varies much from matrix to
matrix. To address this problem, some fixed-complexity LLL reductions (FCLLL)
have been proposed. In this paper, we propose two greedy selection based FCLLL
algorithms: GfcLLL(1) and GfcLLL(2). Simulations show that both of them give
Babai points with lower BER in similar or much shorter CPU time than existing
ones.
</dc:description>
 <dc:description>Comment: To appear in IEEE Communications Letters</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01075</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Affect Intensity Estimation Using Multiple Modalities</dc:title>
 <dc:creator>Patwardhan, Amol</dc:creator>
 <dc:creator>Knapp, Gerald</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  One of the challenges in affect recognition is accurate estimation of the
emotion intensity level. This research proposes development of an affect
intensity estimation model based on a weighted sum of classification confidence
levels, displacement of feature points and speed of feature point motion. The
parameters of the model were calculated from data captured using multiple
modalities such as face, body posture, hand movement and speech. A preliminary
study was conducted to compare the accuracy of the model with the annotated
intensity levels. An emotion intensity scale ranging from 0 to 1 along the
arousal dimension in the emotion space was used. Results indicated speech and
hand modality significantly contributed in improving accuracy in emotion
intensity estimation using the proposed model.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, 2 tables, Published as short paper in (Florida
  Artificial Intelligence Research Society Conference (2014)) Flairs 27
  Conference. Peer reviewed and published paper, Key words: affect, intensity,
  multimodal, Kinect, emotion, face, body, hand, head, speech</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01076</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aggressive actions and anger detection from multiple modalities using
  Kinect</dc:title>
 <dc:creator>Patwardhan, Amol</dc:creator>
 <dc:creator>Knapp, Gerald</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Prison facilities, mental correctional institutions, sports bars and places
of public protest are prone to sudden violence and conflicts. Surveillance
systems play an important role in mitigation of hostile behavior and
improvement of security by detecting such provocative and aggressive
activities. This research proposed using automatic aggressive behavior and
anger detection to improve the effectiveness of the surveillance systems. An
emotion and aggression aware component will make the surveillance system highly
responsive and capable of alerting the security guards in real time. This
research proposed facial expression, head, hand and body movement and speech
tracking for detecting anger and aggressive actions. Recognition was achieved
using support vector machines and rule based features. The multimodal affect
recognition precision rate for anger improved by 15.2% and recall rate improved
by 11.7% when behavioral rule based features were used in aggressive action
detection.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures, 5 tables, in peer review with ACM TIST, Key
  words: Aggression, multimodal anger recognition, Kinect</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01077</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EmoFit: Affect Monitoring System for Sedentary Jobs</dc:title>
 <dc:creator>Patwardhan, Amol</dc:creator>
 <dc:creator>Knapp, Gerald</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Emotional and physical well-being at workplace is important for a positive
work environment and higher productivity. Jobs such as software programming
lead to a sedentary lifestyle and require high interaction with computers.
Working at the same job for years can cause a feeling of intellectual
stagnation and lack of drive. Many employees experience lack of motivation,
mild to extreme depression due to reasons such as aversion towards job
responsibilities and incompatibility with coworkers or boss. This research
proposed an affect monitoring system EmoFit that would play the role of
psychological and physical health trainer. The day to day computer activity and
body language was analyzed to detect the physical and emotional well-being of
the user. Keystrokes, activity interruptions, eye tracking, facial expressions,
body posture and speech were monitored to gauge the users health. The system
also provided activities such as at-desk exercise and stress relief game and
motivational quotes in an attempt to promote users well-being. The experimental
results and positive feedback from test subjects showed that EmoFit would help
improve emotional and physical well-being at jobs that involve significant
computer usage.
</dc:description>
 <dc:description>Comment: 9 pages, 10 figures, Preprint, arXiv.org</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01084</identifier>
 <datestamp>2016-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Models for Split-execution Computing Systems</dc:title>
 <dc:creator>Humble, Travis S.</dc:creator>
 <dc:creator>McCaskey, Alexander J.</dc:creator>
 <dc:creator>Schrock, Jonathan</dc:creator>
 <dc:creator>Seddiqi, Hadayat</dc:creator>
 <dc:creator>Britt, Keith A.</dc:creator>
 <dc:creator>Imam, Neena</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Split-execution computing leverages the capabilities of multiple
computational models to solve problems, but splitting program execution across
different computational models incurs costs associated with the translation
between domains. We analyze the performance of a split-execution computing
system developed from conventional and quantum processing units (QPUs) by using
behavioral models that track resource usage. We focus on asymmetric processing
models built using conventional CPUs and a family of special-purpose QPUs that
employ quantum computing principles. Our performance models account for the
translation of a classical optimization problem into the physical
representation required by the quantum processor while also accounting for
hardware limitations and conventional processor speed and memory. We conclude
that the bottleneck in this split-execution computing system lies at the
quantum-classical interface and that the primary time cost is independent of
quantum processor behavior.
</dc:description>
 <dc:description>Comment: Presented at 18th Workshop on Advances in Parallel and Distributed
  Computational Models [APDCM2016] on 23 May 2016; 10 pages</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01084</dc:identifier>
 <dc:identifier>2016 IEEE International Parallel and Distributed Processing
  Symposium Workshops, pp. 545-554 (2016)</dc:identifier>
 <dc:identifier>doi:10.1109/IPDPSW.2016.113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01085</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Association with Maximizing Sum Energy Efficiency for Massive MIMO
  Enabled Heterogeneous Cellular Networks</dc:title>
 <dc:creator>Zhou, Tianqing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we design an association scheme to maximize the sum energy
efficiency for massive multiple-input and multiple-output (MIMO) enabled
heterogeneous cellular networks (HCNs). Considering that the final formulated
problem is in a sum-of-ratio form, we first need to transform it into a
parametric nonfractional form, by which we can achieve its solution through a
two-layer iterative algorithm. The outer layer searches the energy efficiency
parameters and multipliers associated with signal-interference-plus-noise-ratio
(SINR) constraints using Newton-like method, and the inner layer optimizes the
association indices using Lagrange multiplier method. In fact, the inner layer
doesn't need iterative steps when the SINR constraints are not involved in the
original problem, and then the whole algorithm should be a one-layer iterative
one. As for the two-layer iterative algorithm, we also give the corresponding
convergence proof. Numerical results show that the proposed scheme
significantly outperforms the existing one in system throughput and network
energy efficiency. In addition, we also investigate the impacts of the number
of massive antennas and the transmit power of each pico base station on these
association performances.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01091</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Amplify-and-Forward Full-Duplex Relay with Power Splitting-Based SWIPT</dc:title>
 <dc:creator>Liu, Hongwu</dc:creator>
 <dc:creator>Kwak, Kyung Sup</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a virtual harvest-transmit model and a
harvest-transmit-store model for amplify-and-forward full-duplex relay (FDR)
networks with power splitting-based simultaneous wireless information and power
transfer. The relay node employs a battery group consisting of two rechargeable
batteries. By switching periodically between two batteries for charging and
discharging in two consecutive time slots of each transmission block, all the
harvested energy in each block has been applied for full duplex transmission in
the virtual harvest-transmit model. By employing energy scheduling, the relay
node switches among the harvesting, relaying, harvesting-relaying, and idle
behaviors at a block level, so that a part of the harvested energy in a block
can be scheduled for future usage in the harvest-transmit-store model. A greedy
switching policy is designed to implement the harvest-transmit-store model,
where the FDR node transmits when its residual energy ensures decoding at the
destination. Numerical results verify the outage performance of the proposed
schemes.
</dc:description>
 <dc:description>Comment: 4 pages, submit to a conference</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01092</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incorporating prior knowledge in medical image segmentation: a survey</dc:title>
 <dc:creator>Nosrati, Masoud S.</dc:creator>
 <dc:creator>Hamarneh, Ghassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Medical image segmentation, the task of partitioning an image into meaningful
parts, is an important step toward automating medical image analysis and is at
the crux of a variety of medical imaging applications, such as computer aided
diagnosis, therapy planning and delivery, and computer aided interventions.
However, the existence of noise, low contrast and objects' complexity in
medical images are critical obstacles that stand in the way of achieving an
ideal segmentation system. Incorporating prior knowledge into image
segmentation algorithms has proven useful for obtaining more accurate and
plausible results. This paper surveys the different types of prior knowledge
that have been utilized in different segmentation frameworks. We focus our
survey on optimization-based methods that incorporate prior information into
their frameworks. We review and compare these methods in terms of the types of
prior employed, the domain of formulation (continuous vs. discrete), and the
optimization techniques (global vs. local). We also created an interactive
online database of existing works and categorized them based on the type of
prior knowledge they use. Our website is interactive so that researchers can
contribute to keep the database up to date. We conclude the survey by
discussing different aspects of designing an energy functional for image
segmentation, open problems, and future perspectives.
</dc:description>
 <dc:description>Comment: Survey paper, 30 pages</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01097</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AdaNet: Adaptive Structural Learning of Artificial Neural Networks</dc:title>
 <dc:creator>Cortes, Corinna</dc:creator>
 <dc:creator>Gonzalvo, Xavi</dc:creator>
 <dc:creator>Kuznetsov, Vitaly</dc:creator>
 <dc:creator>Mohri, Mehryar</dc:creator>
 <dc:creator>Yang, Scott</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present new algorithms for adaptively learning artificial neural networks.
Our algorithms (AdaNet) adaptively learn both the structure of the network and
its weights. They are based on a solid theoretical analysis, including
data-dependent generalization guarantees that we prove and discuss in detail.
We report the results of large-scale experiments with one of our algorithms on
several binary classification tasks extracted from the CIFAR-10 dataset. The
results demonstrate that our algorithm can automatically learn network
structures with very competitive performance accuracies when compared with
those achieved for neural networks found by standard approaches.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01100</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization, Decomposition, and Dictionary Learning of
  Piecewise-Constant Signals on Graphs</dc:title>
 <dc:creator>Chen, Siheng</dc:creator>
 <dc:creator>Yang, Yaoqing</dc:creator>
 <dc:creator>Moura, Jos&#xe9;. M. F.</dc:creator>
 <dc:creator>Kova&#x10d;evi&#x107;, Jelena</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Motivated by the need to extract meaning from large amounts of complex
structured data, we consider three critical problems on graphs: localization,
decomposition, and dictionary learning of piecewise-constant signals. These
graph-based problems are related to many real-world applications, such as
localizing stimulus in brain connectivity networks, and mining traffic events
in city street networks, where the key issue is to find the supports of
localized activated patterns. Counterparts of these problems in classical
signal/image processing, such as impulse detection and foreground detection,
have been studied over the past few decades. We use piecewise-constant graph
signals to model localized patterns, where each piece indicates a localized
pattern that exhibits homogeneous internal behavior and the number of pieces
indicates the number of localized patterns. For such signals, we show that
decomposition and dictionary learning are natural extensions of localization,
the goal of which is not only to efficiently approximate graph signals, but
also to accurately find supports of localized patterns. For each of the three
problems, i.e., localization, decomposition, and dictionary learning, we
propose a specific graph signal model, an optimization problem, and a
computationally efficient solver. The proposed solvers directly find the
supports of arbitrary localized activated patterns without tuning any
thresholds. We then conduct an extensive empirical study to validate the
proposed methods on both simulated and real data including the analysis of a
large volume of spatio-temporal Manhattan urban data. The analysis validates
the effectiveness of the approach and suggests that graph signal processing
tools may aid in urban planning and traffic forecasting.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01102</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Visualization Method of Four Dimensional Polytopes by Oval Display of
  Parallel Hyperplane Slices</dc:title>
 <dc:creator>Kageyama, Akira</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  A method to visualize polytopes in a four dimensional euclidian space
$(x,y,z,w)$ is proposed. A polytope is sliced by multiple hyperplanes that are
parallel each other and separated by uniform intervals. Since the hyperplanes
are perpendicular to the $w$ axis, the resulting multiple slices appear in the
three-dimensional $(x,y,z)$ space and they are shown by the standard computer
graphics. The polytope is rotated extrinsically in the four dimensional space
by means of a simple input method based on keyboard typings. The multiple
slices are placed on a parabola curve in the three-dimensional world
coordinates. The slices in a view window form an oval appearance. Both the
simple and the double rotations in the four dimensional space are applied to
the polytope. All slices synchronously change their shapes when a rotation is
applied to the polytope. The compact display in the oval of many slices with
the help of quick rotations facilitate a grasp of the four dimensional
configuration of the polytope.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01115</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Click Carving: Segmenting Objects in Video with Point Clicks</dc:title>
 <dc:creator>Jain, Suyog Dutt</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We present a novel form of interactive video object segmentation where a few
clicks by the user helps the system produce a full spatio-temporal segmentation
of the object of interest. Whereas conventional interactive pipelines take the
user's initialization as a starting point, we show the value in the system
taking the lead even in initialization. In particular, for a given video frame,
the system precomputes a ranked list of thousands of possible segmentation
hypotheses (also referred to as object region proposals) using image and motion
cues. Then, the user looks at the top ranked proposals, and clicks on the
object boundary to carve away erroneous ones. This process iterates (typically
2-3 times), and each time the system revises the top ranked proposal set, until
the user is satisfied with a resulting segmentation mask. Finally, the mask is
propagated across the video to produce a spatio-temporal object tube. On three
challenging datasets, we provide extensive comparisons with both existing work
and simpler alternative methods. In all, the proposed Click Carving approach
strikes an excellent balance of accuracy and human effort. It outperforms all
similarly fast methods, and is competitive or better than those requiring 2 to
12 times the effort.
</dc:description>
 <dc:description>Comment: A preliminary version of the material in this document was filed as
  University of Texas technical report no. UT AI16-01</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01116</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power-Efficient Resource Allocation for MC-NOMA with Statistical Channel
  State Information</dc:title>
 <dc:creator>Wei, Zhiqiang</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Yuan, Jinhong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the power-efficient resource allocation for
multicarrier non-orthogonal multiple access (MC-NOMA) systems. The resource
allocation algorithm design is formulated as a non-convex optimization problem
which takes into account the statistical channel state information at
transmitter and quality of service (QoS) constraints. To strike a balance
between system performance and computational complexity, we propose a
suboptimal power allocation and user scheduling with low computational
complexity to minimize the total power consumption. The proposed design
exploits the heterogeneity of QoS requirement to determine the successive
interference cancellation decoding order. Simulation results demonstrate that
the proposed scheme achieves a close-to-optimal performance and significantly
outperforms a conventional orthogonal multiple access (OMA) scheme.
</dc:description>
 <dc:description>Comment: 7 Pages, 5 figures, accepted to IEEE GLOBECOM 2016</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01119</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On User Association in Multi-Tier Full-Duplex Cellular Networks</dc:title>
 <dc:creator>Sakr, Ahmed Hamdi</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We address the user association problem in multi-tier in-band full-duplex
(FD) networks. Specifically, we consider the case of decoupled user association
(DUA) in which users (UEs) are not necessarily served by the same base station
(BS) for uplink (UL) and downlink (DL) transmissions. Instead, UEs can
simultaneously associate to different BSs based on two independent weighted
path-loss user association criteria for UL and DL. We use stochastic geometry
to develop a comprehensive modeling framework for the proposed system model
where BSs and UEs are spatially distributed according to independent point
processes. We derive closed-form expressions for the mean rate utility in FD,
half-duplex (HD) DL, and HD UL networks as well as the mean rate utility of
legacy nodes with only HD capabilities in a multi-tier FD network. We formulate
and solve an optimization problem that aims at maximizing the mean rate utility
of the FD network by optimizing the DL and UL user association criteria. We
investigate the effects of different network parameters including the spatial
density of BSs and power control parameter. We also investigate the effect of
imperfect self-interference cancellation (SIC) and show that it is more severe
at UL, where there exist minimum required SIC capabilities for BSs and UEs for
which FD networks are preferable to HD networks; otherwise, HD networks are
preferable. In addition, we discuss several special cases and provide
guidelines on the possible extensions of the proposed framework. We conclude
that DUA outperforms coupled user association (CUA) in which UEs associate to
the same BS for both UL and DL transmissions.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01124</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Double Covers of Factor Graphs</dc:title>
 <dc:creator>Vontobel, Pascal O.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Many quantities of interest in communications, signal processing, artificial
intelligence, and other areas can be expressed as the partition sum of some
factor graph. Although the exact calculation of the partition sum is in many
cases intractable, it can often be approximated rather well by the Bethe
partition sum. In earlier work, we have shown that graph covers are a useful
tool for expressing and analyzing the Bethe approximation. In this paper, we
present a novel technique for analyzing double covers, a technique which
ultimately leads to a deeper understanding of the Bethe approximation.
</dc:description>
 <dc:description>Comment: Proceedings of the 2016 International Conference on Signal Processing
  and Communications, Bangalore, India, June 12-15, 2016</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01133</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning when to trust distant supervision: An application to
  low-resource POS tagging using cross-lingual projection</dc:title>
 <dc:creator>Fang, Meng</dc:creator>
 <dc:creator>Cohn, Trevor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Cross lingual projection of linguistic annotation suffers from many sources
of bias and noise, leading to unreliable annotations that cannot be used
directly. In this paper, we introduce a novel approach to sequence tagging that
learns to correct the errors from cross-lingual projection using an explicit
debiasing layer. This is framed as joint learning over two corpora, one tagged
with gold standard and the other with projected tags. We evaluated with only
1,000 tokens tagged with gold standard tags, along with more plentiful parallel
data. Our system equals or exceeds the state-of-the-art on eight simulated
low-resource settings, as well as two real low-resource languages, Malagasy and
Kinyarwanda.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01134</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vital nodes identification in complex networks</dc:title>
 <dc:creator>L&#xfc;, Linyuan</dc:creator>
 <dc:creator>Chen, Duanbing</dc:creator>
 <dc:creator>Ren, Xiao-Long</dc:creator>
 <dc:creator>Zhang, Qian-Ming</dc:creator>
 <dc:creator>Zhang, Yi-Cheng</dc:creator>
 <dc:creator>Zhou, Tao</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Real networks exhibit heterogeneous nature with nodes playing far different
roles in structure and function. To identify vital nodes is thus very
significant, allowing us to control the outbreak of epidemics, to conduct
advertisements for e-commercial products, to predict popular scientific
publications, and so on. The vital nodes identification attracts increasing
attentions from both computer science and physical societies, with algorithms
ranging from simply counting the immediate neighbors to complicated machine
learning and message passing approaches. In this review, we clarify the
concepts and metrics, classify the problems and methods, as well as review the
important progresses and describe the state of the art. Furthermore, we provide
extensive empirical analyses to compare well-known methods on disparate real
networks, and highlight the future directions. In despite of the emphasis on
physics-rooted approaches, the unification of the language and comparison with
cross-domain methods would trigger interdisciplinary solutions in the near
future.
</dc:description>
 <dc:description>Comment: 121Pages, 20 figures</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01134</dc:identifier>
 <dc:identifier>doi:10.1016/j.physrep.2016.06.007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01136</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimalist Regression Network with Reinforced Gradients and Weighted
  Estimates: a Case Study on Parameters Estimation in Automated Welding</dc:title>
 <dc:creator>Keshmiri, Soheil</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a minimalist neural regression network as an aggregate of
independent identical regression blocks that are trained simultaneously.
Moreover, it introduces a new multiplicative parameter, shared by all the
neural units of a given layer, to maintain the quality of its gradients.
Furthermore, it increases its estimation accuracy via learning a weight factor
whose quantity captures the redundancy between the estimated and actual values
at each training iteration. We choose the estimation of the direct weld
parameters of different welding techniques to show a significant improvement in
calculation of these parameters by our model in contrast to state-of-the-arts
techniques in the literature. Furthermore, we demonstrate the ability of our
model to retain its performance when presented with combined data of different
welding techniques. This is a nontrivial result in attaining an scalable model
whose quality of estimation is independent of adopted welding techniques.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01146</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a new convergence class in k-bounded sober spaces</dc:title>
 <dc:creator>Andradi, Hadrian</dc:creator>
 <dc:creator>Ho, Weng Kin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>54A20, 06B35</dc:subject>
 <dc:description>  Recently, J. D. Lawson encouraged the domain theory community to consider the
scientific program of developing domain theory in the wider context of $T_0$
spaces instead of restricting to posets. In this paper, we respond to this
calling by proving a topological parallel of a 2005 result due to B. Zhao and
D. Zhao, i.e., an order-theoretic characterisation of those posets for which
the lim-inf convergence is topological. We do this by adopting a recent
approach due to D. Zhao and W. K. Ho by replacing directed subsets with
irreducible sets. As a result, we formulate a new convergence class on $T_0$
spaces called Irr-convergence and established that this convergence class
$\mathcal{I}$ on a $k$-bounded sober space $X$ is topological if and only if
$X$ is Irr-continuous.
</dc:description>
 <dc:description>Comment: 10 pages, Domains XII Workshop</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01149</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Target-Side Context for Discriminative Models in Statistical Machine
  Translation</dc:title>
 <dc:creator>Tamchyna, Ale&#x161;</dc:creator>
 <dc:creator>Fraser, Alexander</dc:creator>
 <dc:creator>Bojar, Ond&#x159;ej</dc:creator>
 <dc:creator>Junczys-Dowmunt, Marcin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Discriminative translation models utilizing source context have been shown to
help statistical machine translation performance. We propose a novel extension
of this work using target context information. Surprisingly, we show that this
model can be efficiently integrated directly in the decoding process. Our
approach scales to large training data sizes and results in consistent
improvements in translation quality on four language pairs. We also provide an
analysis comparing the strengths of the baseline source-context model with our
extended source-context and target-context model and we show that our extension
allows us to better capture morphological coherence. Our work is freely
available as part of Moses.
</dc:description>
 <dc:description>Comment: Accepted as a long paper for ACL 2016</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01152</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Evaluate the Quality of Unsupervised Anomaly Detection
  Algorithms?</dc:title>
 <dc:creator>Goix, Nicolas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  When sufficient labeled data are available, classical criteria based on
Receiver Operating Characteristic (ROC) or Precision-Recall (PR) curves can be
used to compare the performance of un-supervised anomaly detection algorithms.
However , in many situations, few or no data are labeled. This calls for
alternative criteria one can compute on non-labeled data. In this paper, two
criteria that do not require labels are empirically shown to discriminate
accurately (w.r.t. ROC or PR based criteria) between algorithms. These criteria
are based on existing Excess-Mass (EM) and Mass-Volume (MV) curves, which
generally cannot be well estimated in large dimension. A methodology based on
feature sub-sampling and aggregating is also described and tested, extending
the use of these criteria to high-dimensional datasets and solving major
drawbacks inherent to standard EM and MV curves.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01159</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Network-Failure-Tolerant Content Delivery for Web Content</dc:title>
 <dc:creator>Hu, Wen</dc:creator>
 <dc:creator>Wang, Zhi</dc:creator>
 <dc:creator>Sun, Lifeng</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Popularly used to distribute a variety of multimedia content items in today
Internet, HTTP-based web content delivery still suffers from various content
delivery failures. Hindered by the expensive deployment cost, the conventional
CDN can not deploy as many edge servers as possible to successfully deliver
content items to all users under these delivery failures. In this paper, we
propose a joint CDN and peer-assisted web content delivery framework to address
the delivery failure problem. Different from conventional peer-assisted
approaches for web content delivery, which mainly focus on alleviating the CDN
servers bandwidth load, we study how to use a browser-based peer-assisted
scheme, namely WebRTC, to resolve content delivery failures. To this end, we
carry out large-scale measurement studies on how users access and view
webpages. Our measurement results demonstrate the challenges (e.g., peers stay
on a webpage extremely short) that can not be directly solved by conventional
P2P strategies, and some important webpage viewing patterns. Due to these
unique characteristics, WebRTC peers open up new possibilities for helping the
web content delivery, coming with the problem of how to utilize the dynamic
resources efficiently. We formulate the peer selection that is the critical
strategy in our framework, as an optimization problem, and design a heuristic
algorithm based on the measurement insights to solve it. Our simulation
experiments driven by the traces from Tencent QZone demonstrate the
effectiveness of our design: compared with non-peer-assisted strategy and
random peer selection strategy, our design significantly improves the
successful relay ratio of web content items under network failures, e.g., our
design improves the content download ratio up to 60% even when users located in
a particular region (e.g., city) where none can connect to the regional CDN
server.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01162</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unit Interval Vertex Deletion: Fewer Vertices are Relevant</dc:title>
 <dc:creator>Ke, Yuping</dc:creator>
 <dc:creator>Cao, Yixin</dc:creator>
 <dc:creator>Ouyang, Xiating</dc:creator>
 <dc:creator>Wang, Jianxin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C75, 68R10</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  The unit interval vertex deletion problem asks for a set of at most $k$
vertices whose deletion from an $n$-vertex graph makes it a unit interval
graph. We develop an $O(k^4)$-vertex kernel for the problem, significantly
improving the $O(k^{53})$-vertex kernel of Fomin, Saurabh, and Villanger
[ESA'12; SIAM J. Discrete Math 27(2013)]. We introduce a novel way of
organizing cliques of a unit interval graph. Our constructive proof for the
correctness of our algorithm, using interval models, greatly simplifies the
destructive proofs, based on forbidden induced subgraphs, for similar problems
in literature.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01164</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domains via approximation operators</dc:title>
 <dc:creator>Zou, Zhiwei</dc:creator>
 <dc:creator>Li, Qingguo</dc:creator>
 <dc:creator>Ho, Weng Kin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>06B35</dc:subject>
 <dc:description>  In this paper , we tailor-made new approximation operators specially suited
for domain theory. Our approximation operators offers a fresh perspective to
existing concepts and results in domain theory, but also reveals ways to
establishing novel domain-theoretic results. For instance, (1) the well-known
interpolation property of the way-below relation on a continuous poset is
equivalent to the idempotence of a certain set-operator; (2) the continuity of
a poset can be characterized by the coincidence of the Scott closure operator
and the upper approximation operator induced by the way below relation; (3) we
discussed the property which named one-step closure. Additionally, we show how,
to each approximating relation, an associated order-compatible topology can be
defined in such a way that for the case of a continuous poset the topology
associated to the way-below relation is exactly the Scott topology. A
preliminary investigation is carried out on this new topology.
</dc:description>
 <dc:description>Comment: 17 pages; 1figure, Domains XII Workshop</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01167</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic polynomial-time approximation algorithms for partition
  functions and graph polynomials</dc:title>
 <dc:creator>Patel, Viresh</dc:creator>
 <dc:creator>Regts, Guus</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we show a new way of constructing deterministic polynomial-time
approximation algorithms for computing complex-valued evaluations of a large
class of graph polynomials on bounded degree graphs. In particular, our
approach works for the Tutte polynomial and independence polynomial, as well as
partition functions of complex-valued spin and edge-coloring models.
  More specifically, we define a large class of graph polynomials $\mathcal C$
and show that if $p\in \cal C$ and there is a disk $D$ centered at zero in the
complex plane such that $p(G)$ does not vanish on $D$ for all bounded degree
graphs $G$, then for each $z$ in the interior of $D$ there exists a
deterministic polynomial-time approximation algorithm for evaluating $p(G)$ at
$z$. This gives an explicit connection between absence of zeros of graph
polynomials and the existence of efficient approximation algorithms, allowing
us to show new relationships between well-known conjectures.
  Our work builds on a recent line of work initiated by. Barvinok, which
provides a new algorithmic approach besides the existing Markov chain Monte
Carlo method and the correlation decay method for these types of problems.
</dc:description>
 <dc:description>Comment: 27 pages; some changes have been made based on referee comments. In
  particular a tiny error in Proposition 4.4 has been fixed. The introduction
  and concluding remarks have also been rewritten to incorporate the most
  recent developments. Accepted for publication in SIAM Journal on Computation</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01167</dc:identifier>
 <dc:identifier>SIAM J. Comput., 46(6), 1893-1919</dc:identifier>
 <dc:identifier>doi:10.1137/16M1101003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01172</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Measurement Study of TCP Performance for Chunk Delivery in DASH</dc:title>
 <dc:creator>Hu, Wen</dc:creator>
 <dc:creator>Wang, Zhi</dc:creator>
 <dc:creator>Sun, Lifeng</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Dynamic Adaptive Streaming over HTTP (DASH) has emerged as an increasingly
popular paradigm for video streaming [13], in which a video is segmented into
many chunks delivered to users by HTTP request/response over Transmission
Control Protocol (TCP) con- nections. Therefore, it is intriguing to study the
performance of strategies implemented in conventional TCPs, which are not
dedicated for video streaming, e.g., whether chunks are efficiently delivered
when users per- form interactions with the video players. In this paper, we
conduct mea- surement studies on users chunk requesting traces in DASH from a
rep- resentative video streaming provider, to investigate users behaviors in
DASH, and TCP-connection-level traces from CDN servers, to investi- gate the
performance of TCP for DASH. By studying how video chunks are delivered in both
the slow start and congestion avoidance phases, our observations have revealed
the performance characteristics of TCP for DASH as follows: (1) Request
patterns in DASH have a great impact on the performance of TCP variations
including cubic; (2) Strategies in conventional TCPs may cause user perceived
quality degradation in DASH streaming; (3) Potential improvement to TCP
strategies for better delivery in DASH can be further explored.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01184</identifier>
 <datestamp>2016-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Calculation of mutual information for nonlinear communication channel at
  large SNR</dc:title>
 <dc:creator>Terekhov, I. S.</dc:creator>
 <dc:creator>Reznichenko, A. V.</dc:creator>
 <dc:creator>Turitsyn, S. K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Using the path-integral technique we examine the mutual information for the
communication channel modelled by the nonlinear Schr\&quot;odinger equation with
additive Gaussian noise. The nonlinear Schr\&quot;odinger equation is one of the
fundamental models in nonlinear physics, and it has a broad range of
applications, including fiber optical communications --- the backbone of the
Internet. At large signal-to-noise ratio ($\mathrm{SNR}$) we present the mutual
information through the path-integral which is convenient for the perturbative
expansion in nonlinearity. In the limit of small noise and small nonlinearity
we derive analytically the first nonzero nonlinear correction to the mutual
information for the channel.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01184</dc:identifier>
 <dc:identifier>Phys. Rev. E 94, 042203 (2016)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.94.042203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01191</identifier>
 <datestamp>2016-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Best Practices for Replicability, Reproducibility and Reusability of
  Computer-Based Experiments Exemplified by Model Reduction Software</dc:title>
 <dc:creator>Fehr, J&#xf6;rg</dc:creator>
 <dc:creator>Heiland, Jan</dc:creator>
 <dc:creator>Himpe, Christian</dc:creator>
 <dc:creator>Saak, Jens</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68N30</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  Over the recent years the importance of numerical experiments has gradually
been more recognized. Nonetheless, sufficient documentation of how
computational results have been obtained is often not available. Especially in
the scientific computing and applied mathematics domain this is crucial, since
numerical experiments are usually employed to verify the proposed hypothesis in
a publication. This work aims to propose standards and best practices for the
setup and publication of numerical experiments. Naturally, this amounts to a
guideline for development, maintenance, and publication of numerical research
software. Such a primer will enable the replicability and reproducibility of
computer-based experiments and published results and also promote the
reusability of the associated software.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01191</dc:identifier>
 <dc:identifier>doi:10.3934/Math.2016.3.261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01196</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Drawing Graphs on Few Lines and Few Planes</dc:title>
 <dc:creator>Chaplick, Steven</dc:creator>
 <dc:creator>Fleszar, Krzysztof</dc:creator>
 <dc:creator>Lipp, Fabian</dc:creator>
 <dc:creator>Ravsky, Alexander</dc:creator>
 <dc:creator>Verbitsky, Oleg</dc:creator>
 <dc:creator>Wolff, Alexander</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We investigate the problem of drawing graphs in 2D and 3D such that their
edges (or only their vertices) can be covered by few lines or planes. We insist
on straight-line edges and crossing-free drawings. This problem has many
connections to other challenging graph-drawing problems such as small-area or
small-volume drawings, layered or track drawings, and drawing graphs with low
visual complexity. While some facts about our problem are implicit in previous
work, this is the first treatment of the problem in its full generality. Our
contribution is as follows.
  We show lower and upper bounds for the numbers of lines and planes needed for
covering drawings of graphs in certain graph classes. In some cases our bounds
are asymptotically tight; in some cases we are able to determine exact values.
  We relate our parameters to standard combinatorial characteristics of graphs
(such as the chromatic number, treewidth, maximum degree, or arboricity) and to
parameters that have been studied in graph drawing (such as the track number or
the number of segments appearing in a drawing).
  We pay special attention to planar graphs. For example, we show that there
are planar graphs that can be drawn in 3-space on a lot fewer lines than in the
plane.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01202</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal control for a robotic exploration, pick-up and delivery problem</dc:title>
 <dc:creator>Nenchev, Vladislav</dc:creator>
 <dc:creator>Cassandras, Christos G.</dc:creator>
 <dc:creator>Raisch, J&#xf6;rg</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper addresses an optimal control problem for a robot that has to find
and collect a finite number of objects and move them to a depot in minimum
time. The robot has fourth-order dynamics that change instantaneously at any
pick-up or drop-off of an object. The objects are modeled by point masses with
a-priori unknown locations in a bounded two-dimensional space that may contain
unknown obstacles. For this hybrid system, an Optimal Control Problem (OCP) is
approximately solved by a receding horizon scheme, where the derived lower
bound for the cost-to-go is evaluated for the worst and for a probabilistic
case, assuming a uniform distribution of the objects. First, a time-driven
approximate solution based on time and position space discretization and mixed
integer programming is presented. Due to the high computational cost of this
solution, an alternative event-driven approximate approach based on a suitable
motion parameterization and gradient-based optimization is proposed. The
solutions are compared in a numerical example, suggesting that the latter
approach offers a significant computational advantage while yielding similar
qualitative results compared to the former. The methods are particularly
relevant for various robotic applications like automated cleaning, search and
rescue, harvesting or manufacturing.
</dc:description>
 <dc:description>Comment: 14 pages, 23 figures</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01205</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning the semantic structure of objects from Web supervision</dc:title>
 <dc:creator>Novotny, David</dc:creator>
 <dc:creator>Larlus, Diane</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While recent research in image understanding has often focused on recognizing
more types of objects, understanding more about the objects is just as
important. Recognizing object parts and attributes has been extensively studied
before, yet learning large space of such concepts remains elusive due to the
high cost of providing detailed object annotations for supervision. The key
contribution of this paper is an algorithm to learn the nameable parts of
objects automatically, from images obtained by querying Web search engines. The
key challenge is the high level of noise in the annotations; to address it, we
propose a new unified embedding space where the appearance and geometry of
objects and their semantic parts are represented uniformly. Geometric
relationships are induced in a soft manner by a rich set of nonsemantic
mid-level anchors, bridging the gap between semantic and non-semantic parts. We
also show that the resulting embedding provides a visually-intuitive mechanism
to navigate the learned concepts and their corresponding images.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01210</identifier>
 <datestamp>2016-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Garbage In - Some Garbage Out: Asynchronous t-Byzantine as
  Asynchronous Benign t-resilient system with fixed t-Trojan-Horse Inputs</dc:title>
 <dc:creator>Dolev, Danny</dc:creator>
 <dc:creator>Gafni, Eli</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We show that asynchronous $t$ faults Byzantine system is equivalent to
asynchronous $t$-resilient system, where unbeknownst to all, the private inputs
of at most $t$ processors were altered and installed by a malicious oracle.
  The immediate ramification is that dealing with asynchronous Byzantine
systems does not call for new topological methods, as was recently employed by
various researchers: Asynchronous Byzantine is a standard asynchronous system
with an input caveat. It also shows that two recent independent investigations
of vector $\epsilon$-agreement in the Byzantine model, and then in the
fail-stop model, one was superfluous - in these problems the change of $t$
inputs allowed in the Byzantine has no effect compared to the fail-stop case.
  This result was motivated by the aim of casting any asynchronous system as a
synchronous system where all processors are correct and it is the communication
substrate in the form of message-adversary that misbehaves. Thus, in addition,
we get such a characterization for the asynchronous Byzantine system.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01217</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification of block-oriented nonlinear systems starting from linear
  approximations: A survey</dc:title>
 <dc:creator>Schoukens, Maarten</dc:creator>
 <dc:creator>Tiels, Koen</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Block-oriented nonlinear models are popular in nonlinear system
identification because of their advantages of being simple to understand and
easy to use. Many different identification approaches were developed over the
years to estimate the parameters of a wide range of block-oriented nonlinear
models. One class of these approaches uses linear approximations to initialize
the identification algorithm. The best linear approximation framework and the
$\epsilon$-approximation framework, or equivalent frameworks, allow the user to
extract important information about the system, guide the user in selecting
good candidate model structures and orders, and prove to be a good starting
point for nonlinear system identification algorithms. This paper gives an
overview of the different block-oriented nonlinear models that can be
identified using linear approximations, and of the identification algorithms
that have been developed in the past. A non-exhaustive overview of the most
important other block-oriented nonlinear system identification approaches is
also provided throughout this paper.
</dc:description>
 <dc:description>Comment: This manuscript version is made available under the CC-BY-NC-ND 4.0
  license</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01217</dc:identifier>
 <dc:identifier>Automatica, 2017, vol. 85, pg. 272-292</dc:identifier>
 <dc:identifier>doi:10.1016/j.automatica.2017.06.044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01223</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>B.A.T.Mobile: Leveraging Mobility Control Knowledge for Efficient
  Routing in Mobile Robotic Networks</dc:title>
 <dc:creator>Sliwa, Benjamin</dc:creator>
 <dc:creator>Behnke, Daniel</dc:creator>
 <dc:creator>Ide, Christoph</dc:creator>
 <dc:creator>Wietfeld, Christian</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Efficient routing is one of the key challenges of wireless networking for
unmanned autonomous vehicles (UAVs) due to dynamically changing channel and
network topology characteristics. Various well known mobile-ad-hoc routing
protocols, such as AODV, OLSR and B.A.T.M.A.N. have been proposed to allow for
proactive and reactive routing decisions. In this paper, we present a novel
approach which leverages application layer knowledge derived from mobility
control algorithms guiding the behavior of UAVs to fulfill a dedicated task.
Thereby a prediction of future trajectories of the UAVs can be integrated with
the routing protocol to avoid unexpected route breaks and packet loss. The
proposed extension of the B.A.T.M.A.N. routing protocol by a mobility
prediction component - called B.A.T.Mobile - has shown to be very effective to
realize this concept. The results of in-depth simulation studies show that the
proposed protocol reaches a distinct higher availability compared to the
established approaches and shows robust behavior even in challenging channel
conditions.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01223</dc:identifier>
 <dc:identifier>doi:10.1109/GLOCOMW.2016.7848845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01229</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Lower Bounds for Online Hypercube and Rectangle Packing</dc:title>
 <dc:creator>Blitz, David</dc:creator>
 <dc:creator>Heydrich, Sandy</dc:creator>
 <dc:creator>van Stee, Rob</dc:creator>
 <dc:creator>van Vliet, Andr&#xe9;</dc:creator>
 <dc:creator>Woeginger, Gerhard J.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Packing a given sequence of items into as few bins as possible in an online
fashion is a widely studied problem. We improve lower bounds for packing boxes
into bins in two or more dimensions, both for general algorithms for squares
and rectangles (in two dimensions) and for an important subclass, so-called
Harmonic-type algorithms for hypercubes (in two or more dimensions). Lastly, we
show that two adaptions of ideas from a one-dimensional packing algorithm to
square packing do not help to break the barrier of 2.
</dc:description>
 <dc:description>Comment: 19 pages, 4 figures</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01231</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Quasi-Newton Methods for Nonconvex Stochastic Optimization</dc:title>
 <dc:creator>Wang, Xiao</dc:creator>
 <dc:creator>Ma, Shiqian</dc:creator>
 <dc:creator>Goldfarb, Donald</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we study stochastic quasi-Newton methods for nonconvex
stochastic optimization, where we assume that noisy information about the
gradients of the objective function is available via a stochastic first-order
oracle (SFO). We propose a general framework for such methods, for which we
prove almost sure convergence to stationary points and analyze its worst-case
iteration complexity. When a randomly chosen iterate is returned as the output
of such an algorithm, we prove that in the worst-case, the SFO-calls complexity
is $O(\epsilon^{-2})$ to ensure that the expectation of the squared norm of the
gradient is smaller than the given accuracy tolerance $\epsilon$. We also
propose a specific algorithm, namely a stochastic damped L-BFGS (SdLBFGS)
method, that falls under the proposed framework. {Moreover, we incorporate the
SVRG variance reduction technique into the proposed SdLBFGS method, and analyze
its SFO-calls complexity. Numerical results on a nonconvex binary
classification problem using SVM, and a multiclass classification problem using
neural networks are reported.
</dc:description>
 <dc:description>Comment: published in SIAM Journal on Optimization</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01232</identifier>
 <datestamp>2016-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A probabilistic tour of visual attention and gaze shift computational
  models</dc:title>
 <dc:creator>Boccignone, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper a number of problems are considered which are related to the
modelling of eye guidance under visual attention in a natural setting. From a
crude discussion of a variety of available models spelled in probabilistic
terms, it appears that current approaches in computational vision are hitherto
far from achieving the goal of an active observer relying upon eye guidance to
accomplish real-world tasks. We argue that this challenging goal not only
requires to embody, in a principled way, the problem of eye guidance within the
action/perception loop, but to face the inextricable link tying up visual
attention, emotion and executive control, in so far as recent neurobiological
findings are weighed up.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01249</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TTC: A Tensor Transposition Compiler for Multiple Architectures</dc:title>
 <dc:creator>Springer, Paul</dc:creator>
 <dc:creator>Sankaran, Aravind</dc:creator>
 <dc:creator>Bientinesi, Paolo</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>I.1.3</dc:subject>
 <dc:description>  We consider the problem of transposing tensors of arbitrary dimension and
describe TTC, an open source domain-specific parallel compiler. TTC generates
optimized parallel C++/CUDA C code that achieves a significant fraction of the
system's peak memory bandwidth. TTC exhibits high performance across multiple
architectures, including modern AVX-based systems (e.g.,~Intel Haswell, AMD
Steamroller), Intel's Knights Corner as well as different CUDA-based GPUs such
as NVIDIA's Kepler and Maxwell architectures. We report speedups of TTC over a
meaningful baseline implementation generated by external C++ compilers; the
results suggest that a domain-specific compiler can outperform its general
purpose counterpart significantly: For instance, comparing with Intel's latest
C++ compiler on the Haswell and Knights Corner architecture, TTC yields
speedups of up to $8\times$ and $32\times$, respectively. We also showcase
TTC's support for multiple leading dimensions, making it a suitable candidate
for the generation of performance-critical packing functions that are at the
core of the ubiquitous BLAS 3 routines.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01249</dc:identifier>
 <dc:identifier>doi:10.1145/2935323.2935328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01254</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An extended MABAC for multi-attribute decision making using trapezoidal
  interval type-2 fuzzy numbers</dc:title>
 <dc:creator>Roy, Jagannath</dc:creator>
 <dc:creator>Ranjan, Ananta</dc:creator>
 <dc:creator>Debnath, Animesh</dc:creator>
 <dc:creator>Kar, Samarjit</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we attempt to extend Multi Attributive Border Approximation
area Comparison (MABAC) approach for multi-attribute decision making (MADM)
problems based on type-2 fuzzy sets (IT2FSs). As a special case of IT2FSs
interval type-2 trapezoidal fuzzy numbers (IT2TrFNs) are adopted here to deal
with uncertainties present in many practical evaluation and selection problems.
A systematic description of MABAC based on IT2TrFNs is presented in the current
study. The validity and feasibility of the proposed method are illustrated by a
practical example of selecting the most suitable candidate for a software
company which is heading to hire a system analysis engineer based on few
attributes. Finally, a comparison with two other existing MADM methods is
described.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01257</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Singular Persistent Homology with Effective Concurrent Computation</dc:title>
 <dc:creator>Goldfarb, Boris</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  Persistent homology is a popular tool in Topological Data Analysis. It
provides numerical characteristics of data sets which reflect global geometric
properties. In order to be useful in practice, for example for feature
generation in machine learning, it needs to be effectively computable.
Classical homology is a computable topological invariant because of the
Mayer-Vietoris exact and spectral sequences associated to coverings of a space.
We state and prove versions of the Mayer-Vietoris theorem for persistent
homology under mild and commonplace assumptions. This is done through the use
of a new theory, the singular persistent homology, better suited for handling
coverings of data sets. As an application, we create a distributed
computational workflow where the advantage is not only in speed improvement but
also in sheer feasibility for large data sets.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01261</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Flow Scheduling Strategy in Multihoming Video CDNs</dc:title>
 <dc:creator>Ma, Ming</dc:creator>
 <dc:creator>Wang, Zhi</dc:creator>
 <dc:creator>Zhang, Yankai</dc:creator>
 <dc:creator>Sun, Lifeng</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Multihoming for a video Content Delivery Network (CDN) allows edge peering
servers to deliver video chunks through different Internet Service Providers
(ISPs), to achieve an improved quality of service (QoS) for video streaming
users. However, since traditional strategies for a multihoming video CDN are
simply designed according to static rules, e.g., simply sending traffic via a
ISP which is the same as the ISP of client, they fail to dynamically allocate
resources among different ISPs over time. In this paper, we perform measurement
studies to demonstrate that such static allocation mechanism is inefficient to
make full utilization of multiple ISPs' resources. To address this problem, we
propose a dynamic flow scheduling strategy for multihoming video CDN. The
challenge is to find the control parameters that can guide the ISP selection
when performing flow scheduling. Using a data-driven approach, we find factors
that have a major impact on the performance improvement in the dynamic flow
scheduling. We further utilize an information gain approach to generate
parameter combinations that can be used to guide the flow scheduling, i.e., to
determine the ISP each request should be responded by. Our evaluation results
demonstrate that our design effectively performs the flow scheduling. In
particular, our design yields near optimal performance in a simulation of
real-world multihoming setup.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01263</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying notions of generalized weights for universal security on
  wire-tap networks</dc:title>
 <dc:creator>Mart&#xed;nez-Pe&#xf1;as, Umberto</dc:creator>
 <dc:creator>Matsumoto, Ryutaroh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>15A03, 15B33, 94B05, 94C99</dc:subject>
 <dc:description>  Universal security over a network with linear network coding has been
intensively studied. However, previous linear codes used for this purpose were
linear over a larger field than that used on the network. In this work, we
introduce new parameters (relative dimension/rank support profile and relative
generalized matrix weights) for linear codes that are linear over the field
used in the network, measuring the universal security performance of these
codes. The proposed new parameters enable us to use optimally universal secure
linear codes on noiseless networks for all possible parameters, as opposed to
previous works, and also enable us to add universal security to the recently
proposed list-decodable rank-metric codes by Guruswami et al. We give several
properties of the new parameters: monotonicity, Singleton-type lower and upper
bounds, a duality theorem, and definitions and characterizations of
equivalences of linear codes. Finally, we show that our parameters strictly
extend relative dimension/length profile and relative generalized Hamming
weights, respectively, and relative dimension/intersection profile and relative
generalized rank weights, respectively. Moreover, we show that generalized
matrix weights are larger than Delsarte generalized weights.
</dc:description>
 <dc:description>Comment: 8 pages, LaTeX; the current version will appear in the Proceedings of
  the 54th Annual Allerton Conference on Communication, Control, and Computing,
  Monticello, IL, USA, 2016</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01263</dc:identifier>
 <dc:identifier>Proc. 2016 54th Annual Allerton Conference on Communication,
  Control, and Computing, pp.800-807, Monticello, Illinois, USA, September
  27-30, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/ALLERTON.2016.7852315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01265</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Innovation diffusion equations on correlated scale-free networks</dc:title>
 <dc:creator>Bertotti, M. L.</dc:creator>
 <dc:creator>Brunner, J.</dc:creator>
 <dc:creator>Modanese, G.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We introduce a heterogeneous network structure into the Bass diffusion model,
in order to study the diffusion times of innovation or information in networks
with a scale-free structure, typical of regions where diffusion is sensitive to
geographic and logistic influences (like for instance Alpine regions). We
consider both the diffusion peak times of the total population and of the link
classes. In the familiar trickle-down processes the adoption curve of the hubs
is found to anticipate the total adoption in a predictable way. In a major
departure from the standard model, we model a trickle-up process by introducing
heterogeneous publicity coefficients (which can also be negative for the hubs,
thus turning them into stiflers) and a stochastic term which represents the
erratic generation of innovation at the periphery of the network. The results
confirm the robustness of the Bass model and expand considerably its range of
applicability.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures</dc:description>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01265</dc:identifier>
 <dc:identifier>Phys. Lett. A 380 (2016) 2475-2479</dc:identifier>
 <dc:identifier>doi:10.1016/j.physleta.2016.06.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01266</identifier>
 <datestamp>2016-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New features of CitedReferencesExplorer (CRExplorer)</dc:title>
 <dc:creator>Thor, Andreas</dc:creator>
 <dc:creator>Marx, Werner</dc:creator>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  CRExplorer version 1.6.7 was released on July 5, 2016. This version includes
the following new features and improvements: Scopus: Using &quot;File&quot; - &quot;Import&quot; -
&quot;Scopus&quot;, CRExplorer reads files from Scopus. The file format &quot;CSV&quot; (including
citations, abstracts and references) should be chosen in Scopus for downloading
records. Export facilities: Using &quot;File&quot; - &quot;Export&quot; - &quot;Scopus&quot;, CRExplorer
exports files in the Scopus format. Using &quot;File&quot; - &quot;Export&quot; - &quot;Web of Science&quot;,
CRExplorer exports files in the Web of Science format. These files can be
imported in other bibliometric programs (e.g. VOSviewer). Space bar: Select a
specific cited reference in the cited references table, press the space bar,
and all bibliographic details of the CR are shown. Internal file format: Using
&quot;File&quot; - &quot;Save&quot;, working files are saved in the internal file format &quot;*.cre&quot;.
The files include all data including matching results and manual matching
corrections. The files can be opened by using &quot;File&quot; - &quot;Open&quot;.
</dc:description>
 <dc:description>Comment: Accepted for publication in Scientometrics</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01272</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallelized Structures for MIMO FBMC under Strong Channel Frequency
  Selectivity</dc:title>
 <dc:creator>Mestre, Xavier</dc:creator>
 <dc:creator>Gregoratti, David</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A novel architecture for MIMO transmission and reception of filterbank
multicarrier (FBMC) modulated signals under strong frequency selectivity is
presented. The proposed system seeks to approximate an ideal
frequency-selective precoder and linear receiver by Taylor expansion,
exploiting the structure of the analysis and synthesis filterbanks. The
resulting architecture is implemented by linearly combining conventional MIMO
linear transceivers, which are applied to sequential derivatives of the
original filterbank. The classical per-subcarrier precoding/linear receiver
configuration is obtained as a special case of this architecture, when only one
stage is fixed at both transmitter and receiver. An asymptotic expression for
the resulting intersymbol/intercarrier (ISI/ICI) distortion is derived assuming
that the number of subcarriers grows large. This expression can in practice be
used in order to determine the number of parallel stages that need to be
implemented in the proposed architecture. Performance evaluation studies
confirm the substantial advantage of the proposed scheme in practical
frequency-selective MIMO scenarios.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Signal Processing, Vol. 64, No. 5, March 2016</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01272</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2015.2477053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01274</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Topic Analysis with Endogenous and Exogenous Processes</dc:title>
 <dc:creator>Wang, Baiyang</dc:creator>
 <dc:creator>Klabjan, Diego</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of modeling temporal textual data taking endogenous
and exogenous processes into account. Such text documents arise in real world
applications, including job advertisements and economic news articles, which
are influenced by the fluctuations of the general economy. We propose a
hierarchical Bayesian topic model which imposes a &quot;group-correlated&quot;
hierarchical structure on the evolution of topics over time incorporating both
processes, and show that this model can be estimated from Markov chain Monte
Carlo sampling methods. We further demonstrate that this model captures the
intrinsic relationships between the topic distribution and the time-dependent
factors, and compare its performance with latent Dirichlet allocation (LDA) and
two other related models. The model is applied to two collections of documents
to illustrate its empirical performance: online job advertisements from
DirectEmployers Association and journalists' postings on BusinessInsider.com.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01283</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identity of King and Flajolet &amp; al. Formulae for LRU Miss Rate Exact
  Computation</dc:title>
 <dc:creator>Berthet, Christian</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  This short paper gives a detailed proof of identity between two classic
formulas for the computation of the exact Miss Rate of LRU caches. An extension
to the identity of two formulas of the expected time of a partial collection in
the coupon collector problem is also presented.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01284</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Achievable Rate of Bi-Static Modulated Re-Scatter Systems</dc:title>
 <dc:creator>Duan, Ruifeng</dc:creator>
 <dc:creator>J&#xe4;ntti, Riku</dc:creator>
 <dc:creator>Yi&#x11f;itler, H&#xfc;seyin</dc:creator>
 <dc:creator>Ruttik, Kalle</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In ambient re-scatter communications, devices convey information by
modulating and re-scattering the radio frequency signals impinging on their
antennas. In this correspondence, we consider a system consisting of a legacy
modulated continuous carrier multiple-input-multiple-output (MIMO) link and a
multi-antenna modulated re-scatter (MRS) node, where the MRS node modulates and
re-scatters the signal generated by the legacy transmitter. The receiver seeks
to decode both the original message and the information added by the MRS. We
show that the achievable sum rate of this system exceeds that which the legacy
system could achieve alone. We further consider the impact of channel
estimation errors under the least squares channel estimation and study the
achievable rate of the legacy and MRS systems, where a linear minimum mean
square error receiver with successive interference cancellation is utilized for
joint decoding.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, accepted</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01294</identifier>
 <datestamp>2016-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Essential Constraints of Edge-Constrained Proximity Graphs</dc:title>
 <dc:creator>Bose, Prosenjit</dc:creator>
 <dc:creator>De Carufel, Jean-Lou</dc:creator>
 <dc:creator>Shaikhet, Alina</dc:creator>
 <dc:creator>Smid, Michiel</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Given a plane forest $F = (V, E)$ of $|V| = n$ points, we find the minimum
set $S \subseteq E$ of edges such that the edge-constrained minimum spanning
tree over the set $V$ of vertices and the set $S$ of constraints contains $F$.
We present an $O(n \log n )$-time algorithm that solves this problem. We
generalize this to other proximity graphs in the constraint setting, such as
the relative neighbourhood graph, Gabriel graph, $\beta$-skeleton and Delaunay
triangulation. We present an algorithm that identifies the minimum set
$S\subseteq E$ of edges of a given plane graph $I=(V,E)$ such that $I \subseteq
CG_\beta(V, S)$ for $1 \leq \beta \leq 2$, where $CG_\beta(V, S)$ is the
constraint $\beta$-skeleton over the set $V$ of vertices and the set $S$ of
constraints. The running time of our algorithm is $O(n)$, provided that the
constrained Delaunay triangulation of $I$ is given.
</dc:description>
 <dc:description>Comment: 24 pages, 22 figures. A preliminary version of this paper appeared in
  the Proceedings of 27th International Workshop, IWOCA 2016, Helsinki,
  Finland. It was published by Springer in the Lecture Notes in Computer
  Science (LNCS) series</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01299</identifier>
 <datestamp>2016-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trip-Based Public Transit Routing Using Condensed Search Trees</dc:title>
 <dc:creator>Witt, Sascha</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of planning Pareto-optimal journeys in public transit
networks. Most existing algorithms and speed-up techniques work by computing
subjourneys to intermediary stops until the destination is reached. In
contrast, the trip-based model focuses on trips and transfers between them,
constructing journeys as a sequence of trips. In this paper, we develop a
speed-up technique for this model inspired by principles behind existing
state-of-the-art speed-up techniques, Transfer Pattern and Hub Labelling. The
resulting algorithm allows us to compute Pareto-optimal (with respect to
arrival time and number of transfers) 24-hour profiles on very large real-world
networks in less than half a millisecond. Compared to the current state of the
art for bicriteria queries on public transit networks, this is up to two orders
of magnitude faster, while increasing preprocessing overhead by at most one
order of magnitude.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01302</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Resource Theory for Work and Heat</dc:title>
 <dc:creator>Sparaciari, Carlo</dc:creator>
 <dc:creator>Oppenheim, Jonathan</dc:creator>
 <dc:creator>Fritz, Tobias</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Several recent results on thermodynamics have been obtained using the tools
of quantum information theory and resource theories. So far, the resource
theories utilised to describe thermodynamics have assumed the existence of an
infinite thermal reservoir, by declaring that thermal states at some background
temperature come for free. Here, we propose a resource theory of quantum
thermodynamics without a background temperature, so that no states at all come
for free. We apply this resource theory to the case of many non-interacting
systems, and show that all quantum states are classified by their entropy and
average energy, even arbitrarily far away from equilibrium. This implies that
thermodynamics takes place in a two-dimensional convex set that we call the
energy-entropy diagram. The answers to many resource-theoretic questions about
thermodynamics can be read off from this diagram, such as the efficiency of a
heat engine consisting of finite reservoirs, or the rate of conversion between
two states. This allows us to consider a resource theory which puts work and
heat on an equal footing, and serves as a model for other resource theories.
</dc:description>
 <dc:description>Comment: main text: 12 pages, 5 figure; appendix: 7 pages</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01302</dc:identifier>
 <dc:identifier>Phys. Rev. A 96, 052112 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.96.052112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01305</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Inverse Nonlinear Fourier Transforms for Continuous Spectra of
  Zakharov-Shabat Type</dc:title>
 <dc:creator>Wahls, Sander</dc:creator>
 <dc:creator>Vaibhav, Vishal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  The nonlinear Schr\&quot;odinger equation (NSE) is well-known to model an ideal
fiber-optic communication channel. Even though the NSE is a nonlinear evolution
equation, it can be solved analytically using a nonlinear Fourier transform
(NFT). Recently, there has been much interest in transceiver concepts that
utilize this NFT and its inverse to (de-)modulate data. Fast algorithms for the
(inverse) NFT are a key requirement for the simulation and real-time
implementation of fiber-optic communication systems based on NFTs. While much
progress has already been made for accelerating the forward NFT, less is known
on its inverse. The nonlinear Fourier spectrum comprises a continuous and a
discrete part in general, but so far only fast inverse NFTs for signals whose
continuous spectrum is null have been reported in the literature. In this
paper, we investigate the complementary case and propose the first fast inverse
NFT for signals whose discrete spectrum is empty. This is the case required by
transmitters in the recently proposed nonlinear inverse synthesis scheme, but
the problem also occurs in different application areas such as fiber Bragg
grating design. Our algorithms require only $\mathcal{O}(D\log^{2}D)$ floating
point operations to generate $D$ samples of the desired signal, which is almost
an order of magnitude faster than the current state of the art,
$\mathcal{O}(D^{2})$. This paper also quantifies, apparently for the first
time, the impact that truncating a signal in the time-domain has on the NFT.
</dc:description>
 <dc:description>Comment: The paper is being withdrawn because both of the authors no longer
  agree with the conclusions drawn in the paper</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01313</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scenario-based decision-making for power systems investment planning</dc:title>
 <dc:creator>Liu, Jialin</dc:creator>
 <dc:creator>Teytaud, Olivier</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>91-08, 90B50</dc:subject>
 <dc:description>  The optimization of power systems involves complex uncertainties, such as
technological progress, political context, geopolitical constraints.
Negotiations at COP21 are complicated by the huge number of scenarios that
various people want to consider; these scenarios correspond to many
uncertainties. These uncertainties are difficult to modelize as probabilities,
due to the lack of data for future technologies and due to partially
adversarial geopolitical decision makers. Tools for such difficult decision
making problems include Wald and Savage criteria, possibilistic reasoning and
Nash equilibria. We investigate the rationale behind the use of a two-player
Nash equilibrium approach in such a difficult context; we show that the
computational cost is indeed smaller than for simpler criteria. Moreover, it
naturally provides a selection of decisions and scenarios, and it has a natural
interpretation in the sense that Nature does not make decisions taking into
account our own decisions. The algorithm naturally provides a matrix of
results, namely the matrix of outcomes in the most interesting decisions and
for the most critical scenarios. These decisions and scenarios are also
equipped with a ranking.
</dc:description>
 <dc:description>Comment: 9 pages, 6 tables</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01327</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Selection Library (MATLAB Toolbox)</dc:title>
 <dc:creator>Roffo, Giorgio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Feature Selection Library (FSLib) is a widely applicable MATLAB library for
Feature Selection (FS). FS is an essential component of machine learning and
data mining which has been studied for many years under many different
conditions and in diverse scenarios. These algorithms aim at ranking and
selecting a subset of relevant features according to their degrees of
relevance, preference, or importance as defined in a specific application.
Because feature selection can reduce the amount of features used for training
classification models, it alleviates the effect of the curse of dimensionality,
speeds up the learning process, improves model's performance, and enhances data
understanding. This work provides an overview of the feature selection
algorithms included in the toolbox among: filter, embedded, and wrappers
methods.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01330</identifier>
 <datestamp>2017-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomly Generated Subgroups of the Symmetric Group and Random Lifts of
  Graphs</dc:title>
 <dc:creator>Silas, Shashwat</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Amit and Linial showed that a random lift of a graph with minimum degree
$\delta\ge3$ is asymptotically almost surely $\delta$-connected, and mentioned
the problem of estimating this probability as a function of the degree of the
lift. We relate a randomly generated subgroup of the symmetric group on $n$
elements to random $n$-lifts of a graph and use it to provide such an estimate
along with related results. We also improve their later result showing a lower
bound on the edge expansion on random lifts. Our proofs rely on new ideas from
group theory which make several improvements possible. We exactly calculate the
probability that a random lift of a connected graph with first Betti number $l$
is connected by showing that it is equal to the probability that a subgroup of
the symmetric group generated by $l$ random elements is transitive. We also
calculate the probability that a subgroup of a wreath product of symmetric
groups generated by $l$ random generators is transitive. We show the existence
of homotopy invariants in random covering graphs which reduces some of their
properties to those of random regular multigraphs, and in particular makes it
possible to compute the exact probability with which random regular multigraphs
are connected. All our results about random lifts easily extend to iterated
random lifts.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01330</dc:identifier>
 <dc:identifier>(Short version) Electronic Journal of Combinatorics, Issue 24,
  Volume 1, P46, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01335</identifier>
 <datestamp>2016-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matrix Factorization at Scale: a Comparison of Scientific Data Analytics
  in Spark and C+MPI Using Three Case Studies</dc:title>
 <dc:creator>Gittens, Alex</dc:creator>
 <dc:creator>Devarakonda, Aditya</dc:creator>
 <dc:creator>Racah, Evan</dc:creator>
 <dc:creator>Ringenburg, Michael</dc:creator>
 <dc:creator>Gerhardt, Lisa</dc:creator>
 <dc:creator>Kottalam, Jey</dc:creator>
 <dc:creator>Liu, Jialin</dc:creator>
 <dc:creator>Maschhoff, Kristyn</dc:creator>
 <dc:creator>Canon, Shane</dc:creator>
 <dc:creator>Chhugani, Jatin</dc:creator>
 <dc:creator>Sharma, Pramod</dc:creator>
 <dc:creator>Yang, Jiyan</dc:creator>
 <dc:creator>Demmel, James</dc:creator>
 <dc:creator>Harrell, Jim</dc:creator>
 <dc:creator>Krishnamurthy, Venkat</dc:creator>
 <dc:creator>Mahoney, Michael W.</dc:creator>
 <dc:creator>Prabhat</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  We explore the trade-offs of performing linear algebra using Apache Spark,
compared to traditional C and MPI implementations on HPC platforms. Spark is
designed for data analytics on cluster computing platforms with access to local
disks and is optimized for data-parallel tasks. We examine three widely-used
and important matrix factorizations: NMF (for physical plausability), PCA (for
its ubiquity) and CX (for data interpretability). We apply these methods to
TB-sized problems in particle physics, climate modeling and bioimaging. The
data matrices are tall-and-skinny which enable the algorithms to map
conveniently into Spark's data-parallel model. We perform scaling experiments
on up to 1600 Cray XC40 nodes, describe the sources of slowdowns, and provide
tuning guidance to obtain high performance.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01337</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can mobile usage predict illiteracy in a developing country?</dc:title>
 <dc:creator>Sunds&#xf8;y, P&#xe5;l</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The present study provides the first evidence that illiteracy can be reliably
predicted from standard mobile phone logs. By deriving a broad set of mobile
phone indicators reflecting users financial, social and mobility patterns we
show how supervised machine learning can be used to predict individual
illiteracy in an Asian developing country, externally validated against a
large-scale survey. On average the model performs 10 times better than random
guessing with a 70% accuracy. Further we show how individual illiteracy can be
aggregated and mapped geographically at cell tower resolution. Geographical
mapping of illiteracy is crucial to know where the illiterate people are, and
where to put in resources. In underdeveloped countries such mappings are often
based on out-dated household surveys with low spatial and temporal resolution.
One in five people worldwide struggle with illiteracy, and it is estimated that
illiteracy costs the global economy more than 1 trillion dollars each year.
These results potentially enable costeffective, questionnaire-free
investigation of illiteracy-related questions on an unprecedented scale
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01341</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorand</dc:title>
 <dc:creator>Chen, Jing</dc:creator>
 <dc:creator>Micali, Silvio</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  A public ledger is a tamperproof sequence of data that can be read and
augmented by everyone. Public ledgers have innumerable and compelling uses.
They can secure, in plain sight, all kinds of transactions ---such as titles,
sales, and payments--- in the exact order in which they occur. Public ledgers
not only curb corruption, but also enable very sophisticated applications
---such as cryptocurrencies and smart contracts. They stand to revolutionize
the way a democratic society operates. As currently implemented, however, they
scale poorly and cannot achieve their potential.
  Algorand is a truly democratic and efficient way to implement a public
ledger. Unlike prior implementations based on proof of work, it requires a
negligible amount of computation, and generates a transaction history that will
not &quot;fork&quot; with overwhelmingly high probability.
  Algorand is based on (a novel and super fast) message-passing Byzantine
agreement.
  For concreteness, we shall describe Algorand only as a money platform.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01345</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distortion Bounds for Transmitting Correlated Sources with Common Part
  over MAC</dc:title>
 <dc:creator>Yu, Lei</dc:creator>
 <dc:creator>Li, Houqiang</dc:creator>
 <dc:creator>Chen, Chang Wen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the joint source-channel coding problem of sending
two correlated memoryless sources with common part over a memoryless multiple
access channel (MAC). An inner bound and two outer bounds on the achievable
distortion region are derived. In particular, they respectively recover the
existing bounds for several special cases, such as communication without common
part, lossless communication, and noiseless communication. When specialized to
quadratic Gaussian communication case, transmitting Gaussian sources with
Gaussian common part over Gaussian MAC, the inner bound and outer bound are
used to generate two new bounds. Numerical result shows that common part
improves the distortion of such distributed source-channel coding problem.
</dc:description>
 <dc:description>Comment: Presented at Allerton Conference 2016</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01346</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation in a MAC with and without security via Game
  Theoretic Learning</dc:title>
 <dc:creator>Shah, Shahid Mehraj</dc:creator>
 <dc:creator>A, Krishna Chaitanya</dc:creator>
 <dc:creator>Sharma, Vinod</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper a $K$-user fading multiple access channel with and without
security constraints is studied. First we consider a F-MAC without the security
constraints. Under the assumption of individual CSI of users, we propose the
problem of power allocation as a stochastic game when the receiver sends an ACK
or a NACK depending on whether it was able to decode the message or not. We
have used Multiplicative weight no-regret algorithm to obtain a Coarse
Correlated Equilibrium (CCE). Then we consider the case when the users can
decode ACK/NACK of each other. In this scenario we provide an algorithm to
maximize the weighted sum-utility of all the users and obtain a Pareto optimal
point. PP is socially optimal but may be unfair to individual users. Next we
consider the case where the users can cooperate with each other so as to
disagree with the policy which will be unfair to individual user. We then
obtain a Nash bargaining solution, which in addition to being Pareto optimal,
is also fair to each user.
  Next we study a $K$-user fading multiple access wiretap Channel with CSI of
Eve available to the users. We use the previous algorithms to obtain a CCE, PP
and a NBS.
  Next we consider the case where each user does not know the CSI of Eve but
only its distribution. In that case we use secrecy outage as the criterion for
the receiver to send an ACK or a NACK. Here also we use the previous algorithms
to obtain a CCE, PP or a NBS. Finally we show that our algorithms can be
extended to the case where a user can transmit at different rates. At the end
we provide a few examples to compute different solutions and compare them under
different CSI scenarios.
</dc:description>
 <dc:description>Comment: 27 pages, 12 figures. Part of the paper was presented in 2016 IEEE
  Information theory and applicaitons (ITA) Workshop, San Diego, USA in Feb.
  2016. Submitted to journal</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01354</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Discriminative Features using Encoder-Decoder type Deep Neural
  Nets</dc:title>
 <dc:creator>Singh, Vishwajeet</dc:creator>
 <dc:creator>Kumar, Killamsetti Ravi</dc:creator>
 <dc:creator>Eswaran, K</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:description>  As machine learning is applied to an increasing variety of complex problems,
which are defined by high dimensional and complex data sets, the necessity for
task oriented feature learning grows in importance. With the advancement of
Deep Learning algorithms, various successful feature learning techniques have
evolved. In this paper, we present a novel way of learning discriminative
features by training Deep Neural Nets which have Encoder or Decoder type
architecture similar to an Autoencoder. We demonstrate that our approach can
learn discriminative features which can perform better at pattern
classification tasks when the number of training samples is relatively small in
size.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures and 8 tables</dc:description>
 <dc:date>2016-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01355</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Recognition and Identification Using ESM Data</dc:title>
 <dc:creator>Taghavi, E.</dc:creator>
 <dc:creator>Song, D.</dc:creator>
 <dc:creator>Tharmarasa, R.</dc:creator>
 <dc:creator>Kirubarajan, T.</dc:creator>
 <dc:creator>Boury-Brisset, Anne-Claire</dc:creator>
 <dc:creator>Balaji, Bhashyam</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognition and identification of unknown targets is a crucial task in
surveillance and security systems. Electronic Support Measures (ESM) are one of
the most effective sensors for identification, especially for maritime and
air--to--ground applications. In typical surveillance systems multiple ESM
sensors are usually deployed along with kinematic sensors like radar. Different
ESM sensors may produce different types of reports ready to be sent to the
fusion center. The focus of this paper is to develop a new architecture for
target recognition and identification when non--homogeneous ESM and possibly
kinematic reports are received at the fusion center. The new fusion
architecture is evaluated using simulations to show the benefit of utilizing
different ESM reports such as attributes and signal level ESM data.
</dc:description>
 <dc:date>2016-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01359</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cultural Differences in E-Learning: Exploring New Dimensions</dc:title>
 <dc:creator>Hameed, Nazia</dc:creator>
 <dc:creator>Shaikh, Maqbool Uddin</dc:creator>
 <dc:creator>Hameed, Fozia</dc:creator>
 <dc:creator>Shamim, Azra</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Rapid development of Internet and information technologies has gifted us with
a new and diverse mode of learning known as e-learning. In the current era,
e-learning has made rapid, influential, universal, interactive, vibrant, and
economic development. Now e-learning has become a global mode of education.
E-learning means the use of internet, computer and communications technologies
to acquire education. Learners with diverse social, cultural, economic,
linguistic, and religious backgrounds from all over the world are taking
benefits from e-learning. In e-learning, culture of target learners plays a
vital role and need to be explored for better results. Diversity of culture and
learning styles should keep under considerations while designing e-learning
environment. It may help to attain the required results. In this research work,
authors proposed and designed a novel architecture for e-learning system
incorporating cultural diversity of learners. The focus is to concentrate on
cultural factors from e-learning system. Furthermore; a prototype of the
proposed system is implemented for the validation of proposed architecture.
</dc:description>
 <dc:description>Comment: This paper has been published in Conference: 11th WSEAS International
  Conference on Education and Educational Technology (EDU '12). arXiv admin
  note: substantial text overlap with arXiv:1605.01580</dc:description>
 <dc:date>2016-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01381</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-Shot Session Recommendation Systems with Combinatorial Items</dc:title>
 <dc:creator>David, Yahel</dc:creator>
 <dc:creator>Di Castro, Dotan</dc:creator>
 <dc:creator>Karnin, Zohar</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In recent years, content recommendation systems in large websites (or
\emph{content providers}) capture an increased focus. While the type of content
varies, e.g.\ movies, articles, music, advertisements, etc., the high level
problem remains the same. Based on knowledge obtained so far on the user,
recommend the most desired content. In this paper we present a method to handle
the well known user-cold-start problem in recommendation systems. In this
scenario, a recommendation system encounters a new user and the objective is to
present items as relevant as possible with the hope of keeping the user's
session as long as possible. We formulate an optimization problem aimed to
maximize the length of this initial session, as this is believed to be the key
to have the user come back and perhaps register to the system. In particular,
our model captures the fact that a single round with low quality recommendation
is likely to terminate the session. In such a case, we do not proceed to the
next round as the user leaves the system, possibly never to seen again. We
denote this phenomenon a \emph{One-Shot Session}. Our optimization problem is
formulated as an MDP where the action space is of a combinatorial nature as we
recommend in each round, multiple items. This huge action space presents a
computational challenge making the straightforward solution intractable. We
analyze the structure of the MDP to prove monotone and submodular like
properties that allow a computationally efficient solution via a method denoted
by \emph{Greedy Value Iteration} (G-VI).
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01383</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIMO Wiretap Channel under Receiver Side Power Constraints with
  Applications to Wireless Power Transfer and Cognitive Radio</dc:title>
 <dc:creator>Banawan, Karim</dc:creator>
 <dc:creator>Ulukus, Sennur</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider the multiple-input multiple-output (MIMO) wiretap channel under a
minimum receiver-side power constraint in addition to the usual maximum
transmitter-side power constraint. This problem is motivated by energy
harvesting communications with wireless energy transfer, where an added goal is
to deliver a minimum amount of energy to a receiver in addition to delivering
secure data to another receiver. In this paper, we characterize the exact
secrecy capacity of the MIMO wiretap channel under transmitter and
receiver-side power constraints. We first show that solving this problem is
equivalent to solving the secrecy capacity of the wiretap channel under a
double-sided correlation matrix constraint on the channel input. We show the
converse by extending the channel enhancement technique to our case. We present
two achievable schemes that achieve the secrecy capacity: the first achievable
scheme uses a Gaussian codebook with a fixed mean, and the second achievable
scheme uses artificial noise (or cooperative jamming) together with a Gaussian
codebook. The role of the mean or the artificial noise is to enable energy
transfer without sacrificing from the secure rate. This is the first instance
of a channel model where either the use of a mean signal or the use of channel
prefixing via artificial noise is strictly necessary for the MIMO wiretap
channel. We then extend our work to consider a maximum receiver-side power
constraint. This problem is motivated by cognitive radio applications, where an
added goal is to decrease the received signal energy (interference temperature)
at a receiver. We further extend our results to: requiring receiver-side power
constraints at both receivers; considering secrecy constraints at both
receivers to study broadcast channels with confidential messages; and removing
the secrecy constraints to study the classical broadcast channel.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Communications, September 2015.
  Accepted for publication, July 2016</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01383</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2016.2593739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01400</identifier>
 <datestamp>2017-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Aggregate and Iterative Disaggregate Algorithm with Proven Optimality
  in Machine Learning</dc:title>
 <dc:creator>Park, Young Woong</dc:creator>
 <dc:creator>Klabjan, Diego</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a clustering-based iterative algorithm to solve certain
optimization problems in machine learning, where we start the algorithm by
aggregating the original data, solving the problem on aggregated data, and then
in subsequent steps gradually disaggregate the aggregated data. We apply the
algorithm to common machine learning problems such as the least absolute
deviation regression problem, support vector machines, and semi-supervised
support vector machines. We derive model-specific data aggregation and
disaggregation procedures. We also show optimality, convergence, and the
optimality gap of the approximated solution in each iteration. A computational
study is provided.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01400</dc:identifier>
 <dc:identifier>Machine Learning 105 (2016) 199 - 232</dc:identifier>
 <dc:identifier>doi:10.1007/s10994-016-5562-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01404</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PRIMME_SVDS: A High-Performance Preconditioned SVD Solver for Accurate
  Large-Scale Computations</dc:title>
 <dc:creator>Wu, Lingfei</dc:creator>
 <dc:creator>Romero, Eloy</dc:creator>
 <dc:creator>Stathopoulos, Andreas</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The increasing number of applications requiring the solution of large scale
singular value problems have rekindled interest in iterative methods for the
SVD. Some promising recent ad- vances in large scale iterative methods are
still plagued by slow convergence and accuracy limitations for computing
smallest singular triplets. Furthermore, their current implementations in
MATLAB cannot address the required large problems. Recently, we presented a
preconditioned, two-stage method to effectively and accurately compute a small
number of extreme singular triplets. In this research, we present a
high-performance software, PRIMME SVDS, that implements our hybrid method based
on the state-of-the-art eigensolver package PRIMME for both largest and
smallest singular values. PRIMME SVDS fills a gap in production level software
for computing the partial SVD, especially with preconditioning. The numerical
experiments demonstrate its superior performance compared to other
state-of-the-art software and its good parallel performance under strong and
weak scaling.
</dc:description>
 <dc:description>Comment: 23 pages, 10 figures</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01417</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Generalized Cluster-wise Linear Regression</dc:title>
 <dc:creator>Park, Young Woong</dc:creator>
 <dc:creator>Jiang, Yan</dc:creator>
 <dc:creator>Klabjan, Diego</dc:creator>
 <dc:creator>Williams, Loren</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Cluster-wise linear regression (CLR), a clustering problem intertwined with
regression, is to find clusters of entities such that the overall sum of
squared errors from regressions performed over these clusters is minimized,
where each cluster may have different variances. We generalize the CLR problem
by allowing each entity to have more than one observation, and refer to it as
generalized CLR. We propose an exact mathematical programming based approach
relying on column generation, a column generation based heuristic algorithm
that clusters predefined groups of entities, a metaheuristic genetic algorithm
with adapted Lloyd's algorithm for K-means clustering, a two-stage approach,
and a modified algorithm of Sp{\&quot;a}th \cite{Spath1979} for solving generalized
CLR. We examine the performance of our algorithms on a stock keeping unit (SKU)
clustering problem employed in forecasting halo and cannibalization effects in
promotions using real-world retail data from a large supermarket chain. In the
SKU clustering problem, the retailer needs to cluster SKUs based on their
seasonal effects in response to promotions. The seasonal effects are the
results of regressions with predictors being promotion mechanisms and seasonal
dummies performed over clusters generated. We compare the performance of all
proposed algorithms for the SKU problem with real-world and synthetic data.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01417</dc:identifier>
 <dc:identifier>INFORMS Journal on Computing 29-2(2017): 301 - 317</dc:identifier>
 <dc:identifier>doi:10.1287/ijoc.2016.0729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01419</identifier>
 <datestamp>2016-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extended LTLvis Motion Planning interface (Extended Technical Report)</dc:title>
 <dc:creator>Wei, Wei</dc:creator>
 <dc:creator>Kim, Kangjin</dc:creator>
 <dc:creator>Fainekos, Georgios</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This paper introduces an extended version of the Linear Temporal Logic (LTL)
graphical interface. It is a sketch based interface built on the Android
platform which makes the LTL control interface more straightforward and
friendly to nonexpert users. By predefining a set of areas of interest, this
interface can quickly and efficiently create plans that satisfy extended plan
goals in LTL. The interface can also allow users to customize the paths for
this plan by sketching a set of reference trajectories. Given the custom paths
by the user, the LTL specification and the environment, the interface generates
a plan balancing the customized paths and the LTL specifications. We also show
experimental results with the implemented interface.
</dc:description>
 <dc:description>Comment: 8 pages, 15 figures, a technical report for the 2016 IEEE
  International Conference on Systems, Man, and Cybernetics (SMC 2016)</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01426</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chains of Reasoning over Entities, Relations, and Text using Recurrent
  Neural Networks</dc:title>
 <dc:creator>Das, Rajarshi</dc:creator>
 <dc:creator>Neelakantan, Arvind</dc:creator>
 <dc:creator>Belanger, David</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Our goal is to combine the rich multistep inference of symbolic logical
reasoning with the generalization capabilities of neural networks. We are
particularly interested in complex reasoning about entities and relations in
text and large-scale knowledge bases (KBs). Neelakantan et al. (2015) use RNNs
to compose the distributed semantics of multi-hop paths in KBs; however for
multiple reasons, the approach lacks accuracy and practicality. This paper
proposes three significant modeling advances: (1) we learn to jointly reason
about relations, entities, and entity-types; (2) we use neural attention
modeling to incorporate multiple paths; (3) we learn to share strength in a
single RNN that represents logical composition across all relations. On a
largescale Freebase+ClueWeb prediction task, we achieve 25% error reduction,
and a 53% error reduction on sparse relations due to shared strength. On chains
of reasoning in WordNet we reduce error in mean quantile by 84% versus previous
state-of-the-art. The code and data are available at
https://rajarshd.github.io/ChainsofReasoning
</dc:description>
 <dc:description>Comment: accepted to EACL 2017 (fixed latex formatting in previous version)</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-05-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01432</identifier>
 <datestamp>2016-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Neural CCG Parsing with Optimality Guarantees</dc:title>
 <dc:creator>Lee, Kenton</dc:creator>
 <dc:creator>Lewis, Mike</dc:creator>
 <dc:creator>Zettlemoyer, Luke</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce the first global recursive neural parsing model with optimality
guarantees during decoding. To support global features, we give up dynamic
programs and instead search directly in the space of all possible subtrees.
Although this space is exponentially large in the sentence length, we show it
is possible to learn an efficient A* parser. We augment existing parsing
models, which have informative bounds on the outside score, with a global model
that has loose bounds but only needs to model non-local phenomena. The global
model is trained with a new objective that encourages the parser to explore a
tiny fraction of the search space. The approach is applied to CCG parsing,
improving state-of-the-art accuracy by 0.4 F1. The parser finds the optimal
parse for 99.9% of held-out sentences, exploring on average only 190 subtrees.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-09-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01436</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalized Framework on Beamformer Design and CSI Acquisition for
  Single-Carrier Massive MIMO Systems in Millimeter Wave Channels</dc:title>
 <dc:creator>Guvensen, Gokhan M.</dc:creator>
 <dc:creator>Ayanoglu, Ender</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we establish a general framework on the reduced dimensional
channel state information (CSI) estimation and pre-beamformer design for
frequency-selective massive multiple-input multiple-output MIMO systems
employing single-carrier (SC) modulation in time division duplex (TDD) mode by
exploiting the joint angle-delay domain channel sparsity in millimeter (mm)
wave frequencies. First, based on a generic subspace projection taking the
joint angle-delay power profile and user-grouping into account, the reduced
rank minimum mean square error (RR-MMSE) instantaneous CSI estimator is derived
for spatially correlated wideband MIMO channels. Second, the statistical
pre-beamformer design is considered for frequency-selective SC massive MIMO
channels. We examine the dimension reduction problem and subspace (beamspace)
construction on which the RR-MMSE estimation can be realized as accurately as
possible. Finally, a spatio-temporal domain correlator type reduced rank
channel estimator, as an approximation of the RR-MMSE estimate, is obtained by
carrying out least square (LS) estimation in a proper reduced dimensional
beamspace. It is observed that the proposed techniques show remarkable
robustness to the pilot interference (or contamination) with a significant
reduction in pilot overhead.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01437</identifier>
 <datestamp>2016-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attribute Recognition from Adaptive Parts</dc:title>
 <dc:creator>Yang, Luwei</dc:creator>
 <dc:creator>Zhu, Ligen</dc:creator>
 <dc:creator>Wei, Yichen</dc:creator>
 <dc:creator>Liang, Shuang</dc:creator>
 <dc:creator>Tan, Ping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Previous part-based attribute recognition approaches perform part detection
and attribute recognition in separate steps. The parts are not optimized for
attribute recognition and therefore could be sub-optimal. We present an
end-to-end deep learning approach to overcome the limitation. It generates
object parts from key points and perform attribute recognition accordingly,
allowing adaptive spatial transform of the parts. Both key point estimation and
attribute recognition are learnt jointly in a multi-task setting. Extensive
experiments on two datasets verify the efficacy of proposed end-to-end
approach.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01438</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Computational Complexities of Three Privacy Measures for Large
  Networks Under Active Attack</dc:title>
 <dc:creator>Chatterjee, Tanima</dc:creator>
 <dc:creator>DasGupta, Bhaskar</dc:creator>
 <dc:creator>Mobasheri, Nasim</dc:creator>
 <dc:creator>Srinivasan, Venkatkumar</dc:creator>
 <dc:creator>Yero, Ismael G.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>68Q17, 68Q25, 68R10, 05C85, 68W25, 68W40</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  With the arrival of modern internet era, large public networks of various
types have come to existence to benefit the society as a whole and several
research areas such as sociology, economics and geography in particular.
However, the societal and research benefits of these networks have also given
rise to potentially significant privacy issues in the sense that malicious
entities may violate the privacy of the users of such a network by analyzing
the network and deliberately using such privacy violations for deleterious
purposes. Such considerations have given rise to a new active research area
that deals with the quantification of privacy of users in large networks and
the corresponding investigation of computational complexity issues of computing
such quantified privacy measures. In this paper, we formalize three such
privacy measures for large networks and provide non-trivial theoretical
computational complexity results for computing these measures. Our results show
the first two measures can be computed efficiently, whereas the third measure
is provably hard to compute within a logarithmic approximation factor.
Furthermore, we also provide computational complexity results for the case when
the privacy requirement of the network is severely restricted, including an
efficient logarithmic approximation.
</dc:description>
 <dc:description>Comment: 21 pages, 3 figures</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01441</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Simplification in Half-Duplex: Building on Submodularity</dc:title>
 <dc:creator>Cardone, Martina</dc:creator>
 <dc:creator>Ezzeldin, Yahya H.</dc:creator>
 <dc:creator>Fragouli, Christina</dc:creator>
 <dc:creator>Tuninetti, Daniela</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper explores the {\it network simplification} problem in the context
of Gaussian Half-Duplex (HD) diamond networks. Specifically, given an $N$-relay
diamond network, this problem seeks to derive fundamental guarantees on the
capacity of the best $k$-relay subnetwork, as a function of the full network
capacity. The main focus of this work is on the case when $k=N-1$ relays are
selected out of the $N$ possible ones. First, a simple algorithm, which removes
the relay with the minimum capacity (i.e., the worst relay), is analyzed and it
is shown that the remaining $(N-1)$-relay subnetwork has an approximate (i.e.,
optimal up to a constant gap) HD capacity that is at least half of the
approximate HD capacity of the full network. This fraction guarantee is shown
to be tight if only the single relay capacities are known, i.e., there exists a
class of Gaussian HD diamond networks with $N$ relays where, by removing the
worst relay, the subnetwork of the remaining $k=N-1$ relays has an approximate
capacity equal to half of the approximate capacity of the full network. Next,
this work proves a fundamental guarantee, which improves over the previous
fraction: there always exists a subnetwork of $k=N-1$ relays that achieves at
least a fraction $\frac{N-1}{N}$ of the approximate capacity of the full
network. This fraction is proved to be tight and it is shown that any optimal
schedule of the full network can be used by at least one of the $N$ subnetworks
of $N-1$ relays to achieve a worst-case performance guarantee of
$\frac{N-1}{N}$. Additionally, these results are extended to derive lower
bounds on the fraction guarantee for general $k \in [1:N]$. The key steps in
the proofs lie in the derivation of properties of submodular functions, which
provide a combinatorial handle on the network simplification problem in
Gaussian HD diamond networks.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01443</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breakout: An Open Measurement and Intervention Tool for Distributed Peer
  Learning Groups</dc:title>
 <dc:creator>Calacci, Dan</dc:creator>
 <dc:creator>Lederman, Oren</dc:creator>
 <dc:creator>Shrier, David</dc:creator>
 <dc:creator>Pentland, Alex 'Sandy'</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present Breakout, a group interaction platform for online courses that
enables the creation and measurement of face-to-face peer learning groups in
online settings. Breakout is designed to help students easily engage in
synchronous, video breakout session based peer learning in settings that
otherwise force students to rely on asynchronous text-based communication. The
platform also offers data collection and intervention tools for studying the
communication patterns inherent in online learning environments. The goals of
the system are twofold: to enhance student engagement in online learning
settings and to create a platform for research into the relationship between
distributed group interaction patterns and learning outcomes.
</dc:description>
 <dc:description>Comment: Presented at SBP 2016</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01444</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effectiveness of Rapid Rail Transit System in Beijing</dc:title>
 <dc:creator>Cheng, Hui-Min</dc:creator>
 <dc:creator>Ning, Yi-Zi</dc:creator>
 <dc:creator>Ma, Xiaoke</dc:creator>
 <dc:creator>Zhang, Zhong-Yuan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The effectiveness of rapid rail transit system is analyzed using tools of
complex network for the first time. We evaluated the effectiveness of the
system in Beijing quantitatively from different perspectives, including
descriptive statistics analysis, bridging property, centrality property,
ability of connecting different part of the system and ability of disease
spreading. The results showed that the public transport of Beijing does benefit
from the rapid rail transit lines, but there is still room to improve. The
paper concluded with some policy suggestions regarding how to promote the
system. This study offered significant insight that can help understand the
public transportation better. The methodology can be easily applied to analyze
other urban public systems, such as electricity grid, water system, to develop
more livable cities.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01450</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pooling Faces: Template based Face Recognition with Pooled Face Images</dc:title>
 <dc:creator>Hassner, Tal</dc:creator>
 <dc:creator>Masi, Iacopo</dc:creator>
 <dc:creator>Kim, Jungyeon</dc:creator>
 <dc:creator>Choi, Jongmoo</dc:creator>
 <dc:creator>Harel, Shai</dc:creator>
 <dc:creator>Natarajan, Prem</dc:creator>
 <dc:creator>Medioni, Gerard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel approach to template based face recognition. Our dual goal
is to both increase recognition accuracy and reduce the computational and
storage costs of template matching. To do this, we leverage on an approach
which was proven effective in many other domains, but, to our knowledge, never
fully explored for face images: average pooling of face photos. We show how
(and why!) the space of a template's images can be partitioned and then pooled
based on image quality and head pose and the effect this has on accuracy and
template size. We perform extensive tests on the IJB-A and Janus CS2 template
based face identification and verification benchmarks. These show that not only
does our approach outperform published state of the art despite requiring far
fewer cross template comparisons, but also, surprisingly, that image pooling
performs on par with deep feature pooling.
</dc:description>
 <dc:description>Comment: Appeared in the IEEE Computer Society Workshop on Biometrics, IEEE
  Conf. on Computer Vision and Pattern Recognition (CVPR), June, 2016</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01456</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decomposing 8-regular graphs into paths of length 4</dc:title>
 <dc:creator>Botler, F&#xe1;bio</dc:creator>
 <dc:creator>Talon, Alexandre</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05B40, 05C70, 05C51, 05C38</dc:subject>
 <dc:description>  A $T$-decomposition of a graph $G$ is a set of edge-disjoint copies of $T$ in
$G$ that cover the edge set of $G$. Graham and H\&quot;aggkvist (1989) conjectured
that any $2\ell$-regular graph $G$ admits a $T$-decomposition if $T$ is a tree
with $\ell$ edges. Kouider and Lonc (1999) conjectured that, in the special
case where $T$ is the path with $\ell$ edges, $G$ admits a $T$-decomposition
$\mathcal{D}$ where every vertex of $G$ is the end-vertex of exactly two paths
of $\mathcal{D}$, and proved that this statement holds when $G$ has girth at
least $(\ell+3)/2$. In this paper we verify Kouider and Lonc's Conjecture for
paths of length $4$.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01461</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Minimum Mean $p$-th Error in Gaussian Noise Channels and its
  Applications</dc:title>
 <dc:creator>Dytso, Alex</dc:creator>
 <dc:creator>Bustin, Ronit</dc:creator>
 <dc:creator>Tuninetti, Daniela</dc:creator>
 <dc:creator>Devroye, Natasha</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:creator>Shamai, Shlomo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of estimating an arbitrary random vector from its observation
corrupted by additive white Gaussian noise, where the cost function is taken to
be the Minimum Mean $p$-th Error (MMPE), is considered. The classical Minimum
Mean Square Error (MMSE) is a special case of the MMPE. Several bounds,
properties and applications of the MMPE are derived and discussed. The optimal
MMPE estimator is found for Gaussian and binary input distributions. Properties
of the MMPE as a function of the input distribution, SNR and order $p$ are
derived. In particular, it is shown that the MMPE is a continuous function of
$p$ and SNR. These results are possible in view of interpolation and change of
measure bounds on the MMPE. The `Single-Crossing-Point Property' (SCPP) that
bounds the MMSE for all SNR values {\it above} a certain value, at which the
MMSE is known, together with the I-MMSE relationship is a powerful tool in
deriving converse proofs in information theory. By studying the notion of
conditional MMPE, a unifying proof (i.e., for any $p$) of the SCPP is shown. A
complementary bound to the SCPP is then shown, which bounds the MMPE for all
SNR values {\it below} a certain value, at which the MMPE is known. As a first
application of the MMPE, a bound on the conditional differential entropy in
terms of the MMPE is provided, which then yields a generalization of the
Ozarow-Wyner lower bound on the mutual information achieved by a discrete input
on a Gaussian noise channel. As a second application, the MMPE is shown to
improve on previous characterizations of the phase transition phenomenon that
manifests, in the limit as the length of the capacity achieving code goes to
infinity, as a discontinuity of the MMSE as a function of SNR. As a final
application, the MMPE is used to show bounds on the second derivative of mutual
information, that tighten previously known bounds.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01462</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An optimal learning method for developing personalized treatment regimes</dc:title>
 <dc:creator>Wang, Yingfei</dc:creator>
 <dc:creator>Powell, Warren</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A treatment regime is a function that maps individual patient information to
a recommended treatment, hence explicitly incorporating the heterogeneity in
need for treatment across individuals. Patient responses are dichotomous and
can be predicted through an unknown relationship that depends on the patient
information and the selected treatment. The goal is to find the treatments that
lead to the best patient responses on average. Each experiment is expensive,
forcing us to learn the most from each experiment. We adopt a Bayesian approach
both to incorporate possible prior information and to update our treatment
regime continuously as information accrues, with the potential to allow smaller
yet more informative trials and for patients to receive better treatment. By
formulating the problem as contextual bandits, we introduce a knowledge
gradient policy to guide the treatment assignment by maximizing the expected
value of information, for which an approximation method is used to overcome
computational challenges. We provide a detailed study on how to make sequential
medical decisions under uncertainty to reduce health care costs on a real world
knee replacement dataset. We use clustering and LASSO to deal with the
intrinsic sparsity in health datasets. We show experimentally that even though
the problem is sparse, through careful selection of physicians (versus picking
them at random), we can significantly improve the success rates.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01471</identifier>
 <datestamp>2017-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cryptanalysis and Improvement of an Improved Two Factor Authentication
  Scheme for Telecare Medicine Information Systems</dc:title>
 <dc:creator>Jian, Gaopeng</dc:creator>
 <dc:creator>Feng, Rongquan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Telecare medical information systems (TMIS) aim to provide healthcare
services remotely. Efficient and secure mechanism for authentication and key
agreement is required in order to guarantee the security and privacy of
patients in TMIS.
</dc:description>
 <dc:description>Comment: After checking the manuscript again a crucial error was founded in
  the section &quot; Security weaknesses of Amin et al.'s scheme&quot;. In fact Amin et
  al.'s scheme resists offline password guessing attacks but the manuscript
  claims that it doesn't</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2016-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01472</identifier>
 <datestamp>2017-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FSO-based Vertical Backhaul/Fronthaul Framework for 5G+ Wireless
  Networks</dc:title>
 <dc:creator>Alzenad, Mohamed</dc:creator>
 <dc:creator>Shakir, Muhammad Zeeshan</dc:creator>
 <dc:creator>Yanikomeroglu, Halim</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The presence of a super high rate, but also cost-efficient, easy-to-deploy,
and scalable, backhaul/fronthaul framework is essential in the upcoming
fifth-generation (5G) wireless networks \&amp; beyond. Motivated by the mounting
interest in the unmanned flying platforms of various types including unmanned
aerial vehicles (UAVs), drones, balloons, and
high-altitude/medium-altitude/low-altitude platforms (HAPs/MAPs/LAPs), which we
refer to as the networked flying platforms (NFPs), for providing communications
services and the recent advances in free-space optics (FSO), this article
investigates the feasibility of a novel vertical backhaul/fronthaul framework
where the NFPs transport the backhaul/fronthaul traffic between the access and
core networks via point-to-point FSO links. The performance of the proposed
innovative approach is investigated under different weather conditions and a
broad range of system parameters. Simulation results demonstrate that the
FSO-based vertical backhaul/fronthaul framework can offer data rates higher
than the baseline alternatives, and thus can be considered as a promising
solution to the emerging backhaul/fronthaul requirements of the 5G+ wireless
networks, particularly in the presence of ultra-dense heterogeneous small
cells. The paper also presents the challenges that accompany such a novel
framework and provides some key ideas towards overcoming these challenges.
</dc:description>
 <dc:description>Comment: Under Second Round of Revision in IEEE Communications Magazine,
  April, 2017</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:date>2017-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01474</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesising Strategy Improvement and Recursive Algorithms for Solving
  2.5 Player Parity Games</dc:title>
 <dc:creator>Hahn, Ernst Moritz</dc:creator>
 <dc:creator>Schewe, Sven</dc:creator>
 <dc:creator>Turrini, Andrea</dc:creator>
 <dc:creator>Zhang, Lijun</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  2.5 player parity games combine the challenges posed by 2.5 player
reachability games and the qualitative analysis of parity games. These two
types of problems are best approached with different types of algorithms:
strategy improvement algorithms for 2.5 player reachability games and recursive
algorithms for the qualitative analysis of parity games. We present a method
that - in contrast to existing techniques - tackles both aspects with the best
suited approach and works exclusively on the 2.5 player game itself. The
resulting technique is powerful enough to handle games with several million
states.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01477</identifier>
 <datestamp>2016-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating eigenvector and pseudospectra computation using blocked
  multi-shift triangular solves</dc:title>
 <dc:creator>Moon, Tim</dc:creator>
 <dc:creator>Poulson, Jack</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Multi-shift triangular solves are basic linear algebra calculations with
applications in eigenvector and pseudospectra computation. We propose blocked
algorithms that efficiently exploit Level 3 BLAS to perform multi-shift
triangular solves and safe multi-shift triangular solves. Numerical experiments
indicate that computing triangular eigenvectors with a safe multi-shift
triangular solve achieves speedups by a factor of 60 relative to LAPACK. This
algorithm accelerates the calculation of general eigenvectors threefold. When
using multi-shift triangular solves to compute pseudospectra, we report
ninefold speedups relative to EigTool.
</dc:description>
 <dc:description>Comment: 20 pages, 6 figures</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2016-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01478</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixed Strategy for Constrained Stochastic Optimal Control</dc:title>
 <dc:creator>Ono, Masahiro</dc:creator>
 <dc:creator>Chamie, Mahmoud El</dc:creator>
 <dc:creator>Pavone, Marco</dc:creator>
 <dc:creator>Acikmese, Behcet</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Choosing control inputs randomly can result in a reduced expected cost in
optimal control problems with stochastic constraints, such as stochastic model
predictive control (SMPC). We consider a controller with initial randomization,
meaning that the controller randomly chooses from K+1 control sequences at the
beginning (called K-randimization).It is known that, for a finite-state,
finite-action Markov Decision Process (MDP) with K constraints, K-randimization
is sufficient to achieve the minimum cost. We found that the same result holds
for stochastic optimal control problems with continuous state and action
spaces.Furthermore, we show the randomization of control input can result in
reduced cost when the optimization problem is nonconvex, and the cost reduction
is equal to the duality gap. We then provide the necessary and sufficient
conditions for the optimality of a randomized solution, and develop an
efficient solution method based on dual optimization. Furthermore, in a special
case with K=1 such as a joint chance-constrained problem, the dual optimization
can be solved even more efficiently by root finding. Finally, we test the
theories and demonstrate the solution method on multiple practical problems
ranging from path planning to the planning of entry, descent, and landing (EDL)
for future Mars missions.
</dc:description>
 <dc:description>Comment: 11 pages. 9 figures.Preliminary version of a working journal paper</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01482</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus and disagreement: the role of quantized behaviours in opinion
  dynamics</dc:title>
 <dc:creator>Ceragioli, Francesca</dc:creator>
 <dc:creator>Frasca, Paolo</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>34A36, 93A15, 93C99</dc:subject>
 <dc:description>  This paper deals with continuous-time opinion dynamics that feature the
interplay of continuous opinions and discrete behaviours. In our model, the
opinion of one individual is only influenced by the behaviours of fellow
individuals. The key technical difficulty in the study of these dynamics is
that the right-hand sides of the equations are discontinuous and thus their
solutions must be intended in some generalized sense: in our analysis, we
consider both Carath\'eodory and Krasowskii solutions. We first prove existence
and completeness of Carath\'eodory solutions from every initial condition and
we highlight a pathological behaviour of Carath\'eodory solutions, which can
converge to points that are not (Carath\'eodory) equilibria. Notably, such
points can be arbitrarily far from consensus and indeed simulations show that
convergence to non-consensus configurations is very common. In order to cope
with these pathological attractors, we then study Krasowskii solutions. We give
an estimate of the asymptotic distance of all Krasowskii solutions from
consensus and we prove its tightness via an example: this estimate is quadratic
in the number of agents, implying that quantization can drastically destroy
consensus. However, we are able to prove convergence to consensus in some
special cases, namely when the communication among the individuals is described
by either a complete or a complete bipartite graph.
</dc:description>
 <dc:description>Comment: Submitted for journal publication; preliminary incomplete version
  available in the Proceedings of the European Control Conference 2015</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01484</identifier>
 <datestamp>2017-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical study of the role of the topology in spreading on
  communication networks</dc:title>
 <dc:creator>Medvedev, Alexey N.</dc:creator>
 <dc:creator>Kertesz, Janos</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>90B18, 60K35, 82C99</dc:subject>
 <dc:description>  Topological aspects, like community structure, and temporal activity
patterns, like burstiness, have been shown to severly influence the speed of
spreading in temporal networks. We study the influence of the topology on the
susceptible-infected (SI) spreading on time stamped communication networks, as
obtained from a dataset of mobile phone records. We consider city level
networks with intra- and inter-city connections. The networks using only
intra-city links are usually sparse, where the spreading depends mainly on the
average degree. The inter-city links serve as bridges in spreading, speeding up
considerably the process. We demonstrate the effect also on model simulations.
</dc:description>
 <dc:description>Comment: Keywords: complex networks; temporal networks; spreading phenomena;
  SI model; bursty time series; non-Markovian processes; mobile phone data</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01484</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2016.11.109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01485</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting Formal Models from Normative Texts</dc:title>
 <dc:creator>Camilleri, John J.</dc:creator>
 <dc:creator>Gruzitis, Normunds</dc:creator>
 <dc:creator>Schneider, Gerardo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Normative texts are documents based on the deontic notions of obligation,
permission, and prohibition. Our goal is to model such texts using the C-O
Diagram formalism, making them amenable to formal analysis, in particular
verifying that a text satisfies properties concerning causality of actions and
timing constraints. We present an experimental, semi-automatic aid to bridge
the gap between a normative text and its formal representation. Our approach
uses dependency trees combined with our own rules and heuristics for extracting
the relevant components. The resulting tabular data can then be converted into
a C-O Diagram.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01485</dc:identifier>
 <dc:identifier>Natural Language Processing and Information Systems, Lecture Notes
  in Computer Science, Vol. 9612, Springer, 2016, pp. 403-408</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-41754-7_40</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01486</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast, On-board, Model-aided Visual-Inertial Odometry System for
  Quadrotor Micro Aerial Vehicles</dc:title>
 <dc:creator>Abeywardena, Dinuka</dc:creator>
 <dc:creator>Huang, Shoudong</dc:creator>
 <dc:creator>Barnes, Ben</dc:creator>
 <dc:creator>Dissanayake, Gamini</dc:creator>
 <dc:creator>Kodagoda, Sarath</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The main contribution of this paper is a high frequency, low-complexity,
on-board visual-inertial odometry system for quadrotor micro air vehicles. The
system consists of an extended Kalman filter (EKF) based state estimation
algorithm that fuses information from a low cost MEMS inertial measurement unit
acquired at 200Hz and VGA resolution images from a monocular camera at 50Hz.
The dynamic model describing the quadrotor motion is employed in the estimation
algorithm as a third source of information. Visual information is incorporated
into the EKF by enforcing the epipolar constraint on features tracked between
image pairs, avoiding the need to explicitly estimate the location of the
tracked environmental features. Combined use of the dynamic model and epipolar
constraints makes it possible to obtain drift free velocity and attitude
estimates in the presence of both accelerometer and gyroscope biases. A
strategy to deal with the unobservability that arises when the quadrotor is in
hover is also provided. Experimental data from a real-time implementation of
the system on a 50 gram embedded computer are presented in addition to the
simulations to demonstrate the efficacy of the proposed system.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01486</dc:identifier>
 <dc:identifier>Published in 2016 IEEE International Conference on Robotics and
  Automation (ICRA)</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2016.7487290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01490</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Self-explanatory Ontology Visualization with Contextual
  Verbalization</dc:title>
 <dc:creator>Liepi&#x146;&#x161;, Ren&#x101;rs</dc:creator>
 <dc:creator>Boj&#x101;rs, Uldis</dc:creator>
 <dc:creator>Gr&#x16b;z&#x12b;tis, Normunds</dc:creator>
 <dc:creator>&#x10c;er&#x101;ns, K&#x101;rlis</dc:creator>
 <dc:creator>Celms, Edgars</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Ontologies are one of the core foundations of the Semantic Web. To
participate in Semantic Web projects, domain experts need to be able to
understand the ontologies involved. Visual notations can provide an overview of
the ontology and help users to understand the connections among entities.
However, the users first need to learn the visual notation before they can
interpret it correctly. Controlled natural language representation would be
readable right away and might be preferred in case of complex axioms, however,
the structure of the ontology would remain less apparent. We propose to combine
ontology visualizations with contextual ontology verbalizations of selected
ontology (diagram) elements, displaying controlled natural language (CNL)
explanations of OWL axioms corresponding to the selected visual notation
elements. Thus, the domain experts will benefit from both the high-level
overview provided by the graphical notation and the detailed textual
explanations of particular elements in the diagram.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01490</dc:identifier>
 <dc:identifier>Databases and Information Systems, Communications in Computer and
  Information Science, Vol. 615, Springer, 2016, pp. 3-17</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-40180-5_1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01492</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effects of Cultural dimensions and Demographic Characteristics on
  E-learning Acceptance</dc:title>
 <dc:creator>Tarhini, Ali</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This study aims to develop and test an amalgamated conceptual framework based
on Technology Acceptance Model (TAM) and other models from social psychology,
such as theory of reasoned action and TAM2 that captures the salient factors
influencing the user adoption and acceptance of web-based learning systems.
This framework has been applied to the study of higher educational institutions
in the context of developing as well as developed countries (e.g. Lebanon and
UK). Additionally, the framework investigates the moderating effect of
Hofstedes four cultural dimensions at the individual level and a set of
individual differences (age, gender, experience and educational level) on the
key determinants that affect the behavioral intention to use e-learning. A
total of 1197 questionnaires were received from students who were using
web-based learning systems at higher educational institutions in Lebanon and
the UK with opposite scores on cultural dimensions. Confirmatory Factor
Analysis (CFA) was used to perform reliability and validity checks, and
Structural Equation Modeling (SEM) in conjunction with multi-group analysis
method was used to test the hypothesized conceptual model. Our findings suggest
that individual, social, cultural and organizational factors are important to
consider in explaining students behavioral intention and usage of e-learning
environments. The findings of this research contribute to the literature by
validating and supporting the applicability of our extended TAM in the Lebanese
and British contexts and provide several prominent implications to both theory
and practice on the individual, organizational and societal levels.
</dc:description>
 <dc:description>Comment: unpublished thesis</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01492</dc:identifier>
 <dc:identifier>Computer Science, BURA, (2016), 1-190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01517</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Envy-Free Cake-Cutting among Families</dc:title>
 <dc:creator>Segal-Halevi, Erel</dc:creator>
 <dc:creator>Nitzan, Shmuel</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper extends the classic cake-cutting problem to a situation in which
the &quot;cake&quot; is divided among families. Each piece of cake is owned and used
simultaneously by all members of the family. A typical example of such a cake
is land. We examine three ways to assess the fairness of such a division, based
on the classic no-envy criterion: (a) Average envy-freeness means that for each
family, the average value of its share (averaged over all family members) is
weakly larger than the average value of any other share; (b) Unanimous
envy-freeness means that in each family, each member values the family's share
weakly more than any other share; (c) Democratic envy-freeness means that in
each family, at least half the members value the family's share weakly more
than any other share. We study each of these definitions from both an
existential and a computational perspective.
</dc:description>
 <dc:description>Comment: Similar to https://arxiv.org/abs/1510.03903 but uses a different
  fairness criterion. 18 pages. arXiv admin note: substantial text overlap with
  arXiv:1510.03903</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01533</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Message Importance Measure and Its Application to Minority Subset
  Detection in Big Data</dc:title>
 <dc:creator>Fan, Pingyi</dc:creator>
 <dc:creator>Dong, Yunquan</dc:creator>
 <dc:creator>Lu, Jiaxun</dc:creator>
 <dc:creator>Liu, Shanyun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Message importance measure (MIM) is an important index to describe the
message importance in the scenario of big data. Similar to the Shannon Entropy
and Renyi Entropy, MIM is required to characterize the uncertainty of a random
process and some related statistical characteristics. Moreover, MIM also need
to highlight the importance of those events with relatively small occurring
probabilities, thereby is especially applicable to big data. In this paper, we
first define a parametric MIM measure from the viewpoint of information theory
and then investigate its properties. We also present a parameter selection
principle that provides answers to the minority subsets detection problem in
the statistical processing of big data.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01537</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Locally Repairable Systematic Codes Based on Packings</dc:title>
 <dc:creator>Cai, Han</dc:creator>
 <dc:creator>Cheng, Minquan</dc:creator>
 <dc:creator>Fan, Cuiling</dc:creator>
 <dc:creator>Tang, Xiaohu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Locally repairable codes are desirable for distributed storage systems to
improve the repair efficiency. In this paper, we first build a bridge between
locally repairable code and packing. As an application of this bridge, some
optimal locally repairable codes can be obtained by packings, which gives
optimal locally repairable codes with flexible parameters.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01539</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Translating Scala Programs to Isabelle/HOL</dc:title>
 <dc:creator>Hupel, Lars</dc:creator>
 <dc:creator>Kuncak, Viktor</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present a trustworthy connection between the Leon verification system and
the Isabelle proof assistant. Leon is a system for verifying functional Scala
programs. It uses a variety of automated theorem provers (ATPs) to check
verification conditions (VCs) stemming from the input program. Isabelle, on the
other hand, is an interactive theorem prover used to verify mathematical
specifications using its own input language Isabelle/Isar. Users specify
(inductive) definitions and write proofs about them manually, albeit with the
help of semi-automated tactics. The integration of these two systems allows us
to exploit Isabelle's rich standard library and give greater confidence
guarantees in the correctness of analysed programs.
</dc:description>
 <dc:description>Comment: International Joint Conference on Automated Reasoning, 2016</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01539</dc:identifier>
 <dc:identifier>IJCAR 2016: Automated Reasoning Volume 9706 of the series Lecture
  Notes in Computer Science pp 568-577, Springer</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-40229-1_38</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01551</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Sampling and Greedy MAP Inference of Constrained Determinantal Point
  Processes</dc:title>
 <dc:creator>Kathuria, Tarun</dc:creator>
 <dc:creator>Deshpande, Amit</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Subset selection problems ask for a small, diverse yet representative subset
of the given data. When pairwise similarities are captured by a kernel, the
determinants of submatrices provide a measure of diversity or independence of
items within a subset. Matroid theory gives another notion of independence,
thus giving rise to optimization and sampling questions about Determinantal
Point Processes (DPPs) under matroid constraints. Partition constraints, as a
special case, arise naturally when incorporating additional labeling or
clustering information, besides the kernel, in DPPs. Finding the maximum
determinant submatrix under matroid constraints on its row/column indices has
been previously studied. However, the corresponding question of sampling from
DPPs under matroid constraints has been unresolved, beyond the simple
cardinality constrained k-DPPs. We give the first polynomial time algorithm to
sample exactly from DPPs under partition constraints, for any constant number
of partitions. We complement this by a complexity theoretic barrier that rules
out such a result under general matroid constraints. Our experiments indicate
that partition-constrained DPPs offer more flexibility and more diversity than
k-DPPs and their naive extensions, while being reasonably efficient in running
time. We also show that a simple greedy initialization followed by local search
gives improved approximation guarantees for the problem of MAP inference from
k- DPPs on well-conditioned kernels. Our experiments show that this improvement
is significant for larger values of k, supporting our theoretical result.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01569</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nash Social Welfare Approximation for Strategic Agents</dc:title>
 <dc:creator>Br&#xe2;nzei, Simina</dc:creator>
 <dc:creator>Gkatzelis, Vasilis</dc:creator>
 <dc:creator>Mehta, Ruta</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The fair division of resources is an important age-old problem that has led
to a rich body of literature. At the center of this literature lies the
question of whether there exist fair mechanisms despite strategic behavior of
the agents. A fundamental objective function used for measuring fair outcomes
is the Nash social welfare, defined as the geometric mean of the agent
utilities. This objective function is maximized by widely known solution
concepts such as Nash bargaining and the competitive equilibrium with equal
incomes. In this work we focus on the question of (approximately) implementing
the Nash social welfare. The starting point of our analysis is the Fisher
market, a fundamental model of an economy, whose benchmark is precisely the
(weighted) Nash social welfare. We begin by studying two extreme classes of
valuations functions, namely perfect substitutes and perfect complements, and
find that for perfect substitutes, the Fisher market mechanism has a constant
approximation: at most 2 and at least e1e. However, for perfect complements,
the Fisher market does not work well, its bound degrading linearly with the
number of players.
  Strikingly, the Trading Post mechanism---an indirect market mechanism also
known as the Shapley-Shubik game---has significantly better performance than
the Fisher market on its own benchmark. Not only does Trading Post achieve an
approximation of 2 for perfect substitutes, but this bound holds for all
concave utilities and becomes arbitrarily close to optimal for Leontief
utilities (perfect complements), where it reaches $(1+\epsilon)$ for every
$\epsilon &gt; 0$. Moreover, all the Nash equilibria of the Trading Post mechanism
are pure for all concave utilities and satisfy an important notion of fairness
known as proportionality.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2017-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01577</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CUNet: A Compact Unsupervised Network for Image Classification</dc:title>
 <dc:creator>Dong, Le</dc:creator>
 <dc:creator>He, Ling</dc:creator>
 <dc:creator>Kong, Gaipeng</dc:creator>
 <dc:creator>Zhang, Qianni</dc:creator>
 <dc:creator>Cao, Xiaochun</dc:creator>
 <dc:creator>Izquierdo, Ebroul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a compact network called CUNet (compact
unsupervised network) to counter the image classification challenge. Different
from the traditional convolutional neural networks learning filters by the
time-consuming stochastic gradient descent, CUNet learns the filter bank from
diverse image patches with the simple K-means, which significantly avoids the
requirement of scarce labeled training images, reduces the training
consumption, and maintains the high discriminative ability. Besides, we propose
a new pooling method named weighted pooling considering the different weight
values of adjacent neurons, which helps to improve the robustness to small
image distortions. In the output layer, CUNet integrates the feature maps
gained in the last hidden layer, and straightforwardly computes histograms in
non-overlapped blocks. To reduce feature redundancy, we implement the
max-pooling operation on adjacent blocks to select the most competitive
features. Comprehensive experiments are conducted to demonstrate the
state-of-the-art classification performances with CUNet on CIFAR-10, STL-10,
MNIST and Caltech101 benchmark datasets.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01582</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bagged Boosted Trees for Classification of Ecological Momentary
  Assessment Data</dc:title>
 <dc:creator>Spanakis, Gerasimos</dc:creator>
 <dc:creator>Weiss, Gerhard</dc:creator>
 <dc:creator>Roefs, Anne</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Ecological Momentary Assessment (EMA) data is organized in multiple levels
(per-subject, per-day, etc.) and this particular structure should be taken into
account in machine learning algorithms used in EMA like decision trees and its
variants. We propose a new algorithm called BBT (standing for Bagged Boosted
Trees) that is enhanced by a over/under sampling method and can provide better
estimates for the conditional class probability function. Experimental results
on a real-world dataset show that BBT can benefit EMA data classification and
performance.
</dc:description>
 <dc:description>Comment: to be presented at ECAI2016</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01590</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Indexing dif/2</dc:title>
 <dc:creator>Neumerkel, Ulrich</dc:creator>
 <dc:creator>Kral, Stefan</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Many Prolog programs are unnecessarily impure because of inadequate means to
express syntactic inequality. While the frequently provided built-in `dif/2` is
able to correctly describe expected answers, its direct use in programs often
leads to overly complex and inefficient definitions --- mainly due to the lack
of adequate indexing mechanisms. We propose to overcome these problems by using
a new predicate that subsumes both equality and inequality via reification.
Code complexity is reduced with a monotonic, higher-order if-then-else
construct based on `call/N`. For comparable correct uses of impure definitions,
our approach is as determinate and similarly efficient as its impure
counterparts.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01598</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multipair Two-way Half-Duplex Relaying with Massive Arrays and Imperfect
  CSI</dc:title>
 <dc:creator>Kong, Chuili</dc:creator>
 <dc:creator>Zhong, Caijun</dc:creator>
 <dc:creator>Matthaiou, Michail</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Zhang, Zhaoyang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a two-way half-duplex relaying system where multiple pairs of
single antenna users exchange information assisted by a multi-antenna relay.
Taking into account the practical constraint of imperfect channel estimation,
we study the achievable sum spectral efficiency of the amplify-and-forward (AF)
and decode-and-forward (DF) protocols, assuming that the relay employs simple
maximum ratio processing. We derive an exact closed-form expression for the sum
spectral efficiency of the AF protocol and a large-scale approximation for the
sum spectral efficiency of the DF protocol when the number of relay antennas,
$M$, becomes sufficiently large. In addition, we study how the transmit power
scales with $M$ to maintain a desired quality-of-service. In particular, our
results show that by using a large number of relay antennas, the transmit
powers of the user, relay, and pilot symbol can be scaled down proportionally
to $1/M^\alpha$, $1/M^\beta$, and $1/M^\gamma$ for certain $\alpha$, $\beta$,
and $\gamma$, respectively. This elegant power scaling law reveals a
fundamental tradeoff between the transmit powers of the user/relay and pilot
symbol. Finally, capitalizing on the new expressions for the sum spectral
efficiency, novel power allocation schemes are designed to further improve the
sum spectral efficiency.
</dc:description>
 <dc:description>Comment: 64 pages, 19 figures, Submitted to IEEE Transactions on Information
  Theory, July 2016</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01605</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The chromatic number of the square of the 8-cube</dc:title>
 <dc:creator>Kokkala, Janne I.</dc:creator>
 <dc:creator>&#xd6;sterg&#xe5;rd, Patric R. J.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>05C15 (Primary) 94B25 (Secondary)</dc:subject>
 <dc:description>  A cube-like graph is a Cayley graph for the elementary abelian group of order
$2^n$. In studies of the chromatic number of cube-like graphs, the $k$th power
of the $n$-dimensional hypercube, $Q_n^k$, is frequently considered. This
coloring problem can be considered in the framework of coding theory, as the
graph $Q_n^k$ can be constructed with one vertex for each binary word of length
$n$ and edges between vertices exactly when the Hamming distance between the
corresponding words is at most $k$. Consequently, a proper coloring of $Q_n^k$
corresponds to a partition of the $n$-dimensional binary Hamming space into
codes with minimum distance at least $k+1$. The smallest open case, the
chromatic number of $Q_8^2$, is here settled by finding a 13-coloring. Such
13-colorings with specific symmetries are further classified.
</dc:description>
 <dc:description>Comment: 15 pages. Preliminary results of this research were reported in
  arXiv:1509.06913</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01628</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guided Alignment Training for Topic-Aware Neural Machine Translation</dc:title>
 <dc:creator>Chen, Wenhu</dc:creator>
 <dc:creator>Matusov, Evgeny</dc:creator>
 <dc:creator>Khadivi, Shahram</dc:creator>
 <dc:creator>Peter, Jan-Thorsten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we propose an effective way for biasing the attention
mechanism of a sequence-to-sequence neural machine translation (NMT) model
towards the well-studied statistical word alignment models. We show that our
novel guided alignment training approach improves translation quality on
real-life e-commerce texts consisting of product titles and descriptions,
overcoming the problems posed by many unknown words and a large type/token
ratio. We also show that meta-data associated with input texts such as topic or
category information can significantly improve translation quality when used as
an additional signal to the decoder part of the network. With both novel
features, the BLEU score of the NMT system on a product title set improves from
18.6 to 21.3%. Even larger MT quality gains are obtained through domain
adaptation of a general domain NMT system to e-commerce data. The developed NMT
system also performs well on the IWSLT speech translation task, where an
ensemble of four variant systems outperforms the phrase-based baseline by 2.1%
BLEU absolute.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01634</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice Structure of Variable Precision Rough Sets</dc:title>
 <dc:creator>Basu, Sumita</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  The main purpose of this paper is to study the lattice structure of variable
precision rough sets. The notion of variation in precision of rough sets have
been further extended to variable precision rough set with variable
classification error and its algebraic properties are also studied.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01639</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deciphering Malware's use of TLS (without Decryption)</dc:title>
 <dc:creator>Anderson, Blake</dc:creator>
 <dc:creator>Paul, Subharthi</dc:creator>
 <dc:creator>McGrew, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The use of TLS by malware poses new challenges to network threat detection
because traditional pattern-matching techniques can no longer be applied to its
messages. However, TLS also introduces a complex set of observable data
features that allow many inferences to be made about both the client and the
server. We show that these features can be used to detect and understand
malware communication, while at the same time preserving the privacy of benign
uses of encryption. These data features also allow for accurate malware family
attribution of network communication, even when restricted to a single,
encrypted flow.
  To demonstrate this, we performed a detailed study of how TLS is used by
malware and enterprise applications. We provide a general analysis on millions
of TLS encrypted flows, and a targeted study on 18 malware families composed of
thousands of unique malware samples and ten-of-thousands of malicious TLS
flows. Importantly, we identify and accommodate the bias introduced by the use
of a malware sandbox. The performance of a malware classifier is correlated
with a malware family's use of TLS, i.e., malware families that actively evolve
their use of cryptography are more difficult to classify.
  We conclude that malware's usage of TLS is distinct from benign usage in an
enterprise setting, and that these differences can be effectively used in rules
and machine learning classifiers.
</dc:description>
 <dc:description>Comment: 15 pages, 4 figures</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01642</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cryptanalyzing an Image-Scrambling Encryption Algorithm of Pixel Bits</dc:title>
 <dc:creator>Li, Chengqing</dc:creator>
 <dc:creator>Lin, Dongdong</dc:creator>
 <dc:creator>L&#xfc;, Jinhu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>68Wxx</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:description>  Position scrambling (permutation) is widely used in multimedia encryption
schemes and some international encryption standards, such as the Data
Encryption Standard and the Advanced Encryption Standard. In this article, the
authors re-evaluate the security of a typical image-scrambling encryption
algorithm (ISEA). Using the internal correlation remaining in the cipher image,
they disclose important visual information of the corresponding plain image in
a ciphertext-only attack scenario. Furthermore, they found that the real
scrambling domain--the position-scrambling scope of ISEA's scrambled
elements--can be used to support an efficient known or chosen-plaintext attack
on it. Detailed experimental results have verified these points and demonstrate
that some advanced multimedia processing techniques can facilitate the
cryptanalysis of multimedia encryption algorithms.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01642</dc:identifier>
 <dc:identifier>IEEE MultiMedia, vol. 24, no. 3, pp. 64-71, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/MMUL.2017.3051512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01643</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A configurable accelerator for manycores: the Explicitly Many-Processor
  Approach</dc:title>
 <dc:creator>V&#xe9;gh, J&#xe1;nos</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  A new approach to designing processor accelerators is presented. A new
computing model and a special kind of accelerator with dynamic (end-user
programmable) architecture is suggested. The new model considers a processor,
in which a newly introduced supervisor layer coordinates the job of the cores.
The cores have the ability (based on the parallelization information provided
by the compiler, and using the help of the supervisor) to outsource part of the
job they received to some neighbouring core. The introduced changes essentially
and advantageously modify the architecture and operation of the computing
systems. The computing throughput drastically increases, the efficiency of the
technological implementation (computing performance per logic gates) increases,
the non-payload activity for using operating system services decreases, the
real-time behavior changes advantageously, and connecting accelerators to the
processor greatly simplifies. Here only some details of the architecture and
operation of the processor are discussed, the rest is described elsewhere.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01643</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01657</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Graph Exploration with Advice</dc:title>
 <dc:creator>Gorain, Barun</dc:creator>
 <dc:creator>Pelc, Andrzej</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the task of graph exploration. An $n$-node graph has unlabeled
nodes, and all ports at any node of degree $d$ are arbitrarily numbered
$0,\dots, d-1$. A mobile agent has to visit all nodes and stop. The exploration
time is the number of edge traversals. We consider the problem of how much
knowledge the agent has to have a priori, in order to explore the graph in a
given time, using a deterministic algorithm. This a priori information (advice)
is provided to the agent by an oracle, in the form of a binary string, whose
length is called the size of advice. We consider two types of oracles. The
instance oracle knows the entire instance of the exploration problem, i.e., the
port-numbered map of the graph and the starting node of the agent in this map.
The map oracle knows the port-numbered map of the graph but does not know the
starting node of the agent.
  We first consider exploration in polynomial time, and determine the exact
minimum size of advice to achieve it. This size is $\log\log\log n -\Theta(1)$,
for both types of oracles.
  When advice is large, there are two natural time thresholds: $\Theta(n^2)$
for a map oracle, and $\Theta(n)$ for an instance oracle, that can be achieved
with sufficiently large advice. We show that, with a map oracle, time
$\Theta(n^2)$ cannot be improved in general, regardless of the size of advice.
We also show that the smallest size of advice to achieve this time is larger
than $n^\delta$, for any $\delta &lt;1/3$.
  For an instance oracle, advice of size $O(n\log n)$ is enough to achieve time
$O(n)$. We show that, with any advice of size $o(n\log n)$, the time of
exploration must be at least $n^\epsilon$, for any $\epsilon &lt;2$, and with any
advice of size $O(n)$, the time must be $\Omega(n^2)$.
  We also investigate minimum advice sufficient for fast exploration of
hamiltonian graphs.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01668</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor Decomposition for Signal Processing and Machine Learning</dc:title>
 <dc:creator>Sidiropoulos, Nicholas D.</dc:creator>
 <dc:creator>De Lathauwer, Lieven</dc:creator>
 <dc:creator>Fu, Xiao</dc:creator>
 <dc:creator>Huang, Kejun</dc:creator>
 <dc:creator>Papalexakis, Evangelos E.</dc:creator>
 <dc:creator>Faloutsos, Christos</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Tensors or {\em multi-way arrays} are functions of three or more indices
$(i,j,k,\cdots)$ -- similar to matrices (two-way arrays), which are functions
of two indices $(r,c)$ for (row,column). Tensors have a rich history,
stretching over almost a century, and touching upon numerous disciplines; but
they have only recently become ubiquitous in signal and data analytics at the
confluence of signal processing, statistics, data mining and machine learning.
This overview article aims to provide a good starting point for researchers and
practitioners interested in learning about and working with tensors. As such,
it focuses on fundamentals and motivation (using various application examples),
aiming to strike an appropriate balance of breadth {\em and depth} that will
enable someone having taken first graduate courses in matrix algebra and
probability to get started doing research and/or developing tensor algorithms
and software. Some background in applied optimization is useful but not
strictly required. The material covered includes tensor rank and rank
decomposition; basic tensor factorization models and their relationships and
properties (including fairly good coverage of identifiability); broad coverage
of algorithms ranging from alternating optimization to stochastic gradient;
statistical performance analysis; and applications ranging from source
separation to collaborative filtering, mixture and topic modeling,
classification, and multilinear subspace learning.
</dc:description>
 <dc:description>Comment: revised version, overview article</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2016-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01668</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2690524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01679</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a method for Rock Classification using Textural Features and Genetic
  Optimization</dc:title>
 <dc:creator>Valentin, Manuel Blanco</dc:creator>
 <dc:creator>De Bom, Clecio Roque</dc:creator>
 <dc:creator>de Albuquerque, Marcio Portes</dc:creator>
 <dc:creator>de Albuquerque, Marcelo Portes</dc:creator>
 <dc:creator>Faria, Elisangela</dc:creator>
 <dc:creator>Correia, Maury Duarte</dc:creator>
 <dc:creator>Surmas, Rodrigo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we present a method to classify a set of rock textures based on
a Spectral Analysis and the extraction of the texture Features of the resulted
images. Up to 520 features were tested using 4 different filters and all 31
different combinations were verified. The classification process relies on a
Naive Bayes classifier. We performed two kinds of optimizations: statistical
optimization with covariance-based Principal Component Analysis (PCA) and a
genetic optimization, for 10,000 randomly defined samples, achieving a final
maximum classification success of 91% against the original 70% success ratio
(without any optimization nor filters used). After the optimization 9 types of
features emerged as most relevant.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures, 1 appendix. Replaced to match the published
  version</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01679</dc:identifier>
 <dc:identifier>Notas Tecnicas do CBPF, v.7, n.1 (2017)</dc:identifier>
 <dc:identifier>doi:10.7437/NT2236-7640/2017.01.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01683</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Node-Centric Detection of Overlapping Communities in Social Networks</dc:title>
 <dc:creator>Cohen, Yehonatan</dc:creator>
 <dc:creator>Hendler, Danny</dc:creator>
 <dc:creator>Rubin, Amir</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We present NECTAR, a community detection algorithm that generalizes Louvain
method's local search heuristic for overlapping community structures. NECTAR
chooses dynamically which objective function to optimize based on the network
on which it is invoked. Our experimental evaluation on both synthetic benchmark
graphs and real-world networks, based on ground-truth communities, shows that
NECTAR provides excellent results as compared with state of the art community
detection algorithms.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01684</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The zero-error randomized query complexity of the pointer function</dc:title>
 <dc:creator>Radhakrishnan, Jaikumar</dc:creator>
 <dc:creator>Sanyal, Swagato</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The pointer function of G{\&quot;{o}}{\&quot;{o}}s, Pitassi and Watson
\cite{DBLP:journals/eccc/GoosP015a} and its variants have recently been used to
prove separation results among various measures of complexity such as
deterministic, randomized and quantum query complexities, exact and approximate
polynomial degrees, etc. In particular, the widest possible (quadratic)
separations between deterministic and zero-error randomized query complexity,
as well as between bounded-error and zero-error randomized query complexity,
have been obtained by considering {\em
variants}~\cite{DBLP:journals/corr/AmbainisBBL15} of this pointer function.
  However, as was pointed out in \cite{DBLP:journals/corr/AmbainisBBL15}, the
precise zero-error complexity of the original pointer function was not known.
We show a lower bound of $\widetilde{\Omega}(n^{3/4})$ on the zero-error
randomized query complexity of the pointer function on $\Theta(n \log n)$ bits;
since an $\widetilde{O}(n^{3/4})$ upper bound is already known
\cite{DBLP:conf/fsttcs/MukhopadhyayS15}, our lower bound is optimal up to a
factor of $\polylog\, n$.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01686</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Primitive recursive functions versus partial recursive functions:
  comparing the degree of undecidability</dc:title>
 <dc:creator>Matos, Armando B.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Consider a decision problem whose instance is a function. Its degree of
undecidability, measured by the corresponding class of the arithmetic (or
Kleene-Mostowski) hierarchy hierarchy, may depend on whether the instance is a
partial recursive or a primitive recursive function. A similar situation
happens for results like Rice Theorem (which is false for primitive recursive
functions). Classical Recursion Theory deals mainly with the properties of
partial recursive functions. We study several natural decision problems related
to primitive recursive functions and characterise their degree of
undecidability. As an example, we show that, for primitive recursive functions,
the injectivity problem is Pi^0_1-complete while the surjectivity problem is
Pi_2-complete (omit superscripts from now on). We compare the degree of
undecidability (measured by the level in the arithmetic hierarchy) of several
primitive recursive decision problems with the corresponding problems of
classical Recursion Theory. For instance, the problem &quot;does the codomain of a
function have exactly one element?&quot; is Pi_1-complete for primitive recursive
functions and belongs to the class [Delta_2 - (Sigma_1 UNION Pi_1)] for partial
recursive functions. An important decision problem, &quot;does a given primitive
recursive function have at least one zero?&quot; is studied in detail.
</dc:description>
 <dc:description>Comment: Original research work. 46 pages. 12 figures</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01690</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Hierarchical Redundancy Eliminated Tree Augmented Naive Bayes
  Classifier for Coping with Gene Ontology-based Features</dc:title>
 <dc:creator>Wan, Cen</dc:creator>
 <dc:creator>Freitas, Alex A.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:description>  The Tree Augmented Naive Bayes classifier is a type of probabilistic
graphical model that can represent some feature dependencies. In this work, we
propose a Hierarchical Redundancy Eliminated Tree Augmented Naive Bayes
(HRE-TAN) algorithm, which considers removing the hierarchical redundancy
during the classifier learning process, when coping with data containing
hierarchically structured features. The experiments showed that HRE-TAN obtains
significantly better predictive performance than the conventional Tree
Augmented Naive Bayes classifier, and enhanced the robustness against
imbalanced class distributions, in aging-related gene datasets with Gene
Ontology terms used as features.
</dc:description>
 <dc:description>Comment: International Conference on Machine Learning (ICML 2016)
  Computational Biology Workshop</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01691</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Modified Activation Function with Improved Run-Times For Neural
  Networks</dc:title>
 <dc:creator>Anireh, Vincent Ike</dc:creator>
 <dc:creator>Osegi, Emmanuel Ndidi</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper we present a modified version of the Hyperbolic Tangent
Activation Function as a learning unit generator for neural networks. The
function uses an integer calibration constant as an approximation to the Euler
number, e, based on a quadratic Real Number Formula (RNF) algorithm and an
adaptive normalization constraint on the input activations to avoid the
vanishing gradient. We demonstrate the effectiveness of the proposed
modification using a hypothetical and real world dataset and show that lower
run-times can be achieved by learning algorithms using this function leading to
improved speed-ups and learning accuracies during training.
</dc:description>
 <dc:description>Comment: 22pages, 12 figures, 3 tables; Submitted for Publication</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01691</dc:identifier>
 <dc:identifier>Advances in Multidisciplinary &amp; Scientific Research Journal. Vol.
  3. No.2, Pp 33-44</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01704</identifier>
 <datestamp>2016-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Landauer Bound for Analog Computing Systems</dc:title>
 <dc:creator>Diamantini, M. Cristina</dc:creator>
 <dc:creator>Gammaitoni, Luca</dc:creator>
 <dc:creator>Trugenberger, Carlo A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>High Energy Physics - Theory</dc:subject>
 <dc:description>  By establishing a relation between information erasure and continuous phase
transitions we generalise the Landauer bound to analog computing systems. The
entropy production per degree of freedom during erasure of an analog variable
(reset to standard value) is given by the logarithm of the configurational
volume measured in units of its minimal quantum. As a consequence every
computation has to be carried on with a finite number of bits and infinite
precision is forbidden by the fundamental laws of physics, since it would
require an infinite amount of energy.
</dc:description>
 <dc:description>Comment: 5 pages, no figures, to appear in Phys. Rev. E</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01704</dc:identifier>
 <dc:identifier>Phys. Rev. E94, 012139 (2016)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.94.012139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01718</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graphons, mergeons, and so on!</dc:title>
 <dc:creator>Eldridge, Justin</dc:creator>
 <dc:creator>Belkin, Mikhail</dc:creator>
 <dc:creator>Wang, Yusu</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  In this work we develop a theory of hierarchical clustering for graphs. Our
modeling assumption is that graphs are sampled from a graphon, which is a
powerful and general model for generating graphs and analyzing large networks.
Graphons are a far richer class of graph models than stochastic blockmodels,
the primary setting for recent progress in the statistical theory of graph
clustering. We define what it means for an algorithm to produce the &quot;correct&quot;
clustering, give sufficient conditions in which a method is statistically
consistent, and provide an explicit algorithm satisfying these properties.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01719</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep CORAL: Correlation Alignment for Deep Domain Adaptation</dc:title>
 <dc:creator>Sun, Baochen</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep neural networks are able to learn powerful representations from large
quantities of labeled input data, however they cannot always generalize well
across changes in input distributions. Domain adaptation algorithms have been
proposed to compensate for the degradation in performance due to domain shift.
In this paper, we address the case when the target domain is unlabeled,
requiring unsupervised adaptation. CORAL is a &quot;frustratingly easy&quot; unsupervised
domain adaptation method that aligns the second-order statistics of the source
and target distributions with a linear transformation. Here, we extend CORAL to
learn a nonlinear transformation that aligns correlations of layer activations
in deep neural networks (Deep CORAL). Experiments on standard benchmark
datasets show state-of-the-art performance.
</dc:description>
 <dc:description>Comment: Extended Abstract</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01723</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GUICop: Approach and Toolset for Specification-based GUI Testing</dc:title>
 <dc:creator>Hammoud, Dalal</dc:creator>
 <dc:creator>Zaraket, Fadi A.</dc:creator>
 <dc:creator>Masri, Wes</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Oracles used for testing graphical user interface (GUI) programs are required
to take into consideration complicating factors such as variations in screen
resolution or color scheme when comparing observed GUI elements to expected GUI
elements. Researchers proposed fuzzy comparison rules and computationally
expensive image processing techniques to tame the comparison process since
otherwise the naive matching comparison would be too constraining and
consequently impractical. Alternatively, this paper proposes GUICop, a novel
approach with a supporting toolset that takes (1) a GUI program and (2)
user-defined GUI specifications characterizing the rendering behavior of the
GUI elements, and checks whether the execution traces of the program satisfy
the specifications. GUICop comprises the following: 1) a GUI Specification
Language; 2) a Driver; 3) Instrumented GUI Libraries; 4) a Solver; and 5) a
Code Weaver. The user defines the specifications of the subject GUI program
using the GUI Specification Language. The Driver traverses the GUI structure of
the program and generates events that drive its execution. The Instrumented GUI
Libraries capture the GUI execution trace, i.e., information about the
positions and visibility of the GUI elements. And the Solver, enabled by code
injected by the Code Weaver, checks whether the traces satisfy the
specifications. GUICop was successfully evaluated using four open source GUI
applications that included eight defects, namely, Jajuk, Gason, JEdit, and
TerpPaint.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01729</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost-Optimal Algorithms for Planning with Procedural Control Knowledge</dc:title>
 <dc:creator>Shivashankar, Vikas</dc:creator>
 <dc:creator>Alford, Ron</dc:creator>
 <dc:creator>Roberts, Mark</dc:creator>
 <dc:creator>Aha, David W.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  There is an impressive body of work on developing heuristics and other
reasoning algorithms to guide search in optimal and anytime planning algorithms
for classical planning. However, very little effort has been directed towards
developing analogous techniques to guide search towards high-quality solutions
in hierarchical planning formalisms like HTN planning, which allows using
additional domain-specific procedural control knowledge. In lieu of such
techniques, this control knowledge often needs to provide the necessary search
guidance to the planning algorithm, which imposes a substantial burden on the
domain author and can yield brittle or error-prone domain models. We address
this gap by extending recent work on a new hierarchical goal-based planning
formalism called Hierarchical Goal Network (HGN) Planning to develop the
Hierarchically-Optimal Goal Decomposition Planner (HOpGDP), an HGN planning
algorithm that computes hierarchically-optimal plans. HOpGDP is guided by
$h_{HL}$, a new HGN planning heuristic that extends existing admissible
landmark-based heuristics from classical planning to compute admissible cost
estimates for HGN planning problems. Our experimental evaluation across three
benchmark planning domains shows that HOpGDP compares favorably to both optimal
classical planners due to its ability to use domain-specific procedural
knowledge, and a blind-search version of HOpGDP due to the search guidance
provided by $h_{HL}$.
</dc:description>
 <dc:description>Comment: To appear in the Proc. of ECAI 2016</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01730</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rolling Horizon Coevolutionary Planning for Two-Player Video Games</dc:title>
 <dc:creator>Liu, Jialin</dc:creator>
 <dc:creator>P&#xe9;rez-Li&#xe9;bana, Diego</dc:creator>
 <dc:creator>Lucas, Simon M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>91A05, 91A15, 68T20, 97R40</dc:subject>
 <dc:description>  This paper describes a new algorithm for decision making in two-player
real-time video games. As with Monte Carlo Tree Search, the algorithm can be
used without heuristics and has been developed for use in general video game
AI. The approach is to extend recent work on rolling horizon evolutionary
planning, which has been shown to work well for single-player games, to two (or
in principle many) player games. To select an action the algorithm co-evolves
two (or in the general case N) populations, one for each player, where each
individual is a sequence of actions for the respective player. The fitness of
each individual is evaluated by playing it against a selection of
action-sequences from the opposing population. When choosing an action to take
in the game, the first action is chosen from the fittest member of the
population for that player. The new algorithm is compared with a number of
general video game AI algorithms on three variations of a two-player space
battle game, with promising results.
</dc:description>
 <dc:description>Comment: 2 figures, 1 table, 6 pages</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01736</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Achievability of an $(r,l)$ Fractional Linear Network Code</dc:title>
 <dc:creator>Das, Niladri</dc:creator>
 <dc:creator>Rai, Brijesh Kumar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  It is known that there exists a network, called as the M-network, which is
not scalar linearly solvable but has a vector linear solution for message
dimension two. Recently, a generalization of this result has been presented
where it has been shown that for any integer $m\geq 2$, there exists a network
which has a $(m,m)$ vector linear solution, but does not have a $(w,w)$ vector
linear solution for $w&lt;m$. This paper presents a further generalization.
Specifically, we show that for any positive integers $k,n,$ and $m\geq 2$,
there exists a network which has a $(mk,mn)$ fractional linear solution, but
does not have a $(wk,wn)$ fractional linear solution for $w&lt;m$.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01750</identifier>
 <datestamp>2016-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Definitions of Unbounded Evolution and Innovation Reveal
  Universal Mechanisms for Open-Ended Evolution in Dynamical Systems</dc:title>
 <dc:creator>Adams, Alyssa M</dc:creator>
 <dc:creator>Zenil, Hector</dc:creator>
 <dc:creator>Davies, Paul CW</dc:creator>
 <dc:creator>Walker, Sara I</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  Open-ended evolution (OEE) is relevant to a variety of biological, artificial
and technological systems, but has been challenging to reproduce in silico.
Most theoretical efforts focus on key aspects of open-ended evolution as it
appears in biology. We recast the problem as a more general one in dynamical
systems theory, providing simple criteria for open-ended evolution based on two
hallmark features: unbounded evolution and innovation. We define unbounded
evolution as patterns that are non-repeating within the expected Poincare
recurrence time of an equivalent isolated system, and innovation as
trajectories not observed in isolated systems. As a case study, we implement
novel variants of cellular automata (CA) in which the update rules are allowed
to vary with time in three alternative ways. Each is capable of generating
conditions for open-ended evolution, but vary in their ability to do so. We
find that state-dependent dynamics, widely regarded as a hallmark of life,
statistically out-performs other candidate mechanisms, and is the only
mechanism to produce open-ended evolution in a scalable manner, essential to
the notion of ongoing evolution. This analysis suggests a new framework for
unifying mechanisms for generating OEE with features distinctive to life and
its artifacts, with broad applicability to biological and artificial systems.
</dc:description>
 <dc:description>Comment: Main document: 17 pages, Supplement: 21 pages Presented at OEE2: The
  Second Workshop on Open-Ended Evolution, 15th International Conference on the
  Synthesis and Simulation of Living Systems (ALIFE XV), Canc\'un, Mexico, 4-8
  July 2016 (http://www.tim-taylor.com/oee2/)</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2016-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01752</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CrowdCafe - Mobile Crowdsourcing Platform</dc:title>
 <dc:creator>Kucherbaev, Pavel</dc:creator>
 <dc:creator>Abad, Azad</dc:creator>
 <dc:creator>Tranquillini, Stefano</dc:creator>
 <dc:creator>Daniel, Florian</dc:creator>
 <dc:creator>Marchese, Maurizio</dc:creator>
 <dc:creator>Casati, Fabio</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this paper we present a mobile crowdsourcing platform CrowdCafe, where
people can perform microtasks using their smartphones while they ride a bus,
travel by train, stand in a queue or wait for an appointment. These microtasks
are executed in exchange for rewards provided by local stores, such as coffee,
desserts and bus tickets. We present the concept, the implementation and the
evaluation by conducting a study with 52 participants, having 1108 tasks
completed.
</dc:description>
 <dc:description>Comment: Was published before as a part of the phd thesis by Pavel Kucherbaev
  http://eprints-phd.biblio.unitn.it/1716/</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01759</identifier>
 <datestamp>2016-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bag of Tricks for Efficient Text Classification</dc:title>
 <dc:creator>Joulin, Armand</dc:creator>
 <dc:creator>Grave, Edouard</dc:creator>
 <dc:creator>Bojanowski, Piotr</dc:creator>
 <dc:creator>Mikolov, Tomas</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper explores a simple and efficient baseline for text classification.
Our experiments show that our fast text classifier fastText is often on par
with deep learning classifiers in terms of accuracy, and many orders of
magnitude faster for training and evaluation. We can train fastText on more
than one billion words in less than ten minutes using a standard multicore~CPU,
and classify half a million sentences among~312K classes in less than a minute.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2016-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01760</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-theoretic thresholds for community detection in sparse
  networks</dc:title>
 <dc:creator>Banks, Jess</dc:creator>
 <dc:creator>Moore, Cristopher</dc:creator>
 <dc:creator>Neeman, Joe</dc:creator>
 <dc:creator>Netrapalli, Praneeth</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We give upper and lower bounds on the information-theoretic threshold for
community detection in the stochastic block model. Specifically, consider the
symmetric stochastic block model with $q$ groups, average degree $d$, and
connection probabilities $c_\text{in}/n$ and $c_\text{out}/n$ for within-group
and between-group edges respectively; let $\lambda =
(c_\text{in}-c_\text{out})/(qd)$. We show that, when $q$ is large, and $\lambda
= O(1/q)$, the critical value of $d$ at which community detection becomes
possible---in physical terms, the condensation threshold---is \[ d_\text{c} =
\Theta\!\left( \frac{\log q}{q \lambda^2} \right) \, , \] with tighter results
in certain regimes. Above this threshold, we show that any partition of the
nodes into $q$ groups which is as `good' as the planted one, in terms of the
number of within- and between-group edges, is correlated with it. This gives an
exponential-time algorithm that performs better than chance; specifically,
community detection becomes possible below the Kesten-Stigum bound for $q \ge
5$ in the disassortative case $\lambda &lt; 0$, and for $q \ge 11$ in the
assortative case $\lambda &gt;0$ (similar upper bounds were obtained independently
by Abbe and Sandon). Conversely, below this threshold, we show that no
algorithm can label the vertices better than chance, or even distinguish the
block model from an \ER\ random graph with high probability.
  Our lower bound on $d_\text{c}$ uses Robinson and Wormald's small subgraph
conditioning method, and we also give (less explicit) results for non-symmetric
stochastic block models. In the symmetric case, we obtain explicit results by
using bounds on certain functions of doubly stochastic matrices due to
Achlioptas and Naor; indeed, our lower bound on $d_\text{c}$ is their second
moment lower bound on the $q$-colorability threshold for random graphs with a
certain effective degree.
</dc:description>
 <dc:description>Comment: This paper is a combination of arXiv:1601.02658 and arXiv:1404.6304
  which appeared in COLT 2016</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01760</dc:identifier>
 <dc:identifier>29th Annual Conference on Learning Theory (pp. 383-416) (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01794</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VideoLSTM Convolves, Attends and Flows for Action Recognition</dc:title>
 <dc:creator>Li, Zhenyang</dc:creator>
 <dc:creator>Gavves, Efstratios</dc:creator>
 <dc:creator>Jain, Mihir</dc:creator>
 <dc:creator>Snoek, Cees G. M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a new architecture for end-to-end sequence learning of actions in
video, we call VideoLSTM. Rather than adapting the video to the peculiarities
of established recurrent or convolutional architectures, we adapt the
architecture to fit the requirements of the video medium. Starting from the
soft-Attention LSTM, VideoLSTM makes three novel contributions. First, video
has a spatial layout. To exploit the spatial correlation we hardwire
convolutions in the soft-Attention LSTM architecture. Second, motion not only
informs us about the action content, but also guides better the attention
towards the relevant spatio-temporal locations. We introduce motion-based
attention. And finally, we demonstrate how the attention from VideoLSTM can be
used for action localization by relying on just the action class label.
Experiments and comparisons on challenging datasets for action classification
and localization support our claims.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01796</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy accumulation</dc:title>
 <dc:creator>Dupuis, Frederic</dc:creator>
 <dc:creator>Fawzi, Omar</dc:creator>
 <dc:creator>Renner, Renato</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We ask the question whether entropy accumulates, in the sense that the
operationally relevant total uncertainty about an $n$-partite system $A = (A_1,
\ldots A_n)$ corresponds to the sum of the entropies of its parts $A_i$. The
Asymptotic Equipartition Property implies that this is indeed the case to first
order in $n$, under the assumption that the parts $A_i$ are identical and
independent of each other. Here we show that entropy accumulation occurs more
generally, i.e., without an independence assumption, provided one quantifies
the uncertainty about the individual systems $A_i$ by the von Neumann entropy
of suitably chosen conditional states. The analysis of a large system can hence
be reduced to the study of its parts. This is relevant for applications. In
device-independent cryptography, for instance, the approach yields essentially
optimal security bounds valid for general attacks, as shown by Arnon-Friedman
et al.
</dc:description>
 <dc:description>Comment: 40 pages; expandable to 45 pages</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01797</identifier>
 <datestamp>2017-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple and tight device-independent security proofs</dc:title>
 <dc:creator>Arnon-Friedman, Rotem</dc:creator>
 <dc:creator>Renner, Renato</dc:creator>
 <dc:creator>Vidick, Thomas</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Proving security of device-independent (DI) cryptographic protocols has been
regarded to be a complex and tedious task. In this work we show that a newly
developed tool, the &quot;entropy accumulation theorem&quot; of Dupuis et al., can be
effectively applied to give fully general proofs of DI security. At a high
level our technique amounts to establishing a reduction to the scenario in
which the untrusted device operates in an identical and independent way in each
round of the protocol. This makes the proof much simpler and yields
significantly better, essentially tight, quantitative results when considering
general quantum adversaries, compared to what was known before.
  As concrete applications we give simple and modular security proofs for DI
quantum key distribution and randomness expansion protocols based on the CHSH
inequality. For both tasks we establish essentially optimal key rates and noise
tolerance. As loophole-free Bell tests are finally being realised, our results
considerably decrease the gap between theory and experiments, thereby marking
an important step towards practical DI protocols and their implementations.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2017-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01818</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Comparison of ML and MAP Detectors for Multidimensional
  Constellations</dc:title>
 <dc:creator>Alvarado, Alex</dc:creator>
 <dc:creator>Agrell, Erik</dc:creator>
 <dc:creator>Br&#xe4;nnstr&#xf6;m, Fredrik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A classical problem in digital communications is to evaluate the symbol error
probability (SEP) and bit error probability (BEP) of a multidimensional
constellation over an additive white Gaussian noise channel. In this paper, we
revisit this problem for nonequally likely symbols and study the asymptotic
behavior of the optimal maximum a posteriori (MAP) detector. Exact closed-form
asymptotic expressions for SEP and BEP for arbitrary constellations and input
distributions are presented. The well-known union bound is proven to be
asymptotically tight under general conditions. The performance of the
practically relevant maximum likelihood (ML) detector is also analyzed.
Although the decision regions with MAP detection converge to the ML regions at
high signal-to-noise ratios, the ratio between the MAP and ML detector in terms
of both SEP and BEP approach a constant, which depends on the constellation and
a priori probabilities. Necessary and sufficient conditions for asymptotic
equivalence between the MAP and ML detectors are also presented.
</dc:description>
 <dc:description>Comment: Final version, to appear in IEEE Trans. on Inf. Theory</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2017-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01818</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2727521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01826</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single-Player and Two-Player Buttons &amp; Scissors Games</dc:title>
 <dc:creator>Burke, Kyle</dc:creator>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Gregg, Harrison</dc:creator>
 <dc:creator>Hearn, Robert A.</dc:creator>
 <dc:creator>Hesterberg, Adam</dc:creator>
 <dc:creator>Hoffmann, Michael</dc:creator>
 <dc:creator>Ito, Hiro</dc:creator>
 <dc:creator>Kostitsyna, Irina</dc:creator>
 <dc:creator>Leonard, Jody</dc:creator>
 <dc:creator>L&#xf6;ffler, Maarten</dc:creator>
 <dc:creator>Santiago, Aaron</dc:creator>
 <dc:creator>Schmidt, Christiane</dc:creator>
 <dc:creator>Uehara, Ryuhei</dc:creator>
 <dc:creator>Uno, Yushi</dc:creator>
 <dc:creator>Williams, Aaron</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>91A46</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  We study the computational complexity of the Buttons \&amp; Scissors game and
obtain sharp thresholds with respect to several parameters. Specifically we
show that the game is NP-complete for $C = 2$ colors but polytime solvable for
$C = 1$. Similarly the game is NP-complete if every color is used by at most $F
= 4$ buttons but polytime solvable for $F \leq 3$. We also consider
restrictions on the board size, cut directions, and cut sizes. Finally, we
introduce several natural two-player versions of the game and show that they
are PSPACE-complete.
</dc:description>
 <dc:description>Comment: 21 pages, 15 figures. Presented at JCDCG2 2015, Kyoto University,
  Kyoto, Japan, September 14 - 16, 2015</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01827</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressive Spectral Estimation with Single-Snapshot ESPRIT: Stability
  and Resolution</dc:title>
 <dc:creator>Fannjiang, Albert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper Estimation of Signal Parameters via Rotational Invariance
Techniques (ESPRIT) is developed for spectral estimation with single-snapshot
measurement. Stability and resolution analysis with performance guarantee for
Single-Snapshot ESPRIT (SS-ESPRIT) is the main focus. In the noise-free case,
exact reconstruction is guaranteed for any arbitrary set of frequencies as long
as the number of measurement data is at least twice the number of distinct
frequencies to be recovered. In the presence of noise and under the assumption
that the true frequencies are separated by at least two times Rayleigh's
Resolution Length, an explicit error bound for frequency reconstruction is
given in terms of the dynamic range and the separation of the frequencies. The
separation and sparsity constraint compares favorably with those of the leading
approaches to compressed sensing in the continuum.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01828</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Nested String Replacements</dc:title>
 <dc:creator>Petersen, Holger</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We investigate the number of nested string replacements required to reduce a
string of identical characters to one character.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01835</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the Fourth International Workshop on Verification and
  Program Transformation</dc:title>
 <dc:creator>Hamilton, Geoff</dc:creator>
 <dc:creator>Lisitsa, Alexei</dc:creator>
 <dc:creator>Nemytykh, Andrei P.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This volume contains the revised versions of papers presented at the Fourth
International Workshop on Verification and Program Transformation (VPT 2016) on
April 2, 2016 in Eindhoven, The Netherlands. The workshop is an event of the
European Joint Conferences on Theory and Practice of Software (ETAPS 2016).
  The aim of the VPT workshops is to provide a forum where people from the area
of program transformation and the area of program verification can fruitfully
exchange ideas and gain a deeper understanding of the interactions between
those two fields. The research papers which have been recently published in
those fields, show that the interactions are very beneficial and, indeed, go
both ways. In one direction, methods and tools developed in the field of
program transformation, such as partial deduction, partial evaluation,
fold/unfold transformations, and supercompilation, have all been applied with
success for the verification of systems, and in particular, the verification of
infinite state and parameterized systems. In the other direction, methods
developed in program verification, such as model checking, abstract
interpretation, SAT and SMT solving, and automated theorem proving, have been
used to enhance program transformation techniques, thereby making these
techniques more powerful and useful in practice.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01835</dc:identifier>
 <dc:identifier>EPTCS 216, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01838</identifier>
 <datestamp>2017-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordinate-Descent Diffusion Learning by Networked Agents</dc:title>
 <dc:creator>Wang, Chengcheng</dc:creator>
 <dc:creator>Zhang, Yonggang</dc:creator>
 <dc:creator>Ying, Bicheng</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This work examines the mean-square error performance of diffusion stochastic
algorithms under a generalized coordinate-descent scheme. In this setting, the
adaptation step by each agent is limited to a random subset of the coordinates
of its stochastic gradient vector. The selection of coordinates varies randomly
from iteration to iteration and from agent to agent across the network. Such
schemes are useful in reducing computational complexity at each iteration in
power-intensive large data applications. They are also useful in modeling
situations where some partial gradient information may be missing at random.
Interestingly, the results show that the steady-state performance of the
learning strategy is not always degraded, while the convergence rate suffers
some degradation. The results provide yet another indication of the resilience
and robustness of adaptive distributed strategies.
</dc:description>
 <dc:description>Comment: Accepted for publication</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2017-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01838</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2757903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01842</identifier>
 <datestamp>2017-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Significant Fourier Coefficients: Clarifications,
  Simplifications, Applications and Limitations</dc:title>
 <dc:creator>Galbraith, Steven D.</dc:creator>
 <dc:creator>Laity, Joel</dc:creator>
 <dc:creator>Shani, Barak</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Ideas from Fourier analysis have been used in cryptography for three decades.
Akavia, Goldwasser and Safra unified some of these ideas to give a complete
algorithm that finds significant Fourier coefficients of functions on any
finite abelian group. Their algorithm stimulated a lot of interest in the
cryptography community, especially in the context of &quot;bit security&quot;. This paper
attempts to be a friendly and comprehensive guide to the tools and results in
this field. The intended readership is cryptographers who have heard about
these tools and seek an understanding of their mechanics, and their usefulness
and limitations. A compact overview of the algorithm is presented with emphasis
on the ideas behind it. We survey some applications of this algorithm, and
explain that several results should be taken in the right context. We point out
that some of the most important bit security problems are still open. Our
original contributions include: an approach to the subject based on modulus
switching; a discussion of the limitations on the usefulness of these tools; an
answer to an open question about the modular inversion hidden number problem.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2017-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01845</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Urban Social Media Inequality: Definition, Measurements, and Application</dc:title>
 <dc:creator>Indaco, Agustin</dc:creator>
 <dc:creator>Manovich, Lev</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Social media content shared today in cities, such as Instagram images, their
tags and descriptions, is the key form of contemporary city life. It tells
people where activities and locations that interest them are and it allows them
to share their urban experiences and self-representations. Therefore, any
analysis of urban structures and cultures needs to consider social media
activity. In our paper, we introduce the novel concept of social media
inequality. This concept allows us to quantitatively compare patterns in social
media activities between parts of a city, a number of cities, or any other
spatial areas. We define this concept using an analogy with the concept of
economic inequality. Economic inequality indicates how some economic
characteristics or material resources, such as income, wealth or consumption
are distributed in a city, country or between countries. Accordingly, we can
define social media inequality as the measure of the distribution of
characteristics from social media content shared in a particular geographic
area or between areas. An example of such characteristics is the number of
photos shared by all users of a social network such as Instagram in a given
city or city area, or the content of these photos. We propose that the standard
inequality measures used in other disciplines, such as the Gini coefficient,
can also be used to characterize social media inequality. To test our ideas, we
use a dataset of 7,442,454 public geo-coded Instagram images shared in
Manhattan during five months (March-July) in 2014, and also selected data for
287 Census tracts in Manhattan. We compare patterns in Instagram sharing for
locals and for visitors for all tracts, and also for hours in a 24-hour cycle.
We also look at relations between social media inequality and socio-economic
inequality using selected indicators for Census tracts.
</dc:description>
 <dc:description>Comment: 53 pages, 11 figures, 3 tables</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2016-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01848</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Decentralized Robust Optimal Design for Homogeneous Linear
  Multi-Agent Systems</dc:title>
 <dc:creator>Nguyen, Dinh Hoa</dc:creator>
 <dc:creator>Narikiyo, Tatsuo</dc:creator>
 <dc:creator>Kawanishi, Michihiro</dc:creator>
 <dc:creator>Hara, Shinji</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes novel approaches to design hierarchical decentralized
robust controllers for homogeneous linear multi-agent systems (MASs) perturbed
by disturbances/noise. Firstly, based on LQR method, we present a systematic
procedure to design hierarchical decentralized optimal stabilizing controllers
for MASs without disturbances/noise. Next, a method for deriving reduced-order
hierarchical decentralized stabilizing controllers is presented by suitable
selections of the weighting matrices in the LQR performance index. Secondly,
the hierarchical decentralized robust controller designs in terms of
$H_{\infty}$ and $H_{2}$ norms are introduced, which include two different
scenarios namely general and LQR-based synthesis. For the general synthesis,
the robust controller gains are computed as solutions of a distributed convex
optimization problem with LMI constraints. On the other hand, for the LQR-based
design, the robust controller gains obtained from the general synthesis are
further verified as LQR stabilizing gains to be unified with the LQR-based
design when there are no disturbances/noise. This results in a hierarchical
decentralized inverse optimal control problem, for which we will propose a new
method to resolve it. Finally, several numerical examples are presented to
illustrate the effectiveness of the proposed approaches.
</dc:description>
 <dc:description>Comment: revised version submitted to IEEE Transactions on Control of Network
  Systems</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01855</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Multi-domain Regularized Deep Learning for Anatomical
  Structure Detection and Segmentation from Ultrasound Images</dc:title>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Zheng, Yefeng</dc:creator>
 <dc:creator>Park, Jin-Hyeong</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:creator>Zhou, S. Kevin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accurate detection and segmentation of anatomical structures from ultrasound
images are crucial for clinical diagnosis and biometric measurements. Although
ultrasound imaging has been widely used with superiorities such as low cost and
portability, the fuzzy border definition and existence of abounding artifacts
pose great challenges for automatically detecting and segmenting the complex
anatomical structures. In this paper, we propose a multi-domain regularized
deep learning method to address this challenging problem. By leveraging the
transfer learning from cross domains, the feature representations are
effectively enhanced. The results are further improved by the iterative
refinement. Moreover, our method is quite efficient by taking advantage of a
fully convolutional network, which is formulated as an end-to-end learning
framework of detection and segmentation. Extensive experimental results on a
large-scale database corroborated that our method achieved a superior detection
and segmentation accuracy, outperforming other methods by a significant margin
and demonstrating competitive capability even compared to human performance.
</dc:description>
 <dc:description>Comment: MICCAI 2016</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01856</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Name Translation Improves Neural Machine Translation</dc:title>
 <dc:creator>Li, Xiaoqing</dc:creator>
 <dc:creator>Zhang, Jiajun</dc:creator>
 <dc:creator>Zong, Chengqing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In order to control computational complexity, neural machine translation
(NMT) systems convert all rare words outside the vocabulary into a single unk
symbol. Previous solution (Luong et al., 2015) resorts to use multiple numbered
unks to learn the correspondence between source and target rare words. However,
testing words unseen in the training corpus cannot be handled by this method.
And it also suffers from the noisy word alignment. In this paper, we focus on a
major type of rare words -- named entity (NE), and propose to translate them
with character level sequence to sequence model. The NE translation model is
further used to derive high quality NE alignment in the bilingual training
corpus. With the integration of NE translation and alignment modules, our NMT
system is able to surpass the baseline system by 2.9 BLEU points on the Chinese
to English task.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01864</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Quadratic Programming Relaxation Approach to Compute-and-Forward
  Network Coding Design</dc:title>
 <dc:creator>Zhou, Baojian</dc:creator>
 <dc:creator>Wen, Jinming</dc:creator>
 <dc:creator>Mow, Wai Ho</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Using physical layer network coding, compute-and-forward is a promising
relaying scheme that effectively exploits the interference between users and
thus achieves high rates. In this paper, we consider the problem of finding the
optimal integer-valued coefficient vector for a relay in the
compute-and-forward scheme to maximize the computation rate at that relay.
Although this problem turns out to be a shortest vector problem, which is
suspected to be NP-hard, we show that it can be relaxed to a series of
equality-constrained quadratic programmings. The solutions of the relaxed
problems serve as real-valued approximations of the optimal coefficient vector,
and are quantized to a set of integer-valued vectors, from which a coefficient
vector is selected. The key to the efficiency of our method is that the
closed-form expressions of the real-valued approximations can be derived with
the Lagrange multiplier method. Numerical results demonstrate that compared
with the existing methods, our method offers comparable rates at an
impressively low complexity.
</dc:description>
 <dc:description>Comment: Part of this work has been presented in ISIT'2014</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01869</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Semantic Matching of Queries to Ads in Sponsored Search
  Advertising</dc:title>
 <dc:creator>Grbovic, Mihajlo</dc:creator>
 <dc:creator>Djuric, Nemanja</dc:creator>
 <dc:creator>Radosavljevic, Vladan</dc:creator>
 <dc:creator>Silvestri, Fabrizio</dc:creator>
 <dc:creator>Baeza-Yates, Ricardo</dc:creator>
 <dc:creator>Feng, Andrew</dc:creator>
 <dc:creator>Ordentlich, Erik</dc:creator>
 <dc:creator>Yang, Lee</dc:creator>
 <dc:creator>Owens, Gavin</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Sponsored search represents a major source of revenue for web search engines.
This popular advertising model brings a unique possibility for advertisers to
target users' immediate intent communicated through a search query, usually by
displaying their ads alongside organic search results for queries deemed
relevant to their products or services. However, due to a large number of
unique queries it is challenging for advertisers to identify all such relevant
queries. For this reason search engines often provide a service of advanced
matching, which automatically finds additional relevant queries for advertisers
to bid on. We present a novel advanced matching approach based on the idea of
semantic embeddings of queries and ads. The embeddings were learned using a
large data set of user search sessions, consisting of search queries, clicked
ads and search links, while utilizing contextual information such as dwell time
and skipped ads. To address the large-scale nature of our problem, both in
terms of data and vocabulary size, we propose a novel distributed algorithm for
training of the embeddings. Finally, we present an approach for overcoming a
cold-start problem associated with new ads and queries. We report results of
editorial evaluation and online tests on actual search traffic. The results
show that our approach significantly outperforms baselines in terms of
relevance, coverage, and incremental revenue. Lastly, we open-source learned
query embeddings to be used by researchers in computational advertising and
related fields.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures, 39th International ACM SIGIR Conference on
  Research and Development in Information Retrieval, SIGIR 2016, Pisa, Italy</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01869</dc:identifier>
 <dc:identifier>39th International ACM SIGIR Conference on Research and
  Development in Information Retrieval, SIGIR 2016, Pisa, Italy</dc:identifier>
 <dc:identifier>doi:10.1145/2911451.2911538.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01872</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Downlink Cell Association and Load Balancing for Joint Millimeter
  Wave-Microwave Cellular Networks</dc:title>
 <dc:creator>Semiari, Omid</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The integration of millimeter-wave base stations (mmW-BSs) with conventional
microwave base stations ($\mu$W-BSs) is a promising solution for enhancing the
quality-of-service (QoS) of emerging 5G networks. However, the significant
differences in the signal propagation characteristics over the mmW and $\mu$W
frequency bands will require novel cell association schemes cognizant of both
mmW and $\mu$W systems. In this paper, a novel cell association framework is
proposed that considers both the blockage probability and the achievable rate
to assign user equipments (UEs) to mmW-BSs or $\mu$W-BSs. The problem is
formulated as a one-to-many matching problem with minimum quota constraints for
the BSs that provides an efficient way to balance the load over the mmW and
$\mu$W frequency bands. To solve the problem, a distributed algorithm is
proposed that is guaranteed to yield a Pareto optimal and two-sided stable
solution. Simulation results show that the proposed matching with minimum quota
(MMQ) algorithm outperforms the conventional max-RSSI and max-SINR cell
association schemes. In addition, it is shown that the proposed MMQ algorithm
can effectively balance the number of UEs associated with the $\mu$W-BSs and
mmW-BSs and achieve further gains, in terms of the average sum rate.
</dc:description>
 <dc:description>Comment: 2016 IEEE Global Communications Conference: Mobile and Wireless
  Networks</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01880</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complete Description of Matching Polytopes with One Linearized Quadratic
  Term for Bipartite Graphs</dc:title>
 <dc:creator>Walter, Matthias</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>52B99</dc:subject>
 <dc:description>  We consider, for complete bipartite graphs, the convex hulls of
characteristic vectors of all matchings, extended by a binary entry indicating
whether the matching contains two specific edges. These polytopes are
associated to the quadratic matching problems with a single linearized
quadratic term. We provide a complete irredundant inequality description, which
settles a conjecture by Klein (Ph.D. thesis, TU Dortmund, 2015). In addition,
we also derive facetness and separation results for the polytopes. The
completeness proof is based on a geometric relationship to a matching polytope
of a nonbipartite graph. Using standard techniques, we finally extend the
result to capacitated b-matchings.
</dc:description>
 <dc:description>Comment: 24 pages, 4 figures</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01883</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling-based Incremental Information Gathering with Applications to
  Robotic Exploration and Environmental Monitoring</dc:title>
 <dc:creator>Jadidi, Maani Ghaffari</dc:creator>
 <dc:creator>Miro, Jaime Valls</dc:creator>
 <dc:creator>Dissanayake, Gamini</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this article, we propose a sampling-based motion planning algorithm
equipped with an information-theoretic convergence criterion for incremental
informative motion planning. The proposed approach allows dense map
representations and incorporates the full state uncertainty into the planning
process. The problem is formulated as a constrained maximization problem. Our
approach is built on rapidly-exploring information gathering algorithms and
benefits from advantages of sampling-based optimal motion planning algorithms.
We propose two information functions and their variants for fast and online
computations. We prove an information-theoretic convergence for an entire
exploration and information gathering mission based on the least upper bound of
the average map entropy. A natural automatic stopping criterion for
information-driven motion control results from the convergence analysis. We
demonstrate the performance of the proposed algorithms using three scenarios:
comparison of the proposed information functions and sensor configuration
selection, robotic exploration in unknown environments, and a wireless signal
strength monitoring task in a lake from a publicly available dataset collected
using an autonomous surface vehicle.
</dc:description>
 <dc:description>Comment: Revision submitted to IJRR, 49 pages</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-09-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01886</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Join-continuity + Hypercontinuity = Prime continuity</dc:title>
 <dc:creator>Ho, Weng Kin</dc:creator>
 <dc:creator>Jung, Achim</dc:creator>
 <dc:creator>Zhao, Dongsheng</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>06B35</dc:subject>
 <dc:description>  A remarkable result due to Kou, Liu &amp; Luo states that the condition of
continuity for a dcpo can be split into quasi-continuity and meet-continuity.
Their argument contained a gap, however, which is probably why the authors of
the monograph Continuous Lattices and Domains used a different (and fairly
sophisticated) sequence of lemmas in order to establish the result. In this
note we show that by considering the Stone dual, that is, the lattice of
Scott-open subsets, a straightforward proof may be given. We do this by showing
that a complete lattice is prime-continuous if and only if it is
join-continuous and hypercontinuous. A pleasant side effect of this approach is
that the characterisation of continuity by Kou, Liu &amp; Luo also holds for
posets, not just dcpos.
</dc:description>
 <dc:description>Comment: 7 pages, Domains XII Workshop</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01887</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The symbol-pair distance distribution of repeated-root cyclic codes over
  $\mathbb{F}_{p^m}$</dc:title>
 <dc:creator>Zhu, Shixin</dc:creator>
 <dc:creator>Sun, Zhonghua</dc:creator>
 <dc:creator>Wang, Liqi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Symbol-pair codes are proposed to protect against pair errors in symbol-pair
read channels. One of the most important task in symbol-pair coding theory is
to determine the minimum pair-distance of symbol-pair codes. In this paper, we
investigate the symbol-pair distances of cyclic codes of length $p^e$ over
$\mathbb{F}_{p^m}$. The exact symbol-pair distances of all cyclic codes of such
length are determined.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01893</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embracing Agile methodology during DevOps Developer Internship Program</dc:title>
 <dc:creator>Patwardhan, Amol</dc:creator>
 <dc:creator>Kidd, Jon</dc:creator>
 <dc:creator>Urena, Tiffany</dc:creator>
 <dc:creator>Rajgopalan, Aishwarya</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The DevOps team adopted agile methodologies during the summer internship
program as an initiative to move away from waterfall. The DevOps team
implemented the Scrum software development strategy to create an internal data
dictionary web application. This article reports on the transition process and
lessons learned from the pilot program.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, Submitted for peer review to IEEE Software</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01895</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Walk Graph Laplacian based Smoothness Prior for Soft Decoding of
  JPEG Images</dc:title>
 <dc:creator>Liu, Xianming</dc:creator>
 <dc:creator>Cheung, Gene</dc:creator>
 <dc:creator>Wu, Xiaolin</dc:creator>
 <dc:creator>Zhao, Debin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given the prevalence of JPEG compressed images, optimizing image
reconstruction from the compressed format remains an important problem. Instead
of simply reconstructing a pixel block from the centers of indexed DCT
coefficient quantization bins (hard decoding), soft decoding reconstructs a
block by selecting appropriate coefficient values within the indexed bins with
the help of signal priors. The challenge thus lies in how to define suitable
priors and apply them effectively.
  In this paper, we combine three image priors---Laplacian prior for DCT
coefficients, sparsity prior and graph-signal smoothness prior for image
patches---to construct an efficient JPEG soft decoding algorithm. Specifically,
we first use the Laplacian prior to compute a minimum mean square error (MMSE)
initial solution for each code block. Next, we show that while the sparsity
prior can reduce block artifacts, limiting the size of the over-complete
dictionary (to lower computation) would lead to poor recovery of high DCT
frequencies. To alleviate this problem, we design a new graph-signal smoothness
prior (desired signal has mainly low graph frequencies) based on the left
eigenvectors of the random walk graph Laplacian matrix (LERaG). Compared to
previous graph-signal smoothness priors, LERaG has desirable image filtering
properties with low computation overhead. We demonstrate how LERaG can
facilitate recovery of high DCT frequencies of a piecewise smooth (PWS) signal
via an interpretation of low graph frequency components as relaxed solutions to
normalized cut in spectral clustering. Finally, we construct a soft decoding
algorithm using the three signal priors with appropriate prior weights.
Experimental results show that our proposal outperforms state-of-the-art soft
decoding algorithms in both objective and subjective evaluations noticeably.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01895</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2627807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01896</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cell-Edge-Aware Precoding for Downlink Massive MIMO Cellular Networks</dc:title>
 <dc:creator>Yang, Howard H.</dc:creator>
 <dc:creator>Geraci, Giovanni</dc:creator>
 <dc:creator>Quek, Tony Q. S.</dc:creator>
 <dc:creator>Andrews, Jeffrey G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a cell-edge-aware (CEA) zero forcing (ZF) precoder that exploits
the excess spatial degrees of freedom provided by a large number of base
station (BS) antennas to suppress inter-cell interference at the most
vulnerable user equipments (UEs). We evaluate the downlink performance of
CEA-ZF, as well as that of a conventional cell-edge-unaware (CEU) ZF precoder
in a network with random base station topology. Our analysis and simulations
show that the proposed CEA-ZF precoder outperforms CEU-ZF precoding in terms of
(i) aggregate per-cell data rate, (ii) coverage probability, and (iii)
95%-likely, or edge user, rate. In particular, when both perfect channel state
information and a large number of antennas N are available at the BSs, we
demonstrate that the outage probability under CEA-ZF and CEU-ZF decay as 1/N^2
and 1/N, respectively. This result identifies CEA-ZF as a more effective
precoding scheme for massive MIMO cellular networks. Our framework also reveals
the importance of scheduling the optimal number of UEs per BS, and confirms the
necessity to control the amount of pilot contamination received during the
channel estimation phase.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01896</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2690387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01908</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Downlink Power Control for Massive MIMO Cellular Systems with Optimal
  User Association</dc:title>
 <dc:creator>Van Chien, Trinh</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper aims to minimize the total transmit power consumption for Massive
MIMO (multiple-input multiple-output) downlink cellular systems when each user
is served by the optimized subset of the base stations (BSs). We derive a lower
bound on the ergodic spectral efficiency (SE) for Rayleigh fading channels and
maximum ratio transmission (MRT) when the BSs cooperate using non-coherent
joint transmission. We solve the joint user association and downlink transmit
power minimization problem optimally under fixed SE constraints. Furthermore,
we solve a max-min fairness problem with user specific weights that maximizes
the worst SE among the users. The optimal BS-user association rule is derived,
which is different from maximum signal-to-noise-ratio (max-SNR) association.
Simulation results manifest that the proposed methods can provide good SE for
the users using less transmit power than in small-scale systems and that the
optimal user association can effectively balance the load between BSs when
needed.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, presented at ICC 2016</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01912</identifier>
 <datestamp>2017-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear Self-Interference Cancellation for Full-Duplex Radios: From
  Link- and System-Level Performance Perspectives</dc:title>
 <dc:creator>Sim, Min Soo</dc:creator>
 <dc:creator>Chung, MinKeun</dc:creator>
 <dc:creator>Kim, Dongkyu</dc:creator>
 <dc:creator>Chung, Jaehoon</dc:creator>
 <dc:creator>Kim, Dong Ku</dc:creator>
 <dc:creator>Chae, Chan-Byoung</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  One of the promising technologies for LTE Evolution is full-duplex radio, an
innovation is expected to double the spectral efficiency. To realize
full-duplex in practice, the main challenge is overcoming self-interference,
and to do so, researchers have developed self-interference cancellation
techniques. Since most wireless transceivers use power amplifiers, especially
in cellular systems, researchers have revealed the importance of nonlinear
self-interference cancellation. In this article, we first explore several
nonlinear digital self-interference cancellation techniques. We then propose a
low complexity pre-calibration-based nonlinear digital self-interference
cancellation technique. Next we discuss issues about reference signal
allocation and the overhead of each technique. For performance evaluations, we
carry out extensive measurements through a real-time prototype and
link-/system-level simulations. For link-level analysis, we measure the amount
of cancelled self-interference for each technique. We also evaluate
system-level performances through 3D ray-tracing-based simulations. Numerical
results confirm the significant performance improvement over a half-duplex
system even in interference-limited indoor environments.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01924</identifier>
 <datestamp>2017-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intra-cluster Characteristics of 28 GHz Wireless Channel in Urban Micro
  Street Canyon</dc:title>
 <dc:creator>Wu, Shangbin</dc:creator>
 <dc:creator>Hur, Sooyoung</dc:creator>
 <dc:creator>Whang, Kuyeon</dc:creator>
 <dc:creator>Nekovee, Maziar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates intra-cluster channel characteristics of non
line-of-sight (NLOS) 28 GHz channels in street canyon scenarios. These channel
characteristics include cluster numbers, number of subpaths within each
cluster, intra-cluster delay spreads, and intra-cluster angular spreads. Both
measurement and ray tracing results are presented and compared. Furthermore,
distribution fittings are performed and models and parameters for different
intra-cluster channel characteristics are proposed.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01924</dc:identifier>
 <dc:identifier>doi:10.1109/GLOCOM.2016.7841916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01935</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Random Access Error Exponents for Codebooks of Different
  Word-Lengths</dc:title>
 <dc:creator>Farkas, L&#xf3;r&#xe1;nt</dc:creator>
 <dc:creator>K&#xf3;i, Tam&#xe1;s</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Csisz\'ar's channel coding theorem for multiple codebooks is generalized
allowing the codeword lenghts differ across codebooks. Also in this case, for
each codebook an error exponent can be achieved that equals the random coding
exponent for this codebook alone, in addition, erasure detection failure
probability tends to 0. This is proved even for sender and receiver not knowing
the channel. As a corollary, a substantial improvement is obtained when the
sender knows the channel.
</dc:description>
 <dc:description>Comment: This paper is submitted to IEEE Transactions on Information Theory.
  It was presented in part at the recent result poster session of ISIT 2016,
  Barcelona</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01942</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralised Resource Allocation and Coordination for 5G Cellular
  Communication Networks</dc:title>
 <dc:creator>P&#xe9;rez, Gabriel Otero</dc:creator>
 <dc:creator>Veiga, Manuel Fern&#xe1;ndez</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In order to cope with the ever increasing traffic load that networks will
need to support, a new approach for planning cellular networks deployments
should be followed. Traditionally, cell association and resource allocation has
been based on the received signal power but this approach seems to be
inadequate regarding the brewing of heterogeneous networks. In this work, we
first implement a network simulator in order to test new cell associacion and
resource allocation techniques. Then, we pose the network utility maximisation
problem, reformulating the Downlink and Uplink Decoupling (DUDe) scheme under
the framework and tools of mathematical optimisation. We derive the explicit
solution of the problem under fixed and non-fixed association policy so as to
propose and develope both centralised and decentralised algorithms capable of
solving cell association and resource allocation problems. We observe that the
decentralised approach requires low computational effort and represents a
significant gain in the overall performance of the network.
</dc:description>
 <dc:description>Comment: 80 pages, Preliminary Version</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01948</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Novel Performance Analysis of Network Coded Communications in
  Single-Relay Networks</dc:title>
 <dc:creator>Tsimbalo, Evgeny</dc:creator>
 <dc:creator>Tassi, Andrea</dc:creator>
 <dc:creator>Piechocki, Robert J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In this paper, we analyze the performance of a single-relay network in which
the reliability is provided by means of Random Linear Network Coding (RLNC). We
consider a scenario when both source and relay nodes can encode packets. Unlike
the traditional approach to relay networks, we introduce a passive relay mode,
in which the relay node simply retransmits collected packets in case it cannot
decode them. In contrast with the previous studies, we derive a novel
theoretical framework for the performance characterization of the considered
relay network. We extend our analysis to a more general scenario, in which
coding coefficients are generated from non-binary fields. The theoretical
results are verified using simulation, for both binary and non-binary fields.
It is also shown that the passive relay mode significantly improves the
performance compared with the active-only case, offering an up to two-fold gain
in terms of the decoding probability. The proposed framework can be used as a
building block for the analysis of more complex network topologies.
</dc:description>
 <dc:description>Comment: Proceedings of IEEE GLOBECOM 2016 Communication Theory Symposium, to
  appear</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01952</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A First Look at User Activity on Tinder</dc:title>
 <dc:creator>Tyson, Gareth</dc:creator>
 <dc:creator>Perta, Vasile C.</dc:creator>
 <dc:creator>Haddadi, Hamed</dc:creator>
 <dc:creator>Seto, Michael C.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Mobile dating apps have become a popular means to meet potential partners.
Although several exist, one recent addition stands out amongst all others.
Tinder presents its users with pictures of people geographically nearby, whom
they can either like or dislike based on first impressions. If two users like
each other, they are allowed to initiate a conversation via the chat feature.
In this paper we use a set of curated profiles to explore the behaviour of men
and women in Tinder. We reveal differences between the way men and women
interact with the app, highlighting the strategies employed. Women attain large
numbers of matches rapidly, whilst men only slowly accumulate matches. To
expand on our findings, we collect survey data to understand user intentions on
Tinder. Most notably, our results indicate that a little effort in grooming
profiles, especially for male users, goes a long way in attracting attention.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01958</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stock trend prediction using news sentiment analysis</dc:title>
 <dc:creator>Kalyani, Joshi</dc:creator>
 <dc:creator>Bharathi, Prof. H. N.</dc:creator>
 <dc:creator>Jyothi, Prof. Rao</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Efficient Market Hypothesis is the popular theory about stock prediction.
With its failure much research has been carried in the area of prediction of
stocks. This project is about taking non quantifiable data such as financial
news articles about a company and predicting its future stock trend with news
sentiment classification. Assuming that news articles have impact on stock
market, this is an attempt to study relationship between news and stock trend.
To show this, we created three different classification models which depict
polarity of news articles being positive or negative. Observations show that RF
and SVM perform well in all types of testing. Na\&quot;ive Bayes gives good result
but not compared to the other two. Experiments are conducted to evaluate
various aspects of the proposed model and encouraging results are obtained in
all of the experiments. The accuracy of the prediction model is more than 80%
and in comparison with news random labeling with 50% of accuracy; the model has
increased the accuracy by 30%.
</dc:description>
 <dc:description>Comment: 11 PAGES, 4 FIGURES</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01963</identifier>
 <datestamp>2017-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence Training and Adaptation of Highway Deep Neural Networks</dc:title>
 <dc:creator>Lu, Liang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Highway deep neural network (HDNN) is a type of depth-gated feedforward
neural network, which has shown to be easier to train with more hidden layers
and also generalise better compared to conventional plain deep neural networks
(DNNs). Previously, we investigated a structured HDNN architecture for speech
recognition, in which the two gate functions were tied across all the hidden
layers, and we were able to train a much smaller model without sacrificing the
recognition accuracy. In this paper, we carry on the study of this architecture
with sequence-discriminative training criterion and speaker adaptation
techniques on the AMI meeting speech recognition corpus. We show that these two
techniques improve speech recognition accuracy on top of the model trained with
the cross entropy criterion. Furthermore, we demonstrate that the two gate
functions that are tied across all the hidden layers are able to control the
information flow over the whole network, and we can achieve considerable
improvements by only updating these gate functions in both sequence training
and adaptation experiments.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, published at IEEE SLT 2016. arXiv admin note:
  text overlap with arXiv:1610.05812</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01967</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rigorous Multiple-Precision Evaluation of D-Finite Functions in SageMath</dc:title>
 <dc:creator>Mezzarobba, Marc</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We present a new open source implementation in the SageMath computer algebra
system of algorithms for the numerical solution of linear ODEs with polynomial
coefficients. Our code supports regular singular connection problems and
provides rigorous error bounds.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01967</dc:identifier>
 <dc:identifier>5th International Congress on Mathematical Software (ICMS~2016),
  Jul 2016, Berlin, Germany</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01971</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Superimposition of eye fundus images for longitudinal analysis from
  large public health databases</dc:title>
 <dc:creator>Noyel, Guillaume</dc:creator>
 <dc:creator>Thomas, Rebecca</dc:creator>
 <dc:creator>Bhakta, Gavin</dc:creator>
 <dc:creator>Crowder, Andrew</dc:creator>
 <dc:creator>Owens, David</dc:creator>
 <dc:creator>Boyle, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a method is presented for superimposition (i.e. registration)
of eye fundus images from persons with diabetes screened over many years for
diabetic retinopathy. The method is fully automatic and robust to camera
changes and colour variations across the images both in space and time. All the
stages of the process are designed for longitudinal analysis of cohort public
health databases where retinal examinations are made at approximately yearly
intervals. The method relies on a model correcting two radial distortions and
an affine transformation between pairs of images which is robustly fitted on
salient points. Each stage involves linear estimators followed by non-linear
optimisation. The model of image warping is also invertible for fast
computation. The method has been validated (1) on a simulated montage and (2)
on public health databases with 69 patients with high quality images (271 pairs
acquired mostly with different types of camera and 268 pairs acquired mostly
with the same type of camera) with success rates of 92% and 98%, and five
patients (20 pairs) with low quality images with a success rate of 100%.
Compared to two state-of-the-art methods, ours gives better results.
</dc:description>
 <dc:description>Comment: This is a preprint of the published article. It is a preliminary
  version.The Version of Record is available online at
  https://doi.org/10.1088/2057-1976/aa7d16</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01971</dc:identifier>
 <dc:identifier>Biomedical Physics &amp; Engineering Express, 2017, 3 (4)</dc:identifier>
 <dc:identifier>doi:10.1088/2057-1976/aa7d16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01977</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Depth Super-Resolution : Learning Depth Super-Resolution using Deep
  Convolutional Neural Network</dc:title>
 <dc:creator>Song, Xibin</dc:creator>
 <dc:creator>Dai, Yuchao</dc:creator>
 <dc:creator>Qin, Xueying</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Depth image super-resolution is an extremely challenging task due to the
information loss in sub-sampling. Deep convolutional neural network have been
widely applied to color image super-resolution. Quite surprisingly, this
success has not been matched to depth super-resolution. This is mainly due to
the inherent difference between color and depth images. In this paper, we
bridge up the gap and extend the success of deep convolutional neural network
to depth super-resolution. The proposed deep depth super-resolution method
learns the mapping from a low-resolution depth image to a high resolution one
in an end-to-end style. Furthermore, to better regularize the learned depth
map, we propose to exploit the depth field statistics and the local correlation
between depth image and color image. These priors are integrated in an energy
minimization formulation, where the deep neural network learns the unary term,
the depth field statistics works as global model constraint and the color-depth
correlation is utilized to enforce the local structure in depth images.
Extensive experiments on various depth super-resolution benchmark datasets show
that our method outperforms the state-of-the-art depth image super-resolution
methods with a margin.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01979</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Untrimmed Video Classification for Activity Detection: submission to
  ActivityNet Challenge</dc:title>
 <dc:creator>Singh, Gurkirt</dc:creator>
 <dc:creator>Cuzzolin, Fabio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current state-of-the-art human activity recognition is focused on the
classification of temporally trimmed videos in which only one action occurs per
frame. We propose a simple, yet effective, method for the temporal detection of
activities in temporally untrimmed videos with the help of untrimmed
classification. Firstly, our model predicts the top k labels for each untrimmed
video by analysing global video-level features. Secondly, frame-level binary
classification is combined with dynamic programming to generate the temporally
trimmed activity proposals. Finally, each proposal is assigned a label based on
the global label, and scored with the score of the temporal activity proposal
and the global score. Ultimately, we show that untrimmed video classification
models can be used as stepping stone for temporal detection.
</dc:description>
 <dc:description>Comment: 3 pages, Presented at ActivityNet Large Scale Activity Recognition
  Challenge workshop at CVPR 2016, Second position in ActivityNet Detection
  challenge 2016</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01981</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nesterov's Accelerated Gradient and Momentum as approximations to
  Regularised Update Descent</dc:title>
 <dc:creator>Botev, Aleksandar</dc:creator>
 <dc:creator>Lever, Guy</dc:creator>
 <dc:creator>Barber, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a unifying framework for adapting the update direction in
gradient-based iterative optimization methods. As natural special cases we
re-derive classical momentum and Nesterov's accelerated gradient method,
lending a new intuitive interpretation to the latter algorithm. We show that a
new algorithm, which we term Regularised Gradient Descent, can converge more
quickly than either Nesterov's algorithm or the classical momentum algorithm.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01983</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronization Detection in Networks of Coupled Oscillators for Pattern
  Recognition</dc:title>
 <dc:creator>Vodenicarevic, Damir</dc:creator>
 <dc:creator>Locatelli, Nicolas</dc:creator>
 <dc:creator>Grollier, Julie</dc:creator>
 <dc:creator>Querlioz, Damien</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>I.5.5</dc:subject>
 <dc:subject>B.8.1</dc:subject>
 <dc:description>  Coupled oscillator-based networks are an attractive approach for implementing
hardware neural networks based on emerging nanotechnologies. However, the
readout of the state of a coupled oscillator network is a difficult challenge
in hardware implementations, as it necessitates complex signal processing to
evaluate the degree of synchronization between oscillators, possibly more
complicated than the coupled oscillator network itself. In this work, we focus
on a coupled oscillator network particularly adapted to emerging technologies,
and evaluate two schemes for reading synchronization patterns that can be
readily implemented with basic CMOS circuits. Through simulation of a simple
generic coupled oscillator network, we compare the operation of these readout
techniques with a previously proposed full statistics evaluation scheme. Our
approaches provide results nearly identical to the mathematical method, but
also show better resilience to moderate noise, which is a major concern for
hardware implementations. These results open the door to widespread realization
of hardware coupled oscillator-based neural systems.
</dc:description>
 <dc:description>Comment: Accepted to 2016 IEEE World Congress on Computational Intelligence 8
  pages, 8 figures</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01989</identifier>
 <datestamp>2016-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demand-Flow of Agents with Gross-Substitute Valuations</dc:title>
 <dc:creator>Segal-Halevi, Erel</dc:creator>
 <dc:creator>Hassidim, Avinatan</dc:creator>
 <dc:creator>Aumann, Yonatan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the class of valuations on indivisible items called
gross-substitute (GS). This class was introduced by Kelso and Crawford (1982)
and is widely used in studies of markets with indivisibilities. GS is a
condition on the demand-flow in a specific scenario: some items become more
expensive while other items retain their price. We prove that GS implies a much
stronger condition, describing the demand-flow in the general scenario in which
all prices may change. We prove that the demand of GS agents always flows
(weakly) downwards, i.e, from items with higher price-increase to items with
lower price-increase. We show that this property is equivalent to GS and is not
true when there are complementarities.
</dc:description>
 <dc:description>Comment: 7 pages. Improved examples and added missing proofs</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01989</dc:identifier>
 <dc:identifier>Operations Research Letters 44 (2016), pp. 757-760</dc:identifier>
 <dc:identifier>doi:10.1016/j.orl.2016.09.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01990</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Maturity Model for Public Administration as Open Translation Data
  Providers</dc:title>
 <dc:creator>Bel, N&#xfa;ria</dc:creator>
 <dc:creator>Forcada, Mikel L.</dc:creator>
 <dc:creator>G&#xf3;mez-P&#xe9;rez, Asunci&#xf3;n</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Any public administration that produces translation data can be a provider of
useful reusable data to meet its own translation needs and the ones of other
public organizations and private companies that work with texts of the same
domain. These data can also be crucial to produce domain-tuned Machine
Translation systems. The organization's management of the translation process,
the characteristics of the archives of the generated resources and of the
infrastructure available to support them determine the efficiency and the
effectiveness with which the materials produced can be converted into reusable
data. However, it is of utmost importance that the organizations themselves
first become aware of the goods they are producing and, second, adapt their
internal processes to become optimal providers. In this article, we propose a
Maturity Model to help these organizations to achieve it by identifying the
different stages of the management of translation data that determine the path
to the aforementioned goal.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01993</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Biabduction (and Related Problems) in Array Separation Logic</dc:title>
 <dc:creator>Brotherston, James</dc:creator>
 <dc:creator>Gorogiannis, Nikos</dc:creator>
 <dc:creator>Kanovich, Max</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:description>  We investigate array separation logic (ASL), a variant of symbolic-heap
separation logic in which the data structures are either pointers or arrays,
i.e., contiguous blocks of allocated memory. This logic provides a language for
compositional memory safety proofs of imperative array programs.
  We focus on the biabduction problem for this logic, which has been
established as the key to automatic specification inference at the industrial
scale. We present an NP decision procedure for biabduction in ASL that produces
solutions of reasonable quality, and we also show that the problem of finding a
consistent solution is NP-hard.
  Along the way, we study satisfiability and entailment in our logic, giving
decision procedures and complexity bounds for both problems. We show
satisfiability to be NP-complete, and entailment to be decidable with high
complexity. The somewhat surprising fact that biabduction is much simpler than
entailment is explained by the fact that, as we show, the element of choice
over biabduction solutions enables us to dramatically reduce the search space.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01995</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improper signaling and symbol extensions: How far can we go with
  Gaussian P2P codebooks in the interfering MAC with TIN?</dc:title>
 <dc:creator>Kariminezhad, Ali</dc:creator>
 <dc:creator>Chaaban, Anas</dc:creator>
 <dc:creator>Sezgin, Aydin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Meeting the challenges of 5G demands better exploitation of the available
spectrum by allowing multiple parties to share resources. For instance, a
secondary unlicensed system can share resources with the cellular uplink of a
primary licensed system for an improved spectral efficiency. This induces
interference which has to be taken into account when designing such a system. A
simple yet robust strategy is treating interference as noise (TIN), which is
widely adapted in practice. It is thus important to study the capabilities and
limitations of TIN in such scenarios. In this paper, we study this scenario
modelled as Multiple Access Channel (MAC) interfered by a Point-to-Point (P2P)
channel. Here, we focus on rate maximization and power minimization problems
separately. We use improper Gaussian signaling (instead of proper) at the
transmitters to increase the design flexibility, which offers the freedom of
optimizing the transmit signal pseudo-variance in addition to its variance.
Furthermore, we allow correlation among the transmitted signals over orthogonal
resource basis (i.e., time or frequency) for the purpose of optimal signaling
design over the extended channel. We formulate the rate maximization problem as
a semidefinite program, and use semidefinite relaxation (SDR) to obtain a
near-optimal solution. Numerical optimizations show that, by improper Gaussian
signaling the achievable rates can be improved upto three times depending on
the strength of the interfering links. Furthermore, we observe significant
benefits in power consumption by improper Gaussian signaling with symbol
extensions compared to the traditional proper Gaussian signaling.
Interestingly, by minimizing sum power given the solution of the rate
maximization problem improves the energy efficiency significantly.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.01996</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Access Mechanisms for QoS Provisioning in Hardware
  Constrained Dynamic Spectrum Access</dc:title>
 <dc:creator>Vassilaras, Spyridon</dc:creator>
 <dc:creator>Alexandropoulos, George C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  One of the major challenges in Dynamic Spectrum Access (DSA) systems is to
guarantee a required level of Quality of Service (QoS) to secondary users of
the spectrum. In this paper, we propose efficient algorithms for deriving
optimal policies for the sensing / transmitting trade-off in
hardware-constrained DSA systems. Unlike previous approaches which seek to
maximize mean data rate for the secondary users, the proposed algorithms derive
policies which minimize the probability of excessive queuing delays. Large
Deviations (LD) asymptotics are used to approximate the probability of interest
and policies maximizing the associated LD exponent are proposed. Although
dynamic programming is not able to identify the optimal policy in this case,
much more efficient algorithms than exhaustive search are proposed. These
algorithms are based on specific properties of the optimal policy which are
described and proven in this paper.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, presented in IEEE SPAWC 2016</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.01996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02001</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the Workshop on FORmal methods for the quantitative
  Evaluation of Collective Adaptive SysTems</dc:title>
 <dc:creator>ter Beek, Maurice H.</dc:creator>
 <dc:creator>Loreti, Michele</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Collective Adaptive Systems (CAS) consist of a large number of spatially
distributed heterogeneous entities with decentralised control and varying
degrees of complex autonomous behaviour that may be competing for shared
resources even when collaborating to reach common goals. It is important to
carry out thorough quantitative modelling and analysis and verification of
their design to investigate all aspects of their behaviour before they are put
into operation. This requires combinations of formal methods and applied
mathematics which moreover scale to large-scale CAS. The primary goal of
FORECAST is to raise awareness in the software engineering and formal methods
communities of the particularities of CAS and the design and control problems
which they bring.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02001</dc:identifier>
 <dc:identifier>EPTCS 217, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02003</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tubelets: Unsupervised action proposals from spatiotemporal super-voxels</dc:title>
 <dc:creator>Jain, Mihir</dc:creator>
 <dc:creator>van Gemert, Jan</dc:creator>
 <dc:creator>J&#xe9;gou, Herv&#xe9;</dc:creator>
 <dc:creator>Bouthemy, Patrick</dc:creator>
 <dc:creator>Snoek, Cees G. M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper considers the problem of localizing actions in videos as a
sequences of bounding boxes. The objective is to generate action proposals that
are likely to include the action of interest, ideally achieving high recall
with few proposals. Our contributions are threefold. First, inspired by
selective search for object proposals, we introduce an approach to generate
action proposals from spatiotemporal super-voxels in an unsupervised manner, we
call them Tubelets. Second, along with the static features from individual
frames our approach advantageously exploits motion. We introduce independent
motion evidence as a feature to characterize how the action deviates from the
background and explicitly incorporate such motion information in various stages
of the proposal generation. Finally, we introduce spatiotemporal refinement of
Tubelets, for more precise localization of actions, and pruning to keep the
number of Tubelets limited. We demonstrate the suitability of our approach by
extensive experiments for action proposal quality and action localization on
three public datasets: UCF Sports, MSR-II and UCF101. For action proposal
quality, our unsupervised proposals beat all other existing approaches on the
three datasets. For action localization, we show top performance on both the
trimmed videos of UCF Sports and UCF101 as well as the untrimmed videos of
MSR-II.
</dc:description>
 <dc:description>Comment: submitted to International Journal of Computer Vision</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02005</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Working Locally Thinking Globally - Part I: Theoretical Guarantees for
  Convolutional Sparse Coding</dc:title>
 <dc:creator>Papyan, Vardan</dc:creator>
 <dc:creator>Sulam, Jeremias</dc:creator>
 <dc:creator>Elad, Michael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The celebrated sparse representation model has led to remarkable results in
various signal processing tasks in the last decade. However, despite its
initial purpose of serving as a global prior for entire signals, it has been
commonly used for modeling low dimensional patches due to the computational
constraints it entails when deployed with learned dictionaries. A way around
this problem has been proposed recently, adopting a convolutional sparse
representation model. This approach assumes that the global dictionary is a
concatenation of banded Circulant matrices. Although several works have
presented algorithmic solutions to the global pursuit problem under this new
model, very few truly-effective guarantees are known for the success of such
methods. In the first of this two-part work, we address the theoretical aspects
of the sparse convolutional model, providing the first meaningful answers to
corresponding questions of uniqueness of solutions and success of pursuit
algorithms. To this end, we generalize mathematical quantities, such as the
$\ell_0$ norm, the mutual coherence and the Spark, to their counterparts in the
convolutional setting, which intrinsically capture local measures of the global
model. In a companion paper, we extend the analysis to a noisy regime,
addressing the stability of the sparsest solutions and pursuit algorithms, and
demonstrate practical approaches for solving the global pursuit problem via
simple local processing.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02009</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Working Locally Thinking Globally - Part II: Stability and Algorithms
  for Convolutional Sparse Coding</dc:title>
 <dc:creator>Papyan, Vardan</dc:creator>
 <dc:creator>Sulam, Jeremias</dc:creator>
 <dc:creator>Elad, Michael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The convolutional sparse model has recently gained increasing attention in
the signal and image processing communities, and several methods have been
proposed for solving the pursuit problem emerging from it -- in particular its
convex relaxation, Basis Pursuit. In the first of this two-part work, we have
provided a theoretical back-bone for this model, providing guarantees for the
uniqueness of the sparsest solution and for the success of pursuit algorithms
by introducing the notion of stripe sparsity and other related measures.
Herein, we extend the analysis to a noisy regime, thereby considering signal
perturbations and model deviations. We address questions of stability of the
sparsest solutions and the success of pursuit algorithms, both greedy and
convex. Classical definitions such as the RIP are generalized to the
convolutional model, and existing notions such as the ERC are connected to our
setting. On the algorithmic side, we demonstrate how to solve the global
pursuit problem by using simple local processing, thus offering a first of its
kind bridge between global modeling of signals and their patch-based local
treatment.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02014</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computationally Efficient Deniable Communication</dc:title>
 <dc:creator>Zhang, Qiaosheng</dc:creator>
 <dc:creator>Bakshi, Mayank</dc:creator>
 <dc:creator>Jaggi, Sidharth</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we design the first computationally efficient codes for
simultaneously reliable and deniable communication over a Binary Symmetric
Channel (BSC). Our setting is as follows - a transmitter Alice wishes to
potentially reliably transmit a message to a receiver Bob, while ensuring that
the transmission taking place is deniable from eavesdropper Willie (who hears
Alice's transmission over a noisier BSC). Prior works show that Alice can
reliably and deniably transmit O(\sqrt{n}) bits over n channel uses without any
shared secret between Alice and Bob. One drawback of prior works is that the
computational complexity of the codes designed scales as 2^{\Theta(\sqrt{n})}.
In this work we provide the first computationally tractable codes with provable
guarantees on both reliability and deniability, while simultaneously achieving
the best known throughput for the problem.
</dc:description>
 <dc:description>Comment: 38 pages, 6 figures. Short version will appear in Proceedings of the
  IEEE International Symposium on Information Theory (ISIT), Barcelona, Spain,
  2016</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02014</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2016.7541696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02016</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numeric Deduction in Symbolic Computation. Application to Normalizing
  Transformations</dc:title>
 <dc:creator>Shevchenko, Ivan I.</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Algorithms of numeric (in exact arithmetic) deduction of analytical
expressions, proposed and described by Shevchenko and Vasiliev (1993), are
developed and implemented in a computer algebra code. This code is built as a
superstructure for the computer algebra package by Shevchenko and Sokolsky
(1993a) for normalization of Hamiltonian systems of ordinary differential
equations, in order that high complexity problems of normalization could be
solved. As an example, a resonant normal form of a Hamiltonian describing the
hyperboloidal precession of a dynamically symmetric satellite is derived by
means of the numeric deduction technique. The technique provides a considerable
economy, about 30 times in this particular application, in computer memory
consumption. It is naturally parallelizable. Thus the economy of memory
consumption is convertible into a gain in computation speed.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02016</dc:identifier>
 <dc:identifier>Journal of Symbolic Computation, Volume 24, Issue 1, Pages 103-111
  (1997)</dc:identifier>
 <dc:identifier>doi:10.1006/jsco.1997.0115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02018</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping Data to Ontologies with Exceptions Using Answer Set Programming</dc:title>
 <dc:creator>Lupp, Daniel P.</dc:creator>
 <dc:creator>Thorstensen, Evgenij</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In ontology-based data access, databases are connected to an ontology via
mappings from queries over the database to queries over the ontology. In this
paper, we consider mappings from relational databases to first-order
ontologies, and define an ASP-based framework for GLAV mappings with queries
over the ontology in the mapping rule bodies. We show that this type of
mappings can be used to express constraints and exceptions, as well as being a
powerful mechanism for succinctly representing OBDA mappings. We give an
algorithm for brave reasoning in this setting, and show that this problem has
either the same data complexity as ASP (NP- complete), or it is at least as
hard as the complexity of checking entailment for the ontology queries.
Furthermore, we show that for ontologies with UCQ-rewritable queries there
exists a natural reduction from mapping programs to \exists-ASP, an extension
of ASP with existential variables that itself admits a natural reduction to
ASP.
</dc:description>
 <dc:description>Comment: 8 pages, ONTOLP 2016</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02020</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Functional Complexity Framework for the Analysis of Telecommunication
  Networks</dc:title>
 <dc:creator>Dzaferagic, Merim</dc:creator>
 <dc:creator>Kaminski, Nicholas</dc:creator>
 <dc:creator>McBride, Neal</dc:creator>
 <dc:creator>Macaluso, Irene</dc:creator>
 <dc:creator>Marchetti, Nicola</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The rapid evolution of network services demands new paradigms for studying
and designing networks. In order to understand the underlying mechanisms that
provide network functions, we propose a framework which enables the functional
analysis of telecommunication networks. This framework allows us to isolate and
analyse a network function as a complex system. We propose functional
topologies to visualise the relationships between system entities and enable
the systematic study of interactions between them. We also define a complexity
metric $C_F$ (functional complexity) which quantifies the variety of structural
patterns and roles of nodes in the topology. This complexity metric provides a
wholly new approach to study the operation of telecommunication networks. We
study the relationship between $C_F$ and different graph structures by
analysing graph theory metrics in order to recognize complex organisations.
$C_F$ is equal to zero for both a full mesh topology and a disconnected
topology. We show that complexity is very high for a dense structure that shows
high integration (shorter average path length and high average clustering
coefficient). We make a connection between functional complexity, robustness
and response to changes that may appear in the system configuration. We also
make a connection between the implementation and the outcome of a network
function which correlates the characteristics of the outcome with the complex
relationships that underpin the functional structure.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:date>2017-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02024</identifier>
 <datestamp>2016-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mini-Batch Spectral Clustering</dc:title>
 <dc:creator>Han, Yufei</dc:creator>
 <dc:creator>Filippone, Maurizio</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The cost of computing the spectrum of Laplacian matrices hinders the
application of spectral clustering to large data sets. While approximations
recover computational tractability, they can potentially affect clustering
performance. This paper proposes a practical approach to learn spectral
clustering based on adaptive stochastic gradient optimization. Crucially, the
proposed approach recovers the exact spectrum of Laplacian matrices in the
limit of the iterations, and the cost of each iteration is linear in the number
of samples. Extensive experimental validation on data sets with up to half a
million samples demonstrate its scalability and its ability to outperform
state-of-the-art approximate methods to learn spectral clustering for a given
computational budget.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02028</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial neural networks and fuzzy logic for recognizing alphabet
  characters and mathematical symbols</dc:title>
 <dc:creator>Farulla, Giuseppe Air&#xf2;</dc:creator>
 <dc:creator>Armano, Tiziana</dc:creator>
 <dc:creator>Capietto, Anna</dc:creator>
 <dc:creator>Murru, Nadir</dc:creator>
 <dc:creator>Rossini, Rosaria</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Optical Character Recognition software (OCR) are important tools for
obtaining accessible texts. We propose the use of artificial neural networks
(ANN) in order to develop pattern recognition algorithms capable of recognizing
both normal texts and formulae. We present an original improvement of the
backpropagation algorithm. Moreover, we describe a novel image segmentation
algorithm that exploits fuzzy logic for separating touching characters.
</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02028</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science, Volume 9759 2016, Computers
  Helping People with Special Needs, p. 7-14</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-41264-1_1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02037</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refinement of the Equilibrium of Public Goods Games over Networks:
  Efficiency and Effort of Specialized Equilibria</dc:title>
 <dc:creator>Pandit, Parthe</dc:creator>
 <dc:creator>Kulkarni, Ankur A.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>91A43, 05C57, 91D30, 90C35</dc:subject>
 <dc:description>  Recently Bramoulle and Kranton presented a model for the provision of public
goods over a network and showed the existence of a class of Nash equilibria
called specialized equilibria wherein some agents exert maximum effort while
other agents free ride. We examine the efficiency, effort and cost of
specialized equilibria in comparison to other equilibria. Our main results show
that the welfare of a particular specialized equilibrium approaches the maximum
welfare amongst all equilibria as the concavity of the benefit function tends
to unity. For forest networks a similar result also holds as the concavity
approaches zero. Moreover, without any such concavity conditions, there exists
for any network a specialized equilibrium that requires the maximum weighted
effort amongst all equilibria. When the network is a forest, a specialized
equilibrium also incurs the minimum total cost amongst all equilibria. For
well-covered forest networks we show that all welfare maximizing equilibria are
specialized and all equilibria incur the same total cost. Thus we argue that
specialized equilibria may be considered as a refinement of the equilibrium of
the public goods game. We show several results on the structure and efficiency
of equilibria that highlight the role of dependants in the network.
</dc:description>
 <dc:description>Comment: under review with Journal of Economic Theory</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02045</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Distributed Pseudo TDMA Channel Access Protocol for
  Multi-Transmit-Receive Wireless Mesh Networks</dc:title>
 <dc:creator>Xu, Yuanhuizi</dc:creator>
 <dc:creator>Chin, Kwan-Wu</dc:creator>
 <dc:creator>Soh, Sieteng</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wireless Mesh Networks (WMNs) technology has been used in recent years for
broadband access in both cities and rural areas. A key development is to equip
routers with multiple directional antennas so that these routers can transmit
to, or receive from multiple neighbors simultaneously. The
Multi-Transmit-Receive (MTR) feature can boost network capacity significantly
if suitable scheduling policy is applied. In this paper, we propose a
distributed link scheduler called PCP-TDMA that fully utilizes the MTR
capability. In particular, it activates every link at least once within the
shortest period of time. We evaluated the performance of PCP-TDMA in various
network topologies, and compared it against a centralized algorithm called
ALGO-2, and two distributed approaches: JazzyMAC and ROMA. The results show
that PCP-TDMA achieves similar performance with the centralized algorithm in
all scenarios, and outperforms the distributed approaches significantly.
Specifically, in a fully connected network, the resulting superframe length of
PCP-TDMA is less than 1/3 and 1/2 of JazzyMAC and ROMA, respectively.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02046</identifier>
 <datestamp>2016-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MoCap-guided Data Augmentation for 3D Pose Estimation in the Wild</dc:title>
 <dc:creator>Rogez, Gr&#xe9;gory</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the problem of 3D human pose estimation in the wild. A
significant challenge is the lack of training data, i.e., 2D images of humans
annotated with 3D poses. Such data is necessary to train state-of-the-art CNN
architectures. Here, we propose a solution to generate a large set of
photorealistic synthetic images of humans with 3D pose annotations. We
introduce an image-based synthesis engine that artificially augments a dataset
of real images with 2D human pose annotations using 3D Motion Capture (MoCap)
data. Given a candidate 3D pose our algorithm selects for each joint an image
whose 2D pose locally matches the projected 3D pose. The selected images are
then combined to generate a new synthetic image by stitching local image
patches in a kinematically constrained manner. The resulting images are used to
train an end-to-end CNN for full-body 3D pose estimation. We cluster the
training data into a large number of pose classes and tackle pose estimation as
a K-way classification problem. Such an approach is viable only with large
training sets such as ours. Our method outperforms the state of the art in
terms of 3D pose estimation in controlled environments (Human3.6M) and shows
promising results for in-the-wild images (LSP). This demonstrates that CNNs
trained on artificial images generalize well to real images.
</dc:description>
 <dc:description>Comment: 9 pages, accepted to appear in NIPS 2016</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02052</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and robust mesh generation on the sphere Application to coastal
  domains</dc:title>
 <dc:creator>Remacle, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Lambrechts, Jonathan</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  This paper presents a fast an robust mesh generation procedure that is able
to generate meshes of the earth system (ocean and continent) in matters of
seconds. Our algorithm takes as input a standard shape-file i.e. geospatial
vector data format for geographic information system (GIS) software. The input
is initially coarsened in order to automatically remove unwanted channels that
are under a desired resolution. A valid non-overlapping 1D mesh is then created
on the sphere using the Euclidian coordinates system $x,y,z$. A modified
Delaunay kernel is then proposed that enables to generate meshes on the sphere
in a straightforward manner without parametrization. One of the main difficulty
in dealing with geographical data is the over-sampled nature of coastline
representations. We propose here an algorithm that automatically unrefines
coastline data. Small features are automatically removed while always keeping a
valid (non-overlapping) geometrical representation of the domain. A Delaunay
refinement procedure is subsequently applied to the domain. The refinement
scheme is also multi-threaded at a fine grain level, allowing to generate about
a million points per second on 8 threads. Examples of meshes of the Baltic sea
as well as of the global ocean are presented.
</dc:description>
 <dc:description>Comment: Submitted to the 25th international meshing round table</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02060</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Communities under Differential Privacy</dc:title>
 <dc:creator>Nguyen, Hiep H.</dc:creator>
 <dc:creator>Imine, Abdessamad</dc:creator>
 <dc:creator>Rusinowitch, Michael</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Complex networks usually expose community structure with groups of nodes
sharing many links with the other nodes in the same group and relatively few
with the nodes of the rest. This feature captures valuable information about
the organization and even the evolution of the network. Over the last decade, a
great number of algorithms for community detection have been proposed to deal
with the increasingly complex networks. However, the problem of doing this in a
private manner is rarely considered. In this paper, we solve this problem under
differential privacy, a prominent privacy concept for releasing private data.
We analyze the major challenges behind the problem and propose several schemes
to tackle them from two perspectives: input perturbation and algorithm
perturbation. We choose Louvain method as the back-end community detection for
input perturbation schemes and propose the method LouvainDP which runs Louvain
algorithm on a noisy super-graph. For algorithm perturbation, we design
ModDivisive using exponential mechanism with the modularity as the score. We
have thoroughly evaluated our techniques on real graphs of different sizes and
verified their outperformance over the state-of-the-art.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02061</identifier>
 <datestamp>2016-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing Verbs with Rich Contexts: an Evaluation on Verb Similarity</dc:title>
 <dc:creator>Chersoni, Emmanuele</dc:creator>
 <dc:creator>Santus, Enrico</dc:creator>
 <dc:creator>Lenci, Alessandro</dc:creator>
 <dc:creator>Blache, Philippe</dc:creator>
 <dc:creator>Huang, Chu-Ren</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Several studies on sentence processing suggest that the mental lexicon keeps
track of the mutual expectations between words. Current DSMs, however,
represent context words as separate features, thereby loosing important
information for word expectations, such as word interrelations. In this paper,
we present a DSM that addresses this issue by defining verb contexts as joint
syntactic dependencies. We test our representation in a verb similarity task on
two datasets, showing that joint contexts achieve performances comparable to
single dependencies or even better. Moreover, they are able to overcome the
data sparsity problem of joint feature spaces, in spite of the limited size of
our training corpus.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02062</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating the Dissemination of Social and Mobile Search in Categories
  of Information Needs Using Websites as Proxies</dc:title>
 <dc:creator>Fuchs, Christoph</dc:creator>
 <dc:creator>Nayyar, Akash</dc:creator>
 <dc:creator>Nussbaumer, Ruth</dc:creator>
 <dc:creator>Groh, Georg</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  With the increasing popularity of social means to satisfy information needs
using Social Media (e.g., Social Media Question Asking, SMQA) or Social
Information Retrieval approaches, this paper tries to identify types of
information needs which are inherently social and therefore better suited for
those techniques. We describe an experiment where prominent websites from
various content categories are used to represent their respective content area
and allow to correlate attributes of the content areas. The underlying
assumption is that successful websites for focused content areas perfectly
align with the information seekers' requirements when satisfying information
needs in the respective content areas. Based on a manually collected dataset of
URLs from websites covering a broad range of topics taken from Alexa
(http://www.alexa.com} (retrieved 2015-11-04)) (a company that publishes
statistics about web traffic), a crowdsourcing approach is employed to rate the
information needs that could get solved by the respective URLs according to
several dimensions (incl. sociality and mobility) to investigate possible
correlations with other attributes. Our results suggest that information needs
which do not require a certain formal expertise play an important role in
social information retrieval and that some content areas are better suited for
social information retrieval (e.g., Factual Knowledge &amp; News, Games, Lifestyle)
than others (e.g., Health &amp; Lifestyle).
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02071</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Selfish Creation of Robust Networks</dc:title>
 <dc:creator>Chauhan, Ankit</dc:creator>
 <dc:creator>Lenzner, Pascal</dc:creator>
 <dc:creator>Melnichenko, Anna</dc:creator>
 <dc:creator>M&#xfc;nn, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Robustness is one of the key properties of nowadays networks. However,
robustness cannot be simply enforced by design or regulation since many
important networks, most prominently the Internet, are not created and
controlled by a central authority. Instead, Internet-like networks emerge from
strategic decisions of many selfish agents. Interestingly, although lacking a
coordinating authority, such naturally grown networks are surprisingly robust
while at the same time having desirable properties like a small diameter.
  To investigate this phenomenon we present the first simple model for selfish
network creation which explicitly incorporates agents striving for a central
position in the network while at the same time protecting themselves against
random edge-failure. We show that networks in our model are diverse and we
prove the versatility of our model by adapting various properties and
techniques from the non-robust versions which we then use for establishing
bounds on the Price of Anarchy. Moreover, we analyze the computational hardness
of finding best possible strategies and investigate the game dynamics of our
model.
</dc:description>
 <dc:description>Comment: to appear at SAGT'16</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02078</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepChrome: Deep-learning for predicting gene expression from histone
  modifications</dc:title>
 <dc:creator>Singh, Ritambhara</dc:creator>
 <dc:creator>Lanchantin, Jack</dc:creator>
 <dc:creator>Robins, Gabriel</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  Motivation: Histone modifications are among the most important factors that
control gene regulation. Computational methods that predict gene expression
from histone modification signals are highly desirable for understanding their
combinatorial effects in gene regulation. This knowledge can help in developing
'epigenetic drugs' for diseases like cancer. Previous studies for quantifying
the relationship between histone modifications and gene expression levels
either failed to capture combinatorial effects or relied on multiple methods
that separate predictions and combinatorial analysis. This paper develops a
unified discriminative framework using a deep convolutional neural network to
classify gene expression using histone modification data as input. Our system,
called DeepChrome, allows automatic extraction of complex interactions among
important features. To simultaneously visualize the combinatorial interactions
among histone modifications, we propose a novel optimization-based technique
that generates feature pattern maps from the learnt deep model. This provides
an intuitive description of underlying epigenetic mechanisms that regulate
genes. Results: We show that DeepChrome outperforms state-of-the-art models
like Support Vector Machines and Random Forests for gene expression
classification task on 56 different cell-types from REMC database. The output
of our visualization technique not only validates the previous observations but
also allows novel insights about combinatorial interactions among histone
modification marks, some of which have recently been observed by experimental
studies.
</dc:description>
 <dc:description>Comment: This work will be originally published in Bioinformatics Journal
  (ECCB 2016)</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02093</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Neural Network and Time Series Modeling Based Approach to
  Forecasting the Exchange Rate in a Multivariate Framework</dc:title>
 <dc:creator>Chaudhuri, Tamal Datta</dc:creator>
 <dc:creator>Ghosh, Indranil</dc:creator>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Any discussion on exchange rate movements and forecasting should include
explanatory variables from both the current account and the capital account of
the balance of payments. In this paper, we include such factors to forecast the
value of the Indian rupee vis a vis the US Dollar. Further, factors reflecting
political instability and lack of mechanism for enforcement of contracts that
can affect both direct foreign investment and also portfolio investment, have
been incorporated. The explanatory variables chosen are the 3 month Rupee
Dollar futures exchange rate (FX4), NIFTY returns (NIFTYR), Dow Jones
Industrial Average returns (DJIAR), Hang Seng returns (HSR), DAX returns (DR),
crude oil price (COP), CBOE VIX (CV) and India VIX (IV). To forecast the
exchange rate, we have used two different classes of frameworks namely,
Artificial Neural Network (ANN) based models and Time Series Econometric
models. Multilayer Feed Forward Neural Network (MLFFNN) and Nonlinear
Autoregressive models with Exogenous Input (NARX) Neural Network are the
approaches that we have used as ANN models. Generalized Autoregressive
Conditional Heteroskedastic (GARCH) and Exponential Generalized Autoregressive
Conditional Heteroskedastic (EGARCH) techniques are the ones that we have used
as Time Series Econometric methods. Within our framework, our results indicate
that, although the two different approaches are quite efficient in forecasting
the exchange rate, MLFNN and NARX are the most efficient.
</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02093</dc:identifier>
 <dc:identifier>Journal of Insurance and Financial Management, Vol. 1, Issue 5,
  PP. 92-123, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02096</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A k-core Decomposition Framework for Graph Clustering</dc:title>
 <dc:creator>Giatsidis, Christos</dc:creator>
 <dc:creator>Malliaros, Fragkiskos D.</dc:creator>
 <dc:creator>Tziortziotis, Nikolaos</dc:creator>
 <dc:creator>Dhanjal, Charanpal</dc:creator>
 <dc:creator>Kiagias, Emmanouil</dc:creator>
 <dc:creator>Thilikos, Dimitrios M.</dc:creator>
 <dc:creator>Vazirgiannis, Michalis</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Graph clustering or community detection constitutes an important task for
investigating the internal structure of graphs, with a plethora of applications
in several domains. Traditional techniques for graph clustering, such as
spectral methods, typically suffer from high time and space complexity. In this
article, we present CoreCluster, an efficient graph clustering framework based
on the concept of graph degeneracy, that can be used along with any known graph
clustering algorithm. Our approach capitalizes on processing the graph in an
hierarchical manner provided by its core expansion sequence, an ordered
partition of the graph into different levels according to the k-core
decomposition. Such a partition provides an efficient way to process the graph
in an incremental manner that preserves its clustering structure, while making
the execution of the chosen clustering algorithm much faster due to the smaller
size of the graph's partitions onto which the algorithm operates. An
experimental analysis on a multitude of real and synthetic data demonstrates
that our approach can be applied to any clustering algorithm accelerating the
clustering process, while the quality of the clustering structure is preserved
or even improved.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02104</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Shot Visual Recognition via Bidirectional Latent Embedding</dc:title>
 <dc:creator>Wang, Qian</dc:creator>
 <dc:creator>Chen, Ke</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-shot learning for visual recognition, e.g., object and action
recognition, has recently attracted a lot of attention. However, it still
remains challenging in bridging the semantic gap between visual features and
their underlying semantics and transferring knowledge to semantic categories
unseen during learning. Unlike most of the existing zero-shot visual
recognition methods, we propose a stagewise bidirectional latent embedding
framework to two subsequent learning stages for zero-shot visual recognition.
In the bottom-up stage, a latent embedding space is first created by exploring
the topological and labeling information underlying training data of known
classes via a proper supervised subspace learning algorithm and the latent
embedding of training data are used to form landmarks that guide embedding
semantics underlying unseen classes into this learned latent space. In the
top-down stage, semantic representations of unseen-class labels in a given
label vocabulary are then embedded to the same latent space to preserve the
semantic relatedness between all different classes via our proposed
semi-supervised Sammon mapping with the guidance of landmarks. Thus, the
resultant latent embedding space allows for predicting the label of a test
instance with a simple nearest-neighbor rule. To evaluate the effectiveness of
the proposed framework, we have conducted extensive experiments on four
benchmark datasets in object and action recognition, i.e., AwA, CUB-200-2011,
UCF101 and HMDB51. The experimental results under comparative studies
demonstrate that our proposed approach yields the state-of-the-art performance
under inductive and transductive settings.
</dc:description>
 <dc:description>Comment: Technical report, School of Computer Science, The University of
  Manchester. Accepted by IJCV</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02109</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting and Understanding Law-Making with Word Vectors and an
  Ensemble Model</dc:title>
 <dc:creator>Nay, John J.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Out of nearly 70,000 bills introduced in the U.S. Congress from 2001 to 2015,
only 2,513 were enacted. We developed a machine learning approach to
forecasting the probability that any bill will become law. Starting in 2001
with the 107th Congress, we trained models on data from previous Congresses,
predicted all bills in the current Congress, and repeated until the 113th
Congress served as the test. For prediction we scored each sentence of a bill
with a language model that embeds legislative vocabulary into a
high-dimensional, semantic-laden vector space. This language representation
enables our investigation into which words increase the probability of
enactment for any topic. To test the relative importance of text and context,
we compared the text model to a context-only model that uses variables such as
whether the bill's sponsor is in the majority party. To test the effect of
changes to bills after their introduction on our ability to predict their final
outcome, we compared using the bill text and meta-data available at the time of
introduction with using the most recent data. At the time of introduction
context-only predictions outperform text-only, and with the newest data
text-only outperforms context-only. Combining text and context always performs
best. We conducted a global sensitivity analysis on the combined model to
determine important variables predicting enactment.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02109</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0176999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02133</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extreme Scaling of Supercomputing with Stranded Power: Costs and
  Capabilities</dc:title>
 <dc:creator>Yang, Fan</dc:creator>
 <dc:creator>Chien, Andrew A.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Power consumption (supply, heat, cost) and associated carbon emissions
(environmental impact) are increasingly critical challenges in scaling
supercomputing to Exascale and beyond. We proposes to exploit stranded power,
renewable energy that has no value to the power grid, for scaling
supercomputers, Zero-Carbon Cloud (ZCCloud), and showing that stranded power
can be employed effectively to expand computing [1]. We build on those results
with a new analysis of stranded power, characterizing temporal, geographic, and
interval properties. We simulate production supercomputing workloads and model
datacenter total-cost-of-ownership (TCO), assessing the costs and capabilities
of stranded-power based supercomputing. Results show that the ZCCloud approach
is cost-effective today in regions with high cost power. The ZCCloud approach
reduces TCO by 21-45%, and improves cost-effectiveness up to 34%. We study many
scenarios. With higher power price, cheaper computing hardware and higher
system power density, benefits rise to 55%, 97% and 116% respectively. Finally,
we study future extreme-scale systems, showing that beyond terascale, projected
power requirements in excess of 100MW make ZCCloud up to 45% lower cost, for a
fixed budget, increase peak PFLOPS achievable by 80%.
</dc:description>
 <dc:description>Comment: 12 pages, 22 figures</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02135</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding binomials in polynomial ideals</dc:title>
 <dc:creator>Jensen, Anders</dc:creator>
 <dc:creator>Kahle, Thomas</dc:creator>
 <dc:creator>Katth&#xe4;n, Lukas</dc:creator>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>68W99 (Primary), 11R04, 11Y16, 11Y40, 13P05, 13P99, 14T05, 68W30
  (Secondary)</dc:subject>
 <dc:description>  We describe an algorithm which finds binomials in a given ideal
$I\subset\mathbb{Q}[x_1,\dots,x_n]$ and in particular decides whether binomials
exist in $I$ at all. Binomials in polynomial ideals can be well hidden. For
example, the lowest degree of a binomial cannot be bounded as a function of the
number of indeterminates, the degree of the generators, or the
Castelnuovo--Mumford regularity. We approach the detection problem by reduction
to the Artinian case using tropical geometry. The Artinian case is solved with
algorithms from computational number theory.
</dc:description>
 <dc:description>Comment: 11 pages, v2: final version, to appear in Res. Math. Sci</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02137</identifier>
 <datestamp>2017-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental Parameters of Main-Sequence Stars in an Instant with Machine
  Learning</dc:title>
 <dc:creator>Bellinger, Earl P.</dc:creator>
 <dc:creator>Angelou, George C.</dc:creator>
 <dc:creator>Hekker, Saskia</dc:creator>
 <dc:creator>Basu, Sarbani</dc:creator>
 <dc:creator>Ball, Warrick</dc:creator>
 <dc:creator>Guggenberger, Elisabeth</dc:creator>
 <dc:subject>Astrophysics - Solar and Stellar Astrophysics</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Owing to the remarkable photometric precision of space observatories like
Kepler, stellar and planetary systems beyond our own are now being
characterized en masse for the first time. These characterizations are pivotal
for endeavors such as searching for Earth-like planets and solar twins,
understanding the mechanisms that govern stellar evolution, and tracing the
dynamics of our Galaxy. The volume of data that is becoming available, however,
brings with it the need to process this information accurately and rapidly.
While existing methods can constrain fundamental stellar parameters such as
ages, masses, and radii from these observations, they require substantial
computational efforts to do so.
  We develop a method based on machine learning for rapidly estimating
fundamental parameters of main-sequence solar-like stars from classical and
asteroseismic observations. We first demonstrate this method on a
hare-and-hound exercise and then apply it to the Sun, 16 Cyg A &amp; B, and 34
planet-hosting candidates that have been observed by the Kepler spacecraft. We
find that our estimates and their associated uncertainties are comparable to
the results of other methods, but with the additional benefit of being able to
explore many more stellar parameters while using much less computation time. We
furthermore use this method to present evidence for an empirical diffusion-mass
relation. Our method is open source and freely available for the community to
use.
  The source code for all analyses and for all figures appearing in this
manuscript can be found electronically at
https://github.com/earlbellinger/asteroseismology
</dc:description>
 <dc:description>Comment: 26 pages, 18 figures, accepted for publication in ApJ</dc:description>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02137</dc:identifier>
 <dc:identifier>doi:10.3847/0004-637X/830/1/31</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02168</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Boolean Gates in Slime Mould</dc:title>
 <dc:creator>Harding, Simon</dc:creator>
 <dc:creator>Koutnik, Jan</dc:creator>
 <dc:creator>Greff, Klaus</dc:creator>
 <dc:creator>Schmidhuber, Jurgen</dc:creator>
 <dc:creator>Adamatzky, Andy</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Slime mould of Physarum polycephalum is a large cell exhibiting rich spatial
non-linear electrical characteristics. We exploit the electrical properties of
the slime mould to implement logic gates using a flexible hardware platform
designed for investigating the electrical properties of a substrate (MECOBO).
We apply arbitrary electrical signals to `configure' the slime mould, i.e.
change shape of its body and, measure the slime mould's electrical response. We
show that it is possible to find configurations that allow the Physarum to act
as any 2-input Boolean gate. The occurrence frequency of the gates discovered
in the slime was analysed and compared to complexity hierarchies of logical
gates obtained in other unconventional materials. The search for gates was
performed by both sweeping across configurations in the real material as well
as training a neural network-based model and searching the gates therein using
gradient descent.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02171</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Argumentation Models for Cyber Attribution</dc:title>
 <dc:creator>Nunes, Eric</dc:creator>
 <dc:creator>Shakarian, Paulo</dc:creator>
 <dc:creator>Simari, Gerardo I.</dc:creator>
 <dc:creator>Ruef, Andrew</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A major challenge in cyber-threat analysis is combining information from
different sources to find the person or the group responsible for the
cyber-attack. It is one of the most important technical and policy challenges
in cyber-security. The lack of ground truth for an individual responsible for
an attack has limited previous studies. In this paper, we take a first step
towards overcoming this limitation by building a dataset from the
capture-the-flag event held at DEFCON, and propose an argumentation model based
on a formal reasoning framework called DeLP (Defeasible Logic Programming)
designed to aid an analyst in attributing a cyber-attack. We build models from
latent variables to reduce the search space of culprits (attackers), and show
that this reduction significantly improves the performance of
classification-based approaches from 37% to 62% in identifying the attacker.
</dc:description>
 <dc:description>Comment: 8 pages paper to be presented at International Symposium on
  Foundations of Open Source Intelligence and Security Informatics (FOSINT-SI)
  2016 In conjunction with ASONAM 2016 San Francisco, CA, USA, August 19-20,
  2016</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02173</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single-Channel Multi-Speaker Separation using Deep Clustering</dc:title>
 <dc:creator>Isik, Yusuf</dc:creator>
 <dc:creator>Roux, Jonathan Le</dc:creator>
 <dc:creator>Chen, Zhuo</dc:creator>
 <dc:creator>Watanabe, Shinji</dc:creator>
 <dc:creator>Hershey, John R.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep clustering is a recently introduced deep learning architecture that uses
discriminatively trained embeddings as the basis for clustering. It was
recently applied to spectrogram segmentation, resulting in impressive results
on speaker-independent multi-speaker separation. In this paper we extend the
baseline system with an end-to-end signal approximation objective that greatly
improves performance on a challenging speech separation. We first significantly
improve upon the baseline system performance by incorporating better
regularization, larger temporal context, and a deeper architecture, culminating
in an overall improvement in signal to distortion ratio (SDR) of 10.3 dB
compared to the baseline of 6.0 dB for two-speaker separation, as well as a 7.1
dB SDR improvement for three-speaker separation. We then extend the model to
incorporate an enhancement layer to refine the signal estimates, and perform
end-to-end training through both the clustering and enhancement stages to
maximize signal fidelity. We evaluate the results using automatic speech
recognition. The new signal approximation objective, combined with end-to-end
training, produces unprecedented performance, reducing the word error rate
(WER) from 89.1% down to 30.8%. This represents a major advancement towards
solving the cocktail party problem.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02174</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward a Robust Crowd-labeling Framework using Expert Evaluation and
  Pairwise Comparison</dc:title>
 <dc:creator>Khattak, Faiza Khan</dc:creator>
 <dc:creator>Salleb-Aouissi, Ansaf</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Crowd-labeling emerged from the need to label large-scale and complex data, a
tedious, expensive, and time-consuming task. One of the main challenges in the
crowd-labeling task is to control for or determine in advance the proportion of
low-quality/malicious labelers. If that proportion grows too high, there is
often a phase transition leading to a steep, non-linear drop in labeling
accuracy as noted by Karger et al. [2014]. To address these challenges, we
propose a new framework called Expert Label Injected Crowd Estimation (ELICE)
and extend it to different versions and variants that delay phase transition
leading to a better labeling accuracy. ELICE automatically combines and boosts
bulk crowd labels supported by labels from experts for limited number of
instances from the dataset. The expert-labels help to estimate the individual
ability of crowd labelers and difficulty of each instance, both of which are
used to aggregate the labels. Empirical evaluation shows the superiority of
ELICE as compared to other state-of-the-art methods. We also derive a lower
bound on the number of expert-labeled instances needed to estimate the crowd
ability and dataset difficulty as well as to get better quality labels.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02177</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Deep Learning to the Newsvendor Problem</dc:title>
 <dc:creator>Oroojlooyjadid, Afshin</dc:creator>
 <dc:creator>Snyder, Lawrence</dc:creator>
 <dc:creator>Tak&#xe1;&#x10d;, Martin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The newsvendor problem is one of the most basic and widely applied inventory
models. There are numerous extensions of this problem. One important extension
is the multi-item newsvendor problem, in which the demand of each item may be
correlated with that of other items. If the joint probability distribution of
the demand is known, the problem can be solved analytically. However,
approximating the probability distribution is not easy and is prone to error;
therefore, the resulting solution to the newsvendor problem may be not optimal.
To address this issue, we propose an algorithm based on deep learning that
optimizes the order quantities for all products based on features of the demand
data. Our algorithm integrates the forecasting and inventory-optimization
steps, rather than solving them separately, as is typically done, and does not
require knowledge of the probability distributions of the demand. Numerical
experiments on real-world data suggest that our algorithm outperforms other
approaches, including data-driven and machine learning approaches, especially
for demands with high volatility.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02179</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Cooperation of a Full-Duplex Relay in Random Access
  Networks</dc:title>
 <dc:creator>Avgouleas, Ioannis</dc:creator>
 <dc:creator>Pappas, Nikolaos</dc:creator>
 <dc:creator>Yuan, Di</dc:creator>
 <dc:creator>Angelakis, Vangelis</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we analyze the probabilistic cooperation of a full-duplex relay
in a multiuser random-access network. The relay is equipped with on/off modes
for the receiver and the transmitter independently. These modes are modeled as
probabilities by which the receiver and the transmitter are activated. We
provide analytical expressions for the performance of the relay queue, such as
arrival and service rates, stability conditions, and the average queue size. We
optimize the relay's operation setup to maximize the network-wide throughput
while, simultaneously, we keep the relay's queue stable and minimize the
consumed energy. Furthermore, we study the effect of the SINR threshold and the
self-interference (SI) coefficient on the per-user and network-wide throughput.
For low SINR threshold, we show under which circumstances it is beneficial to
switch off the relay completely, or switch off the relay's receiver only.
</dc:description>
 <dc:description>Comment: Submitted for journal publication</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02184</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing the Sum of Radii of Disjoint Balls or Disks</dc:title>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Finding nonoverlapping balls with given centers in any metric space,
maximizing the sum of radii of the balls, can be expressed as a linear program.
Its dual linear program expresses the problem of finding a minimum-weight set
of cycles (allowing 2-cycles) covering all vertices in a complete geometric
graph. For points in a Euclidean space of any finite dimension~$d$, with any
convex distance function on this space, this graph can be replaced by a sparse
subgraph obeying a separator theorem. This graph structure leads to an
algorithm for finding the optimum set of balls in time $O(n^{2-1/d})$,
improving the $O(n^3)$ time of a naive cycle cover algorithm. As a subroutine,
we provide an algorithm for weighted bipartite matching in graphs with
separators, which speeds up the best previous algorithm for this problem on
planar bipartite graphs from $O(n^{3/2}\log n)$ to $O(n^{3/2})$ time. We also
show how to constrain the balls to all have radius at least a given threshold
value, and how to apply our radius-sum optimization algorithms to the problem
of embedding a finite metric space into a star metric minimizing the average
distance to the hub.
</dc:description>
 <dc:description>Comment: 20 pages, 11 figures. A preliminary version of this paper appeared at
  the 28th Canadian Conference on Computational Geometry, Vancouver, 2016</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02184</dc:identifier>
 <dc:identifier>J. Computational Geometry 8 (1): 316-339, 2017</dc:identifier>
 <dc:identifier>doi:10.20382/jocg.v8i1a12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02189</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Models of the Chisholm set</dc:title>
 <dc:creator>Kjos-Hanssen, Bj&#xf8;rn</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  We give a counter-example showing that Carmo and Jones' condition 5(e) may
conflict with other conditions on the models in their paper \emph{A new
approach to contrary-to-duty obligations}.
</dc:description>
 <dc:description>Comment: Paper for Filosofi hovedfag spesialomr{\aa}de 1 exam, University of
  Oslo, Fall 1996. First cited in Carmo and Jones, Deontic logic and
  contrary-to-duties, Handbook of Philosophical Logic, 2002, footnote 28</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02192</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Authorization in Vanadium</dc:title>
 <dc:creator>Erbsen, Andres</dc:creator>
 <dc:creator>Shankar, Asim</dc:creator>
 <dc:creator>Taly, Ankur</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this tutorial, we present an authorization model for distributed systems
that operate with limited internet connectivity. Reliable internet access
remains a luxury for a majority of the world's population. Even for those who
can afford it, a dependence on internet connectivity may lead to sub-optimal
user experiences. With a focus on decentralized deployment, we present an
authorization model that is suitable for scenarios where devices right next to
each other (such as a sensor or a friend's phone) should be able to communicate
securely in a peer-to-peer manner. The model has been deployed as part of an
open-source distributed application framework called Vanadium. As part of this
tutorial, we survey some of the key ideas and techniques used in distributed
authorization, and explain how they are combined in the design of our model.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02196</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persistent Homology on Grassmann Manifolds for Analysis of Hyperspectral
  Movies</dc:title>
 <dc:creator>Chepushtanova, Sofya</dc:creator>
 <dc:creator>Kirby, Michael</dc:creator>
 <dc:creator>Peterson, Chris</dc:creator>
 <dc:creator>Ziegelmeier, Lori</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:description>  The existence of characteristic structure, or shape, in complex data sets has
been recognized as increasingly important for mathematical data analysis. This
realization has motivated the development of new tools such as persistent
homology for exploring topological invariants, or features, in large data sets.
In this paper we apply persistent homology to the characterization of gas
plumes in time dependent sequences of hyperspectral cubes, i.e. the analysis of
4-way arrays. We investigate hyperspectral movies of Long-Wavelength Infrared
data monitoring an experimental release of chemical simulant into the air. Our
approach models regions of interest within the hyperspectral data cubes as
points on the real Grassmann manifold $G(k, n)$ (whose points parameterize the
$k$-dimensional subspaces of $\mathbb{R}^n$), contrasting our approach with the
more standard framework in Euclidean space. An advantage of this approach is
that it allows a sequence of time slices in a hyperspectral movie to be
collapsed to a sequence of points in such a way that some of the key structure
within and between the slices is encoded by the points on the Grassmann
manifold. This motivates the search for topological features, associated with
the evolution of the frames of a hyperspectral movie, within the corresponding
points on the Grassmann manifold. The proposed mathematical model affords the
processing of large data sets while retaining valuable discriminatory
information. In this paper, we discuss how embedding our data in the Grassmann
manifold, together with topological data analysis, captures dynamical events
that occur as the chemical plume is released and evolves.
</dc:description>
 <dc:description>Comment: version 2: typos correction</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02196</dc:identifier>
 <dc:identifier>Computational Topology in Image Context, Volume 9667 of the series
  Lecture Notes in Computer Science, pp. 228-239, June 2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-39441-1_21</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02200</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sapo: Reachability Computation and Parameter Synthesis of Polynomial
  Dynamical Systems</dc:title>
 <dc:creator>Dreossi, Tommaso</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Sapo is a C++ tool for the formal analysis of polynomial dynamical systems.
Its main features are: 1) Reachability computation, i.e., the calculation of
the set of states reachable from a set of initial conditions, and 2) Parameter
synthesis, i.e., the refinement of a set of parameters so that the system
satisfies a given specification. Sapo can represent reachable sets as unions of
boxes, parallelotopes, or parallelotope bundles (symbolic representation of
polytopes). Sets of parameters are represented with polytopes while
specifications are formalized as Signal Temporal Logic (STL) formulas.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02204</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi Channel-Kernel Canonical Correlation Analysis for Cross-View
  Person Re-Identification</dc:title>
 <dc:creator>Lisanti, Giuseppe</dc:creator>
 <dc:creator>Karaman, Svebor</dc:creator>
 <dc:creator>Masi, Iacopo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we introduce a method to overcome one of the main challenges of
person re-identification in multi-camera networks, namely cross-view appearance
changes. The proposed solution addresses the extreme variability of person
appearance in different camera views by exploiting multiple feature
representations. For each feature, Kernel Canonical Correlation Analysis (KCCA)
with different kernels is exploited to learn several projection spaces in which
the appearance correlation between samples of the same person observed from
different cameras is maximized. An iterative logistic regression is finally
used to select and weigh the contributions of each feature projections and
perform the matching between the two views. Experimental evaluation shows that
the proposed solution obtains comparable performance on VIPeR and PRID 450s
datasets and improves on PRID and CUHK01 datasets with respect to the state of
the art.
</dc:description>
 <dc:description>Comment: The latest/updated version of the manuscript with more experiments
  can be found at https://doi.org/10.1145/3038916. Please cite the paper using
  https://doi.org/10.1145/3038916</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:date>2017-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02204</dc:identifier>
 <dc:identifier>ACM Transactions on Multimedia Computing, Communications, and
  Applications (TOMM), Volume 13 Issue 2, March 2017</dc:identifier>
 <dc:identifier>doi:10.1145/3038916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02214</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large Scale GPU Accelerated PPMLR-MHD Simulations for Space Weather
  Forecast</dc:title>
 <dc:creator>Guo, Xiangyu</dc:creator>
 <dc:creator>Tang, Binbin</dc:creator>
 <dc:creator>Tao, Jian</dc:creator>
 <dc:creator>Huang, Zhaohui</dc:creator>
 <dc:creator>Du, Zhihui</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  PPMLR-MHD is a new magnetohydrodynamics (MHD) model used to simulate the
interactions of the solar wind with the magnetosphere, which has been proved to
be the key element of the space weather cause-and-effect chain process from the
Sun to Earth. Compared to existing MHD methods, PPMLR-MHD achieves the
advantage of high order spatial accuracy and low numerical dissipation.
However, the accuracy comes at a cost. On one hand, this method requires more
intensive computation. On the other hand, more boundary data is subject to be
transferred during the process of simulation.s In this work, we present a
parallel hybrid solution of the PPMLR-MHD model implemented using the computing
capabilities of both CPUs and GPUs. We demonstrate that our optimized
implementation alleviates the data transfer overhead by using GPU Direct
technology and can scale up to 151 processes and achieve significant
performance gains by distributing the workload among the CPUs and GPUs on Titan
at Oak Ridge National Laboratory. The performance results show that our
implementation is fast enough to carry out highly accurate MHD simulations in
real time.
</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02214</dc:identifier>
 <dc:identifier>ccgrid 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02218</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A polynomial time algorithm to compute quantum invariants of 3-manifolds
  with bounded first Betti number</dc:title>
 <dc:creator>Maria, Cl&#xe9;ment</dc:creator>
 <dc:creator>Spreer, Jonathan</dc:creator>
 <dc:subject>Mathematics - Geometric Topology</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>57M27, 57Q15, 68Q25</dc:subject>
 <dc:description>  In this article, we introduce a fixed parameter tractable algorithm for
computing the Turaev-Viro invariants TV(4,q), using the dimension of the first
homology group of the manifold as parameter.
  This is, to our knowledge, the first parameterised algorithm in computational
3-manifold topology using a topological parameter. The computation of TV(4,q)
is known to be #P-hard in general; using a topological parameter provides an
algorithm polynomial in the size of the input triangulation for the extremely
large family of 3-manifolds with first homology group of bounded rank.
  Our algorithm is easy to implement and running times are comparable with
running times to compute integral homology groups for standard libraries of
triangulated 3-manifolds. The invariants we can compute this way are powerful:
in combination with integral homology and using standard data sets we are able
to roughly double the pairs of 3-manifolds we can distinguish.
  We hope this qualifies TV(4,q) to be added to the short list of standard
properties (such as orientability, connectedness, Betti numbers, etc.) that can
be computed ad-hoc when first investigating an unknown triangulation.
</dc:description>
 <dc:description>Comment: 14 pages, 3 figures</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02225</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Information Flow Analysis for Programs with Arrays</dc:title>
 <dc:creator>Barany, Gerg&#xf6;</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  Information flow analysis checks whether certain pieces of (confidential)
data may affect the results of computations in unwanted ways and thus leak
information. Dynamic information flow analysis adds instrumentation code to the
target software to track flows at run time and raise alarms if a flow policy is
violated; hybrid analyses combine this with preliminary static analysis.
  Using a subset of C as the target language, we extend previous work on hybrid
information flow analysis that handled pointers to scalars. Our extended
formulation handles arrays, pointers to array elements, and pointer arithmetic.
Information flow through arrays of pointers is tracked precisely while arrays
of non-pointer types are summarized efficiently.
  A prototype of our approach is implemented using the Frama-C program analysis
and transformation framework. Work on a full machine-checked proof of the
correctness of our approach using Isabelle/HOL is well underway; we present the
existing parts and sketch the rest of the correctness argument.
</dc:description>
 <dc:description>Comment: In Proceedings VPT 2016, arXiv:1607.01835</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02225</dc:identifier>
 <dc:identifier>EPTCS 216, 2016, pp. 5-23</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.216.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02226</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Renaming Global Variables in C Mechanically Proved Correct</dc:title>
 <dc:creator>Cohen, Julien</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Most integrated development environments are shipped with refactoring tools.
However, their refactoring operations are often known to be unreliable. As a
consequence, developers have to test their code after applying an automatic
refactoring. In this article, we consider a refactoring operation (renaming of
global variables in C), and we prove that its core implementation preserves the
set of possible behaviors of transformed programs. That proof of correctness
relies on the operational semantics of C provided by CompCert C in Coq.
</dc:description>
 <dc:description>Comment: In Proceedings VPT 2016, arXiv:1607.01835</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02226</dc:identifier>
 <dc:identifier>EPTCS 216, 2016, pp. 50-64</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.216.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02227</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Counterexamples for Model Checking by Transformation</dc:title>
 <dc:creator>Hamilton, G. W.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Counterexamples explain why a desired temporal logic property fails to hold.
The generation of counterexamples is considered to be one of the primary
advantages of model checking as a verification technique. Furthermore, when
model checking does succeed in verifying a property, there is typically no
independently checkable witness that can be used as evidence for the verified
property. Previously, we have shown how program transformation techniques can
be used for the verification of both safety and liveness properties of reactive
systems. However, no counterexamples or witnesses were generated using the
described techniques. In this paper, we address this issue. In particular, we
show how the program transformation technique distillation can be used to
facilitate the construction of counterexamples and witnesses for temporal
properties of reactive systems. Example systems which are intended to model
mutual exclusion are analysed using these techniques with respect to both
safety (mutual exclusion) and liveness (non-starvation), with counterexamples
being generated for those properties which do not hold.
</dc:description>
 <dc:description>Comment: In Proceedings VPT 2016, arXiv:1607.01835. arXiv admin note:
  substantial text overlap with arXiv:1512.03860</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02227</dc:identifier>
 <dc:identifier>EPTCS 216, 2016, pp. 65-82</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.216.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02228</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Trustworthy Refactoring in Erlang</dc:title>
 <dc:creator>Horp&#xe1;csi, D&#xe1;niel</dc:creator>
 <dc:creator>K&#x151;szegi, Judit</dc:creator>
 <dc:creator>Thompson, Simon</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Tool-assisted refactoring transformations must be trustworthy if programmers
are to be confident in applying them on arbitrarily extensive and complex code
in order to improve style or efficiency. We propose a simple, high-level but
rigorous, notation for defining refactoring transformations in Erlang, and show
that this notation provides an extensible, verifiable and executable
specification language for refactoring. To demonstrate the applicability of our
approach, we show how to define and verify a number of example refactorings in
the system.
</dc:description>
 <dc:description>Comment: In Proceedings VPT 2016, arXiv:1607.01835</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02228</dc:identifier>
 <dc:identifier>EPTCS 216, 2016, pp. 83-103</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.216.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02229</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Program Transformation to Identify List-Based Parallel Skeletons</dc:title>
 <dc:creator>Kannan, Venkatesh</dc:creator>
 <dc:creator>Hamilton, G. W.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  Algorithmic skeletons are used as building-blocks to ease the task of
parallel programming by abstracting the details of parallel implementation from
the developer. Most existing libraries provide implementations of skeletons
that are defined over flat data types such as lists or arrays. However,
skeleton-based parallel programming is still very challenging as it requires
intricate analysis of the underlying algorithm and often uses inefficient
intermediate data structures. Further, the algorithmic structure of a given
program may not match those of list-based skeletons. In this paper, we present
a method to automatically transform any given program to one that is defined
over a list and is more likely to contain instances of list-based skeletons.
This facilitates the parallel execution of a transformed program using existing
implementations of list-based parallel skeletons. Further, by using an existing
transformation called distillation in conjunction with our method, we produce
transformed programs that contain fewer inefficient intermediate data
structures.
</dc:description>
 <dc:description>Comment: In Proceedings VPT 2016, arXiv:1607.01835</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02229</dc:identifier>
 <dc:identifier>EPTCS 216, 2016, pp. 118-136</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.216.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02230</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Turchin's Relation for Call-by-Name Computations: A Formal Approach</dc:title>
 <dc:creator>Nepeivoda, Antonina</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Supercompilation is a program transformation technique that was first
described by V. F. Turchin in the 1970s. In supercompilation, Turchin's
relation as a similarity relation on call-stack configurations is used both for
call-by-value and call-by-name semantics to terminate unfolding of the program
being transformed. In this paper, we give a formal grammar model of
call-by-name stack behaviour. We classify the model in terms of the Chomsky
hierarchy and then formally prove that Turchin's relation can terminate all
computations generated by the model.
</dc:description>
 <dc:description>Comment: In Proceedings VPT 2016, arXiv:1607.01835</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02230</dc:identifier>
 <dc:identifier>EPTCS 216, 2016, pp. 137-159</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.216.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02231</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resiliency with Aggregate Computing: State of the Art and Roadmap</dc:title>
 <dc:creator>Viroli, Mirko</dc:creator>
 <dc:creator>Beal, Jacob</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  One of the difficulties in developing collective adaptive systems is the
challenge of simultaneously engineering both the desired resilient behaviour of
the collective and the details of its implementation on individual devices.
Aggregate computing simplifies this problem by separating these aspects into
different layers of abstraction by means of a unifying notion of computational
field and a functional computational model. We review the state of the art in
aggregate computing, discuss the various resiliency properties it supports, and
develop a roadmap of foundational problems still needing to be addressed in the
continued development of this emerging discipline.
</dc:description>
 <dc:description>Comment: In Proceedings FORECAST 2016, arXiv:1607.02001</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02231</dc:identifier>
 <dc:identifier>EPTCS 217, 2016, pp. 5-18</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.217.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02232</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formal Framework for Modeling Trust and Reputation in Collective
  Adaptive Systems</dc:title>
 <dc:creator>Aldini, Alessandro</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Trust and reputation models for distributed, collaborative systems have been
studied and applied in several domains, in order to stimulate cooperation while
preventing selfish and malicious behaviors. Nonetheless, such models have
received less attention in the process of specifying and analyzing formally the
functionalities of the systems mentioned above. The objective of this paper is
to define a process algebraic framework for the modeling of systems that use
(i) trust and reputation to govern the interactions among nodes, and (ii)
communication models characterized by a high level of adaptiveness and
flexibility. Hence, we propose a formalism for verifying, through model
checking techniques, the robustness of these systems with respect to the
typical attacks conducted against webs of trust.
</dc:description>
 <dc:description>Comment: In Proceedings FORECAST 2016, arXiv:1607.02001</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02232</dc:identifier>
 <dc:identifier>EPTCS 217, 2016, pp. 19-30</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.217.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02233</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Formal Methods for Collective Adaptive System Engineering. {Scalable
  Approximated, Spatial} Analysis Techniques. Extended Abstract</dc:title>
 <dc:creator>Latella, Diego</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this extended abstract a view on the role of Formal Methods in System
Engineering is briefly presented. Then two examples of useful analysis
techniques based on solid mathematical theories are discussed as well as the
software tools which have been built for supporting such techniques. The first
technique is Scalable Approximated Population DTMC Model-checking. The second
one is Spatial Model-checking for Closure Spaces. Both techniques have been
developed in the context of the EU funded project QUANTICOL.
</dc:description>
 <dc:description>Comment: In Proceedings FORECAST 2016, arXiv:1607.02001</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02233</dc:identifier>
 <dc:identifier>EPTCS 217, 2016, pp. 53-61</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.217.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02234</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic and Spatial Equivalences for PALOMA</dc:title>
 <dc:creator>Piho, Paul</dc:creator>
 <dc:creator>Hillston, Jane</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We concentrate our study on a recent process algebra - PALOMA - intended to
capture interactions between spatially distributed agents, for example in
collective adaptive systems. New agent-based semantic rules for deriving the
underlying continuous time Markov chain are given in terms of State to Function
Labelled Transition Systems. Furthermore we define a bisimulation with respect
to an isometric transformation of space allowing us to compare PALOMA models
with respect to their relative rather than absolute locations.
</dc:description>
 <dc:description>Comment: In Proceedings FORECAST 2016, arXiv:1607.02001</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02234</dc:identifier>
 <dc:identifier>EPTCS 217, 2016, pp. 69-80</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.217.9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02235</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Collective Adaptive Systems to Human Centric Computation and Back:
  Spatial Model Checking for Medical Imaging</dc:title>
 <dc:creator>Belmonte, Gina</dc:creator>
 <dc:creator>Ciancia, Vincenzo</dc:creator>
 <dc:creator>Latella, Diego</dc:creator>
 <dc:creator>Massink, Mieke</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>D.2.4 model checking</dc:subject>
 <dc:subject>F.4.1 modal logic</dc:subject>
 <dc:subject>J.3 medical information
  systems</dc:subject>
 <dc:description>  Recent research on formal verification for Collective Adaptive Systems (CAS)
pushed advancements in spatial and spatio-temporal model checking, and as a
side result provided novel image analysis methodologies, rooted in logical
methods for topological spaces. Medical Imaging (MI) is a field where such
technologies show potential for ground-breaking innovation. In this position
paper, we present a preliminary investigation centred on applications of
spatial model checking to MI. The focus is shifted from pure logics to a
mixture of logical, statistical and algorithmic approaches, driven by the
logical nature intrinsic to the specification of the properties of interest in
the field. As a result, novel operators are introduced, that could as well be
brought back to the setting of CAS.
</dc:description>
 <dc:description>Comment: In Proceedings FORECAST 2016, arXiv:1607.02001</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02235</dc:identifier>
 <dc:identifier>EPTCS 217, 2016, pp. 81-92</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.217.10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02238</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Quantitative Analysis on Dynamic Costs</dc:title>
 <dc:creator>Chu, Duc-Hiep</dc:creator>
 <dc:creator>Jaffar, Joxan</dc:creator>
 <dc:creator>Murali, Vijayaraghavan</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  In quantitative program analysis, values are assigned to execution traces to
represent a quality measure. Such analyses cover important applications, e.g.
resource usage. Examining all traces is well known to be intractable and
therefore traditional algorithms reason over an over-approximated set.
Typically, inaccuracy arises due to inclusion of infeasible paths in this set.
Thus path-sensitivity is one cure. However, there is another reason for the
inaccuracy: that the cost model, i.e., the way in which the analysis of each
trace is quantified, is dynamic. That is, the cost of a trace is dependent on
the context in which the trace is executed. Thus the goal of accurate analysis,
already challenged by path-sensitivity, is now further challenged by
context-sensitivity.
  In this paper, we address the problem of quantitative analysis defined over a
dynamic cost model. Our algorithm is an &quot;anytime&quot; algorithm: it generates an
answer quickly, but if the analysis resource budget allows, it progressively
produces better solutions via refinement iterations. The result of each
iteration remains sound, but importantly, must converge to an exact analysis
when given an unlimited resource budget. In order to be scalable, our algorithm
is designed to be incremental. We finally give evidence that a new level of
practicality is achieved by an evaluation on a realistic collection of
benchmarks.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02241</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overcoming Challenges in Fixed Point Training of Deep Convolutional
  Networks</dc:title>
 <dc:creator>Lin, Darryl D.</dc:creator>
 <dc:creator>Talathi, Sachin S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It is known that training deep neural networks, in particular, deep
convolutional networks, with aggressively reduced numerical precision is
challenging. The stochastic gradient descent algorithm becomes unstable in the
presence of noisy gradient updates resulting from arithmetic with limited
numeric precision. One of the well-accepted solutions facilitating the training
of low precision fixed point networks is stochastic rounding. However, to the
best of our knowledge, the source of the instability in training neural
networks with noisy gradient updates has not been well investigated. This work
is an attempt to draw a theoretical connection between low numerical precision
and training algorithm stability. In doing so, we will also propose and verify
through experiments methods that are able to improve the training performance
of deep convolutional networks in fixed point.
</dc:description>
 <dc:description>Comment: ICML2016 - Workshop on On-Device Intelligence</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02249</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Complexity Sub-band Digital Predistortion for Spurious Emission
  Suppression in Noncontiguous Spectrum Access</dc:title>
 <dc:creator>Abdelaziz, Mahmoud</dc:creator>
 <dc:creator>Anttila, Lauri</dc:creator>
 <dc:creator>Tarver, Chance</dc:creator>
 <dc:creator>Li, Kaipeng</dc:creator>
 <dc:creator>Cavallaro, Joseph R.</dc:creator>
 <dc:creator>Valkama, Mikko</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Noncontiguous transmission schemes combined with high power-efficiency
requirements pose big challenges for radio transmitter and power amplifier (PA)
design and implementation. Due to the nonlinear nature of the PA, severe
unwanted emissions can occur, which can potentially interfere with neighboring
channel signals or even desensitize the own receiver in frequency division
duplexing (FDD) transceivers. In this article, to suppress such unwanted
emissions, a low-complexity sub-band DPD solution, specifically tailored for
spectrally noncontiguous transmission schemes in low-cost devices, is proposed.
The proposed technique aims at mitigating only the selected spurious
intermodulation distortion components at the PA output, hence allowing for
substantially reduced processing complexity compared to classical linearization
solutions. Furthermore, novel decorrelation based parameter learning solutions
are also proposed and formulated, which offer reduced computing complexity in
parameter estimation as well as the ability to track time-varying features
adaptively. Comprehensive simulation and RF measurement results are provided,
using a commercial LTE-Advanced mobile PA, to evaluate and validate the
effectiveness of the proposed solution in real world scenarios. The obtained
results demonstrate that highly efficient spurious component suppression can be
obtained using the proposed solutions.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02249</dc:identifier>
 <dc:identifier>doi:10.1109/TMTT.2016.2602208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02250</identifier>
 <datestamp>2016-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus Attention-based Neural Networks for Chinese Reading
  Comprehension</dc:title>
 <dc:creator>Cui, Yiming</dc:creator>
 <dc:creator>Liu, Ting</dc:creator>
 <dc:creator>Chen, Zhipeng</dc:creator>
 <dc:creator>Wang, Shijin</dc:creator>
 <dc:creator>Hu, Guoping</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Reading comprehension has embraced a booming in recent NLP research. Several
institutes have released the Cloze-style reading comprehension data, and these
have greatly accelerated the research of machine comprehension. In this work,
we firstly present Chinese reading comprehension datasets, which consist of
People Daily news dataset and Children's Fairy Tale (CFT) dataset. Also, we
propose a consensus attention-based neural network architecture to tackle the
Cloze-style reading comprehension problem, which aims to induce a consensus
attention over every words in the query. Experimental results show that the
proposed neural network significantly outperforms the state-of-the-art
baselines in several public datasets. Furthermore, we setup a baseline for
Chinese reading comprehension task, and hopefully this would speed up the
process for future research.
</dc:description>
 <dc:description>Comment: 8+1 pages, submitted to COLING2016</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02257</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Siamese Regression Networks with Efficient mid-level Feature Extraction
  for 3D Object Pose Estimation</dc:title>
 <dc:creator>Doumanoglou, Andreas</dc:creator>
 <dc:creator>Balntas, Vassileios</dc:creator>
 <dc:creator>Kouskouridas, Rigas</dc:creator>
 <dc:creator>Kim, Tae-Kyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we tackle the problem of estimating the 3D pose of object
instances, using convolutional neural networks. State of the art methods
usually solve the challenging problem of regression in angle space indirectly,
focusing on learning discriminative features that are later fed into a separate
architecture for 3D pose estimation. In contrast, we propose an end-to-end
learning framework for directly regressing object poses by exploiting Siamese
Networks. For a given image pair, we enforce a similarity measure between the
representation of the sample images in the feature and pose space respectively,
that is shown to boost regression performance. Furthermore, we argue that our
pose-guided feature learning using our Siamese Regression Network generates
more discriminative features that outperform the state of the art. Last, our
feature learning formulation provides the ability of learning features that can
perform under severe occlusions, demonstrating high performance on our novel
hand-object dataset.
</dc:description>
 <dc:description>Comment: 9 pages, paper submitted to NIPS 2016, project page:
  http://www.iis.ee.ic.ac.uk/rkouskou/research/SRN.html</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02259</identifier>
 <datestamp>2017-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Entropy and Sufficiency</dc:title>
 <dc:creator>Harremo&#xeb;s, Peter</dc:creator>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>81P16, 94A17</dc:subject>
 <dc:description>  The notion of Bregman divergence and sufficiency will be defined on general
convex state spaces. It is demonstrated that only spectral sets can have a
Bregman divergence that satisfies a sufficiency condition. Positive elements
with trace 1 in a Jordan algebra are examples of spectral sets, and the most
important example is the set of density matrices with complex entries. It is
conjectured that information theoretic considerations lead directly to the
notion of Jordan algebra under some regularity conditions.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02259</dc:identifier>
 <dc:identifier>doi:10.3390/e19050206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02278</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diclique clustering in a directed random graph</dc:title>
 <dc:creator>Bloznelis, Mindaugas</dc:creator>
 <dc:creator>Leskel&#xe4;, Lasse</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>91D30, 60E15</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We discuss a notion of clustering for directed graphs, which describes how
likely two followers of a node are to follow a common target. The associated
network motifs, called dicliques or bi-fans, have been found to be key
structural components in various real-world networks. We introduce a two-mode
statistical network model consisting of actors and auxiliary attributes, where
an actor i decides to follow an actor j whenever i demands an attribute
supplied by j. We show that the digraph admits nontrivial clustering properties
of the aforementioned type, as well as power-law indegree and outdegree
distributions.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02279</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rates of DNA Sequence Profiles for Practical Values of Read Lengths</dc:title>
 <dc:creator>Chang, Zuling</dc:creator>
 <dc:creator>Chrisnata, Johan</dc:creator>
 <dc:creator>Ezerman, Martianus Frederic</dc:creator>
 <dc:creator>Kiah, Han Mao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A recent study by one of the authors has demonstrated the importance of
profile vectors in DNA-based data storage. We provide exact values and lower
bounds on the number of profile vectors for finite values of alphabet size $q$,
read length $\ell$, and word length $n$.Consequently, we demonstrate that for
$q\ge 2$ and $n\le q^{\ell/2-1}$, the number of profile vectors is at least
$q^{\kappa n}$ with $\kappa$ very close to one.In addition to enumeration
results, we provide a set of efficient encoding and decoding algorithms for
each of two particular families of profile vectors.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02281</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two RPG Flow-graphs for Software Watermarking using Bitonic Sequences of
  Self-inverting Permutations</dc:title>
 <dc:creator>Mpanti, Anna</dc:creator>
 <dc:creator>Nikolopoulos, Stavros D.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Software watermarking has received considerable attention and was adopted by
the software development community as a technique to prevent or discourage
software piracy and copyright infringement. A wide range of software
watermarking techniques has been proposed among which the graph-based methods
that encode watermarks as graph structures. Following up on our recently
proposed methods for encoding watermark numbers $w$ as reducible permutation
flow-graphs $F[\pi^*]$ through the use of self-inverting permutations $\pi^*$,
in this paper, we extend the types of flow-graphs available for software
watermarking by proposing two different reducible permutation flow-graphs
$F_1[\pi^*]$ and $F_2[\pi^*]$ incorporating important properties which are
derived from the bitonic subsequences composing the self-inverting permutation
$\pi^*$. We show that a self-inverting permutation $\pi^*$ can be efficiently
encoded into either $F_1[\pi^*]$ or $F_2[\pi^*]$ and also efficiently decoded
from theses graph structures. The proposed flow-graphs $F_1[\pi^*]$ and
$F_2[\pi^*]$ enrich the repository of graphs which can encode the same
watermark number $w$ and, thus, enable us to embed multiple copies of the same
watermark $w$ into an application program $P$. Moreover, the enrichment of that
repository with new flow-graphs increases our ability to select a graph
structure more similar to the structure of a given application program $P$
thereby enhancing the resilience of our codec system to attacks.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02282</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity and Approximability of Budget-Constrained Minimum Cost
  Flows</dc:title>
 <dc:creator>Holzhauser, Michael</dc:creator>
 <dc:creator>Krumke, Sven O.</dc:creator>
 <dc:creator>Thielen, Clemens</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We investigate the complexity and approximability of the budget-constrained
minimum cost flow problem, which is an extension of the traditional minimum
cost flow problem by a second kind of costs associated with each edge, whose
total value in a feasible flow is constrained by a given budget B. This problem
can, e.g., be seen as the application of the {\epsilon}-constraint method to
the bicriteria minimum cost flow problem. We show that we can solve the problem
exactly in weakly polynomial time $O(\log M \cdot MCF(m,n,C,U))$, where C, U,
and M are upper bounds on the largest absolute cost, largest capacity, and
largest absolute value of any number occuring in the input, respectively, and
MCF(m,n,C,U) denotes the complexity of finding a traditional minimum cost flow.
Moreover, we present two fully polynomial-time approximation schemes for the
problem on general graphs and one with an improved running-time for the problem
on acyclic graphs.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02284</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Network Simplex Method for the Budget-Constrained Minimum Cost Flow
  Problem</dc:title>
 <dc:creator>Holzhauser, Michael</dc:creator>
 <dc:creator>Krumke, Sven O.</dc:creator>
 <dc:creator>Thielen, Clemens</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We present a specialized network simplex algorithm for the budget-constrained
minimum cost flow problem, which is an extension of the traditional minimum
cost flow problem by a second kind of costs associated with each edge, whose
total value in a feasible flow is constrained by a given budget B. We present a
fully combinatorial description of the algorithm that is based on a novel
incorporation of two kinds of integral node potentials and three kinds of
reduced costs. We prove optimality criteria and combine two methods that are
commonly used to avoid cycling in traditional network simplex algorithms into
new techniques that are applicable to our problem. With these techniques and
our definition of the reduced costs, we are able to prove a pseudo-polynomial
running time of the overall procedure, which can be further improved by
incorporating Dantzig's pivoting rule. Moreover, we present computational
results that compare our procedure with Gurobi.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02284</dc:identifier>
 <dc:identifier>European Journal of Operational Research 259:3, pp. 864-872 (2017)</dc:identifier>
 <dc:identifier>doi:10.1016/j.ejor.2016.11.024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02290</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Central Catadioptric Cameras Pose Estimation using 3D Lines</dc:title>
 <dc:creator>Mateus, Andre</dc:creator>
 <dc:creator>Miraldo, Pedro</dc:creator>
 <dc:creator>Lima, Pedro U.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this article we purpose a novel method for planar pose estimation of
mobile robots. This method is based on an analytic solution (which we derived)
for the projection of 3D straight lines, onto the mirror of Non-Central
Catadioptric Cameras (NCCS). The resulting solution is rewritten as a function
of the rotation and translation parameters, which is then used as an error
function for a set of mirror points. Those should be the result of the
projection of a set of points incident with the respective 3D lines. The
camera's pose is given by minimizing the error function, with the associated
constraints. The method is validated by experiments both with synthetic and
real data. The latter was collected from a mobile robot equipped with a NCCS.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02291</identifier>
 <datestamp>2016-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Cellular Automata: Types, Dynamics, Non-uniformity and
  Applications</dc:title>
 <dc:creator>Bhattacharjee, Kamalika</dc:creator>
 <dc:creator>Naskar, Nazma</dc:creator>
 <dc:creator>Roy, Souvik</dc:creator>
 <dc:creator>Das, Sukanta</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  Cellular automata (CAs) are dynamic frameworks which exhibit complex global
behavior from simple local interaction and computation. Since the inception of
CA by von Neumann in $1950$s, it has attracted the attention of several
researchers over various backgrounds and fields for modeling different
physical, natural as well as real-life phenomena. Classically, CAs are uniform.
However, non-uniformity has also been introduced in update pattern, lattice
structure, neighborhood dependency and local rule. In this survey, we tour to
the various types of CAs introduced till date, the different characterization
tools, the global behaviors of CAs, like universality, reversibility, dynamics
etc. Special attention is given to non-uniformity in CAs and specially, the
non-uniform elementary CAs, which have been very useful in solving several
real-life problems.
</dc:description>
 <dc:description>Comment: 34 pages; submitted to ACM Computing Surveys</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02296</identifier>
 <datestamp>2016-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the evolution of cooperation under social pressure in multiplex
  networks</dc:title>
 <dc:creator>Pereda, Mar&#xed;a</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this work, we aim to contribute to the understanding of the human
pro-social behavior by studying the influence that a particular form of social
pressure &quot;being watched&quot; has on the evolution of cooperative behavior. We study
how cooperation emerge in multiplex complex topologies by analyzing a
particular bidirectionally-coupled dynamics on top of a two-layers multiplex
network (duplex). The coupled dynamics appears between the Prisoner's Dilemma
game in a network, and a threshold cascade model in the other. The threshold
model is intended to abstract the behavior of a network of vigilant nodes, that
impose pressure of being observed altering hence the temptation to defect of
the dilemma. Cooperation or defection in the game also affects the state of a
node of being vigilant. We analyze these processes on different duplex networks
structures and assess the influence of the topology, average degree and
correlated multiplexity, on the outcome of cooperation. Interestingly, we find
that the social pressure of vigilance may impact cooperation positively or
negatively, depending on the duplex structure, specifically the degree
correlations between layers is determinant. Our results give further
quantitative insights in the promotion of cooperation under social pressure.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02296</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.94.032314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02298</identifier>
 <datestamp>2016-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Channel Resolvability in Presence of Feedback</dc:title>
 <dc:creator>Parizi, Mani Bastani</dc:creator>
 <dc:creator>Telatar, Emre</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the problem of generating an approximately i.i.d. string at the
output of a discrete memoryless channel using a limited amount of randomness at
its input in presence of causal noiseless feedback. Feedback does not decrease
the channel resolution, the minimum entropy rate required to achieve an
accurate approximation of an i.i.d. output string. However, we show that, at
least over a binary symmetric channel, a significantly larger resolvability
exponent (the exponential decay rate of the divergence between the output
distribution and product measure), compared to the best known achievable
resolvability exponent in a system without feedback, is possible. We show that
by employing a variable-length resolvability scheme and using an average number
of coin-flips per channel use, the average divergence between the distribution
of the output sequence and product measure decays exponentially fast in the
average length of output sequence with an exponent equal to $[R-I(U;V)]^+$
where $I(U;V)$ is the mutual information developed across the channel.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures; to be presented at the 54th Annual Allerton
  Conference on Communication, Control, and Computing</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02303</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN-LTE: a Class of 1-X Pooling Convolutional Neural Networks on Label
  Tree Embeddings for Audio Scene Recognition</dc:title>
 <dc:creator>Phan, Huy</dc:creator>
 <dc:creator>Hertel, Lars</dc:creator>
 <dc:creator>Maass, Marco</dc:creator>
 <dc:creator>Koch, Philipp</dc:creator>
 <dc:creator>Mertins, Alfred</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We describe in this report our audio scene recognition system submitted to
the DCASE 2016 challenge. Firstly, given the label set of the scenes, a label
tree is automatically constructed. This category taxonomy is then used in the
feature extraction step in which an audio scene instance is represented by a
label tree embedding image. Different convolutional neural networks, which are
tailored for the task at hand, are finally learned on top of the image features
for scene recognition. Our system reaches an overall recognition accuracy of
81.2% and 83.3% and outperforms the DCASE 2016 baseline with absolute
improvements of 8.7% and 6.1% on the development and test data, respectively.
</dc:description>
 <dc:description>Comment: Task1 technical report for the DCASE2016 challenge. arXiv admin note:
  text overlap with arXiv:1606.07908</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02306</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CaR-FOREST: Joint Classification-Regression Decision Forests for
  Overlapping Audio Event Detection</dc:title>
 <dc:creator>Phan, Huy</dc:creator>
 <dc:creator>Hertel, Lars</dc:creator>
 <dc:creator>Maass, Marco</dc:creator>
 <dc:creator>Koch, Philipp</dc:creator>
 <dc:creator>Mertins, Alfred</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This report describes our submissions to Task2 and Task3 of the DCASE 2016
challenge. The systems aim at dealing with the detection of overlapping audio
events in continuous streams, where the detectors are based on random decision
forests. The proposed forests are jointly trained for classification and
regression simultaneously. Initially, the training is classification-oriented
to encourage the trees to select discriminative features from overlapping
mixtures to separate positive audio segments from the negative ones. The
regression phase is then carried out to let the positive audio segments vote
for the event onsets and offsets, and therefore model the temporal structure of
audio events. One random decision forest is specifically trained for each event
category of interest. Experimental results on the development data show that
our systems significantly outperform the baseline on the Task2 evaluation while
they are inferior to the baseline in the Task3 evaluation.
</dc:description>
 <dc:description>Comment: Task2 and Task3 technical report for the DCASE2016 challenge</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02310</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Training of Tensors for Compositional Distributional
  Semantics</dc:title>
 <dc:creator>Polajnar, Tamara</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Type-based compositional distributional semantic models present an
interesting line of research into functional representations of linguistic
meaning. One of the drawbacks of such models, however, is the lack of training
data required to train each word-type combination. In this paper we address
this by introducing training methods that share parameters between similar
words. We show that these methods enable zero-shot learning for words that have
no training data at all, as well as enabling construction of high-quality
tensors from very few training examples per word.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02317</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power-Availability-Aware Cell Association for Energy-Harvesting
  Small-Cell Base Stations</dc:title>
 <dc:creator>Parzysz, Fanny</dc:creator>
 <dc:creator>Di Renzo, Marco</dc:creator>
 <dc:creator>Verikoukis, Christos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Energy harvesting brings a key solution to the increasing energy bill and
environmental concerns but, at the same time, the network availability may be
deteriorated due to potential energy shortage. In this paper, we analyze the
performance of off-grid small-cell base stations (scBS) with finite battery
capacity and design a new power-availability-aware cell association based on
periodical broadcast of the scBS battery level. Each mobile terminal (MT)
targets its own set of available scBSs before association, i.e. the set of
scBSs that can guarantee service provided (i) the scBS battery level, (ii) the
power required to satisfy a received power constraint at each MT, given the
scBS-MT distance and the shadowing attenuation, and (iii) the estimated power
consumed to serve other MTs potentially associated to the same scBS, which is
computed using stochastic geometry tools. Next, we develop for it a tractable
performance analysis and derive closed-form expressions for the probability of
power outage and the coverage probability. By dynamically adapting to the
fluctuations of the base station battery and user power requirement, the
proposed cell association allows a more even distribution of the available
energy in the network, brings robustness against harvesting impairment and
thereby, significantly outperforms conventional strategies.
</dc:description>
 <dc:description>Comment: Under peer reviewing for IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02318</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Renewed Case for the Reduced Instruction Set Computer: Avoiding ISA
  Bloat with Macro-Op Fusion for RISC-V</dc:title>
 <dc:creator>Celio, Christopher</dc:creator>
 <dc:creator>Dabbelt, Palmer</dc:creator>
 <dc:creator>Patterson, David A.</dc:creator>
 <dc:creator>Asanovi&#x107;, Krste</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  This report makes the case that a well-designed Reduced Instruction Set
Computer (RISC) can match, and even exceed, the performance and code density of
existing commercial Complex Instruction Set Computers (CISC) while maintaining
the simplicity and cost-effectiveness that underpins the original RISC goals.
  We begin by comparing the dynamic instruction counts and dynamic instruction
bytes fetched for the popular proprietary ARMv7, ARMv8, IA-32, and x86-64
Instruction Set Architectures (ISAs) against the free and open RISC-V RV64G and
RV64GC ISAs when running the SPEC CINT2006 benchmark suite. RISC-V was designed
as a very small ISA to support a wide range of implementations, and has a less
mature compiler toolchain. However, we observe that on SPEC CINT2006 RV64G
executes on average 16% more instructions than x86-64, 3% more instructions
than IA-32, 9% more instructions than ARMv8, but 4% fewer instructions than
ARMv7.
  CISC x86 implementations break up complex instructions into smaller internal
RISC-like micro-ops, and the RV64G instruction count is within 2% of the x86-64
retired micro-op count. RV64GC, the compressed variant of RV64G, is the densest
ISA studied, fetching 8% fewer dynamic instruction bytes than x86-64. We
observed that much of the increased RISC-V instruction count is due to a small
set of common multi-instruction idioms.
  Exploiting this fact, the RV64G and RV64GC effective instruction count can be
reduced by 5.4% on average by leveraging macro-op fusion. Combining the
compressed RISC-V ISA extension with macro-op fusion provides both the densest
ISA and the fewest dynamic operations retired per program, reducing the
motivation to add more instructions to the ISA. This approach retains a single
simple ISA suitable for both low-end and high-end implementations, where
high-end implementations can boost performance through microarchitectural
techniques.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02329</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Watch This: Scalable Cost-Function Learning for Path Planning in Urban
  Environments</dc:title>
 <dc:creator>Wulfmeier, Markus</dc:creator>
 <dc:creator>Wang, Dominic Zeng</dc:creator>
 <dc:creator>Posner, Ingmar</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work, we present an approach to learn cost maps for driving in
complex urban environments from a very large number of demonstrations of
driving behaviour by human experts. The learned cost maps are constructed
directly from raw sensor measurements, bypassing the effort of manually
designing cost maps as well as features. When deploying the learned cost maps,
the trajectories generated not only replicate human-like driving behaviour but
are also demonstrably robust against systematic errors in putative robot
configuration. To achieve this we deploy a Maximum Entropy based, non-linear
IRL framework which uses Fully Convolutional Neural Networks (FCNs) to
represent the cost model underlying expert driving behaviour. Using a deep,
parametric approach enables us to scale efficiently to large datasets and
complex behaviours by being run-time independent of dataset extent during
deployment. We demonstrate the scalability and the performance of the proposed
approach on an ambitious dataset collected over the course of one year
including more than 25k demonstration trajectories extracted from over 120km of
driving around pedestrianised areas in the city of Milton Keynes, UK. We
evaluate the resulting cost representations by showing the advantages over a
carefully manually designed cost map and, in addition, demonstrate its
robustness to systematic errors by learning precise cost-maps even in the
presence of system calibration perturbations.
</dc:description>
 <dc:description>Comment: Accepted for publication in the Proceedings of the 2016 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS 2016)</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02330</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Measures of Dependence</dc:title>
 <dc:creator>Lapidoth, Amos</dc:creator>
 <dc:creator>Pfister, Christoph</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by a distributed task-encoding problem, two closely related
families of dependence measures are introduced. They are based on the R\'enyi
divergence of order $\alpha$ and the relative $\alpha$-entropy, respectively,
and both reduce to the mutual information when the parameter $\alpha$ is one.
Their properties are studied and it is shown that the first measure shares many
properties with mutual information, including the data-processing inequality.
The second measure does not satisfy the data-processing inequality, but it
appears naturally in the context of distributed task encoding.
</dc:description>
 <dc:description>Comment: 11 pages; accepted at ICSEE 2016; with additional proofs; fixed typo
  in Theorem 3</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02334</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Betweenness centrality profiles in trees</dc:title>
 <dc:creator>Fish, Benjamin</dc:creator>
 <dc:creator>Kushwaha, Rahul</dc:creator>
 <dc:creator>Turan, Gyorgy</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Betweenness centrality of a vertex in a graph measures the fraction of
shortest paths going through the vertex. This is a basic notion for determining
the importance of a vertex in a network. The k-betweenness centrality of a
vertex is defined similarly, but only considers shortest paths of length at
most k. The sequence of k-betweenness centralities for all possible values of k
forms the betweenness centrality profile of a vertex. We study properties of
betweenness centrality profiles in trees.
  We show that for scale-free random trees, for fixed k, the expectation of
k-betweenness centrality strictly decreases as the index of the vertex
increases. We also analyze worst-case properties of profiles in terms of the
distance of profiles from being monotone, and the number of times pairs of
profiles can cross. This is related to whether k-betweenness centrality, for
small values of k, may be used instead of having to consider all shortest
paths. Bounds are given that are optimal in order of magnitude. We also present
some experimental results for scale-free random trees.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02335</identifier>
 <datestamp>2017-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Mutual Information in Random Linear Estimation</dc:title>
 <dc:creator>Barbier, Jean</dc:creator>
 <dc:creator>Dia, Mohamad</dc:creator>
 <dc:creator>Macris, Nicolas</dc:creator>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  We consider the estimation of a signal from the knowledge of its noisy linear
random Gaussian projections, a problem relevant in compressed sensing, sparse
superposition codes or code division multiple access just to cite few. There
has been a number of works considering the mutual information for this problem
using the heuristic replica method from statistical physics. Here we put these
considerations on a firm rigorous basis. First, we show, using a Guerra-type
interpolation, that the replica formula yields an upper bound to the exact
mutual information. Secondly, for many relevant practical cases, we present a
converse lower bound via a method that uses spatial coupling, state evolution
analysis and the I-MMSE theorem. This yields, in particular, a single letter
formula for the mutual information and the minimal-mean-square error for random
Gaussian linear estimation of all discrete bounded signals.
</dc:description>
 <dc:description>Comment: Presented at the 54th Annual Allerton Conference on Communication,
  Control, and Computing, 2016</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02335</dc:identifier>
 <dc:identifier>2016 54th Annual Allerton Conference on Communication, Control,
  and Computing (Allerton), Pages: 625 - 632</dc:identifier>
 <dc:identifier>doi:10.1109/ALLERTON.2016.7852290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02346</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strengthening Hardness Results to 3-Connected Planar Graphs</dc:title>
 <dc:creator>Da Lozzo, Giordano</dc:creator>
 <dc:creator>Rutter, Ignaz</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In this paper we extend some classical NP-hardness results from the class of
2-connected planar graphs to subclasses of 3-connected planar graphs. The
reduction are partly based on a new graph augmentation, which may be of
independent interest.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02347</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of Realizing Facial Cycles</dc:title>
 <dc:creator>Da Lozzo, Giordano</dc:creator>
 <dc:creator>Rutter, Ignaz</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the following combinatorial problem. Given a planar graph $G=(V,E)$
and a set of simple cycles $\mathcal C$ in $G$, find a planar embedding
$\mathcal E$ of $G$ such that the number of cycles in $\mathcal C$ that bound a
face in $\mathcal E$ is maximized. We establish a tight border of tractability
for this problem in biconnected planar graphs by giving conditions under which
the problem is NP-hard and showing that relaxing any of these conditions makes
the problem polynomial-time solvable. Moreover, we give a $2$-approximation
algorithm for series-parallel graphs and a $(4+\varepsilon)$-approximation for
biconnected planar graphs.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02355</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lexical Based Semantic Orientation of Online Customer Reviews and Blogs</dc:title>
 <dc:creator>khan, Aurangzeb</dc:creator>
 <dc:creator>khan, Khairullah</dc:creator>
 <dc:creator>Ahmad, Shakeel</dc:creator>
 <dc:creator>Kundi, Fazal Masood</dc:creator>
 <dc:creator>Tareen, Irum</dc:creator>
 <dc:creator>Asghar, Muhammad Zubair</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Rapid increase in internet users along with growing power of online review
sites and social media has given birth to sentiment analysis or opinion mining,
which aims at determining what other people think and comment. Sentiments or
Opinions contain public generated content about products, services, policies
and politics. People are usually interested to seek positive and negative
opinions containing likes and dislikes, shared by users for features of
particular product or service. This paper proposed sentence-level lexical based
domain independent sentiment classification method for different types of data
such as reviews and blogs. The proposed method is based on general lexicons
i.e. WordNet, SentiWordNet and user defined lexical dictionaries for semantic
orientation. The relations and glosses of these dictionaries provide solution
to the domain portability problem. The method performs better than word and
text level corpus based machine learning methods for semantic orientation. The
results show the proposed method performs better as it shows precision of 87%
and83% at document and sentence levels respectively for online comments.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02355</dc:identifier>
 <dc:identifier>Journal of American Science 2014;10(8)
  http://www.jofamericanscience.org</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02361</identifier>
 <datestamp>2017-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Factor-Graph Approach to Algebraic Topology, With Applications to
  Kramers--Wannier Duality</dc:title>
 <dc:creator>Al-Bashabsheh, Ali</dc:creator>
 <dc:creator>Vontobel, Pascal O.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Algebraic topology studies topological spaces with the help of tools from
abstract algebra. The main focus of this paper is to show that many concepts
from algebraic topology can be conveniently expressed in terms of (normal)
factor graphs. As an application, we give an alternative proof of a classical
duality result of Kramers and Wannier, which expresses the partition sum of the
two-dimensional Ising model at a low temperature in terms of the partition sum
of the two-dimensional Ising model at a high temperature. Moreover, we discuss
analogous results for the three-dimensional Ising model and the Potts model.
</dc:description>
 <dc:date>2016-07-04</dc:date>
 <dc:date>2017-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02371</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A game theoretic approach to a peer-to-peer cloud storage model</dc:title>
 <dc:creator>Fagnani, Fabio</dc:creator>
 <dc:creator>Franci, Barbara</dc:creator>
 <dc:creator>Grasso, Ennio</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Classical cloud storage based on external data providers has been recognized
to suffer from a number of drawbacks. This is due to its inherent centralized
architecture which makes it vulnerable to external attacks, malware, technical
failures, as well to the large premium charged for business purposes. In this
paper, we propose an alternative distributed peer-to-peer cloud storage model
which is based on the observation that the users themselves often have
available storage capabilities to be offered in principle to other users. Our
set-up is that of a network of users connected through a graph, each of them
being at the same time a source of data to be stored externally and a possible
storage resource. We cast the peer-to-peer storage model to a Potential Game
and we propose an original decentralized algorithm which makes units interact,
cooperate, and store a complete back up of their data on their connected
neighbors. We present theoretical results on the algorithm as well a good
number of simulations which validate our approach.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02376</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Agent System for Groundwater Depletion Using Game Theory</dc:title>
 <dc:creator>Huang, Ying</dc:creator>
 <dc:creator>Janovsky, Pavel</dc:creator>
 <dc:creator>Das, Sanjoy</dc:creator>
 <dc:creator>Welch, Stephen M.</dc:creator>
 <dc:creator>DeLoach, Scott</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>I.6.3</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  Groundwater is one of the most vital of all common pool resources throughout
the world. More than half of groundwater is used to grow crops. This research
models groundwater depletion patterns within a multi-agent system framework.
Irrigators are modeled as agents in the multi-agent system. The irrigation
strategies adopted by the agents are investigated using game theory. A set of
five irrigators, growing three crops: corn, sorghum and wheat, have been
considered in this study. To allow groundwater flow, these agents are assumed
to be located in adjoining farm lands. Irrigators are modeled selfish agents
that strategize their irrigation patterns in order to maximize their own
utilities, i.e. the difference between the total revenue obtained from crop
sales and the costs incurred, including groundwater extraction costs. Due to
groundwater flow, and have no incentive to conserve groundwater. This leads to
unsustainable depletion of the resource under Nash equilibrium, when no
irrigator can increase its utility by unilaterally changing its strategy. All
parameters in this research are representative of Kansas. Recorded
environmental and economic data of the region, along with the DSSAT software,
have been used to obtain these futuristic projections. One of the emergent
phenomena of the simulations is the adoption of crop rotation patterns by the
irrigators to conserve groundwater. The irrigators grow corn, which is a more
profitable yet water intensive crop in one year, and in the next, conserve
water by growing sorghum instead. Another emergent outcome of this research is
the viability of LEMAs. When the irrigators are subject to LEMA-level limits on
groundwater use, there is a slight increase in the aggregate utility of the
LEMA.
</dc:description>
 <dc:description>Comment: 31 pages, MS Thesis of Ms. Ying Huang (Supervisor: S. Das; S. M.
  Welch) Corresponding author: S. Das</dc:description>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02381</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Optimal Boolean Function for Prediction under Quadratic Loss</dc:title>
 <dc:creator>Weinberger, Nir</dc:creator>
 <dc:creator>Shayevitz, Ofer</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Suppose $Y^{n}$ is obtained by observing a uniform Bernoulli random vector
$X^{n}$ through a binary symmetric channel. Courtade and Kumar asked how large
the mutual information between $Y^{n}$ and a Boolean function
$\mathsf{b}(X^{n})$ could be, and conjectured that the maximum is attained by a
dictator function. An equivalent formulation of this conjecture is that
dictator minimizes the prediction cost in a sequential prediction of $Y^{n}$
under logarithmic loss, given $\mathsf{b}(X^{n})$. In this paper, we study the
question of minimizing the sequential prediction cost under a different
(proper) loss function - the quadratic loss. In the noiseless case, we show
that majority asymptotically minimizes this prediction cost among all Boolean
functions. We further show that for weak noise, majority is better than
dictator, and that for strong noise dictator outperforms majority. We
conjecture that for quadratic loss, there is no single sequence of Boolean
functions that is simultaneously (asymptotically) optimal at all noise levels.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02383</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acoustic scene classification using convolutional neural network and
  multiple-width frequency-delta data augmentation</dc:title>
 <dc:creator>Han, Yoonchang</dc:creator>
 <dc:creator>Lee, Kyogu</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In recent years, neural network approaches have shown superior performance to
conventional hand-made features in numerous application areas. In particular,
convolutional neural networks (ConvNets) exploit spatially local correlations
across input data to improve the performance of audio processing tasks, such as
speech recognition, musical chord recognition, and onset detection. Here we
apply ConvNet to acoustic scene classification, and show that the error rate
can be further decreased by using delta features in the frequency domain. We
propose a multiple-width frequency-delta (MWFD) data augmentation method that
uses static mel-spectrogram and frequency-delta features as individual input
examples. In addition, we describe a ConvNet output aggregation method designed
for MWFD augmentation, folded mean aggregation, which combines output
probabilities of static and MWFD features from the same analysis window using
multiplication first, rather than taking an average of all output
probabilities. We describe calculation results using the DCASE 2016 challenge
dataset, which shows that ConvNet outperforms both of the baseline system with
hand-crafted features and a deep neural network approach by around 7%. The
performance was further improved (by 5.7%) using the MWFD augmentation together
with folded mean aggregation. The system exhibited a classification accuracy of
0.831 when classifying 15 acoustic scenes.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures, submitted to IEEE/ACM Transactions on Audio,
  Speech, and Language Processing on 08-July-2016</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02385</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite Length Performance of Random Slotted ALOHA Strategies</dc:title>
 <dc:creator>Dovelos, Konstantinos</dc:creator>
 <dc:creator>Toni, Laura</dc:creator>
 <dc:creator>Frossard, Pascal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multiple connected devices sharing common wireless resources might create
interference if they access the channel simultaneously. Medium access control
(MAC) protocols gener- ally regulate the access of the devices to the shared
channel to limit signal interference. In particular, irregular repetition
slotted ALOHA (IRSA) techniques can achieve high-throughput performance when
interference cancellation methods are adopted to recover from collisions. In
this work, we study the finite length performance for IRSA schemes by building
on the analogy between successive interference cancellation and iterative
belief- propagation on erasure channels. We use a novel combinatorial
derivation based on the matrix-occupancy theory to compute the error
probability and we validate our method with simulation results.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02397</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enlightening Deep Neural Networks with Knowledge of Confounding Factors</dc:title>
 <dc:creator>Zhong, Yu</dc:creator>
 <dc:creator>Ettinger, Gil</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning techniques have demonstrated significant capacity in modeling
some of the most challenging real world problems of high complexity. Despite
the popularity of deep models, we still strive to better understand the
underlying mechanism that drives their success. Motivated by observations that
neurons in trained deep nets predict attributes indirectly related to the
training tasks, we recognize that a deep network learns representations more
general than the task at hand to disentangle impacts of multiple confounding
factors governing the data, in order to isolate the effects of the concerning
factors and optimize a given objective. Consequently, we propose a general
framework to augment training of deep models with information on auxiliary
explanatory data variables, in an effort to boost this disentanglement and
train deep networks that comprehend the data interactions and distributions
more accurately, and thus improve their generalizability. We incorporate
information on prominent auxiliary explanatory factors of the data population
into existing architectures as secondary objective/loss blocks that take inputs
from hidden layers during training. Once trained, these secondary circuits can
be removed to leave a model with the same architecture as the original, but
more generalizable and discerning thanks to its comprehension of data
interactions. Since pose is one of the most dominant confounding factors for
object recognition, we apply this principle to instantiate a pose-aware deep
convolutional neural network and demonstrate that auxiliary pose information
indeed improves the classification accuracy in our experiments on SAR target
classification tasks.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02399</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Translating Bayesian Networks into Entity Relationship Models, Extended
  Version</dc:title>
 <dc:creator>Rosner, Frank</dc:creator>
 <dc:creator>Hinneburg, Alexander</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Big data analytics applications drive the convergence of data management and
machine learning. But there is no conceptual language available that is spoken
in both worlds. The main contribution of the paper is a method to translate
Bayesian networks, a main conceptual language for probabilistic graphical
models, into usable entity relationship models. The transformed representation
of a Bayesian network leaves out mathematical details about probabilistic
relationships but unfolds all information relevant for data management tasks.
As a real world example, we present the TopicExplorer system that uses Bayesian
topic models as a core component in an interactive, database-supported web
application. Last, we sketch a conceptual framework that eases machine learning
specific development tasks while building big data analytics applications.
</dc:description>
 <dc:description>Comment: This is an extended version of a short paper published in the
  Proceedings of the 35th International Conference on Conceptual Modeling, ER
  2016. In addition to a more detailed discussion of the method, this extended
  version describes a case study that applies the method as well as first ideas
  of a conceptual framework for developing big data analytics applications</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02413</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower Bounds on Active Learning for Graphical Model Selection</dc:title>
 <dc:creator>Scarlett, Jonathan</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of estimating the underlying graph associated with a
Markov random field, with the added twist that the decoding algorithm can
iteratively choose which subsets of nodes to sample based on the previous
samples, resulting in an active learning setting. Considering both Ising and
Gaussian models, we provide algorithm-independent lower bounds for
high-probability recovery within the class of degree-bounded graphs. Our main
results are minimax lower bounds for the active setting that match the best
known lower bounds for the passive setting, which in turn are known to be tight
in several cases of interest. Our analysis is based on Fano's inequality, along
with novel mutual information bounds for the active learning setting, and the
application of restricted graph ensembles. While we consider ensembles that are
similar or identical to those used in the passive setting, we require different
analysis techniques, with a key challenge being bounding a mutual information
quantity associated with observed subsets of nodes, as opposed to full
observations.
</dc:description>
 <dc:description>Comment: Accepted to AISTATS 2017</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2017-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02419</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Divisive-agglomerative algorithm and complexity of automatic
  classification problems</dc:title>
 <dc:creator>Rubchinsky, Alexander</dc:creator>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>62H30</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:description>  An algorithm of solution of the Automatic Classification (AC for brevity)
problem is set forth in the paper. In the AC problem, it is required to find
one or several artitions, starting with the given pattern matrix or
dissimilarity, similarity matrix.
</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02420</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blockchain Mining Games</dc:title>
 <dc:creator>Kiayias, Aggelos</dc:creator>
 <dc:creator>Koutsoupias, Elias</dc:creator>
 <dc:creator>Kyropoulou, Maria</dc:creator>
 <dc:creator>Tselekounis, Yiannis</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We study the strategic considerations of miners participating in the
bitcoin's protocol. We formulate and study the stochastic game that underlies
these strategic considerations. The miners collectively build a tree of blocks,
and they are paid when they create a node (mine a block) which will end up in
the path of the tree that is adopted by all. Since the miners can hide newly
mined nodes, they play a game with incomplete information. Here we consider two
simplified forms of this game in which the miners have complete information. In
the simplest game the miners release every mined block immediately, but are
strategic on which blocks to mine. In the second more complicated game, when a
block is mined it is announced immediately, but it may not be released so that
other miners cannot continue mining from it. A miner not only decides which
blocks to mine, but also when to release blocks to other miners. In both games,
we show that when the computational power of each miner is relatively small,
their best response matches the expected behavior of the bitcoin designer.
However, when the computational power of a miner is large, he deviates from the
expected behavior, and other Nash equilibria arise.
</dc:description>
 <dc:description>Comment: Accepted to EC '16</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02431</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning opening books in partially observable games: using random seeds
  in Phantom Go</dc:title>
 <dc:creator>Cazenave, Tristan</dc:creator>
 <dc:creator>Liu, Jialin</dc:creator>
 <dc:creator>Teytaud, Fabien</dc:creator>
 <dc:creator>Teytaud, Olivier</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91A05, 91A10</dc:subject>
 <dc:description>  Many artificial intelligences (AIs) are randomized. One can be lucky or
unlucky with the random seed; we quantify this effect and show that, maybe
contrarily to intuition, this is far from being negligible. Then, we apply two
different existing algorithms for selecting good seeds and good probability
distributions over seeds. This mainly leads to learning an opening book. We
apply this to Phantom Go, which, as all phantom games, is hard for opening book
learning. We improve the winning rate from 50% to 70% in 5x5 against the same
AI, and from approximately 0% to 40% in 5x5, 7x7 and 9x9 against a stronger
(learning) opponent.
</dc:description>
 <dc:description>Comment: 7 pages, 15 figures. Accepted by CIG2016</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02434</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Geometry Methods for Modelling Automotive Radar Interference</dc:title>
 <dc:creator>Al-Hourani, Akram</dc:creator>
 <dc:creator>Evans, Robin J.</dc:creator>
 <dc:creator>Kandeepan, Sithamparanathan</dc:creator>
 <dc:creator>Moran, Bill</dc:creator>
 <dc:creator>Eltom, Hamid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  As the use of automotive radar increases, performance limitations associated
with radar-to-radar interference will become more significant. In this paper we
employ tools from stochastic geometry to characterize the statistics of radar
interference. Specifically, using two different models for vehicle spacial
distributions, namely, a Poisson point process and a Bernoulli lattice process,
we calculate for each case the interference statistics and obtain analytical
expressions for the probability of successful range estimation. Our study shows
that the regularity of the geometrical model appears to have limited effect on
the interference statistics, and so it is possible to obtain tractable tight
bounds for worst case performance. A technique is proposed for designing the
duty cycle for random spectrum access which optimizes the total performance.
This analytical framework is verified using Monte-Carlo simulations.
</dc:description>
 <dc:date>2016-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02436</identifier>
 <datestamp>2017-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Document Clustering Games in Static and Dynamic Scenarios</dc:title>
 <dc:creator>Tripodi, Rocco</dc:creator>
 <dc:creator>Pelillo, Marcello</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this work we propose a game theoretic model for document clustering. Each
document to be clustered is represented as a player and each cluster as a
strategy. The players receive a reward interacting with other players that they
try to maximize choosing their best strategies. The geometry of the data is
modeled with a weighted graph that encodes the pairwise similarity among
documents, so that similar players are constrained to choose similar
strategies, updating their strategy preferences at each iteration of the games.
We used different approaches to find the prototypical elements of the clusters
and with this information we divided the players into two disjoint sets, one
collecting players with a definite strategy and the other one collecting
players that try to learn from others the correct strategy to play. The latter
set of players can be considered as new data points that have to be clustered
according to previous information. This representation is useful in scenarios
in which the data are streamed continuously. The evaluation of the system was
conducted on 13 document datasets using different settings. It shows that the
proposed method performs well compared to different document clustering
algorithms.
</dc:description>
 <dc:description>Comment: This paper will be published in the series Lecture Notes in Computer
  Science (LNCS) published by Springer, containing the ICPRAM 2016 best papers</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02436</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-53375-9_2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02437</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Assignments via Ear Decompositions and Randomized Rounding</dc:title>
 <dc:creator>Adjiashvili, David</dc:creator>
 <dc:creator>Bindewald, Viktor</dc:creator>
 <dc:creator>Michaels, Dennis</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C27</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Many real-life planning problems require making a priori decisions before all
parameters of the problem have been revealed. An important special case of such
problem arises in scheduling problems, where a set of tasks needs to be
assigned to the available set of machines or personnel (resources), in a way
that all tasks have assigned resources, and no two tasks share the same
resource. In its nominal form, the resulting computational problem becomes the
\emph{assignment problem} on general bipartite graphs.
  This paper deals with a robust variant of the assignment problem modeling
situations where certain edges in the corresponding graph are \emph{vulnerable}
and may become unavailable after a solution has been chosen. The goal is to
choose a minimum-cost collection of edges such that if any vulnerable edge
becomes unavailable, the remaining part of the solution contains an assignment
of all tasks.
  We present approximation results and hardness proofs for this type of
problems, and establish several connections to well-known concepts from
matching theory, robust optimization and LP-based techniques.
</dc:description>
 <dc:description>Comment: Full version of ICALP 2016 paper</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02441</identifier>
 <datestamp>2016-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Hypergeometric Ensembles: Statistical Hypothesis Testing in
  Complex Networks</dc:title>
 <dc:creator>Casiraghi, Giona</dc:creator>
 <dc:creator>Nanumyan, Vahan</dc:creator>
 <dc:creator>Scholtes, Ingo</dc:creator>
 <dc:creator>Schweitzer, Frank</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>05C82 (Primary), 62H15 (Secondary)</dc:subject>
 <dc:description>  Statistical ensembles of networks, i.e., probability spaces of all networks
that are consistent with given aggregate statistics, have become instrumental
in the analysis of complex networks. Their numerical and analytical study
provides the foundation for the inference of topological patterns, the
definition of network-analytic measures, as well as for model selection and
statistical hypothesis testing. Contributing to the foundation of these data
analysis techniques, in this Letter we introduce generalized hypergeometric
ensembles, a broad class of analytically tractable statistical ensembles of
finite, directed and weighted networks. This framework can be interpreted as a
generalization of the classical configuration model, which is commonly used to
randomly generate networks with a given degree sequence or distribution. Our
generalization rests on the introduction of dyadic link propensities, which
capture the degree-corrected tendencies of pairs of nodes to form edges between
each other. Studying empirical and synthetic data, we show that our approach
provides broad perspectives for model selection and statistical hypothesis
testing in data on complex networks.
</dc:description>
 <dc:description>Comment: PACS 89.75.Hc, 02.50.Sk, 89.75.Kd; 5 pages, 2 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02444</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explaining Deep Convolutional Neural Networks on Music Classification</dc:title>
 <dc:creator>Choi, Keunwoo</dc:creator>
 <dc:creator>Fazekas, George</dc:creator>
 <dc:creator>Sandler, Mark</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Deep convolutional neural networks (CNNs) have been actively adopted in the
field of music information retrieval, e.g. genre classification, mood
detection, and chord recognition. However, the process of learning and
prediction is little understood, particularly when it is applied to
spectrograms. We introduce auralisation of a CNN to understand its underlying
mechanism, which is based on a deconvolution procedure introduced in [2].
Auralisation of a CNN is converting the learned convolutional features that are
obtained from deconvolution into audio signals. In the experiments and
discussions, we explain trained features of a 5-layer CNN based on the
deconvolved spectrograms and auralised signals. The pairwise correlations per
layers with varying different musical attributes are also investigated to
understand the evolution of the learnt features. It is shown that in the deep
layers, the features are learnt to capture textures, the patterns of continuous
distributions, rather than shapes of lines.
</dc:description>
 <dc:description>Comment: 7 pages, 10 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02450</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the 2016 ICML Workshop on #Data4Good: Machine Learning in
  Social Good Applications</dc:title>
 <dc:creator>Varshney, Kush R.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This is the Proceedings of the ICML Workshop on #Data4Good: Machine Learning
in Social Good Applications, which was held on June 24, 2016 in New York.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02452</identifier>
 <datestamp>2016-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructing bibliometric networks: A comparison between full and
  fractional counting</dc:title>
 <dc:creator>Perianes-Rodriguez, Antonio</dc:creator>
 <dc:creator>Waltman, Ludo</dc:creator>
 <dc:creator>van Eck, Nees Jan</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The analysis of bibliometric networks, such as co-authorship, bibliographic
coupling, and co-citation networks, has received a considerable amount of
attention. Much less attention has been paid to the construction of these
networks. We point out that different approaches can be taken to construct a
bibliometric network. Normally the full counting approach is used, but we
propose an alternative fractional counting approach. The basic idea of the
fractional counting approach is that each action, such as co-authoring or
citing a publication, should have equal weight, regardless of for instance the
number of authors, citations, or references of a publication. We present two
empirical analyses in which the full and fractional counting approaches yield
very different results. These analyses deal with co-authorship networks of
universities and bibliographic coupling networks of journals. Based on
theoretical considerations and on the empirical analyses, we conclude that for
many purposes the fractional counting approach is preferable over the full
counting one.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02453</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Random Mutant Selection at Class-Level in Projects with
  Non-Adequate Test Suites</dc:title>
 <dc:creator>Parsai, Ali</dc:creator>
 <dc:creator>Murgia, Alessandro</dc:creator>
 <dc:creator>Demeyer, Serge</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68N99</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Mutation testing is a standard technique to evaluate the quality of a test
suite. Due to its computationally intensive nature, many approaches have been
proposed to make this technique feasible in real case scenarios. Among these
approaches, uniform random mutant selection has been demonstrated to be simple
and promising. However, works on this area analyze mutant samples at project
level mainly on projects with adequate test suites. In this paper, we fill this
lack of empirical validation by analyzing random mutant selection at class
level on projects with non-adequate test suites. First, we show that uniform
random mutant selection underachieves the expected results. Then, we propose a
new approach named weighted random mutant selection which generates more
representative mutant samples. Finally, we show that representative mutant
samples are larger for projects with high test adequacy.
</dc:description>
 <dc:description>Comment: EASE 2016, Article 11 , 10 pages</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02453</dc:identifier>
 <dc:identifier>Proceedings of the 20th International Conference on Evaluation and
  Assessment in Software Engineering (EASE '16). ACM, New York, NY, USA, 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2915970.2915992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02459</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why We Refactor? Confessions of GitHub Contributors</dc:title>
 <dc:creator>Silva, Danilo</dc:creator>
 <dc:creator>Tsantalis, Nikolaos</dc:creator>
 <dc:creator>Valente, Marco Tulio</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Refactoring is a widespread practice that helps developers to improve the
maintainability and readability of their code. However, there is a limited
number of studies empirically investigating the actual motivations behind
specific refactoring operations applied by developers. To fill this gap, we
monitored Java projects hosted on GitHub to detect recently applied
refactorings, and asked the developers to ex- plain the reasons behind their
decision to refactor the code. By applying thematic analysis on the collected
responses, we compiled a catalogue of 44 distinct motivations for 12 well-known
refactoring types. We found that refactoring activity is mainly driven by
changes in the requirements and much less by code smells. Extract Method is the
most versatile refactoring operation serving 11 different purposes. Finally, we
found evidence that the IDE used by the developers affects the adoption of
automated refactoring tools.
</dc:description>
 <dc:description>Comment: Paper accepted at 24th International Symposium on the Foundations of
  Software Engineering (FSE), pages 1-12, 2016</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02466</identifier>
 <datestamp>2016-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving finite-domain linear constraints in presence of the
  $\texttt{alldifferent}$</dc:title>
 <dc:creator>Bankovi&#x107;, Milan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T27, 68T15</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  In this paper, we investigate the possibility of improvement of the
widely-used filtering algorithm for the linear constraints in constraint
satisfaction problems in the presence of the alldifferent constraints. In many
cases, the fact that the variables in a linear constraint are also constrained
by some alldifferent constraints may help us to calculate stronger bounds of
the variables, leading to a stronger constraint propagation. We propose an
improved filtering algorithm that targets such cases. We provide a detailed
description of the proposed algorithm and prove its correctness. We evaluate
the approach on five different problems that involve combinations of the linear
and the alldifferent constraints. We also compare our algorithm to other
relevant approaches. The experimental results show a great potential of the
proposed improvement.
</dc:description>
 <dc:description>Comment: 28 pages, 2 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02466</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 12, Issue 3 (September
  5, 2016) lmcs:2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02467</identifier>
 <datestamp>2016-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Log-Linear RNNs: Towards Recurrent Neural Networks with Flexible Prior
  Knowledge</dc:title>
 <dc:creator>Dymetman, Marc</dc:creator>
 <dc:creator>Xiao, Chunyang</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce LL-RNNs (Log-Linear RNNs), an extension of Recurrent Neural
Networks that replaces the softmax output layer by a log-linear output layer,
of which the softmax is a special case. This conceptually simple move has two
main advantages. First, it allows the learner to combat training data sparsity
by allowing it to model words (or more generally, output symbols) as complex
combinations of attributes without requiring that each combination is directly
observed in the training data (as the softmax does). Second, it permits the
inclusion of flexible prior knowledge in the form of a priori specified modular
features, where the neural network component learns to dynamically control the
weights of a log-linear distribution exploiting these features.
  We conduct experiments in the domain of language modelling of French, that
exploit morphological prior knowledge and show an important decrease in
perplexity relative to a baseline RNN.
  We provide other motivating iillustrations, and finally argue that the
log-linear and the neural-network components contribute complementary strengths
to the LL-RNN: the LL aspect allows the model to incorporate rich prior
knowledge, while the NN aspect, according to the &quot;representation learning&quot;
paradigm, allows the model to discover novel combination of characteristics.
</dc:description>
 <dc:description>Comment: Updated version of arXiv:1607.02467. Presented at the NIPS-2016 RNN
  Symposium, Barcelona, December 2016</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02480</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Anomaly Detection for Streaming Analytics</dc:title>
 <dc:creator>Ahmad, Subutai</dc:creator>
 <dc:creator>Purdy, Scott</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Much of the worlds data is streaming, time-series data, where anomalies give
significant information in critical situations. Yet detecting anomalies in
streaming data is a difficult task, requiring detectors to process data in
real-time, and learn while simultaneously making predictions. We present a
novel anomaly detection technique based on an on-line sequence memory algorithm
called Hierarchical Temporal Memory (HTM). We show results from a live
application that detects anomalies in financial metrics in real-time. We also
test the algorithm on NAB, a published benchmark for real-time anomaly
detection, where our algorithm achieves best-in-class results.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02481</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring monopartite projections of bipartite networks: an
  entropy-based approach</dc:title>
 <dc:creator>Saracco, Fabio</dc:creator>
 <dc:creator>Straka, Mika J.</dc:creator>
 <dc:creator>Di Clemente, Riccardo</dc:creator>
 <dc:creator>Gabrielli, Andrea</dc:creator>
 <dc:creator>Caldarelli, Guido</dc:creator>
 <dc:creator>Squartini, Tiziano</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Quantitative Finance - General Finance</dc:subject>
 <dc:description>  Bipartite networks are currently regarded as providing a major insight into
the organization of many real-world systems, unveiling the mechanisms driving
the interactions occurring between distinct groups of nodes. One of the most
important issues encountered when modeling bipartite networks is devising a way
to obtain a (monopartite) projection on the layer of interest, which preserves
as much as possible the information encoded into the original bipartite
structure. In the present paper we propose an algorithm to obtain
statistically-validated projections of bipartite networks, according to which
any two nodes sharing a statistically-significant number of neighbors are
linked. Since assessing the statistical significance of nodes similarity
requires a proper statistical benchmark, here we consider a set of four null
models, defined within the exponential random graph framework. Our algorithm
outputs a matrix of link-specific p-values, from which a validated projection
is straightforwardly obtainable, upon running a multiple hypothesis testing
procedure. Finally, we test our method on an economic network (i.e. the
countries-products World Trade Web representation) and a social network (i.e.
MovieLens, collecting the users' ratings of a list of movies). In both cases
non-trivial communities are detected: while projecting the World Trade Web on
the countries layer reveals modules of similarly-industrialized nations,
projecting it on the products layer allows communities characterized by an
increasing level of complexity to be detected; in the second case, projecting
MovieLens on the films layer allows clusters of movies whose affinity cannot be
fully accounted for by genre similarity to be individuated.
</dc:description>
 <dc:description>Comment: 16 pages, 9 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02481</dc:identifier>
 <dc:identifier>New J. Phys. 19, 053022 (2017)</dc:identifier>
 <dc:identifier>doi:10.1088/1367-2630/aa6b38</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02488</identifier>
 <datestamp>2017-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adjusting for Dropout Variance in Batch Normalization and Weight
  Initialization</dc:title>
 <dc:creator>Hendrycks, Dan</dc:creator>
 <dc:creator>Gimpel, Kevin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We show how to adjust for the variance introduced by dropout with corrections
to weight initialization and Batch Normalization, yielding higher accuracy.
Though dropout can preserve the expected input to a neuron between train and
test, the variance of the input differs. We thus propose a new weight
initialization by correcting for the influence of dropout rates and an
arbitrary nonlinearity's influence on variance through simple corrective
scalars. Since Batch Normalization trained with dropout estimates the variance
of a layer's incoming distribution with some inputs dropped, the variance also
differs between train and test. After training a network with Batch
Normalization and dropout, we simply update Batch Normalization's variance
moving averages with dropout off and obtain state of the art on CIFAR-10 and
CIFAR-100 without data augmentation.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2017-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02495</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Zero-Error Feedback Capacity of State-Dependent Channels</dc:title>
 <dc:creator>Bracher, Annina</dc:creator>
 <dc:creator>Lapidoth, Amos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The zero-error feedback capacity of the Gelfand-Pinsker channel is
established. It can be positive even if the channel's zero-error capacity is
zero in the absence of feedback. Moreover, the error-free transmission of a
single bit may require more than one channel use. These phenomena do not occur
when the state is revealed to the transmitter causally, a case that is solved
here using Shannon strategies. Cost constraints on the channel inputs or
channel states are also discussed, as is the scenario where---in addition to
the message---also the state sequence must be recovered.
</dc:description>
 <dc:description>Comment: 98 pages, 4 figures, submitted to IEEE Transactions on Information
  Theory</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02497</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is the Multigrid Method Fault Tolerant? The Two-Grid Case</dc:title>
 <dc:creator>Ainsworth, Mark</dc:creator>
 <dc:creator>Glusa, Christian</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>65F10, 65N22, 65N55, 68M15</dc:subject>
 <dc:description>  The predicted reduced resiliency of next-generation high performance
computers means that it will become necessary to take into account the effects
of randomly occurring faults on numerical methods. Further, in the event of a
hard fault occurring, a decision has to be made as to what remedial action
should be taken in order to resume the execution of the algorithm. The action
that is chosen can have a dramatic effect on the performance and
characteristics of the scheme. Ideally, the resulting algorithm should be
subjected to the same kind of mathematical analysis that was applied to the
original, deterministic variant.
  The purpose of this work is to provide an analysis of the behaviour of the
multigrid algorithm in the presence of faults. Multigrid is arguably the method
of choice for the solution of large-scale linear algebra problems arising from
discretization of partial differential equations and it is of considerable
importance to anticipate its behaviour on an exascale machine. The analysis of
resilience of algorithms is in its infancy and the current work is perhaps the
first to provide a mathematical model for faults and analyse the behaviour of a
state-of-the-art algorithm under the model. It is shown that the Two Grid
Method fails to be resilient to faults. Attention is then turned to identifying
the minimal necessary remedial action required to restore the rate of
convergence to that enjoyed by the ideal fault-free method.
</dc:description>
 <dc:description>Comment: 27 pages and 6 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02497</dc:identifier>
 <dc:identifier>doi:10.1137/16M1100691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02501</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Actionable and Political Text Classification using Word Embeddings and
  LSTM</dc:title>
 <dc:creator>Rao, Adithya</dc:creator>
 <dc:creator>Spasojevic, Nemanja</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>68T50, 92B20</dc:subject>
 <dc:description>  In this work, we apply word embeddings and neural networks with Long
Short-Term Memory (LSTM) to text classification problems, where the
classification criteria are decided by the context of the application. We
examine two applications in particular. The first is that of Actionability,
where we build models to classify social media messages from customers of
service providers as Actionable or Non-Actionable. We build models for over 30
different languages for actionability, and most of the models achieve accuracy
around 85%, with some reaching over 90% accuracy. We also show that using LSTM
neural networks with word embeddings vastly outperform traditional techniques.
Second, we explore classification of messages with respect to political
leaning, where social media messages are classified as Democratic or
Republican. The model is able to classify messages with a high accuracy of
87.57%. As part of our experiments, we vary different hyperparameters of the
neural networks, and report the effect of such variation on the accuracy. These
actionability models have been deployed to production and help company agents
provide customer support by prioritizing which messages to respond to. The
model for political leaning has been opened and made available for wider use.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02502</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Networked SIS Epidemics with Awareness</dc:title>
 <dc:creator>Paarporn, Keith</dc:creator>
 <dc:creator>Eksin, Ceyhun</dc:creator>
 <dc:creator>Weitz, Joshua S.</dc:creator>
 <dc:creator>Shamma, Jeff S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We study an SIS epidemic process over a static contact network where the
nodes have partial information about the epidemic state. They react by limiting
their interactions with their neighbors when they believe the epidemic is
currently prevalent. A node's awareness is weighted by the fraction of infected
neighbors in their social network, and a global broadcast of the fraction of
infected nodes in the entire network. The dynamics of the benchmark (no
awareness) and awareness models are described by discrete-time Markov chains,
from which mean-field approximations (MFA) are derived. The states of the MFA
are interpreted as the nodes' probabilities of being infected. We show a
sufficient condition for existence of a &quot;metastable&quot;, or endemic, state of the
awareness model coincides with that of the benchmark model. Furthermore, we use
a coupling technique to give a full stochastic comparison analysis between the
two chains, which serves as a probabilistic analogue to the MFA analysis. In
particular, we show that adding awareness reduces the expectation of any
epidemic metric on the space of sample paths, e.g. eradication time or total
infections. We characterize the reduction in expectations in terms of the
coupling distribution. In simulations, we evaluate the effect social distancing
has on contact networks from different random graph families (geometric,
Erd\H{o}s-Renyi, and scale-free random networks).
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02504</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Predictive Image Registration</dc:title>
 <dc:creator>Yang, Xiao</dc:creator>
 <dc:creator>Kwitt, Roland</dc:creator>
 <dc:creator>Niethammer, Marc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a method to predict image deformations based on patch-wise image
appearance. Specifically, we design a patch-based deep encoder-decoder network
which learns the pixel/voxel-wise mapping between image appearance and
registration parameters. Our approach can predict general deformation
parameterizations, however, we focus on the large deformation diffeomorphic
metric mapping (LDDMM) registration model. By predicting the LDDMM
momentum-parameterization we retain the desirable theoretical properties of
LDDMM, while reducing computation time by orders of magnitude: combined with
patch pruning, we achieve a 1500x/66x speed up compared to GPU-based
optimization for 2D/3D image registration. Our approach has better prediction
accuracy than predicting deformation or velocity fields and results in
diffeomorphic transformations. Additionally, we create a Bayesian probabilistic
version of our network, which allows evaluation of deformation field
uncertainty through Monte Carlo sampling using dropout at test time. We show
that deformation uncertainty highlights areas of ambiguous deformations. We
test our method on the OASIS brain image dataset in 2D and 3D.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02524</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Replica-Symmetric Prediction for Compressed Sensing with Gaussian
  Matrices is Exact</dc:title>
 <dc:creator>Reeves, Galen</dc:creator>
 <dc:creator>Pfister, Henry D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the fundamental limit of compressed sensing for i.i.d.
signal distributions and i.i.d. Gaussian measurement matrices. Its main
contribution is a rigorous characterization of the asymptotic mutual
information (MI) and minimum mean-square error (MMSE) in this setting. Under
mild technical conditions, our results show that the limiting MI and MMSE are
equal to the values predicted by the replica method from statistical physics.
This resolves a well-known problem that has remained open for over a decade.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02526</identifier>
 <datestamp>2017-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Auction Design for Flexible Consumers</dc:title>
 <dc:creator>Navabi, Shiva</dc:creator>
 <dc:creator>Nayyar, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study the problem of designing revenue-maximizing auctions for allocating
multiple goods to flexible consumers. In our model, each consumer is interested
in a subset of goods known as its flexibility set and wants to consume one good
from this set. A consumer's flexibility set and its utility from consuming a
good from its flexibility set are its private information. We focus on the case
of nested flexibility sets --- each consumer's flexibility set can be one of
$k$ nested sets. We provide several examples where such nested flexibility sets
may arise. We characterize the allocation rule for an incentive compatible,
individually rational and revenue-maximizing auction as the solution to an
integer program. The corresponding payment rule is described by an integral
equation. We then leverage the nestedness of flexibility sets to simplify the
optimal auction and provide a complete characterization of allocations and
payments in terms of simple thresholds.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2017-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02531</identifier>
 <datestamp>2016-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the 2016 ICML Workshop on Human Interpretability in
  Machine Learning (WHI 2016)</dc:title>
 <dc:creator>Kim, Been</dc:creator>
 <dc:creator>Malioutov, Dmitry M.</dc:creator>
 <dc:creator>Varshney, Kush R.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This is the Proceedings of the 2016 ICML Workshop on Human Interpretability
in Machine Learning (WHI 2016), which was held in New York, NY, June 23, 2016.
  Invited speakers were Susan Athey, Rich Caruana, Jacob Feldman, Percy Liang,
and Hanna Wallach.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02533</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial examples in the physical world</dc:title>
 <dc:creator>Kurakin, Alexey</dc:creator>
 <dc:creator>Goodfellow, Ian</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Most existing machine learning classifiers are highly vulnerable to
adversarial examples. An adversarial example is a sample of input data which
has been modified very slightly in a way that is intended to cause a machine
learning classifier to misclassify it. In many cases, these modifications can
be so subtle that a human observer does not even notice the modification at
all, yet the classifier still makes a mistake. Adversarial examples pose
security concerns because they could be used to perform an attack on machine
learning systems, even if the adversary has no access to the underlying model.
Up to now, all previous work have assumed a threat model in which the adversary
can feed data directly into the machine learning classifier. This is not always
the case for systems operating in the physical world, for example those which
are using signals from cameras and other sensors as an input. This paper shows
that even in such physical world scenarios, machine learning systems are
vulnerable to adversarial examples. We demonstrate this by feeding adversarial
images obtained from cell-phone camera to an ImageNet Inception classifier and
measuring the classification accuracy of the system. We find that a large
fraction of adversarial examples are classified incorrectly even when perceived
through the camera.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures. Demo available at https://youtu.be/zQ_uMenoBCk</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2017-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02535</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from Multiway Data: Simple and Efficient Tensor Regression</dc:title>
 <dc:creator>Yu, Rose</dc:creator>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Tensor regression has shown to be advantageous in learning tasks with
multi-directional relatedness. Given massive multiway data, traditional methods
are often too slow to operate on or suffer from memory bottleneck. In this
paper, we introduce subsampled tensor projected gradient to solve the problem.
Our algorithm is impressively simple and efficient. It is built upon projected
gradient method with fast tensor power iterations, leveraging randomized
sketching for further acceleration. Theoretical analysis shows that our
algorithm converges to the correct solution in fixed number of iterations. The
memory requirement grows linearly with the size of the problem. We demonstrate
superior empirical performance on both multi-linear multi-task learning and
spatio-temporal applications.
</dc:description>
 <dc:description>Comment: 10 pages, Proceedings of the 33rd International Conference on Machine
  Learning (ICML-16), 2016</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02535</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02537</identifier>
 <datestamp>2016-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-level Contextual RNNs with Attention Model for Scene Labeling</dc:title>
 <dc:creator>Fan, Heng</dc:creator>
 <dc:creator>Mei, Xue</dc:creator>
 <dc:creator>Prokhorov, Danil</dc:creator>
 <dc:creator>Ling, Haibin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Context in image is crucial for scene labeling while existing methods only
exploit local context generated from a small surrounding area of an image patch
or a pixel, by contrast long-range and global contextual information is
ignored. To handle this issue, we in this work propose a novel approach for
scene labeling by exploring multi-level contextual recurrent neural networks
(ML-CRNNs). Specifically, we encode three kinds of contextual cues, i.e., local
context, global context and image topic context in structural recurrent neural
networks (RNNs) to model long-range local and global dependencies in image. In
this way, our method is able to `see' the image in terms of both long-range
local and holistic views, and make a more reliable inference for image
labeling. Besides, we integrate the proposed contextual RNNs into hierarchical
convolutional neural networks (CNNs), and exploit dependence relationships in
multiple levels to provide rich spatial and semantic information. Moreover, we
novelly adopt an attention model to effectively merge multiple levels and show
that it outperforms average- or max-pooling fusion strategies. Extensive
experiments demonstrate that the proposed approach achieves new
state-of-the-art results on the CamVid, SiftFlow and Stanford-background
datasets.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02539</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Construction with Label Information for Semi-Supervised Learning</dc:title>
 <dc:creator>Zhuang, Liansheng</dc:creator>
 <dc:creator>Zhou, Zihan</dc:creator>
 <dc:creator>Yin, Jingwen</dc:creator>
 <dc:creator>Gao, Shenghua</dc:creator>
 <dc:creator>Lin, Zhouchen</dc:creator>
 <dc:creator>Ma, Yi</dc:creator>
 <dc:creator>Yu, Nenghai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the literature, most existing graph-based semi-supervised learning (SSL)
methods only use the label information of observed samples in the label
propagation stage, while ignoring such valuable information when learning the
graph. In this paper, we argue that it is beneficial to consider the label
information in the graph learning stage. Specifically, by enforcing the weight
of edges between labeled samples of different classes to be zero, we explicitly
incorporate the label information into the state-of-the-art graph learning
methods, such as the Low-Rank Representation (LRR), and propose a novel
semi-supervised graph learning method called Semi-Supervised Low-Rank
Representation (SSLRR). This results in a convex optimization problem with
linear constraints, which can be solved by the linearized alternating direction
method. Though we take LRR as an example, our proposed method is in fact very
general and can be applied to any self-representation graph learning methods.
Experiment results on both synthetic and real datasets demonstrate that the
proposed graph learning method can better capture the global geometric
structure of the data, and therefore is more effective for semi-supervised
learning tasks.
</dc:description>
 <dc:description>Comment: This paper is withdrawn by the authors for some errors</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2017-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02547</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Screen Content Image Segmentation Using Robust Regression and Sparse
  Decomposition</dc:title>
 <dc:creator>Minaee, Shervin</dc:creator>
 <dc:creator>Wang, Yao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper considers how to separate text and/or graphics from smooth
background in screen content and mixed document images and proposes two
approaches to perform this segmentation task. The proposed methods make use of
the fact that the background in each block is usually smoothly varying and can
be modeled well by a linear combination of a few smoothly varying basis
functions, while the foreground text and graphics create sharp discontinuity.
The algorithms separate the background and foreground pixels by trying to fit
background pixel values in the block into a smooth function using two different
schemes. One is based on robust regression, where the inlier pixels will be
considered as background, while remaining outlier pixels will be considered
foreground. The second approach uses a sparse decomposition framework where the
background and foreground layers are modeled with a smooth and sparse
components respectively. These algorithms have been tested on images extracted
from HEVC standard test sequences for screen content coding, and are shown to
have superior performance over previous approaches. The proposed methods can be
used in different applications such as text extraction, separate coding of
background and foreground for compression of screen content, and medical image
segmentation.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02548</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the non-uniqueness of the instantaneous frequency</dc:title>
 <dc:creator>Tavallali, Peyman</dc:creator>
 <dc:creator>Hou, Thomas Y.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In this article, we investigate the debated Instantaneous Frequency (IF)
topic. Here, we show that IF is non-unique inherently. We explain how this
non-uniqueness can be quantified and explained from a mathematical perspective.
The non-uniqueness of the IF can also be observed if different methods of
adaptive signal processing are used. We will also show that even if we know the
physical origin of an oscillatory signal, e.g. linear second order ordinary
differential equation, the non-uniqueness is still present. All in all, we will
end up with the conclusion that, without any a priori assumption about the
relationship of the envelope and phase function of an oscillatory signal, there
is not any preferred neither best representation of the IF of such oscillatory
signal.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the authors because some of the
  statements and conclusions made by this paper were not accurate and their
  interpretations could be misleading based on some feedback from readers</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02549</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Requirement Debugging for Testing and Verification of
  Cyber-Physical Systems</dc:title>
 <dc:creator>Dokhanchi, Adel</dc:creator>
 <dc:creator>Hoxha, Bardh</dc:creator>
 <dc:creator>Fainekos, Georgios</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A framework for the elicitation and debugging of formal specifications for
Cyber-Physical Systems is presented. The elicitation of specifications is
handled through a graphical interface. Two debugging algorithms are presented.
The first checks for erroneous or incomplete temporal logic specifications
without considering the system. The second can be utilized for the analysis of
reactive requirements with respect to system test traces. The specification
debugging framework is applied on a number of formal specifications collected
through a user study. The user study establishes that requirement errors are
common and that the debugging framework can resolve many insidious
specification errors.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02552</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Learning Schemes for Power Allocation in Energy Harvesting
  Communications</dc:title>
 <dc:creator>Sakulkar, Pranav</dc:creator>
 <dc:creator>Krishnamachari, Bhaskar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of power allocation over a time-varying channel with
unknown distribution in energy harvesting communication systems. In this
problem, the transmitter has to choose the transmit power based on the amount
of stored energy in its battery with the goal of maximizing the average rate
obtained over time. We model this problem as a Markov decision process (MDP)
with the transmitter as the agent, the battery status as the state, the
transmit power as the action and the rate obtained as the reward. The average
reward maximization problem over the MDP can be solved by a linear program (LP)
that uses the transition probabilities for the state-action pairs and their
reward values to choose a power allocation policy. Since the rewards associated
the state-action pairs are unknown, we propose two online learning algorithms:
UCLP and Epoch-UCLP that learn these rewards and adapt their policies along the
way. The UCLP algorithm solves the LP at each step to decide its current policy
using the upper confidence bounds on the rewards, while the Epoch-UCLP
algorithm divides the time into epochs, solves the LP only at the beginning of
the epochs and follows the obtained policy in that epoch. We prove that the
reward losses or regrets incurred by both these algorithms are upper bounded by
constants. Epoch-UCLP incurs a higher regret compared to UCLP, but reduces the
computational requirements substantially. We also show that the presented
algorithms work for online learning in cost minimization problems like the
packet scheduling with power-delay tradeoff with minor changes.
</dc:description>
 <dc:description>Comment: This paper is under submission in the IEEE Transaction on Information
  Theory</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02555</identifier>
 <datestamp>2016-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Photometrically Calibrated Benchmark For Monocular Visual Odometry</dc:title>
 <dc:creator>Engel, Jakob</dc:creator>
 <dc:creator>Usenko, Vladyslav</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a dataset for evaluating the tracking accuracy of monocular visual
odometry and SLAM methods. It contains 50 real-world sequences comprising more
than 100 minutes of video, recorded across dozens of different environments --
ranging from narrow indoor corridors to wide outdoor scenes. All sequences
contain mostly exploring camera motion, starting and ending at the same
position. This allows to evaluate tracking accuracy via the accumulated drift
from start to end, without requiring ground truth for the full sequence. In
contrast to existing datasets, all sequences are photometrically calibrated. We
provide exposure times for each frame as reported by the sensor, the camera
response function, and dense lens attenuation factors. We also propose a novel,
simple approach to non-parametric vignette calibration, which requires minimal
set-up and is easy to reproduce. Finally, we thoroughly evaluate two existing
methods (ORB-SLAM and DSO) on the dataset, including an analysis of the effect
of image resolution, camera field of view, and the camera motion direction.
</dc:description>
 <dc:description>Comment: * Corrected a bug in the evaluation setup, which caused the real-time
  results for ORB-SLAM (dashed lines in Figure 8) to be much worse than they
  should be. * https://vision.in.tum.de/data/datasets/mono-dataset</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-10-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02556</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Action Recognition with Joint Attention on Multi-Level Deep Features</dc:title>
 <dc:creator>Wu, Jialin</dc:creator>
 <dc:creator>Wang, Gu</dc:creator>
 <dc:creator>Yang, Wukui</dc:creator>
 <dc:creator>Ji, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel deep supervised neural network for the task of action
recognition in videos, which implicitly takes advantage of visual tracking and
shares the robustness of both deep Convolutional Neural Network (CNN) and
Recurrent Neural Network (RNN). In our method, a multi-branch model is proposed
to suppress noise from background jitters. Specifically, we firstly extract
multi-level deep features from deep CNNs and feed them into 3d-convolutional
network. After that we feed those feature cubes into our novel joint LSTM
module to predict labels and to generate attention regularization. We evaluate
our model on two challenging datasets: UCF101 and HMDB51. The results show that
our model achieves the state-of-art by only using convolutional features.
</dc:description>
 <dc:description>Comment: 13 pages, submitted to BMVC</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02559</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncovering Locally Discriminative Structure for Feature Analysis</dc:title>
 <dc:creator>Wang, Sen</dc:creator>
 <dc:creator>Nie, Feiping</dc:creator>
 <dc:creator>Chang, Xiaojun</dc:creator>
 <dc:creator>Li, Xue</dc:creator>
 <dc:creator>Sheng, Quan Z.</dc:creator>
 <dc:creator>Yao, Lina</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Manifold structure learning is often used to exploit geometric information
among data in semi-supervised feature learning algorithms. In this paper, we
find that local discriminative information is also of importance for
semi-supervised feature learning. We propose a method that utilizes both the
manifold structure of data and local discriminant information. Specifically, we
define a local clique for each data point. The k-Nearest Neighbors (kNN) is
used to determine the structural information within each clique. We then employ
a variant of Fisher criterion model to each clique for local discriminant
evaluation and sum all cliques as global integration into the framework. In
this way, local discriminant information is embedded. Labels are also utilized
to minimize distances between data from the same class. In addition, we use the
kernel method to extend our proposed model and facilitate feature learning in a
high-dimensional space after feature mapping. Experimental results show that
our method is superior to all other compared methods over a number of datasets.
</dc:description>
 <dc:description>Comment: Accepted by ECML/PKDD2016</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02561</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Database-Backed Web Applications in the Wild: How Well Do They Work?</dc:title>
 <dc:creator>Yan, Cong</dc:creator>
 <dc:creator>Cheung, Alvin</dc:creator>
 <dc:creator>Lu, Shan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Most modern database-backed web applications are built upon Object Relational
Mapping (ORM) frameworks. While ORM frameworks ease application development by
abstracting persistent data as objects, such convenience often comes with a
performance cost. In this paper, we present CADO, a tool that analyzes the
application logic and its interaction with databases using the Ruby on Rails
ORM framework. CADO includes a static program analyzer, a profiler and a
synthetic data generator to extract and understand application's performance
characteristics. We used CADO to analyze the performance problems of 27
real-world open-source Rails applications, covering domains such as online
forums, e-commerce, project management, blogs, etc. Based on the results, we
uncovered a number of issues that lead to sub-optimal application performance,
ranging from issuing queries, how result sets are used, and physical design. We
suggest possible remedies for each issue, and highlight new research
opportunities that arise from them.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02562</identifier>
 <datestamp>2016-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CPDY: Extending the Dolev-Yao Attacker with Physical-Layer Interactions</dc:title>
 <dc:creator>Rocchetto, Marco</dc:creator>
 <dc:creator>Tippenhauer, Nils Ole</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We propose extensions to the Dolev-Yao attacker model to make it suitable for
arguments about security of Cyber-Physical Systems. The Dolev-Yao attacker
model uses a set of rules to define potential actions by an attacker with
respect to messages (i.e. information) exchanged between parties during a
protocol execution. As the traditional Dolev-Yao model considers only
information (exchanged over a channel controlled by the attacker), the model
cannot directly be used to argue about the security of cyber-physical systems
where physical-layer interactions are possible. Our Dolev-Yao extension, called
cyber-physical Dolev-Yao (CPDY) attacker model, allows additional orthogonal
interaction channels between the parties. In particular, such orthogonal
channels can be used to model physical-layer mechanical, chemical, or
electrical interactions between components. In addition, we discuss the
inclusion of physical properties such as location or distance in the rule set.
We present an example set of additional rules for the Dolev-Yao attacker, using
those we are able to formally discover physical attacks that previously could
only be found by empirical methods or detailed physical process models.
</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:date>2016-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02565</identifier>
 <datestamp>2016-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct Sparse Odometry</dc:title>
 <dc:creator>Engel, Jakob</dc:creator>
 <dc:creator>Koltun, Vladlen</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel direct sparse visual odometry formulation. It combines a
fully direct probabilistic model (minimizing a photometric error) with
consistent, joint optimization of all model parameters, including geometry --
represented as inverse depth in a reference frame -- and camera motion. This is
achieved in real time by omitting the smoothness prior used in other direct
methods and instead sampling pixels evenly throughout the images. Since our
method does not depend on keypoint detectors or descriptors, it can naturally
sample pixels from across all image regions that have intensity gradient,
including edges or smooth intensity variations on mostly white walls. The
proposed model integrates a full photometric calibration, accounting for
exposure time, lens vignetting, and non-linear response functions. We
thoroughly evaluate our method on three different datasets comprising several
hours of video. The experiments show that the presented approach significantly
outperforms state-of-the-art direct and indirect methods in a variety of
real-world settings, both in terms of tracking accuracy and robustness.
</dc:description>
 <dc:description>Comment: ** Corrected a bug which caused the real-time results for ORB-SLAM
  (dashed lines in Fig. 10 and 12) to be much worse than they should be **
  Added references [12], [13],[19], and Fig. 11. ** Partly re-formulated and
  extended [5. Conclusion]. ** Fixed typos and minor re-formulations</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:date>2016-10-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02568</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning of Appearance Models for Online Object Tracking</dc:title>
 <dc:creator>Zhai, Mengyao</dc:creator>
 <dc:creator>Roshtkhari, Mehrsan Javan</dc:creator>
 <dc:creator>Mori, Greg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a novel deep learning based approach for vision based
single target tracking. We address this problem by proposing a network
architecture which takes the input video frames and directly computes the
tracking score for any candidate target location by estimating the probability
distributions of the positive and negative examples. This is achieved by
combining a deep convolutional neural network with a Bayesian loss layer in a
unified framework. In order to deal with the limited number of positive
training examples, the network is pre-trained offline for a generic image
feature representation and then is fine-tuned in multiple steps. An online
fine-tuning step is carried out at every frame to learn the appearance of the
target. We adopt a two-stage iterative algorithm to adaptively update the
network parameters and maintain a probability density for target/non-target
regions. The tracker has been tested on the standard tracking benchmark and the
results indicate that the proposed solution achieves state-of-the-art tracking
results.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02573</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Microwave Tomographic Imaging of Cerebrovascular Accidents by Using
  High-Performance Computing</dc:title>
 <dc:creator>Tournier, P. -H.</dc:creator>
 <dc:creator>Aliferis, I.</dc:creator>
 <dc:creator>Bonazzoli, M.</dc:creator>
 <dc:creator>de Buhan, M.</dc:creator>
 <dc:creator>Darbas, M.</dc:creator>
 <dc:creator>Dolean, V.</dc:creator>
 <dc:creator>Hecht, F.</dc:creator>
 <dc:creator>Jolivet, P.</dc:creator>
 <dc:creator>Kanfoud, I. El</dc:creator>
 <dc:creator>Migliaccio, C.</dc:creator>
 <dc:creator>Nataf, F.</dc:creator>
 <dc:creator>Pichot, C.</dc:creator>
 <dc:creator>Semenov, S.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  The motivation of this work is the detection of cerebrovascular accidents by
microwave tomographic imaging. This requires the solution of an inverse problem
relying on a minimization algorithm (for example, gradient-based), where
successive iterations consist in repeated solutions of a direct problem. The
reconstruction algorithm is extremely computationally intensive and makes use
of efficient parallel algorithms and high-performance computing. The
feasibility of this type of imaging is conditioned on one hand by an accurate
reconstruction of the material properties of the propagation medium and on the
other hand by a considerable reduction in simulation time. Fulfilling these two
requirements will enable a very rapid and accurate diagnosis. From the
mathematical and numerical point of view, this means solving Maxwell's
equations in time-harmonic regime by appropriate domain decomposition methods,
which are naturally adapted to parallel architectures.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02574</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Miracle of Peer Review and Development in Science: An Agent-Based
  Model</dc:title>
 <dc:creator>Righi, Simone</dc:creator>
 <dc:creator>Tak&#xe1;cs, K&#xe1;roly</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  It is not easy to rationalize how peer review, as the current grassroots of
science, can work based on voluntary contributions of reviewers. There is no
rationale to write impartial and thorough evaluations. Consequently, there is
no risk in submitting low-quality work by authors. As a result, scientists face
a social dilemma: if everyone acts according to his or her own self-interest,
low scientific quality is produced. Still, in practice, reviewers as well as
authors invest high effort in reviews and submissions.
  We examine how the increased relevance of public good benefits (journal
impact factor), the editorial policy of handling incoming reviews, and the
acceptance decisions that take into account reputational information can help
the evolution of high-quality contributions from authors. High effort from the
side of reviewers is problematic even if authors cooperate: reviewers are still
best off by producing low-quality reviews, which does not hinder scientific
development, just adds random noise and unnecessary costs to it. We show with
agent-based simulations that tacit agreements between authors that are based on
reciprocity might decrease these costs, but does not result in superior
scientific quality. Our study underlines why certain self-emerged current
practices, such as the increased importance of journal metrics, the
reputation-based selection of reviewers, and the reputation bias in acceptance
work efficiently for scientific development. Our results find no answers,
however, how the system of peer review with impartial and thorough evaluations
could be sustainable jointly with rapid scientific development.
</dc:description>
 <dc:description>Comment: Submitted to Scientometrics</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02576</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of opinionated text for opinion mining</dc:title>
 <dc:creator>Paramesha, K</dc:creator>
 <dc:creator>Ravishankar, K C</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In sentiment analysis, the polarities of the opinions expressed on an
object/feature are determined to assess the sentiment of a sentence or document
whether it is positive/negative/neutral. Naturally, the object/feature is a
noun representation which refers to a product or a component of a product, let
us say, the &quot;lens&quot; in a camera and opinions emanating on it are captured in
adjectives, verbs, adverbs and noun words themselves. Apart from such words,
other meta-information and diverse effective features are also going to play an
important role in influencing the sentiment polarity and contribute
significantly to the performance of the system. In this paper, some of the
associated information/meta-data are explored and investigated in the sentiment
text. Based on the analysis results presented here, there is scope for further
assessment and utilization of the meta-information as features in text
categorization, ranking text document, identification of spam documents and
polarity classification problems.
</dc:description>
 <dc:description>Comment: Sentiment Analysis, Features, Feature Engineering, Emotions, Word
  Sense Disambiguation, Sentiment Lexicons, Meta-Information</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02576</dc:identifier>
 <dc:identifier>Machine Learning and Applications: An International Journal
  (MLAIJ) Vol.3, No.2, June 2016</dc:identifier>
 <dc:identifier>doi:10.5121/mlaij.2016.3204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02584</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Alternating Direction Method of Multipliers by Majorization
  Minimization</dc:title>
 <dc:creator>Lu, Canyi</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:creator>Lin, Zhouchen</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Accompanied with the rising popularity of compressed sensing, the Alternating
Direction Method of Multipliers (ADMM) has become the most widely used solver
for linearly constrained convex problems with separable objectives. In this
work, we observe that many previous variants of ADMM update the primal variable
by minimizing different majorant functions with their convergence proofs given
case by case. Inspired by the principle of majorization minimization, we
respectively present the unified frameworks and convergence analysis for the
Gauss-Seidel ADMMs and Jacobian ADMMs, which use different historical
information for the current updating. Our frameworks further generalize
previous ADMMs to the ones capable of solving the problems with non-separable
objectives by minimizing their separable majorant surrogates. We also show that
the bound which measures the convergence speed of ADMMs depends on the
tightness of the used majorant function. Then several techniques are introduced
to improve the efficiency of ADMMs by tightening the majorant functions. In
particular, we propose the Mixed Gauss-Seidel and Jacobian ADMM (M-ADMM) which
alleviates the slow convergence issue of Jacobian ADMMs by absorbing merits of
the Gauss-Seidel ADMMs. M-ADMM can be further improved by using backtracking,
wise variable partition and fully exploiting the structure of the constraint.
Beyond the guarantee in theory, numerical experiments on both synthesized and
real-world data further demonstrate the superiority of our new ADMMs in
practice. Finally, we release a toolbox at https://github.com/canyilu/LibADMM
that implements efficient ADMMs for many problems in compressed sensing.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02586</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Dynamics: Probabilistic Future Frame Synthesis via Cross
  Convolutional Networks</dc:title>
 <dc:creator>Xue, Tianfan</dc:creator>
 <dc:creator>Wu, Jiajun</dc:creator>
 <dc:creator>Bouman, Katherine L.</dc:creator>
 <dc:creator>Freeman, William T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of synthesizing a number of likely future frames from a
single input image. In contrast to traditional methods, which have tackled this
problem in a deterministic or non-parametric way, we propose a novel approach
that models future frames in a probabilistic manner. Our probabilistic model
makes it possible for us to sample and synthesize many possible future frames
from a single input image. Future frame synthesis is challenging, as it
involves low- and high-level image and motion understanding. We propose a novel
network structure, namely a Cross Convolutional Network to aid in synthesizing
future frames; this network structure encodes image and motion information as
feature maps and convolutional kernels, respectively. In experiments, our model
performs well on synthetic data, such as 2D shapes and animated game sprites,
as well as on real-wold videos. We also show that our model can be applied to
tasks such as visual analogy-making, and present an analysis of the learned
network representations.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally to this work</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02588</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Influence of temporal aspects and age-correlations on the process of
  opinion formation based on Polish contact survey</dc:title>
 <dc:creator>Grabowski, Andrzej</dc:creator>
 <dc:creator>Jarynowski, Andrzej</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  On the basis of the experimental data concerning interactions between humans
the process of Ising-based model of opinion formation in a social network was
investigated. In the paper the data concerning human social activity, i.e.
frequency and duration time of interpersonal interactions as well as age
correlations - homophily are presented in comparison to base line homogeneous,
static and uniform mixing. It is known from previous studies that number of
contact and average age of nearest neighbors are highly correlated with age of
an individual. Such real, assortative patterns usually speed up processes (like
epidemic spread) on the networks, but here it only plays a role for small
social temperature values (by reducing `freezing by heating' effect). A real
structure of contacts affects processes in many various studies in different
way, however here it causes stronger (dynamic) and smoother (durations)
susceptibility on external field. Moreover, our research shows that the cross
interactions between contact frequency and its duration impose the significant
increase in critical temperature.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02598</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Pricing as an Enabler of Cyber-Insurance: A First Look at
  Differentiated Pricing Markets</dc:title>
 <dc:creator>Pal, Ranjan</dc:creator>
 <dc:creator>Golubchik, Leana</dc:creator>
 <dc:creator>Psounis, Konstantinos</dc:creator>
 <dc:creator>Hui, Pan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Despite the promising potential of network risk management services (e.g.,
cyber-insurance) to improve information security, their deployment is
relatively scarce, primarily due to such service companies being unable to
guarantee profitability. As a novel approach to making cyber-insurance services
more viable, we explore a symbiotic relationship between security vendors
(e.g., Symantec) capable of price differentiating their clients, and
cyber-insurance agencies having possession of information related to the
security investments of their clients. The goal of this relationship is to (i)
allow security vendors to price differentiate their clients based on security
investment information from insurance agencies, (ii) allow the vendors to make
more profit than in homogeneous pricing settings, and (iii) subsequently
transfer some of the extra profit to cyber-insurance agencies to make insurance
services more viable. \noindent In this paper, we perform a theoretical study
of a market for differentiated security product pricing, primarily with a view
to ensuring that security vendors (SVs) make more profit in the differentiated
pricing case as compared to the case of non-differentiated pricing. In order to
practically realize such pricing markets, we propose novel and
\emph{computationally efficient} consumer differentiated pricing mechanisms for
SVs based on (i) the market structure, (ii) the communication network structure
of SV consumers captured via a consumer's \emph{Bonacich centrality} in the
network, and (iii) security investment amounts made by SV consumers.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1101.5617 by other authors
  without attribution</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02613</identifier>
 <datestamp>2017-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New approach to Bayesian high-dimensional linear regression</dc:title>
 <dc:creator>Jalali, Shirin</dc:creator>
 <dc:creator>Maleki, Arian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Consider the problem of estimating parameters $X^n \in \mathbb{R}^n $,
generated by a stationary process, from $m$ response variables $Y^m =
AX^n+Z^m$, under the assumption that the distribution of $X^n$ is known. This
is the most general version of the Bayesian linear regression problem. The lack
of computationally feasible algorithms that can employ generic prior
distributions and provide a good estimate of $X^n$ has limited the set of
distributions researchers use to model the data. In this paper, a new scheme
called Q-MAP is proposed. The new method has the following properties: (i) It
has similarities to the popular MAP estimation under the noiseless setting.
(ii) In the noiseless setting, it achieves the &quot;asymptotically optimal
performance&quot; when $X^n$ has independent and identically distributed components.
(iii) It scales favorably with the dimensions of the problem and therefore is
applicable to high-dimensional setups. (iv) The solution of the Q-MAP
optimization can be found via a proposed iterative algorithm which is provably
robust to the error (noise) in the response variables.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:date>2017-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02632</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized, Self-organizing, Potential field-based Control for
  Individuallymotivated, Mobile Agents in a Cluttered Environment: A
  Vector-Harmonic Potential Field Approach</dc:title>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Spatial multi-agency has been receiving growing attention from researchers
exploring many of the aspects and modalities of this phenomenon. The aim is to
develop the theoretical background needed for a multitude of applications
involving the sharing of resources by more than one agent. A traffic management
system is one of these applications. Here, a large group of mobile robots that
are operating in communication-limited, and sensory-limited modes are required
to cope with each others presence as well as the contents of their environment
while preserving their ability to reach their preset, independent goals. This
work explores the construction of a decentralized traffic controller for a
large group of agents sharing a workspace with stationary forbidden regions.
The suggested multi-agent motion controller is complete provided that a lenient
condition on the geometry of the workspace is upheld. It has a low
computational effort that linearly increases with the number of agents. The
controller is also self-organizing; therefore, it is able to deal, on its own,
with incomplete information and unexpected situations. In addition to the
above, the controller has an open structure to enable any agent to join or
leave the group without the remaining agents having to adjust the manner in
which they function. To meet these requirements, a definition of
decentralization is suggested. This definition equates decentralization to
self-organization in a group of agents operating in an artificial life mode.
The definition is used to provide guidelines for the construction of the
multi-agent controller. The controller is realized using the potential field
approach. Theoretical developments, as well as simulation results, are
provided.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02632</dc:identifier>
 <dc:identifier>IEEE Transactions on Systems, Man, and Cybernetics - Part A:
  Systems and Humans, May 2007, Volume:37, Issue: 3, pp. 372-390</dc:identifier>
 <dc:identifier>doi:10.1109/TSMCA.2007.893483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02637</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Flows Under Thermal Restrictions</dc:title>
 <dc:creator>Sarwari, Samiksha</dc:creator>
 <dc:creator>Rao, Shrisha</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C21,</dc:subject>
 <dc:description>  We define a \emph{thermal network}, which is a network where the flow
functionality of a node depends upon its temperature. This model is inspired by
several types of real-life networks, and generalizes some conventional network
models wherein nodes have fixed capacities and the problem is to maximize the
flow through the network. In a thermal network, the temperature of a node
increases as traffic moves through it, and nodes may also cool spontaneously
over time, or by employing cooling packets. We analyze the problems of
maximizing the flow from a source to a sink for both these cases, for a
holistic view with respect to the single-source-single-sink dynamic flow
problem in a thermal network. We have studied certain properties such a thermal
network exhibits, and give closed-form solutions for the maximum flow that can
be achieved through such a network.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02641</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomised Relevance Model</dc:title>
 <dc:creator>Wurzer, Dominik</dc:creator>
 <dc:creator>Osborne, Miles</dc:creator>
 <dc:creator>Lavrenko, Victor</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Relevance Models are well-known retrieval models and capable of producing
competitive results. However, because they use query expansion they can be very
slow. We address this slowness by incorporating two variants of locality
sensitive hashing (LSH) into the query expansion process. Results on two
document collections suggest that we can obtain large reductions in the amount
of work, with a small reduction in effectiveness. Our approach is shown to be
additive when pruning query terms.
</dc:description>
 <dc:description>Comment: Information Retrieval, Query Expansion, Locality Sensitive Hashing,
  Randomized Algorithm, Relevance Model</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02643</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Deep Temporal Models for Group Activity Recognition</dc:title>
 <dc:creator>Ibrahim, Mostafa S.</dc:creator>
 <dc:creator>Muralidharan, Srikanth</dc:creator>
 <dc:creator>Deng, Zhiwei</dc:creator>
 <dc:creator>Vahdat, Arash</dc:creator>
 <dc:creator>Mori, Greg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present an approach for classifying the activity performed
by a group of people in a video sequence. This problem of group activity
recognition can be addressed by examining individual person actions and their
relations. Temporal dynamics exist both at the level of individual person
actions as well as at the level of group activity. Given a video sequence as
input, methods can be developed to capture these dynamics at both person-level
and group-level detail. We build a deep model to capture these dynamics based
on LSTM (long short-term memory) models. In order to model both person-level
and group-level dynamics, we present a 2-stage deep temporal model for the
group activity recognition problem. In our approach, one LSTM model is designed
to represent action dynamics of individual people in a video sequence and
another LSTM model is designed to aggregate person-level information for group
activity recognition. We collected a new dataset consisting of volleyball
videos labeled with individual and group activities in order to evaluate our
method. Experimental results on this new Volleyball Dataset and the standard
benchmark Collective Activity Dataset demonstrate the efficacy of the proposed
models.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1511.06040</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02643</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02646</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Level Programming Abstractions for Distributed Graph Processing</dc:title>
 <dc:creator>Kalavri, Vasiliki</dc:creator>
 <dc:creator>Vlassov, Vladimir</dc:creator>
 <dc:creator>Haridi, Seif</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Efficient processing of large-scale graphs in distributed environments has
been an increasingly popular topic of research in recent years. Inter-connected
data that can be modeled as graphs arise in application domains such as machine
learning, recommendation, web search, and social network analysis. Writing
distributed graph applications is inherently hard and requires programming
models that can cover a diverse set of problem domains, including iterative
refinement algorithms, graph transformations, graph aggregations, pattern
matching, ego-network analysis, and graph traversals. Several high-level
programming abstractions have been proposed and adopted by distributed graph
processing systems and big data platforms. Even though significant work has
been done to experimentally compare distributed graph processing frameworks, no
qualitative study and comparison of graph programming abstractions has been
conducted yet. In this survey, we review and analyze the most prevalent
high-level programming models for distributed graph processing, in terms of
their semantics and applicability. We identify the classes of graph
applications that can be naturally expressed by each abstraction and we also
give examples of applications that are hard or impossible to express. We review
34 distributed graph processing systems with respect to their programming
abstractions, execution models, and communication mechanisms. Finally, we
discuss trends and open research questions in the area of distributed graph
processing.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02646</dc:identifier>
 <dc:identifier>doi:10.1109/TKDE.2017.2762294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02649</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear signal recovery from $b$-bit-quantized linear measurements:
  precise analysis of the trade-off between bit depth and number of
  measurements</dc:title>
 <dc:creator>Slawski, Martin</dc:creator>
 <dc:creator>Li, Ping</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  We consider the problem of recovering a high-dimensional structured signal
from independent Gaussian linear measurements each of which is quantized to $b$
bits. Our interest is in linear approaches to signal recovery, where &quot;linear&quot;
means that non-linearity resulting from quantization is ignored and the
observations are treated as if they arose from a linear measurement model.
Specifically, the focus is on a generalization of a method for one-bit
observations due to Plan and Vershynin [\emph{IEEE~Trans. Inform. Theory,
\textbf{59} (2013), 482--494}]. At the heart of the present paper is a precise
characterization of the optimal trade-off between the number of measurements
$m$ and the bit depth per measurement $b$ given a total budget of $B = m \cdot
b$ bits when the goal is to minimize the $\ell_2$-error in estimating the
signal. It turns out that the choice $b = 1$ is optimal for estimating the unit
vector (direction) corresponding to the signal for any level of additive
Gaussian noise before quantization as well as for a specific model of
adversarial noise, while the choice $b = 2$ is optimal for estimating the
direction and the norm (scale) of the signal. Moreover, Lloyd-Max quantization
is shown to be an optimal quantization scheme w.r.t. $\ell_2$-estimation error.
Our analysis is corroborated by numerical experiments showing nearly perfect
agreement with our theoretical predictions. The paper is complemented by an
empirical comparison to alternative methods of signal recovery taking the
non-linearity resulting from quantization into account. The results of that
comparison point to a regime change depending on the noise level: in a
low-noise setting, linear signal recovery falls short of more sophisticated
competitors while being competitive in moderate- and high-noise settings.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02652</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Affect Recognition using Kinect</dc:title>
 <dc:creator>Patwardhan, Amol</dc:creator>
 <dc:creator>Knapp, Gerald</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Affect (emotion) recognition has gained significant attention from
researchers in the past decade. Emotion-aware computer systems and devices have
many applications ranging from interactive robots, intelligent online tutor to
emotion based navigation assistant. In this research data from multiple
modalities such as face, head, hand, body and speech was utilized for affect
recognition. The research used color and depth sensing device such as Kinect
for facial feature extraction and tracking human body joints. Temporal features
across multiple frames were used for affect recognition. Event driven decision
level fusion was used to combine the results from each individual modality
using majority voting to recognize the emotions. The study also implemented
affect recognition by matching the features to the rule based emotion templates
per modality. Experiments showed that multimodal affect recognition rates using
combination of emotion templates and supervised learning were better compared
to recognition rates based on supervised learning alone. Recognition rates
obtained using temporal feature were higher compared to recognition rates
obtained using position based features only.
</dc:description>
 <dc:description>Comment: 9 pages, 2 tables, 1 figure, Peer reviewed in ACM TIST</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02653</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of KL Divergence: Optimal Minimax Rate</dc:title>
 <dc:creator>Bu, Yuheng</dc:creator>
 <dc:creator>Zou, Shaofeng</dc:creator>
 <dc:creator>Liang, Yingbin</dc:creator>
 <dc:creator>Veeravalli, Venugopal V.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of estimating the Kullback-Leibler divergence $D(P\|Q)$ between
two unknown distributions $P$ and $Q$ is studied, under the assumption that the
alphabet size $k$ of the distributions can scale to infinity. The estimation is
based on $m$ independent samples drawn from $P$ and $n$ independent samples
drawn from $Q$. It is first shown that there does not exist any consistent
estimator that guarantees asymptotically small worst-case quadratic risk over
the set of all pairs of distributions. A restricted set that contains pairs of
distributions, with density ratio bounded by a function $f(k)$ is further
considered. {An augmented plug-in estimator is proposed, and its worst-case
quadratic risk is shown to be within a constant factor of
$(\frac{k}{m}+\frac{kf(k)}{n})^2+\frac{\log ^2 f(k)}{m}+\frac{f(k)}{n}$, if $m$
and $n$ exceed a constant factor of $k$ and $kf(k)$, respectively.} Moreover,
the minimax quadratic risk is characterized to be within a constant factor of
$(\frac{k}{m\log k}+\frac{kf(k)}{n\log k})^2+\frac{\log ^2
f(k)}{m}+\frac{f(k)}{n}$, if $m$ and $n$ exceed a constant factor of
$k/\log(k)$ and $kf(k)/\log k$, respectively. The lower bound on the minimax
quadratic risk is characterized by employing a generalized Le Cam's method. A
minimax optimal estimator is then constructed by employing both the polynomial
approximation and the plug-in approaches.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02654</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining multiple resolutions into hierarchical representations for
  kernel-based image classification</dc:title>
 <dc:creator>Cui, Yanwei</dc:creator>
 <dc:creator>Lefevre, S&#xe9;bastien</dc:creator>
 <dc:creator>Chapel, Laetitia</dc:creator>
 <dc:creator>Puissant, Anne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Geographic object-based image analysis (GEOBIA) framework has gained
increasing interest recently. Following this popular paradigm, we propose a
novel multiscale classification approach operating on a hierarchical image
representation built from two images at different resolutions. They capture the
same scene with different sensors and are naturally fused together through the
hierarchical representation, where coarser levels are built from a Low Spatial
Resolution (LSR) or Medium Spatial Resolution (MSR) image while finer levels
are generated from a High Spatial Resolution (HSR) or Very High Spatial
Resolution (VHSR) image. Such a representation allows one to benefit from the
context information thanks to the coarser levels, and subregions spatial
arrangement information thanks to the finer levels. Two dedicated structured
kernels are then used to perform machine learning directly on the constructed
hierarchical representation. This strategy overcomes the limits of conventional
GEOBIA classification procedures that can handle only one or very few
pre-selected scales. Experiments run on an urban classification task show that
the proposed approach can highly improve the classification accuracy w.r.t.
conventional approaches working on a single scale.
</dc:description>
 <dc:description>Comment: International Conference on Geographic Object-Based Image Analysis
  (GEOBIA 2016), University of Twente in Enschede, The Netherlands</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02660</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Augmenting Supervised Emotion Recognition with Rule-Based Decision Model</dc:title>
 <dc:creator>Patwardhan, Amol</dc:creator>
 <dc:creator>Knapp, Gerald</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The aim of this research is development of rule based decision model for
emotion recognition. This research also proposes using the rules for augmenting
inter-corporal recognition accuracy in multimodal systems that use supervised
learning techniques. The classifiers for such learning based recognition
systems are susceptible to over fitting and only perform well on intra-corporal
data. To overcome the limitation this research proposes using rule based model
as an additional modality. The rules were developed using raw feature data from
visual channel, based on human annotator agreement and existing studies that
have attributed movement and postures to emotions. The outcome of the rule
evaluations was combined during the decision phase of emotion recognition
system. The results indicate rule based emotion recognition augment recognition
accuracy of learning based systems and also provide better recognition rate
across inter corpus emotion test data.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, 23 tables, IEEE TAC (in review)</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02665</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classifier Risk Estimation under Limited Labeling Resources</dc:title>
 <dc:creator>Kumar, Anurag</dc:creator>
 <dc:creator>Raj, Bhiksha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we propose strategies for estimating performance of a
classifier when labels cannot be obtained for the whole test set. The number of
test instances which can be labeled is very small compared to the whole test
data size. The goal then is to obtain a precise estimate of classifier
performance using as little labeling resource as possible. Specifically, we try
to answer, how to select a subset of the large test set for labeling such that
the performance of a classifier estimated on this subset is as close as
possible to the one on the whole test set. We propose strategies based on
stratified sampling for selecting this subset. We show that these strategies
can reduce the variance in estimation of classifier accuracy by a significant
amount compared to simple random sampling (over 65% in several cases). Hence,
our proposed methods are much more precise compared to random sampling for
accuracy estimation under restricted labeling resources. The reduction in
number of samples required (compared to random sampling) to estimate the
classifier accuracy with only 1% error is high as 60% in some cases.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02668</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Joint Power and Subcarrier Allocation for Full-Duplex
  Multicarrier Non-Orthogonal Multiple Access Systems</dc:title>
 <dc:creator>Sun, Yan</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate resource allocation algorithm design for
multicarrier non-orthogonal multiple access (MC-NOMA) systems employing a
full-duplex (FD) base station (BS) for serving multiple half-duplex (HD)
downlink (DL) and uplink (UL) users simultaneously. The proposed algorithm is
obtained from the solution of a non-convex optimization problem for the
maximization of the weighted sum system throughput. We apply monotonic
optimization to develop an optimal joint power and subcarrier allocation
policy. The optimal resource allocation policy serves as a system performance
benchmark due to its high computational complexity. Furthermore, a suboptimal
iterative scheme based on successive convex approximation is proposed to strike
a balance between computational complexity and optimality. Our simulation
results reveal that the proposed suboptimal algorithm achieves a
close-to-optimal performance. Besides, FD MC-NOMA systems employing the
proposed resource allocation algorithms provide a substantial system throughput
improvement compared to conventional HD multicarrier orthogonal multiple access
(MC-OMA) systems and other baseline schemes. Also, our results unveil that the
proposed FD MC-NOMA systems achieve a fairer resource allocation compared to
traditional HD MC-OMA systems.
</dc:description>
 <dc:description>Comment: Submitted for possible journal publication</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02669</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Model for Distributed Big Data Service Composition using
  Stratified Functional Graph Matching</dc:title>
 <dc:creator>Rivero, Carlos R.</dc:creator>
 <dc:creator>Jamil, Hasan M.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  A significant number of current industrial applications rely on web services.
A cornerstone task in these applications is discovering a suitable service that
meets the threshold of some user needs. Then, those services can be composed to
perform specific functionalities. We argue that the prevailing approach to
compose services based on the &quot;all or nothing&quot; paradigm is limiting and leads
to exceedingly high rejection of potentially suitable services. Furthermore,
contemporary models do not allow &quot;mix and match&quot; composition from atomic
services of different composite services when binary matching is not possible
or desired. In this paper, we propose a new model for service composition based
on &quot;stratified graph summarization&quot; and &quot;service stitching&quot;. We discuss the
limitations of existing approaches with a motivating example, present our
approach to overcome these limitations, and outline a possible architecture for
service composition from atomic services. Our thesis is that, with the advent
of Big Data, our approach will reduce latency in service discovery, and will
improve efficiency and accuracy of matchmaking and composition of services.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02674</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network-Wide Distributed Carrier Frequency Offsets Estimation and
  Compensation</dc:title>
 <dc:creator>Du, Jian</dc:creator>
 <dc:creator>Wu, Yik-Chung</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a fully distributed algorithm for frequency offsets
estimation in decentralized systems. With the proposed algorithm, each node
estimates its frequency offsets by local computations and limited exchange of
information with its direct neighbors. Such algorithm does not require any
centralized information processing or knowledge of global network topology. It
is shown analytically that the proposed algorithm always converges to the
optimal estimates regardless of network topology. Simulation results
demonstrate the fast convergence of the algorithm and show that estimation
mean-squared-error at each node touches the centralized Cram\'{e}r-Rao bound
within a few {iterations of message exchange}. Therefore, the proposed method
has low overhead and is scalable with network size.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02677</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Construction of Cyclic and Constacyclic Codes for b-symbol Read Channels
  Meeting the Plotkin-like Bound</dc:title>
 <dc:creator>Yang, Minghui</dc:creator>
 <dc:creator>Li, Jin</dc:creator>
 <dc:creator>Feng, Keqin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The symbol-pair codes over finite fields have been raised for symbol-pair
read channels and motivated by application of high-density data storage
technologies [1, 2]. Their generalization is the code for b-symbol read
channels (b &gt; 2). Many MDS codes for b-symbol read channels have been
constructed which meet the Singleton-like bound ([3, 4, 10] for b = 2 and [11]
for b &gt; 2). In this paper we show the Plotkin-like bound and present a
construction on irreducible cyclic codes and constacyclic codes meeting the
Plotkin-like bound.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02678</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards an &quot;In-the-Wild&quot; Emotion Dataset Using a Game-based Framework</dc:title>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Abtahi, Farnaz</dc:creator>
 <dc:creator>Tsangouri, Christina</dc:creator>
 <dc:creator>Zhu, Zhigang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In order to create an &quot;in-the-wild&quot; dataset of facial emotions with large
number of balanced samples, this paper proposes a game-based data collection
framework. The framework mainly include three components: a game engine, a game
interface, and a data collection and evaluation module. We use a deep learning
approach to build an emotion classifier as the game engine. Then a emotion web
game to allow gamers to enjoy the games, while the data collection module
obtains automatically-labelled emotion images. Using our game, we have
collected more than 15,000 images within a month of the test run and built an
emotion dataset &quot;GaMo&quot;. To evaluate the dataset, we compared the performance of
two deep learning models trained on both GaMo and CIFE. The results of our
experiments show that because of being large and balanced, GaMo can be used to
build a more robust emotion detector than the emotion detector trained on CIFE,
which was used in the game engine to collect the face images.
</dc:description>
 <dc:description>Comment: This paper is accepted at CVPR 2016 Workshop</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02681</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perturbation-Assisted PAPR Reduction for Large-Scale MIMO-OFDM Systems
  via ADMM</dc:title>
 <dc:creator>Bao, Hengyao</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:creator>Chen, Zhi</dc:creator>
 <dc:creator>Jiang, Tao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of peak-to-average power ratio (PAPR) reduction for
orthogonal frequency-division multiplexing (OFDM) based large-scale
multiple-input multipleoutput (MIMO) systems. A novel perturbation-assisted
scheme is developed to reduce the PAPRs of the transmitted signals by
exploiting the redundant degrees-of-freedom (DoFs) inherent in the large-scale
antenna array. Specifically, we introduce artificial perturbation signals to
the frequency-domain precoded signals, with the aim of reducing the PAPRs of
their time-domain counterpart signals. Meanwhile, the additive perturbation
signal associated with each tone is constrained to lie in the null-space of its
associated channel matrix, such that it does not cause any multi-user inference
or out-of-band radiations. Such a problem is formulated as a convex
optimization problem, and an efficient algorithm is developed by resorting to
the variable splitting and alterative direction method of multipliers (ADMM)
techniques. Simulation results show that the proposed method has a fast
convergence rate and achieves substantial PAPR reduction within only tens of
iterations. In addition, unlike other precoding-based PAPR reduction methods,
our proposed method which introduces perturbation signals to the precoded
signals is independent of the precoding stage and thus could be more suitable
for practical systems.
</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02682</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending Weakly-Sticky Datalog+/-: Query-Answering Tractability and
  Optimizations</dc:title>
 <dc:creator>Milani, Mostafa</dc:creator>
 <dc:creator>Bertossi, Leopoldo</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Weakly-sticky (WS) Datalog+/- is an expressive member of the family of
Datalog+/- programs that is based on the syntactic notions of stickiness and
weak-acyclicity. Query answering over the WS programs has been investigated,
but there is still much work to do on the design and implementation of
practical query answering (QA) algorithms and their optimizations. Here, we
study sticky and WS programs from the point of view of the behavior of the
chase procedure, extending the stickiness property of the chase to that of
generalized stickiness of the chase (gsch-property). With this property we
specify the semantic class of GSCh programs, which includes sticky and WS
programs, and other syntactic subclasses that we identify. In particular, we
introduce joint-weakly-sticky (JWS) programs, that include WS programs. We also
propose a bottom-up QA algorithm for a range of subclasses of GSCh. The
algorithm runs in polynomial time (in data) for JWS programs. Unlike the WS
class, JWS is closed under a general magic-sets rewriting procedure for the
optimization of programs with existential rules. We apply the magic-sets
rewriting in combination with the proposed QA algorithm for the optimization of
QA over JWS programs.
</dc:description>
 <dc:description>Comment: Extended version of RR'16 paper</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02687</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Evaluation of Automated Vehicles in Car-Following Maneuvers</dc:title>
 <dc:creator>Zhao, Ding</dc:creator>
 <dc:creator>Huang, Xianan</dc:creator>
 <dc:creator>Peng, Huei</dc:creator>
 <dc:creator>Lam, Henry</dc:creator>
 <dc:creator>LeBlanc, David J.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  The safety of Automated Vehicles (AVs) must be assured before their release
and deployment. The current approach to evaluation relies primarily on (i)
testing AVs on public roads or (ii) track testing with scenarios defined in a
test matrix. These two methods have completely opposing drawbacks: the former,
while offering realistic scenarios, takes too much time to execute; the latter,
though it can be completed in a short amount of time, has no clear correlation
to safety benefits in the real world. To avoid the aforementioned problems, we
propose Accelerated Evaluation, focusing on the car-following scenario. The
stochastic human-controlled vehicle (HV) motions are modeled based on 1.3
million miles of naturalistic driving data collected by the University of
Michigan Safety Pilot Model Deployment Program. The statistics of the HV
behaviors are then modified to generate more intense interactions between HVs
and AVs to accelerate the evaluation procedure. The Importance Sampling theory
was used to ensure that the safety benefits of AVs are accurately assessed
under accelerated tests. Crash, injury and conflict rates for a simulated AV
are simulated to demonstrate the proposed approach. Results show that test
duration is reduced by a factor of 300 to 100,000 compared with the
non-accelerated (naturalistic) evaluation. In other words, the proposed
techniques have great potential for accelerating the AV evaluation process.
</dc:description>
 <dc:description>Comment: 11 pages, 11 figures</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:date>2017-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02694</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the 4th International Workshop on Strategic Reasoning</dc:title>
 <dc:creator>Lomuscio, Alessio</dc:creator>
 <dc:creator>Vardi, Moshe Y.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This volume contains the proceedings of the Fourth International Workshop on
Strategic Reasoning (SR 2016), held in New York City (USA), July 10, 2016. The
workshop consisted of 2 keynote talks and 9 contributed presentations on themes
of logic, verification, games and equilibria.
  More information about the Strategic Workshop series is available at
http://www.strategicreasoning.net/
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02694</dc:identifier>
 <dc:identifier>EPTCS 218, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02699</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>At Every Corner: Determining Corner Points of Two-User Gaussian
  Interference Channels</dc:title>
 <dc:creator>Rioul, Olivier</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The corner points of the capacity region of the two-user Gaussian
interference channel under strong or weak interference are determined using the
notions of almost Gaussian random vectors, almost lossless addition of random
vectors, and almost linearly dependent random vectors. In particular, the
&quot;missing&quot; corner point problem is solved in a manner that differs from previous
works in that it avoids the use of integration over a continuum of SNR values
or of Monge-Kantorovitch transportation problems.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02705</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dealing with Class Imbalance using Thresholding</dc:title>
 <dc:creator>Hong, Charmgil</dc:creator>
 <dc:creator>Ghosh, Rumi</dc:creator>
 <dc:creator>Srinivasan, Soundar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose thresholding as an approach to deal with class imbalance. We
define the concept of thresholding as a process of determining a decision
boundary in the presence of a tunable parameter. The threshold is the maximum
value of this tunable parameter where the conditions of a certain decision are
satisfied. We show that thresholding is applicable not only for linear
classifiers but also for non-linear classifiers. We show that this is the
implicit assumption for many approaches to deal with class imbalance in linear
classifiers. We then extend this paradigm beyond linear classification and show
how non-linear classification can be dealt with under this umbrella framework
of thresholding. The proposed method can be used for outlier detection in many
real-life scenarios like in manufacturing. In advanced manufacturing units,
where the manufacturing process has matured over time, the number of instances
(or parts) of the product that need to be rejected (based on a strict regime of
quality tests) becomes relatively rare and are defined as outliers. How to
detect these rare parts or outliers beforehand? How to detect combination of
conditions leading to these outliers? These are the questions motivating our
research. This paper focuses on prediction of outliers and conditions leading
to outliers using classification. We address the problem of outlier detection
using classification. The classes are good parts (those passing the quality
tests) and bad parts (those failing the quality tests and can be considered as
outliers). The rarity of outliers transforms this problem into a
class-imbalanced classification problem.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02714</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Leakage through Innocent Content Sharing in Online Social
  Networks</dc:title>
 <dc:creator>Veiga, Maria Han</dc:creator>
 <dc:creator>Eickhoff, Carsten</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The increased popularity and ubiquitous availability of online social
networks and globalised Internet access have affected the way in which people
share content. The information that users willingly disclose on these platforms
can be used for various purposes, from building consumer models for
advertising, to inferring personal, potentially invasive, information. In this
work, we use Twitter, Instagram and Foursquare data to convey the idea that the
content shared by users, especially when aggregated across platforms, can
potentially disclose more information than was originally intended. We perform
two case studies: First, we perform user de-anonymization by mimicking the
scenario of finding the identity of a user making anonymous posts within a
group of users. Empirical evaluation on a sample of real-world social network
profiles suggests that cross-platform aggregation introduces significant
performance gains in user identification. In the second task, we show that it
is possible to infer physical location visits of a user on the basis of shared
Twitter and Instagram content. We present an informativeness scoring function
which estimates the relevance and novelty of a shared piece of information with
respect to an inference task. This measure is validated using an active
learning framework which chooses the most informative content at each given
point in time. Based on a large-scale data sample, we show that by doing this,
we can attain an improved inference performance. In some cases this performance
exceeds even the use of the user's full timeline.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures, submitted to Privacy Preserving Workshop, Sigir</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02715</identifier>
 <datestamp>2016-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Sketch Human Facial Portraits using Personal Styles by
  Case-Based Reasoning</dc:title>
 <dc:creator>Jin, Bingwen</dc:creator>
 <dc:creator>Xu, Songhua</dc:creator>
 <dc:creator>Geng, Weidong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper employs case-based reasoning (CBR) to capture the personal styles
of individual artists and generate the human facial portraits from photos
accordingly. For each human artist to be mimicked, a series of cases are
firstly built-up from her/his exemplars of source facial photo and hand-drawn
sketch, and then its stylization for facial photo is transformed as a
style-transferring process of iterative refinement by looking-for and applying
best-fit cases in a sense of style optimization. Two models, fitness evaluation
model and parameter estimation model, are learned for case retrieval and
adaptation respectively from these cases. The fitness evaluation model is to
decide which case is best-fitted to the sketching of current interest, and the
parameter estimation model is to automate case adaptation. The resultant sketch
is synthesized progressively with an iterative loop of retrieval and adaptation
of candidate cases until the desired aesthetic style is achieved. To explore
the effectiveness and advantages of the novel approach, we experimentally
compare the sketch portraits generated by the proposed method with that of a
state-of-the-art example-based facial sketch generation algorithm as well as a
couple commercial software packages. The comparisons reveal that our CBR based
synthesis method for facial portraits is superior both in capturing and
reproducing artists' personal illustration styles to the peer methods.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2016-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02717</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The BioDynaMo Project</dc:title>
 <dc:creator>Bauer, Roman</dc:creator>
 <dc:creator>Breitwieser, Lukas</dc:creator>
 <dc:creator>Di Meglio, Alberto</dc:creator>
 <dc:creator>Johard, Leonard</dc:creator>
 <dc:creator>Kaiser, Marcus</dc:creator>
 <dc:creator>Manca, Marco</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Talanov, Max</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Computer simulations have become a very powerful tool for scientific
research. Given the vast complexity that comes with many open scientific
questions, a purely analytical or experimental approach is often not viable.
For example, biological systems (such as the human brain) comprise an extremely
complex organization and heterogeneous interactions across different spatial
and temporal scales. In order to facilitate research on such problems, the
BioDynaMo project (\url{https://biodynamo.web.cern.ch/}) aims at a general
platform for computer simulations for biological research. Since the scientific
investigations require extensive computer resources, this platform should be
executable on hybrid cloud computing systems, allowing for the efficient use of
state-of-the-art computing technology. This paper describes challenges during
the early stages of the software development process. In particular, we
describe issues regarding the implementation and the highly interdisciplinary
as well as international nature of the collaboration. Moreover, we explain the
methodologies, the approach, and the lessons learnt by the team during these
first stages.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02720</identifier>
 <datestamp>2016-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intra-layer Nonuniform Quantization for Deep Convolutional Neural
  Network</dc:title>
 <dc:creator>Sun, Fangxuan</dc:creator>
 <dc:creator>Lin, Jun</dc:creator>
 <dc:creator>Wang, Zhongfeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional neural network (DCNN) has achieved remarkable performance
on object detection and speech recognition in recent years. However, the
excellent performance of a DCNN incurs high computational complexity and large
memory requirement. In this paper, an equal distance nonuniform quantization
(ENQ) scheme and a K-means clustering nonuniform quantization (KNQ) scheme are
proposed to reduce the required memory storage when low complexity hardware or
software implementations are considered. For the VGG-16 and the AlexNet, the
proposed nonuniform quantization schemes reduce the number of required memory
storage by approximately 50\% while achieving almost the same or even better
classification accuracy compared to the state-of-the-art quantization method.
Compared to the ENQ scheme, the proposed KNQ scheme provides a better tradeoff
when higher accuracy is required.
</dc:description>
 <dc:description>Comment: submitted to WCSP 2016</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2016-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02725</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-Grained Complexity Analysis of Two Classic TSP Variants</dc:title>
 <dc:creator>de Berg, Mark</dc:creator>
 <dc:creator>Buchin, Kevin</dc:creator>
 <dc:creator>Jansen, Bart M. P.</dc:creator>
 <dc:creator>Woeginger, Gerhard</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>05C85, 68R10, 68U05</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  We analyze two classic variants of the Traveling Salesman Problem using the
toolkit of fine-grained complexity. Our first set of results is motivated by
the Bitonic TSP problem: given a set of $n$ points in the plane, compute a
shortest tour consisting of two monotone chains. It is a classic
dynamic-programming exercise to solve this problem in $O(n^2)$ time. While the
near-quadratic dependency of similar dynamic programs for Longest Common
Subsequence and Discrete Frechet Distance has recently been proven to be
essentially optimal under the Strong Exponential Time Hypothesis, we show that
bitonic tours can be found in subquadratic time. More precisely, we present an
algorithm that solves bitonic TSP in $O(n \log^2 n)$ time and its bottleneck
version in $O(n \log^3 n)$ time. Our second set of results concerns the popular
$k$-OPT heuristic for TSP in the graph setting. More precisely, we study the
$k$-OPT decision problem, which asks whether a given tour can be improved by a
$k$-OPT move that replaces $k$ edges in the tour by $k$ new edges. A simple
algorithm solves $k$-OPT in $O(n^k)$ time for fixed $k$. For 2-OPT, this is
easily seen to be optimal. For $k=3$ we prove that an algorithm with a runtime
of the form $\tilde{O}(n^{3-\epsilon})$ exists if and only if All-Pairs
Shortest Paths in weighted digraphs has such an algorithm. The results for
$k=2,3$ may suggest that the actual time complexity of $k$-OPT is
$\Theta(n^k)$. We show that this is not the case, by presenting an algorithm
that finds the best $k$-move in $O(n^{\lfloor 2k/3 \rfloor + 1})$ time for
fixed $k \geq 3$. This implies that 4-OPT can be solved in $O(n^3)$ time,
matching the best-known algorithm for 3-OPT. Finally, we show how to beat the
quadratic barrier for $k=2$ in two important settings, namely for points in the
plane and when we want to solve 2-OPT repeatedly.
</dc:description>
 <dc:description>Comment: Extended abstract appears in the Proceedings of the 43rd
  International Colloquium on Automata, Languages, and Programming (ICALP 2016)</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02733</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Limited Scale-free Topology with Dynamic Peer Participation</dc:title>
 <dc:creator>Lu, Xiaoyan</dc:creator>
 <dc:creator>Bulut, Eyuphan</dc:creator>
 <dc:creator>Szymanski, Boleslaw</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Growth models have been proposed for constructing the scale-free overlay
topology to improve the performance of unstructured peer-to-peer (P2P)
networks. However, previous growth models are able to maintain the limited
scale-free topology when nodes only join but do not leave the network; the case
of nodes leaving the network while preserving a precise scaling parameter is
not included in the solution. Thus, the full dynamic of node participation,
inherent in P2P networks, is not considered in these models. In order to handle
both nodes joining and leaving the network, we propose a robust growth model
E-SRA, which is capable of producing the perfect limited scale-free overlay
topology with user-defined scaling parameter and hard cut-offs. Scalability of
our approach is ensured since no global information is required to add or
remove a node. E-SRA is also tolerant to individual node failure caused by
errors or attacks. Simulations have shown that E-SRA outperforms other growth
models by producing topologies with high adherence to the desired scale-free
property. Search algorithms, including flooding and normalized flooding,
achieve higher efficiency over the topologies produced by E-SRA.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02733</dc:identifier>
 <dc:identifier>Computer Networks, 106:109-121, 4 Septembe (2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.comnet.2016.06.019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02734</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AccuracyTrader: Accuracy-aware Approximate Processing for Low Tail
  Latency and High Result Accuracy in Cloud Online Services</dc:title>
 <dc:creator>Han, Rui</dc:creator>
 <dc:creator>Huang, Siguang</dc:creator>
 <dc:creator>Tang, Fei</dc:creator>
 <dc:creator>Chang, Fugui</dc:creator>
 <dc:creator>Zhan, Jianfeng</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Modern latency-critical online services such as search engines often process
requests by consulting large input data spanning massive parallel components.
Hence the tail latency of these components determines the service latency. To
trade off result accuracy for tail latency reduction, existing techniques use
the components responding before a specified deadline to produce approximate
results. However, they may skip a large proportion of components when load gets
heavier, thus incurring large accuracy losses. This paper presents
AccuracyTrader that produces approximate results with small accuracy losses
while maintaining low tail latency. AccuracyTrader aggregates information of
input data on each component to create a small synopsis, thus enabling all
components producing initial results quickly using their synopses.
AccuracyTrader also uses synopses to identify the parts of input data most
related to arbitrary requests' result accuracy, thus first using these parts to
improve the produced results in order to minimize accuracy losses. We evaluated
AccuracyTrader using workloads in real services. The results show: (i)
AccuracyTrader reduces tail latency by over 40 times with accuracy losses of
less than 7% compared to existing exact processing techniques; (ii) when using
the same latency, AccuracyTrader reduces accuracy losses by over 13 times
comparing to existing approximate processing techniques.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures, 2 tables</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02734</dc:identifier>
 <dc:identifier>The 45th International Conference on Parallel Processing
  (ICPP-2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02737</identifier>
 <datestamp>2017-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transition Forests: Learning Discriminative Temporal Transitions for
  Action Recognition and Detection</dc:title>
 <dc:creator>Garcia-Hernando, Guillermo</dc:creator>
 <dc:creator>Kim, Tae-Kyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A human action can be seen as transitions between one's body poses over time,
where the transition depicts a temporal relation between two poses. Recognizing
actions thus involves learning a classifier sensitive to these pose transitions
as well as to static poses. In this paper, we introduce a novel method called
transitions forests, an ensemble of decision trees that both learn to
discriminate static poses and transitions between pairs of two independent
frames. During training, node splitting is driven by alternating two criteria:
the standard classification objective that maximizes the discrimination power
in individual frames, and the proposed one in pairwise frame transitions.
Growing the trees tends to group frames that have similar associated
transitions and share same action label incorporating temporal information that
was not available otherwise. Unlike conventional decision trees where the best
split in a node is determined independently of other nodes, the transition
forests try to find the best split of nodes jointly (within a layer) for
incorporating distant node transitions. When inferring the class label of a new
frame, it is passed down the trees and the prediction is made based on previous
frame predictions and the current one in an efficient and online manner. We
apply our method on varied skeleton action recognition and online detection
datasets showing its suitability over several baselines and state-of-the-art
approaches.
</dc:description>
 <dc:description>Comment: to appear in CVPR 2017</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2017-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02744</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applied Lyapunov Stability on Output Tracking Problem for a Class of
  Discrete-Time Linear Systems</dc:title>
 <dc:creator>Zakary, Omar</dc:creator>
 <dc:creator>Rachik, Mostafa</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The robust tracking and model following problem of linear discrete-time
systems is investigated in this paper. An approach to design robust tracking
controllers is proposed. The system is controlled to track dynamic inputs
generated from a reference model. By using the solution of the Lyapunov
equation, the convergence of the tracking error to the origin, is proved. The
proposed approach employs linear controllers rather than nonlinear ones.
Therefore, the designing method is simple for use and the resulting controller
is easy to implement. An application of the proposed approach for a class of
perturbed systems is also considered. Finally, numerical examples are given to
demonstrate the validity of the results.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02744</dc:identifier>
 <dc:identifier>IOSR Journal of Electrical and Electronics Engineering,
  International Organization of Scientific Research (IOSR), 2016, 12 (1),
  pp.11-17</dc:identifier>
 <dc:identifier>doi:10.9790/5728-12121117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02748</identifier>
 <datestamp>2016-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Training For Sketch Retrieval</dc:title>
 <dc:creator>Creswell, Antonia</dc:creator>
 <dc:creator>Bharath, Anil Anthony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generative Adversarial Networks (GAN) are able to learn excellent
representations for unlabelled data which can be applied to image generation
and scene classification. Representations learned by GANs have not yet been
applied to retrieval. In this paper, we show that the representations learned
by GANs can indeed be used for retrieval. We consider heritage documents that
contain unlabelled Merchant Marks, sketch-like symbols that are similar to
hieroglyphs. We introduce a novel GAN architecture with design features that
make it suitable for sketch retrieval. The performance of this sketch-GAN is
compared to a modified version of the original GAN architecture with respect to
simple invariance properties. Experiments suggest that sketch-GANs learn
representations that are suitable for retrieval and which also have increased
stability to rotation, scale and translation compared to the standard GAN
architecture.
</dc:description>
 <dc:description>Comment: Accepted to ECCV2016 VisArt Workshop</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02748</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-46604-0_55</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02754</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Recommender System Based on Personal Behavior Mining</dc:title>
 <dc:creator>Fang, Zhiyuan</dc:creator>
 <dc:creator>Zhang, Lingqi</dc:creator>
 <dc:creator>Chen, Kun</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommender systems are mostly well known for their applications in
e-commerce sites and are mostly static models. Classical personalized
recommender algorithm includes item-based collaborative filtering method
applied in Amazon, matrix factorization based collaborative filtering algorithm
from Netflix, etc. In this article, we hope to combine traditional model with
behavior pattern extraction method. We use desensitized mobile transaction
record provided by T-mall, Alibaba to build a hybrid dynamic recommender
system. The sequential pattern mining aims to find frequent sequential pattern
in sequence database and is applied in this hybrid model to predict customers'
payment behavior thus contributing to the accuracy of the model.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02757</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory Unscented Particle Filter for 6-DOF Tactile Localization</dc:title>
 <dc:creator>Vezzani, Giulia</dc:creator>
 <dc:creator>Pattacini, Ugo</dc:creator>
 <dc:creator>Battistelli, Giorgio</dc:creator>
 <dc:creator>Chisci, Luigi</dc:creator>
 <dc:creator>Natale, Lorenzo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper addresses 6-DOF (degree-of-freedom) tactile localization, i.e. the
pose estimation of tridimensional objects given tactile measurements. This
estimation problem is fundamental for the operation of autonomous robots that
are often required to manipulate and grasp objects whose pose is a-priori
unknown. The nature of tactile measurements, the strict time requirements for
real-time operation and the multimodality of the involved probability
distributions pose remarkable challenges and call for advanced nonlinear
filtering techniques. Following a Bayesian approach, this paper proposes a
novel and effective algorithm, named Memory Unscented Particle Filter (MUPF),
which solves the 6-DOF localization problem recursively in real-time by only
exploiting contact point measurements. MUPF combines a modified particle filter
that incorporates a sliding memory of past measurements to better handle
multimodal distributions, along with the unscented Kalman filter that moves the
particles towards regions of the search space that are more likely with the
measurements. The performance of the proposed MUPF algorithm has been assessed
both in simulation and on a real robotic system equipped with tactile sensors
(i.e., the iCub humanoid robot). The experiments show that the algorithm
provides accurate and reliable localization even with a low number of particles
and, hence, is compatible with real-time requirements.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02757</dc:identifier>
 <dc:identifier>doi:10.1109/TRO.2017.2707092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02760</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Hybrid Power State Estimation under PMU Sampling Phase
  Errors</dc:title>
 <dc:creator>Du, Jian</dc:creator>
 <dc:creator>Ma, Shaodan</dc:creator>
 <dc:creator>Wu, Yik-Chung</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Phasor measurement units (PMUs) have the advantage of providing direct
measurements of power states. However, as the number of PMUs in a power system
is limited, the traditional supervisory control and data acquisition (SCADA)
system cannot be replaced by the PMU-based system overnight. Therefore, hybrid
power state estimation taking advantage of both systems is important. As
experiments show that sampling phase errors among PMUs are inevitable in
practical deployment, this paper proposes a distributed power state estimation
algorithm under PMU phase errors. The proposed distributed algorithm only
involves local computations and limited information exchange between
neighboring areas, thus alleviating the heavy communication burden compared to
the centralized approach. Simulation results show that the performance of the
proposed algorithm is very close to that of centralized optimal hybrid state
estimates without sampling phase error.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02763</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Allocate Resources For Features Acquisition?</dc:title>
 <dc:creator>Richman, Oran</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study classification problems where features are corrupted by noise and
where the magnitude of the noise in each feature is influenced by the resources
allocated to its acquisition. This is the case, for example, when multiple
sensors share a common resource (power, bandwidth, attention, etc.). We develop
a method for computing the optimal resource allocation for a variety of
scenarios and derive theoretical bounds concerning the benefit that may arise
by non-uniform allocation. We further demonstrate the effectiveness of the
developed method in simulations.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02766</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Internet of Things: Can UAVs Provide an Energy-Efficient Mobile
  Architecture?</dc:title>
 <dc:creator>Mozaffari, Mohammad</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Debbah, Merouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the optimal trajectory and deployment of multiple unmanned
aerial vehicles (UAVs), used as aerial base stations to collect data from
ground Internet of Things (IoT) devices, is investigated. In particular, to
enable reliable uplink communications for IoT devices with a minimum energy
consumption, a new approach for optimal mobility of the UAVs is proposed.
First, given a fixed ground IoT network, the total transmit power of the
devices is minimized by properly clustering the IoT devices with each cluster
being served by one UAV. Next, to maintain energy-efficient communications in
time-varying mobile IoT networks, the optimal trajectories of the UAVs are
determined by exploiting the framework of optimal transport theory. Simulation
results show that by using the proposed approach, the total transmit power of
IoT devices for reliable uplink communications can be reduced by 56% compared
to the fixed Voronoi deployment method. Moreover, our results yield the optimal
paths that will be used by UAVs to serve the mobile IoT devices with a minimum
energy consumption.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Global Communications Conference (GLOBECOM), 2016</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02769</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Annotation Methodologies for Vision and Language Dataset Creation</dc:title>
 <dc:creator>Kehat, Gitit</dc:creator>
 <dc:creator>Pustejovsky, James</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Annotated datasets are commonly used in the training and evaluation of tasks
involving natural language and vision (image description generation, action
recognition and visual question answering). However, many of the existing
datasets reflect problems that emerge in the process of data selection and
annotation. Here we point out some of the difficulties and problems one
confronts when creating and validating annotated vision and language datasets.
</dc:description>
 <dc:description>Comment: in Scene Understanding Workshop (SUNw) in CVPR 2016</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02770</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling-based bottleneck pathfinding with applications to Frechet
  matching</dc:title>
 <dc:creator>Solovey, Kiril</dc:creator>
 <dc:creator>Halperin, Dan</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We describe a general probabilistic framework to address a variety of
Frechet-distance optimization problems. Specifically, we are interested in
finding minimal bottleneck-paths in $d$-dimensional Euclidean space between
given start and goal points, namely paths that minimize the maximal value over
a continuous cost map. We present an efficient and simple sampling-based
framework for this problem, which is inspired by, and draws ideas from,
techniques for robot motion planning. We extend the framework to handle not
only standard bottleneck pathfinding, but also the more demanding case, where
the path needs to be monotone in all dimensions. Finally, we provide
experimental results of the framework on several types of problems.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02784</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open Information Extraction</dc:title>
 <dc:creator>Vo, Duc-Thuan</dc:creator>
 <dc:creator>Bagheri, Ebrahim</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Open Information Extraction (Open IE) systems aim to obtain relation tuples
with highly scalable extraction in portable across domain by identifying a
variety of relation phrases and their arguments in arbitrary sentences. The
first generation of Open IE learns linear chain models based on unlexicalized
features such as Part-of-Speech (POS) or shallow tags to label the intermediate
words between pair of potential arguments for identifying extractable
relations. Open IE currently is developed in the second generation that is able
to extract instances of the most frequently observed relation types such as
Verb, Noun and Prep, Verb and Prep, and Infinitive with deep linguistic
analysis. They expose simple yet principled ways in which verbs express
relationships in linguistics such as verb phrase-based extraction or
clause-based extraction. They obtain a significantly higher performance over
previous systems in the first generation. In this paper, we describe an
overview of two Open IE generations including strengths, weaknesses and
application areas.
</dc:description>
 <dc:description>Comment: This paper will appear in the Encyclopedia for Semantic Computing</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02784</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02785</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Violator spaces vs closure spaces</dc:title>
 <dc:creator>Kempner, Yulia</dc:creator>
 <dc:creator>Levit, Vadim E.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  Violator Spaces were introduced by J. Matousek et al. in 2008 as
generalization of Linear Programming problems. Convex geometries were invented
by Edelman and Jamison in 1985 as proper combinatorial abstractions of
convexity. Convex geometries are defined by anti-exchange closure operators. We
investigate an interrelations between violator spaces and closure spaces and
show that violator mapping may be defined by a week version of closure
operators. Moreover, we prove that violator spaces with an unique basis
satisfies the anti-exchange and the Krein-Milman properties.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02789</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Charagram: Embedding Words and Sentences via Character n-grams</dc:title>
 <dc:creator>Wieting, John</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:creator>Gimpel, Kevin</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present Charagram embeddings, a simple approach for learning
character-based compositional models to embed textual sequences. A word or
sentence is represented using a character n-gram count vector, followed by a
single nonlinear transformation to yield a low-dimensional embedding. We use
three tasks for evaluation: word similarity, sentence similarity, and
part-of-speech tagging. We demonstrate that Charagram embeddings outperform
more complex architectures based on character-level recurrent and convolutional
neural networks, achieving new state-of-the-art performance on several
similarity tasks.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02790</identifier>
 <datestamp>2017-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyper Normalisation and Conditioning for Discrete Probability
  Distributions</dc:title>
 <dc:creator>Jacobs, Bart</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>18C10</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Normalisation in probability theory turns a subdistribution into a proper
distribution. It is a partial operation, since it is undefined for the zero
subdistribution. This partiality makes it hard to reason equationally about
normalisation. A novel description of normalisation is given as a
mathematically well-behaved total function. The output of this `hyper'
normalisation operation is a distribution of distributions. It improves
reasoning about normalisation.
  After developing the basics of this theory of (hyper) normalisation, it is
put to use in a similarly new description of conditioning, producing a
distribution of conditional distributions. This is used to give a clean
abstract reformulation of refinement in quantitative information flow.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02790</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 3 (August
  29, 2017) lmcs:3885</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(3:17)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02791</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Syntactic Phylogenetic Trees</dc:title>
 <dc:creator>Shu, Kevin</dc:creator>
 <dc:creator>Aziz, Sharjeel</dc:creator>
 <dc:creator>Huynh, Vy-Luan</dc:creator>
 <dc:creator>Warrick, David</dc:creator>
 <dc:creator>Marcolli, Matilde</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>91F20, 13P10</dc:subject>
 <dc:description>  In this paper we identify several serious problems that arise in the use of
syntactic data from the SSWL database for the purpose of computational
phylogenetic reconstruction. We show that the most naive approach fails to
produce reliable linguistic phylogenetic trees. We identify some of the sources
of the observed problems and we discuss how they may be, at least partly,
corrected by using additional information, such as prior subdivision into
language families and subfamilies, and a better use of the information about
ancient languages. We also describe how the use of phylogenetic algebraic
geometry can help in estimating to what extent the probability distribution at
the leaves of the phylogenetic tree obtained from the SSWL data can be
considered reliable, by testing it on phylogenetic trees established by other
forms of linguistic analysis. In simple examples, we find that, after
restricting to smaller language subfamilies and considering only those SSWL
parameters that are fully mapped for the whole subfamily, the SSWL data match
extremely well reliable phylogenetic trees, according to the evaluation of
phylogenetic invariants. This is a promising sign for the use of SSWL data for
linguistic phylogenetics.
</dc:description>
 <dc:description>Comment: 21 pages, LaTeX, jpg figures</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02793</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Faster Convergence of Cyclic Block Coordinate Descent-type Methods
  for Strongly Convex Minimization</dc:title>
 <dc:creator>Li, Xingguo</dc:creator>
 <dc:creator>Zhao, Tuo</dc:creator>
 <dc:creator>Arora, Raman</dc:creator>
 <dc:creator>Liu, Han</dc:creator>
 <dc:creator>Hong, Mingyi</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The cyclic block coordinate descent-type (CBCD-type) methods, which performs
iterative updates for a few coordinates (a block) simultaneously throughout the
procedure, have shown remarkable computational performance for solving strongly
convex minimization problems. Typical applications include many popular
statistical machine learning methods such as elastic-net regression, ridge
penalized logistic regression, and sparse additive regression. Existing
optimization literature has shown that for strongly convex minimization, the
CBCD-type methods attain iteration complexity of
$\mathcal{O}(p\log(1/\epsilon))$, where $\epsilon$ is a pre-specified accuracy
of the objective value, and $p$ is the number of blocks. However, such
iteration complexity explicitly depends on $p$, and therefore is at least $p$
times worse than the complexity $\mathcal{O}(\log(1/\epsilon))$ of gradient
descent (GD) methods. To bridge this theoretical gap, we propose an improved
convergence analysis for the CBCD-type methods. In particular, we first show
that for a family of quadratic minimization problems, the iteration complexity
$\mathcal{O}(\log^2(p)\cdot\log(1/\epsilon))$ of the CBCD-type methods matches
that of the GD methods in term of dependency on $p$, up to a $\log^2 p$ factor.
Thus our complexity bounds are sharper than the existing bounds by at least a
factor of $p/\log^2(p)$. We also provide a lower bound to confirm that our
improved complexity bounds are tight (up to a $\log^2 (p)$ factor), under the
assumption that the largest and smallest eigenvalues of the Hessian matrix do
not scale with $p$. Finally, we generalize our analysis to other strongly
convex minimization problems beyond quadratic ones.
</dc:description>
 <dc:description>Comment: Accepted by JLMR</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02801</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds on the Number of Measurements for Reliable Compressive
  Classification</dc:title>
 <dc:creator>Reboredo, Hugo</dc:creator>
 <dc:creator>Renna, Francesco</dc:creator>
 <dc:creator>Calderbank, Robert</dc:creator>
 <dc:creator>Rodrigues, Miguel R. D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper studies the classification of high-dimensional Gaussian signals
from low-dimensional noisy, linear measurements. In particular, it provides
upper bounds (sufficient conditions) on the number of measurements required to
drive the probability of misclassification to zero in the low-noise regime,
both for random measurements and designed ones. Such bounds reveal two
important operational regimes that are a function of the characteristics of the
source: i) when the number of classes is less than or equal to the dimension of
the space spanned by signals in each class, reliable classification is possible
in the low-noise regime by using a one-vs-all measurement design; ii) when the
dimension of the spaces spanned by signals in each class is lower than the
number of classes, reliable classification is guaranteed in the low-noise
regime by using a simple random measurement design. Simulation results both
with synthetic and real data show that our analysis is sharp, in the sense that
it is able to gauge the number of measurements required to drive the
misclassification probability to zero in the low-noise regime.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures, 4 tables. Submitted to the IEEE Transactions on
  Signal Processing</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2016-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02801</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2599496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02802</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping distributional to model-theoretic semantic spaces: a baseline</dc:title>
 <dc:creator>Dernoncourt, Franck</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Word embeddings have been shown to be useful across state-of-the-art systems
in many natural language processing tasks, ranging from question answering
systems to dependency parsing. (Herbelot and Vecchi, 2015) explored word
embeddings and their utility for modeling language semantics. In particular,
they presented an approach to automatically map a standard distributional
semantic space onto a set-theoretic model using partial least squares
regression. We show in this paper that a simple baseline achieves a +51%
relative improvement compared to their model on one of the two datasets they
used, and yields competitive results on the second dataset.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02805</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Privacy-Preserving Crowdsourced Data Collection in the Smart City</dc:title>
 <dc:creator>Joy, Joshua</dc:creator>
 <dc:creator>McGoldrick, Ciaran</dc:creator>
 <dc:creator>Gerla, Mario</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Smart cities rely on dynamic and real-time data to enable smart urban
applications such as intelligent transport and epidemics detection. However,
the streaming of big data from IoT devices, especially from mobile platforms
like pedestrians and cars, raises significant privacy concerns.
  Future autonomous vehicles will generate, collect and consume significant
volumes of data to be utilized in delivering safe and efficient transportation
solutions. The sensed data will, inherently, contain personally identifiable
and attributable information - both external (other vehicles, environmental)
and internal (driver, passengers, devices).
  The autonomous vehicles are connected to the infrastructure cloud (e.g.,
Amazon), the edge cloud, and also the mobile cloud (vehicle to vehicle).
Clearly these different entities must co-operate and interoperate in a timely
fashion when routing and transferring the highly dynamic data. In order to
maximise the availability and utility of the sensed data, stakeholders must
have confidence that the data they transmit, receive, aggregate and reason on
is appropriately secured and protected throughout. There are many different
metaphors for providing end-to-end security for data exchanges, but they
commonly require a management and control sidechannel.
  This work proposes a scalable smart city privacy-preserving architecture
named Authorized Analytics that enables each node (e.g. vehicle) to divulge
(contextually) local privatised data. Authorized Analytics is shown to scale
gracefully to IoT scope deployments.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02809</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A sharp recovery condition for block sparse signals by block orthogonal
  multi-matching pursuit</dc:title>
 <dc:creator>Chen, Wengu</dc:creator>
 <dc:creator>Ge, Huanmin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the block orthogonal multi-matching pursuit (BOMMP) algorithm for
the recovery of block sparse signals. A sharp bound is obtained for the exact
reconstruction of block $K$-sparse signals via the BOMMP algorithm in the
noiseless case, based on the block restricted isometry constant (block-RIC).
Moreover, we show that the sharp bound combining with an extra condition on the
minimum $\ell_2$ norm of nonzero blocks of block $K-$sparse signals is
sufficient to recover the true support of block $K$-sparse signals by the BOMMP
in the noise case. The significance of the results we obtain in this paper lies
in the fact that making explicit use of block sparsity of block sparse signals
can achieve better recovery performance than ignoring the additional structure
in the problem as being in the conventional sense.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02809</dc:identifier>
 <dc:identifier>doi:10.1007/s11425-016-0448-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02810</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Benefits of Word Embeddings Features for Active Learning in Clinical
  Information Extraction</dc:title>
 <dc:creator>Kholghi, Mahnoosh</dc:creator>
 <dc:creator>De Vine, Lance</dc:creator>
 <dc:creator>Sitbon, Laurianne</dc:creator>
 <dc:creator>Zuccon, Guido</dc:creator>
 <dc:creator>Nguyen, Anthony</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>68U15, 68T50</dc:subject>
 <dc:description>  This study investigates the use of unsupervised word embeddings and sequence
features for sample representation in an active learning framework built to
extract clinical concepts from clinical free text. The objective is to further
reduce the manual annotation effort while achieving higher effectiveness
compared to a set of baseline features. Unsupervised features are derived from
skip-gram word embeddings and a sequence representation approach. The
comparative performance of unsupervised features and baseline hand-crafted
features in an active learning framework are investigated using a wide range of
selection criteria including least confidence, information diversity,
information density and diversity, and domain knowledge informativeness. Two
clinical datasets are used for evaluation: the i2b2/VA 2010 NLP challenge and
the ShARe/CLEF 2013 eHealth Evaluation Lab. Our results demonstrate significant
improvements in terms of effectiveness as well as annotation effort savings
across both datasets. Using unsupervised features along with baseline features
for sample representation lead to further savings of up to 9% and 10% of the
token and concept annotation rates, respectively.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02815</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Activity Detection in Untrimmed Video with Max-Subgraph Search</dc:title>
 <dc:creator>Chen, Chao-Yeh</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an efficient approach for activity detection in video that unifies
activity categorization with space-time localization. The main idea is to pose
activity detection as a maximum-weight connected subgraph problem. Offline, we
learn a binary classifier for an activity category using positive video
exemplars that are &quot;trimmed&quot; in time to the activity of interest. Then, given a
novel \emph{untrimmed} video sequence, we decompose it into a 3D array of
space-time nodes, which are weighted based on the extent to which their
component features support the learned activity model. To perform detection, we
then directly localize instances of the activity by solving for the
maximum-weight connected subgraph in the test video's space-time graph. We show
that this detection strategy permits an efficient branch-and-cut solution for
the best-scoring---and possibly non-cubically shaped---portion of the video for
a given activity classifier. The upshot is a fast method that can search a
broader space of space-time region candidates than was previously practical,
which we find often leads to more accurate detection. We demonstrate the
proposed algorithm on four datasets, and we show its speed and accuracy
advantages over multiple existing search strategies.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02817</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Codes with Locality for Four Erasures</dc:title>
 <dc:creator>Balaji, S. B.</dc:creator>
 <dc:creator>Prasanth, K. P.</dc:creator>
 <dc:creator>Kumar, P. Vijay</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, codes with locality for four erasures are considered. An upper
bound on the rate of codes with locality with sequential recovery from four
erasures is derived. The rate bound derived here is field independent. An
optimal construction for binary codes meeting this rate bound is also provided.
The construction is based on regular graphs of girth $6$ and employs the
sequential approach of locally recovering from multiple erasures. An extension
of this construction that generates codes which can sequentially recover from
five erasures is also presented.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02822</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity Bounds for Networks with Correlated Sources and
  Characterisation of Distributions by Entropies</dc:title>
 <dc:creator>Thakor, Satyajit</dc:creator>
 <dc:creator>Chan, Terence</dc:creator>
 <dc:creator>Grant, Alex</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Characterising the capacity region for a network can be extremely difficult.
Even with independent sources, determining the capacity region can be as hard
as the open problem of characterising all information inequalities. The
majority of computable outer bounds in the literature are relaxations of the
Linear Programming bound which involves entropy functions of random variables
related to the sources and link messages. When sources are not independent, the
problem is even more complicated. Extension of Linear Programming bounds to
networks with correlated sources is largely open. Source dependence is usually
specified via a joint probability distribution, and one of the main challenges
in extending linear program bounds is the difficulty (or impossibility) of
characterising arbitrary dependencies via entropy functions. This paper tackles
the problem by answering the question of how well entropy functions can
characterise correlation among sources. We show that by using carefully chosen
auxiliary random variables, the characterisation can be fairly &quot;accurate&quot; Using
such auxiliary random variables we also give implicit and explicit outer bounds
on the capacity of networks with correlated sources. The characterisation of
correlation or joint distribution via Shannon entropy functions is also
applicable to other information measures such as Renyi entropy and Tsallis
entropy.
</dc:description>
 <dc:description>Comment: 24 pager, 1 figure, submitted to IEEE Transactions on Information
  Theory. arXiv admin note: text overlap with arXiv:1309.1517</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02829</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypergraph Modelling for Geometric Model Fitting</dc:title>
 <dc:creator>Xiao, Guobao</dc:creator>
 <dc:creator>Wang, Hanzi</dc:creator>
 <dc:creator>Lai, Taotao</dc:creator>
 <dc:creator>Suter, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel hypergraph based method (called HF) to fit
and segment multi-structural data. The proposed HF formulates the geometric
model fitting problem as a hypergraph partition problem based on a novel
hypergraph model. In the hypergraph model, vertices represent data points and
hyperedges denote model hypotheses. The hypergraph, with large and
&quot;data-determined&quot; degrees of hyperedges, can express the complex relationships
between model hypotheses and data points. In addition, we develop a robust
hypergraph partition algorithm to detect sub-hypergraphs for model fitting. HF
can effectively and efficiently estimate the number of, and the parameters of,
model instances in multi-structural data heavily corrupted with outliers
simultaneously. Experimental results show the advantages of the proposed method
over previous methods on both synthetic data and real images.
</dc:description>
 <dc:description>Comment: Pattern Recognition, 2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02829</dc:identifier>
 <dc:identifier>doi:10.1016/J.PATCOG.2016.06.026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02834</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Lower Bounds for Multiplicative Weights Algorithmic Families</dc:title>
 <dc:creator>Gravin, Nick</dc:creator>
 <dc:creator>Peres, Yuval</dc:creator>
 <dc:creator>Sivan, Balasubramanian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the fundamental problem of prediction with expert advice and develop
regret lower bounds for a large family of algorithms for this problem. We
develop simple adversarial primitives, that lend themselves to various
combinations leading to sharp lower bounds for many algorithmic families. We
use these primitives to show that the classic Multiplicative Weights Algorithm
(MWA) has a regret of $\sqrt{\frac{T \ln k}{2}}$, there by completely closing
the gap between upper and lower bounds. We further show a regret lower bound of
$\frac{2}{3}\sqrt{\frac{T\ln k}{2}}$ for a much more general family of
algorithms than MWA, where the learning rate can be arbitrarily varied over
time, or even picked from arbitrary distributions over time. We also use our
primitives to construct adversaries in the geometric horizon setting for MWA to
precisely characterize the regret at $\frac{0.391}{\sqrt{\delta}}$ for the case
of $2$ experts and a lower bound of $\frac{1}{2}\sqrt{\frac{\ln k}{2\delta}}$
for the case of arbitrary number of experts $k$.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02835</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Form Follows Function -- Do algorithms and applications challenge or
  drag behind the hardware evolution?</dc:title>
 <dc:creator>Weinzierl, Tobias</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  We summarise some of the key statements made at the workshop Form Follows
Function at ISC High Performance 2016. The summary highlights what type of
co-design the presented projects experience; often in the absence of an
explicit co-design agenda. Their software development picks up hardware trends
but it also influences the hardware development. Observations illustrate that
this cycle not always is optimal for both sides as it is not proactively
steered. Key statements characterise ideas how it might be possible to
integrate both hardware and software creation closer to the best of both
worlds---again even without classic co-design in mind where new pieces of
hardware are created. The workshop finally identified three development idioms
that might help to improve software and system design with respect to emerging
hardware.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02846</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model reduction of linear time-varying systems with applications for
  moving loads</dc:title>
 <dc:creator>Varona, Maria Cruz</dc:creator>
 <dc:creator>Lohmann, Boris</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we consider different model reduction techniques for systems
with moving loads. Due to the time-dependency of the input and output matrices,
the application of time-varying projection matrices for the reduction offers
new degrees of freedom, which also come along with some challenges. This paper
deals with both simple methods for the reduction of particular linear
time-varying systems, as well as with a more advanced technique considering the
emerging time derivatives.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures, submitted to &quot;MoRePaS 2015 special volume&quot;</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02857</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classifying Variable-Length Audio Files with All-Convolutional Networks
  and Masked Global Pooling</dc:title>
 <dc:creator>Hertel, Lars</dc:creator>
 <dc:creator>Phan, Huy</dc:creator>
 <dc:creator>Mertins, Alfred</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We trained a deep all-convolutional neural network with masked global pooling
to perform single-label classification for acoustic scene classification and
multi-label classification for domestic audio tagging in the DCASE-2016
contest. Our network achieved an average accuracy of 84.5% on the four-fold
cross-validation for acoustic scene recognition, compared to the provided
baseline of 72.5%, and an average equal error rate of 0.17 for domestic audio
tagging, compared to the baseline of 0.21. The network therefore improves the
baselines by a relative amount of 17% and 19%, respectively. The network only
consists of convolutional layers to extract features from the short-time
Fourier transform and one global pooling layer to combine those features. It
particularly possesses neither fully-connected layers, besides the
fully-connected output layer, nor dropout layers.
</dc:description>
 <dc:description>Comment: Technical report for the DCASE-2016 challenge (task 1 and task 4)</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02858</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Factorization Machines for Persistently Cold-starting Online
  Item Recommendation</dc:title>
 <dc:creator>Kitazawa, Takuya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Real-world item recommenders commonly suffer from a persistent cold-start
problem which is caused by dynamically changing users and items. In order to
overcome the problem, several context-aware recommendation techniques have been
recently proposed. In terms of both feasibility and performance, factorization
machine (FM) is one of the most promising methods as generalization of the
conventional matrix factorization techniques. However, since online algorithms
are suitable for dynamic data, the static FMs are still inadequate. Thus, this
paper proposes incremental FMs (iFMs), a general online factorization
framework, and specially extends iFMs into an online item recommender. The
proposed framework can be a promising baseline for further development of the
production recommender systems. Evaluation is done empirically both on
synthetic and real-world unstable datasets.
</dc:description>
 <dc:description>Comment: 4 pages, 6 figures, The 1st Workshop on Profiling User Preferences
  for Dynamic Online and Real-Time Recommendations, RecSys 2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02861</identifier>
 <datestamp>2016-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A two-sided academic landscape: portrait of highly-cited documents in
  Google Scholar (1950-2013)</dc:title>
 <dc:creator>Martin-Martin, Alberto</dc:creator>
 <dc:creator>Orduna-Malea, Enrique</dc:creator>
 <dc:creator>Ayllon, Juan M.</dc:creator>
 <dc:creator>Lopez-Cozar, Emilio Delgado</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The main objective of this paper is to identify the set of highly-cited
documents in Google Scholar and to define their core characteristics (document
types, language, free availability, source providers, and number of versions),
under the hypothesis that the wide coverage of this search engine may provide a
different portrait about this document set respect to that offered by the
traditional bibliographic databases. To do this, a query per year was carried
out from 1950 to 2013 identifying the top 1,000 documents retrieved from Google
Scholar and obtaining a final sample of 64,000 documents, of which 40% provided
a free full-text link. The results obtained show that the average highly-cited
document is a journal article or a book (62% of the top 1% most cited documents
of the sample), written in English (92.5% of all documents) and available
online in PDF format (86.0% of all documents). Yet, the existence of errors
especially when detecting duplicates and linking cites properly must be pointed
out. The fact of managing with highly cited papers, however, minimizes the
effects of these limitations. Given the high presence of books, and to a lesser
extend of other document types (such as proceedings or reports), the research
concludes that Google Scholar data offer an original and different vision of
the most influential academic documents (measured from the perspective of their
citation count), a set composed not only by strictly scientific material
(journal articles) but academic in its broad sense
</dc:description>
 <dc:description>Comment: 26 pages, 5 tables, 10 figures</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02861</dc:identifier>
 <dc:identifier>Revista espa\~nola de Documentaci\'on Cient\'ifica, v. 39, n. 4,
  p. e149, dec. 2016. ISSN 1988-4621</dc:identifier>
 <dc:identifier>doi:10.3989/redc.2016.4.1405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02864</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Structure of Equilibrium Strategies in Dynamic Gaussian Signaling
  Games</dc:title>
 <dc:creator>Sayin, Muhammed</dc:creator>
 <dc:creator>Akyol, Emrah</dc:creator>
 <dc:creator>Basar, Tamer</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper analyzes a finite horizon dynamic signaling game motivated by the
well-known strategic information transmission problems in economics. The
mathematical model involves information transmission between two agents, a
sender who observes two Gaussian processes, state and bias, and a receiver who
takes an action based on the received message from the sender. The players
incur quadratic instantaneous costs as functions of the state, bias and action
variables. Our particular focus is on the Stackelberg equilibrium, which
corresponds to information disclosure and Bayesian persuasion problems in
economics. Prior work solved the static game, and showed that the Stackelberg
equilibrium is achieved by pure strategies that are linear functions of the
state and the bias variables. The main focus of this work is on the dynamic
(multi-stage) setting, where we show that the existence of a pure strategy
Stackelberg equilibrium, within the set of linear strategies, depends on the
problem parameters. Surprisingly, for most problem parameters, a pure linear
strategy does not achieve the Stackelberg equilibrium which implies the
existence of a trade-off between exploiting and revealing information, which
was also encountered in several other asymmetric information games.
</dc:description>
 <dc:description>Comment: will appear in IEEE Multi-Conference on Systems and Control 2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02864</dc:identifier>
 <dc:identifier>doi:10.1109/CCA.2016.7587908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02867</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Initial Experiments on Learning-Based Randomized Bin-Picking Allowing
  Finger Contact with Neighboring Objects</dc:title>
 <dc:creator>Harada, Kensuke</dc:creator>
 <dc:creator>Wan, Weiwei</dc:creator>
 <dc:creator>Tsuji, Tokuo</dc:creator>
 <dc:creator>Kikuchi, Kohei</dc:creator>
 <dc:creator>Nagata, Kazuyuki</dc:creator>
 <dc:creator>Onda, Hiromu</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper proposes a novel method for randomized bin-picking based on
learning. When a two-fingered gripper tries to pick an object from the pile, a
finger often contacts a neighboring object. Even if a finger contacts a
neighboring object, the target object will be successfully picked depending on
the configuration of neighboring objects. In our proposed method, we use the
visual information on neighboring objects to train the discriminator.
Corresponding to a grasping posture of an object, the discriminator predicts
whether or not the pick will be successful even if a finger contacts a
neighboring object. We examine two learning algorithms, the linear support
vector machine (SVM) and the random forest (RF) approaches. By using both
methods, we demonstrate that the picking success rate is significantly higher
than with conventional methods without learning.
</dc:description>
 <dc:description>Comment: To appear in the proceedings of IEEE Int. Conf. on Automation Science
  and Engineering (CASE), 2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02879</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A mathematical evaluation of vote transfer systems</dc:title>
 <dc:creator>Csat&#xf3;, L&#xe1;szl&#xf3;</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91B12</dc:subject>
 <dc:description>  The paper builds a general model of vote transfer systems on the basis of the
current Hungarian electoral rules. It combines single-seat districts and list
mandates with three possible compensation rule for 'wasted' votes in
constituencies: no compensation (direct vote transfer, DVT), compensation for
votes cast for losing party candidates (positive vote transfer, PVT) and
compensation for all votes that are not necessary to win the district (negative
vote transfer, NVT).
  The model is studied in the case of two parties. When the number of votes for
the majority party follows a uniform distribution in each district, DVT results
in the greatest expected seat share, however, application of PVT, and,
especially, NVT increases the probability of winning the election. The
trade-off between vote transfer formulas and the number of list mandates
reveals that the majority party should use an appropriately calibrated NVT
system if it focuses on these two variables.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02893</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Annealing Optimization for Witsenhausen's and Related
  Decentralized Stochastic Control Problems</dc:title>
 <dc:creator>Mehmetoglu, Mustafa</dc:creator>
 <dc:creator>Akyol, Emrah</dc:creator>
 <dc:creator>Rose, Kenneth</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This note studies the global optimization of controller mappings in
discrete-time stochastic control problems including Witsenhausen's celebrated
1968 counter-example. We propose a generally applicable non-convex numerical
optimization method based on the concept of deterministic annealing-which is
derived from information-theoretic principles and was successfully employed in
several problems including vector quantization, classification, and regression.
We present comparative numerical results for two test problems that show the
strict superiority of the proposed method over prior approaches in the
literature.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Automatic Control</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02895</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lagrangian Decomposition based Multi Agent Model Predictive Control for
  Electric Vehicles Charging integrating Real Time Pricing</dc:title>
 <dc:creator>Di Giorgio, Alessandro</dc:creator>
 <dc:creator>Di Maria, Andrea</dc:creator>
 <dc:creator>Liberati, Francesco</dc:creator>
 <dc:creator>Suraci, Vincenzo</dc:creator>
 <dc:creator>Priscoli, Francesco Delli</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a real time distributed control strategy for electric
vehicles charging covering both drivers and grid players' needs. Computation of
the charging load curve is performed by agents working at the level of each
single vehicle, with the information exchanged with grid players being
restricted to the chosen load curve and energy price feedback from the market,
elaborated according to the charging infrastructure congestion. The distributed
control mechanism is based on model predictive control methodology and
Lagrangian decomposition of the optimization control problem at its basis. The
simulation results show the effectiveness of the proposed distributed approach
and the mutual coherence between the computed charging load curves and the
resulting energy price over the time.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02902</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>sk_p: a neural program corrector for MOOCs</dc:title>
 <dc:creator>Pu, Yewen</dc:creator>
 <dc:creator>Narasimhan, Karthik</dc:creator>
 <dc:creator>Solar-Lezama, Armando</dc:creator>
 <dc:creator>Barzilay, Regina</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present a novel technique for automatic program correction in MOOCs,
capable of fixing both syntactic and semantic errors without manual, problem
specific correction strategies. Given an incorrect student program, it
generates candidate programs from a distribution of likely corrections, and
checks each candidate for correctness against a test suite.
  The key observation is that in MOOCs many programs share similar code
fragments, and the seq2seq neural network model, used in the natural-language
processing task of machine translation, can be modified and trained to recover
these fragments.
  Experiment shows our scheme can correct 29% of all incorrect submissions and
out-performs state of the art approach which requires manual, problem specific
correction strategies.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02904</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Vectorization of the Tersoff Multi-Body Potential: An Exercise in
  Performance Portability</dc:title>
 <dc:creator>H&#xf6;hnerbach, Markus</dc:creator>
 <dc:creator>Ismail, Ahmed E.</dc:creator>
 <dc:creator>Bientinesi, Paolo</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Molecular dynamics simulations, an indispensable research tool in
computational chemistry and materials science, consume a significant portion of
the supercomputing cycles around the world. We focus on multi-body potentials
and aim at achieving performance portability. Compared with well-studied pair
potentials, multibody potentials deliver increased simulation accuracy but are
too complex for effective compiler optimization. Because of this, achieving
cross-platform performance remains an open question. By abstracting from target
architecture and computing precision, we develop a vectorization scheme
applicable to both CPUs and accelerators. We present results for the Tersoff
potential within the molecular dynamics code LAMMPS on several architectures,
demonstrating efficiency gains not only for computational kernels, but also for
large-scale simulations. On a cluster of Intel Xeon Phi's, our optimized solver
is between 3 and 5 times faster than the pure MPI reference.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02911</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing the atom graph of a graph and the union join graph of a
  hypergraph</dc:title>
 <dc:creator>Berry, Anne</dc:creator>
 <dc:creator>Simonet, Genevi&#xe8;ve</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The atom graph of a graph is the graph whose vertices are the atoms obtained
by clique minimal separator decomposition of this graph, and whose edges are
the edges of all possible atom trees of this graph. We provide two efficient
algorithms for computing this atom graph, with a complexity in $O(min(n^\alpha
\log n, nm, n(n+\overline{m}))$ time, which is no more than the complexity of
computing the atoms in the general case. %\par We extend our results to
$\alpha$-acyclic hypergraphs. We introduce the notion of union join graph,
which is the union of all possible join trees; we apply our algorithms for atom
graphs to efficiently compute union join graphs.
  Keywords: clique separator decomposition, atom tree, atom graph, clique tree,
clique graph, $\alpha$-acyclic hypergraph.
</dc:description>
 <dc:description>Comment: Submitted in Algorithms on July 11, 2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02914</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Description Length Principle in Supervised Learning with
  Application to Lasso</dc:title>
 <dc:creator>Kawakita, Masanori</dc:creator>
 <dc:creator>Takeuchi, Jun'ichi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The minimum description length (MDL) principle in supervised learning is
studied. One of the most important theories for the MDL principle is Barron and
Cover's theory (BC theory), which gives a mathematical justification of the MDL
principle. The original BC theory, however, can be applied to supervised
learning only approximately and limitedly. Though Barron et al. recently
succeeded in removing a similar approximation in case of unsupervised learning,
their idea cannot be essentially applied to supervised learning in general. To
overcome this issue, an extension of BC theory to supervised learning is
proposed. The derived risk bound has several advantages inherited from the
original BC theory. First, the risk bound holds for finite sample size. Second,
it requires remarkably few assumptions. Third, the risk bound has a form of
redundancy of the two-stage code for the MDL procedure. Hence, the proposed
extension gives a mathematical justification of the MDL principle to supervised
learning like the original BC theory. As an important example of application,
new risk and (probabilistic) regret bounds of lasso with random design are
derived. The derived risk bound holds for any finite sample size $n$ and
feature number $p$ even if $n\ll p$ without boundedness of features in contrast
to the past work. Behavior of the regret bound is investigated by numerical
simulations. We believe that this is the first extension of BC theory to
general supervised learning with random design without approximation.
</dc:description>
 <dc:description>Comment: Sumbitted, IEEE Transactions on Information Theory, on May 16th, 2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02917</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable Matching with Uncertain Linear Preferences</dc:title>
 <dc:creator>Aziz, Haris</dc:creator>
 <dc:creator>Bir&#xf3;, P&#xe9;ter</dc:creator>
 <dc:creator>Gaspers, Serge</dc:creator>
 <dc:creator>de Haan, Ronald</dc:creator>
 <dc:creator>Mattei, Nicholas</dc:creator>
 <dc:creator>Rastegari, Baharak</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the two-sided stable matching setting in which there may be
uncertainty about the agents' preferences due to limited information or
communication. We consider three models of uncertainty: (1) lottery model ---
in which for each agent, there is a probability distribution over linear
preferences, (2) compact indifference model --- for each agent, a weak
preference order is specified and each linear order compatible with the weak
order is equally likely and (3) joint probability model --- there is a lottery
over preference profiles. For each of the models, we study the computational
complexity of computing the stability probability of a given matching as well
as finding a matching with the highest probability of being stable. We also
examine more restricted problems such as deciding whether a certainly stable
matching exists. We find a rich complexity landscape for these problems,
indicating that the form uncertainty takes is significant.
</dc:description>
 <dc:description>Comment: A preliminary version of this paper has been accepted for publication
  in the proceedings of the 9th International Symposium on Algorithmic Game
  Theory (SAGT 2016)</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02919</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Real-Time Estimation of Solar Generation From
  Micro-Synchrophasor Measurements</dc:title>
 <dc:creator>Kara, Emre C.</dc:creator>
 <dc:creator>Roberts, Ciaran M.</dc:creator>
 <dc:creator>Tabone, Michaelangelo</dc:creator>
 <dc:creator>Alvarez, Lilliana</dc:creator>
 <dc:creator>Callaway, Duncan S.</dc:creator>
 <dc:creator>Stewart, Emma M.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a set of methods for estimating the renewable energy
generation downstream of a measurement device using real-world measurements.
First, we present a generation disaggregation scheme where the only information
available for estimation is the micro-synchrophasor measurements obtained at
the substation or feeder head. We then propose two strategies in which we use
measurements from the substation as well as a proxy solar irradiance
measurement. Using these two measurement points, we first propose a multiple
linear regression strategy, in which we estimate a relationship between the
measured reactive power and the load active power consumption, which are then
used in disaggregation. Finally, we expand this strategy to strategically
manage the reconstruction errors in the estimators. We simultaneously
disaggregate the solar generation and load. We show that it is possible to
disaggragate the generation of a 7.5 megawatt photovoltaic site with a
root-mean-squared error of approximately 450 kilowatts.
</dc:description>
 <dc:description>Comment: For submission to Sustainable Energy, Grids and Networks</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02920</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Power Transfer in Massive MIMO Aided HetNets with User
  Association</dc:title>
 <dc:creator>Zhu, Yongxu</dc:creator>
 <dc:creator>Wang, Lifeng</dc:creator>
 <dc:creator>Wong, Kai-Kit</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:creator>Zheng, Zhongbin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper explores the potential of wireless power transfer (WPT) in massive
multiple input multiple output (MIMO) aided heterogeneous networks (HetNets),
where massive MIMO is applied in the macrocells, and users aim to harvest as
much energy as possible and reduce the uplink path loss for enhancing their
information transfer. By addressing the impact of massive MIMO on the user
association, we compare and analyze two user association schemes. We adopt the
linear maximal ratio transmission beam-forming for massive MIMO power transfer
to recharge users. By deriving new statistical properties, we obtain the exact
and asymptotic expressions for the average harvested energy. Then we derive the
average uplink achievable rate under the harvested energy constraint.
</dc:description>
 <dc:description>Comment: 36 pages, 11 figures, to appear in IEEE Transactions on
  Communications</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02920</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2016.2594794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02922</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterization and recognition of proper tagged probe interval graphs</dc:title>
 <dc:creator>Chakraborty, Sourav</dc:creator>
 <dc:creator>Ghosh, Shamik</dc:creator>
 <dc:creator>Paul, Sanchita</dc:creator>
 <dc:creator>Sen, Malay</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C62, 05C75, 05C85</dc:subject>
 <dc:description>  Interval graphs were used in the study of genomics by the famous molecular
biologist Benzer. Later on probe interval graphs were introduced by Zhang as a
generalization of interval graphs for the study of cosmid contig mapping of
DNA.
  A tagged probe interval graph (briefly, TPIG) is motivated by similar
applications to genomics, where the set of vertices is partitioned into two
sets, namely, probes and nonprobes and there is an interval on the real line
corresponding to each vertex. The graph has an edge between two probe vertices
if their corresponding intervals intersect, has an edge between a probe vertex
and a nonprobe vertex if the interval corresponding to a nonprobe vertex
contains at least one end point of the interval corresponding to a probe vertex
and the set of non-probe vertices is an independent set. This class of graphs
have been defined nearly two decades ago, but till today there is no known
recognition algorithm for it.
  In this paper, we consider a natural subclass of TPIG, namely, the class of
proper tagged probe interval graphs (in short PTPIG). We present
characterization and a linear time recognition algorithm for PTPIG. To obtain
this characterization theorem we introduce a new concept called canonical
sequence for proper interval graphs, which, we belief, has an independent
interest in the study of proper interval graphs. Also to obtain the recognition
algorithm for PTPIG, we introduce and solve a variation of consecutive $1$'s
problem, namely, oriented consecutive $1$'s problem and some variations of
PQ-tree algorithm. We also discuss the interrelations between the classes of
PTPIG and TPIG with probe interval graphs and probe proper interval graphs.
</dc:description>
 <dc:description>Comment: 40 pages, 3 figures</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02925</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Low-rank Approximation using Adaptive Gap-based Preconditioning</dc:title>
 <dc:creator>Gonen, Alon</dc:creator>
 <dc:creator>Shalev-Shwartz, Shai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a method for rank $k$ approximation to a given input matrix $X \in
\mathbb{R}^{d \times n}$ which runs in time \[ \tilde{O} \left(d ~\cdot~
\min\left\{n + \tilde{sr}(X) \,G^{-2}_{k,p+1}\ ,\ n^{3/4}\, \tilde{sr}(X)^{1/4}
\,G^{-1/2}_{k,p+1} \right\} ~\cdot~ \text{poly}(p)\right) ~, \] where $p&gt;k$,
$\tilde{sr}(X)$ is related to stable rank of $X$, and $G_{k,p+1} =
\frac{\sigma_k-\sigma_p}{\sigma_k}$ is the multiplicative gap between the
$k$-th and the $(p+1)$-th singular values of $X$. In particular, this yields a
linear time algorithm if the gap is at least $1/\sqrt{n}$ and
$k,p,\tilde{sr}(X)$ are constants.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02925</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02927</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the chemistry of typestate-oriented actors</dc:title>
 <dc:creator>Crafa, Silvia</dc:creator>
 <dc:creator>Padovani, Luca</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Typestate-oriented programming is an extension of the OO paradigm in which
objects are modeled not just in terms of interfaces but also in terms of their
usage protocols, describing legal sequences of method calls, possibly depending
on the object's internal state. We argue that the Actor Model allows
typestate-OOP in an inherently distributed setting, whereby objects/actors can
be accessed concurrently by several processes, and local entities cooperate to
carry out a communication protocol. In this article we illustrate the approach
by means of a number of examples written in Scala Akka. We show that Scala's
abstractions support clean and natural typestate-oriented actor programming
with the usual asynchronous and non-blocking semantics. We also show that the
standard type system of Scala and a typed wrapping of usual (untyped) Akka's
ActorRef are enough to provide rich forms of type safety so that well-typed
actors respect their intended communication protocols. This approach draws on a
solid theoretical background, consisting of a sound behavioral type system for
the Join Calculus, that is a foundational calculus of distributed asynchronous
processes whose semantics is based on the Chemical Abstract Machine, that
unveiled its strong connections with typestate-oriented programming of both
concurrent objects and actors.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02936</identifier>
 <datestamp>2017-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inference of Haemoglobin Concentration From Stereo RGB</dc:title>
 <dc:creator>Jones, Geoffrey</dc:creator>
 <dc:creator>Clancy, Neil T.</dc:creator>
 <dc:creator>Helo, Yusuf</dc:creator>
 <dc:creator>Arridge, Simon</dc:creator>
 <dc:creator>Elson, Daniel S.</dc:creator>
 <dc:creator>Stoyanov, Danail</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multispectral imaging (MSI) can provide information about tissue oxygenation,
perfusion and potentially function during surgery. In this paper we present a
novel, near real-time technique for intrinsic measurements of total haemoglobin
(THb) and blood oxygenation (SO2) in tissue using only RGB images from a stereo
laparoscope. The high degree of spectral overlap between channels makes
inference of haemoglobin concentration challenging, non-linear and under
constrained. We decompose the problem into two constrained linear sub-problems
and show that with Tikhonov regularisation the estimation significantly
improves, giving robust estimation of the Thb. We demonstrate by using the
co-registered stereo image data from two cameras it is possible to get robust
SO2 estimation as well. Our method is closed from, providing computational
efficiency even with multiple cameras. The method we present requires only
spectral response calibration of each camera, without modification of existing
laparoscopic imaging hardware. We validate our technique on synthetic data from
Monte Carlo simulation % of light transport through soft tissue containing
submerged blood vessels and further, in vivo, on a multispectral porcine data
set.
</dc:description>
 <dc:description>Comment: To appear at the 6th International Conference on Medical Imaging and
  Augmented Reality, MIAR 2016, held in Bern, Switzerland during August 2016,
  and in the corresponding proceedings</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2017-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02936</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-43775-0_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02937</identifier>
 <datestamp>2016-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmark for License Plate Character Segmentation</dc:title>
 <dc:creator>Gon&#xe7;alves, Gabriel Resende</dc:creator>
 <dc:creator>da Silva, Sirlene Pio Gomes</dc:creator>
 <dc:creator>Menotti, David</dc:creator>
 <dc:creator>Schwartz, William Robson</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic License Plate Recognition (ALPR) has been the focus of many
researches in the past years. In general, ALPR is divided into the following
problems: detection of on-track vehicles, license plates detection, segmention
of license plate characters and optical character recognition (OCR). Even
though commercial solutions are available for controlled acquisition
conditions, e.g., the entrance of a parking lot, ALPR is still an open problem
when dealing with data acquired from uncontrolled environments, such as roads
and highways when relying only on imaging sensors. Due to the multiple
orientations and scales of the license plates captured by the camera, a very
challenging task of the ALPR is the License Plate Character Segmentation (LPCS)
step, which effectiveness is required to be (near) optimal to achieve a high
recognition rate by the OCR. To tackle the LPCS problem, this work proposes a
novel benchmark composed of a dataset designed to focus specifically on the
character segmentation step of the ALPR within an evaluation protocol.
Furthermore, we propose the Jaccard-Centroid coefficient, a new evaluation
measure more suitable than the Jaccard coefficient regarding the location of
the bounding box within the ground-truth annotation. The dataset is composed of
2,000 Brazilian license plates consisting of 14,000 alphanumeric symbols and
their corresponding bounding box annotations. We also present a new
straightforward approach to perform LPCS efficiently. Finally, we provide an
experimental evaluation for the dataset based on four LPCS approaches and
demonstrate the importance of character segmentation for achieving an accurate
OCR.
</dc:description>
 <dc:description>Comment: 32 pages, single column</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02937</dc:identifier>
 <dc:identifier>J. Electron. Imaging. 25(5), 053034 (Oct 24, 2016)</dc:identifier>
 <dc:identifier>doi:10.1117/1.JEI.25.5.053034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02951</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design Patterns in Beeping Algorithms: Examples, Emulation, and Analysis</dc:title>
 <dc:creator>Casteigts, Arnaud</dc:creator>
 <dc:creator>M&#xe9;tivier, Yves</dc:creator>
 <dc:creator>Robson, John Michael</dc:creator>
 <dc:creator>Zemmari, Akka</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider networks of processes which interact with beeps. In the basic
model defined by Cornejo and Kuhn (2010), processes can choose in each round
either to beep or to listen. Those who beep are unable to detect simultaneous
beeps. Those who listen can only distinguish between silence and the presence
of at least one beep. We refer to this model as $BL$ (beep or listen). Stronger
models exist where the nodes can detect collision while they are beeping
($B_{cd}L$), listening ($BL_{cd}$), or both ($B_{cd}L_{cd}$). Beeping models
are weak in essence and even simple tasks are difficult or unfeasible within.
  We present a set of generic building blocks (design patterns) which seem to
occur frequently in the design of beeping algorithms. They include multi-slot
phases: the fact of dividing the main loop into a number of specialised slots;
exclusive beeps: having a single node beep at a time in a neighbourhood (within
one or two hops); adaptive probability: increasing or decreasing the
probability of beeping to produce more exclusive beeps; internal (resp.
peripheral) collision detection: for detecting collision while beeping (resp.
listening). Based on these patterns, we provide algorithms for a number of
basic problems, including colouring, 2-hop colouring, degree computation, 2-hop
MIS, and collision detection (in $BL$). The patterns make it possible to
formulate these algorithms in a rather concise and elegant way. Their analyses
are more technical; one of them improves significantly upon that of the best
known MIS algorithm by Jeavons et al. (2016). Finally, inspired by a technique
from Afek et al. (2013), our last contribution is to show that any Las Vegas
algorithm relying on collision detection can be transposed into a Monte Carlo
algorithm without collision detection at the cost of a logarithmic slowdown,
which we prove is optimal.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1507.02721</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2017-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02952</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are human interactivity times lognormal?</dc:title>
 <dc:creator>Blenn, Norbert</dc:creator>
 <dc:creator>Van Mieghem, Piet</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this paper, we are analyzing the interactivity time, defined as the
duration between two consecutive tasks such as sending emails, collecting
friends and followers and writing comments in online social networks (OSNs).
The distributions of these times are heavy tailed and often described by a
power-law distribution. However, power-law distributions usually only fit the
heavy tail of empirical data and ignore the information in the smaller value
range. Here, we argue that the durations between writing emails or comments,
adding friends and receiving followers are likely to follow a lognormal
distribution.
  We discuss the similarities between power-law and lognormal distributions,
show that binning of data can deform a lognormal to a power-law distribution
and propose an explanation for the appearance of lognormal interactivity times.
The historical debate of similarities between lognormal and power-law
distributions is reviewed by illustrating the resemblance of measurements in
this paper with the historical problem of income and city size distributions.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02955</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Current-Flow Closeness Centrality with a Multigrid Laplacian
  Solver</dc:title>
 <dc:creator>Bergamini, Elisabetta</dc:creator>
 <dc:creator>Wegner, Michael</dc:creator>
 <dc:creator>Lukarski, Dimitar</dc:creator>
 <dc:creator>Meyerhenke, Henning</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Matrices associated with graphs, such as the Laplacian, lead to numerous
interesting graph problems expressed as linear systems. One field where
Laplacian linear systems play a role is network analysis, e. g. for certain
centrality measures that indicate if a node (or an edge) is important in the
network. One such centrality measure is current-flow closeness. To allow
network analysis workflows to profit from a fast Laplacian solver, we provide
an implementation of the LAMG multigrid solver in the NetworKit package,
facilitating the computation of current-flow closeness values or related
quantities. Our main contribution consists of two algorithms that accelerate
the current-flow computation for one node or a reasonably small node subset
significantly. One algorithm is an unbiased estimator using sampling, the other
one is based on the Johnson-Lindenstrauss transform. Our inexact algorithms
lead to very accurate results in practice. Thanks to them one is now able to
compute an estimation of current-flow closeness of one node on networks with
tens of millions of nodes and edges within seconds or a few minutes. From a
network analytical point of view, our experiments indicate that current-flow
closeness can discriminate among different nodes significantly better than
traditional shortest-path closeness and is also considerably more resistant to
noise - we thus show that two known drawbacks of shortest-path closeness are
alleviated by the current- flow variant.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02959</identifier>
 <datestamp>2016-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Behavior to Sparse Graphical Games: Efficient Recovery of
  Equilibria</dc:title>
 <dc:creator>Ghoshal, Asish</dc:creator>
 <dc:creator>Honorio, Jean</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we study the problem of exact recovery of the pure-strategy
Nash equilibria (PSNE) set of a graphical game from noisy observations of joint
actions of the players alone. We consider sparse linear influence games --- a
parametric class of graphical games with linear payoffs, and represented by
directed graphs of n nodes (players) and in-degree of at most k. We present an
$\ell_1$-regularized logistic regression based algorithm for recovering the
PSNE set exactly, that is both computationally efficient --- i.e. runs in
polynomial time --- and statistically efficient --- i.e. has logarithmic sample
complexity. Specifically, we show that the sufficient number of samples
required for exact PSNE recovery scales as $\mathcal{O}(\mathrm{poly}(k) \log
n)$. We also validate our theoretical results using synthetic experiments.
</dc:description>
 <dc:description>Comment: Accepted at 54th Annual Allerton Conference on Communication,
  Control, and Computing (2016)</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02963</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling movement for collective adaptive systems with CARMA</dc:title>
 <dc:creator>Zo&#x144;, Natalia</dc:creator>
 <dc:creator>Galpin, Vashti</dc:creator>
 <dc:creator>Gilmore, Stephen</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Space and movement through space play an important role in many collective
adaptive systems (CAS). CAS consist of multiple components interacting to
achieve some goal in a system or environment that can change over time. When
these components operate in space, then their behaviour can be affected by
where they are located in that space. Examples include the possibility of
communication between two components located at different points, and rates of
movement of a component that may be affected by location. The CARMA language
and its associated software tools can be used to model such systems. In
particular, a graphical editor for CARMA allows for the specification of
spatial structure and generation of templates that can be used in a CARMA model
with space. We demonstrate the use of this tool to experiment with a model of
pedestrian movement over a network of paths.
</dc:description>
 <dc:description>Comment: In Proceedings FORECAST 2016, arXiv:1607.02001</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02963</dc:identifier>
 <dc:identifier>EPTCS 217, 2016, pp. 43-52</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.217.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02966</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges in Quantitative Abstractions for Collective Adaptive Systems</dc:title>
 <dc:creator>Tribastone, Mirco</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  Like with most large-scale systems, the evaluation of quantitative properties
of collective adaptive systems is an important issue that crosscuts all its
development stages, from design (in the case of engineered systems) to runtime
monitoring and control. Unfortunately it is a difficult problem to tackle in
general, due to the typically high computational cost involved in the analysis.
This calls for the development of appropriate quantitative abstraction
techniques that preserve most of the system's dynamical behaviour using a more
compact representation. This paper focuses on models based on ordinary
differential equations and reviews recent results where abstraction is achieved
by aggregation of variables, reflecting on the shortcomings in the state of the
art and setting out challenges for future research.
</dc:description>
 <dc:description>Comment: In Proceedings FORECAST 2016, arXiv:1607.02001</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02966</dc:identifier>
 <dc:identifier>EPTCS 217, 2016, pp. 62-68</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.217.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02970</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The sequential functionals of type $(\iota \rightarrow \iota)^n
  \rightarrow \iota$ form a dcpo for all $n \in \Bbb N$</dc:title>
 <dc:creator>Normann, Dag</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  We prove that the sequential functionals of some fixed types at type level 2,
taking finite sequences of unary functions as arguments, do form a directed
complete partial ordering. This gives a full characterisation of for which
types the partially ordered set of sequential functionals has this property. As
a tool, we prove a normal form theorem for the finite sequential functionals of
the types in question,
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02974</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BioInfoBase : A Bioinformatics Resourceome</dc:title>
 <dc:creator>Kadkhodaei, Saeid</dc:creator>
 <dc:creator>Barantalab, Fatemeh</dc:creator>
 <dc:creator>Taheri, Sima</dc:creator>
 <dc:creator>Foroughi, Majid</dc:creator>
 <dc:creator>Hashemi, Farahnaz Golestan</dc:creator>
 <dc:creator>Shabanimofrad, Mahmood Reza</dc:creator>
 <dc:creator>Hosseinimonfared, Hossein</dc:creator>
 <dc:creator>Rezaei, Morvarid Akhavan</dc:creator>
 <dc:creator>Ranjbarfard, Ali</dc:creator>
 <dc:creator>Sahebi, Mahbod</dc:creator>
 <dc:creator>Azizi, Parisa</dc:creator>
 <dc:creator>Dadar, Maryam</dc:creator>
 <dc:creator>Abiri, Rambod</dc:creator>
 <dc:creator>Harighi, Mohammad Fazel</dc:creator>
 <dc:creator>Kalhori, Nahid</dc:creator>
 <dc:creator>Etemadi, Mohammad Reza</dc:creator>
 <dc:creator>Baradaran, Ali</dc:creator>
 <dc:creator>Danaee, Mahmoud</dc:creator>
 <dc:creator>Zare, Iman</dc:creator>
 <dc:creator>Ghafarpour, Ahmad</dc:creator>
 <dc:creator>Azhdari, Zahra</dc:creator>
 <dc:creator>Memari, Hamid Rajabi</dc:creator>
 <dc:creator>Safavi, Vajiheh</dc:creator>
 <dc:creator>Tajabadi, Naser</dc:creator>
 <dc:creator>Bande, Faruku</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Over the past decade there has been a significant growth in bioinformatics
databases, tools and resources. Although, bioinformatics is becoming more
specific, increasing the number of bioinformatics-wares has made it difficult
for researchers to find the most appropriate databases, tools or methods which
match their needs. Our coordinated effort has been planned to establish a
reference website in Bioinformatics as a public repository of tools, databases,
directories and resources annotated with contextual information and organized
by functional relevance. Within the first phase of BioInfoBase development, 22
experts in different fields of molecular biology contributed and more than 2500
records were registered, which are increasing daily. For each record submitted
to the database of website almost all related data (40 features) has been
extracted. These include information from the biological category and
subcategory to the scientific article and developer information. Searching the
query keyword(s) returns links containing the entered keyword(s) found within
the different features of the records with more weights on the title, abstract
and application fields. The search results simply provide the users with the
most informative features of the records to select the most suitable ones. The
usefulness of the returned results is ranked according to the matching score
based on the Term Frequency-Inverse Document Frequency (TF-IDF) methods.
Therefore, this search engine will screen a comprehensive index of
bioinformatics tools, databases and resources and provide the best suited
records (links) to the researchers need. The BioInfoBase resource is available
at www.bioinfobase.info.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures, International Association for Plant
  Biotechnology, IAPB Congress, Melbourne, Australia</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02982</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing HPC Security with a User-Based Firewall</dc:title>
 <dc:creator>Prout, Andrew</dc:creator>
 <dc:creator>Arcand, William</dc:creator>
 <dc:creator>Bestor, David</dc:creator>
 <dc:creator>Bergeron, Bill</dc:creator>
 <dc:creator>Byun, Chansup</dc:creator>
 <dc:creator>Gadepally, Vijay</dc:creator>
 <dc:creator>Hubbell, Matthew</dc:creator>
 <dc:creator>Houle, Michael</dc:creator>
 <dc:creator>Jones, Michael</dc:creator>
 <dc:creator>Michaleas, Peter</dc:creator>
 <dc:creator>Milechin, Lauren</dc:creator>
 <dc:creator>Mullen, Julie</dc:creator>
 <dc:creator>Rosa, Antonio</dc:creator>
 <dc:creator>Samsi, Siddharth</dc:creator>
 <dc:creator>Reuther, Albert</dc:creator>
 <dc:creator>Kepner, Jeremy</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  HPC systems traditionally allow their users unrestricted use of their
internal network. While this network is normally controlled enough to guarantee
privacy without the need for encryption, it does not provide a method to
authenticate peer connections. Protocols built upon this internal network must
provide their own authentication. Many methods have been employed to perform
this authentication. However, support for all of these methods requires the HPC
application developer to include support and the user to configure and enable
these services. The user-based firewall capability we have prototyped enables a
set of rules governing connections across the HPC internal network to be put
into place using Linux netfilter. By using an operating system-level
capability, the system is not reliant on any developer or user actions to
enable security. The rules we have chosen and implemented are crafted to not
impact the vast majority of users and be completely invisible to them.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02982</dc:identifier>
 <dc:identifier>doi:10.1109/HPEC.2016.7761641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02986</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Birthday Repetition Theorem and Complexity of Approximating Dense CSPs</dc:title>
 <dc:creator>Manurangsi, Pasin</dc:creator>
 <dc:creator>Raghavendra, Prasad</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  A $(k \times l)$-birthday repetition $\mathcal{G}^{k \times l}$ of a
two-prover game $\mathcal{G}$ is a game in which the two provers are sent
random sets of questions from $\mathcal{G}$ of sizes $k$ and $l$ respectively.
These two sets are sampled independently uniformly among all sets of questions
of those particular sizes. We prove the following birthday repetition theorem:
when $\mathcal{G}$ satisfies some mild conditions, $val(\mathcal{G}^{k \times
l})$ decreases exponentially in $\Omega(kl/n)$ where $n$ is the total number of
questions. Our result positively resolves an open question posted by Aaronson,
Impagliazzo and Moshkovitz (CCC 2014).
  As an application of our birthday repetition theorem, we obtain new
fine-grained hardness of approximation results for dense CSPs. Specifically, we
establish a tight trade-off between running time and approximation ratio for
dense CSPs by showing conditional lower bounds, integrality gaps and
approximation algorithms. In particular, for any sufficiently large $i$ and for
every $k \geq 2$, we show the following results:
  - We exhibit an $O(q^{1/i})$-approximation algorithm for dense Max $k$-CSPs
with alphabet size $q$ via $O_k(i)$-level of Sherali-Adams relaxation.
  - Through our birthday repetition theorem, we obtain an integrality gap of
$q^{1/i}$ for $\tilde\Omega_k(i)$-level Lasserre relaxation for fully-dense Max
$k$-CSP.
  - Assuming that there is a constant $\epsilon &gt; 0$ such that Max 3SAT cannot
be approximated to within $(1-\epsilon)$ of the optimal in sub-exponential
time, our birthday repetition theorem implies that any algorithm that
approximates fully-dense Max $k$-CSP to within a $q^{1/i}$ factor takes
$(nq)^{\tilde \Omega_k(i)}$ time, almost tightly matching the algorithmic
result based on Sherali-Adams relaxation.
</dc:description>
 <dc:description>Comment: 45 pages</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.02988</identifier>
 <datestamp>2017-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The quasiequational theory of relational lattices, in the pure lattice
  signature (embeddability into relational lattices is undecidable)</dc:title>
 <dc:creator>Santocanale, Luigi</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  The natural join and the inner union operations combine relations of a
database. Tropashko and Spight realized that these two operations are themeet
and join operations in a class of lattices, known by now as the relational
lattices. They proposed then lattice theory as an algebraic approach to
thetheory of databases alternative to the relational algebra. Litak et al.
proposed an axiomatization of relational lattices over the signature that
extends thepure lattice signature with a constant and argued that the
quasiequational theory of relational lattices over this extended signature is
undecidable.We prove in this paper that embeddability is undecidable for
relational lattices. More precisely, it is undecidable whether a finite
subdirectly-irreduciblelattice can be embedded into a relational lattice. Our
proof is a reduction from the coverability problem of a multimodal frame by a
universal product frameand, indirectly, from the representability problem for
relation algebras. As corollaries we obtain the following results: the
quasiequational theoryof relational lattices over the pure lattice signature is
undecidable and has no finite base; there is a quasiequation over the pure
lattice signature which holds in all the finite relational lattices but fails
in an infinite relational lattice.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.02988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03021</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Salient Region Detection and Segmentation in Images using Dynamic Mode
  Decomposition</dc:title>
 <dc:creator>K, Sikha O</dc:creator>
 <dc:creator>S, Sachin Kumar</dc:creator>
 <dc:creator>Soman, K P</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual Saliency is the capability of vision system to select distinctive
parts of scene and reduce the amount of visual data that need to be processed.
The presentpaper introduces (1) a novel approach to detect salient regions by
considering color and luminance based saliency scores using Dynamic Mode
Decomposition (DMD), (2) a new interpretation to use DMD approach in static
image processing. This approach integrates two data analysis methods: (1)
Fourier Transform, (2) Principle Component Analysis.The key idea of our work is
to create a color based saliency map. This is based on the observation
thatsalient part of an image usually have distinct colors compared to the
remaining portion of the image. We have exploited the power of different color
spaces to model the complex and nonlinear behavior of human visual system to
generate a color based saliency map. To further improve the effect of final
saliency map, weutilized luminance information exploiting the fact that human
eye is more sensitive towards brightness than color.The experimental results
shows that our method based on DMD theory is effective in comparison with
previous state-of-art saliency estimation approaches. The approach presented in
this paperis evaluated using ROC curve, F-measure rate, Precision-Recall rate,
AUC score etc.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03025</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Dissemination using Instantly Decodable Binary Codes in Fog-Radio
  Access Networks</dc:title>
 <dc:creator>Douik, Ahmed</dc:creator>
 <dc:creator>Sorour, Sameh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Consider a device-to-device (D2D) fog-radio access network wherein a set of
devices are required to store a set of files. Each device is connected to a
subset of the cloud data centers and thus possesses a subset of the data. This
paper investigates the problem of disseminating all files among the devices
while reducing the total time of communication, i.e., the completion time,
using instantly decodable network coding (IDNC). While previous studies on the
use of IDNC in D2D systems assume a fully connected communication network, this
paper tackles the more realistic scenario of a partially connected network in
which devices can only target devices in their transmission range. The paper
first formulates the optimal joint optimization of selecting the transmitting
device(s) and the file combination(s) and exhibits its intractability. The
completion time is approximated using the celebrated decoding delay approach by
deriving the relationship between the quantities in a partially connected
network. The paper introduces the cooperation graph and demonstrates that the
relaxed problem is equivalent to a maximum weight clique problem over the newly
designed graph wherein the weights are obtained by solving a similar problem on
the local IDNC graphs. Extensive simulations reveal that the proposed solution
provides noticeable performance enhancement and outperforms previously proposed
IDNC-based schemes.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2017-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03039</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clearing an Orthogonal Polygon Using Sliding Robots</dc:title>
 <dc:creator>Ghodsi, Mohammad</dc:creator>
 <dc:creator>Mahdavi, Salma Sadat</dc:creator>
 <dc:creator>Sheshkalani, Ali Narenji</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In a multi-robot system, a number of autonomous robots would sense,
communicate, and decide to move within a given domain to achieve a common goal.
In this paper, we consider a new variant of the pursuit-evasion problem in
which the robots (pursuers) each move back and forth along an orthogonal line
segment inside a simple orthogonal polygon $P$. A point $p$ can be covered by a
sliding robot that moves along a line segment s, if there exists a point $q\in
s$ such that $\overline{pq}$ is a line segment perpendicular to $s$. In the
pursuit-evasion problem, a polygonal region is given and a robot called a
pursuer tries to find some mobile targets called evaders. The goal of this
problem is to design a motion strategy for the pursuer such that it can detect
all the evaders. We assume that $P$ includes unpredictable, moving evaders that
have unbounded speed. We propose a motion-planning algorithm for a group of
sliding robots, assuming that they move along the pre-located line segments
with a constant speed to detect all the evaders with unbounded speed.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03050</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a metric for class-conditional KNN</dc:title>
 <dc:creator>Im, Daniel Jiwoong</dc:creator>
 <dc:creator>Taylor, Graham W.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Naive Bayes Nearest Neighbour (NBNN) is a simple and effective framework
which addresses many of the pitfalls of K-Nearest Neighbour (KNN)
classification. It has yielded competitive results on several computer vision
benchmarks. Its central tenet is that during NN search, a query is not compared
to every example in a database, ignoring class information. Instead, NN
searches are performed within each class, generating a score per class. A key
problem with NN techniques, including NBNN, is that they fail when the data
representation does not capture perceptual (e.g.~class-based) similarity. NBNN
circumvents this by using independent engineered descriptors (e.g.~SIFT). To
extend its applicability outside of image-based domains, we propose to learn a
metric which captures perceptual similarity. Similar to how Neighbourhood
Components Analysis optimizes a differentiable form of KNN classification, we
propose &quot;Class Conditional&quot; metric learning (CCML), which optimizes a soft form
of the NBNN selection rule. Typical metric learning algorithms learn either a
global or local metric. However, our proposed method can be adjusted to a
particular level of locality by tuning a single parameter. An empirical
evaluation on classification and retrieval tasks demonstrates that our proposed
method clearly outperforms existing learned distance metrics across a variety
of image and non-image datasets.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03055</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the Political Agenda of the European Parliament Using a
  Dynamic Topic Modeling Approach</dc:title>
 <dc:creator>Greene, Derek</dc:creator>
 <dc:creator>Cross, James P.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This study analyzes the political agenda of the European Parliament (EP)
plenary, how it has evolved over time, and the manner in which Members of the
European Parliament (MEPs) have reacted to external and internal stimuli when
making plenary speeches. To unveil the plenary agenda and detect latent themes
in legislative speeches over time, MEP speech content is analyzed using a new
dynamic topic modeling method based on two layers of Non-negative Matrix
Factorization (NMF). This method is applied to a new corpus of all English
language legislative speeches in the EP plenary from the period 1999-2014. Our
findings suggest that two-layer NMF is a valuable alternative to existing
dynamic topic modeling approaches found in the literature, and can unveil niche
topics and associated vocabularies not captured by existing methods.
Substantively, our findings suggest that the political agenda of the EP evolves
significantly over time and reacts to exogenous events such as EU Treaty
referenda and the emergence of the Euro-crisis. MEP contributions to the
plenary agenda are also found to be impacted upon by voting behaviour and the
committee structure of the Parliament.
</dc:description>
 <dc:description>Comment: Long version including appendix. arXiv admin note: substantial text
  overlap with arXiv:1505.07302</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03057</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from the News: Predicting Entity Popularity on Twitter</dc:title>
 <dc:creator>Saleiro, Pedro</dc:creator>
 <dc:creator>Soares, Carlos</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this work, we tackle the problem of predicting entity popularity on
Twitter based on the news cycle. We apply a supervised learn- ing approach and
extract four types of features: (i) signal, (ii) textual, (iii) sentiment and
(iv) semantic, which we use to predict whether the popularity of a given entity
will be high or low in the following hours. We run several experiments on six
different entities in a dataset of over 150M tweets and 5M news and obtained F1
scores over 0.70. Error analysis indicates that news perform better on
predicting entity popularity on Twitter when they are the primary information
source of the event, in opposition to events such as live TV broadcasts,
political debates or football matches.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03070</identifier>
 <datestamp>2016-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forward Table-Based Presynaptic Event-Triggered Spike-Timing-Dependent
  Plasticity</dc:title>
 <dc:creator>Pedroni, Bruno U.</dc:creator>
 <dc:creator>Sheik, Sadique</dc:creator>
 <dc:creator>Joshi, Siddharth</dc:creator>
 <dc:creator>Detorakis, Georgios</dc:creator>
 <dc:creator>Paul, Somnath</dc:creator>
 <dc:creator>Augustine, Charles</dc:creator>
 <dc:creator>Neftci, Emre</dc:creator>
 <dc:creator>Cauwenberghs, Gert</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Spike-timing-dependent plasticity (STDP) incurs both causal and acausal
synaptic weight updates, for negative and positive time differences between
pre-synaptic and post-synaptic spike events. For realizing such updates in
neuromorphic hardware, current implementations either require forward and
reverse lookup access to the synaptic connectivity table, or rely on
memory-intensive architectures such as crossbar arrays. We present a novel
method for realizing both causal and acausal weight updates using only forward
lookup access of the synaptic connectivity table, permitting memory-efficient
implementation. A simplified implementation in FPGA, using a single timer
variable for each neuron, closely approximates exact STDP cumulative weight
updates for neuron refractory periods greater than 10 ms, and reduces to exact
STDP for refractory periods greater than the STDP time window. Compared to
conventional crossbar implementation, the forward table-based implementation
leads to substantial memory savings for sparsely connected networks supporting
scalable neuromorphic systems with fully reconfigurable synaptic connectivity
and plasticity.
</dc:description>
 <dc:description>Comment: Submitted to BioCAS 2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03077</identifier>
 <datestamp>2016-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of a Robust Stair Climbing Compliant Modular Robot to Tackle
  Overhang on Stairs</dc:title>
 <dc:creator>Bhole, Ajinkya</dc:creator>
 <dc:creator>Turlapati, Sri Harsha</dc:creator>
 <dc:creator>S, Rajashekhar V.</dc:creator>
 <dc:creator>Dixit, Jay</dc:creator>
 <dc:creator>Shah, Suril V.</dc:creator>
 <dc:creator>Krishna, K Madhava</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper discusses the concept and parameter design of a Robust Stair
Climbing Compliant Modular Robot, capable of tackling stairs with overhangs.
Modifying the geometry of the periphery of the wheels of our robot helps in
tackling overhangs. Along with establishing a concept design, robust design
parameters are set to minimize performance variation. The Grey-based Taguchi
Method is adopted for providing an optimal setting for the design parameters of
the robot. The robot prototype is shown to have successfully scaled stairs of
varying dimensions, with overhang, thus corroborating the analysis performed.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03081</identifier>
 <datestamp>2017-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proximal Quasi-Newton Methods for Regularized Convex Optimization with
  Linear and Accelerated Sublinear Convergence Rates</dc:title>
 <dc:creator>Ghanbari, Hiva</dc:creator>
 <dc:creator>Scheinberg, Katya</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In [19], a general, inexact, efficient proximal quasi-Newton algorithm for
composite optimization problems has been proposed and a sublinear global
convergence rate has been established. In this paper, we analyze the
convergence properties of this method, both in the exact and inexact setting,
in the case when the objective function is strongly convex. We also investigate
a practical variant of this method by establishing a simple stopping criterion
for the subproblem optimization. Furthermore, we consider an accelerated
variant, based on FISTA [1], to the proximal quasi-Newton algorithm. A similar
accelerated method has been considered in [7], where the convergence rate
analysis relies on very strong impractical assumptions. We present a modified
analysis while relaxing these assumptions and perform a practical comparison of
the accelerated proximal quasi- Newton algorithm and the regular one. Our
analysis and computational results show that acceleration may not bring any
benefit in the quasi-Newton setting.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03084</identifier>
 <datestamp>2016-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernel-based methods for bandit convex optimization</dc:title>
 <dc:creator>Bubeck, S&#xe9;bastien</dc:creator>
 <dc:creator>Eldan, Ronen</dc:creator>
 <dc:creator>Lee, Yin Tat</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the adversarial convex bandit problem and we build the first
$\mathrm{poly}(T)$-time algorithm with $\mathrm{poly}(n) \sqrt{T}$-regret for
this problem. To do so we introduce three new ideas in the derivative-free
optimization literature: (i) kernel methods, (ii) a generalization of Bernoulli
convolutions, and (iii) a new annealing schedule for exponential weights (with
increasing learning rate). The basic version of our algorithm achieves
$\tilde{O}(n^{9.5} \sqrt{T})$-regret, and we show that a simple variant of this
algorithm can be run in $\mathrm{poly}(n \log(T))$-time per step at the cost of
an additional $\mathrm{poly}(n) T^{o(1)}$ factor in the regret. These results
improve upon the $\tilde{O}(n^{11} \sqrt{T})$-regret and
$\exp(\mathrm{poly}(T))$-time result of the first two authors, and the
$\log(T)^{\mathrm{poly}(n)} \sqrt{T}$-regret and
$\log(T)^{\mathrm{poly}(n)}$-time result of Hazan and Li. Furthermore we
conjecture that another variant of the algorithm could achieve
$\tilde{O}(n^{1.5} \sqrt{T})$-regret, and moreover that this regret is
unimprovable (the current best lower bound being $\Omega(n \sqrt{T})$ and it is
achieved with linear functions). For the simpler situation of zeroth order
stochastic convex optimization this corresponds to the conjecture that the
optimal query complexity is of order $n^3 / \epsilon^2$.
</dc:description>
 <dc:description>Comment: 45 pages</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03085</identifier>
 <datestamp>2016-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Memory Array Structures</dc:title>
 <dc:creator>Rocki, Kamil</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The following report introduces ideas augmenting standard Long Short Term
Memory (LSTM) architecture with multiple memory cells per hidden unit in order
to improve its generalization capabilities. It considers both deterministic and
stochastic variants of memory operation. It is shown that the nondeterministic
Array-LSTM approach improves state-of-the-art performance on character level
text prediction achieving 1.402 BPC on enwik8 dataset. Furthermore, this report
estabilishes baseline neural-based results of 1.12 BPC and 1.19 BPC for enwik9
and enwik10 datasets respectively.
</dc:description>
 <dc:description>Comment: Minor changes</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-10-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03092</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inexact Block Coordinate Descent Methods For Symmetric Nonnegative
  Matrix Factorization</dc:title>
 <dc:creator>Shi, Qingjiang</dc:creator>
 <dc:creator>Sun, Haoran</dc:creator>
 <dc:creator>Lu, Songtao</dc:creator>
 <dc:creator>Hong, Mingyi</dc:creator>
 <dc:creator>Razaviyayn, Meisam</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Symmetric nonnegative matrix factorization (SNMF) is equivalent to computing
a symmetric nonnegative low rank approximation of a data similarity matrix. It
inherits the good data interpretability of the well-known nonnegative matrix
factorization technique and have better ability of clustering nonlinearly
separable data. In this paper, we focus on the algorithmic aspect of the SNMF
problem and propose simple inexact block coordinate decent methods to address
the problem, leading to both serial and parallel algorithms. The proposed
algorithms have guaranteed stationary convergence and can efficiently handle
large-scale and/or sparse SNMF problems. Extensive simulations verify the
effectiveness of the proposed algorithms compared to recent state-of-the-art
algorithms.
</dc:description>
 <dc:description>Comment: Submitted to TSP</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03092</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2731321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03105</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Systholic Boolean Orthonormalizer Network in Wavelet Domain for SAR
  Image Despeckling</dc:title>
 <dc:creator>Mastriani, Mario</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We describe a novel method for removing speckle (in wavelet domain) of
unknown variance from SAR images. The me-thod is based on the following
procedure: We apply 1) Bidimentional Discrete Wavelet Transform (DWT-2D) to the
speckled image, 2) scaling and rounding to the coefficients of the highest
subbands (to obtain integer and positive coefficients), 3) bit-slicing to the
new highest subbands (to obtain bit-planes), 4) then we apply the Systholic
Boolean Orthonormalizer Network (SBON) to the input bit-plane set and we obtain
two orthonormal output bit-plane sets (in a Boolean sense), we project a set on
the other one, by means of an AND operation, and then, 5) we apply
re-assembling, and, 6) re-sca-ling. Finally, 7) we apply Inverse DWT-2D and
reconstruct a SAR image from the modified wavelet coefficients. Despeckling
results compare favorably to the most of methods in use at the moment.
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures, 1 table. arXiv admin note: text overlap with
  arXiv:1405.0632</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03128</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Source-Relay Design for Full--Duplex MIMO AF Relay Systems</dc:title>
 <dc:creator>Shi, Qingjiang</dc:creator>
 <dc:creator>Hong, Mingyi</dc:creator>
 <dc:creator>Gao, Xiqi</dc:creator>
 <dc:creator>Song, Enbin</dc:creator>
 <dc:creator>Cai, Yunlong</dc:creator>
 <dc:creator>Xu, Weiqiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The performance of full-duplex (FD) relay systems can be greatly impacted by
the self-interference (SI) at relays. By exploiting multi-antenna in FD relay
systems, the spectral efficiency of FD relay systems can be enhanced through
spatial SI mitigation. This paper studies joint source transmit beamforming and
relay processing to achieve rate maximization for FD MIMO amplify-and-forward
(AF) relay systems with consideration of relay processing delay. The problem is
difficult to solve due mainly to the SI constraint induced by the relay
processing delay. In this paper, we first present a sufficient condition under
which the relay amplification matrix has rank one structure. Then, for the case
of rank one amplification matrix, the rate maximization problem is equivalently
simplified into an unconstrained problem which can be locally solved using
gradient ascent method. Next, we propose a penalty-based algorithmic framework,
called P-BSUM, for a class of constrained optimization problems which have
difficult equality constraints in addition to some convex constraints. By
rewriting the rate maximization problem with a set of auxiliary variables, we
apply the P-BSUM algorithm to the rate maximization problem in the general
case. Finally, numerical results validate the efficiency of the proposed
algorithms and show that the joint source-relay design approach under the rank
one assumption could be strictly suboptimal as compared to the P-BSUM-based
joint source-relay design approach.
</dc:description>
 <dc:description>Comment: submitted to TSP, 14 pages, 6 figures. It was in part presented in
  ICASSP2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03128</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2605074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03132</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Density of Spherically-Embedded Stiefel and Grassmann Codes</dc:title>
 <dc:creator>Pitaval, Renaud-Alexandre</dc:creator>
 <dc:creator>Wei, Lu</dc:creator>
 <dc:creator>Tirkkonen, Olav</dc:creator>
 <dc:creator>Hollanti, Camilla</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The density of a code is the fraction of the coding space covered by packing
balls centered around the codewords. This paper investigates the density of
codes in the complex Stiefel and Grassmann manifolds equipped with the chordal
distance. The choice of distance enables the treatment of the manifolds as
subspaces of Euclidean hyperspheres. In this geometry, the densest packings are
not necessarily equivalent to maximum-minimum-distance codes. Computing a
code's density follows from computing: i) the normalized volume of a metric
ball and ii) the kissing radius, the radius of the largest balls one can pack
around the codewords without overlapping. First, the normalized volume of a
metric ball is evaluated by asymptotic approximations. The volume of a small
ball can be well-approximated by the volume of a locally-equivalent tangential
ball. In order to properly normalize this approximation, the precise volumes of
the manifolds induced by their spherical embedding are computed. For larger
balls, a hyperspherical cap approximation is used, which is justified by a
volume comparison theorem showing that the normalized volume of a ball in the
Stiefel or Grassmann manifold is asymptotically equal to the normalized volume
of a ball in its embedding sphere as the dimension grows to infinity. Then,
bounds on the kissing radius are derived alongside corresponding bounds on the
density. Unlike spherical codes or codes in flat spaces, the kissing radius of
Grassmann or Stiefel codes cannot be exactly determined from its minimum
distance. It is nonetheless possible to derive bounds on density as functions
of the minimum distance. Stiefel and Grassmann codes have larger density than
their image spherical codes when dimensions tend to infinity. Finally, the
bounds on density lead to refinements of the standard Hamming bounds for
Stiefel and Grassmann codes.
</dc:description>
 <dc:description>Comment: Two-column version (24 pages, 6 figures, 4 tables). To appear in IEEE
  Transactions on Information Theory</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03140</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-Enhanced Architecture for Occupancy-based HVAC Control</dc:title>
 <dc:creator>Jia, Ruoxi</dc:creator>
 <dc:creator>Dong, Roy</dc:creator>
 <dc:creator>Sastry, S. Shankar</dc:creator>
 <dc:creator>Spanos, Costas J.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Large-scale sensing and actuation infrastructures have allowed buildings to
achieve significant energy savings; at the same time, these technologies
introduce significant privacy risks that must be addressed. In this paper, we
present a framework for modeling the trade-off between improved control
performance and increased privacy risks due to occupancy sensing. More
specifically, we consider occupancy-based HVAC control as the control objective
and the location traces of individual occupants as the private variables.
Previous studies have shown that individual location information can be
inferred from occupancy measurements. To ensure privacy, we design an
architecture that distorts the occupancy data in order to hide individual
occupant location information while maintaining HVAC performance. Using mutual
information between the individual's location trace and the reported occupancy
measurement as a privacy metric, we are able to optimally design a scheme to
minimize privacy risk subject to a control performance guarantee. We evaluate
our framework using real-world occupancy data: first, we verify that our
privacy metric accurately assesses the adversary's ability to infer private
variables from the distorted sensor measurements; then, we show that control
performance is maintained through simulations of building operations using
these distorted occupancy readings.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03140</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03161</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A mathematical model for a gaming community</dc:title>
 <dc:creator>Breban, Romulus</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:description>  We consider a large community of individuals who mix strongly and meet in
pairs to bet on a coin toss. We investigate the asset distribution of the
players involved in this zero-sum repeated game. Our main result is that the
asset distribution converges to the exponential distribution, irrespective of
the size of the bet, as long as players can never go bankrupt. Analytical
results suggests that the exponential distribution is a stable fixed point for
this zero-sum repreated game. This is confirmed in numerical experiments.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure</dc:description>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03164</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Cosine Transform to increase speed-up and efficiency of
  Karhunen-Loeve Transform for lossy image compression</dc:title>
 <dc:creator>Mastriani, Mario</dc:creator>
 <dc:creator>Gambini, Juliana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we present a comparison between two techniques of image
compression. In the first case, the image is divided in blocks which are
collected according to zig-zag scan. In the second one, we apply the Fast
Cosine Transform to the image, and then the transformed image is divided in
blocks which are collected according to zig-zag scan too. Later, in both cases,
the Karhunen-Loeve transform is applied to mentioned blocks. On the other hand,
we present three new metrics based on eigenvalues for a better comparative
evaluation of the techniques. Simulations show that the combined version is the
best, with minor Mean Absolute Error (MAE) and Mean Squared Error (MSE), higher
Peak Signal to Noise Ratio (PSNR) and better image quality. Finally, new
technique was far superior to JPEG and JPEG2000.
</dc:description>
 <dc:description>Comment: 10 pages, 20 figures, 2 tables</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03164</dc:identifier>
 <dc:identifier>Intern. Journal of Engineering and Mathematical Sciences. v.6(2),
  pp.82-92 (2010)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03179</identifier>
 <datestamp>2016-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Citation success index - An intuitive pair-wise journal comparison
  metric</dc:title>
 <dc:creator>Milojevi&#x107;, Sta&#x161;a</dc:creator>
 <dc:creator>Radicchi, Filippo</dc:creator>
 <dc:creator>Bar-Ilan, Judit</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this paper we present &quot;citation success index&quot;, a metric for comparing the
citation capacity of pairs of journals. Citation success index is the
probability that a random paper in one journal has more citations than a random
paper in another journal (50% means the two journals do equally well). Unlike
the journal impact factor (IF), the citation success index depends on the
broadness and the shape of citation distributions. Also, it is insensitive to
sporadic highly-cited papers that skew the IF. Nevertheless, we show, based on
16,000 journals containing ~2.4 million articles, that the citation success
index is a relatively tight function of the ratio of IFs of journals being
compared, due to the fact that journals with same IF have quite similar
citation distributions. The citation success index grows slowly as a function
of IF ratio. It is substantial (&gt;90%) only when the ratio of IFs exceeds ~6,
whereas a factor of two difference in IF values translates into a modest
advantage for the journal with higher IF (index of ~70%). We facilitate the
wider adoption of this metric by providing an online calculator that takes as
input parameters only the IFs of the pair of journals.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03182</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stream-based Online Active Learning in a Contextual Multi-Armed Bandit
  Framework</dc:title>
 <dc:creator>Song, Linqi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the stream-based online active learning in a contextual multi-armed
bandit framework. In this framework, the reward depends on both the arm and the
context. In a stream-based active learning setting, obtaining the ground truth
of the reward is costly, and the conventional contextual multi-armed bandit
algorithm fails to achieve a sublinear regret due to this cost. Hence, the
algorithm needs to determine whether or not to request the ground truth of the
reward at current time slot. In our framework, we consider a stream-based
active learning setting in which a query request for the ground truth is sent
to the annotator, together with some prior information of the ground truth.
Depending on the accuracy of the prior information, the query cost varies. Our
algorithm mainly carries out two operations: the refinement of the context and
arm spaces and the selection of actions. In our algorithm, the partitions of
the context space and the arm space are maintained for a certain time slots,
and then become finer as more information about the rewards accumulates. We use
a strategic way to select the arms and to request the ground truth of the
reward, aiming to maximize the total reward. We analytically show that the
regret is sublinear and in the same order with that of the conventional
contextual multi-armed bandit algorithms, where no query cost
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03183</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to calculate partition functions using convex programming
  hierarchies: provable bounds for variational methods</dc:title>
 <dc:creator>Risteski, Andrej</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of approximating partition functions for Ising
models. We make use of recent tools in combinatorial optimization: the
Sherali-Adams and Lasserre convex programming hierarchies, in combination with
variational methods to get algorithms for calculating partition functions in
these families. These techniques give new, non-trivial approximation guarantees
for the partition function beyond the regime of correlation decay. They also
generalize some classical results from statistical physics about the
Curie-Weiss ferromagnetic Ising model, as well as provide a partition function
counterpart of classical results about max-cut on dense graphs
\cite{arora1995polynomial}. With this, we connect techniques from two
apparently disparate research areas -- optimization and counting/partition
function approximations. (i.e. \#-P type of problems).
  Furthermore, we design to the best of our knowledge the first provable,
convex variational methods. Though in the literature there are a host of convex
versions of variational methods \cite{wainwright2003tree, wainwright2005new,
heskes2006convexity, meshi2009convexifying}, they come with no guarantees
(apart from some extremely special cases, like e.g. the graph has a single
cycle \cite{weiss2000correctness}). We consider dense and low threshold rank
graphs, and interestingly, the reason our approach works on these types of
graphs is because local correlations propagate to global correlations --
completely the opposite of algorithms based on correlation decay. In the
process we design novel entropy approximations based on the low-order moments
of a distribution.
  Our proof techniques are very simple and generic, and likely to be applicable
to many other settings other than Ising models.
</dc:description>
 <dc:description>Comment: This paper was accepted for presentation at Conference on Learning
  Theory (COLT) 2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03183</dc:identifier>
 <dc:identifier>29th Annual Conference on Learning Theory (pp. 1402-1416), 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03189</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Estimating Long Term Driver Behavior</dc:title>
 <dc:creator>Gadepally, Vijay</dc:creator>
 <dc:creator>Krishnamurthy, Ashok</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The authors present a cyber-physical systems study on the estimation of
driver behavior in autonomous vehicles and vehicle safety systems. Extending
upon previous work, the approach described is suitable for the long term
estimation and tracking of autonomous vehicle behavior. The proposed system
makes use of a previously defined Hybrid State System and Hidden Markov Model
(HSS+HMM) system which has provided good results for driver behavior
estimation. The HSS+HMM system utilizes the hybrid characteristics of
decision-behavior coupling of many systems such as the driver and the vehicle,
uses Kalman Filter estimates of observable parameters to track the
instantaneous continuous state, and estimates the most likely driver state. The
HSS+HMM system is encompassed in a HSS structure and inter-system connectivity
is determined by using Signal Processing and Pattern Recognition techniques.
The proposed method is suitable for scenarios that involve unknown decisions of
other individuals, such as lane changes or intersection precedence/access. The
long term driver behavior estimation system involves an extended HSS+HMM
structure that is capable of including external information in the estimation
process. Through the grafting and pruning of metastates, the HSS+HMM system can
be dynamically updated to best represent driver choices given external
information. Three application examples are also provided to elucidate the
theoretical system.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03189</dc:identifier>
 <dc:identifier>doi:10.1155/2017/3080859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03191</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Deterministic Conditions for Subspace Clustering under Missing Data</dc:title>
 <dc:creator>Wang, Wenqi</dc:creator>
 <dc:creator>Aeron, Shuchin</dc:creator>
 <dc:creator>Aggarwal, Vaneet</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we present deterministic conditions for success of sparse
subspace clustering (SSC) under missing data, when data is assumed to come from
a Union of Subspaces (UoS) model. We consider two algorithms, which are
variants of SSC with entry-wise zero-filling that differ in terms of the
optimization problems used to find affinity matrix for spectral clustering. For
both the algorithms, we provide deterministic conditions for any pattern of
missing data such that perfect clustering can be achieved. We provide extensive
sets of simulation results for clustering as well as completion of data at
missing entries, under the UoS model. Our experimental results indicate that in
contrast to the full data case, accurate clustering does not imply accurate
subspace identification and completion, indicating the natural order of
relative hardness of these problems.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03193</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Output Observability of Systems Over Finite Alphabets with Linear
  Internal Dynamics</dc:title>
 <dc:creator>Fan, Donglei</dc:creator>
 <dc:creator>Tarraf, Danielle C.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider a class of systems over finite alphabets with linear internal
dynamics, finite-valued control inputs and finitely quantized outputs. We
motivate the need for a new notion of observability and propose three new
notions of output observability, thereby shifting our attention to the problem
of state estimation for output prediction. We derive necessary and sufficient
conditions for a system to be output observable, algorithmic procedures to
verify these conditions, and a construction of finite memory output observers
when certain conditions are met. We conclude with simple illustrative examples.
</dc:description>
 <dc:description>Comment: 26 pages, 3 figures. Submitted for journal publication</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03195</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Step Bayesian Optimization for One-Dimensional Feasibility
  Determination</dc:title>
 <dc:creator>Cashore, J. Massey</dc:creator>
 <dc:creator>Kumarga, Lemuel</dc:creator>
 <dc:creator>Frazier, Peter I.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Bayesian optimization methods allocate limited sampling budgets to maximize
expensive-to-evaluate functions. One-step-lookahead policies are often used,
but computing optimal multi-step-lookahead policies remains a challenge. We
consider a specialized Bayesian optimization problem: finding the superlevel
set of an expensive one-dimensional function, with a Markov process prior. We
compute the Bayes-optimal sampling policy efficiently, and characterize the
suboptimality of one-step lookahead. Our numerical experiments demonstrate that
the one-step lookahead policy is close to optimal in this problem, performing
within 98% of optimal in the experimental settings considered.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03200</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Qualitative Judgement of Research Impact: Domain Taxonomy as a
  Fundamental Framework for Judgement of the Quality of Research</dc:title>
 <dc:creator>Murtagh, Fionn</dc:creator>
 <dc:creator>Orlov, Michael</dc:creator>
 <dc:creator>Mirkin, Boris</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68P01</dc:subject>
 <dc:subject>H.0</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  The appeal of metric evaluation of research impact has attracted considerable
interest in recent times. Although the public at large and administrative
bodies are much interested in the idea, scientists and other researchers are
much more cautious, insisting that metrics are but an auxiliary instrument to
the qualitative peer-based judgement. The goal of this article is to propose
availing of such a well positioned construct as domain taxonomy as a tool for
directly assessing the scope and quality of research. We first show how
taxonomies can be used to analyse the scope and perspectives of a set of
research projects or papers. Then we proceed to define a research team or
researcher's rank by those nodes in the hierarchy that have been created or
significantly transformed by the results of the researcher. An experimental
test of the approach in the data analysis domain is described. Although the
concept of taxonomy seems rather simplistic to describe all the richness of a
research domain, its changes and use can be made transparent and subject to
open discussions.
</dc:description>
 <dc:description>Comment: 22 pages, 7 figures</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03202</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rapid Prediction of Player Retention in Free-to-Play Mobile Games</dc:title>
 <dc:creator>Drachen, Anders</dc:creator>
 <dc:creator>Lundquist, Eric Thurston</dc:creator>
 <dc:creator>Kung, Yungjen</dc:creator>
 <dc:creator>Rao, Pranav Simha</dc:creator>
 <dc:creator>Klabjan, Diego</dc:creator>
 <dc:creator>Sifa, Rafet</dc:creator>
 <dc:creator>Runge, Julian</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Predicting and improving player retention is crucial to the success of mobile
Free-to-Play games. This paper explores the problem of rapid retention
prediction in this context. Heuristic modeling approaches are introduced as a
way of building simple rules for predicting short-term retention. Compared to
common classification algorithms, our heuristic-based approach achieves
reasonable and comparable performance using information from the first session,
day, and week of player activity.
</dc:description>
 <dc:description>Comment: Draft Submitted to AIIDE-16. 7 pages, 5 figures, 3 tables</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03204</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Projection and Approximate Inference for Structured Sparse
  Variables</dc:title>
 <dc:creator>Khanna, Rajiv</dc:creator>
 <dc:creator>Ghosh, Joydeep</dc:creator>
 <dc:creator>Poldrack, Russell</dc:creator>
 <dc:creator>Koyejo, Oluwasanmi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Approximate inference via information projection has been recently introduced
as a general-purpose approach for efficient probabilistic inference given
sparse variables. This manuscript goes beyond classical sparsity by proposing
efficient algorithms for approximate inference via information projection that
are applicable to any structure on the set of variables that admits enumeration
using a \emph{matroid}. We show that the resulting information projection can
be reduced to combinatorial submodular optimization subject to matroid
constraints. Further, leveraging recent advances in submodular optimization, we
provide an efficient greedy algorithm with strong optimization-theoretic
guarantees. The class of probabilistic models that can be expressed in this way
is quite broad and, as we show, includes group sparse regression, group sparse
principal components analysis and sparse canonical correlation analysis, among
others. Moreover, empirical results on simulated data and high dimensional
neuroimaging data highlight the superior performance of the information
projection approach as compared to established baselines for a range of
probabilistic models.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03222</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gland Instance Segmentation by Deep Multichannel Side Supervision</dc:title>
 <dc:creator>Xu, Yan</dc:creator>
 <dc:creator>Li, Yang</dc:creator>
 <dc:creator>Liu, Mingyuan</dc:creator>
 <dc:creator>Wang, Yipei</dc:creator>
 <dc:creator>Lai, Maode</dc:creator>
 <dc:creator>Chang, Eric I-Chao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a new image instance segmentation method that
segments individual glands (instances) in colon histology images. This is a
task called instance segmentation that has recently become increasingly
important. The problem is challenging since not only do the glands need to be
segmented from the complex background, they are also required to be
individually identified. Here we leverage the idea of image-to-image prediction
in recent deep learning by building a framework that automatically exploits and
fuses complex multichannel information, regional and boundary patterns, with
side supervision (deep supervision on side responses) in gland histology
images. Our proposed system, deep multichannel side supervision (DMCS),
alleviates heavy feature design due to the use of convolutional neural networks
guided by side supervision. Compared to methods reported in the 2015 MICCAI
Gland Segmentation Challenge, we observe state-of-the-art results based on a
number of evaluation metrics.
</dc:description>
 <dc:description>Comment: conditionally accepted at MICCAI 2016</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03224</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A fast algorithm for identifying Friends-of-Friends halos</dc:title>
 <dc:creator>Feng, Yu</dc:creator>
 <dc:creator>Modi, Chirag</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We describe a simple and fast algorithm for identifying friends-of-friends
features and prove its correctness. The algorithm avoids unnecessary expensive
neighbor queries, uses minimal memory overhead, and rejects slowdown in high
over-density regions. We define our algorithm formally based on pair
enumeration, a problem that has been heavily studied in fast 2-point
correlation codes and our reference implementation employs a dual KD-tree
correlation function code. We construct features in a hierarchical tree
structure, and use a splay operation to reduce the average cost of identifying
the root of a feature from $O[\log L]$ to $O[1]$ ($L$ is the size of a feature)
without additional memory costs. This reduces the overall time complexity of
merging trees from $O[L\log L]$ to $O[L]$, reducing the number of operations
per splay by orders of magnitude. We next introduce a pruning operation that
skips merge operations between two fully self-connected KD-tree nodes. This
improves the robustness of the algorithm, reducing the number of merge
operations in high density peaks from $O[\delta^2]$ to $O[\delta]$. We show
that for cosmological data set the algorithm eliminates more than half of merge
operations for typically used linking lengths $b \sim 0.2$ (relative to mean
separation). Furthermore, our algorithm is extremely simple and easy to
implement on top of an existing pair enumeration code, reusing the optimization
effort that has been invested in fast correlation function codes.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures. Published in Astronomy and Computing</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03226</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local feature hierarchy for face recognition across pose and
  illumination</dc:title>
 <dc:creator>Jiang, Xiaoyue</dc:creator>
 <dc:creator>Zhang, Dong</dc:creator>
 <dc:creator>Feng, Xiaoyi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Even though face recognition in frontal view and normal lighting condition
works very well, the performance degenerates sharply in extreme conditions.
Recently there are many work dealing with pose and illumination problems,
respectively. However both the lighting and pose variation will always be
encountered at the same time. Accordingly we propose an end-to-end face
recognition method to deal with pose and illumination simultaneously based on
convolutional networks where the discriminative nonlinear features that are
invariant to pose and illumination are extracted. Normally the global structure
for images taken in different views is quite diverse. Therefore we propose to
use the 1*1 convolutional kernel to extract the local features. Furthermore the
parallel multi-stream multi-layer 1*1 convolution network is developed to
extract multi-hierarchy features. In the experiments we obtained the average
face recognition rate of 96.9% on multiPIE dataset,which improves the
state-of-the-art of face recognition across poses and illumination by 7.5%.
Especially for profile-wise positions, the average recognition rate of our
proposed network is 97.8%, which increases the state-of-the-art recognition
rate by 19%.
</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03227</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum-Power Trading for Energy-Efficient Small Cell</dc:title>
 <dc:creator>Wu, Qingqing</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:creator>Chen, Wen</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates spectrum-power trading be- tween a small cell (SC)
and a macro-cell (MC), where the SC consumes power to serve the macro-cell
users (MUs) in exchange for some bandwidth from the MC. Our goal is to maximize
the system energy efficiency (EE) of the SC while guaranteeing the quality of
service (QoS) of each MU as well as small cell users (SUs). Specifically, given
the minimum data rate requirement and the bandwidth provided by the MC, the SC
jointly optimizes MU selection, bandwidth allocation, and power allocation
while guaranteeing its own minimum required system data rate. The problem is
challenging due to the binary MU selection variables and the fractional form
objective function. We first show that in order to achieve the maximum system
EE, the bandwidth of an MU is shared with at most one SU in the SC. Then, for a
given MU selection, the optimal bandwidth and power allocations are obtained by
exploiting the fractional programming. To perform MU selection, we first
introduce the concept of trading EE. Then, we reveal a sufficient and necessary
condition for serving an MU without considering the total power constraint and
the minimum data rate constraint. Based on this insight, we propose a low
computational complexity MU selection algorithm. Simulation results demonstrate
the effectiveness of the proposed algorithms.
</dc:description>
 <dc:description>Comment: 2016 Globecom, Green Communication Systems and Networks (GCSN)</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03238</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scratchpad Sharing in GPUs</dc:title>
 <dc:creator>Jatala, Vishwesh</dc:creator>
 <dc:creator>Anantpur, Jayvant</dc:creator>
 <dc:creator>Karkare, Amey</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  GPGPU applications exploit on-chip scratchpad memory available in the
Graphics Processing Units (GPUs) to improve performance. The amount of thread
level parallelism present in the GPU is limited by the number of resident
threads, which in turn depends on the availability of scratchpad memory in its
streaming multiprocessor (SM). Since the scratchpad memory is allocated at
thread block granularity, part of the memory may remain unutilized. In this
paper, we propose architectural and compiler optimizations to improve the
scratchpad utilization. Our approach, Scratchpad Sharing, addresses scratchpad
under-utilization by launching additional thread blocks in each SM. These
thread blocks use unutilized scratchpad and also share scratchpad with other
resident blocks. To improve the performance of scratchpad sharing, we propose
Owner Warp First (OWF) scheduling that schedules warps from the additional
thread blocks effectively. The performance of this approach, however, is
limited by the availability of the shared part of scratchpad.
  We propose compiler optimizations to improve the availability of shared
scratchpad. We describe a scratchpad allocation scheme that helps in allocating
scratchpad variables such that shared scratchpad is accessed for short
duration. We introduce a new instruction, relssp, that when executed, releases
the shared scratchpad. Finally, we describe an analysis for optimal placement
of relssp instructions such that shared scratchpad is released as early as
possible.
  We implemented the hardware changes using the GPGPU-Sim simulator and
implemented the compiler optimizations in Ocelot framework. We evaluated the
effectiveness of our approach on 19 kernels from 3 benchmarks suites: CUDA-SDK,
GPGPU-Sim, and Rodinia. The kernels that underutilize scratchpad memory show an
average improvement of 19% and maximum improvement of 92.17% compared to the
baseline approach.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03239</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The SensorCloud Protocol: Securely Outsourcing Sensor Data to the Cloud</dc:title>
 <dc:creator>Henze, Martin</dc:creator>
 <dc:creator>Hummen, Ren&#xe9;</dc:creator>
 <dc:creator>Matzutt, Roman</dc:creator>
 <dc:creator>Wehrle, Klaus</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The increasing deployment of sensor networks, ranging from home networks to
industrial automation, leads to a similarly growing demand for storing and
processing the collected sensor data. To satisfy this demand, the most
promising approach to date is the utilization of the dynamically scalable,
on-demand resources made available via the cloud computing paradigm. However,
prevalent security and privacy concerns are a huge obstacle for the outsourcing
of sensor data to the cloud. Hence, sensor data needs to be secured properly
before it can be outsourced to the cloud. When securing the outsourcing of
sensor data to the cloud, one important challenge lies in the representation of
sensor data and the choice of security measures applied to it. In this paper,
we present the SensorCloud protocol, which enables the representation of sensor
data and actuator commands using JSON as well as the encoding of the object
security mechanisms applied to a given sensor data item. Notably, we solely
utilize mechanisms that have been or currently are in the process of being
standardized at the IETF to aid the wide applicability of our approach.
</dc:description>
 <dc:description>Comment: 19 pages, 1 figure, published as technical report of the Department
  of Computer Science of RWTH Aachen University</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03240</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Supervised Learning of Heterogeneous Concepts in Videos</dc:title>
 <dc:creator>Shah, Sohil</dc:creator>
 <dc:creator>Kulkarni, Kuldeep</dc:creator>
 <dc:creator>Biswas, Arijit</dc:creator>
 <dc:creator>Gandhi, Ankit</dc:creator>
 <dc:creator>Deshmukh, Om</dc:creator>
 <dc:creator>Davis, Larry</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Typical textual descriptions that accompany online videos are 'weak': i.e.,
they mention the main concepts in the video but not their corresponding
spatio-temporal locations. The concepts in the description are typically
heterogeneous (e.g., objects, persons, actions). Certain location constraints
on these concepts can also be inferred from the description. The goal of this
paper is to present a generalization of the Indian Buffet Process (IBP) that
can (a) systematically incorporate heterogeneous concepts in an integrated
framework, and (b) enforce location constraints, for efficient classification
and localization of the concepts in the videos. Finally, we develop posterior
inference for the proposed formulation using mean-field variational
approximation. Comparative evaluations on the Casablanca and the A2D datasets
show that the proposed approach significantly outperforms other
state-of-the-art techniques: 24% relative improvement for pairwise concept
classification in the Casablanca dataset and 9% relative improvement for
localization in the A2D dataset as compared to the most competitive baseline.
</dc:description>
 <dc:description>Comment: To appear at ECCV 2016</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03243</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCOR: Software-defined Constrained Optimal Routing Platform for SDN</dc:title>
 <dc:creator>Layeghy, Siamak</dc:creator>
 <dc:creator>Pakzad, Farzaneh</dc:creator>
 <dc:creator>Portmann, Marius</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>68M10, 90B18, 90B20, 90B22, 90C09, 90C27, 90C29, 90C35</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  A Software-defined Constrained Optimal Routing (SCOR) platform is introduced
as a Northbound interface in SDN architecture. It is based on constraint
programming techniques and is implemented in MiniZinc modelling language. Using
constraint programming techniques in this Northbound interface has created an
efficient tool for implementing complex Quality of Service routing applications
in a few lines of code. The code includes only the problem statement and the
solution is found by a general solver program. A routing framework is
introduced based on SDN's architecture model which uses SCOR as its Northbound
interface and an upper layer of applications implemented in SCOR. Performance
of a few implemented routing applications are evaluated in different network
topologies, network sizes and various number of concurrent flows.
</dc:description>
 <dc:description>Comment: 19 pages, 11 figures, 11 algorithms, 3 tables</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03245</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Programming Internet of Things, Service, and People (IoTSP) Applications</dc:title>
 <dc:creator>Chauhan, Saurabh</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Application development for Internet of Things, Service, and People (IoTSP)
is challenging because it involves dealing with the heterogeneity that exists
both in Physical and Internet worlds. Second, stakeholders involved in the
application development have to address issues pertaining to different
life-cycles ranging from design, implementation to deployment. Given these, a
critical challenge is to enable an application development for IoTSP
applications with effectively and efficiently from various stakeholders.
Several approaches to tackling this challenge have been proposed in the fields
of Wireless Sensor Networks (WSN) and Pervasive Computing, regarded as
precursors to the modern day of IoTSP. However, existing approaches only cover
limited subsets of the above mentioned challenges when applied to the IoTSP. In
view of this, we have built upon existing framework and evolved it into a
framework for developing IoTSP applications, with substantial additions and
enhancements in high-level modeling languages and their integration into the
framework, and we present a comparative evaluation results with existing
approaches. This provides the IoTSP community for further benchmarking. The
evaluation is carried out on real devices exhibiting heterogeneity. Our
experimental analysis and results demonstrate that our approach drastically
reduces development effort for IoTSP applications compared to existing
approaches.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1501.05080,
  arXiv:1606.02119 by other authors</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03250</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Trimming: A Data-Driven Neuron Pruning Approach towards
  Efficient Deep Architectures</dc:title>
 <dc:creator>Hu, Hengyuan</dc:creator>
 <dc:creator>Peng, Rui</dc:creator>
 <dc:creator>Tai, Yu-Wing</dc:creator>
 <dc:creator>Tang, Chi-Keung</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  State-of-the-art neural networks are getting deeper and wider. While their
performance increases with the increasing number of layers and neurons, it is
crucial to design an efficient deep architecture in order to reduce
computational and memory costs. Designing an efficient neural network, however,
is labor intensive requiring many experiments, and fine-tunings. In this paper,
we introduce network trimming which iteratively optimizes the network by
pruning unimportant neurons based on analysis of their outputs on a large
dataset. Our algorithm is inspired by an observation that the outputs of a
significant portion of neurons in a large network are mostly zero, regardless
of what inputs the network received. These zero activation neurons are
redundant, and can be removed without affecting the overall accuracy of the
network. After pruning the zero activation neurons, we retrain the network
using the weights before pruning as initialization. We alternate the pruning
and retraining to further reduce zero activations in a network. Our experiments
on the LeNet and VGG-16 show that we can achieve high compression ratio of
parameters without losing or even achieving higher accuracy than the original
network.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03252</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling massively parallel multigrid for multilevel Monte Carlo
  methods</dc:title>
 <dc:creator>Gmeiner, Bj&#xf6;rn</dc:creator>
 <dc:creator>Drzisga, Daniel</dc:creator>
 <dc:creator>Ruede, Ulrich</dc:creator>
 <dc:creator>Scheichl, Robert</dc:creator>
 <dc:creator>Wohlmuth, Barbara</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  The computational complexity of naive, sampling-based uncertainty
quantification for 3D partial differential equations is extremely high.
Multilevel approaches, such as multilevel Monte Carlo (MLMC), can reduce the
complexity significantly, but to exploit them fully in a parallel environment,
sophisticated scheduling strategies are needed. Often fast algorithms that are
executed in parallel are essential to compute fine level samples in 3D, whereas
to compute individual coarse level samples only moderate numbers of processors
can be employed efficiently. We make use of multiple instances of a parallel
multigrid solver combined with advanced load balancing techniques. In
particular, we optimize the concurrent execution across the three layers of the
MLMC method: parallelization across levels, across samples, and across the
spatial grid. The overall efficiency and performance of these methods will be
analyzed. Here the scalability window of the multigrid solver is revealed as
being essential, i.e., the property that the solution can be computed with a
range of process numbers while maintaining good parallel efficiency. We
evaluate the new scheduling strategies in a series of numerical tests, and
conclude the paper demonstrating large 3D scaling experiments.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03254</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NxWLAN: Neighborhood eXtensible WLAN</dc:title>
 <dc:creator>Gaw&#x142;owicz, Piotr</dc:creator>
 <dc:creator>Zehl, Sven</dc:creator>
 <dc:creator>Zubow, Anatolij</dc:creator>
 <dc:creator>Wolisz, Adam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The increased usage of IEEE 802.11 Wireless LAN (WLAN) in residential
environments by unexperienced users leads to dense, unplanned and chaotic
residential WLAN deployments. Often WLAN Access Points (APs) are deployed
unprofitable in terms of radio coverage and interference conditions. In many
cases the usage of the neighbor's AP would be beneficial as it would provide
better radio coverage in some parts of the residential user's apartment.
Moreover, the network performance can be dramatically improved by balancing the
network load over spatially co-located APs.
  We address this problem by presenting Neighborhood extensible WLAN (NxWLAN)
which enables the secure extension of user's home WLANs through usage of
neighboring APs in residential environments with zero configuration efforts and
without revealing WPA2 encryption keys to untrusted neighbor APs. NxWLAN makes
use of virtualization techniques utilizing neighboring AP by deploying
on-demand a Wireless Termination Point (WTP) on the neighboring AP and by
tunneling encrypted 802.11 traffic to the Virtual Access Point (VAP) residing
on the home AP. This allows the client devices to always authenticate against
the home AP using the WPA2-PSK passphrase already stored in the device without
any additional registration process.
  We implemented NxWLAN prototypically using off-the-shelf hardware and open
source software. As the OpenFlow is not suited for forwarding native 802.11
frames, we built software switch using P4 language. The performance evaluation
in a small 802.11 indoor testbed showed the feasibility of our approach. NxWLAN
is provided to the community as open source.
</dc:description>
 <dc:description>Comment: Technical report, Telecommunication Networks Group, Technische
  Universitaet Berlin</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03255</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Variational Model for Joint Motion Estimation and Image Reconstruction</dc:title>
 <dc:creator>Burger, Martin</dc:creator>
 <dc:creator>Dirks, Hendrik</dc:creator>
 <dc:creator>Sch&#xf6;nlieb, Carola-Bibiane</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>68U10, 65K10, 65M06</dc:subject>
 <dc:description>  The aim of this paper is to derive and analyze a variational model for the
joint estimation of motion and reconstruction of image sequences, which is
based on a time-continuous Eulerian motion model. The model can be set up in
terms of the continuity equation or the brightness constancy equation. The
analysis in this paper focuses on the latter for robust motion estimation on
sequences of two-dimensional images. We rigorously prove the existence of a
minimizer in a suitable function space setting. Moreover, we discuss the
numerical solution of the model based on primal-dual algorithms and investigate
several examples. Finally, the benefits of our model compared to existing
techniques, such as sequential image reconstruction and motion estimation, are
shown.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03257</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>City-Identification of Flickr Videos Using Semantic Acoustic Features</dc:title>
 <dc:creator>Elizalde, Benjamin</dc:creator>
 <dc:creator>Chao, Guan-Lin</dc:creator>
 <dc:creator>Zeng, Ming</dc:creator>
 <dc:creator>Lane, Ian</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  City-identification of videos aims to determine the likelihood of a video
belonging to a set of cities. In this paper, we present an approach using only
audio, thus we do not use any additional modality such as images, user-tags or
geo-tags. In this manner, we show to what extent the city-location of videos
correlates to their acoustic information. Success in this task suggests
improvements can be made to complement the other modalities. In particular, we
present a method to compute and use semantic acoustic features to perform
city-identification and the features show semantic evidence of the
identification. The semantic evidence is given by a taxonomy of urban sounds
and expresses the potential presence of these sounds in the city- soundtracks.
We used the MediaEval Placing Task set, which contains Flickr videos labeled by
city. In addition, we used the UrbanSound8K set containing audio clips labeled
by sound- type. Our method improved the state-of-the-art performance and
provides a novel semantic approach to this task
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03258</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Target Directed Event Sequence Generation for Android Applications</dc:title>
 <dc:creator>Yan, Jiwei</dc:creator>
 <dc:creator>Wu, Tianyong</dc:creator>
 <dc:creator>Yan, Jun</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68N01</dc:subject>
 <dc:description>  Testing is a commonly used approach to ensure the quality of software, of
which model-based testing is a hot topic to test GUI programs such as Android
applications (apps). Existing approaches mainly either dynamically construct a
model that only contains the GUI information, or build a model in the view of
code that may fail to describe the changes of GUI widgets during runtime.
Besides, most of these models do not support back stack that is a particular
mechanism of Android. Therefore, this paper proposes a model LATTE that is
constructed dynamically with consideration of the view information in the
widgets as well as the back stack, to describe the transition between GUI
widgets. We also propose a label set to link the elements of the LATTE model to
program snippets. The user can define a subset of the label set as a target for
the testing requirements that need to cover some specific parts of the code. To
avoid the state explosion problem during model construction, we introduce a
definition &quot;state similarity&quot; to balance the model accuracy and analysis cost.
Based on this model, a target directed test generation method is presented to
generate event sequences to effectively cover the target. The experiments on
several real-world apps indicate that the generated test cases based on LATTE
can reach a high coverage, and with the model we can generate the event
sequences to cover a given target with short event sequences.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03258</dc:identifier>
 <dc:identifier>QRS 2017, pages 42-53</dc:identifier>
 <dc:identifier>doi:10.1109/QRS.2017.14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03260</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modified LLL algorithm with shifted start column</dc:title>
 <dc:creator>Ouni, Nizar</dc:creator>
 <dc:creator>Bouallegue, Ridha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Multiple-input multiple-output (MIMO) systems are playing an important role
in the recent wireless communication. The complexity of the different systems
models challenge different researches to get a good complexity to performance
balance. Lattices Reduction Techniques and Lenstra-Lenstra-Lovasz (LLL)
algorithm bring more resources to investigate and can contribute to the
complexity reduction purposes. In this paper, we are looking to modify the LLL
algorithm to reduce the computation operations by exploiting the structure of
the upper triangular matrix without big performance degradation. Basically, the
first columns of the upper triangular matrix contain many zeroes, so the
algorithm will perform several operations with very limited income. We are
presenting a performance and complexity study and our proposal show that we can
gain in term of complexity while the performance results remains almost the
same.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03260</dc:identifier>
 <dc:identifier>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  8, No. 3, June 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03270</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced VIP Algorithms for Forwarding, Caching, and Congestion Control
  in Named Data Networks</dc:title>
 <dc:creator>Cui, Ying</dc:creator>
 <dc:creator>Lai, Fan</dc:creator>
 <dc:creator>Yeh, Edmund</dc:creator>
 <dc:creator>Liu, Ran</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Emerging Information-Centric Networking (ICN) architectures seek to optimally
utilize both bandwidth and storage for efficient content distribution over the
network. The Virtual Interest Packet (VIP) framework has been proposed to
enable joint design of forwarding, caching, and congestion control strategies
within the Named Data Networking (NDN) architecture. While the existing VIP
algorithms exhibit good performance, they are primarily focused on maximizing
network throughput and utility, and do not explicitly consider user delay. In
this paper, we develop a new class of enhanced algorithms for joint dynamic
forwarding, caching and congestion control within the VIP framework. These
enhanced VIP algorithms adaptively stabilize the network and maximize network
utility, while improving the delay performance by intelligently making use of
VIP information beyond one hop. Generalizing Lyapunov drift techniques, we
prove the throughput optimality and characterize the utility-delay tradeoff of
the enhanced VIP algorithms. Numerical experiments demonstrate the superior
performance of the resulting enhanced algorithms for handling Interest Packets
and Data Packets within the actual plane, in terms of low network delay and
high network utility.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, to appear in IEEE GLOBECOM 2016. arXiv admin
  note: text overlap with arXiv:1310.5569</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03272</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance and Complexity Analysis of a Reduced Iterations LLL
  Algorithm</dc:title>
 <dc:creator>Ouni, Nizar</dc:creator>
 <dc:creator>Bouallegue, Ridha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Multiple-input multiple-output (MIMO) systems are playing an increasing and
interesting role in the recent wireless communication. The complexity and the
performance of the systems are driving the different studies and researches.
Lattices Reduction techniques bring more resources to investigate the
complexity and performances of such systems. In this paper, we look to modify a
fixed complexity verity of the LLL algorithm to reduce the computation
operations by reducing the number of iterations without important performance
degradation. Our proposal shows that we can achieve a good performance results
while avoiding extra iteration that does not bring much performance.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1607.03260</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03272</dc:identifier>
 <dc:identifier>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.8, No.3, May 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03273</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalar Quadratic-Gaussian Soft Watermarking Games</dc:title>
 <dc:creator>Mihcak, Kivanc</dc:creator>
 <dc:creator>Akyol, Emrah</dc:creator>
 <dc:creator>Basar, Tamer</dc:creator>
 <dc:creator>Langbort, Cedric</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  We introduce the zero-sum game problem of soft watermarking: The hidden
information (watermark) comes from a continuum and has a perceptual value; the
receiver generates an estimate of the embedded watermark to minimize the
expected estimation error (unlike the conventional watermarking schemes where
both the hidden information and the receiver output are from a discrete finite
set). Applications include embedding a multimedia content into another. We
consider in this paper the scalar Gaussian case and use expected mean-squared
distortion. We formulate the resulting problem as a zero-sum game between the
encoder &amp; receiver pair and the attacker. We show that for the lin- ear
encoder, the optimal attacker is Gaussian-affine, derive the optimal system
parameters in that case, and discuss the corresponding system behavior. We also
provide numerical results to gain further insight and understanding of the
system behavior at optimality.
</dc:description>
 <dc:description>Comment: submitted for publication</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03274</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Cross-Platform Collection of Social Network Profiles</dc:title>
 <dc:creator>Veiga, Maria Han</dc:creator>
 <dc:creator>Eickhoff, Carsten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The proliferation of Internet-enabled devices and services has led to a
shifting balance between digital and analogue aspects of our everyday lives. In
the face of this development there is a growing demand for the study of privacy
hazards, the potential for unique user de-anonymization and information leakage
between the various social media profiles many of us maintain. To enable the
structured study of such adversarial effects, this paper presents a dedicated
dataset of cross-platform social network personas (i.e., the same person has
accounts on multiple platforms). The corpus comprises 850 users who generate
predominantly English content. Each user object contains the online footprint
of the same person in three distinct social networks: Twitter, Instagram and
Foursquare. In total, it encompasses over 2.5M tweets, 340k check-ins and 42k
Instagram posts. We describe the collection methodology, characteristics of the
dataset, and how to obtain it. Finally, we discuss a common use case,
cross-platform user identification.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures, SIGIR 2016, short paper. SIGIR 2016 Proceedings
  of the 39th International ACM SIGIR conference on Research and Development in
  Information Retrieval</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03274</dc:identifier>
 <dc:identifier>doi:10.1145/2911451.2914666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03276</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and simple decycling and dismantling of networks</dc:title>
 <dc:creator>Zdeborov&#xe1;, Lenka</dc:creator>
 <dc:creator>Zhang, Pan</dc:creator>
 <dc:creator>Zhou, Hai-Jun</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Decycling and dismantling of complex networks are underlying many important
applications in network science. Recently these two closely related problems
were tackled by several heuristic algorithms, simple and considerably
sub-optimal, on the one hand, and time-consuming message-passing ones that
evaluate single-node marginal probabilities, on the other hand. In this paper
we propose a simple and extremely fast algorithm, CoreHD, which recursively
removes nodes of the highest degree from the $2$-core of the network. CoreHD
performs much better than all existing simple algorithms. When applied on
real-world networks, it achieves equally good solutions as those obtained by
the state-of-art iterative message-passing algorithms at greatly reduced
computational cost, suggesting that CoreHD should be the algorithm of choice
for many practical purposes.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03280</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytical and Simulation Performance of a Typical User in Random
  Cellular Network</dc:title>
 <dc:creator>Lam, Sinh Cong</dc:creator>
 <dc:creator>Sandrasegaran, Kumbesan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Spatial Poisson Point Process (PPP) network, whose Base Stations (BS)s are
distributed according to a Poisson distribution, is currently used as a
accurate model to analyse the performance of a cellular network. Most current
work on evaluation of PPP network in Rayleigh fading channels are usually
assumed that the BSs have fixed transmission power levels and there is only a
Resource Block (RB) or a user in each cell. In this paper, the
Rayleigh-Lognormal fading channels are considered, and it is assumed that each
cell is allocated $N$ Resource Blocks (RB) to serve M users. Furthermore, the
serving and interfering BS of a typical user are assumed to transmit at
different power levels. The closed-form expression for the network coverage
probability for both low and high SNR is derived by using Gauss-Legendre
approximation. The analytical results indicates that the performance of the
typical user is proportional to the transmission power and density of BSs when
SNR&lt;10 dB and {\lambda}&lt;1, and reaches the upper bound when SNR&gt;10 dB or
{\lambda}&gt;1. The variance of Monte Carlo simulation is considered to verify the
stability and accuracy of simulation results.
</dc:description>
 <dc:description>Comment: Accepted for publication in Journal of Network in March 2016</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03284</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Machine learning approach for Shape From Shading</dc:title>
 <dc:creator>Abada, Lyes</dc:creator>
 <dc:creator>Aouat, Saliha</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The aim of Shape From Shading (SFS) problem is to reconstruct the relief of
an object from a single gray level image. In this paper we present a new method
to solve the problem of SFS using Machine learning method. Our approach belongs
to Local resolution category. The orientation of each part of the object is
represented by the perpendicular vector to the surface (Normal Vector), this
vector is defined by two angles SLANT and TILT, such as the TILT is the angle
between the normal vector and Z-axis, and the SLANT is the angle between the
the X-axis and the projection of the normal to the plane. The TILT can be
determined from the gray level, the unknown is the SLANT. To calculate the
normal of each part of the surface (pixel) a supervised Machine learning method
has been proposed. This method divided into three steps: the first step is the
preparation of the training data from 3D mathematical functions and synthetic
objects. The second step is the creation of database of examples from 3D
objects (off-line process). The third step is the application of test images
(on-line process). The idea is to find for each pixel of the test image the
most similar element in the examples database using a similarity value.
</dc:description>
 <dc:description>Comment: 2nd International Conference on Signal, Image, Vision and their
  Applications (SIVA'13), November 18-20, 2013 - Guelma, Algeria</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03286</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Ho-Zhao Problem</dc:title>
 <dc:creator>Ho, Weng Kin</dc:creator>
 <dc:creator>Goubault-Larrecq, Jean</dc:creator>
 <dc:creator>Jung, Achim</dc:creator>
 <dc:creator>Xi, Xiaoyong</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>06B35</dc:subject>
 <dc:description>  Given a poset $P$, the set, $\Gamma(P)$, of all Scott closed sets ordered by
inclusion forms a complete lattice. A subcategory $\mathbf{C}$ of
$\mathbf{Pos}_d$ (the category of posets and Scott-continuous maps) is said to
be $\Gamma$-faithful if for any posets $P$ and $Q$ in $\mathbf{C}$, $\Gamma(P)
\cong \Gamma(Q)$ implies $P \cong Q$. It is known that the category of all
continuous dcpos and the category of bounded complete dcpos are
$\Gamma$-faithful, while $\mathbf{Pos}_d$ is not. Ho &amp; Zhao (2009) asked
whether the category $\mathbf{DCPO}$ of dcpos is $\Gamma$-faithful. In this
paper, we answer this question in the negative by exhibiting a counterexample.
To achieve this, we introduce a new subcategory of dcpos which is
$\Gamma$-faithful. This subcategory subsumes all currently known
$\Gamma$-faithful subcategories. With this new concept in mind, we construct
the desired counterexample which relies heavily on Johnstone's famous dcpo
which is not sober in its Scott topology.
</dc:description>
 <dc:description>Comment: 19 pages, 4 figures</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03286</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-14(1:7)2018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03289</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boundary conditions for Shape from Shading</dc:title>
 <dc:creator>Abada, Lyes</dc:creator>
 <dc:creator>Aouat, Saliha</dc:creator>
 <dc:creator>Bourahla, Omar el farouk</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The Shape From Shading is one of a computer vision field. It studies the 3D
reconstruction of an object from a single grayscale image. The difficulty of
this field can be expressed in the local ambiguity (convex / concave). J.Shi
and Q.Zhu have proposed a method (Global View) to solve the local ambiguity.
This method based on the graph theory and the relationship between the singular
points. In this work we will show that the use of singular points is not
sufficient and requires further information on the object to resolve this
ambiguity.
</dc:description>
 <dc:description>Comment: International Conference on Pattern Analysis and Intelligent Systems
  (PAIS'15), October.26-27, 2015 - Tebessa, Algeria</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03290</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Bridge Bidding Using Deep Reinforcement Learning</dc:title>
 <dc:creator>Yeh, Chih-Kuan</dc:creator>
 <dc:creator>Lin, Hsuan-Tien</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Bridge is among the zero-sum games for which artificial intelligence has not
yet outperformed expert human players. The main difficulty lies in the bidding
phase of bridge, which requires cooperative decision making under partial
information. Existing artificial intelligence systems for bridge bidding rely
on and are thus restricted by human-designed bidding systems or features. In
this work, we propose a pioneering bridge bidding system without the aid of
human domain knowledge. The system is based on a novel deep reinforcement
learning model, which extracts sophisticated features and learns to bid
automatically based on raw card data. The model includes an
upper-confidence-bound algorithm and additional techniques to achieve a balance
between exploration and exploitation. Our experiments validate the promising
performance of our proposed model. In particular, the model advances from
having no knowledge about bidding to achieving superior performance when
compared with a champion-winning computer bridge program that implements a
human-designed bidding system.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure, 2016 ECAI accepted</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03292</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quadboost: A Scalable Concurrent Quadtree</dc:title>
 <dc:creator>Zhou, Keren</dc:creator>
 <dc:creator>Tan, Guangming</dc:creator>
 <dc:creator>Zhou, Wei</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Building concurrent spatial trees is more complicated than binary search
trees since a space hierarchy should be preserved during modifications. We
present a non-blocking quadtree-quadboost-that supports concurrent insert,
remove, move, and contain operations. To increase its concurrency, we propose a
decoupling approach that separates physical adjustment from logical removal
within the remove operation. In addition, we design a continuous find mechanism
to reduce its search cost. The move operation combines the searches for
different keys together and modifies different positions with atomicity. The
experimental results show that quadboost scales well on a multi-core system
with 32 hardware threads. More than that, it outperforms existing concurrent
trees in retrieving two-dimensional keys with up to 109% improvement when the
number of threads is large. The move operation proved to perform better than
the best-known algorithm, with up to 47%.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03296</identifier>
 <datestamp>2016-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implicit Negative Feedback in Clinical Information Retrieval</dc:title>
 <dc:creator>Kuhn, Lorenz</dc:creator>
 <dc:creator>Eickhoff, Carsten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this paper, we reflect on ways to improve the quality of bio-medical
information retrieval by drawing implicit negative feedback from negated
information in noisy natural language search queries. We begin by studying the
extent to which negations occur in clinical texts and quantify their
detrimental effect on retrieval performance. Subsequently, we present a number
of query reformulation and ranking approaches that remedy these shortcomings by
resolving natural language negations. Our experimental results are based on
data collected in the course of the TREC Clinical Decision Support Track and
show consistent improvements compared to state-of-the-art methods. Using our
novel algorithms, we are able to reduce the negative impact of negations on
early precision by up to 65%.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03296</dc:identifier>
 <dc:identifier>doi:10.1145/2911451.2917761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03305</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Camera Elevation Estimation from a Single Mountain Landscape Photograph</dc:title>
 <dc:creator>Cadik, Martin</dc:creator>
 <dc:creator>Vasicek, Jan</dc:creator>
 <dc:creator>Hradis, Michal</dc:creator>
 <dc:creator>Radenovic, Filip</dc:creator>
 <dc:creator>Chum, Ondrej</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work addresses the problem of camera elevation estimation from a single
photograph in an outdoor environment. We introduce a new benchmark dataset of
one-hundred thousand images with annotated camera elevation called Alps100K. We
propose and experimentally evaluate two automatic data-driven approaches to
camera elevation estimation: one based on convolutional neural networks, the
other on local features. To compare the proposed methods to human performance,
an experiment with 100 subjects is conducted. The experimental results show
that both proposed approaches outperform humans and that the best result is
achieved by their combination.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03305</dc:identifier>
 <dc:identifier>In Xianghua Xie, Mark W. Jones, and Gary K. L. Tam, editors,
  Proceedings of the British Machine Vision Conference (BMVC), pages
  30.1-30.12. BMVA Press, September 2015</dc:identifier>
 <dc:identifier>doi:10.5244/C.29.30</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03306</identifier>
 <datestamp>2016-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Automatic Identification System (AIS) Database for Maritime
  Trajectory Prediction and Data Mining</dc:title>
 <dc:creator>Mao, Shangbo</dc:creator>
 <dc:creator>Tu, Enmei</dc:creator>
 <dc:creator>Zhang, Guanghao</dc:creator>
 <dc:creator>Rachmawati, Lily</dc:creator>
 <dc:creator>Rajabally, Eshan</dc:creator>
 <dc:creator>Huang, Guang-Bin</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In recent years, maritime safety and efficiency become more and more
important across the world. Automatic Identification System (AIS) tracks vessel
movement by onboard transceiver and terrestrial and/or satellite base station.
The data collected by AIS contains broadcast kinematic information and static
information. Both of them are useful for anomaly detection and route prediction
which are key techniques in intelligent maritime research area. This paper is
devoted to construct a standard AIS database for maritime trajectory learning,
prediction and data mining. A path prediction algorithm is tested on this AIS
database and the testing results show this database can be used as a
standardized training resource for different trajectory prediction algorithms
and other AIS data mining algorithms.
</dc:description>
 <dc:description>Comment: Accepted in ELM2016</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03307</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Introductory Course to Judgment Aggregation</dc:title>
 <dc:creator>Slavkovik, Marija</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Reaching some form of consensus is often necessary for autonomous agents that
want to coordinate their actions or otherwise engage in joint activities. One
way to reach a consensus is by aggregating individual information, such as
decisions, beliefs, preferences and constraints. Judgment aggregation is a
social choice method, which generalises voting, that studies the aggregation of
individual judgments regarding the truth-value of logically related
propositions. As such, judgment aggregation is applicable for consensus
reaching problems in multi agent systems. As other social choice theory,
judgment aggregation research is abundant with impossibility results. However,
the aim of this tutorial is to give an introduction to the methods of judgment
aggregation, not the impossibility results. In particular, the tutorial will
introduce the basic frameworks that model judgment aggregation problems and
give an overview of the judgment aggregation functions so far developed as well
as their social theoretic and computational complexity properties. The focus of
the tutorial are consensus reaching problems in multi agent systems that can be
modelled as judgment aggregation problems. The desirable properties of a
judgment aggregation method applied to these problems are not necessarily the
same as properties desirable in legal or political contexts, which is
considered to be the native domain of judgment aggregation. After this tutorial
the participants are expected to be able to read and understand judgment
aggregation literature and have a grasp on the state-of-the-art and open
questions in judgment aggregation research of interest to multi agent systems.
</dc:description>
 <dc:description>Comment: These lecture notes accompany the course &quot;An Introduction to Judgment
  Aggregation for Multi Agent Systems&quot; given at the 18th European Agent Systems
  Summer School</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03313</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting the evolution of stationary graph signals</dc:title>
 <dc:creator>Loukas, Andreas</dc:creator>
 <dc:creator>Perraudin, Nathanael</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  An emerging way of tackling the dimensionality issues arising in the modeling
of a multivariate process is to assume that the inherent data structure can be
captured by a graph. Nevertheless, though state-of-the-art graph-based methods
have been successful for many learning tasks, they do not consider
time-evolving signals and thus are not suitable for prediction. Based on the
recently introduced joint stationarity framework for time-vertex processes,
this letter considers multivariate models that exploit the graph topology so as
to facilitate the prediction. The resulting method yields similar accuracy to
the joint (time-graph) mean-squared error estimator but at lower complexity,
and outperforms purely time-based methods.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03316</identifier>
 <datestamp>2016-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separating Answers from Queries for Neural Reading Comprehension</dc:title>
 <dc:creator>Weissenborn, Dirk</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We present a novel neural architecture for answering queries, designed to
optimally leverage explicit support in the form of query-answer memories. Our
model is able to refine and update a given query while separately accumulating
evidence for predicting the answer. Its architecture reflects this separation
with dedicated embedding matrices and loosely connected information pathways
(modules) for updating the query and accumulating evidence. This separation of
responsibilities effectively decouples the search for query related support and
the prediction of the answer. On recent benchmark datasets for reading
comprehension, our model achieves state-of-the-art results. A qualitative
analysis reveals that the model effectively accumulates weighted evidence from
the query and over multiple support retrieval cycles which results in a robust
answer prediction.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03317</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Populations can be essential in tracking dynamic optima</dc:title>
 <dc:creator>Dang, Duc-Cuong</dc:creator>
 <dc:creator>Jansen, Thomas</dc:creator>
 <dc:creator>Lehre, Per Kristian</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Real-world optimisation problems are often dynamic. Previously good solutions
must be updated or replaced due to changes in objectives and constraints. It is
often claimed that evolutionary algorithms are particularly suitable for
dynamic optimisation because a large population can contain different solutions
that may be useful in the future. However, rigorous theoretical demonstrations
for how populations in dynamic optimisation can be essential are sparse and
restricted to special cases.
  This paper provides theoretical explanations of how populations can be
essential in evolutionary dynamic optimisation in a general and natural
setting. We describe a natural class of dynamic optimisation problems where a
sufficiently large population is necessary to keep track of moving optima
reliably. We establish a relationship between the population-size and the
probability that the algorithm loses track of the optimum.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03320</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Happens After You Both Swipe Right: A Statistical Description of
  Mobile Dating Communications</dc:title>
 <dc:creator>Zhang, Jennie</dc:creator>
 <dc:creator>Yasseri, Taha</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Mobile dating applications (MDAs) have skyrocketed in popularity in the last
few years, with popular MDA Tinder alone matching 26 million pairs of users per
day. In addition to becoming an influential part of modern dating culture, MDAs
facilitate a unique form of mediated communication: dyadic mobile text messages
between pairs of users who are not already acquainted. Furthermore, mobile
dating has paved the way for analysis of these digital interactions via massive
sets of data generated by the instant matching and messaging functions of its
many platforms at an unprecedented scale. This paper looks at one of these sets
of data: metadata of approximately two million conversations, containing 19
million messages, exchanged between 400,000 heterosexual users on an MDA.
Through computational analysis methods, this study offers the very first large
scale quantitative depiction of mobile dating as a whole. We report on
differences in how heterosexual male and female users communicate with each
other on MDAs, differences in behaviors of dyads of varying degrees of social
separation, and factors leading to &quot;success&quot;-operationalized by the exchange of
phone numbers between a match. For instance, we report that men initiate 79% of
conversations--and while about half of the initial messages are responded to,
conversations initiated by men are more likely to be reciprocated. We also
report that the length of conversations, the waiting times, and the length of
messages have fat-tailed distributions. That said, the majority of reciprocated
conversations lead to a phone number exchange within the first 20 messages.
</dc:description>
 <dc:description>Comment: Under Review, 22 pages, 8 tables, 8 figures</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03333</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RGBD Salient Object Detection via Deep Fusion</dc:title>
 <dc:creator>Qu, Liangqiong</dc:creator>
 <dc:creator>He, Shengfeng</dc:creator>
 <dc:creator>Zhang, Jiawei</dc:creator>
 <dc:creator>Tian, Jiandong</dc:creator>
 <dc:creator>Tang, Yandong</dc:creator>
 <dc:creator>Yang, Qingxiong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Numerous efforts have been made to design different low level saliency cues
for the RGBD saliency detection, such as color or depth contrast features,
background and color compactness priors. However, how these saliency cues
interact with each other and how to incorporate these low level saliency cues
effectively to generate a master saliency map remain a challenging problem. In
this paper, we design a new convolutional neural network (CNN) to fuse
different low level saliency cues into hierarchical features for automatically
detecting salient objects in RGBD images. In contrast to the existing works
that directly feed raw image pixels to the CNN, the proposed method takes
advantage of the knowledge in traditional saliency detection by adopting
various meaningful and well-designed saliency feature vectors as input. This
can guide the training of CNN towards detecting salient object more effectively
due to the reduced learning ambiguity. We then integrate a Laplacian
propagation framework with the learned CNN to extract a spatially consistent
saliency map by exploiting the intrinsic structure of the input image.
Extensive quantitative and qualitative experimental evaluations on three
datasets demonstrate that the proposed method consistently outperforms
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: This paper has been submitted to IEEE Transactions on Image
  Processing</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03333</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2682981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03338</identifier>
 <datestamp>2017-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rooted Uniform Monotone Minimum Spanning Trees</dc:title>
 <dc:creator>Mastakas, Konstantinos</dc:creator>
 <dc:creator>Symvonis, Antonios</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We study the construction of the minimum cost spanning geometric graph of a
given rooted point set $P$ where each point of $P$ is connected to the root by
a path that satisfies a given property. We focus on two properties, namely the
monotonicity w.r.t. a single direction ($y$-monotonicity) and the monotonicity
w.r.t. a single pair of orthogonal directions ($xy$-monotonicity). We propose
algorithms that compute the rooted $y$-monotone ($xy$-monotone) minimum
spanning tree of $P$ in $O(|P|\log^2 |P|)$ (resp. $O(|P|\log^3 |P|)$) time when
the direction (resp. pair of orthogonal directions) of monotonicity is given,
and in $O(|P|^2\log|P|)$ time when the optimum direction (resp. pair of
orthogonal directions) has to be determined. We also give simple algorithms
which, given a rooted connected geometric graph, decide if the root is
connected to every other vertex by paths that are all monotone w.r.t. the same
direction (pair of orthogonal directions).
</dc:description>
 <dc:description>Comment: Full version of an article accepted at the 10th International
  Conference on Algorithms and Complexity (CIAC 2017). We mention some of the
  changes we made w.r.t. the previous version. Using two data structures that
  were given by Bentley (Information Processing Letters, 1979), the time
  complexity of two of our algorithms was improved. Furthermore, text was added
  and some typos were corrected</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03340</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time Rescheduling in Distributed Railway Network: An Agent-Based
  Approach</dc:title>
 <dc:creator>Dalapati, Poulami</dc:creator>
 <dc:creator>Agarwal, Piyush</dc:creator>
 <dc:creator>Dutta, Animesh</dc:creator>
 <dc:creator>Bhattacharya, Swapan</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This paper addresses the issues concerning the rescheduling of a static
timetable in case of a disaster encountered in a large and complex railway
network system. The proposed approach tries to modify the schedule so as to
minimise the overall delay of trains. This is achieved by representing the
rescheduling problem in the form of a Petri-Net and the highly uncertain
disaster recovery times in such a model is handled as Markov Decision Processes
(MDP ). For solving the rescheduling problem, a istributed Constraint
Optimisation (DCOP ) based strategy involving the use of autonomous agents is
used to generate the desired schedule. The proposed approach is evaluated on
the actual schedule of the Eastern Railways, India by constructing vari- ous
disaster scenarios using the Java Agent DEvelopment Framework (JADE). When
compared to the existing approaches, the proposed framework substantially
reduces the delay of trains after rescheduling.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03341</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Novel 16-QAM and 64-QAM Near-Complementary Sequences with Low PMEPR in
  OFDM Systems</dc:title>
 <dc:creator>Jiang, Tao</dc:creator>
 <dc:creator>Ni, Chunxing</dc:creator>
 <dc:creator>Xu, Yuance</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we firstly propose a novel construction of $16$-quadrature
amplitude modulation (QAM) near-complementary sequences with low peak-to-mean
envelope power ratio (PMEPR) in orthogonal frequency division multiplexing
(OFDM) systems. The proposed $16$-QAM near-complementary sequences can be
constructed by utilizing novel nonlinear offsets, where the length of the
sequences is $n=2^m$. The family size of the newly constructed $16$-QAM
near-complementary sequences is $8\times (\frac{m!}{2})\times 4^{m+1}$, and the
PMEPR of these sequences is proven to satisfy ${\textrm{PMEPR}}\leq 2.4$. Thus,
the proposed construction can generate a number of $16$-QAM near-complementary
sequences with low PMEPR, resulting in the improvement of the code rate in OFDM
systems. Furthermore, we also propose a novel construction of $64$-QAM
near-complementary sequences with low PMEPR, which is the first proven
construction of $64$-QAM near-complementary sequences. The PMEPRs of two types
of the proposed $64$-QAM near-complementary sequences are proven to satisfy
that ${\textrm{PMEPR}}\leq 3.62$ or ${\textrm{PMEPR}}\leq 2.48$, respectively.
The family size of the newly constructed $64$-QAM near-complementary sequences
is $64\times (\frac{m!}{2})\times 4^{m+1}$.
</dc:description>
 <dc:description>Comment: 27 pages, 2 figures, submitted to IEEE Transactions on Communications</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03341</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2016.2591949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03343</identifier>
 <datestamp>2016-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepBinaryMask: Learning a Binary Mask for Video Compressive Sensing</dc:title>
 <dc:creator>Iliadis, Michael</dc:creator>
 <dc:creator>Spinoulas, Leonidas</dc:creator>
 <dc:creator>Katsaggelos, Aggelos K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we propose a novel encoder-decoder neural network model
referred to as DeepBinaryMask for video compressive sensing. In video
compressive sensing one frame is acquired using a set of coded masks (sensing
matrix) from which a number of video frames is reconstructed, equal to the
number of coded masks. The proposed framework is an end-to-end model where the
sensing matrix is trained along with the video reconstruction. The encoder
learns the binary elements of the sensing matrix and the decoder is trained to
recover the unknown video sequence. The reconstruction performance is found to
improve when using the trained sensing mask from the network as compared to
other mask designs such as random, across a wide variety of compressive sensing
reconstruction algorithms. Finally, our analysis and discussion offers insights
into understanding the characteristics of the trained mask designs that lead to
the improved reconstruction quality.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03344</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secrecy and Energy Efficiency in Massive MIMO Aided Heterogeneous C-RAN:
  A New Look at Interference</dc:title>
 <dc:creator>Wang, Lifeng</dc:creator>
 <dc:creator>Wong, Kai-Kit</dc:creator>
 <dc:creator>Elkashlan, Maged</dc:creator>
 <dc:creator>Nallanathan, Arumugam</dc:creator>
 <dc:creator>Lambotharan, Sangarapillai</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the potential benefits of the massive
multiple-input multiple-output (MIMO) enabled heterogeneous cloud radio access
network (C-RAN) in terms of the secrecy and energy efficiency (EE). In this
network, both remote radio heads (RRHs) and massive MIMO macrocell base
stations (BSs) are deployed and soft fractional frequency reuse (S-FFR) is
adopted to mitigate the inter-tier interference. We first examine the physical
layer security by deriving the area ergodic secrecy rate and secrecy outage
probability. Our results reveal that the use of massive MIMO and C-RAN can
greatly improve the secrecy performance. For C-RAN, a large number of RRHs
achieves high area ergodic secrecy rate and low secrecy outage probability, due
to its powerful interference management. We find that for massive MIMO aided
macrocells, having more antennas and serving more users improves secrecy
performance. Then we derive the EE of the heterogeneous C-RAN, illustrating
that increasing the number of RRHs significantly enhances the network EE.
Furthermore, it is indicated that allocating more radio resources to the RRHs
can linearly increase the EE of RRH tier and improve the network EE without
affecting the EE of the macrocells.
</dc:description>
 <dc:description>Comment: 26 pages, 11 figures, to appear in IEEE Journal of Selected Topics in
  Signal Processing</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03344</dc:identifier>
 <dc:identifier>doi:10.1109/JSTSP.2016.2600520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03349</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tractable Stochastic Geometry Model for IoT Access in LTE Networks</dc:title>
 <dc:creator>Gharbieh, Mohammad</dc:creator>
 <dc:creator>ElSawy, Hesham</dc:creator>
 <dc:creator>Bader, Ahmed</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Internet of Things (IoT) is large-scale by nature. This is not only
manifested by the large number of connected devices, but also by the high
volumes of traffic that must be accommodated. Cellular networks are indeed a
natural candidate for the data tsunami the IoT is expected to generate in
conjunction with legacy human-type traffic. However, the random access process
for scheduling request represents a major bottleneck to support IoT via LTE
cellular networks. Accordingly, this paper develops a mathematical framework to
model and study the random access channel (RACH) scalability to accommodate IoT
traffic. The developed model is based on stochastic geometry and discrete time
Markov chains (DTMC) to account for different access strategies and possible
sources of inter-cell and intra-cell interferences. To this end, the developed
model is utilized to assess and compare three different access strategies,
which incorporate a combination of transmission persistency, back-off, and
power ramping. The analysis and the results showcased herewith clearly
illustrate the vulnerability of the random access procedure as the IoT
intensity grows. Finally, the paper offers insights into effective scenarios
for each transmission strategy in terms of IoT intensity and RACH detection
thresholds.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03353</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Location-aware ICI Reduction in MIMO-OFDM Downlinks for High-speed
  Railway Communication Systems</dc:title>
 <dc:creator>Lu, Jiaxun</dc:creator>
 <dc:creator>Chen, Xuhong</dc:creator>
 <dc:creator>Liu, Shanyun</dc:creator>
 <dc:creator>Fan, Pingyi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  High mobility may destroy the orthogonality of subcarriers in OFDM systems,
resulting in inter- carrier interference (ICI), which may greatly reduce the
service quantity of high-speed railway (HSR) wireless communications. This
paper focuses on ICI mitigation in the HSR downlinks with distributed transmit
antennas.For such a system, its key feature is that the ICIs are caused by
multiple carrier frequency offsets corresponding to multiple transmit antennas.
Meanwhile, the channel of HSR is fast time varying, which is another big
challenge in the system design. In order to get a good performance, low
complexity real-time ICI reduction is necessary. To this end, we first analyzed
the property of the ICI matrix in AWGN and Rician scenarios, respectively.
Then, we propose corresponding low complexity ICI reduction methods based on
location information. For evaluating the effectiveness of the proposed method,
the expectation and variance of remaining interference after ICI reduction is
analyzed with respect to Rician K-factor. In addition, the service quantity and
the bandwidth and computation cost are also discussed. Numerical results are
presented to verify our theoretical analysis and the effectiveness of proposed
ICI reduction methods. One important observation is that our proposed ICI
mitigation method can achieve almost the same service quantity with that
obtained on the case without ICI at 300km/h,that is, ICI has been completely
eliminated. Numerical results also show that the scenarios with Rician
K-factors over 30dB can be considered as AWGN scenarios, which may provide
valuable insights on future system designs.
</dc:description>
 <dc:description>Comment: 30 pages, 6 figures, 3 tables</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03354</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extended Graded Modalities in Strategy Logic</dc:title>
 <dc:creator>Aminof, Benjamin</dc:creator>
 <dc:creator>Malvone, Vadim</dc:creator>
 <dc:creator>Murano, Aniello</dc:creator>
 <dc:creator>Rubin, Sasha</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  Strategy Logic (SL) is a logical formalism for strategic reasoning in
multi-agent systems. Its main feature is that it has variables for strategies
that are associated to specific agents with a binding operator. We introduce
Graded Strategy Logic (GradedSL), an extension of SL by graded quantifiers over
tuples of strategy variables, i.e., &quot;there exist at least g different tuples
(x_1,...,x_n) of strategies&quot; where g is a cardinal from the set N union
{aleph_0, aleph_1, 2^aleph_0}. We prove that the model-checking problem of
GradedSL is decidable. We then turn to the complexity of fragments of GradedSL.
When the g's are restricted to finite cardinals, written GradedNSL, the
complexity of model-checking is no harder than for SL, i.e., it is
non-elementary in the quantifier rank. We illustrate our formalism by showing
how to count the number of different strategy profiles that are Nash equilibria
(NE), or subgame-perfect equilibria (SPE). By analyzing the structure of the
specific formulas involved, we conclude that the important problems of checking
for the existence of a unique NE or SPE can both be solved in 2ExpTime, which
is not harder than merely checking for the existence of such equilibria.
</dc:description>
 <dc:description>Comment: In Proceedings SR 2016, arXiv:1607.02694</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03354</dc:identifier>
 <dc:identifier>EPTCS 218, 2016, pp. 1-14</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.218.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03355</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing Strategies</dc:title>
 <dc:creator>Duijf, Hein</dc:creator>
 <dc:creator>Broersen, Jan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Quite some work in the ATL-tradition uses the differences between various
types of strategies (positional, uniform, perfect recall) to give alternative
semantics to the same logical language. This paper contributes to another
perspective on strategy types, one where we characterise the differences
between them on the syntactic (object language) level. This is important for a
more traditional knowledge representation view on strategic content. Leaving
differences between strategy types implicit in the semantics is a sensible idea
if the goal is to use the strategic formalism for model checking. But, for
traditional knowledge representation in terms of object language level
formulas, we need to extent the language. This paper introduces a strategic
STIT syntax with explicit operators for knowledge that allows us to charaterise
strategy types. This more expressive strategic language is interpreted on
standard ATL-type concurrent epistemic game structures. We introduce rule-based
strategies in our language and fruitfully apply them to the representation and
characterisation of positional and uniform strategies. Our representations
highlight crucial conditions to be met for strategy types. We demonstrate the
usefulness of our work by showing that it leads to a critical reexamination of
coalitional uniform strategies.
</dc:description>
 <dc:description>Comment: In Proceedings SR 2016, arXiv:1607.02694</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03355</dc:identifier>
 <dc:identifier>EPTCS 218, 2016, pp. 15-26</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.218.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03356</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending Finite Memory Determinacy to Multiplayer Games</dc:title>
 <dc:creator>Roux, St&#xe9;phane Le</dc:creator>
 <dc:creator>Pauly, Arno</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  We show that under some general conditions the finite memory determinacy of a
class of two-player win/lose games played on finite graphs implies the
existence of a Nash equilibrium built from finite memory strategies for the
corresponding class of multi-player multi-outcome games. This generalizes a
previous result by Brihaye, De Pril and Schewe. For most of our conditions we
provide counterexamples showing that they cannot be dispensed with.
  Our proofs are generally constructive, that is, provide upper bounds for the
memory required, as well as algorithms to compute the relevant winning
strategies.
</dc:description>
 <dc:description>Comment: In Proceedings SR 2016, arXiv:1607.02694</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03356</dc:identifier>
 <dc:identifier>EPTCS 218, 2016, pp. 27-40</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.218.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03360</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate maximum entropy principles via Goemans-Williamson with
  applications to provable variational methods</dc:title>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:creator>Risteski, Andrej</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The well known maximum-entropy principle due to Jaynes, which states that
given mean parameters, the maximum entropy distribution matching them is in an
exponential family, has been very popular in machine learning due to its
&quot;Occam's razor&quot; interpretation. Unfortunately, calculating the potentials in
the maximum-entropy distribution is intractable \cite{bresler2014hardness}. We
provide computationally efficient versions of this principle when the mean
parameters are pairwise moments: we design distributions that approximately
match given pairwise moments, while having entropy which is comparable to the
maximum entropy distribution matching those moments.
  We additionally provide surprising applications of the approximate maximum
entropy principle to designing provable variational methods for partition
function calculations for Ising models without any assumptions on the
potentials of the model. More precisely, we show that in every temperature, we
can get approximation guarantees for the log-partition function comparable to
those in the low-temperature limit, which is the setting of optimization of
quadratic forms over the hypercube. \cite{alon2006approximating}
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03366</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human-Planned Robotic Grasp Ranges: Capture and Validation</dc:title>
 <dc:creator>John, Brendon</dc:creator>
 <dc:creator>Carter, Jackson</dc:creator>
 <dc:creator>Ruiz, Javier</dc:creator>
 <dc:creator>Allani, Sai Krishna</dc:creator>
 <dc:creator>Dixit, Saurabh</dc:creator>
 <dc:creator>Grimm, Cindy M.</dc:creator>
 <dc:creator>Balasubramanian, Ravi</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:description>  Leveraging human grasping skills to teach a robot to perform a manipulation
task is appealing, but there are several limitations to this approach:
time-inefficient data capture procedures, limited generalization of the data to
other grasps and objects, and inability to use that data to learn more about
how humans perform and evaluate grasps. This paper presents a data capture
protocol that partially addresses these deficiencies by asking participants to
specify ranges over which a grasp is valid. The protocol is verified both
qualitatively through online survey questions (where 95.38% of within-range
grasps are identified correctly with the nearest extreme grasp) and
quantitatively by showing that there is small variation in grasps ranges from
different participants as measured by joint angles, contact points, and
position. We demonstrate that these grasp ranges are valid through testing on a
physical robot (93.75% of grasps interpolated from grasp ranges are
successful).
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures, 5 tables</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03369</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Precision, Recall, and Sensitivity of Monitoring Partially Synchronous
  Distributed Systems</dc:title>
 <dc:creator>Yingchareonthawornchai, Sorrachai</dc:creator>
 <dc:creator>Nguyen, Duong</dc:creator>
 <dc:creator>Valapil, Vidhya Tekken</dc:creator>
 <dc:creator>Kulkarni, Sandeep</dc:creator>
 <dc:creator>Demirbas, Murat</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Runtime verification focuses on analyzing the execution of a given program by
a monitor to determine if it is likely to violate its specifications. There is
often an impedance mismatch between the assumptions/model of the monitor and
that of the underlying program. This constitutes problems especially for
distributed systems, where the concept of current time and state are inherently
uncertain. A monitor designed with asynchronous system model assumptions may
cause false-positives for a program executing in a partially synchronous
system: the monitor may flag a global predicate that does not actually occur in
the underlying system. A monitor designed with a partially synchronous system
model assumption may cause false negatives as well as false positives for a
program executing in an environment where the bounds on partial synchrony
differ (albeit temporarily) from the monitor model assumptions.
  In this paper we analyze the effects of the impedance mismatch between the
monitor and the underlying program for the detection of conjunctive predicates.
We find that there is a small interval where the monitor assumptions are
hypersensitive to the underlying program environment. We provide analytical
derivations for this interval, and also provide simulation support for
exploring the sensitivity of predicate detection to the impedance mismatch
between the monitor and the program under a partially synchronous system.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2016-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03378</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Handover Management in Dense Cellular Networks</dc:title>
 <dc:creator>Arshad, Rabe</dc:creator>
 <dc:creator>ElSawy, Hesham</dc:creator>
 <dc:creator>Sorour, Sameh</dc:creator>
 <dc:creator>Al-Naffouri, Tareq Y.</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Network densification has always been an important factor to cope with the
ever increasing capacity demand. Deploying more base stations (BSs) improves
the spatial frequency utilization, which increases the network capacity.
However, such improvement comes at the expense of shrinking the BSs'
footprints, which increases the handover (HO) rate and may diminish the
foreseen capacity gains. In this paper, we propose a cooperative HO management
scheme to mitigate the HO effect on throughput gains achieved via cellular
network densification. The proposed HO scheme relies on skipping HO to the
nearest BS at some instances along the user's trajectory while enabling
cooperative BS service during HO execution at other instances. To this end, we
develop a mathematical model, via stochastic geometry, to quantify the
performance of the proposed HO scheme in terms of coverage probability and user
throughput. The results show that the proposed cooperative HO scheme
outperforms the always best connected based association at high mobility. Also,
the value of BS cooperation along with handover skipping is quantified with
respect to the HO skipping only that has recently appeared in the literature.
Particularly, the proposed cooperative HO scheme shows throughput gains of 12%
to 27% and 17% on average, when compared to the always best connected and HO
skipping only schemes at user velocity ranging from 80 km/h to 160 Km/h,
respectively.
</dc:description>
 <dc:description>Comment: Globecom 2016</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03380</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An approximate message passing approach for compressive hyperspectral
  imaging using a simultaneous low-rank and joint-sparsity prior</dc:title>
 <dc:creator>Li, Yangqing</dc:creator>
 <dc:creator>Prasad, Saurabh</dc:creator>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:creator>Yin, Changchuan</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers a compressive sensing (CS) approach for hyperspectral
data acquisition, which results in a practical compression ratio substantially
higher than the state-of-the-art. Applying simultaneous low-rank and
joint-sparse (L&amp;S) model to the hyperspectral data, we propose a novel
algorithm to joint reconstruction of hyperspectral data based on loopy belief
propagation that enables the exploitation of both structured sparsity and
amplitude correlations in the data. Experimental results with real
hyperspectral datasets demonstrate that the proposed algorithm outperforms the
state-of-the-art CS-based solutions with substantial reductions in
reconstruction error.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03385</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compiling Stateful Network Properties for Runtime Verification</dc:title>
 <dc:creator>Nelson, Tim</dc:creator>
 <dc:creator>DeMarinis, Nicholas</dc:creator>
 <dc:creator>Hoff, Timothy Adam</dc:creator>
 <dc:creator>Fonseca, Rodrigo</dc:creator>
 <dc:creator>Krishnamurthi, Shriram</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Networks are difficult to configure correctly, and tricky to debug. These
problems are accentuated by temporal and stateful behavior. Static
verification, while useful, is ineffectual for detecting behavioral deviations
induced by hardware faults, security failures, and so on, so dynamic property
monitoring is also valuable. Unfortunately, existing monitoring and runtime
verification for networks largely focuses on properties about individual
packets (such as connectivity) or requires a digest of all network events be
sent to a server, incurring enormous cost.
  We present a network monitoring system that avoids these problems. Because
traces of network events correspond well to temporal logic, we use a subset of
Metric First-Order Temporal Logic as the query language. These queries are
compiled down to execute completely on the network switches. This vastly
reduces network load, improves the precision of queries, and decreases
detection latency. We show the practical feasibility of our work by extending a
widely-used software switch and deploying it on networks. Our work also
suggests improvements to network instruction sets to better support temporal
monitoring.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03392</identifier>
 <datestamp>2017-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical power and prediction accuracy in multisite resting-state
  fMRI connectivity</dc:title>
 <dc:creator>Dansereau, Christian</dc:creator>
 <dc:creator>Benhajali, Yassine</dc:creator>
 <dc:creator>Risterucci, Celine</dc:creator>
 <dc:creator>Pich, Emilio Merlo</dc:creator>
 <dc:creator>Orban, Pierre</dc:creator>
 <dc:creator>Arnold, Douglas</dc:creator>
 <dc:creator>Bellec, Pierre</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Connectivity studies using resting-state functional magnetic resonance
imaging are increasingly pooling data acquired at multiple sites. While this
may allow investigators to speed up recruitment or increase sample size,
multisite studies also potentially introduce systematic biases in connectivity
measures across sites. In this work, we measure the inter-site effect in
connectivity and its impact on our ability to detect individual and group
differences. Our study was based on real, as opposed to simulated, multisite
fMRI datasets collected in N=345 young, healthy subjects across 8 scanning
sites with 3T scanners and heterogeneous scanning protocols, drawn from the
1000 functional connectome project. We first empirically show that typical
functional networks were reliably found at the group level in all sites, and
that the amplitude of the inter-site effects was small to moderate, with a
Cohen's effect size below 0.5 on average across brain connections. We then
implemented a series of Monte-Carlo simulations, based on real data, to
evaluate the impact of the multisite effects on detection power in statistical
tests comparing two groups (with and without the effect) using a general linear
model, as well as on the prediction of group labels with a support-vector
machine. As a reference, we also implemented the same simulations with fMRI
data collected at a single site using an identical sample size. Simulations
revealed that using data from heterogeneous sites only slightly decreased our
ability to detect changes compared to a monosite study with the GLM, and had a
greater impact on prediction accuracy. Taken together, our results support the
feasibility of multisite studies in rs-fMRI provided the sample size is large
enough.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03392</dc:identifier>
 <dc:identifier>NeuroImage.Vol 149, p. 220-232 (2017)</dc:identifier>
 <dc:identifier>doi:10.1016/j.neuroimage.2017.01.072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03401</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parsimonious Mixed-Effects HodgeRank for Crowdsourced Preference
  Aggregation</dc:title>
 <dc:creator>Xu, Qianqian</dc:creator>
 <dc:creator>Xiong, Jiechao</dc:creator>
 <dc:creator>Cao, Xiaochun</dc:creator>
 <dc:creator>Yao, Yuan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In crowdsourced preference aggregation, it is often assumed that all the
annotators are subject to a common preference or utility function which
generates their comparison behaviors in experiments. However, in reality
annotators are subject to variations due to multi-criteria, abnormal, or a
mixture of such behaviors. In this paper, we propose a parsimonious
mixed-effects model based on HodgeRank, which takes into account both the fixed
effect that the majority of annotators follows a common linear utility model,
and the random effect that a small subset of annotators might deviate from the
common significantly and exhibits strongly personalized preferences. HodgeRank
has been successfully applied to subjective quality evaluation of multimedia
and resolves pairwise crowdsourced ranking data into a global consensus ranking
and cyclic conflicts of interests. As an extension, our proposed methodology
further explores the conflicts of interests through the random effect in
annotator specific variations. The key algorithm in this paper establishes a
dynamic path from the common utility to individual variations, with different
levels of parsimony or sparsity on personalization, based on newly developed
Linearized Bregman Algorithms with Inverse Scale Space method. Finally the
validity of the methodology are supported by experiments with both simulated
examples and three real-world crowdsourcing datasets, which shows that our
proposed method exhibits better performance (i.e. smaller test error) compared
with HodgeRank due to its parsimonious property.
</dc:description>
 <dc:description>Comment: 10 pages, ACM Multimedia (full paper) accepted</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03406</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-modal image retrieval with random walk on multi-layer graphs</dc:title>
 <dc:creator>Khasanova, Renata</dc:creator>
 <dc:creator>Dong, Xiaowen</dc:creator>
 <dc:creator>Frossard, Pascal</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The analysis of large collections of image data is still a challenging
problem due to the difficulty of capturing the true concepts in visual data.
The similarity between images could be computed using different and possibly
multimodal features such as color or edge information or even text labels. This
motivates the design of image analysis solutions that are able to effectively
integrate the multi-view information provided by different feature sets. We
therefore propose a new image retrieval solution that is able to sort images
through a random walk on a multi-layer graph, where each layer corresponds to a
different type of information about the image data. We study in depth the
design of the image graph and propose in particular an effective method to
select the edge weights for the multi-layer graph, such that the image ranking
scores are optimised. We then provide extensive experiments in different
real-world photo collections, which confirm the high performance of our new
image retrieval algorithm that generally surpasses state-of-the-art solutions
due to a more meaningful image similarity computation.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03406</dc:identifier>
 <dc:identifier>doi:10.1109/ISM.2016.0011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03408</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Optimization of WSNs using External Information</dc:title>
 <dc:creator>Dias, Gabriel Martins</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  The goal of this work is to describe a self-management system that correlates
data sensed by different Wireless Sensor Networks (WSNs) and adjusts the number
of active nodes in each network to provide an appropriate amount of
measurements. The architecture considers the factors that make the external
data relevant to the local network, such as the distance between covered areas,
the relation between the types of sensed data and the reliability of the
measurements. As a result, the operation of each network will be tuned to
trade-off the accuracy of the measurements and the power consumption.
</dc:description>
 <dc:description>Comment: Published in: IEEE 14th International Symposium and Workshops on a
  World of Wireless, Mobile and Multimedia Networks (WoWMoM), 2013 (copyright
  has been transferred to IEEE)</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03408</dc:identifier>
 <dc:identifier>doi:10.1109/WoWMoM.2013.6583430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03417</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The usability canary in the security coal mine: A cognitive framework
  for evaluation and design of usable authentication solutions</dc:title>
 <dc:creator>Glass, Brain</dc:creator>
 <dc:creator>Jenkinson, Graeme</dc:creator>
 <dc:creator>Liu, Yuqi</dc:creator>
 <dc:creator>Sasse, M. Angela</dc:creator>
 <dc:creator>Stajano, Frank</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Over the past 15 years, researchers have identified an increasing number of
security mechanisms that are so unusable that the intended users either
circumvent them or give up on a service rather than suffer the security. With
hindsight, the reasons can be identified easily enough: either the security
task itself is too cumbersome and/or time-consuming, or it creates high
friction with the users` primary task. The aim of the research presented here
is to equip designers who select and implement security mechanisms with a
method for identifying the ``best fit`` security mechanism at the design stage.
Since many usability problems have been identified with authentication, we
focus on ``best fit`` authentication, and present a framework that allows
security designers not only to model the workload associated with a particular
authentication method, but more importantly to model it in the context of the
user`s primary task. We draw on results from cognitive psychology to create a
method that allows a designer to understand the impact of a particular
authentication method on user productivity and satisfaction. In a validation
study using a physical mockup of an airline check-in kiosk, we demonstrate that
the model can predict user performance and satisfaction. Furthermore, design
experts suggested personalized order recommendations which were similar to our
model`s predictions. Our model is the first that supports identification of a
holistic fit between the task of user authentication and the context in which
it is performed. When applied to new systems, we believe it will help designers
understand the usability impact of their security choices and thus develop
solutions that maximize both.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03417</dc:identifier>
 <dc:identifier>doi:10.14722/eurousec.2016.23007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03425</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Inference of Bijective Non-Rigid Shape Correspondence</dc:title>
 <dc:creator>Vestner, Matthias</dc:creator>
 <dc:creator>Litman, Roee</dc:creator>
 <dc:creator>Bronstein, Alex</dc:creator>
 <dc:creator>Rodol&#xe0;, Emanuele</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many algorithms for the computation of correspondences between deformable
shapes rely on some variant of nearest neighbor matching in a descriptor space.
Such are, for example, various point-wise correspondence recovery algorithms
used as a postprocessing stage in the functional correspondence framework. In
this paper, we show that such frequently used techniques in practice suffer
from lack of accuracy and result in poor surjectivity. We propose an
alternative recovery technique guaranteeing a bijective correspondence and
producing significantly higher accuracy. We derive the proposed method from a
statistical framework of Bayesian inference and demonstrate its performance on
several challenging deformable 3D shape matching datasets.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03428</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning in Quantum Control: High-Dimensional Global Optimization for
  Noisy Quantum Dynamics</dc:title>
 <dc:creator>Palittapongarnpim, Pantita</dc:creator>
 <dc:creator>Wittek, Peter</dc:creator>
 <dc:creator>Zahedinejad, Ehsan</dc:creator>
 <dc:creator>Vedaie, Shakib</dc:creator>
 <dc:creator>Sanders, Barry C.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Quantum control is valuable for various quantum technologies such as
high-fidelity gates for universal quantum computing, adaptive quantum-enhanced
metrology, and ultra-cold atom manipulation. Although supervised machine
learning and reinforcement learning are widely used for optimizing control
parameters in classical systems, quantum control for parameter optimization is
mainly pursued via gradient-based greedy algorithms. Although the quantum
fitness landscape is often compatible with greedy algorithms, sometimes greedy
algorithms yield poor results, especially for large-dimensional quantum
systems. We employ differential evolution algorithms to circumvent the
stagnation problem of non-convex optimization. We improve quantum control
fidelity for noisy system by averaging over the objective function. To reduce
computational cost, we introduce heuristics for early termination of runs and
for adaptive selection of search subspaces. Our implementation is massively
parallel and vectorized to reduce run time even further. We demonstrate our
methods with two examples, namely quantum phase estimation and quantum gate
design, for which we achieve superior fidelity and scalability than obtained
using greedy algorithms.
</dc:description>
 <dc:description>Comment: 32 pages, 4 figures, extension of proceedings in ESANN 2016
  conference submitted to Neurocomputing</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03428</dc:identifier>
 <dc:identifier>Neurocomputing 268 (2017) 116-126</dc:identifier>
 <dc:identifier>doi:10.1016/j.neucom.2016.12.087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03432</identifier>
 <datestamp>2017-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight lower bounds for the complexity of multicoloring</dc:title>
 <dc:creator>Bonamy, Marthe</dc:creator>
 <dc:creator>Kowalik, &#x141;ukasz</dc:creator>
 <dc:creator>Pilipczuk, Micha&#x142;</dc:creator>
 <dc:creator>Soca&#x142;a, Arkadiusz</dc:creator>
 <dc:creator>Wrochna, Marcin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In the multicoloring problem, also known as ($a$:$b$)-coloring or $b$-fold
coloring, we are given a graph G and a set of $a$ colors, and the task is to
assign a subset of $b$ colors to each vertex of G so that adjacent vertices
receive disjoint color subsets. This natural generalization of the classic
coloring problem (the $b=1$ case) is equivalent to finding a homomorphism to
the Kneser graph $KG_{a,b}$, and gives relaxations approaching the fractional
chromatic number.
  We study the complexity of determining whether a graph has an
($a$:$b$)-coloring. Our main result is that this problem does not admit an
algorithm with running time $f(b)\cdot 2^{o(\log b)\cdot n}$, for any
computable $f(b)$, unless the Exponential Time Hypothesis (ETH) fails. A
$(b+1)^n\cdot \text{poly}(n)$-time algorithm due to Nederlof [2008] shows that
this is tight. A direct corollary of our result is that the graph homomorphism
problem does not admit a $2^{O(n+h)}$ algorithm unless ETH fails, even if the
target graph is required to be a Kneser graph. This refines the understanding
given by the recent lower bound of Cygan et al. [SODA 2016].
  The crucial ingredient in our hardness reduction is the usage of detecting
matrices of Lindstr\&quot;om [Canad. Math. Bull., 1965], which is a combinatorial
tool that, to the best of our knowledge, has not yet been used for proving
complexity lower bounds. As a side result, we prove that the running time of
the algorithms of Abasi et al. [MFCS 2014] and of Gabizon et al. [ESA 2015] for
the r-monomial detection problem are optimal under ETH.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03434</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNA Image Pro -- A Tool for Generating Pixel Patterns using DNA Tile
  Assembly</dc:title>
 <dc:creator>Limbachiya, Dixita</dc:creator>
 <dc:creator>Trivedi, Dhaval</dc:creator>
 <dc:creator>Gupta, Manish K</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Self-assembly is a process found everywhere in the Nature. In particular, it
is known that DNA self-assembly is Turing universal. Thus one can do arbitrary
computations or build nano-structures using DNA self-assembly. In order to
understand the DNA self-assembly process, many mathematical models have been
proposed in the literature. In particular, abstract Tile Assembly Model (aTAM)
received much attention. In this work, we investigate pixel pattern generation
using aTAM. For a given image, a tile assembly system is given which can
generate the image by self-assembly process. We also consider image blocks with
specific cyclic pixel patterns (uniform shift and non uniform shift) self
assembly. A software, DNA Image Pro, for generating pixel patterns using DNA
tile assembly is also given.
</dc:description>
 <dc:description>Comment: 14 pages, draft</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03443</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey about Prediction-Based Data Reduction in Wireless Sensor
  Networks</dc:title>
 <dc:creator>Dias, Gabriel Martins</dc:creator>
 <dc:creator>Bellalta, Boris</dc:creator>
 <dc:creator>Oechsner, Simon</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>A.1</dc:subject>
 <dc:description>  One of the main characteristics of Wireless Sensor Networks (WSNs) is the
constrained energy resources of their wireless sensor nodes. Although this
issue has been addressed in several works and got a lot of attention within the
years, the most recent advances pointed out that the energy harvesting and
wireless charging techniques may offer means to overcome such a limitation.
Consequently, an issue that had been put in second place, now emerges: the low
availability of spectrum resources. Because of it, the incorporation of the
WSNs into the Internet of Things and the exponential growth of the latter may
be hindered if no control over the data generation is taken. Alternatively,
part of the sensed data can be predicted without triggering transmissions and
congesting the wireless medium. In this work, we analyze and categorize
existing prediction-based data reduction mechanisms that have been designed for
WSNs. Our main contribution is a systematic procedure for selecting a scheme to
make predictions in WSNs, based on WSNs' constraints, characteristics of
prediction methods and monitored data. Finally, we conclude the paper with a
discussion about future challenges and open research directions in the use of
prediction methods to support the WSNs' growth.
</dc:description>
 <dc:description>Comment: 37 pages, 6 figures, 3 tables. Submitted to ACM Computing Surveys</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03445</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Type-Driven Repair for Information Flow Security</dc:title>
 <dc:creator>Polikarpova, Nadia</dc:creator>
 <dc:creator>Yang, Jean</dc:creator>
 <dc:creator>Itzhaky, Shachar</dc:creator>
 <dc:creator>Solar-Lezama, Armando</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present Lifty, a language that uses type-driven program repair to enforce
information flow policies. In Lifty, the programmer specifies a policy by
annotating the source of sensitive data with a refinement type, and the system
automatically inserts access checks necessary to enforce this policy across the
code. This is a significant improvement over current practice, where
programmers manually implement access checks, and any missing check can cause
an information leak. To support this programming model, we have developed (1)
an encoding of information flow security in terms of decidable refinement types
that enables fully automatic verification and (2) a program repair algorithm
that localizes unsafe accesses to sensitive data and replaces them with
provably secure alternatives. We formalize the encoding and prove its
noninterference guarantee. Our experience using Lifty to implement a conference
management system shows that it decreases policy burden and is able to
efficiently synthesize all necessary access checks, including those required to
prevent a set of reported real-world information leaks.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03450</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Side-Channel Attack Resilience through Route Randomisation in Secure
  Real-Time Networks-on-Chip</dc:title>
 <dc:creator>Indrusiak, Leandro Soares</dc:creator>
 <dc:creator>Harbin, James</dc:creator>
 <dc:creator>Sepulveda, Martha Johanna</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Security can be seen as an optimisation objective in NoC resource management,
and as such poses trade-offs against other objectives such as real-time
schedulability. In this paper, we show how to increase NoC resilience against a
concrete type of security attack, named side-channel attack, which exploit the
correlation between specific non-functional properties (such as packet
latencies and routes, in the case of NoCs) to infer the functional behaviour of
secure applications. For instance, the transmission of a packet over a given
link of the NoC may hint on a cache miss, which can be used by an attacker to
guess specific parts of a secret cryptographic key, effectively weakening it.
  We therefore propose packet route randomisation as a mechanism to increase
NoC resilience against side-channel attacks, focusing specifically on the
potential impact of such an approach upon hard real-time systems, where
schedulability is a vital design requirement. Using an evolutionary
optimisation approach, we show how to effectively apply route randomisation in
such a way that it can increase NoC security while controlling its impact on
hard real-time performance guarantees. Extensive experimental evidence based on
analytical and simulation models supports our findings.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03455</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coupling proofs are probabilistic product programs</dc:title>
 <dc:creator>Barthe, Gilles</dc:creator>
 <dc:creator>Gr&#xe9;goire, Benjamin</dc:creator>
 <dc:creator>Hsu, Justin</dc:creator>
 <dc:creator>Strub, Pierre-Yves</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Couplings are a powerful mathematical tool for reasoning about pairs of
probabilistic processes. Recent developments in formal verification identify a
close connection between couplings and pRHL, a relational program logic
motivated by applications to provable security, enabling formal construction of
couplings from the probability theory literature. However, existing work using
pRHL merely shows existence of a coupling and does not give a way to prove
quantitative properties about the coupling, which are need to reason about
mixing and convergence of probabilistic processes. Furthermore, pRHL is
inherently incomplete, and is not able to capture some advanced forms of
couplings such as shift couplings. We address both problems as follows.
  First, we define an extension of pRHL, called xpRHL, which explicitly
constructs the coupling in a pRHL derivation in the form of a probabilistic
product program that simulates two correlated runs of the original program.
Existing verification tools for probabilistic programs can then be directly
applied to the probabilistic product to prove quantitative properties of the
coupling. Second, we equip pRHL with a new rule for while loops, where
reasoning can freely mix synchronized and unsynchronized loop iterations. Our
proof rule can capture examples of shift couplings, and the logic is relatively
complete for deterministic programs.
  We show soundness of xpRHL and use it to analyze two classes of examples.
First, we verify rapid mixing using different tools from coupling: standard
coupling, shift coupling, and path coupling, a compositional principle for
combining local couplings into a global coupling. Second, we verify
(approximate) equivalence between a source and an optimized program for several
instances of loop optimizations from the literature.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03456</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incomplete Pivoted QR-based Dimensionality Reduction</dc:title>
 <dc:creator>Bermanis, Amit</dc:creator>
 <dc:creator>Rotbart, Aviv</dc:creator>
 <dc:creator>Salhov, Moshe</dc:creator>
 <dc:creator>Averbuch, Amir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  High-dimensional big data appears in many research fields such as image
recognition, biology and collaborative filtering. Often, the exploration of
such data by classic algorithms is encountered with difficulties due to `curse
of dimensionality' phenomenon. Therefore, dimensionality reduction methods are
applied to the data prior to its analysis. Many of these methods are based on
principal components analysis, which is statistically driven, namely they map
the data into a low-dimension subspace that preserves significant statistical
properties of the high-dimensional data. As a consequence, such methods do not
directly address the geometry of the data, reflected by the mutual distances
between multidimensional data point. Thus, operations such as classification,
anomaly detection or other machine learning tasks may be affected.
  This work provides a dictionary-based framework for geometrically driven data
analysis that includes dimensionality reduction, out-of-sample extension and
anomaly detection. It embeds high-dimensional data in a low-dimensional
subspace. This embedding preserves the original high-dimensional geometry of
the data up to a user-defined distortion rate. In addition, it identifies a
subset of landmark data points that constitute a dictionary for the analyzed
dataset. The dictionary enables to have a natural extension of the
low-dimensional embedding to out-of-sample data points, which gives rise to a
distortion-based criterion for anomaly detection. The suggested method is
demonstrated on synthetic and real-world datasets and achieves good results for
classification, anomaly detection and out-of-sample tasks.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03463</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LazySVD: Even Faster SVD Decomposition Yet Without Agonizing Pain</dc:title>
 <dc:creator>Allen-Zhu, Zeyuan</dc:creator>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study $k$-SVD that is to obtain the first $k$ singular vectors of a matrix
$A$. Recently, a few breakthroughs have been discovered on $k$-SVD: Musco and
Musco [1] proved the first gap-free convergence result using the block Krylov
method, Shamir [2] discovered the first variance-reduction stochastic method,
and Bhojanapalli et al. [3] provided the fastest $O(\mathsf{nnz}(A) +
\mathsf{poly}(1/\varepsilon))$-time algorithm using alternating minimization.
  In this paper, we put forward a new and simple LazySVD framework to improve
the above breakthroughs. This framework leads to a faster gap-free method
outperforming [1], and the first accelerated and stochastic method
outperforming [2]. In the $O(\mathsf{nnz}(A) + \mathsf{poly}(1/\varepsilon))$
running-time regime, LazySVD outperforms [3] in certain parameter regimes
without even using alternating minimization.
</dc:description>
 <dc:description>Comment: first circulated on May 20, 2016; this newer version improves writing</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03464</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Representation Theory Perspective on Simultaneous Alignment and
  Classification</dc:title>
 <dc:creator>Lederman, Roy R.</dc:creator>
 <dc:creator>Singer, Amit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  One of the difficulties in 3D reconstruction of molecules from images in
single particle Cryo-Electron Microscopy (Cryo-EM), in addition to high levels
of noise and unknown image orientations, is heterogeneity in samples: in many
cases, the samples contain a mixture of molecules, or multiple conformations of
one molecule. Many algorithms for the reconstruction of molecules from images
in heterogeneous Cryo-EM experiments are based on iterative approximations of
the molecules in a non-convex optimization that is prone to reaching suboptimal
local minima. Other algorithms require an alignment in order to perform
classification, or vice versa. The recently introduced Non-Unique Games
framework provides a representation theoretic approach to studying problems of
alignment over compact groups, and offers convex relaxations for alignment
problems which are formulated as semidefinite programs (SDPs) with certificates
of global optimality under certain circumstances. In this manuscript, we
propose to extend Non-Unique Games to the problem of simultaneous alignment and
classification with the goal of simultaneously classifying Cryo-EM images and
aligning them within their respective classes. Our proposed approach can also
be extended to the case of continuous heterogeneity.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03467</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pseudo-Centroid Clustering</dc:title>
 <dc:creator>Glover, Fred</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Pseudo-Centroid Clustering replaces the traditional concept of a centroid
expressed as a center of gravity with the notion of a pseudo-centroid (or a
coordinate free centroid) which has the advantage of applying to clustering
problems where points do not have numerical coordinates (or categorical
coordinates that are translated into numerical form). Such problems, for which
classical centroids do not exist, are particularly important in social
sciences, marketing, psychology and economics, where distances are not computed
from vector coordinates but rather are expressed in terms of characteristics
such as affinity relationships, psychological preferences, advertising
responses, polling data, market interactions and so forth, where distances,
broadly conceived, measure the similarity (or dissimilarity) of
characteristics, functions or structures.
  We formulate a K-PC algorithm analogous to a K-Means algorithm, and identify
two key types of pseudo-centroids, MinMax centroids and (weighted) MinSum
centroids, and describe how they respectively give rise to a K-MinMax algorithm
and a K-MinSum algorithm which are analogous to a K-Means algorithm. The K-PC
algorithms are able to take advantage of problem structure to identify special
diversity-based and intensity-based starting methods to generate initial
pseudo-centroids and associated clusters, accompanied by theorems for the
intensity-based methods that establish their ability to obtain best clusters of
a selected size from the points available at each stage of construction. We
also introduce a Regret-Threshold PC algorithm that modifies the K-PC algorithm
together with an associated diversification method and a new criterion for
evaluating the quality of a collection of clusters.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03468</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event-based, 6-DOF Camera Tracking from Photometric Depth Maps</dc:title>
 <dc:creator>Gallego, Guillermo</dc:creator>
 <dc:creator>Lund, Jon E. A.</dc:creator>
 <dc:creator>Mueggler, Elias</dc:creator>
 <dc:creator>Rebecq, Henri</dc:creator>
 <dc:creator>Delbruck, Tobi</dc:creator>
 <dc:creator>Scaramuzza, Davide</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Event cameras are bio-inspired vision sensors that output pixel-level
brightness changes instead of standard intensity frames. These cameras do not
suffer from motion blur and have a very high dynamic range, which enables them
to provide reliable visual information during high-speed motions or in scenes
characterized by high dynamic range. These features, along with a very low
power consumption, make event cameras an ideal complement to standard cameras
for VR/AR and video game applications. With these applications in mind, this
paper tackles the problem of accurate, low-latency tracking of an event camera
from an existing photometric depth map (i.e., intensity plus depth information)
built via classic dense reconstruction pipelines. Our approach tracks the 6-DOF
pose of the event camera upon the arrival of each event, thus virtually
eliminating latency. We successfully evaluate the method in both indoor and
outdoor scenes and show that---because of the technological advantages of the
event camera---our pipeline works in scenes characterized by high-speed motion,
which are still unaccessible to standard cameras.
</dc:description>
 <dc:description>Comment: 12 pages, 13 figures. 2 tables. (in press)</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03468</dc:identifier>
 <dc:identifier>IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2017</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2017.2769655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03471</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cop-Win Graphs: Optimal Strategies and Corner Rank</dc:title>
 <dc:creator>Offner, David</dc:creator>
 <dc:creator>Ojakian, Kerry</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C57</dc:subject>
 <dc:description>  We investigate the game of cops and robber, played on a finite graph, between
one cop and one robber. If the cop can force a win on a graph, the graph is
called cop-win. We describe a procedure we call corner ranking, performed on a
graph, which assigns a positive integer or $\infty$ to each vertex. We give a
characterization of cop-win in terms of corner rank and also show that the
well-known characterization of cop-win via dismantling orderings follows from
our work. From the corner rank we can determine the capture time of a graph,
i.e. the number of turns the cop needs to win. We describe a class of optimal
cop strategies we call Lower Way strategies, and a class of optimal robber
strategies we call Higher Way strategies. Roughly speaking, in a Lower Way
strategy, the cop pushes the robber down to lower ranked vertices, while in a
Higher Way strategy, the robber moves to a highest rank vertex that is &quot;safe.&quot;
While interesting in their own right, the strategies are themselves tools in
our proofs. We investigate various properties of the Lower Way strategies.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03474</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Highway Networks</dc:title>
 <dc:creator>Zilly, Julian Georg</dc:creator>
 <dc:creator>Srivastava, Rupesh Kumar</dc:creator>
 <dc:creator>Koutn&#xed;k, Jan</dc:creator>
 <dc:creator>Schmidhuber, J&#xfc;rgen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Many sequential processing tasks require complex nonlinear transition
functions from one step to the next. However, recurrent neural networks with
'deep' transition functions remain difficult to train, even when using Long
Short-Term Memory (LSTM) networks. We introduce a novel theoretical analysis of
recurrent networks based on Gersgorin's circle theorem that illuminates several
modeling and optimization issues and improves our understanding of the LSTM
cell. Based on this analysis we propose Recurrent Highway Networks, which
extend the LSTM architecture to allow step-to-step transition depths larger
than one. Several language modeling experiments demonstrate that the proposed
architecture results in powerful and efficient models. On the Penn Treebank
corpus, solely increasing the transition depth from 1 to 10 improves word-level
perplexity from 90.6 to 65.4 using the same number of parameters. On the larger
Wikipedia datasets for character prediction (text8 and enwik8), RHNs outperform
all previous results and achieve an entropy of 1.27 bits per character.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, 3 tables</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03475</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nystrom Method for Approximating the GMM Kernel</dc:title>
 <dc:creator>Li, Ping</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The GMM (generalized min-max) kernel was recently proposed (Li, 2016) as a
measure of data similarity and was demonstrated effective in machine learning
tasks. In order to use the GMM kernel for large-scale datasets, the prior work
resorted to the (generalized) consistent weighted sampling (GCWS) to convert
the GMM kernel to linear kernel. We call this approach as ``GMM-GCWS''.
  In the machine learning literature, there is a popular algorithm which we
call ``RBF-RFF''. That is, one can use the ``random Fourier features'' (RFF) to
convert the ``radial basis function'' (RBF) kernel to linear kernel. It was
empirically shown in (Li, 2016) that RBF-RFF typically requires substantially
more samples than GMM-GCWS in order to achieve comparable accuracies.
  The Nystrom method is a general tool for computing nonlinear kernels, which
again converts nonlinear kernels into linear kernels. We apply the Nystrom
method for approximating the GMM kernel, a strategy which we name as
``GMM-NYS''. In this study, our extensive experiments on a set of fairly large
datasets confirm that GMM-NYS is also a strong competitor of RBF-RFF.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03476</identifier>
 <datestamp>2017-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end training of object class detectors for mean average precision</dc:title>
 <dc:creator>Henderson, Paul</dc:creator>
 <dc:creator>Ferrari, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a method for training CNN-based object class detectors directly
using mean average precision (mAP) as the training loss, in a truly end-to-end
fashion that includes non-maximum suppression (NMS) at training time. This
contrasts with the traditional approach of training a CNN for a window
classification loss, then applying NMS only at test time, when mAP is used as
the evaluation metric in place of classification accuracy. However, mAP
following NMS forms a piecewise-constant structured loss over thousands of
windows, with gradients that do not convey useful information for gradient
descent. Hence, we define new, general gradient-like quantities for piecewise
constant functions, which have wide applicability. We describe how to calculate
these efficiently for mAP following NMS, enabling to train a detector based on
Fast R-CNN directly for mAP. This model achieves equivalent performance to the
standard Fast R-CNN on the PASCAL VOC 2007 and 2012 datasets, while being
conceptually more appealing as the very same model and loss are used at both
training and test time.
</dc:description>
 <dc:description>Comment: This version has minor additions to results (ablation study) and
  discussion</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03479</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SAT-based Distributed Reactive Control Protocol Synthesis for Boolean
  Networks</dc:title>
 <dc:creator>Sahin, Yunus Emre</dc:creator>
 <dc:creator>Ozay, Necmiye</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers the synthesis of distributed reactive control protocols
for a Boolean network in a distributed manner. We start with a directed acyclic
graph representing a network of Boolean subsystems and a global contract, given
as an assumption-guarantee pair. Assumption captures the environment behavior,
and guarantee is the requirements to be satisfied by the system. Local
assumption-guarantee contracts, together with local control protocols ensuring
these local contracts, are computed recursively for each subsystem based on the
partial order structure induced by the directed acyclic graph. By construction,
implementing these local control protocols together guarantees the satisfaction
of the global assumption-guarantee contract. Moreover, local control protocol
synthesis reduces to quantified satisfiability (QSAT) problems in this setting.
We also discuss structural properties of the network that affect the
completeness of the proposed algorithm. As an application, we show how an
aircraft electric power system can be represented as a Boolean network, and we
synthesize distributed control protocols from a global assumption-guarantee
contract. The assumptions capture possible failures of the system components,
and the guarantees capture safety requirements related to power distribution.
</dc:description>
 <dc:description>Comment: This is an extended version of the paper with the same title that
  will appear in IEEE MSC 2016</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03483</identifier>
 <datestamp>2017-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Block Models and Personalized PageRank</dc:title>
 <dc:creator>Kloumann, Isabel</dc:creator>
 <dc:creator>Ugander, Johan</dc:creator>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Methods for ranking the importance of nodes in a network have a rich history
in machine learning and across domains that analyze structured data. Recent
work has evaluated these methods though the seed set expansion problem: given a
subset $S$ of nodes from a community of interest in an underlying graph, can we
reliably identify the rest of the community? We start from the observation that
the most widely used techniques for this problem, personalized PageRank and
heat kernel methods, operate in the space of landing probabilities of a random
walk rooted at the seed set, ranking nodes according to weighted sums of
landing probabilities of different length walks. Both schemes, however, lack an
a priori relationship to the seed set objective. In this work we develop a
principled framework for evaluating ranking methods by studying seed set
expansion applied to the stochastic block model. We derive the optimal gradient
for separating the landing probabilities of two classes in a stochastic block
model, and find, surprisingly, that under reasonable assumptions the gradient
is asymptotically equivalent to personalized PageRank for a specific choice of
the PageRank parameter $\alpha$ that depends on the block model parameters.
This connection provides a novel formal motivation for the success of
personalized PageRank in seed set expansion and node ranking generally. We use
this connection to propose more advanced techniques incorporating higher
moments of landing probabilities; our advanced methods exhibit greatly improved
performance despite being simple linear classification rules, and are even
competitive with belief propagation.
</dc:description>
 <dc:description>Comment: 30 pages, 3 figures</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03483</dc:identifier>
 <dc:identifier>Proc. National Academy of Sciences, 114(1) 33-38, 3 January 2017</dc:identifier>
 <dc:identifier>doi:10.1073/pnas.1611275114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03502</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural brain-information interfaces: Recommending information by
  relevance inferred from human brain signals</dc:title>
 <dc:creator>Eugster, Manuel J. A.</dc:creator>
 <dc:creator>Ruotsalo, Tuukka</dc:creator>
 <dc:creator>Spap&#xe9;, Michiel M.</dc:creator>
 <dc:creator>Barral, Oswald</dc:creator>
 <dc:creator>Ravaja, Niklas</dc:creator>
 <dc:creator>Jacucci, Giulio</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Finding relevant information from large document collections such as the
World Wide Web is a common task in our daily lives. Estimation of a user's
interest or search intention is necessary to recommend and retrieve relevant
information from these collections. We introduce a brain-information interface
used for recommending information by relevance inferred directly from brain
signals. In experiments, participants were asked to read Wikipedia documents
about a selection of topics while their EEG was recorded. Based on the
prediction of word relevance, the individual's search intent was modeled and
successfully used for retrieving new, relevant documents from the whole English
Wikipedia corpus. The results show that the users' interests towards digital
content can be modeled from the brain signals evoked by reading. The introduced
brain-relevance paradigm enables the recommendation of information without any
explicit user interaction, and may be applied across diverse
information-intensive applications.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03502</dc:identifier>
 <dc:identifier>Scientific Reports 6, Article number: 38580 (2016)</dc:identifier>
 <dc:identifier>doi:10.1038/srep38580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03516</identifier>
 <datestamp>2016-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reconstruction-Classification Networks for Unsupervised Domain
  Adaptation</dc:title>
 <dc:creator>Ghifary, Muhammad</dc:creator>
 <dc:creator>Kleijn, W. Bastiaan</dc:creator>
 <dc:creator>Zhang, Mengjie</dc:creator>
 <dc:creator>Balduzzi, David</dc:creator>
 <dc:creator>Li, Wen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose a novel unsupervised domain adaptation algorithm
based on deep learning for visual object recognition. Specifically, we design a
new model called Deep Reconstruction-Classification Network (DRCN), which
jointly learns a shared encoding representation for two tasks: i) supervised
classification of labeled source data, and ii) unsupervised reconstruction of
unlabeled target data.In this way, the learnt representation not only preserves
discriminability, but also encodes useful information from the target domain.
Our new DRCN model can be optimized by using backpropagation similarly as the
standard neural networks.
  We evaluate the performance of DRCN on a series of cross-domain object
recognition tasks, where DRCN provides a considerable improvement (up to ~8% in
accuracy) over the prior state-of-the-art algorithms. Interestingly, we also
observe that the reconstruction pipeline of DRCN transforms images from the
source domain into images whose appearance resembles the target dataset. This
suggests that DRCN's performance is due to constructing a single composite
representation that encodes information about both the structure of target
images and the classification of source images. Finally, we provide a formal
analysis to justify the algorithm's objective in domain adaptation context.
</dc:description>
 <dc:description>Comment: to appear in European Conference on Computer Vision (ECCV) 2016</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03519</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variable-Length Coding with Stop-Feedback for the Common-Message
  Broadcast Channel in the Nonasymptotic Regime</dc:title>
 <dc:creator>Trillingsgaard, Kasper Fl&#xf8;e</dc:creator>
 <dc:creator>Yang, Wei</dc:creator>
 <dc:creator>Durisi, Giuseppe</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate the maximum coding rate for a given average blocklength and
error probability over a K-user discrete memoryless broadcast channel for the
scenario where a common message is transmitted using variable-length
stop-feedback codes. For the point-to-point case, Polyanskiy et al. (2011)
demonstrated that variable-length coding combined with stop-feedback
significantly increase the speed of convergence of the maximum coding rate to
capacity. This speed-up manifests itself in the absence of a square-root
penalty in the asymptotic expansion of the maximum coding rate for large
blocklengths, i.e., zero dispersion. In this paper, we present nonasymptotic
achievability and converse bounds on the maximum coding rate of the
common-message K-user discrete memoryless broadcast channel, which strengthen
and generalize the ones reported in Trillingsgaard et al. (2015) for the
two-user case. An asymptotic analysis of these bounds reveals that zero
dispersion cannot be achieved for certain common-message broadcast channels
(e.g., the binary symmetric broadcast channel). Furthermore, we identify
conditions under which our converse and achievability bounds are tight up to
the second order. Through numerical evaluations, we illustrate that our
second-order expansions approximate accurately the maximum coding rate and that
the speed of convergence to capacity is indeed slower than for the
point-to-point case.
</dc:description>
 <dc:description>Comment: extended version of a paper presented at ISIT 2016</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03542</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open-Vocabulary Semantic Parsing with both Distributional Statistics and
  Formal Knowledge</dc:title>
 <dc:creator>Gardner, Matt</dc:creator>
 <dc:creator>Krishnamurthy, Jayant</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Traditional semantic parsers map language onto compositional, executable
queries in a fixed schema. This mapping allows them to effectively leverage the
information contained in large, formal knowledge bases (KBs, e.g., Freebase) to
answer questions, but it is also fundamentally limiting---these semantic
parsers can only assign meaning to language that falls within the KB's
manually-produced schema. Recently proposed methods for open vocabulary
semantic parsing overcome this limitation by learning execution models for
arbitrary language, essentially using a text corpus as a kind of knowledge
base. However, all prior approaches to open vocabulary semantic parsing replace
a formal KB with textual information, making no use of the KB in their models.
We show how to combine the disparate representations used by these two
approaches, presenting for the first time a semantic parser that (1) produces
compositional, executable representations of language, (2) can successfully
leverage the information contained in both a formal KB and a large corpus, and
(3) is not limited to the schema of the underlying KB. We demonstrate
significantly improved performance over state-of-the-art baselines on an
open-domain natural language question answering task.
</dc:description>
 <dc:description>Comment: Re-written abstract and intro, other minor changes throughout. This
  version published at AAAI 2017</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03547</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Multi-Class Cost-Sensitive Boosting via Estimation of the
  Minimum-Risk Class</dc:title>
 <dc:creator>Appel, Ron</dc:creator>
 <dc:creator>Burgos-Artizzu, Xavier</dc:creator>
 <dc:creator>Perona, Pietro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a simple unified framework for multi-class cost-sensitive
boosting. The minimum-risk class is estimated directly, rather than via an
approximation of the posterior distribution. Our method jointly optimizes
binary weak learners and their corresponding output vectors, requiring classes
to share features at each iteration. By training in a cost-sensitive manner,
weak learners are invested in separating classes whose discrimination is
important, at the expense of less relevant classification boundaries.
Additional contributions are a family of loss functions along with proof that
our algorithm is Boostable in the theoretical sense, as well as an efficient
procedure for growing decision trees for use as weak learners. We evaluate our
method on a variety of datasets: a collection of synthetic planar data, common
UCI datasets, MNIST digits, SUN scenes, and CUB-200 birds. Results show
state-of-the-art performance across all datasets against several strong
baselines, including non-boosting multi-class approaches.
</dc:description>
 <dc:description>Comment: Project website: http://www.vision.caltech.edu/~appel/projects/REBEL/</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03559</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Sampling for Strongly Rayleigh Measures with Application to
  Determinantal Point Processes</dc:title>
 <dc:creator>Li, Chengtao</dc:creator>
 <dc:creator>Jegelka, Stefanie</dc:creator>
 <dc:creator>Sra, Suvrit</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this note we consider sampling from (non-homogeneous) strongly Rayleigh
probability measures. As an important corollary, we obtain a fast mixing Markov
Chain sampler for Determinantal Point Processes.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03562</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robustness analysis of bimodal networks in the whole range of degree
  correlation</dc:title>
 <dc:creator>Mizutaka, Shogo</dc:creator>
 <dc:creator>Tanizawa, Toshihiro</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present exact analysis of the physical properties of bimodal networks
specified by the two peak degree distribution fully incorporating the
degree-degree correlation between node connection. The structure of the
correlated bimodal network is uniquely determined by the Pearson coefficient of
the degree correlation, keeping its degree distribution fixed. The percolation
threshold and the giant component fraction of the correlated bimodal network
are analytically calculated in the whole range of the Pearson coefficient from
$-1$ to $1$ against two major types of node removal, which are the random
failure and the degree-based targeted attack. The Pearson coefficient for
next-nearest-neighbor pairs is also calculated, which always takes a positive
value even when the correlation between nearest-neighbor pairs is negative.
From the results, it is confirmed that the percolation threshold is a
monotonically decreasing function of the Pearson coefficient for the degrees of
nearest-neighbor pairs increasing from $-1$ and $1$ regardless of the types of
node removal. In contrast, the node fraction of the giant component for bimodal
networks with positive degree correlation rapidly decreases in the early stage
of random failure, while that for bimodal networks with negative degree
correlation remains relatively large until the removed node fraction reaches
the threshold. In this sense, bimodal networks with negative degree correlation
are more robust against random failure than those with positive degree
correlation.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03562</dc:identifier>
 <dc:identifier>Phys. Rev. E 94, 022308 (2016)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.94.022308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03571</identifier>
 <datestamp>2017-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic Management for Heterogeneous Networks with Opportunistic
  Unlicensed Spectrum Sharing</dc:title>
 <dc:creator>Liu, Chun-Hung</dc:creator>
 <dc:creator>Tsai, Hong-Cheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper studies how to maximize the per-user-based throughput in an M-tier
heterogeneous wireless network (HetNet) by optimally managing traffic flows
between the access points (APs) in the HetNet. The APs in the first M-1 tiers
can use the licensed spectrum at the same time whereas they share the
unlicensed spectrum with the APs in the Mth tier by the proposed opportunistic
carrier sense multiple access with collision avoidance (CSMA/CA) protocol. The
APs that access the licensed and unlicensed spectra simultaneously are able to
integrate their spectrum resources by the carrier aggregation technique. We
first characterize the distribution of the cell load and the channel access
probability of each AP using a generalized AP association scheme. For an AP in
each tier, the tight lower bounds on its mean spectrum efficiencies in the
licensed and unlicensed spectra are derived for the general random models of
the channel gain and AP association weights. We define the per-user link
throughput and per-user network throughput based on the derived the mean
spectrum efficiencies and maximize them by proposing the decentralized and
centralized traffic management schemes for the APs in the first M-1 tiers under
the constraint that the per-user link throughput of the tier-M APs must be
above some minimum required value. Finally, a numerical example of coexisting
LTE and WiFi networks is provided to validate our derived results and findings.
</dc:description>
 <dc:description>Comment: 30 pages, 6 figures, journal</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:date>2017-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03572</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Reliability Limits in Nanoscale Circuits</dc:title>
 <dc:creator>Chatterjee, Avhishek</dc:creator>
 <dc:creator>Varshney, Lav R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the nanoscale regime, the behavior of both extant and emerging
semiconductor devices are often unreliable. Reliability of such devices often
trades-off with their energy consumption, speed, and/or chip area. We study the
energy-reliability limits for circuits designed using such devices. Using the
mutual information propagation in logic circuits technique developed by
Pippenger, together with optimization, we obtain lower bounds on the energy
consumption for computing n-input boolean functions. Most extant technologies
require all gates to have the same electrical operating point and in circuits
of such uniform gates, the minimum energy required to achieve any non-trivial
reliability scales superlinearly with the number of inputs. On the other hand,
in some emerging technologies such as spin electronics, where the gates in a
circuit can have different operating points, energy scaling can be linear in
the number of inputs. As part of our development we find a simple procedure for
energy allocation across gates in a boolean circuit with different operating
points.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03575</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IntelliAd Understanding In-APP Ad Costs From Users Perspective</dc:title>
 <dc:creator>Gao, Cuiyun</dc:creator>
 <dc:creator>Xu, Hui</dc:creator>
 <dc:creator>Man, Yichuan</dc:creator>
 <dc:creator>Zhou, Yangfan</dc:creator>
 <dc:creator>Lyu, Michael R.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Ads are an important revenue source for mobile app development, especially
for free apps, whose expense can be compensated by ad revenue. The ad benefits
also carry with costs. For example, too many ads can interfere the user
experience, leading to less user retention and reduced earnings ultimately. In
the paper, we aim at understanding the ad costs from users perspective. We
utilize app reviews, which are widely recognized as expressions of user
perceptions, to identify the ad costs concerned by users. Four types of ad
costs, i.e., number of ads, memory/CPU overhead, traffic usage, and bettery
consumption, have been discovered from user reviews. To verify whether
different ad integration schemes generate different ad costs, we first obtain
the commonly used ad schemes from 104 popular apps, and then design a framework
named IntelliAd to automatically measure the ad costs of each scheme. To
demonstrate whether these costs indeed influence users reactions, we finally
observe the correlations between the measured ad costs and the user
perceptions. We discover that the costs related to memory/CPU overhead and
battery consumption are more concerned by users, while the traffic usage is
less concerned by users in spite of its obvious variations among different
schemes in the experiments. Our experimental results provide the developers
with suggestions on better incorporating ads into apps and, meanwhile, ensuring
the user experience.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03578</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Active RBSE Framework to Generate Optimal Stimulus Sequences in a BCI
  for Spelling</dc:title>
 <dc:creator>Moghadamfalahi, Mohammad</dc:creator>
 <dc:creator>Akcakaya, Murat</dc:creator>
 <dc:creator>Nezamfar, Hooman</dc:creator>
 <dc:creator>Sourati, Jamshid</dc:creator>
 <dc:creator>Erdogmus, Deniz</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  A class of brain computer interfaces (BCIs) employs noninvasive recordings of
electroencephalography (EEG) signals to enable users with severe speech and
motor impairments to interact with their environment and social network. For
example, EEG based BCIs for typing popularly utilize event related potentials
(ERPs) for inference. Presentation paradigm design in current ERP-based letter
by letter typing BCIs typically query the user with an arbitrary subset
characters. However, the typing accuracy and also typing speed can potentially
be enhanced with more informed subset selection and flash assignment. In this
manuscript, we introduce the active recursive Bayesian state estimation
(active-RBSE) framework for inference and sequence optimization. Prior to
presentation in each iteration, rather than showing a subset of randomly
selected characters, the developed framework optimally selects a subset based
on a query function. Selected queries are made adaptively specialized for users
during each intent detection. Through a simulation-based study, we assess the
effect of active-RBSE on the performance of a language-model assisted typing
BCI in terms of typing speed and accuracy. To provide a baseline for
comparison, we also utilize standard presentation paradigms namely, row and
column matrix presentation paradigm and also random rapid serial visual
presentation paradigms. The results show that utilization of active-RBSE can
enhance the online performance of the system, both in terms of typing accuracy
and speed.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, Will be submitted to IEEE transactions on Signal
  Processing</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03578</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2728500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03581</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding and Indexing of Lattice Codes</dc:title>
 <dc:creator>Kurkoski, Brian M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Encoding and indexing of lattice codes is generalized from self-similar
lattice codes to a broader class of lattices. If coding lattice
$\Lambda_{\textrm{c}}$ and shaping lattice $\Lambda_{\textrm{s}}$ satisfy
$\Lambda_{\textrm{s}} \subseteq \Lambda_{\textrm{c}}$, then
$\Lambda_{\textrm{c}} / \Lambda_{\textrm{s}}$ is a quotient group that can be
used to form a (nested) lattice code $\mathcal{C}$. Conway and Sloane's method
of encoding and indexing does not apply when the lattices are not self-similar.
Results are provided for two classes of lattices. (1) If $\Lambda_{\textrm{c}}$
and $\Lambda_{\textrm{s}}$ both have generator matrices in triangular form,
then encoding is always possible. (2) When $\Lambda_{\textrm{c}}$ and
$\Lambda_{\textrm{s}}$ are described by full generator matrices, if a solution
to a linear diophantine equation exists, then encoding is possible. In
addition, special cases where $\mathcal{C}$ is a cyclic code are also
considered. A condition for the existence of a group homomorphism between the
information and $\mathcal{C}$ is given. The results are applicable to a variety
of coding lattices, including Construction A, Construction D and LDLCs. The
$D_4$, $E_8$ and convolutional code lattices are shown to be good choices for
the shaping lattice. Thus, a lattice code $\mathcal{C}$ can be designed by
selecting $\Lambda_{\textrm{c}}$ and $\Lambda_{\textrm{s}}$ separately,
avoiding competing design requirements of self-similar lattice codes.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03583</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Repeated multimarket contact with observation errors</dc:title>
 <dc:creator>Sekiguchi, Atsushi Iwasakiand Tadashi</dc:creator>
 <dc:creator>Yamamoto, Shun</dc:creator>
 <dc:creator>Yokoo, Makoto</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper analyzes repeated multimarket contact with observation errors
where two players operate in multiple markets simultaneously. Multimarket
contact has received much attention in economics, management, and so on.
Despite vast empirical studies that examine whether multimarket contact fosters
cooperation or collusion, little is theoretically known as to how players
behave in an equilibrium when each player receives a noisy and different
observation or signal indicating other firms' actions (private monitoring). To
the best of our knowledge, we are the first to construct a strategy designed
for multiple markets whose per-market equilibrium payoffs exceed one for a
single market, in our setting. We first construct an entirely novel strategy
whose behavior is specified by a non-linear function of the signal
configurations. We then show that the per-market equilibrium payoff improves
when the number of markets is sufficiently large.
</dc:description>
 <dc:description>Comment: Accepted for the 9th Intl. Symp. on Algorithmic Game Theory</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03592</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cluster Sampling Filters for Non-Gaussian Data Assimilation</dc:title>
 <dc:creator>Attia, Ahmed</dc:creator>
 <dc:creator>Moosavi, Azam</dc:creator>
 <dc:creator>Sandu, Adrian</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  This paper presents a fully non-Gaussian version of the Hamiltonian Monte
Carlo (HMC) sampling filter. The Gaussian prior assumption in the original HMC
filter is relaxed. Specifically, a clustering step is introduced after the
forecast phase of the filter, and the prior density function is estimated by
fitting a Gaussian Mixture Model (GMM) to the prior ensemble. Using the data
likelihood function, the posterior density is then formulated as a mixture
density, and is sampled using a HMC approach (or any other scheme capable of
sampling multimodal densities in high-dimensional subspaces). The main filter
developed herein is named &quot;cluster HMC sampling filter&quot; (ClHMC). A multi-chain
version of the ClHMC filter, namely MC-ClHMC is also proposed to guarantee that
samples are taken from the vicinities of all probability modes of the
formulated posterior. The new methodologies are tested using a
quasi-geostrophic (QG) model with double-gyre wind forcing and bi-harmonic
friction. Numerical results demonstrate the usefulness of using GMMs to relax
the Gaussian prior assumption in the HMC filtering paradigm.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03594</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Uncertainty Online Against an Adversary</dc:title>
 <dc:creator>Kuleshov, Volodymyr</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Assessing uncertainty is an important step towards ensuring the safety and
reliability of machine learning systems. Existing uncertainty estimation
techniques may fail when their modeling assumptions are not met, e.g. when the
data distribution differs from the one seen at training time. Here, we propose
techniques that assess a classification algorithm's uncertainty via calibrated
probabilities (i.e. probabilities that match empirical outcome frequencies in
the long run) and which are guaranteed to be reliable (i.e. accurate and
calibrated) on out-of-distribution input, including input generated by an
adversary. This represents an extension of classical online learning that
handles uncertainty in addition to guaranteeing accuracy under adversarial
assumptions. We establish formal guarantees for our methods, and we validate
them on two real-world problems: question answering and medical diagnosis from
genomic data.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03597</identifier>
 <datestamp>2017-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating Eulerian Fluid Simulation With Convolutional Networks</dc:title>
 <dc:creator>Tompson, Jonathan</dc:creator>
 <dc:creator>Schlachter, Kristofer</dc:creator>
 <dc:creator>Sprechmann, Pablo</dc:creator>
 <dc:creator>Perlin, Ken</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Efficient simulation of the Navier-Stokes equations for fluid flow is a long
standing problem in applied mathematics, for which state-of-the-art methods
require large compute resources. In this work, we propose a data-driven
approach that leverages the approximation power of deep-learning with the
precision of standard solvers to obtain fast and highly realistic simulations.
Our method solves the incompressible Euler equations using the standard
operator splitting method, in which a large sparse linear system with many free
parameters must be solved. We use a Convolutional Network with a highly
tailored architecture, trained using a novel unsupervised learning framework to
solve the linear system. We present real-time 2D and 3D simulations that
outperform recently proposed data-driven methods; the obtained results are
realistic and show good generalization properties.
</dc:description>
 <dc:description>Comment: Significant revision</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03600</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Elekes-Szab\'o Theorem in four dimensions</dc:title>
 <dc:creator>Raz, Orit E.</dc:creator>
 <dc:creator>Sharir, Micha</dc:creator>
 <dc:creator>de Zeeuw, Frank</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let $F\in\mathbb{C}[x,y,s,t]$ be an irreducible constant-degree polynomial,
and let $A,B,C,D\subset\mathbb{C}$ be finite sets of size $n$. We show that $F$
vanishes on at most $O(n^{8/3})$ points of the Cartesian product $A\times
B\times C\times D$, unless $F$ has a special group-related form. A similar
statement holds for $A,B,C,D$ of unequal sizes. This is a four-dimensional
extension of our recent improved analysis of the original Elekes-Szab\'o
theorem in three dimensions. We give three applications: an expansion bound for
three-variable real polynomials that do not have a special form, a bound on the
number of coplanar quadruples on a space curve that is neither planar nor
quartic, and a bound on the number of four-point circles on a plane curve that
has degree at least five.
</dc:description>
 <dc:description>Comment: 15 pages. v2: We added an application to a problem about coplanar
  quadruples on space curves</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03607</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cloud Empowered Self-Managing WSNs</dc:title>
 <dc:creator>Dias, Gabriel Martins</dc:creator>
 <dc:creator>Margi, Cintia Borges</dc:creator>
 <dc:creator>de Oliveira, Filipe C. P.</dc:creator>
 <dc:creator>Bellalta, Boris</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  Wireless Sensor Networks (WSNs) are composed of low powered and
resource-constrained wireless sensor nodes that are not capable of performing
high-complexity algorithms. Integrating these networks into the Internet of
Things (IoT) facilitates their real-time optimization based on remote data
visualization and analysis. This work describes the design and implementation
of a scalable system architecture that integrates WSNs and cloud services to
work autonomously in an IoT environment. The implementation relies on Software
Defined Networking features to simplify the WSN management and exploits data
analytics tools to execute a reinforcement learning algorithm that takes
decisions based on the environment's evolution. It can automatically configure
wireless sensor nodes to measure and transmit the temperature only at periods
when the environment changes more often. Without any human intervention, the
system could reduce nearly 85% the number of transmissions, showing the
potential of this mechanism to extend WSNs lifetime without compromising the
data quality. Besides attending to similar use cases, such a WSN autonomic
management could promote a new business model to offer sensing tasks as a
service, which is also introduced in this work.
</dc:description>
 <dc:description>Comment: 12 pages, 4200 words, 4 figures, 2 tables, submitted to &quot;IEEE
  Communications Magazine&quot; special issue on the Internet of Things</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03611</identifier>
 <datestamp>2016-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing Driving Styles with Deep Learning</dc:title>
 <dc:creator>Dong, Weishan</dc:creator>
 <dc:creator>Li, Jian</dc:creator>
 <dc:creator>Yao, Renjie</dc:creator>
 <dc:creator>Li, Changsheng</dc:creator>
 <dc:creator>Yuan, Ting</dc:creator>
 <dc:creator>Wang, Lanjun</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Characterizing driving styles of human drivers using vehicle sensor data,
e.g., GPS, is an interesting research problem and an important real-world
requirement from automotive industries. A good representation of driving
features can be highly valuable for autonomous driving, auto insurance, and
many other application scenarios. However, traditional methods mainly rely on
handcrafted features, which limit machine learning algorithms to achieve a
better performance. In this paper, we propose a novel deep learning solution to
this problem, which could be the first attempt of extending deep learning to
driving behavior analysis based on GPS data. The proposed approach can
effectively extract high level and interpretable features describing complex
driving patterns. It also requires significantly less human experience and
work. The power of the learned driving style representations are validated
through the driver identification problem using a large real dataset.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-10-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03618</identifier>
 <datestamp>2016-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Lax-Milgram Theorem. A detailed proof to be formalized in Coq</dc:title>
 <dc:creator>Cl&#xe9;ment, Fran&#xe7;ois</dc:creator>
 <dc:creator>Martin, Vincent</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  To obtain the highest confidence on the correction of numerical simulation
programs implementing the finite element method, one has to formalize the
mathematical notions and results that allow to establish the soundness of the
method. The Lax-Milgram theorem may be seen as one of those theoretical
cornerstones: under some completeness and coercivity assumptions, it states
existence and uniqueness of the solution to the weak formulation of some
boundary value problems. The purpose of this document is to provide the formal
proof community with a very detailed pen-and-paper proof of the Lax-Milgram
theorem.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03626</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>San Francisco Crime Classification</dc:title>
 <dc:creator>Abouelnaga, Yehya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  San Francisco Crime Classification is an online competition administered by
Kaggle Inc. The competition aims at predicting the future crimes based on a
given set of geographical and time-based features. In this paper, I achieved a
an accuracy that ranks at top %18, as of May 19th, 2016. I will explore the
data, and explain in details the tools I used to achieve that result.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03629</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Multi-party Matrix Multiplication and Trust Computations</dc:title>
 <dc:creator>Dumas, Jean-Guillaume</dc:creator>
 <dc:creator>Lafourcade, Pascal</dc:creator>
 <dc:creator>Orfila, Jean-Baptiste</dc:creator>
 <dc:creator>Puys, Maxime</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  This paper deals with distributed matrix multiplication. Each player owns
only one row of both matrices and wishes to learn about one distinct row of the
product matrix, without revealing its input to the other players. We first
improve on a weighted average protocol, in order to securely compute a
dot-product with a quadratic volume of communications and linear number of
rounds. We also propose a protocol with five communication rounds, using a
Paillier-like underlying homomorphic public key cryptosystem, which is secure
in the semi-honest model or secure with high probability in the malicious
adversary model. Using ProVerif, a cryptographic protocol verification tool, we
are able to check the security of the protocol and provide a countermeasure for
each attack found by the tool. We also give a randomization method to avoid
collusion attacks. As an application, we show that this protocol enables a
distributed and secure evaluation of trust relationships in a network, for a
large class of trust evaluation schemes.
</dc:description>
 <dc:description>Comment: Pierangela Samarati. SECRYPT 2016 : 13th International Conference on
  Security and Cryptography, Lisbonne, Portugal, 26--28 Juillet 2016. 2016</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03642</identifier>
 <datestamp>2016-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conversions between Electrical Network Representations</dc:title>
 <dc:creator>Cooman, Adam</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The behaviour of electrical networks can be described with many different
representations, each with their distinct benefits. In this paper, we consider
Z, Y, G, H, ABCD, S and T parameters. Formulas exist to go from one
representation to another, but implementing them is an error-prone procedure.
In this paper, we present a more elegant way to implement the transformations
based on matrix calculations.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03649</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LTL-based Verification of Reconfigurable Workflows</dc:title>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Logics and model-checking have been successfully used in the last decades for
modeling and verification of various types of hardware (and software) systems.
While most languages and techniques emerged in a context of monolithic systems
with a limited self-adaptability, modern systems require approaches able to
cope with dynamically changing requirements and emergent behaviors. The
emphasis on system reconfigurability has not been followed by an adequate
research effort, and the current state of the art lacks logics and model
checking paradigms that can describe and analyze complex modern systems in a
comprehensive way. This paper describes a case study involving the dynamic
reconfiguration of an office workflow. We state the requirements on a system
implementing the workflow and its reconfiguration and we prove workflow
reconfiguration termination by providing a compilation of generic workflows
into LTL, using the Bound model checker Zot. The objective of this paper is
demonstrating how temporal logics and model checking are effective in proving
properties of dynamic, reconfigurable and adaptable systems. This simple case
study is just a &quot;proof of concept&quot; to demonstrate the feasibility of our ideas.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1406.1395</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03649</dc:identifier>
 <dc:identifier>doi:10.12988/ams.2014.410816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03651</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$r-$Bell polynomials in combinatorial Hopf algebras</dc:title>
 <dc:creator>Chouria, Ali</dc:creator>
 <dc:creator>Luque, Jean-Gabriel</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>11B73, 05E05, 16T05</dc:subject>
 <dc:description>  We introduce partial $r$-Bell polynomials in three combinatorial Hopf
algebras. We prove a factorization formula for the generating functions which
is a consequence of the Zassenhauss formula.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03651</dc:identifier>
 <dc:identifier>Comptes Rendus de l'Acad\'emie des sciences Volume 355, Issue 3,
  Pages 243-247 (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03659</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open, privacy-preserving protocols for lawful surveillance</dc:title>
 <dc:creator>Segal, Aaron</dc:creator>
 <dc:creator>Feigenbaum, Joan</dc:creator>
 <dc:creator>Ford, Bryan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The question of how government agencies can acquire actionable, useful
information about legitimate but unknown targets without intruding upon the
electronic activity of innocent parties is extremely important. We address this
question by providing experimental evidence that actionable, useful information
can indeed be obtained in a manner that preserves the privacy of innocent
parties and that holds government agencies accountable. In particular, we
present practical, privacy-preserving protocols for two operations that
law-enforcement and intelligence agencies have used effectively: set
intersection and contact chaining. Experiments with our protocols suggest that
privacy-preserving contact chaining can perform a 3-hop privacy-preserving
graph traversal producing 27,000 ciphertexts in under two minutes. These
ciphertexts are usable in turn via privacy-preserving set intersection to
pinpoint potential unknown targets within a body of 150,000 total ciphertexts
within 10 minutes, without exposing personal information about non-targets.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03665</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy- and Spectral-Efficiency Tradeoff in Full-Duplex Communications</dc:title>
 <dc:creator>Wen, Dingzhu</dc:creator>
 <dc:creator>Yu, Guanding</dc:creator>
 <dc:creator>Liy, Rongpeng</dc:creator>
 <dc:creator>Cheny, Yan</dc:creator>
 <dc:creator>Liz, Geoffrey Ye</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the tradeoff between energyefficiency (EE) and
spectral-efficiency (SE) for full-duplex (FD) enabled cellular networks.We
assume that small cell base stations are working in the FD mode while user
devices still work in the conventional half-duplex (HD) mode. First, a
necessary condition for a FD transceiver to achieve better EE-SE tradeoff than
a HD one is derived. Then, we analyze the EE-SE relation of a FD transceiver in
the scenario of single pair of users and obtain a closed-form expression. Next,
we extend the result into the multiuser scenario and prove that EE is a
quasi-concave function of SE in general and develop an optimal algorithm to
achieve the maximum EE based on the Lagrange dual method. Our analysis is
finally verified by extensive numerical results.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, conference</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03671</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Use of Conjugate Teager-Kaiser Energy Operators with Matched
  Filters</dc:title>
 <dc:creator>Montillet, Jean-Philippe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>94A12, 94A15, 90C25, 46A11, 34L30</dc:subject>
 <dc:description>  This work presents the proof of concept of using energy operator theory based
on the conjugate Teager-Kaiser energy operators in matched filters for signal
detection in multipath fading channels. To do so, we consider signals in the
space $\mathcal{S}(\mathbb{R})$ a subspace of the Schwartz space
$\mathbf{S}^-(\mathbb{R})$ in order to approximate the received signal. These
functions obey to some specific properties as shown in this work. It allows to
decompose the received signals into subchannels with their own
Signal-to-Noise-Ratio.
</dc:description>
 <dc:description>Comment: Working Paper, 8 pages, 1 Figure</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03677</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Distributed Algorithms for Selfish Agents</dc:title>
 <dc:creator>Collet, Simon</dc:creator>
 <dc:creator>Fraigniaud, Pierre</dc:creator>
 <dc:creator>Penna, Paolo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In the classical framework of local distributed network computing, it is
generally assumed that the entities executing distributed algorithms are
altruistic. However, in various scenarios, the value of the output produced by
an entity may have a tremendous impact on its future. This is for instance the
case of tasks such as computing maximal independent sets (MIS) in networks.
Indeed, a node belonging to the MIS may be later asked more than to a node not
in the MIS, e.g., because MIS in networks are often used as backbones to
collect, transfer, and broadcast information, which is costly. In this paper,
we revisit typical local distributed network computing tasks in the framework
of algorithmic game theory. Specifically, we focus on the construction of
solutions for locally checkable labeling (LCL) tasks, which form a large class
of distributed tasks, including MIS, coloring, maximal matching, etc., and
which have been studied for more than 20 years in distributed computing.
  Given an LCL task, the nodes are collectively aiming at computing a solution,
but, at the individual level, every node plays rationally and selfishly with
the objective of optimizing its own profit. Surprisingly, the classical
frameworks for game theory are not fully appropriate for the purpose of our
study. Moreover, we show that classical notions like Nash equilibria may yield
algorithms requiring an arbitrarily large number of rounds to converge.
Nevertheless, by extending and generalizing core results from game theory, we
establish the existence of a so-called trembling-hand perfect equilibria, a
subset of Nash equilibria that is well suited to LCL construction tasks. The
main outcome of the paper is therefore that, for essentially all distributed
tasks whose solutions are locally checkable, there exist construction
algorithms which are robust to selfishness.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03681</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Feature Learning Based on Deep Models for Environmental
  Audio Tagging</dc:title>
 <dc:creator>Xu, Yong</dc:creator>
 <dc:creator>Huang, Qiang</dc:creator>
 <dc:creator>Wang, Wenwu</dc:creator>
 <dc:creator>Foster, Peter</dc:creator>
 <dc:creator>Sigtia, Siddharth</dc:creator>
 <dc:creator>Jackson, Philip J. B.</dc:creator>
 <dc:creator>Plumbley, Mark D.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Environmental audio tagging aims to predict only the presence or absence of
certain acoustic events in the interested acoustic scene. In this paper we make
contributions to audio tagging in two parts, respectively, acoustic modeling
and feature learning. We propose to use a shrinking deep neural network (DNN)
framework incorporating unsupervised feature learning to handle the multi-label
classification task. For the acoustic modeling, a large set of contextual
frames of the chunk are fed into the DNN to perform a multi-label
classification for the expected tags, considering that only chunk (or
utterance) level rather than frame-level labels are available. Dropout and
background noise aware training are also adopted to improve the generalization
capability of the DNNs. For the unsupervised feature learning, we propose to
use a symmetric or asymmetric deep de-noising auto-encoder (sDAE or aDAE) to
generate new data-driven features from the Mel-Filter Banks (MFBs) features.
The new features, which are smoothed against background noise and more compact
with contextual information, can further improve the performance of the DNN
baseline. Compared with the standard Gaussian Mixture Model (GMM) baseline of
the DCASE 2016 audio tagging challenge, our proposed method obtains a
significant equal error rate (EER) reduction from 0.21 to 0.13 on the
development set. The proposed aDAE system can get a relative 6.7% EER reduction
compared with the strong DNN baseline on the development set. Finally, the
results also show that our approach obtains the state-of-the-art performance
with 0.15 EER on the evaluation set of the DCASE 2016 audio tagging task while
EER of the first prize of this challenge is 0.17.
</dc:description>
 <dc:description>Comment: 10 pages, dcase 2016 challenge</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03681</dc:identifier>
 <dc:identifier>IEEE/ACM Transactions on Audio, Speech and Language Processing
  25(6):1230-1241, Jun 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TASLP.2017.2690563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03682</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical learning for DNN-based acoustic scene classification</dc:title>
 <dc:creator>Xu, Yong</dc:creator>
 <dc:creator>Huang, Qiang</dc:creator>
 <dc:creator>Wang, Wenwu</dc:creator>
 <dc:creator>Plumbley, Mark D.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we present a deep neural network (DNN)-based acoustic scene
classification framework. Two hierarchical learning methods are proposed to
improve the DNN baseline performance by incorporating the hierarchical taxonomy
information of environmental sounds. Firstly, the parameters of the DNN are
initialized by the proposed hierarchical pre-training. Multi-level objective
function is then adopted to add more constraint on the cross-entropy based loss
function. A series of experiments were conducted on the Task1 of the Detection
and Classification of Acoustic Scenes and Events (DCASE) 2016 challenge. The
final DNN-based system achieved a 22.9% relative improvement on average scene
classification error as compared with the Gaussian Mixture Model (GMM)-based
benchmark system across four standard folds.
</dc:description>
 <dc:description>Comment: 5 pages, DCASE 2016 challenge workshop paper, poster</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03683</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breaking the Economic Barrier of Caching in Cellular Networks:
  Incentives and Contracts</dc:title>
 <dc:creator>Hamidouche, Kenza</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper, a novel approach for providing incentives for caching in small
cell networks (SCNs) is proposed based on the economics framework of contract
theory. In this model, a mobile network operator (MNO) designs contracts that
will be offered to a number of content providers (CPs) to motivate them to
cache their content at the MNO's small base stations (SBSs). A practical model
in which information about the traffic generated by the CPs' users is not known
to the MNO is considered. Under such asymmetric information, the incentive
contract between the MNO and each CP is properly designed so as to determine
the amount of allocated storage to the CP and the charged price by the MNO. The
contracts are derived by the MNO in a way to maximize the global benefit of the
CPs and prevent them from using their private information to manipulate the
outcome of the caching process. For this interdependent contract model, the
closed-form expressions of the price and the allocated storage space to each CP
are derived. This proposed mechanism is shown to satisfy the sufficient and
necessary conditions for the feasibility of a contract. Moreover, it is shown
that the proposed pricing model is budget balanced, enabling the MNO to cover
all the caching expenses via the prices charged to the CPs. Simulation results
show that none of the CPs will have an incentive to choose a contract designed
for CPs with different traffic loads.
</dc:description>
 <dc:description>Comment: Accepted for publication at Globecom 2016</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03685</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Solutions for the Maximum Revenue Multi-item Auction under
  Dominant-Strategy and Bayesian Implementations</dc:title>
 <dc:creator>Yao, Andrew Chi-Chih</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Very few exact solutions are known for the monopolist's $k$-item $n$-buyer
maximum revenue problem with additive valuation in which $k, n &gt;1$ and the
buyers $i$ have independent private distributions $F^j_i$ on items $j$. In this
paper we derive exact formulas for the maximum revenue when $k=2$ and $F^j_i$
are any IID distributions on support of size 2, for both the dominant-strategy
(DIC) and the Bayesian (BIC) implementations. The formulas lead to the simple
characterization that, the two implementations have identical maximum revenue
if and only if selling-separately is optimal for the distribution. Our results
also give the first demonstration, in this setting, of revenue gaps between the
two implementations. For instance, if $k=n=2$ and
$Pr\{X_F=1\}=Pr\{X_F=2\}=\frac{1}{2}$, then the maximum revenue in the Bayesian
implementation exceeds that in the dominant-strategy by exactly $2\%$; the same
gap exists for the continuous uniform distribution $X_F$ over $[a, a+1]\cup[2a,
2a+1]$ for all large $a$.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03688</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Anarchy of Scheduling Without Money</dc:title>
 <dc:creator>Giannakopoulos, Yiannis</dc:creator>
 <dc:creator>Koutsoupias, Elias</dc:creator>
 <dc:creator>Kyropoulou, Maria</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the scheduling problem on $n$ strategic unrelated machines when
no payments are allowed, under the objective of minimizing the makespan. We
adopt the model introduced in [Koutsoupias, Theory Comput Syst (2014)] where a
machine is bound by her declarations in the sense that if she is assigned a
particular job then she will have to execute it for an amount of time at least
equal to the one she reported, even if her private, true processing
capabilities are actually faster. We provide a (non-truthful) randomized
algorithm whose pure Price of Anarchy is arbitrarily close to $1$ for the case
of a single task and close to $n$ if it is applied independently to schedule
many tasks. Previous work considers the constraint of truthfulness and proves a
tight approximation ratio of $(n+1)/2$ for one task which generalizes to
$n(n+1)/2$ for many tasks. Furthermore, we revisit the truthfulness case and
reduce the latter approximation ratio for many tasks down to $n$,
asymptotically matching the best known lower bound. This is done via a detour
to the relaxed, fractional version of the problem, for which we are also able
to provide an optimal approximation ratio of $1$. Finally, we mention that all
our algorithms achieve optimal ratios of $1$ for the social welfare objective.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03691</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Cost-Sensitive Feature Acquisition</dc:title>
 <dc:creator>Contardo, Gabriella</dc:creator>
 <dc:creator>Denoyer, Ludovic</dc:creator>
 <dc:creator>Arti&#xe8;res, Thierry</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a reinforcement learning based approach to tackle the
cost-sensitive learning problem where each input feature has a specific cost.
The acquisition process is handled through a stochastic policy which allows
features to be acquired in an adaptive way. The general architecture of our
approach relies on representation learning to enable performing prediction on
any partially observed sample, whatever the set of its observed features are.
The resulting model is an original mix of representation learning and of
reinforcement learning ideas. It is learned with policy gradient techniques to
minimize a budgeted inference cost. We demonstrate the effectiveness of our
proposed method with several experiments on a variety of datasets for the
sparse prediction problem where all features have the same cost, but also for
some cost-sensitive settings.
</dc:description>
 <dc:description>Comment: 12 pages, conference : accepted at IDA 2016</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03705</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Possibilistic Networks: Parameters Learning from Imprecise Data and
  Evaluation strategy</dc:title>
 <dc:creator>Haddad, Maroua</dc:creator>
 <dc:creator>Leray, Philippe</dc:creator>
 <dc:creator>Amor, Nahla Ben</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  There has been an ever-increasing interest in multidisciplinary research on
representing and reasoning with imperfect data. Possibilistic networks present
one of the powerful frameworks of interest for representing uncertain and
imprecise information. This paper covers the problem of their parameters
learning from imprecise datasets, i.e., containing multi-valued data. We
propose in the rst part of this paper a possibilistic networks sampling
process. In the second part, we propose a likelihood function which explores
the link between random sets theory and possibility theory. This function is
then deployed to parametrize possibilistic networks.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03707</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Re-presenting a Story by Emotional Factors using Sentimental Analysis
  Method</dc:title>
 <dc:creator>Jo, Hwiyeol</dc:creator>
 <dc:creator>Moon, Yohan</dc:creator>
 <dc:creator>Kim, Jong In</dc:creator>
 <dc:creator>Ryu, Jeong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Remembering an event is affected by personal emotional status. We examined
the psychological status and personal factors; depression (Center for
Epidemiological Studies - Depression, Radloff, 1977), present affective
(Positive Affective and Negative Affective Schedule, Watson et al., 1988), life
orient (Life Orient Test, Scheier &amp; Carver, 1985), self-awareness (Core Self
Evaluation Scale, Judge et al., 2003), and social factor (Social Support,
Sarason et al., 1983) of undergraduate students (N=64) and got summaries of a
story, Chronicle of a Death Foretold (Gabriel Garcia Marquez, 1981) from them.
We implement a sentimental analysis model based on convolutional neural network
(LeCun &amp; Bengio, 1995) to evaluate each summary. From the same vein used for
transfer learning (Pan &amp; Yang, 2010), we collected 38,265 movie review data to
train the model and then use them to score summaries of each student. The
results of CES-D and PANAS show the relationship between emotion and memory
retrieval as follows: depressed people have shown a tendency of representing a
story more negatively, and they seemed less expressive. People with full of
emotion - high in PANAS - have retrieved their memory more expressively than
others, using more negative words then others. The contributions of this study
can be summarized as follows: First, lightening the relationship between
emotion and its effect during times of storing or retrieving a memory. Second,
suggesting objective methods to evaluate the intensity of emotion in natural
language format, using a sentimental analysis model.
</dc:description>
 <dc:description>Comment: Paper version of CogSci2016; We should correct poor English</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03718</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Streaming Algorithms For Computing Edit Distance Without Exploiting
  Suffix Trees</dc:title>
 <dc:creator>Chakraborty, Diptarka</dc:creator>
 <dc:creator>Goldenberg, Elazar</dc:creator>
 <dc:creator>Kouck&#xfd;, Michal</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The edit distance is a way of quantifying how similar two strings are to one
another by counting the minimum number of character insertions, deletions, and
substitutions required to transform one string into the other.
  In this paper we study the computational problem of computing the edit
distance between a pair of strings where their distance is bounded by a
parameter $k\ll n$. We present two streaming algorithms for computing edit
distance: One runs in time $O(n+k^2)$ and the other $n+O(k^3)$. By writing
$n+O(k^3)$ we want to emphasize that the number of operations per an input
symbol is a small constant. In particular, the running time does not depend on
the alphabet size, and the algorithm should be easy to implement.
  Previously a streaming algorithm with running time $O(n+k^4)$ was given in
the paper by the current authors (STOC'16). The best off-line algorithm runs in
time $O(n+k^2)$ (Landau et al., 1998) which is known to be optimal under the
Strong Exponential Time Hypothesis.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03725</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Millimeter Wave Receiver Efficiency: A Comprehensive Comparison of
  Beamforming Schemes with Low Resolution ADCs</dc:title>
 <dc:creator>Abbas, Waqas bin</dc:creator>
 <dc:creator>Gomez-Cuba, Felipe</dc:creator>
 <dc:creator>Zorzi, Michele</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we study the achievable rate and the energy efficiency of
Analog, Hybrid and Digital Combining (AC, HC and DC) for millimeter wave (mmW)
receivers. We take into account the power consumption of all receiver
components, not just Analog-to-Digital Converters (ADC), determine some
practical limitations of beamforming in each architecture, and develop
performance analysis charts that enable comparison of different receivers
simultaneously in terms of two metrics, namely, Spectral Efficiency (SE) and
Energy Efficiency (EE). We present a multi-objective utility optimization
interpretation to find the best SE-EE weighted trade-off among AC, DC and HC
schemes. We consider an Additive Quantization Noise Model (AQNM) to evaluate
the achievable rates with low resolution ADCs. Our analysis shows that AC is
only advantageous if the channel rank is strictly one, the link has very low
SNR, or there is a very stringent low power constraint at the receiver.
Otherwise, we show that the usual claim that DC requires the highest power is
not universally valid. Rather, either DC or HC alternatively result in the
better SE vs EE trade-off depending strongly on the considered power
consumption characteristic values for each component of the mmW receiver.
</dc:description>
 <dc:description>Comment: 32 pages, 17 figures, 4 tables. Submitted to IEEE Transactions on
  Wireless Communications</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03730</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Shallow Detection Cascades for Wearable Sensor-Based Mobile
  Health Applications</dc:title>
 <dc:creator>Dadkhahi, Hamid</dc:creator>
 <dc:creator>Saleheen, Nazir</dc:creator>
 <dc:creator>Kumar, Santosh</dc:creator>
 <dc:creator>Marlin, Benjamin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The field of mobile health aims to leverage recent advances in wearable
on-body sensing technology and smart phone computing capabilities to develop
systems that can monitor health states and deliver just-in-time adaptive
interventions. However, existing work has largely focused on analyzing
collected data in the off-line setting. In this paper, we propose a novel
approach to learning shallow detection cascades developed explicitly for use in
a real-time wearable-phone or wearable-phone-cloud systems. We apply our
approach to the problem of cigarette smoking detection from a combination of
wrist-worn actigraphy data and respiration chest band data using two and three
stage cascades.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03733</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data as processes: introducing measurement data into CARMA models</dc:title>
 <dc:creator>Gilmore, Stephen</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Measurement data provides a precise and detailed description of components
within a complex system but it is rarely used directly as a component of a
system model. In this paper we introduce a model-based representation of
measurement data and use it together with modeller-defined components expressed
in the CARMA modelling language. We assess both liveness and safety properties
of these models with embedded data.
</dc:description>
 <dc:description>Comment: In Proceedings FORECAST 2016, arXiv:1607.02001</dc:description>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03733</dc:identifier>
 <dc:identifier>EPTCS 217, 2016, pp. 31-42</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.217.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03737</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Multicarrier Modulation Framework</dc:title>
 <dc:creator>Maliatsos, Konstantinos</dc:creator>
 <dc:creator>Kofidis, Eleftherios</dc:creator>
 <dc:creator>Kanatas, Athanasios</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Orthogonal frequency division multiplexing (OFDM) has been recently
recognized as inadequate to meet the increased requirements of the next
generation of communication systems. A number of alternative modulation
solutions, based on the use of filter banks, have thus been proposed and are
currently being considered as candidate waveforms for the envisaged air
interface of the future networks. A unified view of these schemes would largely
facilitate a systematic comparison of their pros and cons as well as the study
of methods for related signal processing problems. To this end, a generic
modulator is developed in this paper, following a structured matrix
formulation. With appropriate parameter settings, existing modulation schemes
can result as special cases. Three such popular examples are presented in
detail.
</dc:description>
 <dc:description>Comment: 8 pages, 1 Figure</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03738</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do semantic parts emerge in Convolutional Neural Networks?</dc:title>
 <dc:creator>Gonzalez-Garcia, Abel</dc:creator>
 <dc:creator>Modolo, Davide</dc:creator>
 <dc:creator>Ferrari, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic object parts can be useful for several visual recognition tasks.
Lately, these tasks have been addressed using Convolutional Neural Networks
(CNN), achieving outstanding results. In this work we study whether CNNs learn
semantic parts in their internal representation. We investigate the responses
of convolutional filters and try to associate their stimuli with semantic
parts. We perform two extensive quantitative analyses. First, we use
ground-truth part bounding-boxes from the PASCAL-Part dataset to determine how
many of those semantic parts emerge in the CNN. We explore this emergence for
different layers, network depths, and supervision levels. Second, we collect
human judgements in order to study what fraction of all filters systematically
fire on any semantic part, even if not annotated in PASCAL-Part. Moreover, we
explore several connections between discriminative power and semantics. We find
out which are the most discriminative filters for object recognition, and
analyze whether they respond to semantic parts or to other image patches. We
also investigate the other direction: we determine which semantic parts are the
most discriminative and whether they correspond to those parts emerging in the
network. This enables to gain an even deeper understanding of the role of
semantic parts in the network.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03739</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Cycloidal Gears for 3D Printing</dc:title>
 <dc:creator>Daniels, Sunny</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  (Shortened version of abstract in article itself)
  This article describes an algorithm for producing, for any desired resolution
and any desired numbers of wheel and pinion teeth, polygonal approximations to
the shapes of a pair of cycloidal gears that mesh correctly. An Octave
implementation of the algorithm, mostly written in 2014, is included. The
Octave implementation contains a (crude, but evidently adequate, at least for
reasonable numbers of wheel and pinion teeth) solution of the problem of
iteratively finding the generating wheel angle corresponding to the tips of the
tooth addenda.
  However, this Octave implementation does not contain a good solution to the
problem of automatically determining the generating wheel angles required to
produce a polygon which approximates the curved addenda to a resolution
specified by the user. A proposed better solution to this problem, involving a
priority queue, is discussed.
</dc:description>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03747</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategies with Parallel Causes</dc:title>
 <dc:creator>de Visme, Marc</dc:creator>
 <dc:creator>Winskel, Glynn</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In a distributed game we imagine a team Player engaging a team Opponent in a
distributed fashion. Such games and their strategies have been formalised in
concurrent games based on event structures. However there are limitations in
founding strategies on traditional event structures. Sometimes a probabilistic
distributed strategy relies on certain benign races where, intuitively, several
members of team Player may race each other to make a common move. Although
there are event structures which support such parallel causes, in which an
event is enabled in several compatible ways, they do not support an operation
of hiding central to the composition of strategies; nor do they support
probability adequately. An extension of traditional event structures is devised
which supports parallel causes and hiding, as well as the mix of probability
and nondeterminism needed to account for probabilistic distributed strategies.
The extension is tested in the construction of a bicategory of probabilistic
distributed strategies with parallel causes. The bicategory is rich in
operations relevant to probabilistic as well as deterministic parallel
programming.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03748</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Software Delivery Process Shortcomings and Architectural
  Pitfalls</dc:title>
 <dc:creator>Patwardhan, Amol</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper highlights the common pitfalls of overcomplicating the software
architecture, development and delivery process by examining two enterprise
level web application products built using Microsoft.Net framework. The aim of
this paper is to identify, discuss and analyze architectural, development and
deployment issues and learn lessons using real world examples from the chosen
software products as case studies.
</dc:description>
 <dc:description>Comment: 10 pages, Submitted to PeerJ Computer Science (in review)</dc:description>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03760</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Games and Strategies</dc:title>
 <dc:creator>Winskel, Glynn</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A summary of work on distributed games and strategies done within the first
three years of the ERC project ECSYM is presented.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03766</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AudioPairBank: Towards A Large-Scale Tag-Pair-Based Audio Content
  Analysis</dc:title>
 <dc:creator>Sager, Sebastian</dc:creator>
 <dc:creator>Elizalde, Benjamin</dc:creator>
 <dc:creator>Borth, Damian</dc:creator>
 <dc:creator>Schulze, Christian</dc:creator>
 <dc:creator>Raj, Bhiksha</dc:creator>
 <dc:creator>Lane, Ian</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently, sound recognition has been used to identify sounds, such as car and
river. However, sounds have nuances that may be better described by
adjective-noun pairs such as slow car, and verb-noun pairs such as flying
insects, which are under explored. Therefore, in this work we investigate the
relation between audio content and both adjective-noun pairs and verb-noun
pairs. Due to the lack of datasets with these kinds of annotations, we
collected and processed the AudioPairBank corpus consisting of a combined total
of 1,123 pairs and over 33,000 audio files. One contribution is the previously
unavailable documentation of the challenges and implications of collecting
audio recordings with these type of labels. A second contribution is to show
the degree of correlation between the audio content and the labels through
sound recognition experiments, which yielded results of 70% accuracy, hence
also providing a performance benchmark. The results and study in this paper
encourage further exploration of the nuances in audio and are meant to
complement similar research performed on images and text in multimedia
analysis.
</dc:description>
 <dc:description>Comment: This paper is a revised version of &quot;AudioSentibank: Large-scale
  Semantic Ontology of Acoustic Concepts for Audio Content Analysis&quot;</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03780</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Vector Space for Distributional Semantics for Entailment</dc:title>
 <dc:creator>Henderson, James</dc:creator>
 <dc:creator>Popa, Diana Nicoleta</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Distributional semantics creates vector-space representations that capture
many forms of semantic similarity, but their relation to semantic entailment
has been less clear. We propose a vector-space model which provides a formal
foundation for a distributional semantics of entailment. Using a mean-field
approximation, we develop approximate inference procedures and entailment
operators over vectors of probabilities of features being known (versus
unknown). We use this framework to reinterpret an existing
distributional-semantic model (Word2Vec) as approximating an entailment-based
model of the distributions of words in contexts, thereby predicting lexical
entailment relations. In both unsupervised and semi-supervised experiments on
hyponymy detection, we get substantial improvements over previous results.
</dc:description>
 <dc:description>Comment: To appear in Proc. 54th Annual Meeting of the Association
  Computational Linguistics (ACL 2016)</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03785</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Convolutional Neural Network for Image Classification on
  Pascal VOC Challenge 2012 dataset</dc:title>
 <dc:creator>Shetty, Suyash</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this project we work on creating a model to classify images for the Pascal
VOC Challenge 2012. We use convolutional neural networks trained on a single
GPU instance provided by Amazon via their cloud service Amazon Web Services
(AWS) to classify images in the Pascal VOC 2012 data set. We train multiple
convolutional neural network models and finally settle on the best model which
produced a validation accuracy of 85.6% and a testing accuracy of 85.24%.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03786</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Event Localization via Alternating Direction Method of
  Multipliers</dc:title>
 <dc:creator>Zhang, Chunlei</dc:creator>
 <dc:creator>Wang, Yongqiang</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper addresses the problem of distributed event localization using
noisy range measurements with respect to sensors with known positions. Event
localization is fundamental in many wireless sensor network applications such
as homeland security, law enforcement, and environmental studies. However, a
distributed algorithm is still lacking which can split the intensive
localization computation among a wireless sensor network in which individual
sensors only have limited computational capacity. Based on the alternating
direction method of multipliers (ADMM), we propose a distributed event
localization structure and two scalable distributed algorithms named GS-ADMM
and J-ADMM respectively. More specifically, we consider a scenario in which the
entire sensor network is divided into several clusters with a cluster head
collecting measurements within each cluster and performing local localization.
In the meantime, the cluster heads exchange intermediate computation
information which will be factored into their local computations to achieve
consistency (consensus) across the localization results of all cluster heads.
Simulation results confirm that the proposed approaches can indeed achieve
localization consistency (consensus) across the clusters and each cluster can
obtain better localization performance compared with the case in which cluster
heads only use local measurements within clusters.
</dc:description>
 <dc:description>Comment: 13 pages, 13 figures</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03787</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to obtain lattices from (f,sigma,delta)-codes via a generalization
  of Construction A</dc:title>
 <dc:creator>Pumpluen, Susanne</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>Primary: 17A35, Secondary: 11T71, 94B40, 94B05</dc:subject>
 <dc:description>  We show how cyclic $(f,\sigma,\delta)$-codes over finite rings canonically
induce a $\mathbb{Z}$-lattice in $\mathbb{R}^N$ by using certain quotients of
orders in nonassociative division algebras defined using the skew polynomial
$f$. This construction generalizes the one using certain $\sigma$-constacyclic
codes by Ducoat and Oggier, which used quotients of orders in non-commutative
associative division algebras defined by $f$, and can be viewed as a
generalization of the classical Construction A for lattices from linear codes.
It has the potential to be applied to coset coding, in particular to wire-tap
coding. Previous results by Ducoat and Oggier are obtained as special cases.
</dc:description>
 <dc:description>Comment: Parts of the paper have been rewritten and some proofs included,
  Section 6 has been dropped</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03791</identifier>
 <datestamp>2016-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Approximation for Weighted Tree Augmentation with Bounded Costs</dc:title>
 <dc:creator>Adjiashvili, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>90C27</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  The Weighted Tree Augmentation Problem (WTAP) is a fundamental well-studied
problem in the field of network design. Given an undirected tree $G=(V,E)$, an
additional set of edges $L \subseteq V\times V$ disjoint from $E$ called
\textit{links}, and a cost vector $c\in \mathbb{R}_{\geq 0}^L$, WTAP asks to
find a minimum-cost set $F\subseteq L$ with the property that $(V,E\cup F)$ is
$2$-edge connected. The special case where $c_\ell = 1$ for all $\ell\in L$ is
called the Tree Augmentation Problem (TAP). Both problems are known to be
NP-hard.
  For the class of bounded cost vectors, we present a first improved
approximation algorithm for WTAP since more than three decades. Concretely, for
any $M\in \mathbb{Z}_{\geq 1}$ and $\epsilon &gt; 0,$ we present an LP based
$(\delta+\epsilon)$-approximation for WTAP restricted to cost vectors $c$ in
$[1,M]^L$ for $\delta \approx 1.96417$. For the special case of TAP we improve
this factor to $\frac{5}{3}+\epsilon$.
  Our results rely on a new LP, that significantly differs from existing LPs
achieving improved bounds for TAP. We round a fractional solution in two
phases. The first phase uses the fractional solution to decompose the tree and
its fractional solution into so-called $\beta$-simple pairs losing only an
$\epsilon$-factor in the objective function. We then show how to use the
additional constraints in our LP combined with the $\beta$-simple structure to
round a fractional solution in each part of the decomposition.
</dc:description>
 <dc:description>Comment: 21 pages, 8 figures</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03795</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hybrid Dynamical Extension of Averaging</dc:title>
 <dc:creator>De, Avik</dc:creator>
 <dc:creator>Burden, Samuel A.</dc:creator>
 <dc:creator>Koditschek, Daniel E.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  We extend a smooth dynamical systems averaging technique to a class of hybrid
systems with a limit cycle that is particularly relevant to the synthesis of
stable legged gaits. After introducing a definition of hybrid averageability
sufficient to recover the classical result, we provide a simple illustration of
its applicability to legged locomotion and conclude with some rather more
speculative remarks concerning the prospects for further generalization of
these ideas.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03810</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Algebraic Representation of One-Tape Deterministic Turing Machine</dc:title>
 <dc:creator>Liu, Yue</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  An algebraic representation of the Turing machines is given, where the
configurations of Turing machines are represented by 4 order tensors, and the
transition functions by 8 order tensors. Two types of tensor product are
defined, one is to model the evolution of the Turing machines, and the other is
to model the compositions of transition functions. It is shown that the two
types of tensor product are harmonic in the sense that the associate law is
obeyed.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03819</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Chen Conjecture regarding the complexity of QCSPs</dc:title>
 <dc:creator>Martin, Barnaby</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Let A be an idempotent algebra on a finite domain. We combine results of Chen
2008 and Zhuk 2015 to argue that if Inv(A) satisfies the polynomially generated
powers property (PGP), then QCSP(Inv(A)) is in NP. We then use the result of
Zhuk to prove a converse, that if Inv(A) satisfies the exponentially generated
powers property (EGP), then QCSP(Inv(A)) is co-NP-hard. Since Zhuk proved that
only PGP and EGP are possible, we derive a full dichotomy for the QCSP,
justifying the moral correctness of what we term the Chen Conjecture.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03821</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Truthfulness with Value-Maximizing Bidders</dc:title>
 <dc:creator>Fadaei, Salman</dc:creator>
 <dc:creator>Bichler, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In markets such as digital advertising auctions, bidders want to maximize
value rather than payoff. This is different to the utility functions typically
assumed in auction theory and leads to different strategies and outcomes. We
refer to bidders who maximize value as value bidders. While simple
single-object auction formats are truthful, standard multi-object auction
formats allow for manipulation. It is straightforward to show that there cannot
be a truthful and revenue-maximizing deterministic auction mechanism with value
bidders and general valuations. Approximation has been used as a means to
achieve truthfulness, and we study which approximation ratios we can get from
truthful approximation mechanisms. We show that the approximation ratio that
can be achieved with a deterministic and truthful approximation mechanism with
$n$ bidders and $m$ items cannot be higher than 1/n for general valuations. For
randomized approximation mechanisms there is a framework with a ratio of
O(sqrt(m)). We provide better ratios for environments with restricted
valuations.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03822</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Extraction and Automated Classification of Heartbeats by Machine
  Learning</dc:title>
 <dc:creator>Lakshminarayan, Choudur</dc:creator>
 <dc:creator>Basil, Tony</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present algorithms for the detection of a class of heart arrhythmias with
the goal of eventual adoption by practicing cardiologists. In clinical
practice, detection is based on a small number of meaningful features extracted
from the heartbeat cycle. However, techniques proposed in the literature use
high dimensional vectors consisting of morphological, and time based features
for detection. Using electrocardiogram (ECG) signals, we found smaller subsets
of features sufficient to detect arrhythmias with high accuracy. The features
were found by an iterative step-wise feature selection method. We depart from
common literature in the following aspects: 1. As opposed to a high dimensional
feature vectors, we use a small set of features with meaningful clinical
interpretation, 2. we eliminate the necessity of short-duration
patient-specific ECG data to append to the global training data for
classification 3. We apply semi-parametric classification procedures (in an
ensemble framework) for arrhythmia detection, and 4. our approach is based on a
reduced sampling rate of ~ 115 Hz as opposed to 360 Hz in standard literature.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03827</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The KIT Motion-Language Dataset</dc:title>
 <dc:creator>Plappert, Matthias</dc:creator>
 <dc:creator>Mandery, Christian</dc:creator>
 <dc:creator>Asfour, Tamim</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Linking human motion and natural language is of great interest for the
generation of semantic representations of human activities as well as for the
generation of robot activities based on natural language input. However, while
there have been years of research in this area, no standardized and openly
available dataset exists to support the development and evaluation of such
systems. We therefore propose the KIT Motion-Language Dataset, which is large,
open, and extensible. We aggregate data from multiple motion capture databases
and include them in our dataset using a unified representation that is
independent of the capture system or marker set, making it easy to work with
the data regardless of its origin. To obtain motion annotations in natural
language, we apply a crowd-sourcing approach and a web-based tool that was
specifically build for this purpose, the Motion Annotation Tool. We thoroughly
document the annotation process itself and discuss gamification methods that we
used to keep annotators motivated. We further propose a novel method,
perplexity-based selection, which systematically selects motions for further
annotation that are either under-represented in our dataset or that have
erroneous annotations. We show that our method mitigates the two aforementioned
problems and ensures a systematic annotation process. We provide an in-depth
analysis of the structure and contents of our resulting dataset, which, as of
June 14, 2016, contains 3917 motions with a total duration of 11.26 hours and
5486 annotations in natural language that contain 45779 words. We believe that
this makes our dataset an excellent choice that enables more transparent and
comparable research in this important area.
</dc:description>
 <dc:description>Comment: 5 figures, 4 tables, submitted to Big Data journal, Special Issue on
  Robotics</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03830</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Clock Skew and Offset Estimation in Wireless Sensor
  Networks: Asynchronous Algorithm and Convergence Analysis</dc:title>
 <dc:creator>Du, Jian</dc:creator>
 <dc:creator>Wu, Yik-Chung</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a fully distributed algorithm for joint clock skew
and offset estimation in wireless sensor networks based on belief propagation.
In the proposed algorithm, each node can estimate its clock skew and offset in
a completely distributed and asynchronous way: some nodes may update their
estimates more frequently than others using outdated message from neighboring
nodes. In addition, the proposed algorithm is robust to random packet loss.
Such algorithm does not require any centralized information processing or
coordination, and is scalable with network size. The proposed algorithm
represents a unified framework that encompasses both classes of synchronous and
asynchronous algorithms for network-wide clock synchronization. It is shown
analytically that the proposed asynchronous algorithm converges to the optimal
estimates with estimation mean-square-error at each node approaching the
centralized Cram\'er-Rao bound under any network topology. Simulation results
further show that {the convergence speed is faster than that corresponding to a
synchronous algorithm}.
</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03848</identifier>
 <datestamp>2016-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Periodicity of identifying codes in strips</dc:title>
 <dc:creator>Jiang, Minghui</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  An identifying code in a graph is a subset of vertices having a nonempty and
distinct intersection with the closed neighborhood of every vertex. We prove
that the infimum density of any identifying code in $S_k$ (an infinite strip of
$k$ rows in the square grid) can always be achieved by a periodic identifying
code with pattern length at most $2^{4k}$. Assisted by a compute program
implementing Karp's algorithm for minimum cycle mean, we find a periodic
identifying code in $S_4$ with the minimum density $11/28$, and a periodic
identifying code in $S_5$ with the minimum density $19/50$.
</dc:description>
 <dc:description>Comment: added two references [2,3] and updated introduction</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03849</identifier>
 <datestamp>2016-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fitting a Simplicial Complex using a Variation of k-means</dc:title>
 <dc:creator>Beben, Piotr</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We give a simple and effective two stage algorithm for approximating a point
cloud $\mathcal{S}\subset\mathbb{R}^m$ by a simplicial complex $K$. The first
stage is an iterative fitting procedure that generalizes k-means clustering,
while the second stage involves deleting redundant simplices. A form of
dimension reduction of $\mathcal{S}$ is obtained as a consequence.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03854</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Partially Observable Hidden Markov Model and its Application to
  Keystroke Dynamics</dc:title>
 <dc:creator>Monaco, John V.</dc:creator>
 <dc:creator>Tappert, Charles C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The partially observable hidden Markov model is an extension of the hidden
Markov Model in which the hidden state is conditioned on an independent Markov
chain. This structure is motivated by the presence of discrete metadata, such
as an event type, that may partially reveal the hidden state but itself
emanates from a separate process. Such a scenario is encountered in keystroke
dynamics whereby a user's typing behavior is dependent on the text that is
typed. Under the assumption that the user can be in either an active or passive
state of typing, the keyboard key names are event types that partially reveal
the hidden state due to the presence of relatively longer time intervals
between words and sentences than between letters of a word. Using five public
datasets, the proposed model is shown to consistently outperform other anomaly
detectors, including the standard HMM, in biometric identification and
verification tasks and is generally preferred over the HMM in a Monte Carlo
goodness of fit test.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03856</identifier>
 <datestamp>2016-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Structured-Output Regression Learning for Computational Color
  Constancy</dc:title>
 <dc:creator>Qian, Yanlin</dc:creator>
 <dc:creator>Chen, Ke</dc:creator>
 <dc:creator>Kamarainen, Joni-Kristian</dc:creator>
 <dc:creator>Nikkanen, Jarno</dc:creator>
 <dc:creator>Matas, Jiri</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computational color constancy that requires esti- mation of illuminant colors
of images is a fundamental yet active problem in computer vision, which can be
formulated into a regression problem. To learn a robust regressor for color
constancy, obtaining meaningful imagery features and capturing latent
correlations across output variables play a vital role. In this work, we
introduce a novel deep structured-output regression learning framework to
achieve both goals simultaneously. By borrowing the power of deep convolutional
neural networks (CNN) originally designed for visual recognition, the proposed
framework can automatically discover strong features for white balancing over
different illumination conditions and learn a multi-output regressor beyond
underlying relationships between features and targets to find the complex
interdependence of dif- ferent dimensions of target variables. Experiments on
two public benchmarks demonstrate that our method achieves competitive
performance in comparison with the state-of-the-art approaches.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03866</identifier>
 <datestamp>2016-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical optimization of Steiner Trees via the cavity method</dc:title>
 <dc:creator>Braunstein, Alfredo</dc:creator>
 <dc:creator>Muntoni, Anna</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:description>  The optimization version of the cavity method for single instances, called
Max-Sum, has been applied in the past to the Minimum Steiner Tree Problem on
Graphs and variants. Max-Sum has been shown experimentally to give
asymptotically optimal results on certain types of weighted random graphs, and
to give good solutions in short computation times for some types of real
networks. However, the hypotheses behind the formulation and the cavity method
itself limit substantially the class of instances on which the approach gives
good results (or even converges). Moreover, in the standard model formulation,
the diameter of the tree solution is limited by a predefined bound, that
affects both computation time and convergence properties. In this work we
describe two main enhancements to the Max-Sum equations to be able to cope with
optimization of real-world instances. First, we develop an alternative 'flat'
model formulation, that allows to reduce substantially the relevant
configuration space, making the approach feasible on instances with large
solution diameter, in particular when the number of terminal nodes is small.
Second, we propose an integration between Max-Sum and three greedy heuristics.
This integration allows to transform Max-Sum into a highly competitive
self-contained algorithm, in which a feasible solution is given at each step of
the iterative procedure. Part of this development participated on the 2014
DIMACS challenge on Steiner Problems, and we report the results here.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03866</dc:identifier>
 <dc:identifier>J. Stat. Mech. (2016) 073302</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2016/07/073302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03877</identifier>
 <datestamp>2016-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compactification of *-autonomous categories</dc:title>
 <dc:creator>Slavnov, Sergey</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  We study the question when a *-autonomous (Mix-)category has a representation
as a $*$-autonomous category of a compact one. We prove that necessary and
sufficient condition is that weak distributivity maps are monic (or,
equivalently epic). For a Mix-category, this condition is, in turn, equivalent
to the requirement that Mix-maps be monic (or epic). We call categories
satisfying this property torsion-free. An important side result is that
torsion-free categories have canonical partial traces.
</dc:description>
 <dc:description>Comment: Withdrawn. The author found a stupid diverging loophole in a proof,
  and the announced result is false anyway</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03881</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opinion Dynamics in Networks: Convergence, Stability and Lack of
  Explosion</dc:title>
 <dc:creator>Mai, Tung</dc:creator>
 <dc:creator>Panageas, Ioannis</dc:creator>
 <dc:creator>Vazirani, Vijay V.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Inspired by the work of [Kempe, Kleinberg, Oren, Slivkins, EC13] we introduce
and analyze a model on opinion formation; the update rule of our dynamics is a
simplified version of that of Kempe et. al. We assume that the population is
partitioned into types whose interaction pattern is specified by a graph.
Interaction leads to population mass moving from types of smaller mass to those
of bigger. We show that starting uniformly at random over all population
vectors on the simplex, our dynamics converges point-wise with probability one
to an independent set. This settles an open problem of Kempe et. al., as
applicable to our dynamics. We believe that our techniques can be used to
settle the open problem for the Kempe et. al. dynamics as well.
  Next, we extend the model of Kempe et. al. by introducing the notion of birth
and death of types, with the interaction graph evolving appropriately. Birth of
types is determined by a Bernoulli process and types die when their population
mass is less than a parameter $\epsilon$. We show that if the births are
infrequent, then there are long periods of &quot;stability&quot; in which there is no
population mass that moves. Finally we show that even if births are frequent
and &quot;stability&quot; is not attained, the total number of types does not explode: it
remains logarithmic in $1/\epsilon$.
</dc:description>
 <dc:description>Comment: 24 pages, 3 figures. Preliminary version in ICALP 2017</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03884</identifier>
 <datestamp>2017-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An investigation of GPU-based stiff chemical kinetics integration
  methods</dc:title>
 <dc:creator>Curtis, Nicholas J.</dc:creator>
 <dc:creator>Niemeyer, Kyle E.</dc:creator>
 <dc:creator>Sung, Chih-Jen</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>80A32 (Primary), 80A30, 65L04, 65L06 (Secondary)</dc:subject>
 <dc:description>  A fifth-order implicit Runge-Kutta method and two fourth-order exponential
integration methods equipped with Krylov subspace approximations were
implemented for the GPU and paired with the analytical chemical kinetic
Jacobian software pyJac. The performance of each algorithm was evaluated by
integrating thermochemical state data sampled from stochastic partially stirred
reactor simulations and compared with the commonly used CPU-based implicit
integrator CVODE. We estimated that the implicit Runge-Kutta method running on
a single GPU is equivalent to CVODE running on 12-38 CPU cores for integration
of a single global integration time step of 1e-6 s with hydrogen and methane
models. In the stiffest case studied---the methane model with a global
integration time step of 1e-4 s---thread divergence and higher memory traffic
significantly decreased GPU performance to the equivalent of CVODE running on
approximately three CPU cores. The exponential integration algorithms performed
more slowly than the implicit integrators on both the CPU and GPU. Thread
divergence and memory traffic were identified as the main limiters of GPU
integrator performance, and techniques to mitigate these issues were discussed.
Use of a finite-difference Jacobian on the GPU---in place of the analytical
Jacobian provided by pyJac---greatly decreased integrator performance due to
thread divergence, resulting in maximum slowdowns of 7.11-240.96 times; in
comparison, the corresponding slowdowns on the CPU were just 1.39-2.61 times,
underscoring the importance of use of an analytical Jacobian for efficient GPU
integration. Finally, future research directions for working towards enabling
realistic chemistry in reactive-flow simulations via GPU\slash SIMD accelerated
stiff chemical kinetic integration were identified.
</dc:description>
 <dc:description>Comment: 34 pages, 6 figures; pdfLaTeX</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03884</dc:identifier>
 <dc:identifier>Combust. Flame 179 (2017) 312-324</dc:identifier>
 <dc:identifier>doi:10.1016/j.combustflame.2017.02.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03895</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tie-breaker: Using language models to quantify gender bias in sports
  journalism</dc:title>
 <dc:creator>Fu, Liye</dc:creator>
 <dc:creator>Danescu-Niculescu-Mizil, Cristian</dc:creator>
 <dc:creator>Lee, Lillian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Gender bias is an increasingly important issue in sports journalism. In this
work, we propose a language-model-based approach to quantify differences in
questions posed to female vs. male athletes, and apply it to tennis post-match
interviews. We find that journalists ask male players questions that are
generally more focused on the game when compared with the questions they ask
their female counterparts. We also provide a fine-grained analysis of the
extent to which the salience of this bias depends on various factors, such as
question type, game outcome or player rank.
</dc:description>
 <dc:description>Comment: Best paper award at the IJCAI workshop on NLP Meets Journalism; 5
  pages, 2 figures; data and other info available at
  http://www.cs.cornell.edu/~liye/tennis.html</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03914</identifier>
 <datestamp>2017-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A simple multiforce layout for multiplex networks</dc:title>
 <dc:creator>Fatemi, Zahra</dc:creator>
 <dc:creator>Salehi, Mostafa</dc:creator>
 <dc:creator>Magnani, Matteo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We introduce multiforce, a force-directed layout for multiplex networks,
where the nodes of the network are organized into multiple layers and both
in-layer and inter-layer relationships among nodes are used to compute node
coordinates. The proposed approach generalizes existing work, providing a range
of intermediate layouts in-between the ones produced by known methods. Our
experiments on real data show that multiforce can keep nodes well aligned
across different layers without significantly affecting their internal layouts
when the layers have similar or compatible topologies. As a consequence,
multiforce enriches the benefits of force-directed layouts by also supporting
the identification of topological correspondences between layers.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03918</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Isomorphism Restricted by Lists</dc:title>
 <dc:creator>Klavik, Pavel</dc:creator>
 <dc:creator>Knop, Du&#x161;an</dc:creator>
 <dc:creator>Zeman, Peter</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The complexity of graph isomorphism (GraphIso) is a famous unresolved problem
in theoretical computer science. For graphs $G$ and $H$, it asks whether they
are the same up to a relabeling of vertices. In 1981, Lubiw proved that list
restricted graph isomorphism (ListIso) is NP-complete: for each $u \in V(G)$,
we are given a list ${\mathfrak L}(u) \subseteq V(H)$ of possible images of
$u$. After 35 years, we revive the study of this problem and consider which
results for GraphIso translate to ListIso.
  We prove the following: 1) When GraphIso is GI-complete for a class of
graphs, it translates into NP-completeness of ListIso. 2) Combinatorial
algorithms for GraphIso translate into algorithms for ListIso: for trees,
planar graphs, interval graphs, circle graphs, permutation graphs, bounded
genus graphs, and bounded treewidth graphs. 3) Algorithms based on group theory
do not translate: ListIso remains NP-complete for cubic colored graphs with
sizes of color classes bounded by 8.
  Also, ListIso allows to classify results for the graph isomorphism problem.
Some algorithms are robust and translate to ListIso. A fundamental problem is
to construct a combinatorial polynomial-time algorithm for cubic graph
isomorphism, avoiding group theory. By the 3rd result, ListIso is NP-hard for
them, so no robust algorithm for cubic graph isomorphism exists, unless P = NP.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03922</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of Graphical User Interface For Microwave Filter Design</dc:title>
 <dc:creator>Gerard, Djengomemgoto</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This research project aims at developing a low-cost, time-effective and a
stand-alone graphical user interface (GUI) that will be used to design
microwave filters. Throughout the projects, the main theory behind the
technology of microwave filters, their generalized mathematical equations and
the analysis of their different circuit topologies have been reviewed. This
review helps to extract the necessary information needed for the design of
microwave filters. Besides, the guiding principles and the underlying
engineering factors for a successful and information-oriented GUI were also
highlighted. To carry out the project, the High-Level GUI Development
Environment (GUIDE) together with a structured programming approach have been
used to design the GUI, and to program its related functionalities. The
frequency responses are generated by using the generalized equation of each
filter class and type; and by using their different circuit topologies (Shunt
or Series topology). The GUI can also provide reactive element values from
given specification. Moreover, the features for the design of ultra-wideband
(UWB) band-pass filter, capacitively coupled and combline filter are also
incorporated into the stand-alone application. The finalized prototype will
serve both industries and educational institutions.
</dc:description>
 <dc:description>Comment: BSc Thesis (30th December, 2013), Universiti Teknologi PETRONAS,
  Malaysia. arXiv admin note: text overlap with arXiv:1206.3509 by other
  authors without attribution</dc:description>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03936</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted BFBT Preconditioner for Stokes Flow Problems with Highly
  Heterogeneous Viscosity</dc:title>
 <dc:creator>Rudi, Johann</dc:creator>
 <dc:creator>Stadler, Georg</dc:creator>
 <dc:creator>Ghattas, Omar</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65F08, 65F10, 65N55, 65Y05 (Primary), 76D07, 76A05, 65N30
  (Secondary)</dc:subject>
 <dc:description>  We present a weighted BFBT approximation (w-BFBT) to the inverse Schur
complement of a Stokes system with highly heterogeneous viscosity. When used as
part of a Schur complement-based Stokes preconditioner, we observe robust fast
convergence for Stokes problems with smooth but highly varying (up to 10 orders
of magnitude) viscosities, optimal algorithmic scalability with respect to mesh
refinement, and only a mild dependence on the polynomial order of high-order
finite element discretizations ($Q_k \times P_{k-1}^{disc}$, order $k \ge 2$).
For certain difficult problems, we demonstrate numerically that w-BFBT
significantly improves Stokes solver convergence over the widely used inverse
viscosity-weighted pressure mass matrix approximation of the Schur complement.
In addition, we derive theoretical eigenvalue bounds to prove spectral
equivalence of w-BFBT. Using detailed numerical experiments, we discuss
modifications to w-BFBT at Dirichlet boundaries that decrease the number of
iterations. The overall algorithmic performance of the Stokes solver is
governed by the efficacy of w-BFBT as a Schur complement approximation and, in
addition, by our parallel hybrid spectral-geometric-algebraic multigrid (HMG)
method, which we use to approximate the inverses of the viscous block and
variable-coefficient pressure Poisson operators within w-BFBT. Building on the
scalability of HMG, our Stokes solver achieves a parallel efficiency of 90%
while weak scaling over a more than 600-fold increase from 48 to all 30,000
cores of TACC's Lonestar 5 supercomputer.
</dc:description>
 <dc:description>Comment: To appear in SIAM Journal on Scientific Computing</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03938</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tolerant Junta Testing and the Connection to Submodular Optimization and
  Function Isomorphism</dc:title>
 <dc:creator>Blais, Eric</dc:creator>
 <dc:creator>Canonne, Cl&#xe9;ment L.</dc:creator>
 <dc:creator>Eden, Talya</dc:creator>
 <dc:creator>Levi, Amit</dc:creator>
 <dc:creator>Ron, Dana</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A function $f\colon \{-1,1\}^n \to \{-1,1\}$ is a $k$-junta if it depends on
at most $k$ of its variables. We consider the problem of tolerant testing of
$k$-juntas, where the testing algorithm must accept any function that is
$\epsilon$-close to some $k$-junta and reject any function that is
$\epsilon'$-far from every $k'$-junta for some $\epsilon'= O(\epsilon)$ and $k'
= O(k)$.
  Our first result is an algorithm that solves this problem with query
complexity polynomial in $k$ and $1/\epsilon$. This result is obtained via a
new polynomial-time approximation algorithm for submodular function
minimization (SFM) under large cardinality constraints, which holds even when
only given an approximate oracle access to the function.
  Our second result considers the case where $k'=k$. We show how to obtain a
smooth tradeoff between the amount of tolerance and the query complexity in
this setting. Specifically, we design an algorithm that given $\rho\in(0,1/2)$
accepts any function that is $\frac{\epsilon\rho}{16}$-close to some $k$-junta
and rejects any function that is $\epsilon$-far from every $k$-junta. The query
complexity of the algorithm is $O\big( \frac{k\log k}{\epsilon\rho(1-\rho)^k}
\big)$.
  Finally, we show how to apply the second result to the problem of tolerant
isomorphism testing between two unknown Boolean functions $f$ and $g$. We give
an algorithm for this problem whose query complexity only depends on the
(unknown) smallest $k$ such that either $f$ or $g$ is close to being a
$k$-junta.
</dc:description>
 <dc:description>Comment: Polished the writing, corrected typos, and fixed an issue in the
  proof of Theorem 1.2</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03946</identifier>
 <datestamp>2016-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VisiSploit: An Optical Covert-Channel to Leak Data through an Air-Gap</dc:title>
 <dc:creator>Guri, Mordechai</dc:creator>
 <dc:creator>Hasson, Ofer</dc:creator>
 <dc:creator>Kedma, Gabi</dc:creator>
 <dc:creator>Elovici, Yuval</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In recent years, various out-of-band covert channels have been proposed that
demonstrate the feasibility of leaking data out of computers without the need
for network connectivity. The methods proposed have been based on different
type of electromagnetic, acoustic, and thermal emissions. However, optical
channels have largely been considered less covert: because they are visible to
the human eye and hence can be detected, they have received less attention from
researchers. In this paper, we introduce VisiSploit, a new type of optical
covert channel which, unlike other optical methods, is also stealthy. Our
method exploits the limitations of human visual perception in order to
unobtrusively leak data through a standard computer LCD display. Our
experiments show that very low contrast or fast flickering images which are
invisible to human subjects, can be recovered from photos taken by a camera.
Consequentially, we show that malicious code on a compromised computer can
obtain sensitive data (e.g., images, encryption keys, passwords), and project
it onto a computer LCD screen, invisible and unbeknownst to users, allowing an
attacker to reconstruct the data using a photo taken by a nearby (possibly
hidden) camera. In order to demonstrate the feasibility of this type of attack
and evaluate the channel's stealth, we conducted a battery of tests with 40
human subjects. We also examined the channel's boundaries under various
parameters, with different types of encoded objects, at several distances, and
using several kinds of cameras. Our results show that binary data can be leaked
via our covert channel. Further research and discussion may widen the scope of
this field beyond its current boundaries, yielding novel attack paradigms that
exploit the subtle mechanisms of human visual perception.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03948</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making recommendations bandwidth aware</dc:title>
 <dc:creator>Song, Linqi</dc:creator>
 <dc:creator>Fragouli, Christina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper asks how much we can gain in terms of bandwidth and user
satisfaction, if recommender systems became bandwidth aware and took into
account not only the user preferences, but also the fact that they may need to
serve these users under bandwidth constraints, as is the case over wireless
networks. We formulate this as a new problem in the context of index coding: we
relax the index coding requirements to capture scenarios where each client has
preferences associated with messages. The client is satisfied to receive any
message she does not already have, with a satisfaction proportional to her
preference for that message. We consistently find, over a number of scenarios
we sample, that although the optimization problems are in general NP-hard,
significant bandwidth savings are possible even when restricted to polynomial
time algorithms.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03949</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large Scale SfM with the Distributed Camera Model</dc:title>
 <dc:creator>Sweeney, Chris</dc:creator>
 <dc:creator>Fragoso, Victor</dc:creator>
 <dc:creator>Hollerer, Tobias</dc:creator>
 <dc:creator>Turk, Matthew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce the distributed camera model, a novel model for
Structure-from-Motion (SfM). This model describes image observations in terms
of light rays with ray origins and directions rather than pixels. As such, the
proposed model is capable of describing a single camera or multiple cameras
simultaneously as the collection of all light rays observed. We show how the
distributed camera model is a generalization of the standard camera model and
describe a general formulation and solution to the absolute camera pose problem
that works for standard or distributed cameras. The proposed method computes a
solution that is up to 8 times more efficient and robust to rotation
singularities in comparison with gDLS. Finally, this method is used in an novel
large-scale incremental SfM pipeline where distributed cameras are accurately
and robustly merged together. This pipeline is a direct generalization of
traditional incremental SfM; however, instead of incrementally adding one
camera at a time to grow the reconstruction the reconstruction is grown by
adding a distributed camera. Our pipeline produces highly accurate
reconstructions efficiently by avoiding the need for many bundle adjustment
iterations and is capable of computing a 3D model of Rome from over 15,000
images in just 22 minutes.
</dc:description>
 <dc:description>Comment: Published at 2016 3DV Conference</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03959</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gr\&quot;unbaum coloring and its generalization to arbitrary dimension</dc:title>
 <dc:creator>Lawrencenko, S.</dc:creator>
 <dc:creator>Vyalyi, M. N.</dc:creator>
 <dc:creator>Zgonnik, L. V.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Geometric Topology</dc:subject>
 <dc:subject>Mathematics - History and Overview</dc:subject>
 <dc:subject>05C15 (Primary) 05B05, 52C20, 52C22, 05B07, 57M20, 57M15 (Secondary)</dc:subject>
 <dc:description>  This paper is a collection of thoughts and observations, being partly a
review and partly a report of current research, on recent work in various
aspects of Gr\&quot;unbaum colorings, their existence and usage. In particular, one
of the most striking significances of Gr\&quot;unbaum's Conjecture in the
2-dimensional case is its equivalence to the 4-Color Theorem. The notion of
Gr\&quot;unbaum coloring is extended from the 2-dimensional case to the case of
arbitrary finite hyper-dimensions.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03959</dc:identifier>
 <dc:identifier>Australasian Journal of Combinatorics. 2017. Volume 67(2). Pages
  119-130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03961</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deleting and Testing Forbidden Patterns in Multi-Dimensional Arrays</dc:title>
 <dc:creator>Ben-Eliezer, Omri</dc:creator>
 <dc:creator>Korman, Simon</dc:creator>
 <dc:creator>Reichman, Daniel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Understanding the local behaviour of structured multi-dimensional data is a
fundamental problem in various areas of computer science. As the amount of data
is often huge, it is desirable to obtain sublinear time algorithms, and
specifically property testers, to understand local properties of the data.
  We focus on the natural local problem of testing pattern freeness: given a
large $d$-dimensional array $A$ and a fixed $d$-dimensional pattern $P$ over a
finite alphabet, we say that $A$ is $P$-free if it does not contain a copy of
the forbidden pattern $P$ as a consecutive subarray. The distance of $A$ to
$P$-freeness is the fraction of entries of $A$ that need to be modified to make
it $P$-free. For any $\epsilon \in [0,1]$ and any large enough pattern $P$ over
any alphabet, other than a very small set of exceptional patterns, we design a
tolerant tester that distinguishes between the case that the distance is at
least $\epsilon$ and the case that it is at most $a_d \epsilon$, with query
complexity and running time $c_d \epsilon^{-1}$, where $a_d &lt; 1$ and $c_d$
depend only on $d$.
  To analyze the testers we establish several combinatorial results, including
the following $d$-dimensional modification lemma, which might be of independent
interest: for any large enough pattern $P$ over any alphabet (excluding a small
set of exceptional patterns for the binary case), and any array $A$ containing
a copy of $P$, one can delete this copy by modifying one of its locations
without creating new $P$-copies in $A$.
  Our results address an open question of Fischer and Newman, who asked whether
there exist efficient testers for properties related to tight substructures in
multi-dimensional structured data. They serve as a first step towards a general
understanding of local properties of multi-dimensional arrays, as any such
property can be characterized by a fixed family of forbidden patterns.
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:date>2017-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03967</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concatenated image completion via tensor augmentation and completion</dc:title>
 <dc:creator>Bengua, Johann A.</dc:creator>
 <dc:creator>Tuan, Hoang D.</dc:creator>
 <dc:creator>Phien, Ho N.</dc:creator>
 <dc:creator>Do, Minh N.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper proposes a novel framework called concatenated image completion
via tensor augmentation and completion (ICTAC), which recovers missing entries
of color images with high accuracy. Typical images are second- or third-order
tensors (2D/3D) depending if they are grayscale or color, hence tensor
completion algorithms are ideal for their recovery. The proposed framework
performs image completion by concatenating copies of a single image that has
missing entries into a third-order tensor, applying a dimensionality
augmentation technique to the tensor, utilizing a tensor completion algorithm
for recovering its missing entries, and finally extracting the recovered image
from the tensor. The solution relies on two key components that have been
recently proposed to take advantage of the tensor train (TT) rank: A tensor
augmentation tool called ket augmentation (KA) that represents a low-order
tensor by a higher-order tensor, and the algorithm tensor completion by
parallel matrix factorization via tensor train (TMac-TT), which has been
demonstrated to outperform state-of-the-art tensor completion algorithms.
Simulation results for color image recovery show the clear advantage of our
framework against current state-of-the-art tensor completion algorithms.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, submitted to ICSPCS 2016</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03971</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>8th European Conference on Python in Science (EuroSciPy 2015)</dc:title>
 <dc:creator>Varoquaux, Nelle</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  The 8th edition of the European Conference on Python in Science, EuroSciPy
was held for the second time in the beautiful city of Cambridge, UK from
August, 26th to 29th, 2014. More than 200 participants, both from academia and
industry, attended the conference.
  As usual, the conference kicked off with two days of tutorials, divided into
an introductory and an advanced track. The introductory track, presented by
Joris Vankerschaver, Valerio Maggio Joris Van den Bossche, Stijn Van Hoey and
Nicolas Rougier, gave a quick but thorough overview of the SciPy stack, while
the experience track focused on different advanced topics. This second track
began with an introduction to Bokeh, by Bryan Van den Ven, followed by an image
processing tutorial with scikit-image by Emmanuelle Gouillart and Juan
Nunez-Iglesias. The afternoon continued with two tutorials on data analysis:
the first, intitulated &quot;How 'good' is your model, and how can you make it
better?&quot; (by Chih-Chun Chen, Dimitry Foures, Elena Chatzimichali, Giuseppe
Vettigli) focused on the challenges face while attempting model selections, and
the first day concluded with a statistics in python tutorial by Gael Varoquaux.
During the second day, the attendees tackled an in depth 4 hour tutorial on
Cython, presented by Stefan Behnel, and a crash course on &quot;Evidence-Based
Teaching: What We Know and How to Use It&quot;, by Greg Wilson.
</dc:description>
 <dc:description>Comment: euroscipy-proceedings2015-01</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03979</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Planning For Rescue Operations</dc:title>
 <dc:creator>Khaffaf, Mona</dc:creator>
 <dc:creator>Khaffaf, Arshia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  After an earthquake, disaster sites pose a multitude of health and safety
concerns. A rescue operation of people trapped in the ruins after an earthquake
disaster requires a series of intelligent behavior, including planning. For a
successful rescue operation, given a limited number of available actions and
regulations, the role of planning in rescue operations is crucial. Fortunately,
recent developments in automated planning by artificial intelligence community
can help different organization in this crucial task. Due to the number of
rules and regulations, we believe that a rule based system for planning can be
helpful for this specific planning problem. In this research work, we use logic
rules to represent rescue and related regular regulations, together with a
logic based planner to solve this complicated problem. Although this research
is still in the prototyping and modeling stage, it clearly shows that rule
based languages can be a good infrastructure for this computational task. The
results of this research can be used by different organizations, such as
Iranian Red Crescent Society and International Institute of Seismology and
Earthquake Engineering (IISEE).
</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03990</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Algorithms for Segmented Regression</dc:title>
 <dc:creator>Acharya, Jayadev</dc:creator>
 <dc:creator>Diakonikolas, Ilias</dc:creator>
 <dc:creator>Li, Jerry</dc:creator>
 <dc:creator>Schmidt, Ludwig</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We study the fixed design segmented regression problem: Given noisy samples
from a piecewise linear function $f$, we want to recover $f$ up to a desired
accuracy in mean-squared error.
  Previous rigorous approaches for this problem rely on dynamic programming
(DP) and, while sample efficient, have running time quadratic in the sample
size. As our main contribution, we provide new sample near-linear time
algorithms for the problem that -- while not being minimax optimal -- achieve a
significantly better sample-time tradeoff on large datasets compared to the DP
approach. Our experimental evaluation shows that, compared with the DP
approach, our algorithms provide a convergence rate that is only off by a
factor of $2$ to $4$, while achieving speedups of three orders of magnitude.
</dc:description>
 <dc:description>Comment: 27 pages, appeared in ICML 2016</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.03991</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vision-based Traffic Flow Prediction using Dynamic Texture Model and
  Gaussian Process</dc:title>
 <dc:creator>Liu, Bin</dc:creator>
 <dc:creator>Ji, Hao</dc:creator>
 <dc:creator>Dai, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we describe work in progress towards a real-time vision-based
traffic flow prediction (TFP) system. The proposed method consists of three
elemental operators, that are dynamic texture model based motion segmentation,
feature extraction and Gaussian process (GP) regression. The objective of
motion segmentation is to recognize the target regions covering the moving
vehicles in the sequence of visual processes. The feature extraction operator
aims to extract useful features from the target regions. The extracted features
are then mapped to the number of vehicles through the operator of GP
regression. A training stage using historical visual data is required for
determining the parameter values of the GP. Using a low-resolution visual data
set, we performed preliminary evaluations on the performance of the proposed
method. The results show that our method beats a benchmark solution based on
Gaussian mixture model, and has the potential to be developed into qualified
and practical solutions to real-time TFP.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, conference</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2016-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.03991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04002</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Directed Hamiltonicity and Out-Branchings via Generalized Laplacians</dc:title>
 <dc:creator>Bj&#xf6;rklund, Andreas</dc:creator>
 <dc:creator>Kaski, Petteri</dc:creator>
 <dc:creator>Koutis, Ioannis</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We are motivated by a tantalizing open question in exact algorithms: can we
detect whether an $n$-vertex directed graph $G$ has a Hamiltonian cycle in time
significantly less than $2^n$? We present new randomized algorithms that
improve upon several previous works:
  1. We show that for any constant $0&lt;\lambda&lt;1$ and prime $p$ we can count the
Hamiltonian cycles modulo $p^{\lfloor (1-\lambda)\frac{n}{3p}\rfloor}$ in
expected time less than $c^n$ for a constant $c&lt;2$ that depends only on $p$ and
$\lambda$. Such an algorithm was previously known only for the case of counting
modulo two [Bj\&quot;orklund and Husfeldt, FOCS 2013].
  2. We show that we can detect a Hamiltonian cycle in $O^*(3^{n-\alpha(G)})$
time and polynomial space, where $\alpha(G)$ is the size of the maximum
independent set in $G$. In particular, this yields an $O^*(3^{n/2})$ time
algorithm for bipartite directed graphs, which is faster than the
exponential-space algorithm in [Cygan et al., STOC 2013].
  Our algorithms are based on the algebraic combinatorics of &quot;incidence
assignments&quot; that we can capture through evaluation of determinants of
Laplacian-like matrices, inspired by the Matrix--Tree Theorem for directed
graphs. In addition to the novel algorithms for directed Hamiltonicity, we use
the Matrix--Tree Theorem to derive simple algebraic algorithms for detecting
out-branchings. Specifically, we give an $O^*(2^k)$-time randomized algorithm
for detecting out-branchings with at least $k$ internal vertices, improving
upon the algorithms of [Zehavi, ESA 2015] and [Bj\&quot;orklund et al., ICALP 2015].
We also present an algebraic algorithm for the directed $k$-Leaf problem, based
on a non-standard monomial detection problem.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04004</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Filter Design for Generalized Frequency-Division Multiplexing</dc:title>
 <dc:creator>Han, Seungyul</dc:creator>
 <dc:creator>Sung, Youngchul</dc:creator>
 <dc:creator>Lee, Yong H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:description>  In this paper, optimal filter design for generalized frequency-division
multiplexing (GFDM) is considered under two design criteria: rate maximization
and out-of-band (OOB) emission minimization. First, the problem of GFDM filter
optimization for rate maximization is formulated by expressing the transmission
rate of GFDM as a function of GFDM filter coefficients. It is shown that
Dirichlet filters are rate-optimal in additive white Gaussian noise (AWGN)
channels with no carrier frequency offset (CFO) under linear zero-forcing (ZF)
or minimum mean-square error (MMSE) receivers, but in general channels
perturbed by CFO a properly designed nontrivial GFDM filter can yield better
performance than Dirichlet filters by adjusting the subcarrier waveform to cope
with the channel-induced CFO. Next, the problem of GFDM filter design for OOB
emission minimization is formulated by expressing the power spectral density
(PSD) of the GFDM transmit signal as a function of GFDM filter coefficients,
and it is shown that the OOB emission can be reduced significantly by designing
the GFDM filter properly. Finally, joint design of GFDM filter and window for
the two design criteria is considered.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, submitted to IEEE Transactions on Signal
  Processing</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04004</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2641382</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04005</identifier>
 <datestamp>2017-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing minimum-length coordinated motions for two discs</dc:title>
 <dc:creator>Kirkpatrick, David</dc:creator>
 <dc:creator>Liu, Paul</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  We study the problem of determining optimal coordinated motions for two disc
robots in an otherwise obstacle-free plane. Using the total path length traced
by the two disc centres as a measure of distance, we give an exact
characterization of a shortest collision-avoiding motion for all initial and
final configurations of the robots. The individual paths are composed of at
most six (straight or circular-arc) segments, and their total length can be
expressed as a simple integral with a closed form solution depending only on
the initial and final configuration of the robots. Furthermore, the paths can
be parametrized in such a way that (i) only one robot is moving at any given
time (decoupled motion), or (ii) the angle between the two robots' centres
changes monotonically.
</dc:description>
 <dc:description>Comment: long-form of conference submission, 26 pages, 18 figures</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2017-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04005</dc:identifier>
 <dc:identifier>Proceedings of the 28th Canadian Conference on Computational
  Geometry (2016). p. 252-259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04025</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experiments with Synchronizing Automata</dc:title>
 <dc:creator>Kisielewicz, Andrzej</dc:creator>
 <dc:creator>Kowalski, Jakub</dc:creator>
 <dc:creator>Szyku&#x142;a, Marek</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We have improved an algorithm generating synchronizing automata with a large
length of the shortest reset words. This has been done by refining some known
results concerning bounds on the reset length. Our improvements make possible
to consider a number of conjectures and open questions concerning synchronizing
automata, checking them for automata with a small number of states and
discussing the results. In particular, we have verified the \v{C}ern\'y
conjecture for all binary automata with at most 12 states, and all ternary
automata with at most 8 states.
</dc:description>
 <dc:description>Comment: CIAA 2016. The final publication available at
  http://link.springer.com/chapter/10.1007/978-3-319-40946-7_15</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04025</dc:identifier>
 <dc:identifier>In Implementation and Application of Automata (CIAA 2016), volume
  9705 of LNCS, pages 176--188, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-40946-7_15</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04031</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State complexity of multiple catenation</dc:title>
 <dc:creator>Caron, Pascal</dc:creator>
 <dc:creator>Luque, Jean-Gabriel</dc:creator>
 <dc:creator>Patrou, Bruno</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We improve some results relative to the state complexity of the multiple
catenation described by Gao and Yu. In particular we nearly divide by 2 the
size of the alphabet needed for witnesses. We also give some refinements to the
algebraic expression of the state complexity, which is especially complex with
this operation. We obtain these results by using peculiar DFAs defined by
Brzozowski.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04032</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Gray World-Based Color Normalization of Thin Blood Film Images</dc:title>
 <dc:creator>Tek, F. Boray</dc:creator>
 <dc:creator>Dempster, Andrew G.</dc:creator>
 <dc:creator>Kale, &#x130;zzet</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68U10</dc:subject>
 <dc:description>  This paper presents an effective color normalization method for thin blood
film images of peripheral blood specimens. Thin blood film images can easily be
separated to foreground (cell) and background (plasma) parts. The color of the
plasma region is used to estimate and reduce the differences arising from
different illumination conditions. A second stage normalization based on the
database-gray world algorithm transforms the color of the foreground objects to
match a reference color character. The quantitative experiments demonstrate the
effectiveness of the method and its advantages against two other general
purpose color correction methods: simple gray world and Retinex.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, conference unpublished</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04033</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings 3rd Workshop on Horn Clauses for Verification and Synthesis</dc:title>
 <dc:creator>Gallagher, John P.</dc:creator>
 <dc:creator>R&#xfc;mmer, Philipp</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This volume contains the proceedings of HCVS 2016, the Third Workshop on Horn
Clauses for Verification and Synthesis which was held on April 3, 2016 in
Eindhoven, The Netherlands as a satellite event of the European Joint
Conferences on Theory and Practice of Software (ETAPS 2016). Many program
verification and synthesis problems of interest can be modeled directly using
Horn clauses and many recent advances in the CLP and CAV communities have
centered around efficiently solving problems presented as Horn clauses. The
Third Workshop on Horn Clauses for Verification and Synthesis was organised
with the aim to bring together researchers working in the two communities of
Constraint/Logic Programming and Program Verification on the topic of Horn
clause based analysis, verification and synthesis. Horn clauses for
verification and synthesis have been advocated by these two communities in
different times and from different perspectives, and this workshop is organized
to stimulate interaction and a fruitful exchange and integration of
experiences.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04033</dc:identifier>
 <dc:identifier>EPTCS 219, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04063</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Update Strength in EDAs and ACO: How to Avoid Genetic Drift</dc:title>
 <dc:creator>Sudholt, Dirk</dc:creator>
 <dc:creator>Witt, Carsten</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We provide a rigorous runtime analysis concerning the update strength, a
vital parameter in probabilistic model-building GAs such as the step size $1/K$
in the compact Genetic Algorithm (cGA) and the evaporation factor $\rho$ in
ACO. While a large update strength is desirable for exploitation, there is a
general trade-off: too strong updates can lead to genetic drift and poor
performance. We demonstrate this trade-off for the cGA and a simple MMAS ACO
algorithm on the OneMax function. More precisely, we obtain lower bounds on the
expected runtime of $\Omega(K\sqrt{n} + n \log n)$ and $\Omega(\sqrt{n}/\rho +
n \log n)$, respectively, showing that the update strength should be limited to
$1/K, \rho = O(1/(\sqrt{n} \log n))$. In fact, choosing $1/K, \rho \sim
1/(\sqrt{n}\log n)$ both algorithms efficiently optimize OneMax in expected
time $O(n \log n)$. Our analyses provide new insights into the stochastic
behavior of probabilistic model-building GAs and propose new guidelines for
setting the update strength in global optimization.
</dc:description>
 <dc:description>Comment: 32 pages. An extended abstract of this work will appear in the
  proceedings of the Genetic and Evolutionary Computation Conference (GECCO
  2016). This revision fixes the abstract in the metadata</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2016-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04072</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orthogonal Design of Cyclic Block Filtered Multitone Modulation</dc:title>
 <dc:creator>Girotto, Mauro</dc:creator>
 <dc:creator>Tonello, Andrea M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The orthogonal design of a Cyclic Block Filtered Multititone Modulation
(CB-FMT) system is addressed. CB-FMT is a filter bank modulation scheme that
uses frequency confined prototype pulses, similarly to Filtered Multitone
Modulation (FMT). Differently from FMT, where the linear convolution is used,
the cyclic convolution is exploited in CB-FMT. This allows to efficiently
implement the system via a concatenation of discrete Fourier transforms (DFT).
The necessary and sufficient orthogonality conditions are derived in time
domain and frequency domain. Then, these conditions are expressed in matrix
form and the prototype pulse coefficients are parameterized with
hyper-spherical coordinates. The effect of a linear time-variant transmission
medium is discussed. In such a scenario, the optimal filter bank orthogonal
design is considered with the objective of maximizing either the
in-band-to-out-band sub-channel energy ratio or the achievable rate. Numerical
results and comparisons show the performance improvements attainable with
several designed optimal pulses also w.r.t. the use of the baseline
root-raised-cosine pulse.
</dc:description>
 <dc:description>Comment: A version of this manuscript has been submitted to the IEEE
  Transactions on Communications for possible publication</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04077</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing a High Performance Parallel Personal Cluster</dc:title>
 <dc:creator>Kapanova, K. G.</dc:creator>
 <dc:creator>Sellier, J. M.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Today, many scientific and engineering areas require high performance
computing to perform computationally intensive experiments. For example, many
advances in transport phenomena, thermodynamics, material properties,
computational chemistry and physics are possible only because of the
availability of such large scale computing infrastructures. Yet many challenges
are still open. The cost of energy consumption, cooling, competition for
resources have been some of the reasons why the scientific and engineering
communities are turning their interests to the possibility of implementing
energy-efficient servers utilizing low-power CPUs for computing-intensive
tasks. In this paper we introduce a novel approach, which was recently
presented at Linux Conference Europe 2015, based on the Beowulf concept and
utilizing single board computers (SBC). We present a low-energy consumption
architecture capable to tackle heavily demanding scientific computational
problems. Additionally, our goal is to provide a low cost personal solution for
scientists and engineers. In order to evaluate the performance of the proposed
architecture we ran several standard benchmarking tests. Furthermore, we assess
the reliability of the machine in real life situations by performing two
benchmark tools involving practical TCAD for physicist and engineers in the
semiconductor industry.
</dc:description>
 <dc:description>Comment: 12 pages, 12 figures</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04083</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Configurations of lines in space and combinatorial rigidity</dc:title>
 <dc:creator>Raz, Orit E.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let $L$ be a sequence $(\ell_1,\ell_2,\ldots,\ell_n)$ of $n$ lines in
$\mathbb{C}^3$. We define the {\it intersection graph} $G_L=([n],E)$ of $L$,
where $[n]:=\{1,\ldots, n\}$, and with $\{i,j\}\in E$ if and only if $i\neq j$
and the corresponding lines $\ell_i$ and $\ell_j$ intersect, or are parallel
(or coincide). For a graph $G=([n],E)$, we say that a sequence $L$ is a {\it
realization} of $G$ if $G\subset G_L$. One of the main results of this paper is
to provide a combinatorial characterization of graphs $G=([n],E)$ that have the
following property: For every {\it generic} realization $L$ of $G$ that
consists of $n$ pairwise distinct lines, we have $G_L=K_n$, in which case the
lines of $L$ are either all concurrent or all coplanar.
  The general statements that we obtain about lines, apart from their
independent interest, turns out to be closely related to the notion of graph
rigidity. The connection is established due to the so-called Elekes--Sharir
framework, which allows us to transform the problem into an incidence problem
involving lines in three dimensions. By exploiting the geometry of contacts
between lines in 3D, we can obtain alternative, simpler, and more precise
characterizations of the rigidity of graphs.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04090</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kripke Semantics for Fuzzy Logics</dc:title>
 <dc:creator>Safari, Parvin</dc:creator>
 <dc:creator>Salehi, Saeed</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B52, 03F50, 03F55, 03A20</dc:subject>
 <dc:description>  Kripke frames (and models) provide a suitable semantics for sub-classical
logics, for example Intuitionistic Logic (of Brouwer and Heyting) axiomatizes
the reflexive and transitive Kripke frames (with persistent satisfaction
relations), and the Basic Logic (of Visser) axiomatizes transitive Kripke
frames (with persistent satisfaction relations). Here, we investigate whether
Kripke frames/models could provide a semantics for fuzzy logics. For each axiom
of the Basic Fuzzy Logic, necessary and sufficient conditions are sought for
Kripke frames/models which satisfy them. It turns out that the only fuzzy
logics (logics containing the Basic Fuzzy Logic) which are sound and complete
with respect to a class of Kripke frames/models are the extensions of the
G\&quot;odel Logic (or the super-intuitionistic logic of Dummett), indeed this logic
is sound and strongly complete with respect to reflexive, transitive and
connected (linear) Kripke frames (with persistent satisfaction relations). This
provides a semantic characterization for the G\&quot;odel Logic among
(propositional) fuzzy logics.
</dc:description>
 <dc:description>Comment: Soft Computing (2016)</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2016-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04090</dc:identifier>
 <dc:identifier>doi:10.1007/s00500-016-2387-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04091</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Sampling in Julia</dc:title>
 <dc:creator>Jacobsen, Robert Dahl</dc:creator>
 <dc:creator>Nielsen, Morten</dc:creator>
 <dc:creator>Rasmussen, Morten Grud</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Generalized sampling is a numerically stable framework for obtaining
reconstructions of signals in different bases and frames from their samples. In
this paper, we will introduce a carefully documented toolbox for performing
generalized sampling in Julia. Julia is a new language for technical computing
with focus on performance, which is ideally suited to handle the large size
problems often encountered in generalized sampling. The toolbox provides
specialized solutions for the setup of Fourier bases and wavelets. The
performance of the toolbox is compared to existing implementations of
generalized sampling in MATLAB.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04104</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language-integrated provenance</dc:title>
 <dc:creator>Fehrenbach, Stefan</dc:creator>
 <dc:creator>Cheney, James</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Provenance, or information about the origin or derivation of data, is
important for assessing the trustworthiness of data and identifying and
correcting mistakes. Most prior implementations of data provenance have
involved heavyweight modifications to database systems and little attention has
been paid to how the provenance data can be used outside such a system. We
present extensions to the Links programming language that build on its support
for language-integrated query to support provenance queries by rewriting and
normalizing monadic comprehensions and extending the type system to distinguish
provenance metadata from normal data. The main contribution of this article is
to show that the two most common forms of provenance can be implemented
efficiently and used safely as a programming language feature with no changes
to the database system.
</dc:description>
 <dc:description>Comment: Accepted to Science of Computer Programming special issue on PPDP
  2016</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04109</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General Sub-packetized Access-Optimal Regenerating Codes</dc:title>
 <dc:creator>Kralevska, Katina</dc:creator>
 <dc:creator>Gligoroski, Danilo</dc:creator>
 <dc:creator>&#xd8;verby, Harald</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents a novel construction of $(n,k,d=n-1)$ access-optimal
regenerating codes for an arbitrary sub-packetization level $\alpha$ for exact
repair of any systematic node. We refer to these codes as general
sub-packetized because we provide an algorithm for constructing codes for any
$\alpha$ less than or equal to $r^{\lceil \frac{k}{r} \rceil}$ where
$\frac{k}{r}$ is not necessarily an integer. This leads to a flexible
construction of codes for different code rates compared to existing approaches.
We derive the lower and the upper bound of the repair bandwidth. The repair
bandwidth depends on the code parameters and $\alpha$. The repair process of a
failed systematic node is linear and highly parallelized, which means that a
set of $\lceil \frac{\alpha}{r} \rceil$ symbols is independently repaired first
and used along with the accessed data from other nodes to recover the remaining
symbols.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04109</dc:identifier>
 <dc:identifier>IEEE COMMUNICATIONS LETTERS, VOL. 20, NO. 7, JULY 2016</dc:identifier>
 <dc:identifier>doi:10.1109/LCOMM.2016.2561287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04110</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Recurrent Neural Network for Learning Expressive Ontologies</dc:title>
 <dc:creator>Petrucci, Giulio</dc:creator>
 <dc:creator>Ghidini, Chiara</dc:creator>
 <dc:creator>Rospocher, Marco</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Recently, Neural Networks have been proven extremely effective in many
natural language processing tasks such as sentiment analysis, question
answering, or machine translation. Aiming to exploit such advantages in the
Ontology Learning process, in this technical report we present a detailed
description of a Recurrent Neural Network based system to be used to pursue
such goal.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04125</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Citation count distributions for large monodisciplinary journals</dc:title>
 <dc:creator>Thelwall, Mike</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Many different citation-based indicators are used by researchers and research
evaluators to help evaluate the impact of scholarly outputs. Although the
appropriateness of individual citation indicators depends in part on the
statistical properties of citation counts, there is no universally agreed
best-fitting statistical distribution against which to check them. The two
current leading candidates are the discretised lognormal and the hooked or
shifted power law. These have been mainly tested on sets of articles from a
single field and year but these collections can include multiple specialisms
that might dilute their properties. This article fits statistical distributions
to 50 large subject-specific journals in the belief that individual journals
can be purer than subject categories and may therefore give clearer findings.
The results show that in most cases the discretised lognormal fits
significantly better than the hooked power law, reversing previous findings for
entire subcategories. This suggests that the discretised lognormal is the more
appropriate distribution for modelling pure citation data. Thus future
analytical investigations of the properties of citation indicators can use the
lognormal distribution to analyse their basic properties. This article also
includes improved software for fitting the hooked power law.
</dc:description>
 <dc:description>Comment: Thelwall, M. (in press). Citation count distributions for large
  monodisciplinary journals. Journal of Informetrics. Software for extra
  accurate hooked power law fitting, 100 extra graphs, and data are here:
  https://figshare.com/articles/Citation_count_distributions_for_large_monodisciplinary_journals/3479129</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04125</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2016.07.006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04128</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Counterexamples Concerning the Scott Topology on a Partial Order</dc:title>
 <dc:creator>Hertling, Peter</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - General Topology</dc:subject>
 <dc:subject>06F30</dc:subject>
 <dc:description>  We construct a complete lattice $Z$ such that the binary supremum function
$\sup:Z\times Z\to Z$ is discontinuous with respect to the product topology on
$Z\times Z$ of the Scott topologies on each copy of $Z$. In addition, we show
that bounded completeness of a complete lattice $Z$ is in general not inherited
by the dcpo $C(X,Z)$ of continuous functions from $X$ to $Z$ where $X$ may be
any topological space and where on $Z$ the Scott topology is considered.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04137</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balanced Locally Repairable Codes</dc:title>
 <dc:creator>Kralevska, Katina</dc:creator>
 <dc:creator>Gligoroski, Danilo</dc:creator>
 <dc:creator>&#xd8;verby, Harald</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce a family of balanced locally repairable codes (BLRCs) $[n, k,
d]$ for arbitrary values of $n$, $k$ and $d$. Similar to other locally
repairable codes (LRCs), the presented codes are suitable for applications that
require a low repair locality. The novelty that we introduce in our
construction is that we relax the strict requirement the repair locality to be
a fixed small number $l$, and we allow the repair locality to be either $l$ or
$l+1$. This gives us the flexibility to construct BLRCs for arbitrary values of
$n$ and $k$ which partially solves the open problem of finding a general
construction of LRCs. Additionally, the relaxed locality criteria gives us an
opportunity to search for BLRCs that have a low repair locality even when
double failures occur. We use metrics such as a storage overhead, an average
repair bandwidth, a Mean Time To Data Loss (MTTDL) and an update complexity to
compare the performance of BLRCs with existing LRCs.
</dc:description>
 <dc:description>Comment: Accepted for presentation at International Symposium on Turbo Codes
  and Iterative Information Processing 2016</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04138</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Persistent Storage and Retrieval of Domain Models using Graph
  Database Technology</dc:title>
 <dc:creator>Hochgeschwender, Nico</dc:creator>
 <dc:creator>Voos, Holger</dc:creator>
 <dc:creator>Kraetzschmar, Gerhard K.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We employ graph database technology to persistently store and retrieve robot
domain models.
</dc:description>
 <dc:description>Comment: Presented at DSLRob 2015 (arXiv:1601.00877)</dc:description>
 <dc:date>2016-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04143</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling Rate Distortion</dc:title>
 <dc:creator>Boda, Vinay Praneeth</dc:creator>
 <dc:creator>Narayan, Prakash</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Consider a discrete memoryless multiple source with $m$ components of which
$k \leq m$ possibly different sources are sampled at each time instant and
jointly compressed in order to reconstruct all the $m$ sources under a given
distortion criterion. A new notion of sampling rate distortion function is
introduced, and is characterized first for the case of fixed-set sampling.
Next, for independent random sampling performed without knowledge of the source
outputs, it is shown that the sampling rate distortion function is the same
regardless of whether or not the decoder is informed of the sequence of sampled
sets. Furthermore, memoryless random sampling is considered with the sampler
depending on the source outputs and with an informed decoder. It is shown that
deterministic sampling, characterized by a conditional point-mass, is optimal
and suffices to achieve the sampling rate distortion function. For memoryless
random sampling with an uninformed decoder, an upper bound for the sampling
rate distortion function is seen to possess a similar property of conditional
point-mass optimality. It is shown by example that memoryless sampling with an
informed decoder can outperform strictly any independent random sampler, and
that memoryless sampling can do strictly better with an informed decoder than
without.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04147</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-modal dictionary learning for image separation with application in
  art investigation</dc:title>
 <dc:creator>Deligiannis, Nikos</dc:creator>
 <dc:creator>Mota, Joao F. C.</dc:creator>
 <dc:creator>Cornelis, Bruno</dc:creator>
 <dc:creator>Rodrigues, Miguel R. D.</dc:creator>
 <dc:creator>Daubechies, Ingrid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In support of art investigation, we propose a new source separation method
that unmixes a single X-ray scan acquired from double-sided paintings. In this
problem, the X-ray signals to be separated have similar morphological
characteristics, which brings previous source separation methods to their
limits. Our solution is to use photographs taken from the front and back-side
of the panel to drive the separation process. The crux of our approach relies
on the coupling of the two imaging modalities (photographs and X-rays) using a
novel coupled dictionary learning framework able to capture both common and
disparate features across the modalities using parsimonious representations;
the common component models features shared by the multi-modal images, whereas
the innovation component captures modality-specific information. As such, our
model enables the formulation of appropriately regularized convex optimization
procedures that lead to the accurate separation of the X-rays. Our dictionary
learning framework can be tailored both to a single- and a multi-scale
framework, with the latter leading to a significant performance improvement.
Moreover, to improve further on the visual quality of the separated images, we
propose to train coupled dictionaries that ignore certain parts of the painting
corresponding to craquelure. Experimentation on synthetic and real data - taken
from digital acquisition of the Ghent Altarpiece (1432) - confirms the
superiority of our method against the state-of-the-art morphological component
analysis technique that uses either fixed or trained dictionaries to perform
image separation.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Images Processing</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04147</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2623484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04149</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Best-Response Dynamics in Combinatorial Auctions with Item Bidding</dc:title>
 <dc:creator>D&#xfc;tting, Paul</dc:creator>
 <dc:creator>Kesselheim, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In a combinatorial auction with item bidding, agents participate in multiple
single-item second-price auctions at once. As some items might be substitutes,
agents need to strategize in order to maximize their utilities. A number of
results indicate that high welfare can be achieved this way, giving bounds on
the welfare at equilibrium. Recently, however, criticism has been raised that
equilibria are hard to compute and therefore unlikely to be attained.
  In this paper, we take a different perspective. We study simple best-response
dynamics. That is, agents are activated one after the other and each activated
agent updates his strategy myopically to a best response against the other
agents' current strategies. Often these dynamics may take exponentially long
before they converge or they may not converge at all. However, as we show,
convergence is not even necessary for good welfare guarantees. Given that
agents' bid updates are aggressive enough but not too aggressive, the game will
remain in states of good welfare after each agent has updated his bid at least
once.
  In more detail, we show that if agents have fractionally subadditive
valuations, natural dynamics reach and remain in a state that provides a $1/3$
approximation to the optimal welfare after each agent has updated his bid at
least once. For subadditive valuations, we can guarantee an $\Omega(1/\log m)$
approximation in case of $m$ items that applies after each agent has updated
his bid at least once and at any point after that. The latter bound is
complemented by a negative result, showing that no kind of best-response
dynamics can guarantee more than an $o(\log \log m/\log m)$ fraction of the
optimal social welfare.
</dc:description>
 <dc:description>Comment: Extended abstract in Proceedings of the 28th ACM-SIAM Symposium on
  Discrete Algorithms, SODA 2017, Barcelona, Spain</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04156</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Canonicity for Cubical Type Theory</dc:title>
 <dc:creator>Huber, Simon</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Cubical type theory is an extension of Martin-L\&quot;of type theory recently
proposed by Cohen, Coquand, M\&quot;ortberg and the author which allows for direct
manipulation of $n$-dimensional cubes and where Voevodsky's Univalence Axiom is
provable. In this paper we prove canonicity for cubical type theory: any
natural number in a context build from only name variables is judgmentally
equal to a numeral. To achieve this we formulate a typed and deterministic
operational semantics and employ a computability argument adapted to a
presheaf-like setting.
</dc:description>
 <dc:description>Comment: 34 pages. v2: Added section on propositional truncation; fixed typos.
  To appear in the Journal of Automated Reasoning</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04162</identifier>
 <datestamp>2016-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strong completions of spaces</dc:title>
 <dc:creator>Andradi, Hadrian</dc:creator>
 <dc:creator>Ho, Weng Kin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - General Topology</dc:subject>
 <dc:subject>06B35, 54D35</dc:subject>
 <dc:description>  A non-empty subset of a topological space is irreducible if whenever it is
covered by the union of two closed sets, then already it is covered by one of
them. Irreducible sets occur in proliferation: (1) every singleton set is
irreducible, (2) directed subsets (which of fundamental status in domain
theory) of a poset are exactly its Alexandroff irreducible sets, (3) directed
subsets (with respect to the specialization order) of a $T_0$ space are always
irreducible, and (4) the topological closure of every irreducible set is again
irreducible. In recent years, the usefulness of irreducible sets in domain
theory and non-Hausdorff topology has expanded. Notably, Zhao and Ho (2009)
developed the core of domain theory directly in the context of $T_0$ spaces by
choosing the irreducible sets as the topological substitute for directed sets.
Just as the existence of suprema of directed subsets is featured prominently in
domain theory (and hence the notion of a dcpo -- a poset in which all directed
suprema exist), so too is that of irreducible subsets in the topological domain
theory developed by Zhao and Ho (2009). The topological counterpart of a dcpo
is thus this: A $T_0$ space is said to be strongly complete if the suprema of
all irreducible subsets exist. In this paper, we show that the category,
$\mathbf{scTop^+}$, of strongly complete $T_0$ spaces forms are reflective
subcategory of a certain lluf subcategory, $\mathbf{Top^+}$, of $T_0$ spaces.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2016-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04174</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptable Precomputation for Random Walker Image Segmentation and
  Registration</dc:title>
 <dc:creator>Andrews, Shawn</dc:creator>
 <dc:creator>Hamarneh, Ghassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The random walker (RW) algorithm is used for both image segmentation and
registration, and possesses several useful properties that make it popular in
medical imaging, such as being globally optimizable, allowing user interaction,
and providing uncertainty information. The RW algorithm defines a weighted
graph over an image and uses the graph's Laplacian matrix to regularize its
solutions. This regularization reduces to solving a large system of equations,
which may be excessively time consuming in some applications, such as when
interacting with a human user. Techniques have been developed that precompute
eigenvectors of a Laplacian offline, after image acquisition but before any
analysis, in order speed up the RW algorithm online, when segmentation or
registration is being performed. However, precomputation requires certain
algorithm parameters be fixed offline, limiting their flexibility. In this
paper, we develop techniques to update the precomputed data online when RW
parameters are altered. Specifically, we dynamically determine the number of
eigenvectors needed for a desired accuracy based on user input, and derive
update equations for the eigenvectors when the edge weights or topology of the
image graph are changed. We present results demonstrating that our techniques
make RW with precomputation much more robust to offline settings while only
sacrificing minimal accuracy.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04176</identifier>
 <datestamp>2017-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast, deterministic computation of the Hermite normal form and
  determinant of a polynomial matrix</dc:title>
 <dc:creator>Labahn, George</dc:creator>
 <dc:creator>Neiger, Vincent</dc:creator>
 <dc:creator>Zhou, Wei</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Given a nonsingular $n \times n$ matrix of univariate polynomials over a
field $\mathbb{K}$, we give fast and deterministic algorithms to compute its
determinant and its Hermite normal form. Our algorithms use
$\widetilde{\mathcal{O}}(n^\omega \lceil s \rceil)$ operations in $\mathbb{K}$,
where $s$ is bounded from above by both the average of the degrees of the rows
and that of the columns of the matrix and $\omega$ is the exponent of matrix
multiplication. The soft-$O$ notation indicates that logarithmic factors in the
big-$O$ are omitted while the ceiling function indicates that the cost is
$\widetilde{\mathcal{O}}(n^\omega)$ when $s = o(1)$. Our algorithms are based
on a fast and deterministic triangularization method for computing the diagonal
entries of the Hermite form of a nonsingular matrix.
</dc:description>
 <dc:description>Comment: 34 pages, 3 algorithms</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2017-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04180</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hazelnut: A Bidirectionally Typed Structure Editor Calculus</dc:title>
 <dc:creator>Omar, Cyrus</dc:creator>
 <dc:creator>Voysey, Ian</dc:creator>
 <dc:creator>Hilton, Michael</dc:creator>
 <dc:creator>Aldrich, Jonathan</dc:creator>
 <dc:creator>Hammer, Matthew A.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Structure editors allow programmers to edit the tree structure of a program
directly. This can have cognitive benefits, particularly for novice and
end-user programmers (as evidenced by the popularity of structure editors like
Scratch.) It also simplifies matters for tool designers, because they do not
need to contend with malformed program text.
  This paper defines Hazelnut, a structure editor based on a small
bidirectionally typed lambda calculus extended with holes and a cursor (a la
Huet's zipper.) Hazelnut goes one step beyond syntactic well-formedness: it's
edit actions operate over statically meaningful (i.e. well-typed) terms.
Naively, this prohibition on ill-typed edit states would force the programmer
to construct terms in a rigid &quot;outside-in&quot; manner. To avoid this problem, the
action semantics automatically places terms assigned a type that is
inconsistent with the expected type inside a hole. This safely defers the type
consistency check until the term inside the hole is finished.
  Hazelnut is a foundational type-theoretic account of typed structure editing,
rather than an end-user tool itself. To that end, we describe how Hazelnut's
rich metatheory, which we have mechanized in Agda, guides the definition of an
extension to the calculus. We also discuss various plausible evaluation
strategies for terms with holes, and in so doing reveal connections with
gradual typing and contextual modal type theory (the Curry-Howard
interpretation of contextual modal logic.) Finally, we discuss how Hazelnut's
semantics lends itself to implementation as a functional reactive program. Our
reference implementation is written using js_of_ocaml.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04186</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale Analysis of Chess Games with Chess Engines: A Preliminary
  Report</dc:title>
 <dc:creator>Acher, Mathieu</dc:creator>
 <dc:creator>Esnault, Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The strength of chess engines together with the availability of numerous
chess games have attracted the attention of chess players, data scientists, and
researchers during the last decades. State-of-the-art engines now provide an
authoritative judgement that can be used in many applications like cheating
detection, intrinsic ratings computation, skill assessment, or the study of
human decision-making. A key issue for the research community is to gather a
large dataset of chess games together with the judgement of chess engines.
Unfortunately the analysis of each move takes lots of times. In this paper, we
report our effort to analyse almost 5 millions chess games with a computing
grid. During summer 2015, we processed 270 millions unique played positions
using the Stockfish engine with a quite high depth (20). We populated a
database of 1+ tera-octets of chess evaluations, representing an estimated time
of 50 years of computation on a single machine. Our effort is a first step
towards the replication of research results, the supply of open data and
procedures for exploring new directions, and the investigation of software
engineering/scalability issues when computing billions of moves.
</dc:description>
 <dc:date>2016-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04193</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Clustering for Optical Confirmation and Redshift Estimation of
  X-ray Selected Galaxy Cluster Candidates in the SDSS Stripe 82</dc:title>
 <dc:creator>Mahmoud, Eman</dc:creator>
 <dc:creator>Takey, Ali</dc:creator>
 <dc:creator>Shoukry, Amin</dc:creator>
 <dc:subject>Astrophysics - Astrophysics of Galaxies</dc:subject>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  We develop a galaxy cluster finding algorithm based on spectral clustering
technique to identify optical counterparts and estimate optical redshifts for
X-ray selected cluster candidates. As an application, we run our algorithm on a
sample of X-ray cluster candidates selected from the third XMM-Newton
serendipitous source catalog (3XMM-DR5) that are located in the Stripe 82 of
the Sloan Digital Sky Survey (SDSS). Our method works on galaxies described in
the color-magnitude feature space. We begin by examining 45 galaxy clusters
with published spectroscopic redshifts in the range of 0.1 to 0.8 with a median
of 0.36. As a result, we are able to identify their optical counterparts and
estimate their photometric redshifts, which have a typical accuracy of 0.025
and agree with the published ones. Then, we investigate another 40 X-ray
cluster candidates (from the same cluster survey) with no redshift information
in the literature and found that 12 candidates are considered as galaxy
clusters in the redshift range from 0.29 to 0.76 with a median of 0.57. These
systems are newly discovered clusters in X-rays and optical data. Among them 7
clusters have spectroscopic redshifts for at least one member galaxy.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures, 3 tables, 1 appendix, Accepted by Journal of
  &quot;Astronomy and Computing&quot;</dc:description>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04193</dc:identifier>
 <dc:identifier>doi:10.1016/j.ascom.2016.07.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04197</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of an intermediate representation for query languages</dc:title>
 <dc:creator>Vernoux, Romain</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Data oriented applications, usually written in a high-level, general-purpose
programming language (such as Java) interact with database through a coarse
interface. Informally, the text of a query is built on the application side
(either via plain string concatenation or through an abstract notion of
statement) and shipped to the database over the wire where it is executed. The
results are then serialized and sent back to the &quot;client-code&quot; where they are
translated in the language's native datatypes. This round trip is detrimental
to performances but, worse, such a programming model prevents one from having
richer queries, namely queries containing user-defined functions (that is
functions defined by the programmer and used e.g. in the filter condition of a
SQL query). While some databases also possess a &quot;server-side&quot; language (e.g.
PL/SQL in Oracle database), its integration with the very-optimized query
execution engine is still minimal and queries containing (PL/SQL) user-defined
functions remain notoriously inefficient. In this setting, we reviewed existing
language-integrated query frameworks, highlighting that existing database query
languages (including SQL) share high-level querying primitives (e.g.,
filtering, joins, aggregation) that can be represented by operators, but differ
widely regarding the semantics of their expression language. In order to
represent queries in an application language- and database-agnostic manner, we
designed a small calculus, dubbed &quot;QIR&quot; for Query Intermediate Representation.
QIR contains expressions, corresponding to a small extension of the pure
lambda-calculus, and operators to represent usual querying primitives. In the
effort to send efficient queries to the database, we abstracted the idea of
&quot;good&quot; query representations in a measure on QIR terms. Then, we designed an
evaluation strategy rewriting QIR query representations into &quot;better&quot; ones.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04200</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edit Distance: Sketching, Streaming and Document Exchange</dc:title>
 <dc:creator>Belazzougui, Djamal</dc:creator>
 <dc:creator>Zhang, Qin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show that in the document exchange problem, where Alice holds $x \in
\{0,1\}^n$ and Bob holds $y \in \{0,1\}^n$, Alice can send Bob a message of
size $O(K(\log^2 K+\log n))$ bits such that Bob can recover $x$ using the
message and his input $y$ if the edit distance between $x$ and $y$ is no more
than $K$, and output &quot;error&quot; otherwise. Both the encoding and decoding can be
done in time $\tilde{O}(n+\mathsf{poly}(K))$. This result significantly
improves the previous communication bounds under polynomial encoding/decoding
time. We also show that in the referee model, where Alice and Bob hold $x$ and
$y$ respectively, they can compute sketches of $x$ and $y$ of sizes
$\mathsf{poly}(K \log n)$ bits (the encoding), and send to the referee, who can
then compute the edit distance between $x$ and $y$ together with all the edit
operations if the edit distance is no more than $K$, and output &quot;error&quot;
otherwise (the decoding). To the best of our knowledge, this is the first
result for sketching edit distance using $\mathsf{poly}(K \log n)$ bits.
Moreover, the encoding phase of our sketching algorithm can be performed by
scanning the input string in one pass. Thus our sketching algorithm also
implies the first streaming algorithm for computing edit distance and all the
edits exactly using $\mathsf{poly}(K \log n)$ bits of space.
</dc:description>
 <dc:description>Comment: Full version of an article to be presented at the 57th Annual IEEE
  Symposium on Foundations of Computer Science (FOCS 2016)</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04206</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliable MIMO Optical Wireless Communications Through Super-Rectangular
  Cover</dc:title>
 <dc:creator>Zhang, Yan-Yu</dc:creator>
 <dc:creator>Yu, Hong-Yi</dc:creator>
 <dc:creator>Zhang, Jian-Kang</dc:creator>
 <dc:creator>Wang, Jin-Long</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider an intensity modulated direct detection MIMO
optical wireless communication (OWC) system. For such a system, a novel
super-rectangular cover theory is developed to characterize both the unique
identifiability and full reliability. This theory states that a transmitted
matrix signal can be uniquely identified if and only if the cover order is
equal to the transmitter aperture number, i.e., full cover. In addition, we
prove that full reliability is guaranteed for space-time block coded MIMO-OWC
over commonly used log-normal fading channels with an ML detector if and only
if the STBC enables full cover. In addition, the diversity gain can be
geometrically interpreted as the cover order of the super-rectangle, which
should be maximized, and the volume of this super-rectangle, as the diversity
loss, should be minimized. Using this established error performance criterion,
the optimal linear STBC for block fading channels is proved to be spatial
repetition code with an optimal power allocation. The design of the optimal
non-linear STBC is shown to be equivalent to constructing the optimal
multi-dimensional constellation. Specifically, a multi-dimensional
constellation from Diophantine equations is proposed and then, shown to be more
energy-efficient than the commonly used nonnegative pulse amplitude modulation
constellation.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Informaiton Theory</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04220</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Complexity of Arranging Music</dc:title>
 <dc:creator>Moses, William S.</dc:creator>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  This paper proves that arrangement of music is NP-hard when subject to
various constraints: avoiding musical dissonance, limiting how many notes can
be played simultaneously, and limiting transition speed between chords. These
results imply the computational complexity of related musical problems,
including musical choreography and rhythm games.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04228</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fifty Shades of Ratings: How to Benefit from a Negative Feedback in
  Top-N Recommendations Tasks</dc:title>
 <dc:creator>Frolov, Evgeny</dc:creator>
 <dc:creator>Oseledets, Ivan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Conventional collaborative filtering techniques treat a top-n recommendations
problem as a task of generating a list of the most relevant items. This
formulation, however, disregards an opposite - avoiding recommendations with
completely irrelevant items. Due to that bias, standard algorithms, as well as
commonly used evaluation metrics, become insensitive to negative feedback. In
order to resolve this problem we propose to treat user feedback as a
categorical variable and model it with users and items in a ternary way. We
employ a third-order tensor factorization technique and implement a higher
order folding-in method to support online recommendations. The method is
equally sensitive to entire spectrum of user ratings and is able to accurately
predict relevant items even from a negative only feedback. Our method may
partially eliminate the need for complicated rating elicitation process as it
provides means for personalized recommendations from the very beginning of an
interaction with a recommender system. We also propose a modification of
standard metrics which helps to reveal unwanted biases and account for
sensitivity to a negative feedback. Our model achieves state-of-the-art quality
in standard recommendation tasks while significantly outperforming other
methods in the cold-start &quot;no-positive-feedback&quot; scenarios.
</dc:description>
 <dc:description>Comment: Accepted as a long paper at ACM RecSys 2016 conference, 8 pages, 6
  figures, 2 tables</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04228</dc:identifier>
 <dc:identifier>doi:10.1145/2959100.2959170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04229</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Viterbi is Hard: Better Runtimes Imply Faster Clique
  Algorithms</dc:title>
 <dc:creator>Backurs, Arturs</dc:creator>
 <dc:creator>Tzamos, Christos</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The classic algorithm of Viterbi computes the most likely path in a Hidden
Markov Model (HMM) that results in a given sequence of observations. It runs in
time $O(Tn^2)$ given a sequence of $T$ observations from a HMM with $n$ states.
Despite significant interest in the problem and prolonged effort by different
communities, no known algorithm achieves more than a polylogarithmic speedup.
  In this paper, we explain this difficulty by providing matching conditional
lower bounds. We show that the Viterbi algorithm runtime is optimal up to
subpolynomial factors even when the number of distinct observations is small.
Our lower bounds are based on assumptions that the best known algorithms for
the All-Pairs Shortest Paths problem (APSP) and for the Max-Weight $k$-Clique
problem in edge-weighted graphs are essentially tight.
  Finally, using a recent algorithm by Green Larsen and Williams for online
Boolean matrix-vector multiplication, we get a $2^{\Omega(\sqrt {\log n})}$
speedup for the Viterbi algorithm when there are few distinct transition
probabilities in the HMM.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04232</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Layerwise computability and image randomness</dc:title>
 <dc:creator>Bienvenu, Laurent</dc:creator>
 <dc:creator>Hoyrup, Mathieu</dc:creator>
 <dc:creator>Shen, Alexander</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>03D32</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  Algorithmic randomness theory starts with a notion of an individual random
object. To be reasonable, this notion should have some natural properties; in
particular, an object should be random with respect to image distribution if
and only if it has a random preimage. This result (for computable distributions
and mappings, and Martin-L\&quot;of randomness) was known for a long time
(folklore); in this paper we prove its natural generalization for layerwise
computable mappings, and discuss the related quantitative results.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04243</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A real-time analysis of rock fragmentation using UAV technology</dc:title>
 <dc:creator>Bamford, Thomas</dc:creator>
 <dc:creator>Esmaeili, Kamran</dc:creator>
 <dc:creator>Schoellig, Angela P.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accurate measurement of blast-induced rock fragmentation is of great
importance for many mining operations. The post-blast rock size distribution
can significantly influence the efficiency of all the downstream mining and
comminution processes. Image analysis methods are one of the most common
methods used to measure rock fragment size distribution in mines regardless of
criticism for lack of accuracy to measure fine particles and other perceived
deficiencies. The current practice of collecting rock fragmentation data for
image analysis is highly manual and provides data with low temporal and spatial
resolution. Using UAVs for collecting images of rock fragments can not only
improve the quality of the image data but also automate the data collection
process. Ultimately, real-time acquisition of high temporal- and
spatial-resolution data based on UAV technology will provide a broad range of
opportunities for both improving blast design without interrupting the
production process and reducing the cost of the human operator. This paper
presents the results of a series of laboratory-scale rock fragment measurements
using a quadrotor UAV equipped with a camera. The goal of this work is to
highlight the benefits of aerial fragmentation analysis in terms of both
prediction accuracy and time effort. A pile of rock fragments with different
fragment sizes was placed in a lab that is equipped with a motion capture
camera system for precise UAV localization and control. Such an environment
presents optimal conditions for UAV flight and thus, is well-suited for
conducting proof-of-concept experiments before testing them in large-scale
field experiments. The pile was photographed by a camera attached to the UAV,
and the particle size distribution curves were generated in almost real-time.
The pile was also manually photographed and the results of the manual method
were compared to the UAV method.
</dc:description>
 <dc:description>Comment: 12 pages, 12 figures, 6th International Conference on Computer
  Applications in the Minerals Industries</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04245</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite Element Integration with Quadrature on the GPU</dc:title>
 <dc:creator>Knepley, Matthew G.</dc:creator>
 <dc:creator>Rupp, Karl</dc:creator>
 <dc:creator>Terrel, Andy R.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  We present a novel, quadrature-based finite element integration method for
low-order elements on GPUs, using a pattern we call \textit{thread
transposition} to avoid reductions while vectorizing aggressively. On the
NVIDIA GTX580, which has a nominal single precision peak flop rate of 1.5 TF/s
and a memory bandwidth of 192 GB/s, we achieve close to 300 GF/s for element
integration on first-order discretization of the Laplacian operator with
variable coefficients in two dimensions, and over 400 GF/s in three dimensions.
From our performance model we find that this corresponds to 90\% of our
measured achievable bandwidth peak of 310 GF/s. Further experimental results
also match the predicted performance when used with double precision (120 GF/s
in two dimensions, 150 GF/s in three dimensions). Results obtained for the
linear elasticity equations (220 GF/s and 70 GF/s in two dimensions, 180 GF/s
and 60 GF/s in three dimensions) also demonstrate the applicability of our
method to vector-valued partial differential equations.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04254</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composing Scalable Nonlinear Algebraic Solvers</dc:title>
 <dc:creator>Brune, Peter R.</dc:creator>
 <dc:creator>Knepley, Matthew G.</dc:creator>
 <dc:creator>Smith, Barry F.</dc:creator>
 <dc:creator>Tu, Xuemin</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>65F08, 65Y05, 65Y20, 68W10</dc:subject>
 <dc:description>  Most efficient linear solvers use composable algorithmic components, with the
most common model being the combination of a Krylov accelerator and one or more
preconditioners. A similar set of concepts may be used for nonlinear algebraic
systems, where nonlinear composition of different nonlinear solvers may
significantly improve the time to solution. We describe the basic concepts of
nonlinear composition and preconditioning and present a number of solvers
applicable to nonlinear partial differential equations. We have developed a
software framework in order to easily explore the possible combinations of
solvers. We show that the performance gains from using composed solvers can be
substantial compared with gains from standard Newton-Krylov methods.
</dc:description>
 <dc:description>Comment: 29 pages, 14 figures, 13 tables</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04254</dc:identifier>
 <dc:identifier>SIAM Review 57(4), 535-565, 2015</dc:identifier>
 <dc:identifier>doi:10.1137/130936725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04255</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timed Supervisory Control for Operational Planning and Scheduling under
  Multiple Job Deadlines</dc:title>
 <dc:creator>Shehabinia, Ahmad Reza</dc:creator>
 <dc:creator>Lin, Liyong</dc:creator>
 <dc:creator>Su, Rong</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we model an operational planning and scheduling problem under
multiple job deadlines in a time-weighted automaton framework. We first present
a method to determine whether all given job specifications and deadlines can be
met by computing a supremal controllable job satisfaction sublanguage. When
this supremal sublanguage is not empty, we compute one of its controllable
sublanguages that ensures the minimum total job earliness by adding proper
delays. When this supremal sublanguage is empty, we will determine the minimal
sets of job deadlines that need to be relaxed.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04256</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Android Permission Model</dc:title>
 <dc:creator>Birendra, Chalise</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The recent evolution on the smart phone technology has made its application
market huge and less secure. Every single day large number of apps introduced
in the android market (mostly on google play store) without any particular
inspections which creates a lot of security issues and they remain unresolved.
There are a lot of recent and increasing security issues which are mostly
caused by the android apps. Mainly, the access of user data through the apps
relied on the users given permission to apps.So, it is always a big question
that how different apps on the android smart phones bypass the android
permission model to have root access and how user data compromised or stolen by
its apps. It is not startling that the Google Play Store has massive number of
malicious apps that may gain users attention to fall victim for one, but some
time it might be even worse than we thought. In this paper, we will look at the
security issues (i.e. rooting phone, malware bypassing and secondary storage)
and how easy to get access to users phone by using its app.
  Furthermore, I will discuss the android update mechanism and its
functionalities as well as vulnerability to possible third party bypassing and
root access. Moreover, a key feature and source of the all possible access
route to android applications I will discuss an android permission model.
Finally, I will first time present concept of the feature based development
model implementing a feature based permission selections as a solution to
android application system and describe the purposed Feature based permission
model in detail how it is the solution for current security issues caused by
intentional (evil coded) or unintentional (poorly coded) coding using android
permission models.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figure</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2016-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04263</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Limits of Popularity-Based Recommendations, and the Role of Social
  Ties</dc:title>
 <dc:creator>Bressan, Marco</dc:creator>
 <dc:creator>Leucci, Stefano</dc:creator>
 <dc:creator>Panconesi, Alessandro</dc:creator>
 <dc:creator>Raghavan, Prabhakar</dc:creator>
 <dc:creator>Terolli, Erisa</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this paper we introduce a mathematical model that captures some of the
salient features of recommender systems that are based on popularity and that
try to exploit social ties among the users. We show that, under very general
conditions, the market always converges to a steady state, for which we are
able to give an explicit form. Thanks to this we can tell rather precisely how
much a market is altered by a recommendation system, and determine the power of
users to influence others. Our theoretical results are complemented by
experiments with real world social networks showing that social graphs prevent
large market distortions in spite of the presence of highly influential users.
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures, KDD 2016</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04263</dc:identifier>
 <dc:identifier>doi:10.1145/2939672.2939797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04267</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced Boolean Correlation Matrix Memory</dc:title>
 <dc:creator>Mastriani, Mario</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper introduces an Enhanced Boolean version of the Correlation Matrix
Memory (CMM), which is useful to work with binary memories. A novel Boolean
Orthonormalization Process (BOP) is presented to convert a non-orthonormal
Boolean basis, i.e., a set of non-orthonormal binary vectors (in a Boolean
sense) to an orthonormal Boolean basis, i.e., a set of orthonormal binary
vectors (in a Boolean sense). This work shows that it is possible to improve
the performance of Boolean CMM thanks BOP algorithm. Besides, the BOP algorithm
has a lot of additional fields of applications, e.g.: Steganography, Hopfield
Networks, Bi-level image processing, etc. Finally, it is important to mention
that the BOP is an extremely stable and fast algorithm.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures</dc:description>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04287</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Diophantine Equations, Group CSPs, and Graph Isomorphism</dc:title>
 <dc:creator>Berkholz, Christoph</dc:creator>
 <dc:creator>Grohe, Martin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In recent years, we have seen several approaches to the graph isomorphism
problem based on &quot;generic&quot; mathematical programming or algebraic (Gr\&quot;obner
basis) techniques. For most of these, lower bounds have been established. In
fact, it has been shown that the pairs of nonisomorphic CFI-graphs (introduced
by Cai, F\&quot;urer, and Immerman in 1992 as hard examples for the combinatorial
Weisfeiler-Leman algorithm) cannot be distinguished by these mathematical
algorithms. A notable exception were the algebraic algorithms over the field
GF(2), for which no lower bound was known. Another, in some way even stronger,
approach to graph isomorphism testing is based on solving systems of linear
Diophantine equations (that is, linear equations over the integers), which is
known to be possible in polynomial time. So far, no lower bounds for this
approach were known.
  Lower bounds for the algebraic algorithms can best be proved in the framework
of proof complexity, where they can be phrased as lower bounds for algebraic
proof systems such as Nullstellensatz or the (more powerful) polynomial
calculus. We give new hard examples for these systems: families of pairs of
non-isomorphic graphs that are hard to distinguish by polynomial calculus
proofs simultaneously over all prime fields, including GF(2), as well as
examples that are hard to distinguish by the
systems-of-linear-Diophantine-equations approach.
  In a previous paper, we observed that the CFI-graphs are closely related to
what we call &quot;group CSPs&quot;: constraint satisfaction problems where the
constraints are membership tests in some coset of a subgroup of a cartesian
power of a base group (Z_2 in the case of the classical CFI-graphs). Our new
examples are also based on group CSPs (for Abelian groups), but here we extend
the CSPs by a few non-group constraints to obtain even harder instances for
graph isomorphism.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04298</identifier>
 <datestamp>2016-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Placement of Cores, Caches and Memory Controllers in Network
  On-Chip</dc:title>
 <dc:creator>Tootaghaj, Diman Zad</dc:creator>
 <dc:creator>Farhat, Farshid</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Parallel programming is emerging fast and intensive applications need more
resources, so there is a huge demand for on-chip multiprocessors. Accessing L1
caches beside the cores are the fastest after registers but the size of private
caches cannot increase because of design, cost and technology limits. Then
split I-cache and D-cache are used with shared LLC (last level cache). For a
unified shared LLC, bus interface is not scalable, and it seems that
distributed shared LLC (DSLLC) is a better choice. Most of papers assume a
distributed shared LLC beside each core in on-chip network. Many works assume
that DSLLCs are placed in all cores; however, we will show that this design
ignores the effect of traffic congestion in on-chip network. In fact, our work
focuses on optimal placement of cores, DSLLCs and even memory controllers to
minimize the expected latency based on traffic load in a mesh on-chip network
with fixed number of cores and total cache capacity. We try to do some
analytical modeling deriving intended cost function and then optimize the mean
delay of the on-chip network communication. This work is supposed to be
verified using some traffic patterns that are run on CSIM simulator.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2016-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04311</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Defensive Distillation is Not Robust to Adversarial Examples</dc:title>
 <dc:creator>Carlini, Nicholas</dc:creator>
 <dc:creator>Wagner, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We show that defensive distillation is not secure: it is no more resistant to
targeted misclassification attacks than unprotected neural networks.
</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04315</identifier>
 <datestamp>2017-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Semantic Encoders</dc:title>
 <dc:creator>Munkhdalai, Tsendsuren</dc:creator>
 <dc:creator>Yu, Hong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a memory augmented neural network for natural language
understanding: Neural Semantic Encoders. NSE is equipped with a novel memory
update rule and has a variable sized encoding memory that evolves over time and
maintains the understanding of input sequences through read}, compose and write
operations. NSE can also access multiple and shared memories. In this paper, we
demonstrated the effectiveness and the flexibility of NSE on five different
natural language tasks: natural language inference, question answering,
sentence classification, document sentiment analysis and machine translation
where NSE achieved state-of-the-art performance when evaluated on publically
available benchmarks. For example, our shared-memory model showed an
encouraging result on neural machine translation, improving an attention-based
baseline by approximately 1.0 BLEU.
</dc:description>
 <dc:description>Comment: Accepted in EACL 2017, added: comparison with NTM, qualitative
  analysis and memory visualization</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:date>2017-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04318</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Citizen Reactions and Ebola-Related Information
  Propagation on Social Media</dc:title>
 <dc:creator>Tran, Thanh</dc:creator>
 <dc:creator>Lee, Kyumin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In severe outbreaks such as Ebola, bird flu and SARS, people share news, and
their thoughts and responses regarding the outbreaks on social media.
Understanding how people perceive the severe outbreaks, what their responses
are, and what factors affect these responses become important. In this paper,
we conduct a comprehensive study of understanding and mining the spread of
Ebola-related information on social media. In particular, we (i) conduct a
large-scale data-driven analysis of geotagged social media messages to
understand citizen reactions regarding Ebola; (ii) build information
propagation models which measure locality of information; and (iii) analyze
spatial, temporal and social properties of Ebola-related information. Our work
provides new insights into Ebola outbreak by understanding citizen reactions
and topic-based information propagation, as well as providing a foundation for
analysis and response of future public health crises.
</dc:description>
 <dc:description>Comment: 2016 IEEE/ACM International Conference on Advances in Social Networks
  Analysis and Mining (ASONAM 2016)</dc:description>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04320</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Repository Adaptibility in an Agent-Based University
  Environment</dc:title>
 <dc:creator>Cabukovski, Vanco</dc:creator>
 <dc:creator>Golubovski, Roman</dc:creator>
 <dc:creator>Temjanovski, Riste</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Automated e-Learning Systems (AeLS) are fundamental to contemporary
educational concepts worldwide. It has become a standard not only in support to
the formal curriculum, but containing social platform capabilities,
gamification elements and functionalities fostering communities of experts,
also for faster knowledge dissemination. Additionally, AeLSs support internal
communications and customizable analytics and methodologies to quickly identify
learning performance, which in turn can be used as feedback to implement
adaptability in tailoring the content management to meet specific individual
needs. The volume of fast growing AeLS content of supplement material and
exchanged communication combined with the already huge material archived in the
university libraries is enormous and needs sophisticated managing through
electronic repositories. Such integration of content management systems (CMS)
present challenges which can be solved optimally with the use of distributed
management implemented through agent-based systems. This paper depicts a
successful implementation of an Integrated Intelligent Agent Based University
Information System (IABUIS).
</dc:description>
 <dc:description>Comment: 14 pages 4 figures</dc:description>
 <dc:date>2016-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1607.04320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="101000" completeListSize="155308">2369777|102001</resumptionToken>
</ListRecords>
</OAI-PMH>
